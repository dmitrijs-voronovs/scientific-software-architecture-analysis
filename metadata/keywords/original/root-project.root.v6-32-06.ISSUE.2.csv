id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/root-project/root/pull/3062:440,Performance,perform,performance,440,"TTreeProcessorMT does not guarantee that TTreeReader::GetCurrentEntry; returns the global entry number of the underlying dataset.; RDF, however, needs a unique entry identifier to use for Filter/Define; cache invalidation, so for MT runs we now use an atomic counter. As a consequence, in MT runs `rdfentry_` is now an arbitrary integer; with no connection to the underlying ROOT dataset. This PR solves the same bug as #3051 , without the performance hit, at the cost of losing correspondence between RDF's `rdfentry_` column values and the global entry numbers in a corresponding TChain.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3062
https://github.com/root-project/root/pull/3066:268,Availability,error,error,268,"The `dnn_cuda` library is only an intermediate library that is not meant to be installed with ROOT, so it needs to be static since TMVA needs to export its dependencies and if this library is shared; the dependency won't be there after a `make install'. Therefore the error in CMake:. ```; CMake Error: install(EXPORT ""ROOTExports"" ...) includes target ""TMVA"" which requires target ""dnn_cuda"" that is not in the export set.; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3066
https://github.com/root-project/root/pull/3066:296,Availability,Error,Error,296,"The `dnn_cuda` library is only an intermediate library that is not meant to be installed with ROOT, so it needs to be static since TMVA needs to export its dependencies and if this library is shared; the dependency won't be there after a `make install'. Therefore the error in CMake:. ```; CMake Error: install(EXPORT ""ROOTExports"" ...) includes target ""TMVA"" which requires target ""dnn_cuda"" that is not in the export set.; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3066
https://github.com/root-project/root/pull/3066:79,Deployability,install,installed,79,"The `dnn_cuda` library is only an intermediate library that is not meant to be installed with ROOT, so it needs to be static since TMVA needs to export its dependencies and if this library is shared; the dependency won't be there after a `make install'. Therefore the error in CMake:. ```; CMake Error: install(EXPORT ""ROOTExports"" ...) includes target ""TMVA"" which requires target ""dnn_cuda"" that is not in the export set.; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3066
https://github.com/root-project/root/pull/3066:244,Deployability,install,install,244,"The `dnn_cuda` library is only an intermediate library that is not meant to be installed with ROOT, so it needs to be static since TMVA needs to export its dependencies and if this library is shared; the dependency won't be there after a `make install'. Therefore the error in CMake:. ```; CMake Error: install(EXPORT ""ROOTExports"" ...) includes target ""TMVA"" which requires target ""dnn_cuda"" that is not in the export set.; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3066
https://github.com/root-project/root/pull/3066:303,Deployability,install,install,303,"The `dnn_cuda` library is only an intermediate library that is not meant to be installed with ROOT, so it needs to be static since TMVA needs to export its dependencies and if this library is shared; the dependency won't be there after a `make install'. Therefore the error in CMake:. ```; CMake Error: install(EXPORT ""ROOTExports"" ...) includes target ""TMVA"" which requires target ""dnn_cuda"" that is not in the export set.; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3066
https://github.com/root-project/root/pull/3066:156,Integrability,depend,dependencies,156,"The `dnn_cuda` library is only an intermediate library that is not meant to be installed with ROOT, so it needs to be static since TMVA needs to export its dependencies and if this library is shared; the dependency won't be there after a `make install'. Therefore the error in CMake:. ```; CMake Error: install(EXPORT ""ROOTExports"" ...) includes target ""TMVA"" which requires target ""dnn_cuda"" that is not in the export set.; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3066
https://github.com/root-project/root/pull/3066:204,Integrability,depend,dependency,204,"The `dnn_cuda` library is only an intermediate library that is not meant to be installed with ROOT, so it needs to be static since TMVA needs to export its dependencies and if this library is shared; the dependency won't be there after a `make install'. Therefore the error in CMake:. ```; CMake Error: install(EXPORT ""ROOTExports"" ...) includes target ""TMVA"" which requires target ""dnn_cuda"" that is not in the export set.; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3066
https://github.com/root-project/root/pull/3069:40,Integrability,depend,dependent,40,"This removes the implementation headers dependent on OpenCascade from the include directory of geocad (moved to src), keeping only the interface header. Added an example of use in tutorials (geo2occ.C)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3069
https://github.com/root-project/root/pull/3069:135,Integrability,interface,interface,135,"This removes the implementation headers dependent on OpenCascade from the include directory of geocad (moved to src), keeping only the interface header. Added an example of use in tutorials (geo2occ.C)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3069
https://github.com/root-project/root/pull/3082:103,Integrability,inject,injects,103,"As a follow up of the discussion in ROOT-9846:. https://sft.its.cern.ch/jira/browse/ROOT-9846. This PR injects the necessary pythonizations to support the `len(c)` syntax when getting the size of containers (`TCollection`, `TArray`, `RooAbsCollection` and their respective derivates) from Python.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3082
https://github.com/root-project/root/pull/3082:103,Security,inject,injects,103,"As a follow up of the discussion in ROOT-9846:. https://sft.its.cern.ch/jira/browse/ROOT-9846. This PR injects the necessary pythonizations to support the `len(c)` syntax when getting the size of containers (`TCollection`, `TArray`, `RooAbsCollection` and their respective derivates) from Python.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3082
https://github.com/root-project/root/pull/3083:290,Deployability,update,updated,290,"RooDataSets can be written to ASCII files. However, the output stream is not exposed to the user, i.e., the user cannot modify e.g. the precision. By exposing the stream to the user, the data set can be written to any ostream with user-defined stream modifiers. The rf102 tutorial has been updated accordingly, input/output tests have been added.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3083
https://github.com/root-project/root/pull/3083:77,Security,expose,exposed,77,"RooDataSets can be written to ASCII files. However, the output stream is not exposed to the user, i.e., the user cannot modify e.g. the precision. By exposing the stream to the user, the data set can be written to any ostream with user-defined stream modifiers. The rf102 tutorial has been updated accordingly, input/output tests have been added.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3083
https://github.com/root-project/root/pull/3083:324,Testability,test,tests,324,"RooDataSets can be written to ASCII files. However, the output stream is not exposed to the user, i.e., the user cannot modify e.g. the precision. By exposing the stream to the user, the data set can be written to any ostream with user-defined stream modifiers. The rf102 tutorial has been updated accordingly, input/output tests have been added.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3083
https://github.com/root-project/root/pull/3094:136,Availability,error,error,136,"This is a leftover from e6d7c53889f35bfbb986bf1890a89501b6900d41,; dependency for rootd.rc.d needs to be deleted. This patch fixes this error when you run install:; ```; CMake Error at cmake_install.cmake:132 (file):; file INSTALL cannot find; ""/build/yuka/build-py2-rootpy/BUILD/slc7_amd64_gcc700/lcg/root/6.15.01-cms/build/etc/daemons/rootd.rc.d"".; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3094
https://github.com/root-project/root/pull/3094:176,Availability,Error,Error,176,"This is a leftover from e6d7c53889f35bfbb986bf1890a89501b6900d41,; dependency for rootd.rc.d needs to be deleted. This patch fixes this error when you run install:; ```; CMake Error at cmake_install.cmake:132 (file):; file INSTALL cannot find; ""/build/yuka/build-py2-rootpy/BUILD/slc7_amd64_gcc700/lcg/root/6.15.01-cms/build/etc/daemons/rootd.rc.d"".; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3094
https://github.com/root-project/root/pull/3094:119,Deployability,patch,patch,119,"This is a leftover from e6d7c53889f35bfbb986bf1890a89501b6900d41,; dependency for rootd.rc.d needs to be deleted. This patch fixes this error when you run install:; ```; CMake Error at cmake_install.cmake:132 (file):; file INSTALL cannot find; ""/build/yuka/build-py2-rootpy/BUILD/slc7_amd64_gcc700/lcg/root/6.15.01-cms/build/etc/daemons/rootd.rc.d"".; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3094
https://github.com/root-project/root/pull/3094:155,Deployability,install,install,155,"This is a leftover from e6d7c53889f35bfbb986bf1890a89501b6900d41,; dependency for rootd.rc.d needs to be deleted. This patch fixes this error when you run install:; ```; CMake Error at cmake_install.cmake:132 (file):; file INSTALL cannot find; ""/build/yuka/build-py2-rootpy/BUILD/slc7_amd64_gcc700/lcg/root/6.15.01-cms/build/etc/daemons/rootd.rc.d"".; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3094
https://github.com/root-project/root/pull/3094:223,Deployability,INSTALL,INSTALL,223,"This is a leftover from e6d7c53889f35bfbb986bf1890a89501b6900d41,; dependency for rootd.rc.d needs to be deleted. This patch fixes this error when you run install:; ```; CMake Error at cmake_install.cmake:132 (file):; file INSTALL cannot find; ""/build/yuka/build-py2-rootpy/BUILD/slc7_amd64_gcc700/lcg/root/6.15.01-cms/build/etc/daemons/rootd.rc.d"".; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3094
https://github.com/root-project/root/pull/3094:67,Integrability,depend,dependency,67,"This is a leftover from e6d7c53889f35bfbb986bf1890a89501b6900d41,; dependency for rootd.rc.d needs to be deleted. This patch fixes this error when you run install:; ```; CMake Error at cmake_install.cmake:132 (file):; file INSTALL cannot find; ""/build/yuka/build-py2-rootpy/BUILD/slc7_amd64_gcc700/lcg/root/6.15.01-cms/build/etc/daemons/rootd.rc.d"".; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3094
https://github.com/root-project/root/pull/3095:68,Deployability,install,installation,68,"This PR removes some remnants of the previous PR, preventing proper installation.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3095
https://github.com/root-project/root/pull/3096:266,Deployability,patch,patch,266,"Using clang 4 to build with C++ 17 support fails as `__cplusplus` is defined as [`201406L`](https://github.com/llvm-mirror/clang/blob/release_40/lib/Frontend/InitPreprocessor.cpp#L379) for `cxx17`. This is needed for the macOS conda package, but it can be left as a patch that is applied before configuring if you would rather keep the checking against the correct value.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3096
https://github.com/root-project/root/pull/3096:295,Modifiability,config,configuring,295,"Using clang 4 to build with C++ 17 support fails as `__cplusplus` is defined as [`201406L`](https://github.com/llvm-mirror/clang/blob/release_40/lib/Frontend/InitPreprocessor.cpp#L379) for `cxx17`. This is needed for the macOS conda package, but it can be left as a patch that is applied before configuring if you would rather keep the checking against the correct value.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3096
https://github.com/root-project/root/pull/3098:20,Availability,error,error,20,"Link to compilation error:; https://epsft-jenkins.cern.ch/view/ROOT%20Nightly/job/root-nightly-master/1977/LABEL=mac1012,SPEC=noimt/parsed_console/. The error is due to a bug in clang3.5, reproducible in isolation:; https://godbolt.org/z/jtYXv6. The workaround is to avoid specifying the template parameters of a; template base class -- the full type is injected in the derived class; anyway (thanks Axel!).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3098
https://github.com/root-project/root/pull/3098:153,Availability,error,error,153,"Link to compilation error:; https://epsft-jenkins.cern.ch/view/ROOT%20Nightly/job/root-nightly-master/1977/LABEL=mac1012,SPEC=noimt/parsed_console/. The error is due to a bug in clang3.5, reproducible in isolation:; https://godbolt.org/z/jtYXv6. The workaround is to avoid specifying the template parameters of a; template base class -- the full type is injected in the derived class; anyway (thanks Axel!).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3098
https://github.com/root-project/root/pull/3098:354,Integrability,inject,injected,354,"Link to compilation error:; https://epsft-jenkins.cern.ch/view/ROOT%20Nightly/job/root-nightly-master/1977/LABEL=mac1012,SPEC=noimt/parsed_console/. The error is due to a bug in clang3.5, reproducible in isolation:; https://godbolt.org/z/jtYXv6. The workaround is to avoid specifying the template parameters of a; template base class -- the full type is injected in the derived class; anyway (thanks Axel!).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3098
https://github.com/root-project/root/pull/3098:267,Safety,avoid,avoid,267,"Link to compilation error:; https://epsft-jenkins.cern.ch/view/ROOT%20Nightly/job/root-nightly-master/1977/LABEL=mac1012,SPEC=noimt/parsed_console/. The error is due to a bug in clang3.5, reproducible in isolation:; https://godbolt.org/z/jtYXv6. The workaround is to avoid specifying the template parameters of a; template base class -- the full type is injected in the derived class; anyway (thanks Axel!).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3098
https://github.com/root-project/root/pull/3098:354,Security,inject,injected,354,"Link to compilation error:; https://epsft-jenkins.cern.ch/view/ROOT%20Nightly/job/root-nightly-master/1977/LABEL=mac1012,SPEC=noimt/parsed_console/. The error is due to a bug in clang3.5, reproducible in isolation:; https://godbolt.org/z/jtYXv6. The workaround is to avoid specifying the template parameters of a; template base class -- the full type is injected in the derived class; anyway (thanks Axel!).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3098
https://github.com/root-project/root/pull/3100:816,Security,secur,secure,816,"Functions and classes that are outdated, but will probably never be removed, can be flagged with deprecation warnings at the discretion of the user. This was a request by the experiments during the Sarajevo workshop.; The macros would be used as follows:; ```; class BetterNotUse {; } R__SUGGEST_CLASS(""NewerClass"");; ```; ```; TIterator* createIterator() const; R__SUGGEST_FUNCTION(""begin(), end() or range-based for loops.""); {; return new RooLinkedListIter(makeLegacyIterator());; }; ```; Since this uses class/function attributes, these need to be put *after* the class body and *before* the function body. Defining `R__SUGGEST_FASTER_FUNCTIONS`, the compiler will e.g. issue:; ```; root-src/roofit/roofitcore/src/RooAbsCollection.cxx:725:21: warning: 'fwdIterator' is deprecated:; This function has faster/more secure alternatives:; begin(), end() and range-based for loops. [-Wdeprecated-declarations]; RooFIter iter = fwdIterator() ;; ^; ```; With `R__SUGGEST_FASTER_CLASSES`, one gets:; ```; /home/shageboe/root-dbg/include/RooStats/RooStatsUtils.h:64:7: warning: 'RooLinkedListIter' is deprecated: This class has a faster/more secure alternative: The ROOFIter is faster. [-Wdeprecated-declarations]; RooLinkedListIter it = set->iterator();; ```; PS: Names are totally up for debate.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3100
https://github.com/root-project/root/pull/3100:1136,Security,secur,secure,1136,"Functions and classes that are outdated, but will probably never be removed, can be flagged with deprecation warnings at the discretion of the user. This was a request by the experiments during the Sarajevo workshop.; The macros would be used as follows:; ```; class BetterNotUse {; } R__SUGGEST_CLASS(""NewerClass"");; ```; ```; TIterator* createIterator() const; R__SUGGEST_FUNCTION(""begin(), end() or range-based for loops.""); {; return new RooLinkedListIter(makeLegacyIterator());; }; ```; Since this uses class/function attributes, these need to be put *after* the class body and *before* the function body. Defining `R__SUGGEST_FASTER_FUNCTIONS`, the compiler will e.g. issue:; ```; root-src/roofit/roofitcore/src/RooAbsCollection.cxx:725:21: warning: 'fwdIterator' is deprecated:; This function has faster/more secure alternatives:; begin(), end() and range-based for loops. [-Wdeprecated-declarations]; RooFIter iter = fwdIterator() ;; ^; ```; With `R__SUGGEST_FASTER_CLASSES`, one gets:; ```; /home/shageboe/root-dbg/include/RooStats/RooStatsUtils.h:64:7: warning: 'RooLinkedListIter' is deprecated: This class has a faster/more secure alternative: The ROOFIter is faster. [-Wdeprecated-declarations]; RooLinkedListIter it = set->iterator();; ```; PS: Names are totally up for debate.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3100
https://github.com/root-project/root/pull/3104:31,Deployability,release,releases,31,This allows us to create daily releases and binaries for arbitrary tags (not just `x.yy.zz` as currently allowed by `build/version_number`),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3104
https://github.com/root-project/root/pull/3107:975,Integrability,wrap,wrapped,975,"This implements the `RDataFrame` pythonization `AsNumpy`, which reads out the dataframe as a collection of numpy arrays. Here's an example how it looks like:. ```python; df = ROOT.RDataFrame(""Events"", ""root://eospublic.cern.ch//eos/root-eos/cms_opendata_2012_nanoaod/Run2012B_DoubleMuParked.root"") \; .Filter(""All(Muon_pt>30)"", ""Only events with muons that have pt larger 30GeV""); npy = df.AsNumpy(columns=[""nMuon"", ""PV_npvs""]). print(""Number of events selected: {}"".format(npy[""PV_npvs""].size)); print(""Average number of primary vertices per event: {:.2f}"".format(numpy.mean(npy[""PV_npvs""]))); print(""Average number of muons per event: {:.2f}"".format(numpy.mean(npy[""nMuon""]))); ```; ```; Number of events selected: 2846996; Average number of primary vertices per event: 16.03; Average number of muons per event: 1.29; ```. In addition to reading fundamental types, we support reading out any type of C++ object in the file being returned as a numpy array of Python objects wrapped by PyROOT. ```python; ROOT.gInterpreter.Declare(""""""; // Inject the C++ class CustomObject in the C++ runtime.; class CustomObject {; public:; int x = 42;; };; // Create a function that returns such an object. This is called to fill the dataframe.; CustomObject fill_object() { return CustomObject(); }; """"""). df = ROOT.RDataFrame(4).Define(""custom_object"", ""fill_object()""); npy = df.AsNumpy(); print(npy); ```; ```; {'custom_object': array([<ROOT.CustomObject object at 0x64d8d50>,; <ROOT.CustomObject object at 0x79bd140>,; <ROOT.CustomObject object at 0x743f440>,; <ROOT.CustomObject object at 0x7359710>], dtype=object)}; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3107
https://github.com/root-project/root/pull/3107:1039,Integrability,Inject,Inject,1039,"This implements the `RDataFrame` pythonization `AsNumpy`, which reads out the dataframe as a collection of numpy arrays. Here's an example how it looks like:. ```python; df = ROOT.RDataFrame(""Events"", ""root://eospublic.cern.ch//eos/root-eos/cms_opendata_2012_nanoaod/Run2012B_DoubleMuParked.root"") \; .Filter(""All(Muon_pt>30)"", ""Only events with muons that have pt larger 30GeV""); npy = df.AsNumpy(columns=[""nMuon"", ""PV_npvs""]). print(""Number of events selected: {}"".format(npy[""PV_npvs""].size)); print(""Average number of primary vertices per event: {:.2f}"".format(numpy.mean(npy[""PV_npvs""]))); print(""Average number of muons per event: {:.2f}"".format(numpy.mean(npy[""nMuon""]))); ```; ```; Number of events selected: 2846996; Average number of primary vertices per event: 16.03; Average number of muons per event: 1.29; ```. In addition to reading fundamental types, we support reading out any type of C++ object in the file being returned as a numpy array of Python objects wrapped by PyROOT. ```python; ROOT.gInterpreter.Declare(""""""; // Inject the C++ class CustomObject in the C++ runtime.; class CustomObject {; public:; int x = 42;; };; // Create a function that returns such an object. This is called to fill the dataframe.; CustomObject fill_object() { return CustomObject(); }; """"""). df = ROOT.RDataFrame(4).Define(""custom_object"", ""fill_object()""); npy = df.AsNumpy(); print(npy); ```; ```; {'custom_object': array([<ROOT.CustomObject object at 0x64d8d50>,; <ROOT.CustomObject object at 0x79bd140>,; <ROOT.CustomObject object at 0x743f440>,; <ROOT.CustomObject object at 0x7359710>], dtype=object)}; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3107
https://github.com/root-project/root/pull/3107:1039,Security,Inject,Inject,1039,"This implements the `RDataFrame` pythonization `AsNumpy`, which reads out the dataframe as a collection of numpy arrays. Here's an example how it looks like:. ```python; df = ROOT.RDataFrame(""Events"", ""root://eospublic.cern.ch//eos/root-eos/cms_opendata_2012_nanoaod/Run2012B_DoubleMuParked.root"") \; .Filter(""All(Muon_pt>30)"", ""Only events with muons that have pt larger 30GeV""); npy = df.AsNumpy(columns=[""nMuon"", ""PV_npvs""]). print(""Number of events selected: {}"".format(npy[""PV_npvs""].size)); print(""Average number of primary vertices per event: {:.2f}"".format(numpy.mean(npy[""PV_npvs""]))); print(""Average number of muons per event: {:.2f}"".format(numpy.mean(npy[""nMuon""]))); ```; ```; Number of events selected: 2846996; Average number of primary vertices per event: 16.03; Average number of muons per event: 1.29; ```. In addition to reading fundamental types, we support reading out any type of C++ object in the file being returned as a numpy array of Python objects wrapped by PyROOT. ```python; ROOT.gInterpreter.Declare(""""""; // Inject the C++ class CustomObject in the C++ runtime.; class CustomObject {; public:; int x = 42;; };; // Create a function that returns such an object. This is called to fill the dataframe.; CustomObject fill_object() { return CustomObject(); }; """"""). df = ROOT.RDataFrame(4).Define(""custom_object"", ""fill_object()""); npy = df.AsNumpy(); print(npy); ```; ```; {'custom_object': array([<ROOT.CustomObject object at 0x64d8d50>,; <ROOT.CustomObject object at 0x79bd140>,; <ROOT.CustomObject object at 0x743f440>,; <ROOT.CustomObject object at 0x7359710>], dtype=object)}; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3107
https://github.com/root-project/root/pull/3108:20,Usability,simpl,simply,20,Why can't compilers simply ignore these options when they don't know?,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3108
https://github.com/root-project/root/pull/3111:18,Performance,load,loaded,18,"If `libPyROOT` is loaded with `gSystem->Load`, the static initialization block in `TMemoryRegulator.cxx` is executed and ends up invoking `PyCFunction_New`, which causes a crash from Python 3.7. The crash is due to Python not being initialized, so we need to protect that case. Note that when loading `libPyROOT` from `ROOT.py`, which is what happens when someone uses PyROOT, the Python interpreter already exists and is initialized, so invoking `PyCFunction_New` does not crash.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3111
https://github.com/root-project/root/pull/3111:40,Performance,Load,Load,40,"If `libPyROOT` is loaded with `gSystem->Load`, the static initialization block in `TMemoryRegulator.cxx` is executed and ends up invoking `PyCFunction_New`, which causes a crash from Python 3.7. The crash is due to Python not being initialized, so we need to protect that case. Note that when loading `libPyROOT` from `ROOT.py`, which is what happens when someone uses PyROOT, the Python interpreter already exists and is initialized, so invoking `PyCFunction_New` does not crash.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3111
https://github.com/root-project/root/pull/3111:293,Performance,load,loading,293,"If `libPyROOT` is loaded with `gSystem->Load`, the static initialization block in `TMemoryRegulator.cxx` is executed and ends up invoking `PyCFunction_New`, which causes a crash from Python 3.7. The crash is due to Python not being initialized, so we need to protect that case. Note that when loading `libPyROOT` from `ROOT.py`, which is what happens when someone uses PyROOT, the Python interpreter already exists and is initialized, so invoking `PyCFunction_New` does not crash.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3111
https://github.com/root-project/root/pull/3127:159,Deployability,Patch,Patch,159,If we include the definition of SMatrix after MathFunctions.h (which; relies on HelperOps.h (to forward declare SMatrix) we cannot see the; default arguments. Patch by Lorenzo Moneta and me!. (cherry picked from commit d4b004c641b1e939250eb17721083a2016172bef),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3127
https://github.com/root-project/root/pull/3135:200,Availability,error,errors,200,…Helper for basic types. Make copy-constructor extern and put extern templates of the `TakeHelper` to speed-up the `Take` action of basic types. This prepares #3107. ~~TODO: Put ifdef guards to catch errors with gcc5 and others.~~,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3135
https://github.com/root-project/root/pull/3145:3,Safety,avoid,avoid,3,to avoid an odd namespace to appear in the doc,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3145
https://github.com/root-project/root/pull/3149:45,Testability,test,test,45,This addresses point 1 of issue ROOT-9742. A test macro with instructions on how optical surface information can be retrieved from TGeoManager is provided in: tutorials/geom/gdml/testoptical.C,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3149
https://github.com/root-project/root/pull/3149:179,Testability,test,testoptical,179,This addresses point 1 of issue ROOT-9742. A test macro with instructions on how optical surface information can be retrieved from TGeoManager is provided in: tutorials/geom/gdml/testoptical.C,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3149
https://github.com/root-project/root/pull/3150:25,Deployability,patch,patch,25,"Hi,; I'm trying to add a patch to address the issue here: https://sft.its.cern.ch/jira/browse/ROOT-9655.; There are two features:; 1) using the default option, TPaletteAxis will have the same range as the early histogram that the current histogram is normalized to, and thus the correct palette;; 2) New options ""SAME0"" and ""SAMES0"" to allow opting out of the default normalization.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3150
https://github.com/root-project/root/pull/3152:422,Testability,test,tests,422,"This PR addresses the report in [ROOT-9859](https://sft.its.cern.ch/jira/browse/ROOT-9859) about the change in behaviour of `__str__`, which now relies on cling to obtain a pretty printing for a class. With this PR, if what we obtain from cling is not pretty but just an address, we fall back to `__repr__` in `__str__`. The PR contains the changes for both current and experimental PyROOT, together with their respective tests and tutorials.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3152
https://github.com/root-project/root/pull/3153:650,Safety,avoid,avoid,650,"from one entry to another.; It can happen that the size of C arrays stored in branches varies a lot; from event to event. It can happen also that a very small array becomes; suddently very big. This triggers a reallocation of the buffer ROOT; uses internally to hold the read content.; When snapshotting, RDataFrame, was setting the addresses of the output; tree only once at the 1st event processed (per slot). This of course could; lead to the persistification of corrupted values. This change allow to keep track of the changing addresses and properly; handle them via the TBranch::SetAddress method. A test is also added to the suite in order to avoid regressions in the; future. Nota bene: this **does also** fix ROOT-9860",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3153
https://github.com/root-project/root/pull/3153:606,Testability,test,test,606,"from one entry to another.; It can happen that the size of C arrays stored in branches varies a lot; from event to event. It can happen also that a very small array becomes; suddently very big. This triggers a reallocation of the buffer ROOT; uses internally to hold the read content.; When snapshotting, RDataFrame, was setting the addresses of the output; tree only once at the 1st event processed (per slot). This of course could; lead to the persistification of corrupted values. This change allow to keep track of the changing addresses and properly; handle them via the TBranch::SetAddress method. A test is also added to the suite in order to avoid regressions in the; future. Nota bene: this **does also** fix ROOT-9860",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3153
https://github.com/root-project/root/pull/3154:38,Testability,test,testing,38,"Such data can be used with JSROOT for testing only client side without running of C++; Of course, client is not fully-functional, but many aspects can be tested much-much easier",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3154
https://github.com/root-project/root/pull/3154:154,Testability,test,tested,154,"Such data can be used with JSROOT for testing only client side without running of C++; Of course, client is not fully-functional, but many aspects can be tested much-much easier",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3154
https://github.com/root-project/root/pull/3158:21,Integrability,interface,interface,21,This makes the array interface pythonizations truly lazy so that the classes are not touched during `import ROOT`.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3158
https://github.com/root-project/root/pull/3160:51,Availability,failure,failures,51,"…ersions and improve test coverage. Fixes the test failures in the incremental builds since `dict.keys() == [...]` seems to behave differently on different Python versions. As well, I've changed `any` to `all` (my bad) to increase the test coverage. Edit: This test failure: http://cdash.cern.ch/testDetails.php?test=58796321&build=604175",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3160
https://github.com/root-project/root/pull/3160:266,Availability,failure,failure,266,"…ersions and improve test coverage. Fixes the test failures in the incremental builds since `dict.keys() == [...]` seems to behave differently on different Python versions. As well, I've changed `any` to `all` (my bad) to increase the test coverage. Edit: This test failure: http://cdash.cern.ch/testDetails.php?test=58796321&build=604175",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3160
https://github.com/root-project/root/pull/3160:21,Testability,test,test,21,"…ersions and improve test coverage. Fixes the test failures in the incremental builds since `dict.keys() == [...]` seems to behave differently on different Python versions. As well, I've changed `any` to `all` (my bad) to increase the test coverage. Edit: This test failure: http://cdash.cern.ch/testDetails.php?test=58796321&build=604175",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3160
https://github.com/root-project/root/pull/3160:46,Testability,test,test,46,"…ersions and improve test coverage. Fixes the test failures in the incremental builds since `dict.keys() == [...]` seems to behave differently on different Python versions. As well, I've changed `any` to `all` (my bad) to increase the test coverage. Edit: This test failure: http://cdash.cern.ch/testDetails.php?test=58796321&build=604175",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3160
https://github.com/root-project/root/pull/3160:235,Testability,test,test,235,"…ersions and improve test coverage. Fixes the test failures in the incremental builds since `dict.keys() == [...]` seems to behave differently on different Python versions. As well, I've changed `any` to `all` (my bad) to increase the test coverage. Edit: This test failure: http://cdash.cern.ch/testDetails.php?test=58796321&build=604175",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3160
https://github.com/root-project/root/pull/3160:261,Testability,test,test,261,"…ersions and improve test coverage. Fixes the test failures in the incremental builds since `dict.keys() == [...]` seems to behave differently on different Python versions. As well, I've changed `any` to `all` (my bad) to increase the test coverage. Edit: This test failure: http://cdash.cern.ch/testDetails.php?test=58796321&build=604175",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3160
https://github.com/root-project/root/pull/3160:296,Testability,test,testDetails,296,"…ersions and improve test coverage. Fixes the test failures in the incremental builds since `dict.keys() == [...]` seems to behave differently on different Python versions. As well, I've changed `any` to `all` (my bad) to increase the test coverage. Edit: This test failure: http://cdash.cern.ch/testDetails.php?test=58796321&build=604175",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3160
https://github.com/root-project/root/pull/3160:312,Testability,test,test,312,"…ersions and improve test coverage. Fixes the test failures in the incremental builds since `dict.keys() == [...]` seems to behave differently on different Python versions. As well, I've changed `any` to `all` (my bad) to increase the test coverage. Edit: This test failure: http://cdash.cern.ch/testDetails.php?test=58796321&build=604175",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3160
https://github.com/root-project/root/pull/3167:68,Modifiability,variab,variable,68,hinting to the potential absence of a branch holding the size of a; variable size C array.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3167
https://github.com/root-project/root/pull/3170:220,Availability,failure,failures,220,@etejedor This seems to fix the problem with attaching a property to the class definition. I do not understand why we get an `bad argument to internal function` if we skip the proxy function ... Edit: These are the test failures: http://cdash.cern.ch/viewTest.php?onlyfailed&buildid=604404,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3170
https://github.com/root-project/root/pull/3170:215,Testability,test,test,215,@etejedor This seems to fix the problem with attaching a property to the class definition. I do not understand why we get an `bad argument to internal function` if we skip the proxy function ... Edit: These are the test failures: http://cdash.cern.ch/viewTest.php?onlyfailed&buildid=604404,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3170
https://github.com/root-project/root/pull/3174:33,Deployability,release,release,33,Fixes version detection e.g. for release / cpack builds.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3174
https://github.com/root-project/root/pull/3174:14,Safety,detect,detection,14,Fixes version detection e.g. for release / cpack builds.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3174
https://github.com/root-project/root/pull/3179:16,Deployability,patch,patch,16,"The aim of this patch is to make runtime modules ""installable"". Previously, modulemap.overlay.yaml file was being generated by cmake; __only__ for build directory. So the path/to/your/build/directory was; hardcoded to modulemap.overlay.yaml and Cling was reading modulemap for; stl and libc from the build directory even if it was installed to different; location. This was a problem for CMSSW, so in this patch I'm generating two; overlay files, one for build directory and other one for installed; directory. CMake will generate modulemap.overlay.yaml for __build__; directory from modulemap.overlay.yaml.in.build at compilation time, and; it will generate and install modulemap.overlay.yaml for __install__; directory from modulemap.overlay.yaml.install.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3179
https://github.com/root-project/root/pull/3179:50,Deployability,install,installable,50,"The aim of this patch is to make runtime modules ""installable"". Previously, modulemap.overlay.yaml file was being generated by cmake; __only__ for build directory. So the path/to/your/build/directory was; hardcoded to modulemap.overlay.yaml and Cling was reading modulemap for; stl and libc from the build directory even if it was installed to different; location. This was a problem for CMSSW, so in this patch I'm generating two; overlay files, one for build directory and other one for installed; directory. CMake will generate modulemap.overlay.yaml for __build__; directory from modulemap.overlay.yaml.in.build at compilation time, and; it will generate and install modulemap.overlay.yaml for __install__; directory from modulemap.overlay.yaml.install.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3179
https://github.com/root-project/root/pull/3179:331,Deployability,install,installed,331,"The aim of this patch is to make runtime modules ""installable"". Previously, modulemap.overlay.yaml file was being generated by cmake; __only__ for build directory. So the path/to/your/build/directory was; hardcoded to modulemap.overlay.yaml and Cling was reading modulemap for; stl and libc from the build directory even if it was installed to different; location. This was a problem for CMSSW, so in this patch I'm generating two; overlay files, one for build directory and other one for installed; directory. CMake will generate modulemap.overlay.yaml for __build__; directory from modulemap.overlay.yaml.in.build at compilation time, and; it will generate and install modulemap.overlay.yaml for __install__; directory from modulemap.overlay.yaml.install.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3179
https://github.com/root-project/root/pull/3179:406,Deployability,patch,patch,406,"The aim of this patch is to make runtime modules ""installable"". Previously, modulemap.overlay.yaml file was being generated by cmake; __only__ for build directory. So the path/to/your/build/directory was; hardcoded to modulemap.overlay.yaml and Cling was reading modulemap for; stl and libc from the build directory even if it was installed to different; location. This was a problem for CMSSW, so in this patch I'm generating two; overlay files, one for build directory and other one for installed; directory. CMake will generate modulemap.overlay.yaml for __build__; directory from modulemap.overlay.yaml.in.build at compilation time, and; it will generate and install modulemap.overlay.yaml for __install__; directory from modulemap.overlay.yaml.install.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3179
https://github.com/root-project/root/pull/3179:489,Deployability,install,installed,489,"The aim of this patch is to make runtime modules ""installable"". Previously, modulemap.overlay.yaml file was being generated by cmake; __only__ for build directory. So the path/to/your/build/directory was; hardcoded to modulemap.overlay.yaml and Cling was reading modulemap for; stl and libc from the build directory even if it was installed to different; location. This was a problem for CMSSW, so in this patch I'm generating two; overlay files, one for build directory and other one for installed; directory. CMake will generate modulemap.overlay.yaml for __build__; directory from modulemap.overlay.yaml.in.build at compilation time, and; it will generate and install modulemap.overlay.yaml for __install__; directory from modulemap.overlay.yaml.install.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3179
https://github.com/root-project/root/pull/3179:663,Deployability,install,install,663,"The aim of this patch is to make runtime modules ""installable"". Previously, modulemap.overlay.yaml file was being generated by cmake; __only__ for build directory. So the path/to/your/build/directory was; hardcoded to modulemap.overlay.yaml and Cling was reading modulemap for; stl and libc from the build directory even if it was installed to different; location. This was a problem for CMSSW, so in this patch I'm generating two; overlay files, one for build directory and other one for installed; directory. CMake will generate modulemap.overlay.yaml for __build__; directory from modulemap.overlay.yaml.in.build at compilation time, and; it will generate and install modulemap.overlay.yaml for __install__; directory from modulemap.overlay.yaml.install.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3179
https://github.com/root-project/root/pull/3179:749,Deployability,install,install,749,"The aim of this patch is to make runtime modules ""installable"". Previously, modulemap.overlay.yaml file was being generated by cmake; __only__ for build directory. So the path/to/your/build/directory was; hardcoded to modulemap.overlay.yaml and Cling was reading modulemap for; stl and libc from the build directory even if it was installed to different; location. This was a problem for CMSSW, so in this patch I'm generating two; overlay files, one for build directory and other one for installed; directory. CMake will generate modulemap.overlay.yaml for __build__; directory from modulemap.overlay.yaml.in.build at compilation time, and; it will generate and install modulemap.overlay.yaml for __install__; directory from modulemap.overlay.yaml.install.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3179
https://github.com/root-project/root/pull/3180:514,Availability,redundant,redundant,514,"…hanged. This patch (also) aims to make runtime module installable. This part of code in Clang is comparing the location of ""modulemap which; is currently loaded and gives a definition of current module (say, stl); and ""the location of the modulemap where the current implicit module (like stl) was built"". This was problematic for CMSSW, as they should install modulemaps; and prebuilt pcms to other directory. stl and libc pcms should be; prebuilt, installed and used from installed directory, so this check is; redundant for that usecase.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3180
https://github.com/root-project/root/pull/3180:14,Deployability,patch,patch,14,"…hanged. This patch (also) aims to make runtime module installable. This part of code in Clang is comparing the location of ""modulemap which; is currently loaded and gives a definition of current module (say, stl); and ""the location of the modulemap where the current implicit module (like stl) was built"". This was problematic for CMSSW, as they should install modulemaps; and prebuilt pcms to other directory. stl and libc pcms should be; prebuilt, installed and used from installed directory, so this check is; redundant for that usecase.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3180
https://github.com/root-project/root/pull/3180:55,Deployability,install,installable,55,"…hanged. This patch (also) aims to make runtime module installable. This part of code in Clang is comparing the location of ""modulemap which; is currently loaded and gives a definition of current module (say, stl); and ""the location of the modulemap where the current implicit module (like stl) was built"". This was problematic for CMSSW, as they should install modulemaps; and prebuilt pcms to other directory. stl and libc pcms should be; prebuilt, installed and used from installed directory, so this check is; redundant for that usecase.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3180
https://github.com/root-project/root/pull/3180:354,Deployability,install,install,354,"…hanged. This patch (also) aims to make runtime module installable. This part of code in Clang is comparing the location of ""modulemap which; is currently loaded and gives a definition of current module (say, stl); and ""the location of the modulemap where the current implicit module (like stl) was built"". This was problematic for CMSSW, as they should install modulemaps; and prebuilt pcms to other directory. stl and libc pcms should be; prebuilt, installed and used from installed directory, so this check is; redundant for that usecase.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3180
https://github.com/root-project/root/pull/3180:451,Deployability,install,installed,451,"…hanged. This patch (also) aims to make runtime module installable. This part of code in Clang is comparing the location of ""modulemap which; is currently loaded and gives a definition of current module (say, stl); and ""the location of the modulemap where the current implicit module (like stl) was built"". This was problematic for CMSSW, as they should install modulemaps; and prebuilt pcms to other directory. stl and libc pcms should be; prebuilt, installed and used from installed directory, so this check is; redundant for that usecase.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3180
https://github.com/root-project/root/pull/3180:475,Deployability,install,installed,475,"…hanged. This patch (also) aims to make runtime module installable. This part of code in Clang is comparing the location of ""modulemap which; is currently loaded and gives a definition of current module (say, stl); and ""the location of the modulemap where the current implicit module (like stl) was built"". This was problematic for CMSSW, as they should install modulemaps; and prebuilt pcms to other directory. stl and libc pcms should be; prebuilt, installed and used from installed directory, so this check is; redundant for that usecase.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3180
https://github.com/root-project/root/pull/3180:155,Performance,load,loaded,155,"…hanged. This patch (also) aims to make runtime module installable. This part of code in Clang is comparing the location of ""modulemap which; is currently loaded and gives a definition of current module (say, stl); and ""the location of the modulemap where the current implicit module (like stl) was built"". This was problematic for CMSSW, as they should install modulemaps; and prebuilt pcms to other directory. stl and libc pcms should be; prebuilt, installed and used from installed directory, so this check is; redundant for that usecase.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3180
https://github.com/root-project/root/pull/3180:514,Safety,redund,redundant,514,"…hanged. This patch (also) aims to make runtime module installable. This part of code in Clang is comparing the location of ""modulemap which; is currently loaded and gives a definition of current module (say, stl); and ""the location of the modulemap where the current implicit module (like stl) was built"". This was problematic for CMSSW, as they should install modulemaps; and prebuilt pcms to other directory. stl and libc pcms should be; prebuilt, installed and used from installed directory, so this check is; redundant for that usecase.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3180
https://github.com/root-project/root/pull/3181:60,Deployability,install,installed,60,"Previously, only pcms which were generated by rootcling was installed.; For example, stl.pcm and _Builtin_intrinsics.pcm were not copied to; install directory and was implicitly build to; /tmp/org.llvm.clang.yuka../ at runtime. This behavior is not what we; want, we want all our root related pcms to be prebuilt and just be; installed and used from that location.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3181
https://github.com/root-project/root/pull/3181:141,Deployability,install,install,141,"Previously, only pcms which were generated by rootcling was installed.; For example, stl.pcm and _Builtin_intrinsics.pcm were not copied to; install directory and was implicitly build to; /tmp/org.llvm.clang.yuka../ at runtime. This behavior is not what we; want, we want all our root related pcms to be prebuilt and just be; installed and used from that location.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3181
https://github.com/root-project/root/pull/3181:326,Deployability,install,installed,326,"Previously, only pcms which were generated by rootcling was installed.; For example, stl.pcm and _Builtin_intrinsics.pcm were not copied to; install directory and was implicitly build to; /tmp/org.llvm.clang.yuka../ at runtime. This behavior is not what we; want, we want all our root related pcms to be prebuilt and just be; installed and used from that location.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3181
https://github.com/root-project/root/pull/3182:47,Deployability,patch,patches,47,"Same as #3163, but to be applied onto v6-16-00-patches branch.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3182
https://github.com/root-project/root/pull/3184:227,Safety,avoid,avoid,227,If gDirectory is a nullptr use gROOT. TObject::Clone uses; TDirectory[File]::CloneObject and the TDirectoryFile object; actually change the behavior (set gFile to nullptr) in a way; that probably require significant surgery to avoid using the; virtual function.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3184
https://github.com/root-project/root/pull/3185:177,Deployability,Update,Update,177,"* Document constructor of RooBukinPdf.; * RooArgList; * Improve doxygen for RooDataSet.; * Measurement, RooBernstein, RooCustomizer.; * Add VisualizeError to RooAbsPdf docs.; * Update index.md files to also show roofit tutorials.; * Fix typo in RooPolyVar docs.; * Add image and description for RooArgusBG, minor improvements for RooAbsPdf and AsymptoticCalculator.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3185
https://github.com/root-project/root/pull/3186:304,Deployability,patch,patch,304,"When building with CMSSW, root was being in an infinite loop when; parsing this forward declaration at TCling::RegisterModule:; `namespace reco{namespace btau{enum __attribute__((annotate(\""$clingAutoload$DataFormats/BTauReco/interface/TaggingVariable.h\""))) TaggingVariableName : unsigned int;}}`. This patch fixes the bug which nsPos was always the size of namespace; name (4, in this case)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3186
https://github.com/root-project/root/pull/3186:226,Integrability,interface,interface,226,"When building with CMSSW, root was being in an infinite loop when; parsing this forward declaration at TCling::RegisterModule:; `namespace reco{namespace btau{enum __attribute__((annotate(\""$clingAutoload$DataFormats/BTauReco/interface/TaggingVariable.h\""))) TaggingVariableName : unsigned int;}}`. This patch fixes the bug which nsPos was always the size of namespace; name (4, in this case)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3186
https://github.com/root-project/root/pull/3187:227,Safety,avoid,avoid,227,If gDirectory is a nullptr use gROOT. TObject::Clone uses; TDirectory[File]::CloneObject and the TDirectoryFile object; actually change the behavior (set gFile to nullptr) in a way; that probably require significant surgery to avoid using the; virtual function.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3187
https://github.com/root-project/root/pull/3189:10,Performance,perform,performance,10,This is a performance optimisation.; We do not need a rw lock in this case because a write lock is needed; both when a slot is taken out of the stack and when it's put back.; The header of the class has also been made slimmer thanks to the usage; of a fwd declaration.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3189
https://github.com/root-project/root/pull/3193:73,Deployability,release,release,73,Prevent ldap.h sneaking in from wrong location as is the case during LCG release builds if ROOT is tried to be built with ldap support. All details can be found at SPI-1120,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3193
https://github.com/root-project/root/pull/3194:223,Deployability,integrat,integration,223,"This is very first prototype for testing and further development. Idea to scan geometry and create render data on C++ side, ; only final WebGL display implemented in web browser. Also will be test-case for OpenUI TableTree integration. One need specialized OData-like requests to show only visible part of geometry hierarchy. tutorials/eve7/viewer.C shows basic usage.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3194
https://github.com/root-project/root/pull/3194:223,Integrability,integrat,integration,223,"This is very first prototype for testing and further development. Idea to scan geometry and create render data on C++ side, ; only final WebGL display implemented in web browser. Also will be test-case for OpenUI TableTree integration. One need specialized OData-like requests to show only visible part of geometry hierarchy. tutorials/eve7/viewer.C shows basic usage.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3194
https://github.com/root-project/root/pull/3194:33,Testability,test,testing,33,"This is very first prototype for testing and further development. Idea to scan geometry and create render data on C++ side, ; only final WebGL display implemented in web browser. Also will be test-case for OpenUI TableTree integration. One need specialized OData-like requests to show only visible part of geometry hierarchy. tutorials/eve7/viewer.C shows basic usage.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3194
https://github.com/root-project/root/pull/3194:192,Testability,test,test-case,192,"This is very first prototype for testing and further development. Idea to scan geometry and create render data on C++ side, ; only final WebGL display implemented in web browser. Also will be test-case for OpenUI TableTree integration. One need specialized OData-like requests to show only visible part of geometry hierarchy. tutorials/eve7/viewer.C shows basic usage.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3194
https://github.com/root-project/root/pull/3196:5,Performance,perform,performance,5,Slow performance was due to excessive fsync and writing of TTree objects resulting in byte written to disk far exceeding the file size ... (code was using AutoSave instead of AutoFlush). Added speeding up of test-bench.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3196
https://github.com/root-project/root/pull/3196:208,Testability,test,test-bench,208,Slow performance was due to excessive fsync and writing of TTree objects resulting in byte written to disk far exceeding the file size ... (code was using AutoSave instead of AutoFlush). Added speeding up of test-bench.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3196
https://github.com/root-project/root/pull/3199:78,Integrability,depend,dependency,78,"This was last methods where TVirtualPad and TVirtualPainter3D were used.; Now dependency from libGpad remains only via libTreePlayer.; Later these specialized classes will be moved to separate library to make libROOTEve only depend from libGeom, libCore, libMath libraries",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3199
https://github.com/root-project/root/pull/3199:225,Integrability,depend,depend,225,"This was last methods where TVirtualPad and TVirtualPainter3D were used.; Now dependency from libGpad remains only via libTreePlayer.; Later these specialized classes will be moved to separate library to make libROOTEve only depend from libGeom, libCore, libMath libraries",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3199
https://github.com/root-project/root/pull/3202:122,Availability,recover,recovered,122,"I think these files are fine to remove, but maybe even removing only the ROOT 5 ones would be already enough (they can be recovered from the older version tarballs in any case).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3202
https://github.com/root-project/root/pull/3202:122,Safety,recover,recovered,122,"I think these files are fine to remove, but maybe even removing only the ROOT 5 ones would be already enough (they can be recovered from the older version tarballs in any case).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3202
https://github.com/root-project/root/pull/3204:21,Testability,test,tests,21,"When running doctest tests with `python -m doctest testfile.py`, doctest changes the current working directory to the directory where `testfile.py` is. This is problematic for our JupyROOT doctest tests, located in `$ROOT_SRC/bindings/pyroot/JupyROOT`, because Python will prepend that directory to the `PYTHONPATH`. Since such directory contains other Python modules, those will have precedence over any other module from the system. This caused a problem e.g. with `$ROOT_SRC/bindings/pyroot/JupyROOT/html`, which was wrongly picked instead of the system's package called html. For example, this can be seen [here](https://epsft-jenkins.cern.ch/job/root-pullrequests-build/50688/testReport/projectroot.roottest.python/JupyROOT/roottest_python_JupyROOT_cppcompleter_doctest/). This commit proposes a reorganization of the Python modules in `$ROOT_SRC/bindings/pyroot/JupyROOT`, in particular those that contain doctest tests, so that the interference caused by doctest does not happen.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3204
https://github.com/root-project/root/pull/3204:51,Testability,test,testfile,51,"When running doctest tests with `python -m doctest testfile.py`, doctest changes the current working directory to the directory where `testfile.py` is. This is problematic for our JupyROOT doctest tests, located in `$ROOT_SRC/bindings/pyroot/JupyROOT`, because Python will prepend that directory to the `PYTHONPATH`. Since such directory contains other Python modules, those will have precedence over any other module from the system. This caused a problem e.g. with `$ROOT_SRC/bindings/pyroot/JupyROOT/html`, which was wrongly picked instead of the system's package called html. For example, this can be seen [here](https://epsft-jenkins.cern.ch/job/root-pullrequests-build/50688/testReport/projectroot.roottest.python/JupyROOT/roottest_python_JupyROOT_cppcompleter_doctest/). This commit proposes a reorganization of the Python modules in `$ROOT_SRC/bindings/pyroot/JupyROOT`, in particular those that contain doctest tests, so that the interference caused by doctest does not happen.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3204
https://github.com/root-project/root/pull/3204:135,Testability,test,testfile,135,"When running doctest tests with `python -m doctest testfile.py`, doctest changes the current working directory to the directory where `testfile.py` is. This is problematic for our JupyROOT doctest tests, located in `$ROOT_SRC/bindings/pyroot/JupyROOT`, because Python will prepend that directory to the `PYTHONPATH`. Since such directory contains other Python modules, those will have precedence over any other module from the system. This caused a problem e.g. with `$ROOT_SRC/bindings/pyroot/JupyROOT/html`, which was wrongly picked instead of the system's package called html. For example, this can be seen [here](https://epsft-jenkins.cern.ch/job/root-pullrequests-build/50688/testReport/projectroot.roottest.python/JupyROOT/roottest_python_JupyROOT_cppcompleter_doctest/). This commit proposes a reorganization of the Python modules in `$ROOT_SRC/bindings/pyroot/JupyROOT`, in particular those that contain doctest tests, so that the interference caused by doctest does not happen.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3204
https://github.com/root-project/root/pull/3204:197,Testability,test,tests,197,"When running doctest tests with `python -m doctest testfile.py`, doctest changes the current working directory to the directory where `testfile.py` is. This is problematic for our JupyROOT doctest tests, located in `$ROOT_SRC/bindings/pyroot/JupyROOT`, because Python will prepend that directory to the `PYTHONPATH`. Since such directory contains other Python modules, those will have precedence over any other module from the system. This caused a problem e.g. with `$ROOT_SRC/bindings/pyroot/JupyROOT/html`, which was wrongly picked instead of the system's package called html. For example, this can be seen [here](https://epsft-jenkins.cern.ch/job/root-pullrequests-build/50688/testReport/projectroot.roottest.python/JupyROOT/roottest_python_JupyROOT_cppcompleter_doctest/). This commit proposes a reorganization of the Python modules in `$ROOT_SRC/bindings/pyroot/JupyROOT`, in particular those that contain doctest tests, so that the interference caused by doctest does not happen.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3204
https://github.com/root-project/root/pull/3204:681,Testability,test,testReport,681,"When running doctest tests with `python -m doctest testfile.py`, doctest changes the current working directory to the directory where `testfile.py` is. This is problematic for our JupyROOT doctest tests, located in `$ROOT_SRC/bindings/pyroot/JupyROOT`, because Python will prepend that directory to the `PYTHONPATH`. Since such directory contains other Python modules, those will have precedence over any other module from the system. This caused a problem e.g. with `$ROOT_SRC/bindings/pyroot/JupyROOT/html`, which was wrongly picked instead of the system's package called html. For example, this can be seen [here](https://epsft-jenkins.cern.ch/job/root-pullrequests-build/50688/testReport/projectroot.roottest.python/JupyROOT/roottest_python_JupyROOT_cppcompleter_doctest/). This commit proposes a reorganization of the Python modules in `$ROOT_SRC/bindings/pyroot/JupyROOT`, in particular those that contain doctest tests, so that the interference caused by doctest does not happen.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3204
https://github.com/root-project/root/pull/3204:920,Testability,test,tests,920,"When running doctest tests with `python -m doctest testfile.py`, doctest changes the current working directory to the directory where `testfile.py` is. This is problematic for our JupyROOT doctest tests, located in `$ROOT_SRC/bindings/pyroot/JupyROOT`, because Python will prepend that directory to the `PYTHONPATH`. Since such directory contains other Python modules, those will have precedence over any other module from the system. This caused a problem e.g. with `$ROOT_SRC/bindings/pyroot/JupyROOT/html`, which was wrongly picked instead of the system's package called html. For example, this can be seen [here](https://epsft-jenkins.cern.ch/job/root-pullrequests-build/50688/testReport/projectroot.roottest.python/JupyROOT/roottest_python_JupyROOT_cppcompleter_doctest/). This commit proposes a reorganization of the Python modules in `$ROOT_SRC/bindings/pyroot/JupyROOT`, in particular those that contain doctest tests, so that the interference caused by doctest does not happen.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3204
https://github.com/root-project/root/pull/3208:274,Deployability,Patch,Patch,274,In TGlobalMappedFunction all global functions casted to the type: `void *(*)()`; But in reality all used functions have other signature: `void *&(*)()`; To silent compiler warnings intermediate casting to (void*) was used - this is **dangerous** and in generally **wrong**. Patch introduces functor inside TGlobalMappedFunction.; Within lambda each function called as it is and just return value casted to `void *`.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3208
https://github.com/root-project/root/pull/3211:64,Modifiability,variab,variables,64,if(ENV{}) does not work with CMake 3.12.; string cannot set ENV variables in CMake 3.12.; Also suppress existing ROOTSYS from CMAKE_PREFIX_PATH to not pick up externals from another build.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3211
https://github.com/root-project/root/pull/3214:18,Integrability,inject,inject,18,This allows us to inject -DGSL_LIBRARY etc for relwase builds.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3214
https://github.com/root-project/root/pull/3214:18,Security,inject,inject,18,This allows us to inject -DGSL_LIBRARY etc for relwase builds.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3214
https://github.com/root-project/root/pull/3215:301,Testability,test,tested,301,"``""_typename""`` was always first member in JSON object.; Therefore every next member add to object was separated with ``"",""`` - very simple.; Now, when typeinfo can be excluded, one must ensure that before first data member no any extra separators are inserted. In the #3203 only simple usecases were tested - now skipping should work everywhere.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3215
https://github.com/root-project/root/pull/3215:133,Usability,simpl,simple,133,"``""_typename""`` was always first member in JSON object.; Therefore every next member add to object was separated with ``"",""`` - very simple.; Now, when typeinfo can be excluded, one must ensure that before first data member no any extra separators are inserted. In the #3203 only simple usecases were tested - now skipping should work everywhere.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3215
https://github.com/root-project/root/pull/3215:280,Usability,simpl,simple,280,"``""_typename""`` was always first member in JSON object.; Therefore every next member add to object was separated with ``"",""`` - very simple.; Now, when typeinfo can be excluded, one must ensure that before first data member no any extra separators are inserted. In the #3203 only simple usecases were tested - now skipping should work everywhere.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3215
https://github.com/root-project/root/pull/3216:157,Availability,down,down,157,"With the attached example, the direct case takes 23.6s while original TTreeReader version takes 34.2s. With the included changes, the TTreeReader version is down to 28.7s.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3216
https://github.com/root-project/root/pull/3221:1213,Integrability,interface,interface,1213,"Implementation of the C++ side of RTensor. This PR replaces #2593. In addition, a second commit adds the feature `TMVA::Experimental::AsTensor`, which reads out an `RDataFrame` node as an `RTensor`. See the tutorials for examples or the short snipplets below. **RTensor basics:**; ```cpp; using namespace TMVA::Experimental;. // Create an RTensor from existing data; float data[] = {1, 2, 3, 4, 5, 6};; RTensor<float> x(data, {2, 3});; std::cout << x << std::endl;; // { { 1, 2, 3 }, { 4, 5, 6 } }. // Reshape the tensor without touching the data; x.Reshape({1, 6});; std::cout << x << std::endl;; // { { 1, 2, 3, 4, 5, 6 } }. // Remove dimensions of 1; x.Squeeze();; std::cout << x << std::endl;; // { 1, 2, 3, 4, 5, 6 }. // Add dimensions; x.ExpandDims(0);; std::cout << x << std::endl;; // { { 1, 2, 3, 4, 5, 6 } }. // Transpose the tensor; x.Transpose();; std::cout << x << std::endl;; // { {1}, {2}, {3}, {4}, {5}, {6} }. // Extract slices as new RTensor objects; x.Reshape({2, 3});; std::cout << x << std::endl;; // { { 1, 3, 5 }, { 2, 4, 6 } }. auto y = x.Slice({-1, 0});; std::cout << y << std::endl;; // { 1, 2 }. auto z = x.Slice({0, -1});; std::cout << z << std::endl;; // { 1, 3, 5 }. // STL iterator interface and range-based loops; for(auto &v: x) v++;; std::cout << x << std::endl;; // { { 2, 4, 6 }, { 3, 5, 7 } }; ```. **TMVA::Experimental::AsTensor usage:**. ```cpp; ROOT::RDataFrame df(5);; auto df2 = df.Define(""x"", ""1.f*rdfentry_"").Define(""y"", ""-1.f*rdfentry_"");; auto x = TMVA::Experimental::AsTensor<float>(df2);; std::cout << x << std::endl;; // { { 0, -0 }, { 1, -1 }, { 2, -2 }, { 3, -3 }, { 4, -4 } }; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3221
https://github.com/root-project/root/pull/3222:96,Deployability,update,updated,96,"When RooWorkspaces that contain a RooStats::ModelConfig are cloned, the ModelConfig did not get updated. With current RooFit, this is impossible because of a circular dependency. The ModelConfig would therefore still point to the original workspace. By introducing an abstract interface, the circular dependency is broken such that this updating works now. **Question for reviewers**; Currently, the abstract interface does not have Type/Streamer info such that root complains:; `Warning in <TStreamerInfo::Build>: RooStats::ModelConfig: base class RooWorkspaceHandle has no streamer or dictionary it will not be saved`; How can this be silenced? Since the interface is abstract, no I/O is needed, maybe not even type info.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3222
https://github.com/root-project/root/pull/3222:167,Integrability,depend,dependency,167,"When RooWorkspaces that contain a RooStats::ModelConfig are cloned, the ModelConfig did not get updated. With current RooFit, this is impossible because of a circular dependency. The ModelConfig would therefore still point to the original workspace. By introducing an abstract interface, the circular dependency is broken such that this updating works now. **Question for reviewers**; Currently, the abstract interface does not have Type/Streamer info such that root complains:; `Warning in <TStreamerInfo::Build>: RooStats::ModelConfig: base class RooWorkspaceHandle has no streamer or dictionary it will not be saved`; How can this be silenced? Since the interface is abstract, no I/O is needed, maybe not even type info.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3222
https://github.com/root-project/root/pull/3222:277,Integrability,interface,interface,277,"When RooWorkspaces that contain a RooStats::ModelConfig are cloned, the ModelConfig did not get updated. With current RooFit, this is impossible because of a circular dependency. The ModelConfig would therefore still point to the original workspace. By introducing an abstract interface, the circular dependency is broken such that this updating works now. **Question for reviewers**; Currently, the abstract interface does not have Type/Streamer info such that root complains:; `Warning in <TStreamerInfo::Build>: RooStats::ModelConfig: base class RooWorkspaceHandle has no streamer or dictionary it will not be saved`; How can this be silenced? Since the interface is abstract, no I/O is needed, maybe not even type info.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3222
https://github.com/root-project/root/pull/3222:301,Integrability,depend,dependency,301,"When RooWorkspaces that contain a RooStats::ModelConfig are cloned, the ModelConfig did not get updated. With current RooFit, this is impossible because of a circular dependency. The ModelConfig would therefore still point to the original workspace. By introducing an abstract interface, the circular dependency is broken such that this updating works now. **Question for reviewers**; Currently, the abstract interface does not have Type/Streamer info such that root complains:; `Warning in <TStreamerInfo::Build>: RooStats::ModelConfig: base class RooWorkspaceHandle has no streamer or dictionary it will not be saved`; How can this be silenced? Since the interface is abstract, no I/O is needed, maybe not even type info.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3222
https://github.com/root-project/root/pull/3222:409,Integrability,interface,interface,409,"When RooWorkspaces that contain a RooStats::ModelConfig are cloned, the ModelConfig did not get updated. With current RooFit, this is impossible because of a circular dependency. The ModelConfig would therefore still point to the original workspace. By introducing an abstract interface, the circular dependency is broken such that this updating works now. **Question for reviewers**; Currently, the abstract interface does not have Type/Streamer info such that root complains:; `Warning in <TStreamerInfo::Build>: RooStats::ModelConfig: base class RooWorkspaceHandle has no streamer or dictionary it will not be saved`; How can this be silenced? Since the interface is abstract, no I/O is needed, maybe not even type info.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3222
https://github.com/root-project/root/pull/3222:657,Integrability,interface,interface,657,"When RooWorkspaces that contain a RooStats::ModelConfig are cloned, the ModelConfig did not get updated. With current RooFit, this is impossible because of a circular dependency. The ModelConfig would therefore still point to the original workspace. By introducing an abstract interface, the circular dependency is broken such that this updating works now. **Question for reviewers**; Currently, the abstract interface does not have Type/Streamer info such that root complains:; `Warning in <TStreamerInfo::Build>: RooStats::ModelConfig: base class RooWorkspaceHandle has no streamer or dictionary it will not be saved`; How can this be silenced? Since the interface is abstract, no I/O is needed, maybe not even type info.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3222
https://github.com/root-project/root/pull/3223:227,Safety,avoid,avoid,227,If gDirectory is a nullptr use gROOT. TObject::Clone uses; TDirectory[File]::CloneObject and the TDirectoryFile object; actually change the behavior (set gFile to nullptr) in a way; that probably require significant surgery to avoid using the; virtual function.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3223
https://github.com/root-project/root/pull/3225:58,Performance,load,loaded,58,"These two libraries do not need to be linked, they can be loaded at runtime when necessary. `ROOTVecOps` in particular forces `libPyROOT.so` to link against Vdt when that is enabled, which we would like to avoid. *Note:* `RVec` pythonization has been recently made lazy in 3017be2d80c160d8726c887fad2ede81c295c27a.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3225
https://github.com/root-project/root/pull/3225:206,Safety,avoid,avoid,206,"These two libraries do not need to be linked, they can be loaded at runtime when necessary. `ROOTVecOps` in particular forces `libPyROOT.so` to link against Vdt when that is enabled, which we would like to avoid. *Note:* `RVec` pythonization has been recently made lazy in 3017be2d80c160d8726c887fad2ede81c295c27a.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3225
https://github.com/root-project/root/pull/3227:13,Safety,detect,detect,13,"CMake should detect this, but since the output `G__Imt.cxx` is used both by `G__Imt` (custom target created by `ROOT_GENERATE_DICTIONARY()`) and `Imt` (via `target_sources()`), it leads to problems in parallel builds.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3227
https://github.com/root-project/root/pull/3228:18,Deployability,install,install,18,"We do not need to install rdict here, because it is already installed.; Also this FIXME doesn't work as the list of pcms change; depending on which -D option that you give to cmake.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3228
https://github.com/root-project/root/pull/3228:60,Deployability,install,installed,60,"We do not need to install rdict here, because it is already installed.; Also this FIXME doesn't work as the list of pcms change; depending on which -D option that you give to cmake.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3228
https://github.com/root-project/root/pull/3228:129,Integrability,depend,depending,129,"We do not need to install rdict here, because it is already installed.; Also this FIXME doesn't work as the list of pcms change; depending on which -D option that you give to cmake.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3228
https://github.com/root-project/root/pull/3233:20,Performance,optimiz,optimize,20,With `#pragma cling optimize (3)`:; ```; $ root.exe -l -b -q enrico_clingopt.C; Processing enrico_clingopt.C...; 1.13e-07; (int) 0; ```. And `#pragma cling optimize (0)`:; ```; $ root.exe -l -b -q enrico_clingopt.C; Processing enrico_clingopt.C...; 2.15174; (int) 0; ```,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3233
https://github.com/root-project/root/pull/3233:156,Performance,optimiz,optimize,156,With `#pragma cling optimize (3)`:; ```; $ root.exe -l -b -q enrico_clingopt.C; Processing enrico_clingopt.C...; 1.13e-07; (int) 0; ```. And `#pragma cling optimize (0)`:; ```; $ root.exe -l -b -q enrico_clingopt.C; Processing enrico_clingopt.C...; 2.15174; (int) 0; ```,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3233
https://github.com/root-project/root/pull/3234:56,Energy Efficiency,allocate,allocated,56,"At O0, all variables of all local scopes get separately allocated on the stack.; This sums up to 6k; streaming e.g. a RooWorkspace has 100s of recursions of this; function. Force O3, where the stack size shrinks to just above 200 bytes.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3234
https://github.com/root-project/root/pull/3234:11,Modifiability,variab,variables,11,"At O0, all variables of all local scopes get separately allocated on the stack.; This sums up to 6k; streaming e.g. a RooWorkspace has 100s of recursions of this; function. Force O3, where the stack size shrinks to just above 200 bytes.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3234
https://github.com/root-project/root/pull/3235:206,Deployability,toggle,toggle,206,Next iteration of geometry viewer. Following new functions are introduced:; - search of geometry nodes and results display; - sync highlighting of selected volumes in hierarchy browser and in GL drawing; - toggle visibility flags and proper redraw; - fix problems with clipping. Up-to-date demo: https://linev.github.io/geomCMS/,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3235
https://github.com/root-project/root/pull/3237:981,Energy Efficiency,green,green,981,"This PR makes sure that member function templates are added to the dictionary of class proxies, so that they are found when the user is trying to access them. For instance:. ```python; import ROOT. ROOT.gInterpreter.Declare(""""""; struct TestClass {; template<class T> void templatedMember(const T& value) { }; };; """"""). t = ROOT.TestClass(); t.templatedMember('int')(1); ```; The example also works if there are non-templated overloads and the user tries to instantiate the templated one, thanks to https://github.com/root-project/root/pull/3226. The re-injection of the pythonization of `GetObject` in `TDirectoryFile` is now necessary because, as a result of these changes, `GetObject` will be added to the dictionary of `TDirectoryFile` as a `TemplateProxy`. If we want the pythonization to prevail, we need to inject it (it will replace the `TemplateProxy`, just like in `TDirectory`). `TFile` will inherit that pythonization too, so we keep the current behaviour and all tests green. An extension of the PyROOT tests for templates is coming in another PR.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3237
https://github.com/root-project/root/pull/3237:553,Integrability,inject,injection,553,"This PR makes sure that member function templates are added to the dictionary of class proxies, so that they are found when the user is trying to access them. For instance:. ```python; import ROOT. ROOT.gInterpreter.Declare(""""""; struct TestClass {; template<class T> void templatedMember(const T& value) { }; };; """"""). t = ROOT.TestClass(); t.templatedMember('int')(1); ```; The example also works if there are non-templated overloads and the user tries to instantiate the templated one, thanks to https://github.com/root-project/root/pull/3226. The re-injection of the pythonization of `GetObject` in `TDirectoryFile` is now necessary because, as a result of these changes, `GetObject` will be added to the dictionary of `TDirectoryFile` as a `TemplateProxy`. If we want the pythonization to prevail, we need to inject it (it will replace the `TemplateProxy`, just like in `TDirectory`). `TFile` will inherit that pythonization too, so we keep the current behaviour and all tests green. An extension of the PyROOT tests for templates is coming in another PR.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3237
https://github.com/root-project/root/pull/3237:813,Integrability,inject,inject,813,"This PR makes sure that member function templates are added to the dictionary of class proxies, so that they are found when the user is trying to access them. For instance:. ```python; import ROOT. ROOT.gInterpreter.Declare(""""""; struct TestClass {; template<class T> void templatedMember(const T& value) { }; };; """"""). t = ROOT.TestClass(); t.templatedMember('int')(1); ```; The example also works if there are non-templated overloads and the user tries to instantiate the templated one, thanks to https://github.com/root-project/root/pull/3226. The re-injection of the pythonization of `GetObject` in `TDirectoryFile` is now necessary because, as a result of these changes, `GetObject` will be added to the dictionary of `TDirectoryFile` as a `TemplateProxy`. If we want the pythonization to prevail, we need to inject it (it will replace the `TemplateProxy`, just like in `TDirectory`). `TFile` will inherit that pythonization too, so we keep the current behaviour and all tests green. An extension of the PyROOT tests for templates is coming in another PR.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3237
https://github.com/root-project/root/pull/3237:902,Modifiability,inherit,inherit,902,"This PR makes sure that member function templates are added to the dictionary of class proxies, so that they are found when the user is trying to access them. For instance:. ```python; import ROOT. ROOT.gInterpreter.Declare(""""""; struct TestClass {; template<class T> void templatedMember(const T& value) { }; };; """"""). t = ROOT.TestClass(); t.templatedMember('int')(1); ```; The example also works if there are non-templated overloads and the user tries to instantiate the templated one, thanks to https://github.com/root-project/root/pull/3226. The re-injection of the pythonization of `GetObject` in `TDirectoryFile` is now necessary because, as a result of these changes, `GetObject` will be added to the dictionary of `TDirectoryFile` as a `TemplateProxy`. If we want the pythonization to prevail, we need to inject it (it will replace the `TemplateProxy`, just like in `TDirectory`). `TFile` will inherit that pythonization too, so we keep the current behaviour and all tests green. An extension of the PyROOT tests for templates is coming in another PR.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3237
https://github.com/root-project/root/pull/3237:146,Security,access,access,146,"This PR makes sure that member function templates are added to the dictionary of class proxies, so that they are found when the user is trying to access them. For instance:. ```python; import ROOT. ROOT.gInterpreter.Declare(""""""; struct TestClass {; template<class T> void templatedMember(const T& value) { }; };; """"""). t = ROOT.TestClass(); t.templatedMember('int')(1); ```; The example also works if there are non-templated overloads and the user tries to instantiate the templated one, thanks to https://github.com/root-project/root/pull/3226. The re-injection of the pythonization of `GetObject` in `TDirectoryFile` is now necessary because, as a result of these changes, `GetObject` will be added to the dictionary of `TDirectoryFile` as a `TemplateProxy`. If we want the pythonization to prevail, we need to inject it (it will replace the `TemplateProxy`, just like in `TDirectory`). `TFile` will inherit that pythonization too, so we keep the current behaviour and all tests green. An extension of the PyROOT tests for templates is coming in another PR.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3237
https://github.com/root-project/root/pull/3237:553,Security,inject,injection,553,"This PR makes sure that member function templates are added to the dictionary of class proxies, so that they are found when the user is trying to access them. For instance:. ```python; import ROOT. ROOT.gInterpreter.Declare(""""""; struct TestClass {; template<class T> void templatedMember(const T& value) { }; };; """"""). t = ROOT.TestClass(); t.templatedMember('int')(1); ```; The example also works if there are non-templated overloads and the user tries to instantiate the templated one, thanks to https://github.com/root-project/root/pull/3226. The re-injection of the pythonization of `GetObject` in `TDirectoryFile` is now necessary because, as a result of these changes, `GetObject` will be added to the dictionary of `TDirectoryFile` as a `TemplateProxy`. If we want the pythonization to prevail, we need to inject it (it will replace the `TemplateProxy`, just like in `TDirectory`). `TFile` will inherit that pythonization too, so we keep the current behaviour and all tests green. An extension of the PyROOT tests for templates is coming in another PR.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3237
https://github.com/root-project/root/pull/3237:813,Security,inject,inject,813,"This PR makes sure that member function templates are added to the dictionary of class proxies, so that they are found when the user is trying to access them. For instance:. ```python; import ROOT. ROOT.gInterpreter.Declare(""""""; struct TestClass {; template<class T> void templatedMember(const T& value) { }; };; """"""). t = ROOT.TestClass(); t.templatedMember('int')(1); ```; The example also works if there are non-templated overloads and the user tries to instantiate the templated one, thanks to https://github.com/root-project/root/pull/3226. The re-injection of the pythonization of `GetObject` in `TDirectoryFile` is now necessary because, as a result of these changes, `GetObject` will be added to the dictionary of `TDirectoryFile` as a `TemplateProxy`. If we want the pythonization to prevail, we need to inject it (it will replace the `TemplateProxy`, just like in `TDirectory`). `TFile` will inherit that pythonization too, so we keep the current behaviour and all tests green. An extension of the PyROOT tests for templates is coming in another PR.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3237
https://github.com/root-project/root/pull/3237:236,Testability,Test,TestClass,236,"This PR makes sure that member function templates are added to the dictionary of class proxies, so that they are found when the user is trying to access them. For instance:. ```python; import ROOT. ROOT.gInterpreter.Declare(""""""; struct TestClass {; template<class T> void templatedMember(const T& value) { }; };; """"""). t = ROOT.TestClass(); t.templatedMember('int')(1); ```; The example also works if there are non-templated overloads and the user tries to instantiate the templated one, thanks to https://github.com/root-project/root/pull/3226. The re-injection of the pythonization of `GetObject` in `TDirectoryFile` is now necessary because, as a result of these changes, `GetObject` will be added to the dictionary of `TDirectoryFile` as a `TemplateProxy`. If we want the pythonization to prevail, we need to inject it (it will replace the `TemplateProxy`, just like in `TDirectory`). `TFile` will inherit that pythonization too, so we keep the current behaviour and all tests green. An extension of the PyROOT tests for templates is coming in another PR.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3237
https://github.com/root-project/root/pull/3237:328,Testability,Test,TestClass,328,"This PR makes sure that member function templates are added to the dictionary of class proxies, so that they are found when the user is trying to access them. For instance:. ```python; import ROOT. ROOT.gInterpreter.Declare(""""""; struct TestClass {; template<class T> void templatedMember(const T& value) { }; };; """"""). t = ROOT.TestClass(); t.templatedMember('int')(1); ```; The example also works if there are non-templated overloads and the user tries to instantiate the templated one, thanks to https://github.com/root-project/root/pull/3226. The re-injection of the pythonization of `GetObject` in `TDirectoryFile` is now necessary because, as a result of these changes, `GetObject` will be added to the dictionary of `TDirectoryFile` as a `TemplateProxy`. If we want the pythonization to prevail, we need to inject it (it will replace the `TemplateProxy`, just like in `TDirectory`). `TFile` will inherit that pythonization too, so we keep the current behaviour and all tests green. An extension of the PyROOT tests for templates is coming in another PR.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3237
https://github.com/root-project/root/pull/3237:975,Testability,test,tests,975,"This PR makes sure that member function templates are added to the dictionary of class proxies, so that they are found when the user is trying to access them. For instance:. ```python; import ROOT. ROOT.gInterpreter.Declare(""""""; struct TestClass {; template<class T> void templatedMember(const T& value) { }; };; """"""). t = ROOT.TestClass(); t.templatedMember('int')(1); ```; The example also works if there are non-templated overloads and the user tries to instantiate the templated one, thanks to https://github.com/root-project/root/pull/3226. The re-injection of the pythonization of `GetObject` in `TDirectoryFile` is now necessary because, as a result of these changes, `GetObject` will be added to the dictionary of `TDirectoryFile` as a `TemplateProxy`. If we want the pythonization to prevail, we need to inject it (it will replace the `TemplateProxy`, just like in `TDirectory`). `TFile` will inherit that pythonization too, so we keep the current behaviour and all tests green. An extension of the PyROOT tests for templates is coming in another PR.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3237
https://github.com/root-project/root/pull/3237:1015,Testability,test,tests,1015,"This PR makes sure that member function templates are added to the dictionary of class proxies, so that they are found when the user is trying to access them. For instance:. ```python; import ROOT. ROOT.gInterpreter.Declare(""""""; struct TestClass {; template<class T> void templatedMember(const T& value) { }; };; """"""). t = ROOT.TestClass(); t.templatedMember('int')(1); ```; The example also works if there are non-templated overloads and the user tries to instantiate the templated one, thanks to https://github.com/root-project/root/pull/3226. The re-injection of the pythonization of `GetObject` in `TDirectoryFile` is now necessary because, as a result of these changes, `GetObject` will be added to the dictionary of `TDirectoryFile` as a `TemplateProxy`. If we want the pythonization to prevail, we need to inject it (it will replace the `TemplateProxy`, just like in `TDirectory`). `TFile` will inherit that pythonization too, so we keep the current behaviour and all tests green. An extension of the PyROOT tests for templates is coming in another PR.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3237
https://github.com/root-project/root/pull/3240:141,Availability,error,error,141,"...because when GSL is not found, HistFactory is not built. Without this change, when GSL is not present ROOT builds fail with the following error:. ```; In file included from /home/eguiraud/ROOT/root/test/stressHistFactory_tests.cxx:25:0,; from /home/eguiraud/ROOT/root/test/stressHistFactory.cxx:26:; /home/eguiraud/ROOT/root/test/stressHistFactory_models.cxx:8:46: fatal error: RooStats/HistFactory/Measurement.h: No such file or directory; #include ""RooStats/HistFactory/Measurement.h""; ^; compilation terminated.; test/CMakeFiles/stressHistFactory.dir/build.make:62: recipe for target 'test/CMakeFiles/stressHistFactory.dir/stressHistFactory.cxx.o' failed; ```. @hageboeck this fixes the issue I was complaining about today :smile: . @amadio maybe you can think of a nicer fix, this PR is most of all a bug report.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3240
https://github.com/root-project/root/pull/3240:374,Availability,error,error,374,"...because when GSL is not found, HistFactory is not built. Without this change, when GSL is not present ROOT builds fail with the following error:. ```; In file included from /home/eguiraud/ROOT/root/test/stressHistFactory_tests.cxx:25:0,; from /home/eguiraud/ROOT/root/test/stressHistFactory.cxx:26:; /home/eguiraud/ROOT/root/test/stressHistFactory_models.cxx:8:46: fatal error: RooStats/HistFactory/Measurement.h: No such file or directory; #include ""RooStats/HistFactory/Measurement.h""; ^; compilation terminated.; test/CMakeFiles/stressHistFactory.dir/build.make:62: recipe for target 'test/CMakeFiles/stressHistFactory.dir/stressHistFactory.cxx.o' failed; ```. @hageboeck this fixes the issue I was complaining about today :smile: . @amadio maybe you can think of a nicer fix, this PR is most of all a bug report.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3240
https://github.com/root-project/root/pull/3240:201,Testability,test,test,201,"...because when GSL is not found, HistFactory is not built. Without this change, when GSL is not present ROOT builds fail with the following error:. ```; In file included from /home/eguiraud/ROOT/root/test/stressHistFactory_tests.cxx:25:0,; from /home/eguiraud/ROOT/root/test/stressHistFactory.cxx:26:; /home/eguiraud/ROOT/root/test/stressHistFactory_models.cxx:8:46: fatal error: RooStats/HistFactory/Measurement.h: No such file or directory; #include ""RooStats/HistFactory/Measurement.h""; ^; compilation terminated.; test/CMakeFiles/stressHistFactory.dir/build.make:62: recipe for target 'test/CMakeFiles/stressHistFactory.dir/stressHistFactory.cxx.o' failed; ```. @hageboeck this fixes the issue I was complaining about today :smile: . @amadio maybe you can think of a nicer fix, this PR is most of all a bug report.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3240
https://github.com/root-project/root/pull/3240:271,Testability,test,test,271,"...because when GSL is not found, HistFactory is not built. Without this change, when GSL is not present ROOT builds fail with the following error:. ```; In file included from /home/eguiraud/ROOT/root/test/stressHistFactory_tests.cxx:25:0,; from /home/eguiraud/ROOT/root/test/stressHistFactory.cxx:26:; /home/eguiraud/ROOT/root/test/stressHistFactory_models.cxx:8:46: fatal error: RooStats/HistFactory/Measurement.h: No such file or directory; #include ""RooStats/HistFactory/Measurement.h""; ^; compilation terminated.; test/CMakeFiles/stressHistFactory.dir/build.make:62: recipe for target 'test/CMakeFiles/stressHistFactory.dir/stressHistFactory.cxx.o' failed; ```. @hageboeck this fixes the issue I was complaining about today :smile: . @amadio maybe you can think of a nicer fix, this PR is most of all a bug report.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3240
https://github.com/root-project/root/pull/3240:328,Testability,test,test,328,"...because when GSL is not found, HistFactory is not built. Without this change, when GSL is not present ROOT builds fail with the following error:. ```; In file included from /home/eguiraud/ROOT/root/test/stressHistFactory_tests.cxx:25:0,; from /home/eguiraud/ROOT/root/test/stressHistFactory.cxx:26:; /home/eguiraud/ROOT/root/test/stressHistFactory_models.cxx:8:46: fatal error: RooStats/HistFactory/Measurement.h: No such file or directory; #include ""RooStats/HistFactory/Measurement.h""; ^; compilation terminated.; test/CMakeFiles/stressHistFactory.dir/build.make:62: recipe for target 'test/CMakeFiles/stressHistFactory.dir/stressHistFactory.cxx.o' failed; ```. @hageboeck this fixes the issue I was complaining about today :smile: . @amadio maybe you can think of a nicer fix, this PR is most of all a bug report.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3240
https://github.com/root-project/root/pull/3240:519,Testability,test,test,519,"...because when GSL is not found, HistFactory is not built. Without this change, when GSL is not present ROOT builds fail with the following error:. ```; In file included from /home/eguiraud/ROOT/root/test/stressHistFactory_tests.cxx:25:0,; from /home/eguiraud/ROOT/root/test/stressHistFactory.cxx:26:; /home/eguiraud/ROOT/root/test/stressHistFactory_models.cxx:8:46: fatal error: RooStats/HistFactory/Measurement.h: No such file or directory; #include ""RooStats/HistFactory/Measurement.h""; ^; compilation terminated.; test/CMakeFiles/stressHistFactory.dir/build.make:62: recipe for target 'test/CMakeFiles/stressHistFactory.dir/stressHistFactory.cxx.o' failed; ```. @hageboeck this fixes the issue I was complaining about today :smile: . @amadio maybe you can think of a nicer fix, this PR is most of all a bug report.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3240
https://github.com/root-project/root/pull/3240:591,Testability,test,test,591,"...because when GSL is not found, HistFactory is not built. Without this change, when GSL is not present ROOT builds fail with the following error:. ```; In file included from /home/eguiraud/ROOT/root/test/stressHistFactory_tests.cxx:25:0,; from /home/eguiraud/ROOT/root/test/stressHistFactory.cxx:26:; /home/eguiraud/ROOT/root/test/stressHistFactory_models.cxx:8:46: fatal error: RooStats/HistFactory/Measurement.h: No such file or directory; #include ""RooStats/HistFactory/Measurement.h""; ^; compilation terminated.; test/CMakeFiles/stressHistFactory.dir/build.make:62: recipe for target 'test/CMakeFiles/stressHistFactory.dir/stressHistFactory.cxx.o' failed; ```. @hageboeck this fixes the issue I was complaining about today :smile: . @amadio maybe you can think of a nicer fix, this PR is most of all a bug report.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3240
https://github.com/root-project/root/pull/3242:15,Availability,error,errors,15,This fixes the errors in #3222. Patch by Oksana and me!,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3242
https://github.com/root-project/root/pull/3242:32,Deployability,Patch,Patch,32,This fixes the errors in #3222. Patch by Oksana and me!,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3242
https://github.com/root-project/root/pull/3245:132,Testability,test,tests,132,"As far as I can tell support for TEntryLists in TTreeProcessorMT is broken, and I'm not sure how to fix it.; I have disabled the MT tests for now.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3245
https://github.com/root-project/root/pull/3246:7,Availability,error,error,7,1. Fix error with normals production for TGeo shapes; 2. Catch exception in GluTess code; 3. Support TGeoNode with finders; 4. Provide geodemo.C macro with all supported shapes,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3246
https://github.com/root-project/root/pull/3248:12,Deployability,patch,patch,12,"Before this patch: the destructor of a derived node type destroyed; its shared_ptr to the previous node. The destructor of the base node; type, called _afterwards_, called fLoopManager->Deregister(this).; In the special case in which the previous node was precisely; RLoopManager and no other RInterfaces or nodes held a shared_ptr to; it, the RLoopManager was being destructed (in the dtor of the derived class); just before that same node called Deregister on it (in the dtor of the; base class). After this patch: the derived node types are responsible for calling; Deregister, before destroying the shared_ptr to previous node. This fixes the use after delete reported in ROOT-9898.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3248
https://github.com/root-project/root/pull/3248:510,Deployability,patch,patch,510,"Before this patch: the destructor of a derived node type destroyed; its shared_ptr to the previous node. The destructor of the base node; type, called _afterwards_, called fLoopManager->Deregister(this).; In the special case in which the previous node was precisely; RLoopManager and no other RInterfaces or nodes held a shared_ptr to; it, the RLoopManager was being destructed (in the dtor of the derived class); just before that same node called Deregister on it (in the dtor of the; base class). After this patch: the derived node types are responsible for calling; Deregister, before destroying the shared_ptr to previous node. This fixes the use after delete reported in ROOT-9898.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3248
https://github.com/root-project/root/pull/3249:53,Performance,OPTimiz,OPTimizer,53,"Dear ROOT team,. This is the code for Interior Point OPTimizer (Ipopt) . You can find more documentation on http://oproject.org/pages/Ipopt.html. Thanks; Omar.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3249
https://github.com/root-project/root/pull/3253:232,Deployability,patch,patch,232,"When writing trained methods to the output file, there was a typo in the target directory. This lead to the results of a method of type ""BDT"" and name ""MyBDT"" being placed (incorrectly) in a folder named; ""Method_MyBDT/MyBDT"". This patch places the data correctly in ""Method_BDT/BDT"". This is important since e.g. the GUI relies on all BDT's being placed in the ""MethodBDT"" folder. This will affect all methods, not only BDT's. This can be seen e.g. in the output of the `TMVAClassification.C` macro with several BDT's enabled: The GUI cannot generate plots for all BDT's. That the previous implementation was a typo is corroborated by this line:; ```; Log() << kDEBUG << Form(""Dataset[%s] : "", datasetName) << "" Base Directory for ""; << GetMethodTypeName() << "" not set yet --> check if already there.."" << Endl;; ```; , where it is implied that a directory of name `GetMethodTypeName()` should be created. However, in the old implementation a directory with name `GetMethodName()` was created instead. The issue was reported [here](https://root-forum.cern.ch/t/tmvagui-not-working-for-multiple-methods-of-bdt-in-file/32267) initially.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3253
https://github.com/root-project/root/pull/3253:653,Testability,Log,Log,653,"When writing trained methods to the output file, there was a typo in the target directory. This lead to the results of a method of type ""BDT"" and name ""MyBDT"" being placed (incorrectly) in a folder named; ""Method_MyBDT/MyBDT"". This patch places the data correctly in ""Method_BDT/BDT"". This is important since e.g. the GUI relies on all BDT's being placed in the ""MethodBDT"" folder. This will affect all methods, not only BDT's. This can be seen e.g. in the output of the `TMVAClassification.C` macro with several BDT's enabled: The GUI cannot generate plots for all BDT's. That the previous implementation was a typo is corroborated by this line:; ```; Log() << kDEBUG << Form(""Dataset[%s] : "", datasetName) << "" Base Directory for ""; << GetMethodTypeName() << "" not set yet --> check if already there.."" << Endl;; ```; , where it is implied that a directory of name `GetMethodTypeName()` should be created. However, in the old implementation a directory with name `GetMethodName()` was created instead. The issue was reported [here](https://root-forum.cern.ch/t/tmvagui-not-working-for-multiple-methods-of-bdt-in-file/32267) initially.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3253
https://github.com/root-project/root/pull/3254:38,Safety,safe,safety,38,The static vectors look like a thread safety issue in our tests.; std::array avoid memory allocation on every execution in the same way; the static vector does. NB: `#include <array>` is already present in the codegen from `MethodBase.cxx`. WIP: local building and testing,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3254
https://github.com/root-project/root/pull/3254:77,Safety,avoid,avoid,77,The static vectors look like a thread safety issue in our tests.; std::array avoid memory allocation on every execution in the same way; the static vector does. NB: `#include <array>` is already present in the codegen from `MethodBase.cxx`. WIP: local building and testing,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3254
https://github.com/root-project/root/pull/3254:58,Testability,test,tests,58,The static vectors look like a thread safety issue in our tests.; std::array avoid memory allocation on every execution in the same way; the static vector does. NB: `#include <array>` is already present in the codegen from `MethodBase.cxx`. WIP: local building and testing,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3254
https://github.com/root-project/root/pull/3254:265,Testability,test,testing,265,The static vectors look like a thread safety issue in our tests.; std::array avoid memory allocation on every execution in the same way; the static vector does. NB: `#include <array>` is already present in the codegen from `MethodBase.cxx`. WIP: local building and testing,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3254
https://github.com/root-project/root/pull/3255:17,Availability,failure,failures,17,"A number of test failures have to be fixed in the experimental PyROOT builds:. https://epsft-jenkins.cern.ch/job/root-exp-pyroot/8/. This PR temporarily disables those failing tests for the experimental PyROOT builds, and they will be re-enabled progressively as they are fixed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3255
https://github.com/root-project/root/pull/3255:12,Testability,test,test,12,"A number of test failures have to be fixed in the experimental PyROOT builds:. https://epsft-jenkins.cern.ch/job/root-exp-pyroot/8/. This PR temporarily disables those failing tests for the experimental PyROOT builds, and they will be re-enabled progressively as they are fixed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3255
https://github.com/root-project/root/pull/3255:176,Testability,test,tests,176,"A number of test failures have to be fixed in the experimental PyROOT builds:. https://epsft-jenkins.cern.ch/job/root-exp-pyroot/8/. This PR temporarily disables those failing tests for the experimental PyROOT builds, and they will be re-enabled progressively as they are fixed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3255
https://github.com/root-project/root/pull/3260:17,Availability,failure,failures,17,"A number of test failures have to be fixed in the experimental PyROOT builds:. https://epsft-jenkins.cern.ch/job/root-exp-pyroot/9/. This PR temporarily flags those tests as ""will fail"" for the experimental PyROOT builds, and they will be restored progressively as they are fixed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3260
https://github.com/root-project/root/pull/3260:12,Testability,test,test,12,"A number of test failures have to be fixed in the experimental PyROOT builds:. https://epsft-jenkins.cern.ch/job/root-exp-pyroot/9/. This PR temporarily flags those tests as ""will fail"" for the experimental PyROOT builds, and they will be restored progressively as they are fixed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3260
https://github.com/root-project/root/pull/3260:165,Testability,test,tests,165,"A number of test failures have to be fixed in the experimental PyROOT builds:. https://epsft-jenkins.cern.ch/job/root-exp-pyroot/9/. This PR temporarily flags those tests as ""will fail"" for the experimental PyROOT builds, and they will be restored progressively as they are fixed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3260
https://github.com/root-project/root/pull/3261:59,Modifiability,variab,variable,59,RooDataHist warns that it has to readjust the binning of a variable; although no such adjustment is happening. Fixes: ROOT-8163,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3261
https://github.com/root-project/root/pull/3262:166,Performance,load,loading,166,"and therewith notebooks.; This was necessary to work around fakemodule, which has been removed; from ipython a long time ago.; The invocation to TPython triggers the loading of the TPyClassGenerator; TClassGenerator. Such generator acquires the GIL from within C++ code; unavoidably leading to deadlocks if ROOT thread safety is enabled. As a side effect, importing Python from within notebooks and ipython significantly speeds up.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3262
https://github.com/root-project/root/pull/3262:319,Safety,safe,safety,319,"and therewith notebooks.; This was necessary to work around fakemodule, which has been removed; from ipython a long time ago.; The invocation to TPython triggers the loading of the TPyClassGenerator; TClassGenerator. Such generator acquires the GIL from within C++ code; unavoidably leading to deadlocks if ROOT thread safety is enabled. As a side effect, importing Python from within notebooks and ipython significantly speeds up.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3262
https://github.com/root-project/root/pull/3263:80,Availability,failure,failures,80,"This reverts commit f84668d78f3911ad8a67b4ba03145cd5845f14fb.; It leads to test failures on centos7, while all other systems are ok.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3263
https://github.com/root-project/root/pull/3263:75,Testability,test,test,75,"This reverts commit f84668d78f3911ad8a67b4ba03145cd5845f14fb.; It leads to test failures on centos7, while all other systems are ok.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3263
https://github.com/root-project/root/pull/3266:74,Deployability,install,installation,74,- Use `PCRE_PCRE_LIBRARY` and `PCRE_PCREPOSIX_LIBRARY` variables; - Avoid installation of empty `lib/pkgconfig` directory. Fixes: [ROOT-9864](https://sft.its.cern.ch/jira/browse/ROOT-9864),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3266
https://github.com/root-project/root/pull/3266:55,Modifiability,variab,variables,55,- Use `PCRE_PCRE_LIBRARY` and `PCRE_PCREPOSIX_LIBRARY` variables; - Avoid installation of empty `lib/pkgconfig` directory. Fixes: [ROOT-9864](https://sft.its.cern.ch/jira/browse/ROOT-9864),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3266
https://github.com/root-project/root/pull/3266:68,Safety,Avoid,Avoid,68,- Use `PCRE_PCRE_LIBRARY` and `PCRE_PCREPOSIX_LIBRARY` variables; - Avoid installation of empty `lib/pkgconfig` directory. Fixes: [ROOT-9864](https://sft.its.cern.ch/jira/browse/ROOT-9864),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3266
https://github.com/root-project/root/pull/3267:812,Availability,avail,available,812,"This patch includes:; - Remove existing modulemap.overlay files; Cling now can generate virtual overlay files on-demand.; - Implement `-modulemap_overlay` flag to Cling; This flag is used to tell Cling the location of modulemaps to be; overlayed. (eg. stl.modulemap, libc.modulemap); - Generate and load virtual modulemap in Cling; It is in Interpreter constructor, happens as part of cxxmodules; initialization step.; - Implement an interface to Clang CompilerInvocation which can take FileSystem pointer; Previously, Clang only took a ""string of filenames"" which clearly doesn't; work for our usecase. We already discussed this new interface at; modules meeting, so this change will land upstream.; - Add a file existence check in Clang; When compiling a pcm and when Clang saw the #include with which pcm was available; (or being generated implicitly), Clang was putting a notation of the full path to this pcm.; This caused an error when build directory was deleted, because the path didn't exist anymore. This patch enables modules to be binary distributed, and to make it; work in CMSSW enviroment.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3267
https://github.com/root-project/root/pull/3267:931,Availability,error,error,931,"This patch includes:; - Remove existing modulemap.overlay files; Cling now can generate virtual overlay files on-demand.; - Implement `-modulemap_overlay` flag to Cling; This flag is used to tell Cling the location of modulemaps to be; overlayed. (eg. stl.modulemap, libc.modulemap); - Generate and load virtual modulemap in Cling; It is in Interpreter constructor, happens as part of cxxmodules; initialization step.; - Implement an interface to Clang CompilerInvocation which can take FileSystem pointer; Previously, Clang only took a ""string of filenames"" which clearly doesn't; work for our usecase. We already discussed this new interface at; modules meeting, so this change will land upstream.; - Add a file existence check in Clang; When compiling a pcm and when Clang saw the #include with which pcm was available; (or being generated implicitly), Clang was putting a notation of the full path to this pcm.; This caused an error when build directory was deleted, because the path didn't exist anymore. This patch enables modules to be binary distributed, and to make it; work in CMSSW enviroment.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3267
https://github.com/root-project/root/pull/3267:5,Deployability,patch,patch,5,"This patch includes:; - Remove existing modulemap.overlay files; Cling now can generate virtual overlay files on-demand.; - Implement `-modulemap_overlay` flag to Cling; This flag is used to tell Cling the location of modulemaps to be; overlayed. (eg. stl.modulemap, libc.modulemap); - Generate and load virtual modulemap in Cling; It is in Interpreter constructor, happens as part of cxxmodules; initialization step.; - Implement an interface to Clang CompilerInvocation which can take FileSystem pointer; Previously, Clang only took a ""string of filenames"" which clearly doesn't; work for our usecase. We already discussed this new interface at; modules meeting, so this change will land upstream.; - Add a file existence check in Clang; When compiling a pcm and when Clang saw the #include with which pcm was available; (or being generated implicitly), Clang was putting a notation of the full path to this pcm.; This caused an error when build directory was deleted, because the path didn't exist anymore. This patch enables modules to be binary distributed, and to make it; work in CMSSW enviroment.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3267
https://github.com/root-project/root/pull/3267:1015,Deployability,patch,patch,1015,"This patch includes:; - Remove existing modulemap.overlay files; Cling now can generate virtual overlay files on-demand.; - Implement `-modulemap_overlay` flag to Cling; This flag is used to tell Cling the location of modulemaps to be; overlayed. (eg. stl.modulemap, libc.modulemap); - Generate and load virtual modulemap in Cling; It is in Interpreter constructor, happens as part of cxxmodules; initialization step.; - Implement an interface to Clang CompilerInvocation which can take FileSystem pointer; Previously, Clang only took a ""string of filenames"" which clearly doesn't; work for our usecase. We already discussed this new interface at; modules meeting, so this change will land upstream.; - Add a file existence check in Clang; When compiling a pcm and when Clang saw the #include with which pcm was available; (or being generated implicitly), Clang was putting a notation of the full path to this pcm.; This caused an error when build directory was deleted, because the path didn't exist anymore. This patch enables modules to be binary distributed, and to make it; work in CMSSW enviroment.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3267
https://github.com/root-project/root/pull/3267:434,Integrability,interface,interface,434,"This patch includes:; - Remove existing modulemap.overlay files; Cling now can generate virtual overlay files on-demand.; - Implement `-modulemap_overlay` flag to Cling; This flag is used to tell Cling the location of modulemaps to be; overlayed. (eg. stl.modulemap, libc.modulemap); - Generate and load virtual modulemap in Cling; It is in Interpreter constructor, happens as part of cxxmodules; initialization step.; - Implement an interface to Clang CompilerInvocation which can take FileSystem pointer; Previously, Clang only took a ""string of filenames"" which clearly doesn't; work for our usecase. We already discussed this new interface at; modules meeting, so this change will land upstream.; - Add a file existence check in Clang; When compiling a pcm and when Clang saw the #include with which pcm was available; (or being generated implicitly), Clang was putting a notation of the full path to this pcm.; This caused an error when build directory was deleted, because the path didn't exist anymore. This patch enables modules to be binary distributed, and to make it; work in CMSSW enviroment.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3267
https://github.com/root-project/root/pull/3267:634,Integrability,interface,interface,634,"This patch includes:; - Remove existing modulemap.overlay files; Cling now can generate virtual overlay files on-demand.; - Implement `-modulemap_overlay` flag to Cling; This flag is used to tell Cling the location of modulemaps to be; overlayed. (eg. stl.modulemap, libc.modulemap); - Generate and load virtual modulemap in Cling; It is in Interpreter constructor, happens as part of cxxmodules; initialization step.; - Implement an interface to Clang CompilerInvocation which can take FileSystem pointer; Previously, Clang only took a ""string of filenames"" which clearly doesn't; work for our usecase. We already discussed this new interface at; modules meeting, so this change will land upstream.; - Add a file existence check in Clang; When compiling a pcm and when Clang saw the #include with which pcm was available; (or being generated implicitly), Clang was putting a notation of the full path to this pcm.; This caused an error when build directory was deleted, because the path didn't exist anymore. This patch enables modules to be binary distributed, and to make it; work in CMSSW enviroment.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3267
https://github.com/root-project/root/pull/3267:299,Performance,load,load,299,"This patch includes:; - Remove existing modulemap.overlay files; Cling now can generate virtual overlay files on-demand.; - Implement `-modulemap_overlay` flag to Cling; This flag is used to tell Cling the location of modulemaps to be; overlayed. (eg. stl.modulemap, libc.modulemap); - Generate and load virtual modulemap in Cling; It is in Interpreter constructor, happens as part of cxxmodules; initialization step.; - Implement an interface to Clang CompilerInvocation which can take FileSystem pointer; Previously, Clang only took a ""string of filenames"" which clearly doesn't; work for our usecase. We already discussed this new interface at; modules meeting, so this change will land upstream.; - Add a file existence check in Clang; When compiling a pcm and when Clang saw the #include with which pcm was available; (or being generated implicitly), Clang was putting a notation of the full path to this pcm.; This caused an error when build directory was deleted, because the path didn't exist anymore. This patch enables modules to be binary distributed, and to make it; work in CMSSW enviroment.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3267
https://github.com/root-project/root/pull/3267:565,Usability,clear,clearly,565,"This patch includes:; - Remove existing modulemap.overlay files; Cling now can generate virtual overlay files on-demand.; - Implement `-modulemap_overlay` flag to Cling; This flag is used to tell Cling the location of modulemaps to be; overlayed. (eg. stl.modulemap, libc.modulemap); - Generate and load virtual modulemap in Cling; It is in Interpreter constructor, happens as part of cxxmodules; initialization step.; - Implement an interface to Clang CompilerInvocation which can take FileSystem pointer; Previously, Clang only took a ""string of filenames"" which clearly doesn't; work for our usecase. We already discussed this new interface at; modules meeting, so this change will land upstream.; - Add a file existence check in Clang; When compiling a pcm and when Clang saw the #include with which pcm was available; (or being generated implicitly), Clang was putting a notation of the full path to this pcm.; This caused an error when build directory was deleted, because the path didn't exist anymore. This patch enables modules to be binary distributed, and to make it; work in CMSSW enviroment.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3267
https://github.com/root-project/root/pull/3269:136,Modifiability,inherit,inherits,136,"The method TClass::GetClass<T> obtains the TClass instance pointer; corresponding to T in two ways, according to the nature of T.; If T inherits from or is TObject, the TClass* value is obtained via the; T::Class() static method, which locks only upon the first call.; If T is a generic type, internally the TClass::GetClass(type_info, ...); method is called. The new functionality is put to a good use by this commit in TBuffer; and TDirectoryFile. It is worth noting how the usage of tag dispatching could be replaced; by 'if constexpr'.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3269
https://github.com/root-project/root/pull/3274:116,Integrability,depend,dependencies,116,"Move declaration of ESockOptions and ESendRecvOptions enums from TSocket.h to TSystem.h, to get rid of this include dependencies in CMake:; include_directories(${CMAKE_SOURCE_DIR}/net/net/inc)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3274
https://github.com/root-project/root/pull/3279:65,Integrability,depend,dependency,65,roottools CMake target purpose is to provide handle to used as a dependency in roottest.git.; It will fix problem of data generation for roottest.git tests in very parallel build (ROOT-performance PR node).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3279
https://github.com/root-project/root/pull/3279:185,Performance,perform,performance,185,roottools CMake target purpose is to provide handle to used as a dependency in roottest.git.; It will fix problem of data generation for roottest.git tests in very parallel build (ROOT-performance PR node).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3279
https://github.com/root-project/root/pull/3279:150,Testability,test,tests,150,roottools CMake target purpose is to provide handle to used as a dependency in roottest.git.; It will fix problem of data generation for roottest.git tests in very parallel build (ROOT-performance PR node).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3279
https://github.com/root-project/root/pull/3282:150,Performance,load,load,150,"Otherwise `libcppyy` and `libcppyy_backend` are generated with the`.dylib` suffix on OSX. This causes a crash when importing cppyy, since it tries to load `libcppyy_backend.so` using ctypes. Thank you @amadio for the suggestion of setting `CMAKE_SHARED_LIBRARY_SUFFIX`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3282
https://github.com/root-project/root/pull/3287:5,Deployability,patch,patch,5,This patch is to fix a warning by duplicated definitions of SIGSYS in signal.h; and in TUnixSystem.cxx.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3287
https://github.com/root-project/root/pull/3291:5,Deployability,patch,patch,5,"This patch is a tentative fix to JIRA bug [ROOT-9907](https://sft.its.cern.ch/jira/browse/ROOT-9907) (TGeoNavigator::FindNextBoundaryAndStep yields nonsensical answers with overlapping volumes). The bug seems to be due to the fact that `/CUVE_1/FAIS_1/PLAQUE_2` fails the `Contains()` check on line 1416, despite the fact that (or because?) the point is exactly on the volume boundary. Therefore, `PLAQUE_2` is not considered **at all** for limiting the current step length, which is unsound. By suppressing the `Contains()` check, we allow `snext` to be set to 0.0, which is a sensible response in this situation. I am not sure whether suppressing this check is entirely reasonable. I perused the source code for a few `TGeoShape`s and I have the impression that `DistFromOutside()` returne `TGeoShape::Big()` if the point happens to be inside the shape, but I could not find any documentation where this post-condition is clearly spelt out. If this is true for any shape, then I would argue that it is safe to omit the `Contains()` check (at worst we will end up with `snext=TGeoShape::Big()`, which is exactly what we had with the check anyway). @agheata, I hope you can take a look at this patch. Perhaps you are also aware of other places in `TGeoNavigator` where it may be wise to apply a similar correction...? Thanks.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3291
https://github.com/root-project/root/pull/3291:1194,Deployability,patch,patch,1194,"This patch is a tentative fix to JIRA bug [ROOT-9907](https://sft.its.cern.ch/jira/browse/ROOT-9907) (TGeoNavigator::FindNextBoundaryAndStep yields nonsensical answers with overlapping volumes). The bug seems to be due to the fact that `/CUVE_1/FAIS_1/PLAQUE_2` fails the `Contains()` check on line 1416, despite the fact that (or because?) the point is exactly on the volume boundary. Therefore, `PLAQUE_2` is not considered **at all** for limiting the current step length, which is unsound. By suppressing the `Contains()` check, we allow `snext` to be set to 0.0, which is a sensible response in this situation. I am not sure whether suppressing this check is entirely reasonable. I perused the source code for a few `TGeoShape`s and I have the impression that `DistFromOutside()` returne `TGeoShape::Big()` if the point happens to be inside the shape, but I could not find any documentation where this post-condition is clearly spelt out. If this is true for any shape, then I would argue that it is safe to omit the `Contains()` check (at worst we will end up with `snext=TGeoShape::Big()`, which is exactly what we had with the check anyway). @agheata, I hope you can take a look at this patch. Perhaps you are also aware of other places in `TGeoNavigator` where it may be wise to apply a similar correction...? Thanks.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3291
https://github.com/root-project/root/pull/3291:1004,Safety,safe,safe,1004,"This patch is a tentative fix to JIRA bug [ROOT-9907](https://sft.its.cern.ch/jira/browse/ROOT-9907) (TGeoNavigator::FindNextBoundaryAndStep yields nonsensical answers with overlapping volumes). The bug seems to be due to the fact that `/CUVE_1/FAIS_1/PLAQUE_2` fails the `Contains()` check on line 1416, despite the fact that (or because?) the point is exactly on the volume boundary. Therefore, `PLAQUE_2` is not considered **at all** for limiting the current step length, which is unsound. By suppressing the `Contains()` check, we allow `snext` to be set to 0.0, which is a sensible response in this situation. I am not sure whether suppressing this check is entirely reasonable. I perused the source code for a few `TGeoShape`s and I have the impression that `DistFromOutside()` returne `TGeoShape::Big()` if the point happens to be inside the shape, but I could not find any documentation where this post-condition is clearly spelt out. If this is true for any shape, then I would argue that it is safe to omit the `Contains()` check (at worst we will end up with `snext=TGeoShape::Big()`, which is exactly what we had with the check anyway). @agheata, I hope you can take a look at this patch. Perhaps you are also aware of other places in `TGeoNavigator` where it may be wise to apply a similar correction...? Thanks.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3291
https://github.com/root-project/root/pull/3291:924,Usability,clear,clearly,924,"This patch is a tentative fix to JIRA bug [ROOT-9907](https://sft.its.cern.ch/jira/browse/ROOT-9907) (TGeoNavigator::FindNextBoundaryAndStep yields nonsensical answers with overlapping volumes). The bug seems to be due to the fact that `/CUVE_1/FAIS_1/PLAQUE_2` fails the `Contains()` check on line 1416, despite the fact that (or because?) the point is exactly on the volume boundary. Therefore, `PLAQUE_2` is not considered **at all** for limiting the current step length, which is unsound. By suppressing the `Contains()` check, we allow `snext` to be set to 0.0, which is a sensible response in this situation. I am not sure whether suppressing this check is entirely reasonable. I perused the source code for a few `TGeoShape`s and I have the impression that `DistFromOutside()` returne `TGeoShape::Big()` if the point happens to be inside the shape, but I could not find any documentation where this post-condition is clearly spelt out. If this is true for any shape, then I would argue that it is safe to omit the `Contains()` check (at worst we will end up with `snext=TGeoShape::Big()`, which is exactly what we had with the check anyway). @agheata, I hope you can take a look at this patch. Perhaps you are also aware of other places in `TGeoNavigator` where it may be wise to apply a similar correction...? Thanks.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3291
https://github.com/root-project/root/pull/3298:189,Testability,test,tests,189,"This PR mainly adds pythonisations for `TCollection` and its subclasses. It also adds a pythonisation for `TIter`, which is necessary to iterate over `TCollection`s. The corresponding unit tests for every pythonisation are also proposed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3298
https://github.com/root-project/root/pull/3299:4,Security,expose,expose,4,"Not expose ROOT/RConfig.h to rootcling, but to add the header to ROOT_Config pcm.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3299
https://github.com/root-project/root/pull/3303:14,Availability,error,errors,14,This leads to errors due to absolute paths if ROOT is already; installed in the configured prefix (e.g. /usr/lib64/root):. CMake Error at cmake/modules/RootNewMacros.cmake:288 (message):; Header path; '/usr/lib64/root/include/ROOT/RVirtualCanvasPainter.hxx'; /usr/lib64/root/include/ROOT/RVirtualCanvasPainter.hxx; is not relative!; Call Stack (most recent call first):; cmake/modules/RootNewMacros.cmake:968 (ROOT_GENERATE_DICTIONARY); graf2d/gpadv7/CMakeLists.txt:6 (ROOT_STANDARD_LIBRARY_PACKAGE),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3303
https://github.com/root-project/root/pull/3303:129,Availability,Error,Error,129,This leads to errors due to absolute paths if ROOT is already; installed in the configured prefix (e.g. /usr/lib64/root):. CMake Error at cmake/modules/RootNewMacros.cmake:288 (message):; Header path; '/usr/lib64/root/include/ROOT/RVirtualCanvasPainter.hxx'; /usr/lib64/root/include/ROOT/RVirtualCanvasPainter.hxx; is not relative!; Call Stack (most recent call first):; cmake/modules/RootNewMacros.cmake:968 (ROOT_GENERATE_DICTIONARY); graf2d/gpadv7/CMakeLists.txt:6 (ROOT_STANDARD_LIBRARY_PACKAGE),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3303
https://github.com/root-project/root/pull/3303:63,Deployability,install,installed,63,This leads to errors due to absolute paths if ROOT is already; installed in the configured prefix (e.g. /usr/lib64/root):. CMake Error at cmake/modules/RootNewMacros.cmake:288 (message):; Header path; '/usr/lib64/root/include/ROOT/RVirtualCanvasPainter.hxx'; /usr/lib64/root/include/ROOT/RVirtualCanvasPainter.hxx; is not relative!; Call Stack (most recent call first):; cmake/modules/RootNewMacros.cmake:968 (ROOT_GENERATE_DICTIONARY); graf2d/gpadv7/CMakeLists.txt:6 (ROOT_STANDARD_LIBRARY_PACKAGE),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3303
https://github.com/root-project/root/pull/3303:177,Integrability,message,message,177,This leads to errors due to absolute paths if ROOT is already; installed in the configured prefix (e.g. /usr/lib64/root):. CMake Error at cmake/modules/RootNewMacros.cmake:288 (message):; Header path; '/usr/lib64/root/include/ROOT/RVirtualCanvasPainter.hxx'; /usr/lib64/root/include/ROOT/RVirtualCanvasPainter.hxx; is not relative!; Call Stack (most recent call first):; cmake/modules/RootNewMacros.cmake:968 (ROOT_GENERATE_DICTIONARY); graf2d/gpadv7/CMakeLists.txt:6 (ROOT_STANDARD_LIBRARY_PACKAGE),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3303
https://github.com/root-project/root/pull/3303:80,Modifiability,config,configured,80,This leads to errors due to absolute paths if ROOT is already; installed in the configured prefix (e.g. /usr/lib64/root):. CMake Error at cmake/modules/RootNewMacros.cmake:288 (message):; Header path; '/usr/lib64/root/include/ROOT/RVirtualCanvasPainter.hxx'; /usr/lib64/root/include/ROOT/RVirtualCanvasPainter.hxx; is not relative!; Call Stack (most recent call first):; cmake/modules/RootNewMacros.cmake:968 (ROOT_GENERATE_DICTIONARY); graf2d/gpadv7/CMakeLists.txt:6 (ROOT_STANDARD_LIBRARY_PACKAGE),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3303
https://github.com/root-project/root/pull/3306:4,Energy Efficiency,adapt,adapt,4,and adapt the size of the block for TBufferMergerFile,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3306
https://github.com/root-project/root/pull/3306:4,Modifiability,adapt,adapt,4,and adapt the size of the block for TBufferMergerFile,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3306
https://github.com/root-project/root/pull/3310:130,Deployability,release,release,130,"This is a backport of commit 68509691, fixing bug [ROOT-9907](https://sft.its.cern.ch/jira/browse/ROOT-9907). Do you guys plan to release a new patch to the v6.12 series?",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3310
https://github.com/root-project/root/pull/3310:144,Deployability,patch,patch,144,"This is a backport of commit 68509691, fixing bug [ROOT-9907](https://sft.its.cern.ch/jira/browse/ROOT-9907). Do you guys plan to release a new patch to the v6.12 series?",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3310
https://github.com/root-project/root/pull/3312:25,Availability,failure,failure,25,This fixes the following failure of the test-stresshistofit-interpreted test:. 151: Processing C:/Users/sftnight/git/master/test/stressHistoFit.cxx...; 151: In file included from input_line_10:1:; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:117:9: warning: 'FOREGROUND_BLUE' macro redefined [-Wmacro-redefined]; 151: #define FOREGROUND_BLUE 1; 151: ^; 151: C:\Program Files (x86)\Windows Kits\10\Include\10.0.17134.0\um\consoleapi2.h:35:9: note: previous definition is here; 151: #define FOREGROUND_BLUE 0x0001 // text color contains blue.; 151: ^; 151: In file included from input_line_10:1:; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:118:9: warning: 'FOREGROUND_GREEN' macro redefined [-Wmacro-redefined]; 151: #define FOREGROUND_GREEN 2; 151: ^; 151: C:\Program Files (x86)\Windows Kits\10\Include\10.0.17134.0\um\consoleapi2.h:36:9: note: previous definition is here; 151: #define FOREGROUND_GREEN 0x0002 // text color contains green.; 151: ^; 151: In file included from input_line_10:1:; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:119:9: warning: 'FOREGROUND_RED' macro redefined [-Wmacro-redefined]; 151: #define FOREGROUND_RED 4; 151: ^; 151: C:\Program Files (x86)\Windows Kits\10\Include\10.0.17134.0\um\consoleapi2.h:37:9: note: previous definition is here; 151: #define FOREGROUND_RED 0x0004 // text color contains red.; 151: ^; 151: In file included from input_line_10:1:; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:120:9: warning: 'FOREGROUND_INTENSITY' macro redefined [-Wmacro-redefined]; 151: #define FOREGROUND_INTENSITY 8; 151: ^; 151: C:\Program Files (x86)\Windows Kits\10\Include\10.0.17134.0\um\consoleapi2.h:38:9: note: previous definition is here; 151: #define FOREGROUND_INTENSITY 0x0008 // text color is intensified.; 151: ^; 151: In file included from input_line_10:1:; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:124:19: error: functions that differ only in their return type cannot be overloaded; 1,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3312
https://github.com/root-project/root/pull/3312:1923,Availability,error,error,1923,"; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:119:9: warning: 'FOREGROUND_RED' macro redefined [-Wmacro-redefined]; 151: #define FOREGROUND_RED 4; 151: ^; 151: C:\Program Files (x86)\Windows Kits\10\Include\10.0.17134.0\um\consoleapi2.h:37:9: note: previous definition is here; 151: #define FOREGROUND_RED 0x0004 // text color contains red.; 151: ^; 151: In file included from input_line_10:1:; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:120:9: warning: 'FOREGROUND_INTENSITY' macro redefined [-Wmacro-redefined]; 151: #define FOREGROUND_INTENSITY 8; 151: ^; 151: C:\Program Files (x86)\Windows Kits\10\Include\10.0.17134.0\um\consoleapi2.h:38:9: note: previous definition is here; 151: #define FOREGROUND_INTENSITY 0x0008 // text color is intensified.; 151: ^; 151: In file included from input_line_10:1:; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:124:19: error: functions that differ only in their return type cannot be overloaded; 151: bool __stdcall SetConsoleTextAttribute(void *, unsigned int);; 151: ^; 151: C:\Program Files (x86)\Windows Kits\10\Include\10.0.17134.0\um\consoleapi2.h:245:1: note: previous declaration is here; 151: SetConsoleTextAttribute(; 151: ^; 151: Error in <TInterpreter::AutoParse>: Error parsing payload code for class TUnuranContDist with content:; 151:; 151: #line 1 ""libUnuran dictionary payload""; 151:; 151: #ifndef HAVE_CONFIG_H; 151: #define HAVE_CONFIG_H 1; 151: #endif; 151:; 151: #define _BACKWARD_BACKWARD_WARNING_H; 151: #include ""TUnuran.h""; 151: #include ""TUnuranBaseDist.h""; 151: #include ""TUnuranContDist.h""; 151: #include ""TUnuranDiscrDist.h""; 151: #include ""TUnuranEmpDist.h""; 151: #include ""TUnuranMultiContDist.h""; 151: #include ""TUnuranSampler.h""; 151:; 151: #undef _BACKWARD_BACKWARD_WARNING_H; 151:; 151: Error in <TInterpreter::AutoParse>: Error parsing payload code for class TUnuranDiscrDist with content:; 151:; 151: #line 1 ""libUnuran dictionary payload""; 151:; 151: #ifndef HAVE_CONFIG_H; 151: ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3312
https://github.com/root-project/root/pull/3312:2245,Availability,Error,Error,2245,"ext color contains red.; 151: ^; 151: In file included from input_line_10:1:; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:120:9: warning: 'FOREGROUND_INTENSITY' macro redefined [-Wmacro-redefined]; 151: #define FOREGROUND_INTENSITY 8; 151: ^; 151: C:\Program Files (x86)\Windows Kits\10\Include\10.0.17134.0\um\consoleapi2.h:38:9: note: previous definition is here; 151: #define FOREGROUND_INTENSITY 0x0008 // text color is intensified.; 151: ^; 151: In file included from input_line_10:1:; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:124:19: error: functions that differ only in their return type cannot be overloaded; 151: bool __stdcall SetConsoleTextAttribute(void *, unsigned int);; 151: ^; 151: C:\Program Files (x86)\Windows Kits\10\Include\10.0.17134.0\um\consoleapi2.h:245:1: note: previous declaration is here; 151: SetConsoleTextAttribute(; 151: ^; 151: Error in <TInterpreter::AutoParse>: Error parsing payload code for class TUnuranContDist with content:; 151:; 151: #line 1 ""libUnuran dictionary payload""; 151:; 151: #ifndef HAVE_CONFIG_H; 151: #define HAVE_CONFIG_H 1; 151: #endif; 151:; 151: #define _BACKWARD_BACKWARD_WARNING_H; 151: #include ""TUnuran.h""; 151: #include ""TUnuranBaseDist.h""; 151: #include ""TUnuranContDist.h""; 151: #include ""TUnuranDiscrDist.h""; 151: #include ""TUnuranEmpDist.h""; 151: #include ""TUnuranMultiContDist.h""; 151: #include ""TUnuranSampler.h""; 151:; 151: #undef _BACKWARD_BACKWARD_WARNING_H; 151:; 151: Error in <TInterpreter::AutoParse>: Error parsing payload code for class TUnuranDiscrDist with content:; 151:; 151: #line 1 ""libUnuran dictionary payload""; 151:; 151: #ifndef HAVE_CONFIG_H; 151: #define HAVE_CONFIG_H 1; 151: #endif; 151:; 151: #define _BACKWARD_BACKWARD_WARNING_H; 151: #include ""TUnuran.h""; 151: #include ""TUnuranBaseDist.h""; 151: #include ""TUnuranContDist.h""; 151: #include ""TUnuranDiscrDist.h""; 151: #include ""TUnuranEmpDist.h""; 151: #include ""TUnuranMultiContDist.h""; 151: #include ""TUnuranSampler.h""; 151:",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3312
https://github.com/root-project/root/pull/3312:2281,Availability,Error,Error,2281,"ext color contains red.; 151: ^; 151: In file included from input_line_10:1:; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:120:9: warning: 'FOREGROUND_INTENSITY' macro redefined [-Wmacro-redefined]; 151: #define FOREGROUND_INTENSITY 8; 151: ^; 151: C:\Program Files (x86)\Windows Kits\10\Include\10.0.17134.0\um\consoleapi2.h:38:9: note: previous definition is here; 151: #define FOREGROUND_INTENSITY 0x0008 // text color is intensified.; 151: ^; 151: In file included from input_line_10:1:; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:124:19: error: functions that differ only in their return type cannot be overloaded; 151: bool __stdcall SetConsoleTextAttribute(void *, unsigned int);; 151: ^; 151: C:\Program Files (x86)\Windows Kits\10\Include\10.0.17134.0\um\consoleapi2.h:245:1: note: previous declaration is here; 151: SetConsoleTextAttribute(; 151: ^; 151: Error in <TInterpreter::AutoParse>: Error parsing payload code for class TUnuranContDist with content:; 151:; 151: #line 1 ""libUnuran dictionary payload""; 151:; 151: #ifndef HAVE_CONFIG_H; 151: #define HAVE_CONFIG_H 1; 151: #endif; 151:; 151: #define _BACKWARD_BACKWARD_WARNING_H; 151: #include ""TUnuran.h""; 151: #include ""TUnuranBaseDist.h""; 151: #include ""TUnuranContDist.h""; 151: #include ""TUnuranDiscrDist.h""; 151: #include ""TUnuranEmpDist.h""; 151: #include ""TUnuranMultiContDist.h""; 151: #include ""TUnuranSampler.h""; 151:; 151: #undef _BACKWARD_BACKWARD_WARNING_H; 151:; 151: Error in <TInterpreter::AutoParse>: Error parsing payload code for class TUnuranDiscrDist with content:; 151:; 151: #line 1 ""libUnuran dictionary payload""; 151:; 151: #ifndef HAVE_CONFIG_H; 151: #define HAVE_CONFIG_H 1; 151: #endif; 151:; 151: #define _BACKWARD_BACKWARD_WARNING_H; 151: #include ""TUnuran.h""; 151: #include ""TUnuranBaseDist.h""; 151: #include ""TUnuranContDist.h""; 151: #include ""TUnuranDiscrDist.h""; 151: #include ""TUnuranEmpDist.h""; 151: #include ""TUnuranMultiContDist.h""; 151: #include ""TUnuranSampler.h""; 151:",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3312
https://github.com/root-project/root/pull/3312:2826,Availability,Error,Error,2826,"ffer only in their return type cannot be overloaded; 151: bool __stdcall SetConsoleTextAttribute(void *, unsigned int);; 151: ^; 151: C:\Program Files (x86)\Windows Kits\10\Include\10.0.17134.0\um\consoleapi2.h:245:1: note: previous declaration is here; 151: SetConsoleTextAttribute(; 151: ^; 151: Error in <TInterpreter::AutoParse>: Error parsing payload code for class TUnuranContDist with content:; 151:; 151: #line 1 ""libUnuran dictionary payload""; 151:; 151: #ifndef HAVE_CONFIG_H; 151: #define HAVE_CONFIG_H 1; 151: #endif; 151:; 151: #define _BACKWARD_BACKWARD_WARNING_H; 151: #include ""TUnuran.h""; 151: #include ""TUnuranBaseDist.h""; 151: #include ""TUnuranContDist.h""; 151: #include ""TUnuranDiscrDist.h""; 151: #include ""TUnuranEmpDist.h""; 151: #include ""TUnuranMultiContDist.h""; 151: #include ""TUnuranSampler.h""; 151:; 151: #undef _BACKWARD_BACKWARD_WARNING_H; 151:; 151: Error in <TInterpreter::AutoParse>: Error parsing payload code for class TUnuranDiscrDist with content:; 151:; 151: #line 1 ""libUnuran dictionary payload""; 151:; 151: #ifndef HAVE_CONFIG_H; 151: #define HAVE_CONFIG_H 1; 151: #endif; 151:; 151: #define _BACKWARD_BACKWARD_WARNING_H; 151: #include ""TUnuran.h""; 151: #include ""TUnuranBaseDist.h""; 151: #include ""TUnuranContDist.h""; 151: #include ""TUnuranDiscrDist.h""; 151: #include ""TUnuranEmpDist.h""; 151: #include ""TUnuranMultiContDist.h""; 151: #include ""TUnuranSampler.h""; 151:; 151: #undef _BACKWARD_BACKWARD_WARNING_H; 151:; 151: Error in <TInterpreter::AutoParse>: Error parsing payload code for class TUnuranEmpDist with content:; 151:; 151: #line 1 ""libUnuran dictionary payload""; 151:; 151: #ifndef HAVE_CONFIG_H; 151: #define HAVE_CONFIG_H 1; 151: #endif; 151:; 151: #define _BACKWARD_BACKWARD_WARNING_H; 151: #include ""TUnuran.h""; 151: #include ""TUnuranBaseDist.h""; 151: #include ""TUnuranContDist.h""; 151: #include ""TUnuranDiscrDist.h""; 151: #include ""TUnuranEmpDist.h""; 151: #include ""TUnuranMultiContDist.h""; 151: #include ""TUnuranSampler.h""; 151:; 151: #undef ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3312
https://github.com/root-project/root/pull/3312:2862,Availability,Error,Error,2862,"ffer only in their return type cannot be overloaded; 151: bool __stdcall SetConsoleTextAttribute(void *, unsigned int);; 151: ^; 151: C:\Program Files (x86)\Windows Kits\10\Include\10.0.17134.0\um\consoleapi2.h:245:1: note: previous declaration is here; 151: SetConsoleTextAttribute(; 151: ^; 151: Error in <TInterpreter::AutoParse>: Error parsing payload code for class TUnuranContDist with content:; 151:; 151: #line 1 ""libUnuran dictionary payload""; 151:; 151: #ifndef HAVE_CONFIG_H; 151: #define HAVE_CONFIG_H 1; 151: #endif; 151:; 151: #define _BACKWARD_BACKWARD_WARNING_H; 151: #include ""TUnuran.h""; 151: #include ""TUnuranBaseDist.h""; 151: #include ""TUnuranContDist.h""; 151: #include ""TUnuranDiscrDist.h""; 151: #include ""TUnuranEmpDist.h""; 151: #include ""TUnuranMultiContDist.h""; 151: #include ""TUnuranSampler.h""; 151:; 151: #undef _BACKWARD_BACKWARD_WARNING_H; 151:; 151: Error in <TInterpreter::AutoParse>: Error parsing payload code for class TUnuranDiscrDist with content:; 151:; 151: #line 1 ""libUnuran dictionary payload""; 151:; 151: #ifndef HAVE_CONFIG_H; 151: #define HAVE_CONFIG_H 1; 151: #endif; 151:; 151: #define _BACKWARD_BACKWARD_WARNING_H; 151: #include ""TUnuran.h""; 151: #include ""TUnuranBaseDist.h""; 151: #include ""TUnuranContDist.h""; 151: #include ""TUnuranDiscrDist.h""; 151: #include ""TUnuranEmpDist.h""; 151: #include ""TUnuranMultiContDist.h""; 151: #include ""TUnuranSampler.h""; 151:; 151: #undef _BACKWARD_BACKWARD_WARNING_H; 151:; 151: Error in <TInterpreter::AutoParse>: Error parsing payload code for class TUnuranEmpDist with content:; 151:; 151: #line 1 ""libUnuran dictionary payload""; 151:; 151: #ifndef HAVE_CONFIG_H; 151: #define HAVE_CONFIG_H 1; 151: #endif; 151:; 151: #define _BACKWARD_BACKWARD_WARNING_H; 151: #include ""TUnuran.h""; 151: #include ""TUnuranBaseDist.h""; 151: #include ""TUnuranContDist.h""; 151: #include ""TUnuranDiscrDist.h""; 151: #include ""TUnuranEmpDist.h""; 151: #include ""TUnuranMultiContDist.h""; 151: #include ""TUnuranSampler.h""; 151:; 151: #undef ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3312
https://github.com/root-project/root/pull/3312:3408,Availability,Error,Error,3408," in <TInterpreter::AutoParse>: Error parsing payload code for class TUnuranContDist with content:; 151:; 151: #line 1 ""libUnuran dictionary payload""; 151:; 151: #ifndef HAVE_CONFIG_H; 151: #define HAVE_CONFIG_H 1; 151: #endif; 151:; 151: #define _BACKWARD_BACKWARD_WARNING_H; 151: #include ""TUnuran.h""; 151: #include ""TUnuranBaseDist.h""; 151: #include ""TUnuranContDist.h""; 151: #include ""TUnuranDiscrDist.h""; 151: #include ""TUnuranEmpDist.h""; 151: #include ""TUnuranMultiContDist.h""; 151: #include ""TUnuranSampler.h""; 151:; 151: #undef _BACKWARD_BACKWARD_WARNING_H; 151:; 151: Error in <TInterpreter::AutoParse>: Error parsing payload code for class TUnuranDiscrDist with content:; 151:; 151: #line 1 ""libUnuran dictionary payload""; 151:; 151: #ifndef HAVE_CONFIG_H; 151: #define HAVE_CONFIG_H 1; 151: #endif; 151:; 151: #define _BACKWARD_BACKWARD_WARNING_H; 151: #include ""TUnuran.h""; 151: #include ""TUnuranBaseDist.h""; 151: #include ""TUnuranContDist.h""; 151: #include ""TUnuranDiscrDist.h""; 151: #include ""TUnuranEmpDist.h""; 151: #include ""TUnuranMultiContDist.h""; 151: #include ""TUnuranSampler.h""; 151:; 151: #undef _BACKWARD_BACKWARD_WARNING_H; 151:; 151: Error in <TInterpreter::AutoParse>: Error parsing payload code for class TUnuranEmpDist with content:; 151:; 151: #line 1 ""libUnuran dictionary payload""; 151:; 151: #ifndef HAVE_CONFIG_H; 151: #define HAVE_CONFIG_H 1; 151: #endif; 151:; 151: #define _BACKWARD_BACKWARD_WARNING_H; 151: #include ""TUnuran.h""; 151: #include ""TUnuranBaseDist.h""; 151: #include ""TUnuranContDist.h""; 151: #include ""TUnuranDiscrDist.h""; 151: #include ""TUnuranEmpDist.h""; 151: #include ""TUnuranMultiContDist.h""; 151: #include ""TUnuranSampler.h""; 151:; 151: #undef _BACKWARD_BACKWARD_WARNING_H; 151:; 151: CMake Error at C:/Users/sftnight/git/master/cmake/modules/RootTestDriver.cmake:232 (message):; 151: error code: 1; 151:; 151:; 2/2 Test #151: test-stresshistofit-interpreted ...***Failed Error regular expression found in output. Regex=[FAILED|Error in] 10.55 sec",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3312
https://github.com/root-project/root/pull/3312:3444,Availability,Error,Error,3444," in <TInterpreter::AutoParse>: Error parsing payload code for class TUnuranContDist with content:; 151:; 151: #line 1 ""libUnuran dictionary payload""; 151:; 151: #ifndef HAVE_CONFIG_H; 151: #define HAVE_CONFIG_H 1; 151: #endif; 151:; 151: #define _BACKWARD_BACKWARD_WARNING_H; 151: #include ""TUnuran.h""; 151: #include ""TUnuranBaseDist.h""; 151: #include ""TUnuranContDist.h""; 151: #include ""TUnuranDiscrDist.h""; 151: #include ""TUnuranEmpDist.h""; 151: #include ""TUnuranMultiContDist.h""; 151: #include ""TUnuranSampler.h""; 151:; 151: #undef _BACKWARD_BACKWARD_WARNING_H; 151:; 151: Error in <TInterpreter::AutoParse>: Error parsing payload code for class TUnuranDiscrDist with content:; 151:; 151: #line 1 ""libUnuran dictionary payload""; 151:; 151: #ifndef HAVE_CONFIG_H; 151: #define HAVE_CONFIG_H 1; 151: #endif; 151:; 151: #define _BACKWARD_BACKWARD_WARNING_H; 151: #include ""TUnuran.h""; 151: #include ""TUnuranBaseDist.h""; 151: #include ""TUnuranContDist.h""; 151: #include ""TUnuranDiscrDist.h""; 151: #include ""TUnuranEmpDist.h""; 151: #include ""TUnuranMultiContDist.h""; 151: #include ""TUnuranSampler.h""; 151:; 151: #undef _BACKWARD_BACKWARD_WARNING_H; 151:; 151: Error in <TInterpreter::AutoParse>: Error parsing payload code for class TUnuranEmpDist with content:; 151:; 151: #line 1 ""libUnuran dictionary payload""; 151:; 151: #ifndef HAVE_CONFIG_H; 151: #define HAVE_CONFIG_H 1; 151: #endif; 151:; 151: #define _BACKWARD_BACKWARD_WARNING_H; 151: #include ""TUnuran.h""; 151: #include ""TUnuranBaseDist.h""; 151: #include ""TUnuranContDist.h""; 151: #include ""TUnuranDiscrDist.h""; 151: #include ""TUnuranEmpDist.h""; 151: #include ""TUnuranMultiContDist.h""; 151: #include ""TUnuranSampler.h""; 151:; 151: #undef _BACKWARD_BACKWARD_WARNING_H; 151:; 151: CMake Error at C:/Users/sftnight/git/master/cmake/modules/RootTestDriver.cmake:232 (message):; 151: error code: 1; 151:; 151:; 2/2 Test #151: test-stresshistofit-interpreted ...***Failed Error regular expression found in output. Regex=[FAILED|Error in] 10.55 sec",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3312
https://github.com/root-project/root/pull/3312:3994,Availability,Error,Error,3994," in <TInterpreter::AutoParse>: Error parsing payload code for class TUnuranContDist with content:; 151:; 151: #line 1 ""libUnuran dictionary payload""; 151:; 151: #ifndef HAVE_CONFIG_H; 151: #define HAVE_CONFIG_H 1; 151: #endif; 151:; 151: #define _BACKWARD_BACKWARD_WARNING_H; 151: #include ""TUnuran.h""; 151: #include ""TUnuranBaseDist.h""; 151: #include ""TUnuranContDist.h""; 151: #include ""TUnuranDiscrDist.h""; 151: #include ""TUnuranEmpDist.h""; 151: #include ""TUnuranMultiContDist.h""; 151: #include ""TUnuranSampler.h""; 151:; 151: #undef _BACKWARD_BACKWARD_WARNING_H; 151:; 151: Error in <TInterpreter::AutoParse>: Error parsing payload code for class TUnuranDiscrDist with content:; 151:; 151: #line 1 ""libUnuran dictionary payload""; 151:; 151: #ifndef HAVE_CONFIG_H; 151: #define HAVE_CONFIG_H 1; 151: #endif; 151:; 151: #define _BACKWARD_BACKWARD_WARNING_H; 151: #include ""TUnuran.h""; 151: #include ""TUnuranBaseDist.h""; 151: #include ""TUnuranContDist.h""; 151: #include ""TUnuranDiscrDist.h""; 151: #include ""TUnuranEmpDist.h""; 151: #include ""TUnuranMultiContDist.h""; 151: #include ""TUnuranSampler.h""; 151:; 151: #undef _BACKWARD_BACKWARD_WARNING_H; 151:; 151: Error in <TInterpreter::AutoParse>: Error parsing payload code for class TUnuranEmpDist with content:; 151:; 151: #line 1 ""libUnuran dictionary payload""; 151:; 151: #ifndef HAVE_CONFIG_H; 151: #define HAVE_CONFIG_H 1; 151: #endif; 151:; 151: #define _BACKWARD_BACKWARD_WARNING_H; 151: #include ""TUnuran.h""; 151: #include ""TUnuranBaseDist.h""; 151: #include ""TUnuranContDist.h""; 151: #include ""TUnuranDiscrDist.h""; 151: #include ""TUnuranEmpDist.h""; 151: #include ""TUnuranMultiContDist.h""; 151: #include ""TUnuranSampler.h""; 151:; 151: #undef _BACKWARD_BACKWARD_WARNING_H; 151:; 151: CMake Error at C:/Users/sftnight/git/master/cmake/modules/RootTestDriver.cmake:232 (message):; 151: error code: 1; 151:; 151:; 2/2 Test #151: test-stresshistofit-interpreted ...***Failed Error regular expression found in output. Regex=[FAILED|Error in] 10.55 sec",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3312
https://github.com/root-project/root/pull/3312:4088,Availability,error,error,4088," in <TInterpreter::AutoParse>: Error parsing payload code for class TUnuranContDist with content:; 151:; 151: #line 1 ""libUnuran dictionary payload""; 151:; 151: #ifndef HAVE_CONFIG_H; 151: #define HAVE_CONFIG_H 1; 151: #endif; 151:; 151: #define _BACKWARD_BACKWARD_WARNING_H; 151: #include ""TUnuran.h""; 151: #include ""TUnuranBaseDist.h""; 151: #include ""TUnuranContDist.h""; 151: #include ""TUnuranDiscrDist.h""; 151: #include ""TUnuranEmpDist.h""; 151: #include ""TUnuranMultiContDist.h""; 151: #include ""TUnuranSampler.h""; 151:; 151: #undef _BACKWARD_BACKWARD_WARNING_H; 151:; 151: Error in <TInterpreter::AutoParse>: Error parsing payload code for class TUnuranDiscrDist with content:; 151:; 151: #line 1 ""libUnuran dictionary payload""; 151:; 151: #ifndef HAVE_CONFIG_H; 151: #define HAVE_CONFIG_H 1; 151: #endif; 151:; 151: #define _BACKWARD_BACKWARD_WARNING_H; 151: #include ""TUnuran.h""; 151: #include ""TUnuranBaseDist.h""; 151: #include ""TUnuranContDist.h""; 151: #include ""TUnuranDiscrDist.h""; 151: #include ""TUnuranEmpDist.h""; 151: #include ""TUnuranMultiContDist.h""; 151: #include ""TUnuranSampler.h""; 151:; 151: #undef _BACKWARD_BACKWARD_WARNING_H; 151:; 151: Error in <TInterpreter::AutoParse>: Error parsing payload code for class TUnuranEmpDist with content:; 151:; 151: #line 1 ""libUnuran dictionary payload""; 151:; 151: #ifndef HAVE_CONFIG_H; 151: #define HAVE_CONFIG_H 1; 151: #endif; 151:; 151: #define _BACKWARD_BACKWARD_WARNING_H; 151: #include ""TUnuran.h""; 151: #include ""TUnuranBaseDist.h""; 151: #include ""TUnuranContDist.h""; 151: #include ""TUnuranDiscrDist.h""; 151: #include ""TUnuranEmpDist.h""; 151: #include ""TUnuranMultiContDist.h""; 151: #include ""TUnuranSampler.h""; 151:; 151: #undef _BACKWARD_BACKWARD_WARNING_H; 151:; 151: CMake Error at C:/Users/sftnight/git/master/cmake/modules/RootTestDriver.cmake:232 (message):; 151: error code: 1; 151:; 151:; 2/2 Test #151: test-stresshistofit-interpreted ...***Failed Error regular expression found in output. Regex=[FAILED|Error in] 10.55 sec",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3312
https://github.com/root-project/root/pull/3312:4175,Availability,Error,Error,4175," in <TInterpreter::AutoParse>: Error parsing payload code for class TUnuranContDist with content:; 151:; 151: #line 1 ""libUnuran dictionary payload""; 151:; 151: #ifndef HAVE_CONFIG_H; 151: #define HAVE_CONFIG_H 1; 151: #endif; 151:; 151: #define _BACKWARD_BACKWARD_WARNING_H; 151: #include ""TUnuran.h""; 151: #include ""TUnuranBaseDist.h""; 151: #include ""TUnuranContDist.h""; 151: #include ""TUnuranDiscrDist.h""; 151: #include ""TUnuranEmpDist.h""; 151: #include ""TUnuranMultiContDist.h""; 151: #include ""TUnuranSampler.h""; 151:; 151: #undef _BACKWARD_BACKWARD_WARNING_H; 151:; 151: Error in <TInterpreter::AutoParse>: Error parsing payload code for class TUnuranDiscrDist with content:; 151:; 151: #line 1 ""libUnuran dictionary payload""; 151:; 151: #ifndef HAVE_CONFIG_H; 151: #define HAVE_CONFIG_H 1; 151: #endif; 151:; 151: #define _BACKWARD_BACKWARD_WARNING_H; 151: #include ""TUnuran.h""; 151: #include ""TUnuranBaseDist.h""; 151: #include ""TUnuranContDist.h""; 151: #include ""TUnuranDiscrDist.h""; 151: #include ""TUnuranEmpDist.h""; 151: #include ""TUnuranMultiContDist.h""; 151: #include ""TUnuranSampler.h""; 151:; 151: #undef _BACKWARD_BACKWARD_WARNING_H; 151:; 151: Error in <TInterpreter::AutoParse>: Error parsing payload code for class TUnuranEmpDist with content:; 151:; 151: #line 1 ""libUnuran dictionary payload""; 151:; 151: #ifndef HAVE_CONFIG_H; 151: #define HAVE_CONFIG_H 1; 151: #endif; 151:; 151: #define _BACKWARD_BACKWARD_WARNING_H; 151: #include ""TUnuran.h""; 151: #include ""TUnuranBaseDist.h""; 151: #include ""TUnuranContDist.h""; 151: #include ""TUnuranDiscrDist.h""; 151: #include ""TUnuranEmpDist.h""; 151: #include ""TUnuranMultiContDist.h""; 151: #include ""TUnuranSampler.h""; 151:; 151: #undef _BACKWARD_BACKWARD_WARNING_H; 151:; 151: CMake Error at C:/Users/sftnight/git/master/cmake/modules/RootTestDriver.cmake:232 (message):; 151: error code: 1; 151:; 151:; 2/2 Test #151: test-stresshistofit-interpreted ...***Failed Error regular expression found in output. Regex=[FAILED|Error in] 10.55 sec",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3312
https://github.com/root-project/root/pull/3312:4231,Availability,Error,Error,4231," in <TInterpreter::AutoParse>: Error parsing payload code for class TUnuranContDist with content:; 151:; 151: #line 1 ""libUnuran dictionary payload""; 151:; 151: #ifndef HAVE_CONFIG_H; 151: #define HAVE_CONFIG_H 1; 151: #endif; 151:; 151: #define _BACKWARD_BACKWARD_WARNING_H; 151: #include ""TUnuran.h""; 151: #include ""TUnuranBaseDist.h""; 151: #include ""TUnuranContDist.h""; 151: #include ""TUnuranDiscrDist.h""; 151: #include ""TUnuranEmpDist.h""; 151: #include ""TUnuranMultiContDist.h""; 151: #include ""TUnuranSampler.h""; 151:; 151: #undef _BACKWARD_BACKWARD_WARNING_H; 151:; 151: Error in <TInterpreter::AutoParse>: Error parsing payload code for class TUnuranDiscrDist with content:; 151:; 151: #line 1 ""libUnuran dictionary payload""; 151:; 151: #ifndef HAVE_CONFIG_H; 151: #define HAVE_CONFIG_H 1; 151: #endif; 151:; 151: #define _BACKWARD_BACKWARD_WARNING_H; 151: #include ""TUnuran.h""; 151: #include ""TUnuranBaseDist.h""; 151: #include ""TUnuranContDist.h""; 151: #include ""TUnuranDiscrDist.h""; 151: #include ""TUnuranEmpDist.h""; 151: #include ""TUnuranMultiContDist.h""; 151: #include ""TUnuranSampler.h""; 151:; 151: #undef _BACKWARD_BACKWARD_WARNING_H; 151:; 151: Error in <TInterpreter::AutoParse>: Error parsing payload code for class TUnuranEmpDist with content:; 151:; 151: #line 1 ""libUnuran dictionary payload""; 151:; 151: #ifndef HAVE_CONFIG_H; 151: #define HAVE_CONFIG_H 1; 151: #endif; 151:; 151: #define _BACKWARD_BACKWARD_WARNING_H; 151: #include ""TUnuran.h""; 151: #include ""TUnuranBaseDist.h""; 151: #include ""TUnuranContDist.h""; 151: #include ""TUnuranDiscrDist.h""; 151: #include ""TUnuranEmpDist.h""; 151: #include ""TUnuranMultiContDist.h""; 151: #include ""TUnuranSampler.h""; 151:; 151: #undef _BACKWARD_BACKWARD_WARNING_H; 151:; 151: CMake Error at C:/Users/sftnight/git/master/cmake/modules/RootTestDriver.cmake:232 (message):; 151: error code: 1; 151:; 151:; 2/2 Test #151: test-stresshistofit-interpreted ...***Failed Error regular expression found in output. Regex=[FAILED|Error in] 10.55 sec",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3312
https://github.com/root-project/root/pull/3312:962,Energy Efficiency,green,green,962,This fixes the following failure of the test-stresshistofit-interpreted test:. 151: Processing C:/Users/sftnight/git/master/test/stressHistoFit.cxx...; 151: In file included from input_line_10:1:; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:117:9: warning: 'FOREGROUND_BLUE' macro redefined [-Wmacro-redefined]; 151: #define FOREGROUND_BLUE 1; 151: ^; 151: C:\Program Files (x86)\Windows Kits\10\Include\10.0.17134.0\um\consoleapi2.h:35:9: note: previous definition is here; 151: #define FOREGROUND_BLUE 0x0001 // text color contains blue.; 151: ^; 151: In file included from input_line_10:1:; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:118:9: warning: 'FOREGROUND_GREEN' macro redefined [-Wmacro-redefined]; 151: #define FOREGROUND_GREEN 2; 151: ^; 151: C:\Program Files (x86)\Windows Kits\10\Include\10.0.17134.0\um\consoleapi2.h:36:9: note: previous definition is here; 151: #define FOREGROUND_GREEN 0x0002 // text color contains green.; 151: ^; 151: In file included from input_line_10:1:; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:119:9: warning: 'FOREGROUND_RED' macro redefined [-Wmacro-redefined]; 151: #define FOREGROUND_RED 4; 151: ^; 151: C:\Program Files (x86)\Windows Kits\10\Include\10.0.17134.0\um\consoleapi2.h:37:9: note: previous definition is here; 151: #define FOREGROUND_RED 0x0004 // text color contains red.; 151: ^; 151: In file included from input_line_10:1:; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:120:9: warning: 'FOREGROUND_INTENSITY' macro redefined [-Wmacro-redefined]; 151: #define FOREGROUND_INTENSITY 8; 151: ^; 151: C:\Program Files (x86)\Windows Kits\10\Include\10.0.17134.0\um\consoleapi2.h:38:9: note: previous definition is here; 151: #define FOREGROUND_INTENSITY 0x0008 // text color is intensified.; 151: ^; 151: In file included from input_line_10:1:; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:124:19: error: functions that differ only in their return type cannot be overloaded; 1,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3312
https://github.com/root-project/root/pull/3312:4072,Integrability,message,message,4072," in <TInterpreter::AutoParse>: Error parsing payload code for class TUnuranContDist with content:; 151:; 151: #line 1 ""libUnuran dictionary payload""; 151:; 151: #ifndef HAVE_CONFIG_H; 151: #define HAVE_CONFIG_H 1; 151: #endif; 151:; 151: #define _BACKWARD_BACKWARD_WARNING_H; 151: #include ""TUnuran.h""; 151: #include ""TUnuranBaseDist.h""; 151: #include ""TUnuranContDist.h""; 151: #include ""TUnuranDiscrDist.h""; 151: #include ""TUnuranEmpDist.h""; 151: #include ""TUnuranMultiContDist.h""; 151: #include ""TUnuranSampler.h""; 151:; 151: #undef _BACKWARD_BACKWARD_WARNING_H; 151:; 151: Error in <TInterpreter::AutoParse>: Error parsing payload code for class TUnuranDiscrDist with content:; 151:; 151: #line 1 ""libUnuran dictionary payload""; 151:; 151: #ifndef HAVE_CONFIG_H; 151: #define HAVE_CONFIG_H 1; 151: #endif; 151:; 151: #define _BACKWARD_BACKWARD_WARNING_H; 151: #include ""TUnuran.h""; 151: #include ""TUnuranBaseDist.h""; 151: #include ""TUnuranContDist.h""; 151: #include ""TUnuranDiscrDist.h""; 151: #include ""TUnuranEmpDist.h""; 151: #include ""TUnuranMultiContDist.h""; 151: #include ""TUnuranSampler.h""; 151:; 151: #undef _BACKWARD_BACKWARD_WARNING_H; 151:; 151: Error in <TInterpreter::AutoParse>: Error parsing payload code for class TUnuranEmpDist with content:; 151:; 151: #line 1 ""libUnuran dictionary payload""; 151:; 151: #ifndef HAVE_CONFIG_H; 151: #define HAVE_CONFIG_H 1; 151: #endif; 151:; 151: #define _BACKWARD_BACKWARD_WARNING_H; 151: #include ""TUnuran.h""; 151: #include ""TUnuranBaseDist.h""; 151: #include ""TUnuranContDist.h""; 151: #include ""TUnuranDiscrDist.h""; 151: #include ""TUnuranEmpDist.h""; 151: #include ""TUnuranMultiContDist.h""; 151: #include ""TUnuranSampler.h""; 151:; 151: #undef _BACKWARD_BACKWARD_WARNING_H; 151:; 151: CMake Error at C:/Users/sftnight/git/master/cmake/modules/RootTestDriver.cmake:232 (message):; 151: error code: 1; 151:; 151:; 2/2 Test #151: test-stresshistofit-interpreted ...***Failed Error regular expression found in output. Regex=[FAILED|Error in] 10.55 sec",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3312
https://github.com/root-project/root/pull/3312:40,Testability,test,test-stresshistofit-interpreted,40,This fixes the following failure of the test-stresshistofit-interpreted test:. 151: Processing C:/Users/sftnight/git/master/test/stressHistoFit.cxx...; 151: In file included from input_line_10:1:; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:117:9: warning: 'FOREGROUND_BLUE' macro redefined [-Wmacro-redefined]; 151: #define FOREGROUND_BLUE 1; 151: ^; 151: C:\Program Files (x86)\Windows Kits\10\Include\10.0.17134.0\um\consoleapi2.h:35:9: note: previous definition is here; 151: #define FOREGROUND_BLUE 0x0001 // text color contains blue.; 151: ^; 151: In file included from input_line_10:1:; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:118:9: warning: 'FOREGROUND_GREEN' macro redefined [-Wmacro-redefined]; 151: #define FOREGROUND_GREEN 2; 151: ^; 151: C:\Program Files (x86)\Windows Kits\10\Include\10.0.17134.0\um\consoleapi2.h:36:9: note: previous definition is here; 151: #define FOREGROUND_GREEN 0x0002 // text color contains green.; 151: ^; 151: In file included from input_line_10:1:; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:119:9: warning: 'FOREGROUND_RED' macro redefined [-Wmacro-redefined]; 151: #define FOREGROUND_RED 4; 151: ^; 151: C:\Program Files (x86)\Windows Kits\10\Include\10.0.17134.0\um\consoleapi2.h:37:9: note: previous definition is here; 151: #define FOREGROUND_RED 0x0004 // text color contains red.; 151: ^; 151: In file included from input_line_10:1:; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:120:9: warning: 'FOREGROUND_INTENSITY' macro redefined [-Wmacro-redefined]; 151: #define FOREGROUND_INTENSITY 8; 151: ^; 151: C:\Program Files (x86)\Windows Kits\10\Include\10.0.17134.0\um\consoleapi2.h:38:9: note: previous definition is here; 151: #define FOREGROUND_INTENSITY 0x0008 // text color is intensified.; 151: ^; 151: In file included from input_line_10:1:; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:124:19: error: functions that differ only in their return type cannot be overloaded; 1,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3312
https://github.com/root-project/root/pull/3312:72,Testability,test,test,72,This fixes the following failure of the test-stresshistofit-interpreted test:. 151: Processing C:/Users/sftnight/git/master/test/stressHistoFit.cxx...; 151: In file included from input_line_10:1:; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:117:9: warning: 'FOREGROUND_BLUE' macro redefined [-Wmacro-redefined]; 151: #define FOREGROUND_BLUE 1; 151: ^; 151: C:\Program Files (x86)\Windows Kits\10\Include\10.0.17134.0\um\consoleapi2.h:35:9: note: previous definition is here; 151: #define FOREGROUND_BLUE 0x0001 // text color contains blue.; 151: ^; 151: In file included from input_line_10:1:; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:118:9: warning: 'FOREGROUND_GREEN' macro redefined [-Wmacro-redefined]; 151: #define FOREGROUND_GREEN 2; 151: ^; 151: C:\Program Files (x86)\Windows Kits\10\Include\10.0.17134.0\um\consoleapi2.h:36:9: note: previous definition is here; 151: #define FOREGROUND_GREEN 0x0002 // text color contains green.; 151: ^; 151: In file included from input_line_10:1:; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:119:9: warning: 'FOREGROUND_RED' macro redefined [-Wmacro-redefined]; 151: #define FOREGROUND_RED 4; 151: ^; 151: C:\Program Files (x86)\Windows Kits\10\Include\10.0.17134.0\um\consoleapi2.h:37:9: note: previous definition is here; 151: #define FOREGROUND_RED 0x0004 // text color contains red.; 151: ^; 151: In file included from input_line_10:1:; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:120:9: warning: 'FOREGROUND_INTENSITY' macro redefined [-Wmacro-redefined]; 151: #define FOREGROUND_INTENSITY 8; 151: ^; 151: C:\Program Files (x86)\Windows Kits\10\Include\10.0.17134.0\um\consoleapi2.h:38:9: note: previous definition is here; 151: #define FOREGROUND_INTENSITY 0x0008 // text color is intensified.; 151: ^; 151: In file included from input_line_10:1:; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:124:19: error: functions that differ only in their return type cannot be overloaded; 1,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3312
https://github.com/root-project/root/pull/3312:124,Testability,test,test,124,This fixes the following failure of the test-stresshistofit-interpreted test:. 151: Processing C:/Users/sftnight/git/master/test/stressHistoFit.cxx...; 151: In file included from input_line_10:1:; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:117:9: warning: 'FOREGROUND_BLUE' macro redefined [-Wmacro-redefined]; 151: #define FOREGROUND_BLUE 1; 151: ^; 151: C:\Program Files (x86)\Windows Kits\10\Include\10.0.17134.0\um\consoleapi2.h:35:9: note: previous definition is here; 151: #define FOREGROUND_BLUE 0x0001 // text color contains blue.; 151: ^; 151: In file included from input_line_10:1:; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:118:9: warning: 'FOREGROUND_GREEN' macro redefined [-Wmacro-redefined]; 151: #define FOREGROUND_GREEN 2; 151: ^; 151: C:\Program Files (x86)\Windows Kits\10\Include\10.0.17134.0\um\consoleapi2.h:36:9: note: previous definition is here; 151: #define FOREGROUND_GREEN 0x0002 // text color contains green.; 151: ^; 151: In file included from input_line_10:1:; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:119:9: warning: 'FOREGROUND_RED' macro redefined [-Wmacro-redefined]; 151: #define FOREGROUND_RED 4; 151: ^; 151: C:\Program Files (x86)\Windows Kits\10\Include\10.0.17134.0\um\consoleapi2.h:37:9: note: previous definition is here; 151: #define FOREGROUND_RED 0x0004 // text color contains red.; 151: ^; 151: In file included from input_line_10:1:; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:120:9: warning: 'FOREGROUND_INTENSITY' macro redefined [-Wmacro-redefined]; 151: #define FOREGROUND_INTENSITY 8; 151: ^; 151: C:\Program Files (x86)\Windows Kits\10\Include\10.0.17134.0\um\consoleapi2.h:38:9: note: previous definition is here; 151: #define FOREGROUND_INTENSITY 0x0008 // text color is intensified.; 151: ^; 151: In file included from input_line_10:1:; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:124:19: error: functions that differ only in their return type cannot be overloaded; 1,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3312
https://github.com/root-project/root/pull/3312:231,Testability,test,test,231,This fixes the following failure of the test-stresshistofit-interpreted test:. 151: Processing C:/Users/sftnight/git/master/test/stressHistoFit.cxx...; 151: In file included from input_line_10:1:; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:117:9: warning: 'FOREGROUND_BLUE' macro redefined [-Wmacro-redefined]; 151: #define FOREGROUND_BLUE 1; 151: ^; 151: C:\Program Files (x86)\Windows Kits\10\Include\10.0.17134.0\um\consoleapi2.h:35:9: note: previous definition is here; 151: #define FOREGROUND_BLUE 0x0001 // text color contains blue.; 151: ^; 151: In file included from input_line_10:1:; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:118:9: warning: 'FOREGROUND_GREEN' macro redefined [-Wmacro-redefined]; 151: #define FOREGROUND_GREEN 2; 151: ^; 151: C:\Program Files (x86)\Windows Kits\10\Include\10.0.17134.0\um\consoleapi2.h:36:9: note: previous definition is here; 151: #define FOREGROUND_GREEN 0x0002 // text color contains green.; 151: ^; 151: In file included from input_line_10:1:; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:119:9: warning: 'FOREGROUND_RED' macro redefined [-Wmacro-redefined]; 151: #define FOREGROUND_RED 4; 151: ^; 151: C:\Program Files (x86)\Windows Kits\10\Include\10.0.17134.0\um\consoleapi2.h:37:9: note: previous definition is here; 151: #define FOREGROUND_RED 0x0004 // text color contains red.; 151: ^; 151: In file included from input_line_10:1:; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:120:9: warning: 'FOREGROUND_INTENSITY' macro redefined [-Wmacro-redefined]; 151: #define FOREGROUND_INTENSITY 8; 151: ^; 151: C:\Program Files (x86)\Windows Kits\10\Include\10.0.17134.0\um\consoleapi2.h:38:9: note: previous definition is here; 151: #define FOREGROUND_INTENSITY 0x0008 // text color is intensified.; 151: ^; 151: In file included from input_line_10:1:; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:124:19: error: functions that differ only in their return type cannot be overloaded; 1,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3312
https://github.com/root-project/root/pull/3312:642,Testability,test,test,642,This fixes the following failure of the test-stresshistofit-interpreted test:. 151: Processing C:/Users/sftnight/git/master/test/stressHistoFit.cxx...; 151: In file included from input_line_10:1:; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:117:9: warning: 'FOREGROUND_BLUE' macro redefined [-Wmacro-redefined]; 151: #define FOREGROUND_BLUE 1; 151: ^; 151: C:\Program Files (x86)\Windows Kits\10\Include\10.0.17134.0\um\consoleapi2.h:35:9: note: previous definition is here; 151: #define FOREGROUND_BLUE 0x0001 // text color contains blue.; 151: ^; 151: In file included from input_line_10:1:; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:118:9: warning: 'FOREGROUND_GREEN' macro redefined [-Wmacro-redefined]; 151: #define FOREGROUND_GREEN 2; 151: ^; 151: C:\Program Files (x86)\Windows Kits\10\Include\10.0.17134.0\um\consoleapi2.h:36:9: note: previous definition is here; 151: #define FOREGROUND_GREEN 0x0002 // text color contains green.; 151: ^; 151: In file included from input_line_10:1:; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:119:9: warning: 'FOREGROUND_RED' macro redefined [-Wmacro-redefined]; 151: #define FOREGROUND_RED 4; 151: ^; 151: C:\Program Files (x86)\Windows Kits\10\Include\10.0.17134.0\um\consoleapi2.h:37:9: note: previous definition is here; 151: #define FOREGROUND_RED 0x0004 // text color contains red.; 151: ^; 151: In file included from input_line_10:1:; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:120:9: warning: 'FOREGROUND_INTENSITY' macro redefined [-Wmacro-redefined]; 151: #define FOREGROUND_INTENSITY 8; 151: ^; 151: C:\Program Files (x86)\Windows Kits\10\Include\10.0.17134.0\um\consoleapi2.h:38:9: note: previous definition is here; 151: #define FOREGROUND_INTENSITY 0x0008 // text color is intensified.; 151: ^; 151: In file included from input_line_10:1:; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:124:19: error: functions that differ only in their return type cannot be overloaded; 1,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3312
https://github.com/root-project/root/pull/3312:1057,Testability,test,test,1057,ng failure of the test-stresshistofit-interpreted test:. 151: Processing C:/Users/sftnight/git/master/test/stressHistoFit.cxx...; 151: In file included from input_line_10:1:; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:117:9: warning: 'FOREGROUND_BLUE' macro redefined [-Wmacro-redefined]; 151: #define FOREGROUND_BLUE 1; 151: ^; 151: C:\Program Files (x86)\Windows Kits\10\Include\10.0.17134.0\um\consoleapi2.h:35:9: note: previous definition is here; 151: #define FOREGROUND_BLUE 0x0001 // text color contains blue.; 151: ^; 151: In file included from input_line_10:1:; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:118:9: warning: 'FOREGROUND_GREEN' macro redefined [-Wmacro-redefined]; 151: #define FOREGROUND_GREEN 2; 151: ^; 151: C:\Program Files (x86)\Windows Kits\10\Include\10.0.17134.0\um\consoleapi2.h:36:9: note: previous definition is here; 151: #define FOREGROUND_GREEN 0x0002 // text color contains green.; 151: ^; 151: In file included from input_line_10:1:; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:119:9: warning: 'FOREGROUND_RED' macro redefined [-Wmacro-redefined]; 151: #define FOREGROUND_RED 4; 151: ^; 151: C:\Program Files (x86)\Windows Kits\10\Include\10.0.17134.0\um\consoleapi2.h:37:9: note: previous definition is here; 151: #define FOREGROUND_RED 0x0004 // text color contains red.; 151: ^; 151: In file included from input_line_10:1:; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:120:9: warning: 'FOREGROUND_INTENSITY' macro redefined [-Wmacro-redefined]; 151: #define FOREGROUND_INTENSITY 8; 151: ^; 151: C:\Program Files (x86)\Windows Kits\10\Include\10.0.17134.0\um\consoleapi2.h:38:9: note: previous definition is here; 151: #define FOREGROUND_INTENSITY 0x0008 // text color is intensified.; 151: ^; 151: In file included from input_line_10:1:; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:124:19: error: functions that differ only in their return type cannot be overloaded; 151: bool __stdcall Set,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3312
https://github.com/root-project/root/pull/3312:1464,Testability,test,test,1464,"0\um\consoleapi2.h:35:9: note: previous definition is here; 151: #define FOREGROUND_BLUE 0x0001 // text color contains blue.; 151: ^; 151: In file included from input_line_10:1:; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:118:9: warning: 'FOREGROUND_GREEN' macro redefined [-Wmacro-redefined]; 151: #define FOREGROUND_GREEN 2; 151: ^; 151: C:\Program Files (x86)\Windows Kits\10\Include\10.0.17134.0\um\consoleapi2.h:36:9: note: previous definition is here; 151: #define FOREGROUND_GREEN 0x0002 // text color contains green.; 151: ^; 151: In file included from input_line_10:1:; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:119:9: warning: 'FOREGROUND_RED' macro redefined [-Wmacro-redefined]; 151: #define FOREGROUND_RED 4; 151: ^; 151: C:\Program Files (x86)\Windows Kits\10\Include\10.0.17134.0\um\consoleapi2.h:37:9: note: previous definition is here; 151: #define FOREGROUND_RED 0x0004 // text color contains red.; 151: ^; 151: In file included from input_line_10:1:; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:120:9: warning: 'FOREGROUND_INTENSITY' macro redefined [-Wmacro-redefined]; 151: #define FOREGROUND_INTENSITY 8; 151: ^; 151: C:\Program Files (x86)\Windows Kits\10\Include\10.0.17134.0\um\consoleapi2.h:38:9: note: previous definition is here; 151: #define FOREGROUND_INTENSITY 0x0008 // text color is intensified.; 151: ^; 151: In file included from input_line_10:1:; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:124:19: error: functions that differ only in their return type cannot be overloaded; 151: bool __stdcall SetConsoleTextAttribute(void *, unsigned int);; 151: ^; 151: C:\Program Files (x86)\Windows Kits\10\Include\10.0.17134.0\um\consoleapi2.h:245:1: note: previous declaration is here; 151: SetConsoleTextAttribute(; 151: ^; 151: Error in <TInterpreter::AutoParse>: Error parsing payload code for class TUnuranContDist with content:; 151:; 151: #line 1 ""libUnuran dictionary payload""; 151:; 151: #ifndef HAVE_CONFIG",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3312
https://github.com/root-project/root/pull/3312:1891,Testability,test,test,1891,"i2.h:36:9: note: previous definition is here; 151: #define FOREGROUND_GREEN 0x0002 // text color contains green.; 151: ^; 151: In file included from input_line_10:1:; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:119:9: warning: 'FOREGROUND_RED' macro redefined [-Wmacro-redefined]; 151: #define FOREGROUND_RED 4; 151: ^; 151: C:\Program Files (x86)\Windows Kits\10\Include\10.0.17134.0\um\consoleapi2.h:37:9: note: previous definition is here; 151: #define FOREGROUND_RED 0x0004 // text color contains red.; 151: ^; 151: In file included from input_line_10:1:; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:120:9: warning: 'FOREGROUND_INTENSITY' macro redefined [-Wmacro-redefined]; 151: #define FOREGROUND_INTENSITY 8; 151: ^; 151: C:\Program Files (x86)\Windows Kits\10\Include\10.0.17134.0\um\consoleapi2.h:38:9: note: previous definition is here; 151: #define FOREGROUND_INTENSITY 0x0008 // text color is intensified.; 151: ^; 151: In file included from input_line_10:1:; 151: C:\Users\sftnight\git\master\test\stressHistoFit.cxx:124:19: error: functions that differ only in their return type cannot be overloaded; 151: bool __stdcall SetConsoleTextAttribute(void *, unsigned int);; 151: ^; 151: C:\Program Files (x86)\Windows Kits\10\Include\10.0.17134.0\um\consoleapi2.h:245:1: note: previous declaration is here; 151: SetConsoleTextAttribute(; 151: ^; 151: Error in <TInterpreter::AutoParse>: Error parsing payload code for class TUnuranContDist with content:; 151:; 151: #line 1 ""libUnuran dictionary payload""; 151:; 151: #ifndef HAVE_CONFIG_H; 151: #define HAVE_CONFIG_H 1; 151: #endif; 151:; 151: #define _BACKWARD_BACKWARD_WARNING_H; 151: #include ""TUnuran.h""; 151: #include ""TUnuranBaseDist.h""; 151: #include ""TUnuranContDist.h""; 151: #include ""TUnuranDiscrDist.h""; 151: #include ""TUnuranEmpDist.h""; 151: #include ""TUnuranMultiContDist.h""; 151: #include ""TUnuranSampler.h""; 151:; 151: #undef _BACKWARD_BACKWARD_WARNING_H; 151:; 151: Error in <TInterpreter::AutoPar",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3312
https://github.com/root-project/root/pull/3312:4119,Testability,Test,Test,4119," in <TInterpreter::AutoParse>: Error parsing payload code for class TUnuranContDist with content:; 151:; 151: #line 1 ""libUnuran dictionary payload""; 151:; 151: #ifndef HAVE_CONFIG_H; 151: #define HAVE_CONFIG_H 1; 151: #endif; 151:; 151: #define _BACKWARD_BACKWARD_WARNING_H; 151: #include ""TUnuran.h""; 151: #include ""TUnuranBaseDist.h""; 151: #include ""TUnuranContDist.h""; 151: #include ""TUnuranDiscrDist.h""; 151: #include ""TUnuranEmpDist.h""; 151: #include ""TUnuranMultiContDist.h""; 151: #include ""TUnuranSampler.h""; 151:; 151: #undef _BACKWARD_BACKWARD_WARNING_H; 151:; 151: Error in <TInterpreter::AutoParse>: Error parsing payload code for class TUnuranDiscrDist with content:; 151:; 151: #line 1 ""libUnuran dictionary payload""; 151:; 151: #ifndef HAVE_CONFIG_H; 151: #define HAVE_CONFIG_H 1; 151: #endif; 151:; 151: #define _BACKWARD_BACKWARD_WARNING_H; 151: #include ""TUnuran.h""; 151: #include ""TUnuranBaseDist.h""; 151: #include ""TUnuranContDist.h""; 151: #include ""TUnuranDiscrDist.h""; 151: #include ""TUnuranEmpDist.h""; 151: #include ""TUnuranMultiContDist.h""; 151: #include ""TUnuranSampler.h""; 151:; 151: #undef _BACKWARD_BACKWARD_WARNING_H; 151:; 151: Error in <TInterpreter::AutoParse>: Error parsing payload code for class TUnuranEmpDist with content:; 151:; 151: #line 1 ""libUnuran dictionary payload""; 151:; 151: #ifndef HAVE_CONFIG_H; 151: #define HAVE_CONFIG_H 1; 151: #endif; 151:; 151: #define _BACKWARD_BACKWARD_WARNING_H; 151: #include ""TUnuran.h""; 151: #include ""TUnuranBaseDist.h""; 151: #include ""TUnuranContDist.h""; 151: #include ""TUnuranDiscrDist.h""; 151: #include ""TUnuranEmpDist.h""; 151: #include ""TUnuranMultiContDist.h""; 151: #include ""TUnuranSampler.h""; 151:; 151: #undef _BACKWARD_BACKWARD_WARNING_H; 151:; 151: CMake Error at C:/Users/sftnight/git/master/cmake/modules/RootTestDriver.cmake:232 (message):; 151: error code: 1; 151:; 151:; 2/2 Test #151: test-stresshistofit-interpreted ...***Failed Error regular expression found in output. Regex=[FAILED|Error in] 10.55 sec",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3312
https://github.com/root-project/root/pull/3312:4130,Testability,test,test-stresshistofit-interpreted,4130," in <TInterpreter::AutoParse>: Error parsing payload code for class TUnuranContDist with content:; 151:; 151: #line 1 ""libUnuran dictionary payload""; 151:; 151: #ifndef HAVE_CONFIG_H; 151: #define HAVE_CONFIG_H 1; 151: #endif; 151:; 151: #define _BACKWARD_BACKWARD_WARNING_H; 151: #include ""TUnuran.h""; 151: #include ""TUnuranBaseDist.h""; 151: #include ""TUnuranContDist.h""; 151: #include ""TUnuranDiscrDist.h""; 151: #include ""TUnuranEmpDist.h""; 151: #include ""TUnuranMultiContDist.h""; 151: #include ""TUnuranSampler.h""; 151:; 151: #undef _BACKWARD_BACKWARD_WARNING_H; 151:; 151: Error in <TInterpreter::AutoParse>: Error parsing payload code for class TUnuranDiscrDist with content:; 151:; 151: #line 1 ""libUnuran dictionary payload""; 151:; 151: #ifndef HAVE_CONFIG_H; 151: #define HAVE_CONFIG_H 1; 151: #endif; 151:; 151: #define _BACKWARD_BACKWARD_WARNING_H; 151: #include ""TUnuran.h""; 151: #include ""TUnuranBaseDist.h""; 151: #include ""TUnuranContDist.h""; 151: #include ""TUnuranDiscrDist.h""; 151: #include ""TUnuranEmpDist.h""; 151: #include ""TUnuranMultiContDist.h""; 151: #include ""TUnuranSampler.h""; 151:; 151: #undef _BACKWARD_BACKWARD_WARNING_H; 151:; 151: Error in <TInterpreter::AutoParse>: Error parsing payload code for class TUnuranEmpDist with content:; 151:; 151: #line 1 ""libUnuran dictionary payload""; 151:; 151: #ifndef HAVE_CONFIG_H; 151: #define HAVE_CONFIG_H 1; 151: #endif; 151:; 151: #define _BACKWARD_BACKWARD_WARNING_H; 151: #include ""TUnuran.h""; 151: #include ""TUnuranBaseDist.h""; 151: #include ""TUnuranContDist.h""; 151: #include ""TUnuranDiscrDist.h""; 151: #include ""TUnuranEmpDist.h""; 151: #include ""TUnuranMultiContDist.h""; 151: #include ""TUnuranSampler.h""; 151:; 151: #undef _BACKWARD_BACKWARD_WARNING_H; 151:; 151: CMake Error at C:/Users/sftnight/git/master/cmake/modules/RootTestDriver.cmake:232 (message):; 151: error code: 1; 151:; 151:; 2/2 Test #151: test-stresshistofit-interpreted ...***Failed Error regular expression found in output. Regex=[FAILED|Error in] 10.55 sec",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3312
https://github.com/root-project/root/pull/3319:83,Energy Efficiency,reduce,reduces,83,The DataLoader had a number of extraneous includes and friends. Removing them also reduces compilation time!,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3319
https://github.com/root-project/root/pull/3321:102,Integrability,interface,interface,102,"The purpose of this PR is to support discussion about the following proposal for a modern application interface for TMVA. See below the tutorial, which showcases the interface implemented in this PR as proof-of-concept. ```cpp; void train(const std::string& filename) {; // optimized out; }. void tmva003_RLegacyReader(); {; // First, let's train a model with TMVA.; const std::string filename = ""http://root.cern.ch/files/tmva_class_example.root"";; train(filename);. // Next, we load the model from the TMVA XML file.; RLegacyReader model(""TMVAClassification/weights/TMVAClassification_BDT.weights.xml"");. // In case you need a reminder of the names and order of the variables during; // training, you can ask the model for it.; auto variables = model.GetVariableNames();; std::cout << ""\nVariable names used during training: "" << variables << ""\n\n"";. // The model can now be applied in different scenarios:; // 1) Event-by-event inference; // 2) Batch inference on data of multiple events; // 3) Model inference as part of an RDataFrame graph. // 1) Event-by-event inference; // The event-by-event inference takes the values of the variables as a std::vector<float>.; // Note that the return value is as well a std::vector<float> since the reader; // is also capable to process models with multiple outputs.; auto prediction = model.Predict({0.5, 1.0, -0.2, 1.5});; std::cout << ""Single-event inference: "" << prediction << ""\n\n"";. // 2) Batch inference on data of multiple events; // For batch inference, the data needs to be structured as a matrix. For this; // purpose, TMVA makes use of the RTensor class. For convenience, we use RDataFrame; // and the AsTensor utility to make the read-out from the ROOT file.; ROOT::RDataFrame df(""TreeS"", filename);; auto df2 = df.Range(3); // Read only 10 events; auto x = AsTensor<float>(df2, variables);; std::cout << ""RTensor input for inference on data of multiple events:\n"" << x << ""\n\n"";. auto y = model.Predict(x);; std::cout << ""Prediction perform",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3321
https://github.com/root-project/root/pull/3321:166,Integrability,interface,interface,166,"The purpose of this PR is to support discussion about the following proposal for a modern application interface for TMVA. See below the tutorial, which showcases the interface implemented in this PR as proof-of-concept. ```cpp; void train(const std::string& filename) {; // optimized out; }. void tmva003_RLegacyReader(); {; // First, let's train a model with TMVA.; const std::string filename = ""http://root.cern.ch/files/tmva_class_example.root"";; train(filename);. // Next, we load the model from the TMVA XML file.; RLegacyReader model(""TMVAClassification/weights/TMVAClassification_BDT.weights.xml"");. // In case you need a reminder of the names and order of the variables during; // training, you can ask the model for it.; auto variables = model.GetVariableNames();; std::cout << ""\nVariable names used during training: "" << variables << ""\n\n"";. // The model can now be applied in different scenarios:; // 1) Event-by-event inference; // 2) Batch inference on data of multiple events; // 3) Model inference as part of an RDataFrame graph. // 1) Event-by-event inference; // The event-by-event inference takes the values of the variables as a std::vector<float>.; // Note that the return value is as well a std::vector<float> since the reader; // is also capable to process models with multiple outputs.; auto prediction = model.Predict({0.5, 1.0, -0.2, 1.5});; std::cout << ""Single-event inference: "" << prediction << ""\n\n"";. // 2) Batch inference on data of multiple events; // For batch inference, the data needs to be structured as a matrix. For this; // purpose, TMVA makes use of the RTensor class. For convenience, we use RDataFrame; // and the AsTensor utility to make the read-out from the ROOT file.; ROOT::RDataFrame df(""TreeS"", filename);; auto df2 = df.Range(3); // Read only 10 events; auto x = AsTensor<float>(df2, variables);; std::cout << ""RTensor input for inference on data of multiple events:\n"" << x << ""\n\n"";. auto y = model.Predict(x);; std::cout << ""Prediction perform",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3321
https://github.com/root-project/root/pull/3321:668,Modifiability,variab,variables,668,"The purpose of this PR is to support discussion about the following proposal for a modern application interface for TMVA. See below the tutorial, which showcases the interface implemented in this PR as proof-of-concept. ```cpp; void train(const std::string& filename) {; // optimized out; }. void tmva003_RLegacyReader(); {; // First, let's train a model with TMVA.; const std::string filename = ""http://root.cern.ch/files/tmva_class_example.root"";; train(filename);. // Next, we load the model from the TMVA XML file.; RLegacyReader model(""TMVAClassification/weights/TMVAClassification_BDT.weights.xml"");. // In case you need a reminder of the names and order of the variables during; // training, you can ask the model for it.; auto variables = model.GetVariableNames();; std::cout << ""\nVariable names used during training: "" << variables << ""\n\n"";. // The model can now be applied in different scenarios:; // 1) Event-by-event inference; // 2) Batch inference on data of multiple events; // 3) Model inference as part of an RDataFrame graph. // 1) Event-by-event inference; // The event-by-event inference takes the values of the variables as a std::vector<float>.; // Note that the return value is as well a std::vector<float> since the reader; // is also capable to process models with multiple outputs.; auto prediction = model.Predict({0.5, 1.0, -0.2, 1.5});; std::cout << ""Single-event inference: "" << prediction << ""\n\n"";. // 2) Batch inference on data of multiple events; // For batch inference, the data needs to be structured as a matrix. For this; // purpose, TMVA makes use of the RTensor class. For convenience, we use RDataFrame; // and the AsTensor utility to make the read-out from the ROOT file.; ROOT::RDataFrame df(""TreeS"", filename);; auto df2 = df.Range(3); // Read only 10 events; auto x = AsTensor<float>(df2, variables);; std::cout << ""RTensor input for inference on data of multiple events:\n"" << x << ""\n\n"";. auto y = model.Predict(x);; std::cout << ""Prediction perform",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3321
https://github.com/root-project/root/pull/3321:735,Modifiability,variab,variables,735,"The purpose of this PR is to support discussion about the following proposal for a modern application interface for TMVA. See below the tutorial, which showcases the interface implemented in this PR as proof-of-concept. ```cpp; void train(const std::string& filename) {; // optimized out; }. void tmva003_RLegacyReader(); {; // First, let's train a model with TMVA.; const std::string filename = ""http://root.cern.ch/files/tmva_class_example.root"";; train(filename);. // Next, we load the model from the TMVA XML file.; RLegacyReader model(""TMVAClassification/weights/TMVAClassification_BDT.weights.xml"");. // In case you need a reminder of the names and order of the variables during; // training, you can ask the model for it.; auto variables = model.GetVariableNames();; std::cout << ""\nVariable names used during training: "" << variables << ""\n\n"";. // The model can now be applied in different scenarios:; // 1) Event-by-event inference; // 2) Batch inference on data of multiple events; // 3) Model inference as part of an RDataFrame graph. // 1) Event-by-event inference; // The event-by-event inference takes the values of the variables as a std::vector<float>.; // Note that the return value is as well a std::vector<float> since the reader; // is also capable to process models with multiple outputs.; auto prediction = model.Predict({0.5, 1.0, -0.2, 1.5});; std::cout << ""Single-event inference: "" << prediction << ""\n\n"";. // 2) Batch inference on data of multiple events; // For batch inference, the data needs to be structured as a matrix. For this; // purpose, TMVA makes use of the RTensor class. For convenience, we use RDataFrame; // and the AsTensor utility to make the read-out from the ROOT file.; ROOT::RDataFrame df(""TreeS"", filename);; auto df2 = df.Range(3); // Read only 10 events; auto x = AsTensor<float>(df2, variables);; std::cout << ""RTensor input for inference on data of multiple events:\n"" << x << ""\n\n"";. auto y = model.Predict(x);; std::cout << ""Prediction perform",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3321
https://github.com/root-project/root/pull/3321:832,Modifiability,variab,variables,832,"The purpose of this PR is to support discussion about the following proposal for a modern application interface for TMVA. See below the tutorial, which showcases the interface implemented in this PR as proof-of-concept. ```cpp; void train(const std::string& filename) {; // optimized out; }. void tmva003_RLegacyReader(); {; // First, let's train a model with TMVA.; const std::string filename = ""http://root.cern.ch/files/tmva_class_example.root"";; train(filename);. // Next, we load the model from the TMVA XML file.; RLegacyReader model(""TMVAClassification/weights/TMVAClassification_BDT.weights.xml"");. // In case you need a reminder of the names and order of the variables during; // training, you can ask the model for it.; auto variables = model.GetVariableNames();; std::cout << ""\nVariable names used during training: "" << variables << ""\n\n"";. // The model can now be applied in different scenarios:; // 1) Event-by-event inference; // 2) Batch inference on data of multiple events; // 3) Model inference as part of an RDataFrame graph. // 1) Event-by-event inference; // The event-by-event inference takes the values of the variables as a std::vector<float>.; // Note that the return value is as well a std::vector<float> since the reader; // is also capable to process models with multiple outputs.; auto prediction = model.Predict({0.5, 1.0, -0.2, 1.5});; std::cout << ""Single-event inference: "" << prediction << ""\n\n"";. // 2) Batch inference on data of multiple events; // For batch inference, the data needs to be structured as a matrix. For this; // purpose, TMVA makes use of the RTensor class. For convenience, we use RDataFrame; // and the AsTensor utility to make the read-out from the ROOT file.; ROOT::RDataFrame df(""TreeS"", filename);; auto df2 = df.Range(3); // Read only 10 events; auto x = AsTensor<float>(df2, variables);; std::cout << ""RTensor input for inference on data of multiple events:\n"" << x << ""\n\n"";. auto y = model.Predict(x);; std::cout << ""Prediction perform",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3321
https://github.com/root-project/root/pull/3321:1135,Modifiability,variab,variables,1135,"face for TMVA. See below the tutorial, which showcases the interface implemented in this PR as proof-of-concept. ```cpp; void train(const std::string& filename) {; // optimized out; }. void tmva003_RLegacyReader(); {; // First, let's train a model with TMVA.; const std::string filename = ""http://root.cern.ch/files/tmva_class_example.root"";; train(filename);. // Next, we load the model from the TMVA XML file.; RLegacyReader model(""TMVAClassification/weights/TMVAClassification_BDT.weights.xml"");. // In case you need a reminder of the names and order of the variables during; // training, you can ask the model for it.; auto variables = model.GetVariableNames();; std::cout << ""\nVariable names used during training: "" << variables << ""\n\n"";. // The model can now be applied in different scenarios:; // 1) Event-by-event inference; // 2) Batch inference on data of multiple events; // 3) Model inference as part of an RDataFrame graph. // 1) Event-by-event inference; // The event-by-event inference takes the values of the variables as a std::vector<float>.; // Note that the return value is as well a std::vector<float> since the reader; // is also capable to process models with multiple outputs.; auto prediction = model.Predict({0.5, 1.0, -0.2, 1.5});; std::cout << ""Single-event inference: "" << prediction << ""\n\n"";. // 2) Batch inference on data of multiple events; // For batch inference, the data needs to be structured as a matrix. For this; // purpose, TMVA makes use of the RTensor class. For convenience, we use RDataFrame; // and the AsTensor utility to make the read-out from the ROOT file.; ROOT::RDataFrame df(""TreeS"", filename);; auto df2 = df.Range(3); // Read only 10 events; auto x = AsTensor<float>(df2, variables);; std::cout << ""RTensor input for inference on data of multiple events:\n"" << x << ""\n\n"";. auto y = model.Predict(x);; std::cout << ""Prediction performed on multiple events: "" << y << ""\n\n"";. // 3) Perform inference as part of an RDataFrame graph; // We wri",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3321
https://github.com/root-project/root/pull/3321:1838,Modifiability,variab,variables,1838,"\n"";. // The model can now be applied in different scenarios:; // 1) Event-by-event inference; // 2) Batch inference on data of multiple events; // 3) Model inference as part of an RDataFrame graph. // 1) Event-by-event inference; // The event-by-event inference takes the values of the variables as a std::vector<float>.; // Note that the return value is as well a std::vector<float> since the reader; // is also capable to process models with multiple outputs.; auto prediction = model.Predict({0.5, 1.0, -0.2, 1.5});; std::cout << ""Single-event inference: "" << prediction << ""\n\n"";. // 2) Batch inference on data of multiple events; // For batch inference, the data needs to be structured as a matrix. For this; // purpose, TMVA makes use of the RTensor class. For convenience, we use RDataFrame; // and the AsTensor utility to make the read-out from the ROOT file.; ROOT::RDataFrame df(""TreeS"", filename);; auto df2 = df.Range(3); // Read only 10 events; auto x = AsTensor<float>(df2, variables);; std::cout << ""RTensor input for inference on data of multiple events:\n"" << x << ""\n\n"";. auto y = model.Predict(x);; std::cout << ""Prediction performed on multiple events: "" << y << ""\n\n"";. // 3) Perform inference as part of an RDataFrame graph; // We write a small lambda function that performs for us the inference on; // a dataframe to omit code duplication.; auto make_histo = [&](const std::string &treename) {; ROOT::RDataFrame df(treename, filename);; auto df2 = df.Define(""y"", Predict<4, float>(model), variables);; return df2.Histo1D({"""", """", 30, -1, 1}, ""y"");; };. auto sig = make_histo(""TreeS"");; auto bkg = make_histo(""TreeB"");. gStyle->SetOptStat(0);; auto c = new TCanvas("""", """", 800, 800);; sig->SetLineColor(kRed);; bkg->SetLineColor(kBlue);; bkg->GetXaxis()->SetTitle(""Model response"");; bkg->Draw(""HIST"");; sig->Draw(""HIST SAME"");; c->SaveAs(""bdt_response.pdf"");; }; ```. ![x](https://user-images.githubusercontent.com/6951222/51740397-2f295f80-2094-11e9-8c29-b40bc618a4bc.png)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3321
https://github.com/root-project/root/pull/3321:2364,Modifiability,variab,variables,2364,"\n"";. // The model can now be applied in different scenarios:; // 1) Event-by-event inference; // 2) Batch inference on data of multiple events; // 3) Model inference as part of an RDataFrame graph. // 1) Event-by-event inference; // The event-by-event inference takes the values of the variables as a std::vector<float>.; // Note that the return value is as well a std::vector<float> since the reader; // is also capable to process models with multiple outputs.; auto prediction = model.Predict({0.5, 1.0, -0.2, 1.5});; std::cout << ""Single-event inference: "" << prediction << ""\n\n"";. // 2) Batch inference on data of multiple events; // For batch inference, the data needs to be structured as a matrix. For this; // purpose, TMVA makes use of the RTensor class. For convenience, we use RDataFrame; // and the AsTensor utility to make the read-out from the ROOT file.; ROOT::RDataFrame df(""TreeS"", filename);; auto df2 = df.Range(3); // Read only 10 events; auto x = AsTensor<float>(df2, variables);; std::cout << ""RTensor input for inference on data of multiple events:\n"" << x << ""\n\n"";. auto y = model.Predict(x);; std::cout << ""Prediction performed on multiple events: "" << y << ""\n\n"";. // 3) Perform inference as part of an RDataFrame graph; // We write a small lambda function that performs for us the inference on; // a dataframe to omit code duplication.; auto make_histo = [&](const std::string &treename) {; ROOT::RDataFrame df(treename, filename);; auto df2 = df.Define(""y"", Predict<4, float>(model), variables);; return df2.Histo1D({"""", """", 30, -1, 1}, ""y"");; };. auto sig = make_histo(""TreeS"");; auto bkg = make_histo(""TreeB"");. gStyle->SetOptStat(0);; auto c = new TCanvas("""", """", 800, 800);; sig->SetLineColor(kRed);; bkg->SetLineColor(kBlue);; bkg->GetXaxis()->SetTitle(""Model response"");; bkg->Draw(""HIST"");; sig->Draw(""HIST SAME"");; c->SaveAs(""bdt_response.pdf"");; }; ```. ![x](https://user-images.githubusercontent.com/6951222/51740397-2f295f80-2094-11e9-8c29-b40bc618a4bc.png)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3321
https://github.com/root-project/root/pull/3321:274,Performance,optimiz,optimized,274,"The purpose of this PR is to support discussion about the following proposal for a modern application interface for TMVA. See below the tutorial, which showcases the interface implemented in this PR as proof-of-concept. ```cpp; void train(const std::string& filename) {; // optimized out; }. void tmva003_RLegacyReader(); {; // First, let's train a model with TMVA.; const std::string filename = ""http://root.cern.ch/files/tmva_class_example.root"";; train(filename);. // Next, we load the model from the TMVA XML file.; RLegacyReader model(""TMVAClassification/weights/TMVAClassification_BDT.weights.xml"");. // In case you need a reminder of the names and order of the variables during; // training, you can ask the model for it.; auto variables = model.GetVariableNames();; std::cout << ""\nVariable names used during training: "" << variables << ""\n\n"";. // The model can now be applied in different scenarios:; // 1) Event-by-event inference; // 2) Batch inference on data of multiple events; // 3) Model inference as part of an RDataFrame graph. // 1) Event-by-event inference; // The event-by-event inference takes the values of the variables as a std::vector<float>.; // Note that the return value is as well a std::vector<float> since the reader; // is also capable to process models with multiple outputs.; auto prediction = model.Predict({0.5, 1.0, -0.2, 1.5});; std::cout << ""Single-event inference: "" << prediction << ""\n\n"";. // 2) Batch inference on data of multiple events; // For batch inference, the data needs to be structured as a matrix. For this; // purpose, TMVA makes use of the RTensor class. For convenience, we use RDataFrame; // and the AsTensor utility to make the read-out from the ROOT file.; ROOT::RDataFrame df(""TreeS"", filename);; auto df2 = df.Range(3); // Read only 10 events; auto x = AsTensor<float>(df2, variables);; std::cout << ""RTensor input for inference on data of multiple events:\n"" << x << ""\n\n"";. auto y = model.Predict(x);; std::cout << ""Prediction perform",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3321
https://github.com/root-project/root/pull/3321:480,Performance,load,load,480,"The purpose of this PR is to support discussion about the following proposal for a modern application interface for TMVA. See below the tutorial, which showcases the interface implemented in this PR as proof-of-concept. ```cpp; void train(const std::string& filename) {; // optimized out; }. void tmva003_RLegacyReader(); {; // First, let's train a model with TMVA.; const std::string filename = ""http://root.cern.ch/files/tmva_class_example.root"";; train(filename);. // Next, we load the model from the TMVA XML file.; RLegacyReader model(""TMVAClassification/weights/TMVAClassification_BDT.weights.xml"");. // In case you need a reminder of the names and order of the variables during; // training, you can ask the model for it.; auto variables = model.GetVariableNames();; std::cout << ""\nVariable names used during training: "" << variables << ""\n\n"";. // The model can now be applied in different scenarios:; // 1) Event-by-event inference; // 2) Batch inference on data of multiple events; // 3) Model inference as part of an RDataFrame graph. // 1) Event-by-event inference; // The event-by-event inference takes the values of the variables as a std::vector<float>.; // Note that the return value is as well a std::vector<float> since the reader; // is also capable to process models with multiple outputs.; auto prediction = model.Predict({0.5, 1.0, -0.2, 1.5});; std::cout << ""Single-event inference: "" << prediction << ""\n\n"";. // 2) Batch inference on data of multiple events; // For batch inference, the data needs to be structured as a matrix. For this; // purpose, TMVA makes use of the RTensor class. For convenience, we use RDataFrame; // and the AsTensor utility to make the read-out from the ROOT file.; ROOT::RDataFrame df(""TreeS"", filename);; auto df2 = df.Range(3); // Read only 10 events; auto x = AsTensor<float>(df2, variables);; std::cout << ""RTensor input for inference on data of multiple events:\n"" << x << ""\n\n"";. auto y = model.Predict(x);; std::cout << ""Prediction perform",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3321
https://github.com/root-project/root/pull/3321:1994,Performance,perform,performed,1994,"\n"";. // The model can now be applied in different scenarios:; // 1) Event-by-event inference; // 2) Batch inference on data of multiple events; // 3) Model inference as part of an RDataFrame graph. // 1) Event-by-event inference; // The event-by-event inference takes the values of the variables as a std::vector<float>.; // Note that the return value is as well a std::vector<float> since the reader; // is also capable to process models with multiple outputs.; auto prediction = model.Predict({0.5, 1.0, -0.2, 1.5});; std::cout << ""Single-event inference: "" << prediction << ""\n\n"";. // 2) Batch inference on data of multiple events; // For batch inference, the data needs to be structured as a matrix. For this; // purpose, TMVA makes use of the RTensor class. For convenience, we use RDataFrame; // and the AsTensor utility to make the read-out from the ROOT file.; ROOT::RDataFrame df(""TreeS"", filename);; auto df2 = df.Range(3); // Read only 10 events; auto x = AsTensor<float>(df2, variables);; std::cout << ""RTensor input for inference on data of multiple events:\n"" << x << ""\n\n"";. auto y = model.Predict(x);; std::cout << ""Prediction performed on multiple events: "" << y << ""\n\n"";. // 3) Perform inference as part of an RDataFrame graph; // We write a small lambda function that performs for us the inference on; // a dataframe to omit code duplication.; auto make_histo = [&](const std::string &treename) {; ROOT::RDataFrame df(treename, filename);; auto df2 = df.Define(""y"", Predict<4, float>(model), variables);; return df2.Histo1D({"""", """", 30, -1, 1}, ""y"");; };. auto sig = make_histo(""TreeS"");; auto bkg = make_histo(""TreeB"");. gStyle->SetOptStat(0);; auto c = new TCanvas("""", """", 800, 800);; sig->SetLineColor(kRed);; bkg->SetLineColor(kBlue);; bkg->GetXaxis()->SetTitle(""Model response"");; bkg->Draw(""HIST"");; sig->Draw(""HIST SAME"");; c->SaveAs(""bdt_response.pdf"");; }; ```. ![x](https://user-images.githubusercontent.com/6951222/51740397-2f295f80-2094-11e9-8c29-b40bc618a4bc.png)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3321
https://github.com/root-project/root/pull/3321:2049,Performance,Perform,Perform,2049,"\n"";. // The model can now be applied in different scenarios:; // 1) Event-by-event inference; // 2) Batch inference on data of multiple events; // 3) Model inference as part of an RDataFrame graph. // 1) Event-by-event inference; // The event-by-event inference takes the values of the variables as a std::vector<float>.; // Note that the return value is as well a std::vector<float> since the reader; // is also capable to process models with multiple outputs.; auto prediction = model.Predict({0.5, 1.0, -0.2, 1.5});; std::cout << ""Single-event inference: "" << prediction << ""\n\n"";. // 2) Batch inference on data of multiple events; // For batch inference, the data needs to be structured as a matrix. For this; // purpose, TMVA makes use of the RTensor class. For convenience, we use RDataFrame; // and the AsTensor utility to make the read-out from the ROOT file.; ROOT::RDataFrame df(""TreeS"", filename);; auto df2 = df.Range(3); // Read only 10 events; auto x = AsTensor<float>(df2, variables);; std::cout << ""RTensor input for inference on data of multiple events:\n"" << x << ""\n\n"";. auto y = model.Predict(x);; std::cout << ""Prediction performed on multiple events: "" << y << ""\n\n"";. // 3) Perform inference as part of an RDataFrame graph; // We write a small lambda function that performs for us the inference on; // a dataframe to omit code duplication.; auto make_histo = [&](const std::string &treename) {; ROOT::RDataFrame df(treename, filename);; auto df2 = df.Define(""y"", Predict<4, float>(model), variables);; return df2.Histo1D({"""", """", 30, -1, 1}, ""y"");; };. auto sig = make_histo(""TreeS"");; auto bkg = make_histo(""TreeB"");. gStyle->SetOptStat(0);; auto c = new TCanvas("""", """", 800, 800);; sig->SetLineColor(kRed);; bkg->SetLineColor(kBlue);; bkg->GetXaxis()->SetTitle(""Model response"");; bkg->Draw(""HIST"");; sig->Draw(""HIST SAME"");; c->SaveAs(""bdt_response.pdf"");; }; ```. ![x](https://user-images.githubusercontent.com/6951222/51740397-2f295f80-2094-11e9-8c29-b40bc618a4bc.png)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3321
https://github.com/root-project/root/pull/3321:2140,Performance,perform,performs,2140,"\n"";. // The model can now be applied in different scenarios:; // 1) Event-by-event inference; // 2) Batch inference on data of multiple events; // 3) Model inference as part of an RDataFrame graph. // 1) Event-by-event inference; // The event-by-event inference takes the values of the variables as a std::vector<float>.; // Note that the return value is as well a std::vector<float> since the reader; // is also capable to process models with multiple outputs.; auto prediction = model.Predict({0.5, 1.0, -0.2, 1.5});; std::cout << ""Single-event inference: "" << prediction << ""\n\n"";. // 2) Batch inference on data of multiple events; // For batch inference, the data needs to be structured as a matrix. For this; // purpose, TMVA makes use of the RTensor class. For convenience, we use RDataFrame; // and the AsTensor utility to make the read-out from the ROOT file.; ROOT::RDataFrame df(""TreeS"", filename);; auto df2 = df.Range(3); // Read only 10 events; auto x = AsTensor<float>(df2, variables);; std::cout << ""RTensor input for inference on data of multiple events:\n"" << x << ""\n\n"";. auto y = model.Predict(x);; std::cout << ""Prediction performed on multiple events: "" << y << ""\n\n"";. // 3) Perform inference as part of an RDataFrame graph; // We write a small lambda function that performs for us the inference on; // a dataframe to omit code duplication.; auto make_histo = [&](const std::string &treename) {; ROOT::RDataFrame df(treename, filename);; auto df2 = df.Define(""y"", Predict<4, float>(model), variables);; return df2.Histo1D({"""", """", 30, -1, 1}, ""y"");; };. auto sig = make_histo(""TreeS"");; auto bkg = make_histo(""TreeB"");. gStyle->SetOptStat(0);; auto c = new TCanvas("""", """", 800, 800);; sig->SetLineColor(kRed);; bkg->SetLineColor(kBlue);; bkg->GetXaxis()->SetTitle(""Model response"");; bkg->Draw(""HIST"");; sig->Draw(""HIST SAME"");; c->SaveAs(""bdt_response.pdf"");; }; ```. ![x](https://user-images.githubusercontent.com/6951222/51740397-2f295f80-2094-11e9-8c29-b40bc618a4bc.png)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3321
https://github.com/root-project/root/pull/3321:1317,Safety,predict,prediction,1317,"; // First, let's train a model with TMVA.; const std::string filename = ""http://root.cern.ch/files/tmva_class_example.root"";; train(filename);. // Next, we load the model from the TMVA XML file.; RLegacyReader model(""TMVAClassification/weights/TMVAClassification_BDT.weights.xml"");. // In case you need a reminder of the names and order of the variables during; // training, you can ask the model for it.; auto variables = model.GetVariableNames();; std::cout << ""\nVariable names used during training: "" << variables << ""\n\n"";. // The model can now be applied in different scenarios:; // 1) Event-by-event inference; // 2) Batch inference on data of multiple events; // 3) Model inference as part of an RDataFrame graph. // 1) Event-by-event inference; // The event-by-event inference takes the values of the variables as a std::vector<float>.; // Note that the return value is as well a std::vector<float> since the reader; // is also capable to process models with multiple outputs.; auto prediction = model.Predict({0.5, 1.0, -0.2, 1.5});; std::cout << ""Single-event inference: "" << prediction << ""\n\n"";. // 2) Batch inference on data of multiple events; // For batch inference, the data needs to be structured as a matrix. For this; // purpose, TMVA makes use of the RTensor class. For convenience, we use RDataFrame; // and the AsTensor utility to make the read-out from the ROOT file.; ROOT::RDataFrame df(""TreeS"", filename);; auto df2 = df.Range(3); // Read only 10 events; auto x = AsTensor<float>(df2, variables);; std::cout << ""RTensor input for inference on data of multiple events:\n"" << x << ""\n\n"";. auto y = model.Predict(x);; std::cout << ""Prediction performed on multiple events: "" << y << ""\n\n"";. // 3) Perform inference as part of an RDataFrame graph; // We write a small lambda function that performs for us the inference on; // a dataframe to omit code duplication.; auto make_histo = [&](const std::string &treename) {; ROOT::RDataFrame df(treename, filename);; auto df2 = ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3321
https://github.com/root-project/root/pull/3321:1336,Safety,Predict,Predict,1336,"train a model with TMVA.; const std::string filename = ""http://root.cern.ch/files/tmva_class_example.root"";; train(filename);. // Next, we load the model from the TMVA XML file.; RLegacyReader model(""TMVAClassification/weights/TMVAClassification_BDT.weights.xml"");. // In case you need a reminder of the names and order of the variables during; // training, you can ask the model for it.; auto variables = model.GetVariableNames();; std::cout << ""\nVariable names used during training: "" << variables << ""\n\n"";. // The model can now be applied in different scenarios:; // 1) Event-by-event inference; // 2) Batch inference on data of multiple events; // 3) Model inference as part of an RDataFrame graph. // 1) Event-by-event inference; // The event-by-event inference takes the values of the variables as a std::vector<float>.; // Note that the return value is as well a std::vector<float> since the reader; // is also capable to process models with multiple outputs.; auto prediction = model.Predict({0.5, 1.0, -0.2, 1.5});; std::cout << ""Single-event inference: "" << prediction << ""\n\n"";. // 2) Batch inference on data of multiple events; // For batch inference, the data needs to be structured as a matrix. For this; // purpose, TMVA makes use of the RTensor class. For convenience, we use RDataFrame; // and the AsTensor utility to make the read-out from the ROOT file.; ROOT::RDataFrame df(""TreeS"", filename);; auto df2 = df.Range(3); // Read only 10 events; auto x = AsTensor<float>(df2, variables);; std::cout << ""RTensor input for inference on data of multiple events:\n"" << x << ""\n\n"";. auto y = model.Predict(x);; std::cout << ""Prediction performed on multiple events: "" << y << ""\n\n"";. // 3) Perform inference as part of an RDataFrame graph; // We write a small lambda function that performs for us the inference on; // a dataframe to omit code duplication.; auto make_histo = [&](const std::string &treename) {; ROOT::RDataFrame df(treename, filename);; auto df2 = df.Define(""y"", Pred",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3321
https://github.com/root-project/root/pull/3321:1412,Safety,predict,prediction,1412,"ttp://root.cern.ch/files/tmva_class_example.root"";; train(filename);. // Next, we load the model from the TMVA XML file.; RLegacyReader model(""TMVAClassification/weights/TMVAClassification_BDT.weights.xml"");. // In case you need a reminder of the names and order of the variables during; // training, you can ask the model for it.; auto variables = model.GetVariableNames();; std::cout << ""\nVariable names used during training: "" << variables << ""\n\n"";. // The model can now be applied in different scenarios:; // 1) Event-by-event inference; // 2) Batch inference on data of multiple events; // 3) Model inference as part of an RDataFrame graph. // 1) Event-by-event inference; // The event-by-event inference takes the values of the variables as a std::vector<float>.; // Note that the return value is as well a std::vector<float> since the reader; // is also capable to process models with multiple outputs.; auto prediction = model.Predict({0.5, 1.0, -0.2, 1.5});; std::cout << ""Single-event inference: "" << prediction << ""\n\n"";. // 2) Batch inference on data of multiple events; // For batch inference, the data needs to be structured as a matrix. For this; // purpose, TMVA makes use of the RTensor class. For convenience, we use RDataFrame; // and the AsTensor utility to make the read-out from the ROOT file.; ROOT::RDataFrame df(""TreeS"", filename);; auto df2 = df.Range(3); // Read only 10 events; auto x = AsTensor<float>(df2, variables);; std::cout << ""RTensor input for inference on data of multiple events:\n"" << x << ""\n\n"";. auto y = model.Predict(x);; std::cout << ""Prediction performed on multiple events: "" << y << ""\n\n"";. // 3) Perform inference as part of an RDataFrame graph; // We write a small lambda function that performs for us the inference on; // a dataframe to omit code duplication.; auto make_histo = [&](const std::string &treename) {; ROOT::RDataFrame df(treename, filename);; auto df2 = df.Define(""y"", Predict<4, float>(model), variables);; return df2.Histo1D({""""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3321
https://github.com/root-project/root/pull/3321:1956,Safety,Predict,Predict,1956,"\n"";. // The model can now be applied in different scenarios:; // 1) Event-by-event inference; // 2) Batch inference on data of multiple events; // 3) Model inference as part of an RDataFrame graph. // 1) Event-by-event inference; // The event-by-event inference takes the values of the variables as a std::vector<float>.; // Note that the return value is as well a std::vector<float> since the reader; // is also capable to process models with multiple outputs.; auto prediction = model.Predict({0.5, 1.0, -0.2, 1.5});; std::cout << ""Single-event inference: "" << prediction << ""\n\n"";. // 2) Batch inference on data of multiple events; // For batch inference, the data needs to be structured as a matrix. For this; // purpose, TMVA makes use of the RTensor class. For convenience, we use RDataFrame; // and the AsTensor utility to make the read-out from the ROOT file.; ROOT::RDataFrame df(""TreeS"", filename);; auto df2 = df.Range(3); // Read only 10 events; auto x = AsTensor<float>(df2, variables);; std::cout << ""RTensor input for inference on data of multiple events:\n"" << x << ""\n\n"";. auto y = model.Predict(x);; std::cout << ""Prediction performed on multiple events: "" << y << ""\n\n"";. // 3) Perform inference as part of an RDataFrame graph; // We write a small lambda function that performs for us the inference on; // a dataframe to omit code duplication.; auto make_histo = [&](const std::string &treename) {; ROOT::RDataFrame df(treename, filename);; auto df2 = df.Define(""y"", Predict<4, float>(model), variables);; return df2.Histo1D({"""", """", 30, -1, 1}, ""y"");; };. auto sig = make_histo(""TreeS"");; auto bkg = make_histo(""TreeB"");. gStyle->SetOptStat(0);; auto c = new TCanvas("""", """", 800, 800);; sig->SetLineColor(kRed);; bkg->SetLineColor(kBlue);; bkg->GetXaxis()->SetTitle(""Model response"");; bkg->Draw(""HIST"");; sig->Draw(""HIST SAME"");; c->SaveAs(""bdt_response.pdf"");; }; ```. ![x](https://user-images.githubusercontent.com/6951222/51740397-2f295f80-2094-11e9-8c29-b40bc618a4bc.png)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3321
https://github.com/root-project/root/pull/3321:1983,Safety,Predict,Prediction,1983,"\n"";. // The model can now be applied in different scenarios:; // 1) Event-by-event inference; // 2) Batch inference on data of multiple events; // 3) Model inference as part of an RDataFrame graph. // 1) Event-by-event inference; // The event-by-event inference takes the values of the variables as a std::vector<float>.; // Note that the return value is as well a std::vector<float> since the reader; // is also capable to process models with multiple outputs.; auto prediction = model.Predict({0.5, 1.0, -0.2, 1.5});; std::cout << ""Single-event inference: "" << prediction << ""\n\n"";. // 2) Batch inference on data of multiple events; // For batch inference, the data needs to be structured as a matrix. For this; // purpose, TMVA makes use of the RTensor class. For convenience, we use RDataFrame; // and the AsTensor utility to make the read-out from the ROOT file.; ROOT::RDataFrame df(""TreeS"", filename);; auto df2 = df.Range(3); // Read only 10 events; auto x = AsTensor<float>(df2, variables);; std::cout << ""RTensor input for inference on data of multiple events:\n"" << x << ""\n\n"";. auto y = model.Predict(x);; std::cout << ""Prediction performed on multiple events: "" << y << ""\n\n"";. // 3) Perform inference as part of an RDataFrame graph; // We write a small lambda function that performs for us the inference on; // a dataframe to omit code duplication.; auto make_histo = [&](const std::string &treename) {; ROOT::RDataFrame df(treename, filename);; auto df2 = df.Define(""y"", Predict<4, float>(model), variables);; return df2.Histo1D({"""", """", 30, -1, 1}, ""y"");; };. auto sig = make_histo(""TreeS"");; auto bkg = make_histo(""TreeB"");. gStyle->SetOptStat(0);; auto c = new TCanvas("""", """", 800, 800);; sig->SetLineColor(kRed);; bkg->SetLineColor(kBlue);; bkg->GetXaxis()->SetTitle(""Model response"");; bkg->Draw(""HIST"");; sig->Draw(""HIST SAME"");; c->SaveAs(""bdt_response.pdf"");; }; ```. ![x](https://user-images.githubusercontent.com/6951222/51740397-2f295f80-2094-11e9-8c29-b40bc618a4bc.png)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3321
https://github.com/root-project/root/pull/3321:2338,Safety,Predict,Predict,2338,"\n"";. // The model can now be applied in different scenarios:; // 1) Event-by-event inference; // 2) Batch inference on data of multiple events; // 3) Model inference as part of an RDataFrame graph. // 1) Event-by-event inference; // The event-by-event inference takes the values of the variables as a std::vector<float>.; // Note that the return value is as well a std::vector<float> since the reader; // is also capable to process models with multiple outputs.; auto prediction = model.Predict({0.5, 1.0, -0.2, 1.5});; std::cout << ""Single-event inference: "" << prediction << ""\n\n"";. // 2) Batch inference on data of multiple events; // For batch inference, the data needs to be structured as a matrix. For this; // purpose, TMVA makes use of the RTensor class. For convenience, we use RDataFrame; // and the AsTensor utility to make the read-out from the ROOT file.; ROOT::RDataFrame df(""TreeS"", filename);; auto df2 = df.Range(3); // Read only 10 events; auto x = AsTensor<float>(df2, variables);; std::cout << ""RTensor input for inference on data of multiple events:\n"" << x << ""\n\n"";. auto y = model.Predict(x);; std::cout << ""Prediction performed on multiple events: "" << y << ""\n\n"";. // 3) Perform inference as part of an RDataFrame graph; // We write a small lambda function that performs for us the inference on; // a dataframe to omit code duplication.; auto make_histo = [&](const std::string &treename) {; ROOT::RDataFrame df(treename, filename);; auto df2 = df.Define(""y"", Predict<4, float>(model), variables);; return df2.Histo1D({"""", """", 30, -1, 1}, ""y"");; };. auto sig = make_histo(""TreeS"");; auto bkg = make_histo(""TreeB"");. gStyle->SetOptStat(0);; auto c = new TCanvas("""", """", 800, 800);; sig->SetLineColor(kRed);; bkg->SetLineColor(kBlue);; bkg->GetXaxis()->SetTitle(""Model response"");; bkg->Draw(""HIST"");; sig->Draw(""HIST SAME"");; c->SaveAs(""bdt_response.pdf"");; }; ```. ![x](https://user-images.githubusercontent.com/6951222/51740397-2f295f80-2094-11e9-8c29-b40bc618a4bc.png)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3321
https://github.com/root-project/root/pull/3322:8,Deployability,update,updates,8,"This PR updates the Cppyy copy of experimental PyROOT, in particular with:; - cppyy v1.4.1; - cppyy_backend v1.7.0 (clingwrapper); - CPyCppyy v1.5.1. This update brings in, among other things:; * A few fixes in Cppyy for Windows.; * The possibility to set an environment variable with the path to `libcppyy_backend.so`. This is needed in macOS, where all the Python tests are failing because macOS SIP prevents the Python process from seeing `DYLD_LIBRARY_PATH`:; https://epsft-jenkins.cern.ch/job/root-exp-pyroot/20/LABEL=mac1014,SPEC=default/; * A fix for `addressof` in Cppyy.; * No insertion anymore of `__iter__` in `TCollection`s, which makes it possible to implement an iterator for `TCollection` that all subclasses inherit.; * A new Cppyy interface to create converters of multi-dimensional arrays. On the other hand, this update introduces a warning when Cppyy tries to generate a PCH for standard and system headers. This is to be addressed in another PR.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3322
https://github.com/root-project/root/pull/3322:155,Deployability,update,update,155,"This PR updates the Cppyy copy of experimental PyROOT, in particular with:; - cppyy v1.4.1; - cppyy_backend v1.7.0 (clingwrapper); - CPyCppyy v1.5.1. This update brings in, among other things:; * A few fixes in Cppyy for Windows.; * The possibility to set an environment variable with the path to `libcppyy_backend.so`. This is needed in macOS, where all the Python tests are failing because macOS SIP prevents the Python process from seeing `DYLD_LIBRARY_PATH`:; https://epsft-jenkins.cern.ch/job/root-exp-pyroot/20/LABEL=mac1014,SPEC=default/; * A fix for `addressof` in Cppyy.; * No insertion anymore of `__iter__` in `TCollection`s, which makes it possible to implement an iterator for `TCollection` that all subclasses inherit.; * A new Cppyy interface to create converters of multi-dimensional arrays. On the other hand, this update introduces a warning when Cppyy tries to generate a PCH for standard and system headers. This is to be addressed in another PR.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3322
https://github.com/root-project/root/pull/3322:832,Deployability,update,update,832,"This PR updates the Cppyy copy of experimental PyROOT, in particular with:; - cppyy v1.4.1; - cppyy_backend v1.7.0 (clingwrapper); - CPyCppyy v1.5.1. This update brings in, among other things:; * A few fixes in Cppyy for Windows.; * The possibility to set an environment variable with the path to `libcppyy_backend.so`. This is needed in macOS, where all the Python tests are failing because macOS SIP prevents the Python process from seeing `DYLD_LIBRARY_PATH`:; https://epsft-jenkins.cern.ch/job/root-exp-pyroot/20/LABEL=mac1014,SPEC=default/; * A fix for `addressof` in Cppyy.; * No insertion anymore of `__iter__` in `TCollection`s, which makes it possible to implement an iterator for `TCollection` that all subclasses inherit.; * A new Cppyy interface to create converters of multi-dimensional arrays. On the other hand, this update introduces a warning when Cppyy tries to generate a PCH for standard and system headers. This is to be addressed in another PR.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3322
https://github.com/root-project/root/pull/3322:748,Integrability,interface,interface,748,"This PR updates the Cppyy copy of experimental PyROOT, in particular with:; - cppyy v1.4.1; - cppyy_backend v1.7.0 (clingwrapper); - CPyCppyy v1.5.1. This update brings in, among other things:; * A few fixes in Cppyy for Windows.; * The possibility to set an environment variable with the path to `libcppyy_backend.so`. This is needed in macOS, where all the Python tests are failing because macOS SIP prevents the Python process from seeing `DYLD_LIBRARY_PATH`:; https://epsft-jenkins.cern.ch/job/root-exp-pyroot/20/LABEL=mac1014,SPEC=default/; * A fix for `addressof` in Cppyy.; * No insertion anymore of `__iter__` in `TCollection`s, which makes it possible to implement an iterator for `TCollection` that all subclasses inherit.; * A new Cppyy interface to create converters of multi-dimensional arrays. On the other hand, this update introduces a warning when Cppyy tries to generate a PCH for standard and system headers. This is to be addressed in another PR.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3322
https://github.com/root-project/root/pull/3322:271,Modifiability,variab,variable,271,"This PR updates the Cppyy copy of experimental PyROOT, in particular with:; - cppyy v1.4.1; - cppyy_backend v1.7.0 (clingwrapper); - CPyCppyy v1.5.1. This update brings in, among other things:; * A few fixes in Cppyy for Windows.; * The possibility to set an environment variable with the path to `libcppyy_backend.so`. This is needed in macOS, where all the Python tests are failing because macOS SIP prevents the Python process from seeing `DYLD_LIBRARY_PATH`:; https://epsft-jenkins.cern.ch/job/root-exp-pyroot/20/LABEL=mac1014,SPEC=default/; * A fix for `addressof` in Cppyy.; * No insertion anymore of `__iter__` in `TCollection`s, which makes it possible to implement an iterator for `TCollection` that all subclasses inherit.; * A new Cppyy interface to create converters of multi-dimensional arrays. On the other hand, this update introduces a warning when Cppyy tries to generate a PCH for standard and system headers. This is to be addressed in another PR.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3322
https://github.com/root-project/root/pull/3322:724,Modifiability,inherit,inherit,724,"This PR updates the Cppyy copy of experimental PyROOT, in particular with:; - cppyy v1.4.1; - cppyy_backend v1.7.0 (clingwrapper); - CPyCppyy v1.5.1. This update brings in, among other things:; * A few fixes in Cppyy for Windows.; * The possibility to set an environment variable with the path to `libcppyy_backend.so`. This is needed in macOS, where all the Python tests are failing because macOS SIP prevents the Python process from seeing `DYLD_LIBRARY_PATH`:; https://epsft-jenkins.cern.ch/job/root-exp-pyroot/20/LABEL=mac1014,SPEC=default/; * A fix for `addressof` in Cppyy.; * No insertion anymore of `__iter__` in `TCollection`s, which makes it possible to implement an iterator for `TCollection` that all subclasses inherit.; * A new Cppyy interface to create converters of multi-dimensional arrays. On the other hand, this update introduces a warning when Cppyy tries to generate a PCH for standard and system headers. This is to be addressed in another PR.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3322
https://github.com/root-project/root/pull/3322:366,Testability,test,tests,366,"This PR updates the Cppyy copy of experimental PyROOT, in particular with:; - cppyy v1.4.1; - cppyy_backend v1.7.0 (clingwrapper); - CPyCppyy v1.5.1. This update brings in, among other things:; * A few fixes in Cppyy for Windows.; * The possibility to set an environment variable with the path to `libcppyy_backend.so`. This is needed in macOS, where all the Python tests are failing because macOS SIP prevents the Python process from seeing `DYLD_LIBRARY_PATH`:; https://epsft-jenkins.cern.ch/job/root-exp-pyroot/20/LABEL=mac1014,SPEC=default/; * A fix for `addressof` in Cppyy.; * No insertion anymore of `__iter__` in `TCollection`s, which makes it possible to implement an iterator for `TCollection` that all subclasses inherit.; * A new Cppyy interface to create converters of multi-dimensional arrays. On the other hand, this update introduces a warning when Cppyy tries to generate a PCH for standard and system headers. This is to be addressed in another PR.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3322
https://github.com/root-project/root/pull/3324:472,Availability,avail,available,472,"in Defines and Filters.; When dealing with very large computation graphs with many Define/Filter; transformations defined with jitted strings, the time for matching; column names to strings was non negligible. The previous mechanism to discover the columns present in the strings; to be jitted was based on regular expressions. The new approach is based; on a lexer, lexertk. The idea is to extract identifiers from; the string and then compare them with the column names available; in the DF.; This pr is an extreme version of this performance improvement: https://github.com/root-project/root/pull/3320.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3324
https://github.com/root-project/root/pull/3324:533,Performance,perform,performance,533,"in Defines and Filters.; When dealing with very large computation graphs with many Define/Filter; transformations defined with jitted strings, the time for matching; column names to strings was non negligible. The previous mechanism to discover the columns present in the strings; to be jitted was based on regular expressions. The new approach is based; on a lexer, lexertk. The idea is to extract identifiers from; the string and then compare them with the column names available; in the DF.; This pr is an extreme version of this performance improvement: https://github.com/root-project/root/pull/3320.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3324
https://github.com/root-project/root/pull/3325:437,Testability,test,test,437,"The analytical integral of RooGaussian was using erf() to compute the; integrals. Starting from x>5*sigma, this always yields 1 because of limited; precision, integrals over a range in the high tails would therefore always be zero. Now, erfc() is used, which is much more accurate in the upper tail.; To obtain the same precision in the low tails, all ranges are mapped; onto the upper tail of the Gaussian before calling erfc(). A unit test for various Gaussian integrals has been added.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3325
https://github.com/root-project/root/pull/3326:402,Deployability,integrat,integration,402,"[ROOT-9518] The analytical integral of RooPoisson was interpolating between the points of the; discrete CDF. The CDF, however, is shifted by 1 such that asking for CDF_Pois(x=0, mu=1); yields 0. [ROOT-5333] Further, giving a range with an upper limit larger than max int (variables without; ranges will default to 1.E30) will overflow an integer and yield NaN. Now, max int will be used; as end of the integration range, yielding an integral of 1 in such cases. For an unlimited range,; the integral will always be 1. The CDF obtained with these changes is now discrete.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3326
https://github.com/root-project/root/pull/3326:402,Integrability,integrat,integration,402,"[ROOT-9518] The analytical integral of RooPoisson was interpolating between the points of the; discrete CDF. The CDF, however, is shifted by 1 such that asking for CDF_Pois(x=0, mu=1); yields 0. [ROOT-5333] Further, giving a range with an upper limit larger than max int (variables without; ranges will default to 1.E30) will overflow an integer and yield NaN. Now, max int will be used; as end of the integration range, yielding an integral of 1 in such cases. For an unlimited range,; the integral will always be 1. The CDF obtained with these changes is now discrete.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3326
https://github.com/root-project/root/pull/3326:272,Modifiability,variab,variables,272,"[ROOT-9518] The analytical integral of RooPoisson was interpolating between the points of the; discrete CDF. The CDF, however, is shifted by 1 such that asking for CDF_Pois(x=0, mu=1); yields 0. [ROOT-5333] Further, giving a range with an upper limit larger than max int (variables without; ranges will default to 1.E30) will overflow an integer and yield NaN. Now, max int will be used; as end of the integration range, yielding an integral of 1 in such cases. For an unlimited range,; the integral will always be 1. The CDF obtained with these changes is now discrete.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3326
https://github.com/root-project/root/pull/3327:202,Deployability,update,updated,202,"The RooMinimizer interface does not allow for changing the number of points on a likelihood contour.; By promoting this parameter to a default argument, this is now accessible to the user.; Doxygen was updated accordingly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3327
https://github.com/root-project/root/pull/3327:17,Integrability,interface,interface,17,"The RooMinimizer interface does not allow for changing the number of points on a likelihood contour.; By promoting this parameter to a default argument, this is now accessible to the user.; Doxygen was updated accordingly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3327
https://github.com/root-project/root/pull/3327:165,Security,access,accessible,165,"The RooMinimizer interface does not allow for changing the number of points on a likelihood contour.; By promoting this parameter to a default argument, this is now accessible to the user.; Doxygen was updated accordingly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3327
https://github.com/root-project/root/pull/3330:68,Energy Efficiency,green,green,68,Part of the ongoing campaign to turn the experimental PyROOT builds green.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3330
https://github.com/root-project/root/pull/3331:23,Modifiability,extend,extend,23,Fix doxygen problems / extend docstrings in; - RooPolynomial; - HistFactory; - RooAbsReal; - RooRealSumPdf,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3331
https://github.com/root-project/root/pull/3333:53,Availability,failure,failure,53,Remove usage of deprecated GC macro to prevent build failure in Python3.7.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3333
https://github.com/root-project/root/pull/3336:175,Modifiability,extend,extend,175,"Python deletes temporary objects that are referenced by a C++ object. When the objects are named, the tutorials work.; Further, add a more elaborate tutorial rf204a on how to extend PDFs when fits in multiple ranges are desired.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3336
https://github.com/root-project/root/pull/3339:10,Integrability,depend,depends,10,"Rootbench depends on copy assignment for the `Sample` class. After implementing move semantics to speed up hist2workspace, the copy assignment had been implicitly deleted. This was fixed, and a gtest has been added. Further, HistRef, a member of Sample, is now movable, and the histograms given back by Sample are now `const TH1*` instead of `TH1*`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3339
https://github.com/root-project/root/pull/3340:51,Availability,error,error,51,"Looks like only TGeoCone was ignoring name.; Fixes error described in https://root-forum.cern.ch/t/32493; Patch can be applied to several previous versions: 6.12, 6.14, 6.16",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3340
https://github.com/root-project/root/pull/3340:106,Deployability,Patch,Patch,106,"Looks like only TGeoCone was ignoring name.; Fixes error described in https://root-forum.cern.ch/t/32493; Patch can be applied to several previous versions: 6.12, 6.14, 6.16",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3340
https://github.com/root-project/root/pull/3341:117,Availability,robust,robust,117,Use for bin edge comparisons an epsilon abs value that is computed a a fraction of bin width. This would give a more robust comparison test.; This PR should fix what has been suggested in ROOT-7752,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3341
https://github.com/root-project/root/pull/3341:135,Testability,test,test,135,Use for bin edge comparisons an epsilon abs value that is computed a a fraction of bin width. This would give a more robust comparison test.; This PR should fix what has been suggested in ROOT-7752,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3341
https://github.com/root-project/root/pull/3342:90,Availability,error,errors,90,"These commits are related to the binary distribution of runtime modules, and will fix the errors like https://root-forum.cern.ch/t/module-stl-imported-by-ast-file-found-in-a-different-module-map-file/32461/7.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3342
https://github.com/root-project/root/pull/3345:276,Deployability,update,updated,276,"Replace the RooLinkedList in the central collections of RooFit (RooArgSet, RooArgList) with a std::vector. This speeds up the tutorials of RooFit/RooStats by 10 to 20 %.; The interface with respect to iterators and size() now resembles an STL container. When iterating on the updated collections, only begin(), end() and range-based for loops should be used. The legacy RooFit iterators are still supported, but should not be used, since they are slower. They were flagged with the `R__SUGGEST_ALTERNATIVE` macro. **For Reviewers**; Reviews are most appreciated in `RooAbsCollection.h` (interfaces) and maybe `RooAbsCollection.cxx`. This is the central change.; All other changes are mostly places where old iterators have been replaced by new iterators to make RooFit faster.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3345
https://github.com/root-project/root/pull/3345:175,Integrability,interface,interface,175,"Replace the RooLinkedList in the central collections of RooFit (RooArgSet, RooArgList) with a std::vector. This speeds up the tutorials of RooFit/RooStats by 10 to 20 %.; The interface with respect to iterators and size() now resembles an STL container. When iterating on the updated collections, only begin(), end() and range-based for loops should be used. The legacy RooFit iterators are still supported, but should not be used, since they are slower. They were flagged with the `R__SUGGEST_ALTERNATIVE` macro. **For Reviewers**; Reviews are most appreciated in `RooAbsCollection.h` (interfaces) and maybe `RooAbsCollection.cxx`. This is the central change.; All other changes are mostly places where old iterators have been replaced by new iterators to make RooFit faster.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3345
https://github.com/root-project/root/pull/3345:587,Integrability,interface,interfaces,587,"Replace the RooLinkedList in the central collections of RooFit (RooArgSet, RooArgList) with a std::vector. This speeds up the tutorials of RooFit/RooStats by 10 to 20 %.; The interface with respect to iterators and size() now resembles an STL container. When iterating on the updated collections, only begin(), end() and range-based for loops should be used. The legacy RooFit iterators are still supported, but should not be used, since they are slower. They were flagged with the `R__SUGGEST_ALTERNATIVE` macro. **For Reviewers**; Reviews are most appreciated in `RooAbsCollection.h` (interfaces) and maybe `RooAbsCollection.cxx`. This is the central change.; All other changes are mostly places where old iterators have been replaced by new iterators to make RooFit faster.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3345
https://github.com/root-project/root/pull/3346:51,Availability,error,error,51,Looks like only TGeoCone was ignoring name.; Fixes error described in https://root-forum.cern.ch/t/32493,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3346
https://github.com/root-project/root/pull/3347:51,Availability,error,error,51,Looks like only TGeoCone was ignoring name.; Fixes error described in https://root-forum.cern.ch/t/32493,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3347
https://github.com/root-project/root/pull/3350:88,Deployability,update,updated,88,"- When RooWorkspaces that contain a ModelConfig are cloned, the ModelConfig did not get updated. It would still point to the old workspace.; - Add unit test. This reverts commit fdab28c0ca4782733527e6b74a4f795c252a877e.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3350
https://github.com/root-project/root/pull/3350:152,Testability,test,test,152,"- When RooWorkspaces that contain a ModelConfig are cloned, the ModelConfig did not get updated. It would still point to the old workspace.; - Add unit test. This reverts commit fdab28c0ca4782733527e6b74a4f795c252a877e.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3350
https://github.com/root-project/root/pull/3351:342,Testability,log,logic,342,"This PR puts in place a facade for ROOT to become a Python module with custom behaviour, in a similar way it is done for the current PyROOT.; https://github.com/root-project/root/blob/master/bindings/pyroot/ROOT.py#L560. For now this is just a simple skeleton that redirects lookups to cppyy's global namespace, and more investigation on the logic implemented by the facade of the current PyROOT is necessary.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3351
https://github.com/root-project/root/pull/3351:244,Usability,simpl,simple,244,"This PR puts in place a facade for ROOT to become a Python module with custom behaviour, in a similar way it is done for the current PyROOT.; https://github.com/root-project/root/blob/master/bindings/pyroot/ROOT.py#L560. For now this is just a simple skeleton that redirects lookups to cppyy's global namespace, and more investigation on the logic implemented by the facade of the current PyROOT is necessary.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3351
https://github.com/root-project/root/pull/3353:148,Testability,test,test,148,"strings. properly, for example treating cases such as 'branch0' and 'branch01'.; The code of the helper FindUsedColumnNames has been simplified.; A test has been added.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3353
https://github.com/root-project/root/pull/3353:133,Usability,simpl,simplified,133,"strings. properly, for example treating cases such as 'branch0' and 'branch01'.; The code of the helper FindUsedColumnNames has been simplified.; A test has been added.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3353
https://github.com/root-project/root/pull/3356:71,Testability,test,tests,71,- Fix dynamic libraries extensions (.so/.dll/.pyd); - Fix path for the tests and tutorials; - Make sure hexadecimal pointer values have the correct '0x' prefix (not automatic on Windows),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3356
https://github.com/root-project/root/pull/3360:366,Safety,avoid,avoid,366,"This is needed to fix MacPorts, https://trac.macports.org/ticket/57007, HomeBrew https://github.com/Homebrew/homebrew-core/pull/36585, and any similar system with case insensitivity. `RConfig.h` includes itself instead of `ROOT/RConfig.h`. This prioritizes relative imports for RConfig on most compilers. *Any similar changes should use double-quote imports too* to avoid this ambiguity.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3360
https://github.com/root-project/root/pull/3361:254,Deployability,install,installed,254,"This is an alternative fix vs. #3360 mentioned on Mattermost; this renames `root/ROOT/RConfig.h` to `root/ROOT/RConfig.hxx` so that on case insensitive filesystems `root/RConfig.h` doesn't end up including itself if a user has the base directory ROOT is installed in before the `root` include in the include path. A file `root/ROOT/RConfig.h` is provided that also points at `root/ROOT/RConfig.hxx` for backward compatibility, and it prints a removal message. Since including `ROOT/RConfig.h` is probably quite rare, this could be dropped. Or it could avoid printing a message because it does no harm. (Even `RConfig.h` probably tends to be included mostly by ROOT). If most/all other includes are `.h`, this might be better for consistency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3361
https://github.com/root-project/root/pull/3361:451,Integrability,message,message,451,"This is an alternative fix vs. #3360 mentioned on Mattermost; this renames `root/ROOT/RConfig.h` to `root/ROOT/RConfig.hxx` so that on case insensitive filesystems `root/RConfig.h` doesn't end up including itself if a user has the base directory ROOT is installed in before the `root` include in the include path. A file `root/ROOT/RConfig.h` is provided that also points at `root/ROOT/RConfig.hxx` for backward compatibility, and it prints a removal message. Since including `ROOT/RConfig.h` is probably quite rare, this could be dropped. Or it could avoid printing a message because it does no harm. (Even `RConfig.h` probably tends to be included mostly by ROOT). If most/all other includes are `.h`, this might be better for consistency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3361
https://github.com/root-project/root/pull/3361:569,Integrability,message,message,569,"This is an alternative fix vs. #3360 mentioned on Mattermost; this renames `root/ROOT/RConfig.h` to `root/ROOT/RConfig.hxx` so that on case insensitive filesystems `root/RConfig.h` doesn't end up including itself if a user has the base directory ROOT is installed in before the `root` include in the include path. A file `root/ROOT/RConfig.h` is provided that also points at `root/ROOT/RConfig.hxx` for backward compatibility, and it prints a removal message. Since including `ROOT/RConfig.h` is probably quite rare, this could be dropped. Or it could avoid printing a message because it does no harm. (Even `RConfig.h` probably tends to be included mostly by ROOT). If most/all other includes are `.h`, this might be better for consistency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3361
https://github.com/root-project/root/pull/3361:552,Safety,avoid,avoid,552,"This is an alternative fix vs. #3360 mentioned on Mattermost; this renames `root/ROOT/RConfig.h` to `root/ROOT/RConfig.hxx` so that on case insensitive filesystems `root/RConfig.h` doesn't end up including itself if a user has the base directory ROOT is installed in before the `root` include in the include path. A file `root/ROOT/RConfig.h` is provided that also points at `root/ROOT/RConfig.hxx` for backward compatibility, and it prints a removal message. Since including `ROOT/RConfig.h` is probably quite rare, this could be dropped. Or it could avoid printing a message because it does no harm. (Even `RConfig.h` probably tends to be included mostly by ROOT). If most/all other includes are `.h`, this might be better for consistency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3361
https://github.com/root-project/root/pull/3363:39,Testability,test,test,39,when booking Histo1D and Graph.; Add a test too.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3363
https://github.com/root-project/root/pull/3364:49,Safety,avoid,avoid,49,and a test.; This PR includes also #3363 just to avoid conflicts,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3364
https://github.com/root-project/root/pull/3364:6,Testability,test,test,6,and a test.; This PR includes also #3363 just to avoid conflicts,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3364
https://github.com/root-project/root/pull/3370:146,Availability,avail,available,146,"With the objective of fixing tests, this PR exposes in the ROOT module some functionality of the CPyCppyy extension module. Such functionality is available in the current PyROOT and some tests rely on it. A more exhaustive investigation on which functionality of cppyy we want to expose via the ROOT module is required.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3370
https://github.com/root-project/root/pull/3370:44,Security,expose,exposes,44,"With the objective of fixing tests, this PR exposes in the ROOT module some functionality of the CPyCppyy extension module. Such functionality is available in the current PyROOT and some tests rely on it. A more exhaustive investigation on which functionality of cppyy we want to expose via the ROOT module is required.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3370
https://github.com/root-project/root/pull/3370:280,Security,expose,expose,280,"With the objective of fixing tests, this PR exposes in the ROOT module some functionality of the CPyCppyy extension module. Such functionality is available in the current PyROOT and some tests rely on it. A more exhaustive investigation on which functionality of cppyy we want to expose via the ROOT module is required.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3370
https://github.com/root-project/root/pull/3370:29,Testability,test,tests,29,"With the objective of fixing tests, this PR exposes in the ROOT module some functionality of the CPyCppyy extension module. Such functionality is available in the current PyROOT and some tests rely on it. A more exhaustive investigation on which functionality of cppyy we want to expose via the ROOT module is required.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3370
https://github.com/root-project/root/pull/3370:187,Testability,test,tests,187,"With the objective of fixing tests, this PR exposes in the ROOT module some functionality of the CPyCppyy extension module. Such functionality is available in the current PyROOT and some tests rely on it. A more exhaustive investigation on which functionality of cppyy we want to expose via the ROOT module is required.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3370
https://github.com/root-project/root/pull/3371:196,Energy Efficiency,reduce,reduce,196,"Overall goals:; - fix currently broken dependencies, e.g. touch a header in histfactory does not regenerate its dictionary;; - simplify G__Core CMake setup;; - remove unnecessary dictionaries;; - reduce dependencies / occasions to rebuild dictionaries, e.g. touch hist/hist/src/TH1.cxx and the dictionaries of libraries depending on libHist were rebuild, and so was the PCH. I see an issue with runtime_cxxmodules; let's see what Jenkins says!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3371
https://github.com/root-project/root/pull/3371:39,Integrability,depend,dependencies,39,"Overall goals:; - fix currently broken dependencies, e.g. touch a header in histfactory does not regenerate its dictionary;; - simplify G__Core CMake setup;; - remove unnecessary dictionaries;; - reduce dependencies / occasions to rebuild dictionaries, e.g. touch hist/hist/src/TH1.cxx and the dictionaries of libraries depending on libHist were rebuild, and so was the PCH. I see an issue with runtime_cxxmodules; let's see what Jenkins says!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3371
https://github.com/root-project/root/pull/3371:203,Integrability,depend,dependencies,203,"Overall goals:; - fix currently broken dependencies, e.g. touch a header in histfactory does not regenerate its dictionary;; - simplify G__Core CMake setup;; - remove unnecessary dictionaries;; - reduce dependencies / occasions to rebuild dictionaries, e.g. touch hist/hist/src/TH1.cxx and the dictionaries of libraries depending on libHist were rebuild, and so was the PCH. I see an issue with runtime_cxxmodules; let's see what Jenkins says!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3371
https://github.com/root-project/root/pull/3371:320,Integrability,depend,depending,320,"Overall goals:; - fix currently broken dependencies, e.g. touch a header in histfactory does not regenerate its dictionary;; - simplify G__Core CMake setup;; - remove unnecessary dictionaries;; - reduce dependencies / occasions to rebuild dictionaries, e.g. touch hist/hist/src/TH1.cxx and the dictionaries of libraries depending on libHist were rebuild, and so was the PCH. I see an issue with runtime_cxxmodules; let's see what Jenkins says!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3371
https://github.com/root-project/root/pull/3371:127,Usability,simpl,simplify,127,"Overall goals:; - fix currently broken dependencies, e.g. touch a header in histfactory does not regenerate its dictionary;; - simplify G__Core CMake setup;; - remove unnecessary dictionaries;; - reduce dependencies / occasions to rebuild dictionaries, e.g. touch hist/hist/src/TH1.cxx and the dictionaries of libraries depending on libHist were rebuild, and so was the PCH. I see an issue with runtime_cxxmodules; let's see what Jenkins says!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3371
https://github.com/root-project/root/pull/3374:565,Availability,error,error,565,"It is fixing explicit C++ modules failing with:. `In file included from /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/root/core/imt/src/TThreadExecutor.cxx:8:; In file included from /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/build/include/tbb/tbb.h:76:; /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/build/include/tbb/recursive_mutex.h:54:47: error: declaration of 'PTHREAD_MUTEX_RECURSIVE' must be imported from module 'Imt.ROOT/TTaskGroup.hxx' before it is required; pthread_mutexattr_settype( &mtx_attr, PTHREAD_MUTEX_RECURSIVE );; ^; In module 'Imt' imported from /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/root/core/imt/src/TThreadExecutor.cxx:1:; /usr/include/pthread.h:51:3: note: previous declaration is here; PTHREAD_MUTEX_RECURSIVE = PTHREAD_MUTEX_RECURSIVE_NP,; ^; 1 error generated.`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3374
https://github.com/root-project/root/pull/3374:1076,Availability,error,error,1076,"It is fixing explicit C++ modules failing with:. `In file included from /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/root/core/imt/src/TThreadExecutor.cxx:8:; In file included from /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/build/include/tbb/tbb.h:76:; /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/build/include/tbb/recursive_mutex.h:54:47: error: declaration of 'PTHREAD_MUTEX_RECURSIVE' must be imported from module 'Imt.ROOT/TTaskGroup.hxx' before it is required; pthread_mutexattr_settype( &mtx_attr, PTHREAD_MUTEX_RECURSIVE );; ^; In module 'Imt' imported from /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/root/core/imt/src/TThreadExecutor.cxx:1:; /usr/include/pthread.h:51:3: note: previous declaration is here; PTHREAD_MUTEX_RECURSIVE = PTHREAD_MUTEX_RECURSIVE_NP,; ^; 1 error generated.`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3374
https://github.com/root-project/root/pull/3374:140,Deployability,Release,Release,140,"It is fixing explicit C++ modules failing with:. `In file included from /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/root/core/imt/src/TThreadExecutor.cxx:8:; In file included from /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/build/include/tbb/tbb.h:76:; /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/build/include/tbb/recursive_mutex.h:54:47: error: declaration of 'PTHREAD_MUTEX_RECURSIVE' must be imported from module 'Imt.ROOT/TTaskGroup.hxx' before it is required; pthread_mutexattr_settype( &mtx_attr, PTHREAD_MUTEX_RECURSIVE );; ^; In module 'Imt' imported from /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/root/core/imt/src/TThreadExecutor.cxx:1:; /usr/include/pthread.h:51:3: note: previous declaration is here; PTHREAD_MUTEX_RECURSIVE = PTHREAD_MUTEX_RECURSIVE_NP,; ^; 1 error generated.`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3374
https://github.com/root-project/root/pull/3374:323,Deployability,Release,Release,323,"It is fixing explicit C++ modules failing with:. `In file included from /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/root/core/imt/src/TThreadExecutor.cxx:8:; In file included from /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/build/include/tbb/tbb.h:76:; /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/build/include/tbb/recursive_mutex.h:54:47: error: declaration of 'PTHREAD_MUTEX_RECURSIVE' must be imported from module 'Imt.ROOT/TTaskGroup.hxx' before it is required; pthread_mutexattr_settype( &mtx_attr, PTHREAD_MUTEX_RECURSIVE );; ^; In module 'Imt' imported from /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/root/core/imt/src/TThreadExecutor.cxx:1:; /usr/include/pthread.h:51:3: note: previous declaration is here; PTHREAD_MUTEX_RECURSIVE = PTHREAD_MUTEX_RECURSIVE_NP,; ^; 1 error generated.`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3374
https://github.com/root-project/root/pull/3374:471,Deployability,Release,Release,471,"It is fixing explicit C++ modules failing with:. `In file included from /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/root/core/imt/src/TThreadExecutor.cxx:8:; In file included from /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/build/include/tbb/tbb.h:76:; /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/build/include/tbb/recursive_mutex.h:54:47: error: declaration of 'PTHREAD_MUTEX_RECURSIVE' must be imported from module 'Imt.ROOT/TTaskGroup.hxx' before it is required; pthread_mutexattr_settype( &mtx_attr, PTHREAD_MUTEX_RECURSIVE );; ^; In module 'Imt' imported from /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/root/core/imt/src/TThreadExecutor.cxx:1:; /usr/include/pthread.h:51:3: note: previous declaration is here; PTHREAD_MUTEX_RECURSIVE = PTHREAD_MUTEX_RECURSIVE_NP,; ^; 1 error generated.`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3374
https://github.com/root-project/root/pull/3374:858,Deployability,Release,Release,858,"It is fixing explicit C++ modules failing with:. `In file included from /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/root/core/imt/src/TThreadExecutor.cxx:8:; In file included from /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/build/include/tbb/tbb.h:76:; /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/build/include/tbb/recursive_mutex.h:54:47: error: declaration of 'PTHREAD_MUTEX_RECURSIVE' must be imported from module 'Imt.ROOT/TTaskGroup.hxx' before it is required; pthread_mutexattr_settype( &mtx_attr, PTHREAD_MUTEX_RECURSIVE );; ^; In module 'Imt' imported from /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/root/core/imt/src/TThreadExecutor.cxx:1:; /usr/include/pthread.h:51:3: note: previous declaration is here; PTHREAD_MUTEX_RECURSIVE = PTHREAD_MUTEX_RECURSIVE_NP,; ^; 1 error generated.`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3374
https://github.com/root-project/root/pull/3374:175,Performance,perform,performance-,175,"It is fixing explicit C++ modules failing with:. `In file included from /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/root/core/imt/src/TThreadExecutor.cxx:8:; In file included from /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/build/include/tbb/tbb.h:76:; /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/build/include/tbb/recursive_mutex.h:54:47: error: declaration of 'PTHREAD_MUTEX_RECURSIVE' must be imported from module 'Imt.ROOT/TTaskGroup.hxx' before it is required; pthread_mutexattr_settype( &mtx_attr, PTHREAD_MUTEX_RECURSIVE );; ^; In module 'Imt' imported from /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/root/core/imt/src/TThreadExecutor.cxx:1:; /usr/include/pthread.h:51:3: note: previous declaration is here; PTHREAD_MUTEX_RECURSIVE = PTHREAD_MUTEX_RECURSIVE_NP,; ^; 1 error generated.`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3374
https://github.com/root-project/root/pull/3374:358,Performance,perform,performance-,358,"It is fixing explicit C++ modules failing with:. `In file included from /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/root/core/imt/src/TThreadExecutor.cxx:8:; In file included from /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/build/include/tbb/tbb.h:76:; /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/build/include/tbb/recursive_mutex.h:54:47: error: declaration of 'PTHREAD_MUTEX_RECURSIVE' must be imported from module 'Imt.ROOT/TTaskGroup.hxx' before it is required; pthread_mutexattr_settype( &mtx_attr, PTHREAD_MUTEX_RECURSIVE );; ^; In module 'Imt' imported from /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/root/core/imt/src/TThreadExecutor.cxx:1:; /usr/include/pthread.h:51:3: note: previous declaration is here; PTHREAD_MUTEX_RECURSIVE = PTHREAD_MUTEX_RECURSIVE_NP,; ^; 1 error generated.`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3374
https://github.com/root-project/root/pull/3374:506,Performance,perform,performance-,506,"It is fixing explicit C++ modules failing with:. `In file included from /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/root/core/imt/src/TThreadExecutor.cxx:8:; In file included from /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/build/include/tbb/tbb.h:76:; /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/build/include/tbb/recursive_mutex.h:54:47: error: declaration of 'PTHREAD_MUTEX_RECURSIVE' must be imported from module 'Imt.ROOT/TTaskGroup.hxx' before it is required; pthread_mutexattr_settype( &mtx_attr, PTHREAD_MUTEX_RECURSIVE );; ^; In module 'Imt' imported from /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/root/core/imt/src/TThreadExecutor.cxx:1:; /usr/include/pthread.h:51:3: note: previous declaration is here; PTHREAD_MUTEX_RECURSIVE = PTHREAD_MUTEX_RECURSIVE_NP,; ^; 1 error generated.`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3374
https://github.com/root-project/root/pull/3374:893,Performance,perform,performance-,893,"It is fixing explicit C++ modules failing with:. `In file included from /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/root/core/imt/src/TThreadExecutor.cxx:8:; In file included from /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/build/include/tbb/tbb.h:76:; /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/build/include/tbb/recursive_mutex.h:54:47: error: declaration of 'PTHREAD_MUTEX_RECURSIVE' must be imported from module 'Imt.ROOT/TTaskGroup.hxx' before it is required; pthread_mutexattr_settype( &mtx_attr, PTHREAD_MUTEX_RECURSIVE );; ^; In module 'Imt' imported from /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/root/core/imt/src/TThreadExecutor.cxx:1:; /usr/include/pthread.h:51:3: note: previous declaration is here; PTHREAD_MUTEX_RECURSIVE = PTHREAD_MUTEX_RECURSIVE_NP,; ^; 1 error generated.`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3374
https://github.com/root-project/root/pull/3374:102,Testability,benchmark,benchmark-compile-cxxmodule,102,"It is fixing explicit C++ modules failing with:. `In file included from /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/root/core/imt/src/TThreadExecutor.cxx:8:; In file included from /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/build/include/tbb/tbb.h:76:; /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/build/include/tbb/recursive_mutex.h:54:47: error: declaration of 'PTHREAD_MUTEX_RECURSIVE' must be imported from module 'Imt.ROOT/TTaskGroup.hxx' before it is required; pthread_mutexattr_settype( &mtx_attr, PTHREAD_MUTEX_RECURSIVE );; ^; In module 'Imt' imported from /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/root/core/imt/src/TThreadExecutor.cxx:1:; /usr/include/pthread.h:51:3: note: previous declaration is here; PTHREAD_MUTEX_RECURSIVE = PTHREAD_MUTEX_RECURSIVE_NP,; ^; 1 error generated.`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3374
https://github.com/root-project/root/pull/3374:285,Testability,benchmark,benchmark-compile-cxxmodule,285,"It is fixing explicit C++ modules failing with:. `In file included from /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/root/core/imt/src/TThreadExecutor.cxx:8:; In file included from /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/build/include/tbb/tbb.h:76:; /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/build/include/tbb/recursive_mutex.h:54:47: error: declaration of 'PTHREAD_MUTEX_RECURSIVE' must be imported from module 'Imt.ROOT/TTaskGroup.hxx' before it is required; pthread_mutexattr_settype( &mtx_attr, PTHREAD_MUTEX_RECURSIVE );; ^; In module 'Imt' imported from /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/root/core/imt/src/TThreadExecutor.cxx:1:; /usr/include/pthread.h:51:3: note: previous declaration is here; PTHREAD_MUTEX_RECURSIVE = PTHREAD_MUTEX_RECURSIVE_NP,; ^; 1 error generated.`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3374
https://github.com/root-project/root/pull/3374:433,Testability,benchmark,benchmark-compile-cxxmodule,433,"It is fixing explicit C++ modules failing with:. `In file included from /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/root/core/imt/src/TThreadExecutor.cxx:8:; In file included from /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/build/include/tbb/tbb.h:76:; /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/build/include/tbb/recursive_mutex.h:54:47: error: declaration of 'PTHREAD_MUTEX_RECURSIVE' must be imported from module 'Imt.ROOT/TTaskGroup.hxx' before it is required; pthread_mutexattr_settype( &mtx_attr, PTHREAD_MUTEX_RECURSIVE );; ^; In module 'Imt' imported from /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/root/core/imt/src/TThreadExecutor.cxx:1:; /usr/include/pthread.h:51:3: note: previous declaration is here; PTHREAD_MUTEX_RECURSIVE = PTHREAD_MUTEX_RECURSIVE_NP,; ^; 1 error generated.`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3374
https://github.com/root-project/root/pull/3374:820,Testability,benchmark,benchmark-compile-cxxmodule,820,"It is fixing explicit C++ modules failing with:. `In file included from /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/root/core/imt/src/TThreadExecutor.cxx:8:; In file included from /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/build/include/tbb/tbb.h:76:; /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/build/include/tbb/recursive_mutex.h:54:47: error: declaration of 'PTHREAD_MUTEX_RECURSIVE' must be imported from module 'Imt.ROOT/TTaskGroup.hxx' before it is required; pthread_mutexattr_settype( &mtx_attr, PTHREAD_MUTEX_RECURSIVE );; ^; In module 'Imt' imported from /data/sftnight/workspace/root-benchmark-compile-cxxmodule/BUILDTYPE/Release/COMPILER/clang_gcc62/LABEL/performance-cc7/root/core/imt/src/TThreadExecutor.cxx:1:; /usr/include/pthread.h:51:3: note: previous declaration is here; PTHREAD_MUTEX_RECURSIVE = PTHREAD_MUTEX_RECURSIVE_NP,; ^; 1 error generated.`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3374
https://github.com/root-project/root/pull/3379:37,Availability,failure,failures,37,"The unit test for RooWorkspace tests failures when importing models into the workspace.; Since RooFit will print `ERROR` messages, it looks like there is a problem in the test.; The error messages are now silenced.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3379
https://github.com/root-project/root/pull/3379:114,Availability,ERROR,ERROR,114,"The unit test for RooWorkspace tests failures when importing models into the workspace.; Since RooFit will print `ERROR` messages, it looks like there is a problem in the test.; The error messages are now silenced.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3379
https://github.com/root-project/root/pull/3379:182,Availability,error,error,182,"The unit test for RooWorkspace tests failures when importing models into the workspace.; Since RooFit will print `ERROR` messages, it looks like there is a problem in the test.; The error messages are now silenced.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3379
https://github.com/root-project/root/pull/3379:121,Integrability,message,messages,121,"The unit test for RooWorkspace tests failures when importing models into the workspace.; Since RooFit will print `ERROR` messages, it looks like there is a problem in the test.; The error messages are now silenced.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3379
https://github.com/root-project/root/pull/3379:188,Integrability,message,messages,188,"The unit test for RooWorkspace tests failures when importing models into the workspace.; Since RooFit will print `ERROR` messages, it looks like there is a problem in the test.; The error messages are now silenced.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3379
https://github.com/root-project/root/pull/3379:9,Testability,test,test,9,"The unit test for RooWorkspace tests failures when importing models into the workspace.; Since RooFit will print `ERROR` messages, it looks like there is a problem in the test.; The error messages are now silenced.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3379
https://github.com/root-project/root/pull/3379:31,Testability,test,tests,31,"The unit test for RooWorkspace tests failures when importing models into the workspace.; Since RooFit will print `ERROR` messages, it looks like there is a problem in the test.; The error messages are now silenced.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3379
https://github.com/root-project/root/pull/3379:171,Testability,test,test,171,"The unit test for RooWorkspace tests failures when importing models into the workspace.; Since RooFit will print `ERROR` messages, it looks like there is a problem in the test.; The error messages are now silenced.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3379
https://github.com/root-project/root/pull/3380:654,Availability,failure,failures,654,"Replace the RooLinkedList in the central collections of RooFit (RooArgSet, RooArgList, RooRefCountList) with a std::vector. This speeds up the tutorials of RooFit/RooStats by 10 to 20 %.; The interface with respect to iterators and size() now resembles an STL container. When iterating on the updated collections, only begin(), end() and range-based for loops should be used. The legacy RooFit iterators are still supported, but should not be used, since they are slower. They were flagged with the R__SUGGEST_ALTERNATIVE macro. This PR is identical to #3345, but more improvements were added on top of the branch used there. This is to test if the test failures on centos7 persist.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3380
https://github.com/root-project/root/pull/3380:293,Deployability,update,updated,293,"Replace the RooLinkedList in the central collections of RooFit (RooArgSet, RooArgList, RooRefCountList) with a std::vector. This speeds up the tutorials of RooFit/RooStats by 10 to 20 %.; The interface with respect to iterators and size() now resembles an STL container. When iterating on the updated collections, only begin(), end() and range-based for loops should be used. The legacy RooFit iterators are still supported, but should not be used, since they are slower. They were flagged with the R__SUGGEST_ALTERNATIVE macro. This PR is identical to #3345, but more improvements were added on top of the branch used there. This is to test if the test failures on centos7 persist.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3380
https://github.com/root-project/root/pull/3380:192,Integrability,interface,interface,192,"Replace the RooLinkedList in the central collections of RooFit (RooArgSet, RooArgList, RooRefCountList) with a std::vector. This speeds up the tutorials of RooFit/RooStats by 10 to 20 %.; The interface with respect to iterators and size() now resembles an STL container. When iterating on the updated collections, only begin(), end() and range-based for loops should be used. The legacy RooFit iterators are still supported, but should not be used, since they are slower. They were flagged with the R__SUGGEST_ALTERNATIVE macro. This PR is identical to #3345, but more improvements were added on top of the branch used there. This is to test if the test failures on centos7 persist.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3380
https://github.com/root-project/root/pull/3380:637,Testability,test,test,637,"Replace the RooLinkedList in the central collections of RooFit (RooArgSet, RooArgList, RooRefCountList) with a std::vector. This speeds up the tutorials of RooFit/RooStats by 10 to 20 %.; The interface with respect to iterators and size() now resembles an STL container. When iterating on the updated collections, only begin(), end() and range-based for loops should be used. The legacy RooFit iterators are still supported, but should not be used, since they are slower. They were flagged with the R__SUGGEST_ALTERNATIVE macro. This PR is identical to #3345, but more improvements were added on top of the branch used there. This is to test if the test failures on centos7 persist.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3380
https://github.com/root-project/root/pull/3380:649,Testability,test,test,649,"Replace the RooLinkedList in the central collections of RooFit (RooArgSet, RooArgList, RooRefCountList) with a std::vector. This speeds up the tutorials of RooFit/RooStats by 10 to 20 %.; The interface with respect to iterators and size() now resembles an STL container. When iterating on the updated collections, only begin(), end() and range-based for loops should be used. The legacy RooFit iterators are still supported, but should not be used, since they are slower. They were flagged with the R__SUGGEST_ALTERNATIVE macro. This PR is identical to #3345, but more improvements were added on top of the branch used there. This is to test if the test failures on centos7 persist.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3380
https://github.com/root-project/root/pull/3381:121,Deployability,patch,patch,121,Both of these directories are needed if you have a non-standard location for LibXML2's needs. This is currently a manual patch in the root-feedstock for conda-forge. See <https://github.com/Kitware/CMake/blob/master/Modules/FindLibXml2.cmake>.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3381
https://github.com/root-project/root/pull/3382:0,Deployability,Patch,Patch,0,Patch fixes a ROOT binary distribution of clad for 6.16.02,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3382
https://github.com/root-project/root/pull/3385:354,Availability,fault,faults,354,"Here is some performance information for the reproducer code attached to [ROOT-9133](https://sft.its.cern.ch/jira/browse/ROOT-9133):. **perf stat (before)**; ```; Performance counter stats for 'root-9133':. 135566.779101 task-clock (msec) # 4.167 CPUs utilized ; 481,078 context-switches # 0.004 M/sec ; 710 cpu-migrations # 0.005 K/sec ; 3,512,992 page-faults # 0.026 M/sec ; 456,851,617,713 cycles # 3.370 GHz ; 310,271,051,553 instructions # 0.68 insn per cycle ; 65,664,345,345 branches # 484.369 M/sec ; 723,033,852 branch-misses # 1.10% of all branches . 32.535328793 seconds time elapsed; ```; **perf stat (after)**; ```; Performance counter stats for 'root-9133':. 115840.232563 task-clock (msec) # 6.254 CPUs utilized ; 343,733 context-switches # 0.003 M/sec ; 327 cpu-migrations # 0.003 K/sec ; 1,567,401 page-faults # 0.014 M/sec ; 391,763,587,760 cycles # 3.382 GHz ; 273,699,878,762 instructions # 0.70 insn per cycle ; 57,799,809,349 branches # 498.961 M/sec ; 635,168,730 branch-misses # 1.10% of all branches . 18.522277829 seconds time elapsed; ```; *Note the reduced number of cpu-migrations, page-faults, and context switches, as well as lower runtime.*. **massif (before)**; ![screenshot](https://user-images.githubusercontent.com/249404/52358705-ca2d1c80-2a38-11e9-823e-ea35219fbca1.png); ![screenshot](https://user-images.githubusercontent.com/249404/52359262-d5cd1300-2a39-11e9-8159-73730cbd79e6.png). **massif (after)**; ![screenshot](https://user-images.githubusercontent.com/249404/52358746-db762900-2a38-11e9-9f63-5d2340860f4d.png); ![screenshot](https://user-images.githubusercontent.com/249404/52359437-30666f00-2a3a-11e9-94ed-67dfad3cdbec.png); *Note how `TBuffer::Expand()` goes from 1.8GB allocated memory down to just ~50MB. Also, total memory used drops from 3.8GB to 3.1GB. The size of the output file is 3.1GB. The total amount of used memory is still high since tasks are accumulating large chunks of data into the `TBufferMergerFile`s before calling `Write()` to ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:820,Availability,fault,faults,820,"Here is some performance information for the reproducer code attached to [ROOT-9133](https://sft.its.cern.ch/jira/browse/ROOT-9133):. **perf stat (before)**; ```; Performance counter stats for 'root-9133':. 135566.779101 task-clock (msec) # 4.167 CPUs utilized ; 481,078 context-switches # 0.004 M/sec ; 710 cpu-migrations # 0.005 K/sec ; 3,512,992 page-faults # 0.026 M/sec ; 456,851,617,713 cycles # 3.370 GHz ; 310,271,051,553 instructions # 0.68 insn per cycle ; 65,664,345,345 branches # 484.369 M/sec ; 723,033,852 branch-misses # 1.10% of all branches . 32.535328793 seconds time elapsed; ```; **perf stat (after)**; ```; Performance counter stats for 'root-9133':. 115840.232563 task-clock (msec) # 6.254 CPUs utilized ; 343,733 context-switches # 0.003 M/sec ; 327 cpu-migrations # 0.003 K/sec ; 1,567,401 page-faults # 0.014 M/sec ; 391,763,587,760 cycles # 3.382 GHz ; 273,699,878,762 instructions # 0.70 insn per cycle ; 57,799,809,349 branches # 498.961 M/sec ; 635,168,730 branch-misses # 1.10% of all branches . 18.522277829 seconds time elapsed; ```; *Note the reduced number of cpu-migrations, page-faults, and context switches, as well as lower runtime.*. **massif (before)**; ![screenshot](https://user-images.githubusercontent.com/249404/52358705-ca2d1c80-2a38-11e9-823e-ea35219fbca1.png); ![screenshot](https://user-images.githubusercontent.com/249404/52359262-d5cd1300-2a39-11e9-8159-73730cbd79e6.png). **massif (after)**; ![screenshot](https://user-images.githubusercontent.com/249404/52358746-db762900-2a38-11e9-9f63-5d2340860f4d.png); ![screenshot](https://user-images.githubusercontent.com/249404/52359437-30666f00-2a3a-11e9-94ed-67dfad3cdbec.png); *Note how `TBuffer::Expand()` goes from 1.8GB allocated memory down to just ~50MB. Also, total memory used drops from 3.8GB to 3.1GB. The size of the output file is 3.1GB. The total amount of used memory is still high since tasks are accumulating large chunks of data into the `TBufferMergerFile`s before calling `Write()` to ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:1116,Availability,fault,faults,1116,".cern.ch/jira/browse/ROOT-9133):. **perf stat (before)**; ```; Performance counter stats for 'root-9133':. 135566.779101 task-clock (msec) # 4.167 CPUs utilized ; 481,078 context-switches # 0.004 M/sec ; 710 cpu-migrations # 0.005 K/sec ; 3,512,992 page-faults # 0.026 M/sec ; 456,851,617,713 cycles # 3.370 GHz ; 310,271,051,553 instructions # 0.68 insn per cycle ; 65,664,345,345 branches # 484.369 M/sec ; 723,033,852 branch-misses # 1.10% of all branches . 32.535328793 seconds time elapsed; ```; **perf stat (after)**; ```; Performance counter stats for 'root-9133':. 115840.232563 task-clock (msec) # 6.254 CPUs utilized ; 343,733 context-switches # 0.003 M/sec ; 327 cpu-migrations # 0.003 K/sec ; 1,567,401 page-faults # 0.014 M/sec ; 391,763,587,760 cycles # 3.382 GHz ; 273,699,878,762 instructions # 0.70 insn per cycle ; 57,799,809,349 branches # 498.961 M/sec ; 635,168,730 branch-misses # 1.10% of all branches . 18.522277829 seconds time elapsed; ```; *Note the reduced number of cpu-migrations, page-faults, and context switches, as well as lower runtime.*. **massif (before)**; ![screenshot](https://user-images.githubusercontent.com/249404/52358705-ca2d1c80-2a38-11e9-823e-ea35219fbca1.png); ![screenshot](https://user-images.githubusercontent.com/249404/52359262-d5cd1300-2a39-11e9-8159-73730cbd79e6.png). **massif (after)**; ![screenshot](https://user-images.githubusercontent.com/249404/52358746-db762900-2a38-11e9-9f63-5d2340860f4d.png); ![screenshot](https://user-images.githubusercontent.com/249404/52359437-30666f00-2a3a-11e9-94ed-67dfad3cdbec.png); *Note how `TBuffer::Expand()` goes from 1.8GB allocated memory down to just ~50MB. Also, total memory used drops from 3.8GB to 3.1GB. The size of the output file is 3.1GB. The total amount of used memory is still high since tasks are accumulating large chunks of data into the `TBufferMergerFile`s before calling `Write()` to get it flushed out. We need to break the total run into more tasks or call `Write()` more often to f",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:1738,Availability,down,down,1738,"3):. **perf stat (before)**; ```; Performance counter stats for 'root-9133':. 135566.779101 task-clock (msec) # 4.167 CPUs utilized ; 481,078 context-switches # 0.004 M/sec ; 710 cpu-migrations # 0.005 K/sec ; 3,512,992 page-faults # 0.026 M/sec ; 456,851,617,713 cycles # 3.370 GHz ; 310,271,051,553 instructions # 0.68 insn per cycle ; 65,664,345,345 branches # 484.369 M/sec ; 723,033,852 branch-misses # 1.10% of all branches . 32.535328793 seconds time elapsed; ```; **perf stat (after)**; ```; Performance counter stats for 'root-9133':. 115840.232563 task-clock (msec) # 6.254 CPUs utilized ; 343,733 context-switches # 0.003 M/sec ; 327 cpu-migrations # 0.003 K/sec ; 1,567,401 page-faults # 0.014 M/sec ; 391,763,587,760 cycles # 3.382 GHz ; 273,699,878,762 instructions # 0.70 insn per cycle ; 57,799,809,349 branches # 498.961 M/sec ; 635,168,730 branch-misses # 1.10% of all branches . 18.522277829 seconds time elapsed; ```; *Note the reduced number of cpu-migrations, page-faults, and context switches, as well as lower runtime.*. **massif (before)**; ![screenshot](https://user-images.githubusercontent.com/249404/52358705-ca2d1c80-2a38-11e9-823e-ea35219fbca1.png); ![screenshot](https://user-images.githubusercontent.com/249404/52359262-d5cd1300-2a39-11e9-8159-73730cbd79e6.png). **massif (after)**; ![screenshot](https://user-images.githubusercontent.com/249404/52358746-db762900-2a38-11e9-9f63-5d2340860f4d.png); ![screenshot](https://user-images.githubusercontent.com/249404/52359437-30666f00-2a3a-11e9-94ed-67dfad3cdbec.png); *Note how `TBuffer::Expand()` goes from 1.8GB allocated memory down to just ~50MB. Also, total memory used drops from 3.8GB to 3.1GB. The size of the output file is 3.1GB. The total amount of used memory is still high since tasks are accumulating large chunks of data into the `TBufferMergerFile`s before calling `Write()` to get it flushed out. We need to break the total run into more tasks or call `Write()` more often to further reduce memory usage.*",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:1077,Energy Efficiency,reduce,reduced,1077,".cern.ch/jira/browse/ROOT-9133):. **perf stat (before)**; ```; Performance counter stats for 'root-9133':. 135566.779101 task-clock (msec) # 4.167 CPUs utilized ; 481,078 context-switches # 0.004 M/sec ; 710 cpu-migrations # 0.005 K/sec ; 3,512,992 page-faults # 0.026 M/sec ; 456,851,617,713 cycles # 3.370 GHz ; 310,271,051,553 instructions # 0.68 insn per cycle ; 65,664,345,345 branches # 484.369 M/sec ; 723,033,852 branch-misses # 1.10% of all branches . 32.535328793 seconds time elapsed; ```; **perf stat (after)**; ```; Performance counter stats for 'root-9133':. 115840.232563 task-clock (msec) # 6.254 CPUs utilized ; 343,733 context-switches # 0.003 M/sec ; 327 cpu-migrations # 0.003 K/sec ; 1,567,401 page-faults # 0.014 M/sec ; 391,763,587,760 cycles # 3.382 GHz ; 273,699,878,762 instructions # 0.70 insn per cycle ; 57,799,809,349 branches # 498.961 M/sec ; 635,168,730 branch-misses # 1.10% of all branches . 18.522277829 seconds time elapsed; ```; *Note the reduced number of cpu-migrations, page-faults, and context switches, as well as lower runtime.*. **massif (before)**; ![screenshot](https://user-images.githubusercontent.com/249404/52358705-ca2d1c80-2a38-11e9-823e-ea35219fbca1.png); ![screenshot](https://user-images.githubusercontent.com/249404/52359262-d5cd1300-2a39-11e9-8159-73730cbd79e6.png). **massif (after)**; ![screenshot](https://user-images.githubusercontent.com/249404/52358746-db762900-2a38-11e9-9f63-5d2340860f4d.png); ![screenshot](https://user-images.githubusercontent.com/249404/52359437-30666f00-2a3a-11e9-94ed-67dfad3cdbec.png); *Note how `TBuffer::Expand()` goes from 1.8GB allocated memory down to just ~50MB. Also, total memory used drops from 3.8GB to 3.1GB. The size of the output file is 3.1GB. The total amount of used memory is still high since tasks are accumulating large chunks of data into the `TBufferMergerFile`s before calling `Write()` to get it flushed out. We need to break the total run into more tasks or call `Write()` more often to f",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:1721,Energy Efficiency,allocate,allocated,1721,"3):. **perf stat (before)**; ```; Performance counter stats for 'root-9133':. 135566.779101 task-clock (msec) # 4.167 CPUs utilized ; 481,078 context-switches # 0.004 M/sec ; 710 cpu-migrations # 0.005 K/sec ; 3,512,992 page-faults # 0.026 M/sec ; 456,851,617,713 cycles # 3.370 GHz ; 310,271,051,553 instructions # 0.68 insn per cycle ; 65,664,345,345 branches # 484.369 M/sec ; 723,033,852 branch-misses # 1.10% of all branches . 32.535328793 seconds time elapsed; ```; **perf stat (after)**; ```; Performance counter stats for 'root-9133':. 115840.232563 task-clock (msec) # 6.254 CPUs utilized ; 343,733 context-switches # 0.003 M/sec ; 327 cpu-migrations # 0.003 K/sec ; 1,567,401 page-faults # 0.014 M/sec ; 391,763,587,760 cycles # 3.382 GHz ; 273,699,878,762 instructions # 0.70 insn per cycle ; 57,799,809,349 branches # 498.961 M/sec ; 635,168,730 branch-misses # 1.10% of all branches . 18.522277829 seconds time elapsed; ```; *Note the reduced number of cpu-migrations, page-faults, and context switches, as well as lower runtime.*. **massif (before)**; ![screenshot](https://user-images.githubusercontent.com/249404/52358705-ca2d1c80-2a38-11e9-823e-ea35219fbca1.png); ![screenshot](https://user-images.githubusercontent.com/249404/52359262-d5cd1300-2a39-11e9-8159-73730cbd79e6.png). **massif (after)**; ![screenshot](https://user-images.githubusercontent.com/249404/52358746-db762900-2a38-11e9-9f63-5d2340860f4d.png); ![screenshot](https://user-images.githubusercontent.com/249404/52359437-30666f00-2a3a-11e9-94ed-67dfad3cdbec.png); *Note how `TBuffer::Expand()` goes from 1.8GB allocated memory down to just ~50MB. Also, total memory used drops from 3.8GB to 3.1GB. The size of the output file is 3.1GB. The total amount of used memory is still high since tasks are accumulating large chunks of data into the `TBufferMergerFile`s before calling `Write()` to get it flushed out. We need to break the total run into more tasks or call `Write()` more often to further reduce memory usage.*",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:2108,Energy Efficiency,reduce,reduce,2108,"3):. **perf stat (before)**; ```; Performance counter stats for 'root-9133':. 135566.779101 task-clock (msec) # 4.167 CPUs utilized ; 481,078 context-switches # 0.004 M/sec ; 710 cpu-migrations # 0.005 K/sec ; 3,512,992 page-faults # 0.026 M/sec ; 456,851,617,713 cycles # 3.370 GHz ; 310,271,051,553 instructions # 0.68 insn per cycle ; 65,664,345,345 branches # 484.369 M/sec ; 723,033,852 branch-misses # 1.10% of all branches . 32.535328793 seconds time elapsed; ```; **perf stat (after)**; ```; Performance counter stats for 'root-9133':. 115840.232563 task-clock (msec) # 6.254 CPUs utilized ; 343,733 context-switches # 0.003 M/sec ; 327 cpu-migrations # 0.003 K/sec ; 1,567,401 page-faults # 0.014 M/sec ; 391,763,587,760 cycles # 3.382 GHz ; 273,699,878,762 instructions # 0.70 insn per cycle ; 57,799,809,349 branches # 498.961 M/sec ; 635,168,730 branch-misses # 1.10% of all branches . 18.522277829 seconds time elapsed; ```; *Note the reduced number of cpu-migrations, page-faults, and context switches, as well as lower runtime.*. **massif (before)**; ![screenshot](https://user-images.githubusercontent.com/249404/52358705-ca2d1c80-2a38-11e9-823e-ea35219fbca1.png); ![screenshot](https://user-images.githubusercontent.com/249404/52359262-d5cd1300-2a39-11e9-8159-73730cbd79e6.png). **massif (after)**; ![screenshot](https://user-images.githubusercontent.com/249404/52358746-db762900-2a38-11e9-9f63-5d2340860f4d.png); ![screenshot](https://user-images.githubusercontent.com/249404/52359437-30666f00-2a3a-11e9-94ed-67dfad3cdbec.png); *Note how `TBuffer::Expand()` goes from 1.8GB allocated memory down to just ~50MB. Also, total memory used drops from 3.8GB to 3.1GB. The size of the output file is 3.1GB. The total amount of used memory is still high since tasks are accumulating large chunks of data into the `TBufferMergerFile`s before calling `Write()` to get it flushed out. We need to break the total run into more tasks or call `Write()` more often to further reduce memory usage.*",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:13,Performance,perform,performance,13,"Here is some performance information for the reproducer code attached to [ROOT-9133](https://sft.its.cern.ch/jira/browse/ROOT-9133):. **perf stat (before)**; ```; Performance counter stats for 'root-9133':. 135566.779101 task-clock (msec) # 4.167 CPUs utilized ; 481,078 context-switches # 0.004 M/sec ; 710 cpu-migrations # 0.005 K/sec ; 3,512,992 page-faults # 0.026 M/sec ; 456,851,617,713 cycles # 3.370 GHz ; 310,271,051,553 instructions # 0.68 insn per cycle ; 65,664,345,345 branches # 484.369 M/sec ; 723,033,852 branch-misses # 1.10% of all branches . 32.535328793 seconds time elapsed; ```; **perf stat (after)**; ```; Performance counter stats for 'root-9133':. 115840.232563 task-clock (msec) # 6.254 CPUs utilized ; 343,733 context-switches # 0.003 M/sec ; 327 cpu-migrations # 0.003 K/sec ; 1,567,401 page-faults # 0.014 M/sec ; 391,763,587,760 cycles # 3.382 GHz ; 273,699,878,762 instructions # 0.70 insn per cycle ; 57,799,809,349 branches # 498.961 M/sec ; 635,168,730 branch-misses # 1.10% of all branches . 18.522277829 seconds time elapsed; ```; *Note the reduced number of cpu-migrations, page-faults, and context switches, as well as lower runtime.*. **massif (before)**; ![screenshot](https://user-images.githubusercontent.com/249404/52358705-ca2d1c80-2a38-11e9-823e-ea35219fbca1.png); ![screenshot](https://user-images.githubusercontent.com/249404/52359262-d5cd1300-2a39-11e9-8159-73730cbd79e6.png). **massif (after)**; ![screenshot](https://user-images.githubusercontent.com/249404/52358746-db762900-2a38-11e9-9f63-5d2340860f4d.png); ![screenshot](https://user-images.githubusercontent.com/249404/52359437-30666f00-2a3a-11e9-94ed-67dfad3cdbec.png); *Note how `TBuffer::Expand()` goes from 1.8GB allocated memory down to just ~50MB. Also, total memory used drops from 3.8GB to 3.1GB. The size of the output file is 3.1GB. The total amount of used memory is still high since tasks are accumulating large chunks of data into the `TBufferMergerFile`s before calling `Write()` to ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:163,Performance,Perform,Performance,163,"Here is some performance information for the reproducer code attached to [ROOT-9133](https://sft.its.cern.ch/jira/browse/ROOT-9133):. **perf stat (before)**; ```; Performance counter stats for 'root-9133':. 135566.779101 task-clock (msec) # 4.167 CPUs utilized ; 481,078 context-switches # 0.004 M/sec ; 710 cpu-migrations # 0.005 K/sec ; 3,512,992 page-faults # 0.026 M/sec ; 456,851,617,713 cycles # 3.370 GHz ; 310,271,051,553 instructions # 0.68 insn per cycle ; 65,664,345,345 branches # 484.369 M/sec ; 723,033,852 branch-misses # 1.10% of all branches . 32.535328793 seconds time elapsed; ```; **perf stat (after)**; ```; Performance counter stats for 'root-9133':. 115840.232563 task-clock (msec) # 6.254 CPUs utilized ; 343,733 context-switches # 0.003 M/sec ; 327 cpu-migrations # 0.003 K/sec ; 1,567,401 page-faults # 0.014 M/sec ; 391,763,587,760 cycles # 3.382 GHz ; 273,699,878,762 instructions # 0.70 insn per cycle ; 57,799,809,349 branches # 498.961 M/sec ; 635,168,730 branch-misses # 1.10% of all branches . 18.522277829 seconds time elapsed; ```; *Note the reduced number of cpu-migrations, page-faults, and context switches, as well as lower runtime.*. **massif (before)**; ![screenshot](https://user-images.githubusercontent.com/249404/52358705-ca2d1c80-2a38-11e9-823e-ea35219fbca1.png); ![screenshot](https://user-images.githubusercontent.com/249404/52359262-d5cd1300-2a39-11e9-8159-73730cbd79e6.png). **massif (after)**; ![screenshot](https://user-images.githubusercontent.com/249404/52358746-db762900-2a38-11e9-9f63-5d2340860f4d.png); ![screenshot](https://user-images.githubusercontent.com/249404/52359437-30666f00-2a3a-11e9-94ed-67dfad3cdbec.png); *Note how `TBuffer::Expand()` goes from 1.8GB allocated memory down to just ~50MB. Also, total memory used drops from 3.8GB to 3.1GB. The size of the output file is 3.1GB. The total amount of used memory is still high since tasks are accumulating large chunks of data into the `TBufferMergerFile`s before calling `Write()` to ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3385:629,Performance,Perform,Performance,629,"Here is some performance information for the reproducer code attached to [ROOT-9133](https://sft.its.cern.ch/jira/browse/ROOT-9133):. **perf stat (before)**; ```; Performance counter stats for 'root-9133':. 135566.779101 task-clock (msec) # 4.167 CPUs utilized ; 481,078 context-switches # 0.004 M/sec ; 710 cpu-migrations # 0.005 K/sec ; 3,512,992 page-faults # 0.026 M/sec ; 456,851,617,713 cycles # 3.370 GHz ; 310,271,051,553 instructions # 0.68 insn per cycle ; 65,664,345,345 branches # 484.369 M/sec ; 723,033,852 branch-misses # 1.10% of all branches . 32.535328793 seconds time elapsed; ```; **perf stat (after)**; ```; Performance counter stats for 'root-9133':. 115840.232563 task-clock (msec) # 6.254 CPUs utilized ; 343,733 context-switches # 0.003 M/sec ; 327 cpu-migrations # 0.003 K/sec ; 1,567,401 page-faults # 0.014 M/sec ; 391,763,587,760 cycles # 3.382 GHz ; 273,699,878,762 instructions # 0.70 insn per cycle ; 57,799,809,349 branches # 498.961 M/sec ; 635,168,730 branch-misses # 1.10% of all branches . 18.522277829 seconds time elapsed; ```; *Note the reduced number of cpu-migrations, page-faults, and context switches, as well as lower runtime.*. **massif (before)**; ![screenshot](https://user-images.githubusercontent.com/249404/52358705-ca2d1c80-2a38-11e9-823e-ea35219fbca1.png); ![screenshot](https://user-images.githubusercontent.com/249404/52359262-d5cd1300-2a39-11e9-8159-73730cbd79e6.png). **massif (after)**; ![screenshot](https://user-images.githubusercontent.com/249404/52358746-db762900-2a38-11e9-9f63-5d2340860f4d.png); ![screenshot](https://user-images.githubusercontent.com/249404/52359437-30666f00-2a3a-11e9-94ed-67dfad3cdbec.png); *Note how `TBuffer::Expand()` goes from 1.8GB allocated memory down to just ~50MB. Also, total memory used drops from 3.8GB to 3.1GB. The size of the output file is 3.1GB. The total amount of used memory is still high since tasks are accumulating large chunks of data into the `TBufferMergerFile`s before calling `Write()` to ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3385
https://github.com/root-project/root/pull/3387:83,Integrability,Inject,Injection,83,"This PR adds two sets of pythonizations to `TSeqCollection` and its subclasses:; - Injection of item access methods (`__getitem__`, `__setitem__`, `__delitem__`), both for integer indices and slices.; - Injection of Python-list-like methods (`insert`, `pop`, `reverse`, `sort`, `index`). The PR also includes the corresponding unit tests.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3387
https://github.com/root-project/root/pull/3387:203,Integrability,Inject,Injection,203,"This PR adds two sets of pythonizations to `TSeqCollection` and its subclasses:; - Injection of item access methods (`__getitem__`, `__setitem__`, `__delitem__`), both for integer indices and slices.; - Injection of Python-list-like methods (`insert`, `pop`, `reverse`, `sort`, `index`). The PR also includes the corresponding unit tests.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3387
https://github.com/root-project/root/pull/3387:83,Security,Inject,Injection,83,"This PR adds two sets of pythonizations to `TSeqCollection` and its subclasses:; - Injection of item access methods (`__getitem__`, `__setitem__`, `__delitem__`), both for integer indices and slices.; - Injection of Python-list-like methods (`insert`, `pop`, `reverse`, `sort`, `index`). The PR also includes the corresponding unit tests.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3387
https://github.com/root-project/root/pull/3387:101,Security,access,access,101,"This PR adds two sets of pythonizations to `TSeqCollection` and its subclasses:; - Injection of item access methods (`__getitem__`, `__setitem__`, `__delitem__`), both for integer indices and slices.; - Injection of Python-list-like methods (`insert`, `pop`, `reverse`, `sort`, `index`). The PR also includes the corresponding unit tests.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3387
https://github.com/root-project/root/pull/3387:203,Security,Inject,Injection,203,"This PR adds two sets of pythonizations to `TSeqCollection` and its subclasses:; - Injection of item access methods (`__getitem__`, `__setitem__`, `__delitem__`), both for integer indices and slices.; - Injection of Python-list-like methods (`insert`, `pop`, `reverse`, `sort`, `index`). The PR also includes the corresponding unit tests.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3387
https://github.com/root-project/root/pull/3387:332,Testability,test,tests,332,"This PR adds two sets of pythonizations to `TSeqCollection` and its subclasses:; - Injection of item access methods (`__getitem__`, `__setitem__`, `__delitem__`), both for integer indices and slices.; - Injection of Python-list-like methods (`insert`, `pop`, `reverse`, `sort`, `index`). The PR also includes the corresponding unit tests.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3387
https://github.com/root-project/root/pull/3389:210,Availability,error,error,210,"If not built with the same compiler, CMAKE_CXX_FLAGS may contain flags not known by the default compiler, which will make the test fail. In particular using Ninja + Clang on Linux makes this test fail with the error below without this patch.; ```; c++: error: unrecognized command line option ‘-fcolor-diagnostics’; ninja: build stopped: subcommand failed.; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3389
https://github.com/root-project/root/pull/3389:253,Availability,error,error,253,"If not built with the same compiler, CMAKE_CXX_FLAGS may contain flags not known by the default compiler, which will make the test fail. In particular using Ninja + Clang on Linux makes this test fail with the error below without this patch.; ```; c++: error: unrecognized command line option ‘-fcolor-diagnostics’; ninja: build stopped: subcommand failed.; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3389
https://github.com/root-project/root/pull/3389:235,Deployability,patch,patch,235,"If not built with the same compiler, CMAKE_CXX_FLAGS may contain flags not known by the default compiler, which will make the test fail. In particular using Ninja + Clang on Linux makes this test fail with the error below without this patch.; ```; c++: error: unrecognized command line option ‘-fcolor-diagnostics’; ninja: build stopped: subcommand failed.; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3389
https://github.com/root-project/root/pull/3389:126,Testability,test,test,126,"If not built with the same compiler, CMAKE_CXX_FLAGS may contain flags not known by the default compiler, which will make the test fail. In particular using Ninja + Clang on Linux makes this test fail with the error below without this patch.; ```; c++: error: unrecognized command line option ‘-fcolor-diagnostics’; ninja: build stopped: subcommand failed.; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3389
https://github.com/root-project/root/pull/3389:191,Testability,test,test,191,"If not built with the same compiler, CMAKE_CXX_FLAGS may contain flags not known by the default compiler, which will make the test fail. In particular using Ninja + Clang on Linux makes this test fail with the error below without this patch.; ```; c++: error: unrecognized command line option ‘-fcolor-diagnostics’; ninja: build stopped: subcommand failed.; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3389
https://github.com/root-project/root/pull/3391:235,Integrability,wrap,wrapping,235,"As explained in reviews.llvm.org/D43871, having cstdlib as part; of the stl module causes cyclic references between Clang's builtin; module and our stl module. The best fix is to not have cstdlib; in our module (which is anyway just a wrapping header around; stdlib.h).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3391
https://github.com/root-project/root/pull/3395:100,Performance,race condition,race conditions,100,I previously implemented a check for ensuring that we never again; run into the problem that we get race conditions between generating; and linking dictionaries. This check however was commented out as; it falsely reported some dictionaries as being a possible source; for race conditions. The reason for this is that there are a few; libraries that only use ROOT_LINKER_LIBRARY for linking but; not ROOT_GENERATE_DICTIONARY for generating a dictionary. This; commit adds a whitelist for dictionaries that are allowed to; call ROOT_LINKER_LIBRARY like this and don't introduce any race; conditions (as they don't call ROOT_GENERATE_DICTIONARY and don't; have any depndency on a G__*.cxx source file).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3395
https://github.com/root-project/root/pull/3395:273,Performance,race condition,race conditions,273,I previously implemented a check for ensuring that we never again; run into the problem that we get race conditions between generating; and linking dictionaries. This check however was commented out as; it falsely reported some dictionaries as being a possible source; for race conditions. The reason for this is that there are a few; libraries that only use ROOT_LINKER_LIBRARY for linking but; not ROOT_GENERATE_DICTIONARY for generating a dictionary. This; commit adds a whitelist for dictionaries that are allowed to; call ROOT_LINKER_LIBRARY like this and don't introduce any race; conditions (as they don't call ROOT_GENERATE_DICTIONARY and don't; have any depndency on a G__*.cxx source file).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3395
https://github.com/root-project/root/pull/3396:541,Deployability,patch,patch,541,"It is not recommended to link directly to the Python libraries, but instead, use `-undefined dynamic_lookup` (macOS flag). Depending on how Python was built, using dynamic or static links to the libPython, a direct link can cause it to segfault. This uses that method, and was a necessary change for the conda-forge package for Python 3 macOS. See, for example:; https://pybind11.readthedocs.io/en/stable/compiling.html#building-manually. Note: This might be reasonable to do for Linux too, but maybe with the appropriate flags. The current patch is as conservative as possible. Discussion has moved here: <https://sft.its.cern.ch/jira/browse/ROOT-9950>",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3396:123,Integrability,Depend,Depending,123,"It is not recommended to link directly to the Python libraries, but instead, use `-undefined dynamic_lookup` (macOS flag). Depending on how Python was built, using dynamic or static links to the libPython, a direct link can cause it to segfault. This uses that method, and was a necessary change for the conda-forge package for Python 3 macOS. See, for example:; https://pybind11.readthedocs.io/en/stable/compiling.html#building-manually. Note: This might be reasonable to do for Linux too, but maybe with the appropriate flags. The current patch is as conservative as possible. Discussion has moved here: <https://sft.its.cern.ch/jira/browse/ROOT-9950>",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3396
https://github.com/root-project/root/pull/3399:200,Testability,test,test,200,"This PR replaces #1533. Now TH1::FindFirst(Last)Bin is modified and there exists only a common function for TH1 working for all dimensions. ; The TH2, and TH3 specific functions are then removed. . A test is also added in hist/hist/test",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3399
https://github.com/root-project/root/pull/3399:232,Testability,test,test,232,"This PR replaces #1533. Now TH1::FindFirst(Last)Bin is modified and there exists only a common function for TH1 working for all dimensions. ; The TH2, and TH3 specific functions are then removed. . A test is also added in hist/hist/test",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3399
https://github.com/root-project/root/pull/3400:0,Testability,Test,Tested,0,Tested in roottest to enable both references for buitin_lz4 and external lz4 (PR #289),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3400
https://github.com/root-project/root/pull/3401:37,Modifiability,variab,variable,37,RooAbsSelfCached* were using a local variable that has the same name as a function.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3401
https://github.com/root-project/root/pull/3402:386,Deployability,update,updated,386,"fix a bug in excluding underflow bin when computing shortest interval in BayesianCalculator::ComputeShortestInterval. Before the underflow bin was included and the last bin excluded. ; Normally the underflow bin of the posterior histogram will be empty, but the last bin not and a difference could be observed in the computed interval.; The reference file of stressRooStats needs to be updated ; This fixes problem reported in ROOT-4619",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3402
https://github.com/root-project/root/pull/3404:17,Integrability,depend,dependencies,17,Fix header->dict dependencies.; Simplify core dictionary.; Simplify cmake code for dictionary generation (modulo modules - that's still to be simplified...),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3404
https://github.com/root-project/root/pull/3404:32,Usability,Simpl,Simplify,32,Fix header->dict dependencies.; Simplify core dictionary.; Simplify cmake code for dictionary generation (modulo modules - that's still to be simplified...),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3404
https://github.com/root-project/root/pull/3404:59,Usability,Simpl,Simplify,59,Fix header->dict dependencies.; Simplify core dictionary.; Simplify cmake code for dictionary generation (modulo modules - that's still to be simplified...),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3404
https://github.com/root-project/root/pull/3404:142,Usability,simpl,simplified,142,Fix header->dict dependencies.; Simplify core dictionary.; Simplify cmake code for dictionary generation (modulo modules - that's still to be simplified...),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3404
https://github.com/root-project/root/pull/3405:381,Deployability,install,installed,381,"This is in reference to this forum post - https://root-forum.cern.ch/t/feature-request-make-uninstall/32663. This is but a naive implementation of make uninstall (https://gitlab.kitware.com/cmake/community/wikis/FAQ#can-i-do-make-uninstall-with-cmake). This feature does have some issues.. quoting from the forum post - ""One of the problems could be the removal of files that were installed independently of ROOT. """,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3405
https://github.com/root-project/root/pull/3407:138,Availability,error,error,138,"This fixes 2 out of 3 failing cases in ROOT-9946 (https://sft.its.cern.ch/jira/browse/ROOT-9946),; and throws an exception with a clearer error for the third case (i.e. escaped strings, which still requires fixing I think?). @dpiparo in particular, lexertk fails to correctly tokenize a string like this, due to the escaped double quotes:; ```c++; std::cout << \""check\"" << std::endl; return x;; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3407
https://github.com/root-project/root/pull/3407:130,Usability,clear,clearer,130,"This fixes 2 out of 3 failing cases in ROOT-9946 (https://sft.its.cern.ch/jira/browse/ROOT-9946),; and throws an exception with a clearer error for the third case (i.e. escaped strings, which still requires fixing I think?). @dpiparo in particular, lexertk fails to correctly tokenize a string like this, due to the escaped double quotes:; ```c++; std::cout << \""check\"" << std::endl; return x;; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3407
https://github.com/root-project/root/pull/3410:240,Deployability,update,updated,240,https://github.com/root-project/root/pull/3386 reloaded. This intends to fix PyROOT experimental until https://bitbucket.org/wlav/cppyy-backend/pull-requests/17/remove-special-handling-for-ginterpreter is merged and ROOT's copy of Cppyy is updated with a future release.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3410
https://github.com/root-project/root/pull/3410:262,Deployability,release,release,262,https://github.com/root-project/root/pull/3386 reloaded. This intends to fix PyROOT experimental until https://bitbucket.org/wlav/cppyy-backend/pull-requests/17/remove-special-handling-for-ginterpreter is merged and ROOT's copy of Cppyy is updated with a future release.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3410
https://github.com/root-project/root/pull/3411:86,Deployability,patch,patch,86,"ROOT can get the incorrect flags if a compiler needs c++1z or something similar. This patch makes sure the compiler matches exactly what CMake uses. The old version can cause issues activating C++17 mode on AppleClang, for example, and then using `root-config`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3411
https://github.com/root-project/root/pull/3411:253,Modifiability,config,config,253,"ROOT can get the incorrect flags if a compiler needs c++1z or something similar. This patch makes sure the compiler matches exactly what CMake uses. The old version can cause issues activating C++17 mode on AppleClang, for example, and then using `root-config`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3411
https://github.com/root-project/root/pull/3413:90,Deployability,patch,patch,90,This should be more accurate than the current check. Follow up to #3096 and will remove a patch for the conda package.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3413
https://github.com/root-project/root/pull/3414:18,Performance,optimiz,optimizer,18,"Change hard coded optimizer efficiency and parse the number in the string. Give users more flexibility and go beyond the hard coded optimizer list. User can now write numbers as before, or as a fraction (using a decimal place)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3414
https://github.com/root-project/root/pull/3414:132,Performance,optimiz,optimizer,132,"Change hard coded optimizer efficiency and parse the number in the string. Give users more flexibility and go beyond the hard coded optimizer list. User can now write numbers as before, or as a fraction (using a decimal place)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3414
https://github.com/root-project/root/pull/3415:34,Deployability,integrat,integrated,34,…ath on different platforms. Also integrated in official cppyy repo:; https://bitbucket.org/wlav/cppyy/pull-requests/4/use-platform-independent-python-include/diff,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3415
https://github.com/root-project/root/pull/3415:34,Integrability,integrat,integrated,34,…ath on different platforms. Also integrated in official cppyy repo:; https://bitbucket.org/wlav/cppyy/pull-requests/4/use-platform-independent-python-include/diff,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3415
https://github.com/root-project/root/pull/3418:11,Testability,test,test,11,...and add test coverage,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3418
https://github.com/root-project/root/pull/3423:38,Integrability,inject,injects,38,"The pythonisation proposed in this PR injects a `__setitem__` implementation into `TClonesArray` that customizes the setting of an item. The `__setitem__` pythonization that `TClonesArray` inherits from `TSeqCollection` does not apply in this case and a redefinition is required. The reason is `TClonesArray `sets objects by constructing them in-place, which is impossible to support as the Python object given as value must exist a priori. It can, however, be memcpy'd and stolen, which is the approach used in this redefinition. This is also the reason why this pythonisation needs to be implemented in C++.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3423
https://github.com/root-project/root/pull/3423:189,Modifiability,inherit,inherits,189,"The pythonisation proposed in this PR injects a `__setitem__` implementation into `TClonesArray` that customizes the setting of an item. The `__setitem__` pythonization that `TClonesArray` inherits from `TSeqCollection` does not apply in this case and a redefinition is required. The reason is `TClonesArray `sets objects by constructing them in-place, which is impossible to support as the Python object given as value must exist a priori. It can, however, be memcpy'd and stolen, which is the approach used in this redefinition. This is also the reason why this pythonisation needs to be implemented in C++.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3423
https://github.com/root-project/root/pull/3423:38,Security,inject,injects,38,"The pythonisation proposed in this PR injects a `__setitem__` implementation into `TClonesArray` that customizes the setting of an item. The `__setitem__` pythonization that `TClonesArray` inherits from `TSeqCollection` does not apply in this case and a redefinition is required. The reason is `TClonesArray `sets objects by constructing them in-place, which is impossible to support as the Python object given as value must exist a priori. It can, however, be memcpy'd and stolen, which is the approach used in this redefinition. This is also the reason why this pythonisation needs to be implemented in C++.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3423
https://github.com/root-project/root/pull/3424:403,Availability,avail,available,403,"This PR implements the feature to read numpy arrays with `RDataFrame`. See following example for the use-case:. ```python; data = {; ""x"": numpy.array([1, 2, 3]),; ""y"": numpy.array([4, 5, 6]); }. df = ROOT.ROOT.RDF.MakeNumpyDataFrame(data); df2 = df.Filter(""x>1"").Define(""z"", ""x*y""). assert(df2.Mean(""z"").GetValue(), 14); ```. Edit: Up to now it works only with C++17 since `std::string_view` is not yet available in experimental PyROOT as backport.; Edit: Renamed `MakeRDataFrame` to `MakeNumpyDataFrame`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3424
https://github.com/root-project/root/pull/3424:283,Testability,assert,assert,283,"This PR implements the feature to read numpy arrays with `RDataFrame`. See following example for the use-case:. ```python; data = {; ""x"": numpy.array([1, 2, 3]),; ""y"": numpy.array([4, 5, 6]); }. df = ROOT.ROOT.RDF.MakeNumpyDataFrame(data); df2 = df.Filter(""x>1"").Define(""z"", ""x*y""). assert(df2.Mean(""z"").GetValue(), 14); ```. Edit: Up to now it works only with C++17 since `std::string_view` is not yet available in experimental PyROOT as backport.; Edit: Renamed `MakeRDataFrame` to `MakeNumpyDataFrame`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3424
https://github.com/root-project/root/pull/3425:248,Availability,error,error,248,This commit provides improvement to the BrentRootFinder and to TF1::GetX which uses it.; Now the bracketing is improved and the algorithms find in case of multiple roots the one with lower x value. ; In case the interval does not contain a ROOT an error message is produced and a NaN is returned instead of returning a random value as before.; This commit fixes the problem reported in ; ROOT-4998. The current test. testRootFinder is improved using gtest and adding the case of multiple roots and of log grid searchj that BrentRootFinder supports.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3425
https://github.com/root-project/root/pull/3425:254,Integrability,message,message,254,This commit provides improvement to the BrentRootFinder and to TF1::GetX which uses it.; Now the bracketing is improved and the algorithms find in case of multiple roots the one with lower x value. ; In case the interval does not contain a ROOT an error message is produced and a NaN is returned instead of returning a random value as before.; This commit fixes the problem reported in ; ROOT-4998. The current test. testRootFinder is improved using gtest and adding the case of multiple roots and of log grid searchj that BrentRootFinder supports.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3425
https://github.com/root-project/root/pull/3425:411,Testability,test,test,411,This commit provides improvement to the BrentRootFinder and to TF1::GetX which uses it.; Now the bracketing is improved and the algorithms find in case of multiple roots the one with lower x value. ; In case the interval does not contain a ROOT an error message is produced and a NaN is returned instead of returning a random value as before.; This commit fixes the problem reported in ; ROOT-4998. The current test. testRootFinder is improved using gtest and adding the case of multiple roots and of log grid searchj that BrentRootFinder supports.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3425
https://github.com/root-project/root/pull/3425:417,Testability,test,testRootFinder,417,This commit provides improvement to the BrentRootFinder and to TF1::GetX which uses it.; Now the bracketing is improved and the algorithms find in case of multiple roots the one with lower x value. ; In case the interval does not contain a ROOT an error message is produced and a NaN is returned instead of returning a random value as before.; This commit fixes the problem reported in ; ROOT-4998. The current test. testRootFinder is improved using gtest and adding the case of multiple roots and of log grid searchj that BrentRootFinder supports.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3425
https://github.com/root-project/root/pull/3425:501,Testability,log,log,501,This commit provides improvement to the BrentRootFinder and to TF1::GetX which uses it.; Now the bracketing is improved and the algorithms find in case of multiple roots the one with lower x value. ; In case the interval does not contain a ROOT an error message is produced and a NaN is returned instead of returning a random value as before.; This commit fixes the problem reported in ; ROOT-4998. The current test. testRootFinder is improved using gtest and adding the case of multiple roots and of log grid searchj that BrentRootFinder supports.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3425
https://github.com/root-project/root/pull/3426:51,Testability,test,tests,51,"This PR change the longtest labels for some of the tests. ; Tests like stressHistogram, stressHistoFit, stressRooFit, stressRooStats are essentials and are test suites made of several individual tests. ; Their running for every PR is essential. ; Since for these tests an interpreted and a no interpreted version exists, flag as longtest only the non interpreted version. Start flagging instead as longtest other minor tests in math which take some time (longer than few seconds) but they are not critical.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3426
https://github.com/root-project/root/pull/3426:60,Testability,Test,Tests,60,"This PR change the longtest labels for some of the tests. ; Tests like stressHistogram, stressHistoFit, stressRooFit, stressRooStats are essentials and are test suites made of several individual tests. ; Their running for every PR is essential. ; Since for these tests an interpreted and a no interpreted version exists, flag as longtest only the non interpreted version. Start flagging instead as longtest other minor tests in math which take some time (longer than few seconds) but they are not critical.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3426
https://github.com/root-project/root/pull/3426:156,Testability,test,test,156,"This PR change the longtest labels for some of the tests. ; Tests like stressHistogram, stressHistoFit, stressRooFit, stressRooStats are essentials and are test suites made of several individual tests. ; Their running for every PR is essential. ; Since for these tests an interpreted and a no interpreted version exists, flag as longtest only the non interpreted version. Start flagging instead as longtest other minor tests in math which take some time (longer than few seconds) but they are not critical.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3426
https://github.com/root-project/root/pull/3426:195,Testability,test,tests,195,"This PR change the longtest labels for some of the tests. ; Tests like stressHistogram, stressHistoFit, stressRooFit, stressRooStats are essentials and are test suites made of several individual tests. ; Their running for every PR is essential. ; Since for these tests an interpreted and a no interpreted version exists, flag as longtest only the non interpreted version. Start flagging instead as longtest other minor tests in math which take some time (longer than few seconds) but they are not critical.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3426
https://github.com/root-project/root/pull/3426:263,Testability,test,tests,263,"This PR change the longtest labels for some of the tests. ; Tests like stressHistogram, stressHistoFit, stressRooFit, stressRooStats are essentials and are test suites made of several individual tests. ; Their running for every PR is essential. ; Since for these tests an interpreted and a no interpreted version exists, flag as longtest only the non interpreted version. Start flagging instead as longtest other minor tests in math which take some time (longer than few seconds) but they are not critical.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3426
https://github.com/root-project/root/pull/3426:419,Testability,test,tests,419,"This PR change the longtest labels for some of the tests. ; Tests like stressHistogram, stressHistoFit, stressRooFit, stressRooStats are essentials and are test suites made of several individual tests. ; Their running for every PR is essential. ; Since for these tests an interpreted and a no interpreted version exists, flag as longtest only the non interpreted version. Start flagging instead as longtest other minor tests in math which take some time (longer than few seconds) but they are not critical.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3426
https://github.com/root-project/root/pull/3427:136,Usability,simpl,simple,136,"When using FitSlicesX() and FitSlicesY(), current version of ROOT doesn't allow us to set the range of fit in the other axis. By adding simple piece of code, it'll process TCutG.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3427
https://github.com/root-project/root/pull/3428:369,Performance,cache,cached,369,Without this it currently works fine because RDataFrame does not rewind a DataSource while doing a run on it. However the new RCombinedDS (a RDataSource which iterates on the cartesian product of two other datasources) which I just implemented exposes the issue because the above mentioned condition is not true anymore. This corrects the bug by effectively moving the cached cursor.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3428
https://github.com/root-project/root/pull/3428:244,Security,expose,exposes,244,Without this it currently works fine because RDataFrame does not rewind a DataSource while doing a run on it. However the new RCombinedDS (a RDataSource which iterates on the cartesian product of two other datasources) which I just implemented exposes the issue because the above mentioned condition is not true anymore. This corrects the bug by effectively moving the cached cursor.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3428
https://github.com/root-project/root/pull/3432:92,Testability,test,test,92,"This is a better fix for not_fn, where the check is now applied in the right place, and the test runs regardless (it could check for the not_fn define as well). Followup to #3413 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3432
https://github.com/root-project/root/pull/3433:14,Testability,assert,asserts,14,* Comment out asserts.; * Speedup inner loop by moving some checks one level up in the outer loop.; * Actually support rewinding an RArrowDS,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3433
https://github.com/root-project/root/pull/3435:62,Availability,error,error,62,The v7/line.cxx tutorial fails when run in batch mode with an error about that the DISPLAY can not be opened. Since this tutorial is part of the test suite this causes the tests to fail. This problem started due to some recent changes to the test. This PR reverts some of those changes to make the test work again.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3435
https://github.com/root-project/root/pull/3435:145,Testability,test,test,145,The v7/line.cxx tutorial fails when run in batch mode with an error about that the DISPLAY can not be opened. Since this tutorial is part of the test suite this causes the tests to fail. This problem started due to some recent changes to the test. This PR reverts some of those changes to make the test work again.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3435
https://github.com/root-project/root/pull/3435:172,Testability,test,tests,172,The v7/line.cxx tutorial fails when run in batch mode with an error about that the DISPLAY can not be opened. Since this tutorial is part of the test suite this causes the tests to fail. This problem started due to some recent changes to the test. This PR reverts some of those changes to make the test work again.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3435
https://github.com/root-project/root/pull/3435:242,Testability,test,test,242,The v7/line.cxx tutorial fails when run in batch mode with an error about that the DISPLAY can not be opened. Since this tutorial is part of the test suite this causes the tests to fail. This problem started due to some recent changes to the test. This PR reverts some of those changes to make the test work again.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3435
https://github.com/root-project/root/pull/3435:298,Testability,test,test,298,The v7/line.cxx tutorial fails when run in batch mode with an error about that the DISPLAY can not be opened. Since this tutorial is part of the test suite this causes the tests to fail. This problem started due to some recent changes to the test. This PR reverts some of those changes to make the test work again.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3435
https://github.com/root-project/root/pull/3436:136,Deployability,install,installed,136,The eve7 extension is built conditionally when the root7 option is enabled. The files in etc/eve7 used by this extension should only be installed when the extension is built.; In addition this PR also removes some obsolete patterns from the install rule that are no longer necessary because the files they refer to are no longer in the source tree.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3436
https://github.com/root-project/root/pull/3436:241,Deployability,install,install,241,The eve7 extension is built conditionally when the root7 option is enabled. The files in etc/eve7 used by this extension should only be installed when the extension is built.; In addition this PR also removes some obsolete patterns from the install rule that are no longer necessary because the files they refer to are no longer in the source tree.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3436
https://github.com/root-project/root/pull/3437:84,Energy Efficiency,reduce,reduce,84,HeaderSearch consumes considerable wallclock time and memory for ATLAS; this should reduce it.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3437
https://github.com/root-project/root/pull/3438:157,Availability,redundant,redundant,157,TMVA GPU features are enabled only when both the cuda and tmva-gpu flags are enabled. These flags are not used anywhere else. It looks like the cuda flag is redundant in this case. . Related forum post - https://root-forum.cern.ch/t/feature-request-enable-cuda-if-detected/32764,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3438
https://github.com/root-project/root/pull/3438:157,Safety,redund,redundant,157,TMVA GPU features are enabled only when both the cuda and tmva-gpu flags are enabled. These flags are not used anywhere else. It looks like the cuda flag is redundant in this case. . Related forum post - https://root-forum.cern.ch/t/feature-request-enable-cuda-if-detected/32764,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3438
https://github.com/root-project/root/pull/3438:264,Safety,detect,detected,264,TMVA GPU features are enabled only when both the cuda and tmva-gpu flags are enabled. These flags are not used anywhere else. It looks like the cuda flag is redundant in this case. . Related forum post - https://root-forum.cern.ch/t/feature-request-enable-cuda-if-detected/32764,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3438
https://github.com/root-project/root/pull/3440:167,Deployability,patch,patch,167,"The OSX linker stores the symbols in a shared library by adding an; extra ""_"" as prefix to the mangled name. However, the llvm JIT gives; us a unix mangled name. This patch adds a the missing extra prefix if we are on OSX.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3440
https://github.com/root-project/root/pull/3442:449,Availability,failure,failures,449,"There's a bug on 32-bit non-intel such as armv7l where root-config lists `-lROOTDataFrame` because it passes the check this patch adjusts, but libROOTDataFrame is not built on any 32-bit due to https://github.com/root-project/root/blob/v6-16-00-patches/tree/dataframe/CMakeLists.txt#L7 . Old check only hid DataFrame on i686; this patch changes the check to have the exact same conditions as the check for building DataFrame itself to prevent build failures in apps using root-config.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3442
https://github.com/root-project/root/pull/3442:124,Deployability,patch,patch,124,"There's a bug on 32-bit non-intel such as armv7l where root-config lists `-lROOTDataFrame` because it passes the check this patch adjusts, but libROOTDataFrame is not built on any 32-bit due to https://github.com/root-project/root/blob/v6-16-00-patches/tree/dataframe/CMakeLists.txt#L7 . Old check only hid DataFrame on i686; this patch changes the check to have the exact same conditions as the check for building DataFrame itself to prevent build failures in apps using root-config.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3442
https://github.com/root-project/root/pull/3442:245,Deployability,patch,patches,245,"There's a bug on 32-bit non-intel such as armv7l where root-config lists `-lROOTDataFrame` because it passes the check this patch adjusts, but libROOTDataFrame is not built on any 32-bit due to https://github.com/root-project/root/blob/v6-16-00-patches/tree/dataframe/CMakeLists.txt#L7 . Old check only hid DataFrame on i686; this patch changes the check to have the exact same conditions as the check for building DataFrame itself to prevent build failures in apps using root-config.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3442
https://github.com/root-project/root/pull/3442:331,Deployability,patch,patch,331,"There's a bug on 32-bit non-intel such as armv7l where root-config lists `-lROOTDataFrame` because it passes the check this patch adjusts, but libROOTDataFrame is not built on any 32-bit due to https://github.com/root-project/root/blob/v6-16-00-patches/tree/dataframe/CMakeLists.txt#L7 . Old check only hid DataFrame on i686; this patch changes the check to have the exact same conditions as the check for building DataFrame itself to prevent build failures in apps using root-config.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3442
https://github.com/root-project/root/pull/3442:60,Modifiability,config,config,60,"There's a bug on 32-bit non-intel such as armv7l where root-config lists `-lROOTDataFrame` because it passes the check this patch adjusts, but libROOTDataFrame is not built on any 32-bit due to https://github.com/root-project/root/blob/v6-16-00-patches/tree/dataframe/CMakeLists.txt#L7 . Old check only hid DataFrame on i686; this patch changes the check to have the exact same conditions as the check for building DataFrame itself to prevent build failures in apps using root-config.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3442
https://github.com/root-project/root/pull/3442:477,Modifiability,config,config,477,"There's a bug on 32-bit non-intel such as armv7l where root-config lists `-lROOTDataFrame` because it passes the check this patch adjusts, but libROOTDataFrame is not built on any 32-bit due to https://github.com/root-project/root/blob/v6-16-00-patches/tree/dataframe/CMakeLists.txt#L7 . Old check only hid DataFrame on i686; this patch changes the check to have the exact same conditions as the check for building DataFrame itself to prevent build failures in apps using root-config.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3442
https://github.com/root-project/root/pull/3444:5,Deployability,patch,patch,5,This patch prepares the infrastructure to be able to work with a; global module index.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3444
https://github.com/root-project/root/pull/3445:62,Integrability,Inject,Injection,62,This PR includes two sets of pythonisations for `TObject`:; - Injection of `__contains__` to support 'obj1 in obj2` syntax; https://sft.its.cern.ch/jira/browse/ROOT-9968; - Addition of comparison operators; https://sft.its.cern.ch/jira/browse/ROOT-9969,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3445
https://github.com/root-project/root/pull/3445:62,Security,Inject,Injection,62,This PR includes two sets of pythonisations for `TObject`:; - Injection of `__contains__` to support 'obj1 in obj2` syntax; https://sft.its.cern.ch/jira/browse/ROOT-9968; - Addition of comparison operators; https://sft.its.cern.ch/jira/browse/ROOT-9969,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3445
https://github.com/root-project/root/pull/3447:303,Deployability,update,updated,303,"Add possibility to set model function (and also data) when using Fitter::FitFCN. ; This gives possibility to call FitResult::GetConfidenceIntervals for the fits done using Fitter::FitFCN, as in the in case of TBinomialEfficiencyFitter. . This commit fixes ROOT-7790. The tutorial TesBinomial.C has been updated to compute as example the confidence interval of the fitted function. . This PR also contains a commit fixing the missing statistics in th2poly",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3447
https://github.com/root-project/root/pull/3449:166,Availability,Error,Errors,166,"Hello,. My implementation is named TGraphMultiErrors and is basically a TGraphAsymmErrors with the possibility to include an unlimited amount of different types of y-Errors.; The whole functionality and naming convention of my class is strongly based on the TGraphAsymmErrors class. All functionalities of the TGraphAsymmErrors have been reimplemented. Furthermore like any other TGraph class it inherits from TGraph and has therefore all of it’s functionalities. I attached an example plot as a png picture. Unfortunatly I cannot upload the C macro here, but if you are interested you can find it on the forum: [https://root-forum.cern.ch/t/tgraphmultierrors-class-for-graphs-with-asymmetric-errors-and-multiple-different-y-error-types-e-g-statistic-and-systematic-errors/32784](https://root-forum.cern.ch/t/tgraphmultierrors-class-for-graphs-with-asymmetric-errors-and-multiple-different-y-error-types-e-g-statistic-and-systematic-errors/32784). Since the class reimplements all functionalities of TGraphAsymmErrors, you can refer to it’s documentation for most functionalities: https://root.cern.ch/doc/master/classTGraphAsymmErrors.html. **Differences to TGraphAsymmErrors**; Everywhere TGraphAsymmErrors uses arrays for the y-Errors, my class uses two dimensional arrays (Double_t**) of which the first dimension represents the index of the error dimension and the second one the point. It is assumed that the first y-Error is the statistical one and all following are systematical ones. Therefore when the statistical errors are being computed by a function everything applies to only the first error dimension.; In case a single error on y is required (Like for fitting) the errors are being summed according to the value of fSumErrorsMode which can be at the moment TGraphMultiErrors::kOnlyFirst for only returning the error of the first error type (usally the statistic one), TGraphMultiErrors::kSquareSum for returning the squared sum of the errors of all types (Gaussian propagation) or TGr",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3449
https://github.com/root-project/root/pull/3449:693,Availability,error,errors-and-multiple-different-y-error-types-e-g-statistic-and-systematic-errors,693,"Hello,. My implementation is named TGraphMultiErrors and is basically a TGraphAsymmErrors with the possibility to include an unlimited amount of different types of y-Errors.; The whole functionality and naming convention of my class is strongly based on the TGraphAsymmErrors class. All functionalities of the TGraphAsymmErrors have been reimplemented. Furthermore like any other TGraph class it inherits from TGraph and has therefore all of it’s functionalities. I attached an example plot as a png picture. Unfortunatly I cannot upload the C macro here, but if you are interested you can find it on the forum: [https://root-forum.cern.ch/t/tgraphmultierrors-class-for-graphs-with-asymmetric-errors-and-multiple-different-y-error-types-e-g-statistic-and-systematic-errors/32784](https://root-forum.cern.ch/t/tgraphmultierrors-class-for-graphs-with-asymmetric-errors-and-multiple-different-y-error-types-e-g-statistic-and-systematic-errors/32784). Since the class reimplements all functionalities of TGraphAsymmErrors, you can refer to it’s documentation for most functionalities: https://root.cern.ch/doc/master/classTGraphAsymmErrors.html. **Differences to TGraphAsymmErrors**; Everywhere TGraphAsymmErrors uses arrays for the y-Errors, my class uses two dimensional arrays (Double_t**) of which the first dimension represents the index of the error dimension and the second one the point. It is assumed that the first y-Error is the statistical one and all following are systematical ones. Therefore when the statistical errors are being computed by a function everything applies to only the first error dimension.; In case a single error on y is required (Like for fitting) the errors are being summed according to the value of fSumErrorsMode which can be at the moment TGraphMultiErrors::kOnlyFirst for only returning the error of the first error type (usally the statistic one), TGraphMultiErrors::kSquareSum for returning the squared sum of the errors of all types (Gaussian propagation) or TGr",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3449
https://github.com/root-project/root/pull/3449:860,Availability,error,errors-and-multiple-different-y-error-types-e-g-statistic-and-systematic-errors,860,"Hello,. My implementation is named TGraphMultiErrors and is basically a TGraphAsymmErrors with the possibility to include an unlimited amount of different types of y-Errors.; The whole functionality and naming convention of my class is strongly based on the TGraphAsymmErrors class. All functionalities of the TGraphAsymmErrors have been reimplemented. Furthermore like any other TGraph class it inherits from TGraph and has therefore all of it’s functionalities. I attached an example plot as a png picture. Unfortunatly I cannot upload the C macro here, but if you are interested you can find it on the forum: [https://root-forum.cern.ch/t/tgraphmultierrors-class-for-graphs-with-asymmetric-errors-and-multiple-different-y-error-types-e-g-statistic-and-systematic-errors/32784](https://root-forum.cern.ch/t/tgraphmultierrors-class-for-graphs-with-asymmetric-errors-and-multiple-different-y-error-types-e-g-statistic-and-systematic-errors/32784). Since the class reimplements all functionalities of TGraphAsymmErrors, you can refer to it’s documentation for most functionalities: https://root.cern.ch/doc/master/classTGraphAsymmErrors.html. **Differences to TGraphAsymmErrors**; Everywhere TGraphAsymmErrors uses arrays for the y-Errors, my class uses two dimensional arrays (Double_t**) of which the first dimension represents the index of the error dimension and the second one the point. It is assumed that the first y-Error is the statistical one and all following are systematical ones. Therefore when the statistical errors are being computed by a function everything applies to only the first error dimension.; In case a single error on y is required (Like for fitting) the errors are being summed according to the value of fSumErrorsMode which can be at the moment TGraphMultiErrors::kOnlyFirst for only returning the error of the first error type (usally the statistic one), TGraphMultiErrors::kSquareSum for returning the squared sum of the errors of all types (Gaussian propagation) or TGr",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3449
https://github.com/root-project/root/pull/3449:1231,Availability,Error,Errors,1231,"ymmErrors class. All functionalities of the TGraphAsymmErrors have been reimplemented. Furthermore like any other TGraph class it inherits from TGraph and has therefore all of it’s functionalities. I attached an example plot as a png picture. Unfortunatly I cannot upload the C macro here, but if you are interested you can find it on the forum: [https://root-forum.cern.ch/t/tgraphmultierrors-class-for-graphs-with-asymmetric-errors-and-multiple-different-y-error-types-e-g-statistic-and-systematic-errors/32784](https://root-forum.cern.ch/t/tgraphmultierrors-class-for-graphs-with-asymmetric-errors-and-multiple-different-y-error-types-e-g-statistic-and-systematic-errors/32784). Since the class reimplements all functionalities of TGraphAsymmErrors, you can refer to it’s documentation for most functionalities: https://root.cern.ch/doc/master/classTGraphAsymmErrors.html. **Differences to TGraphAsymmErrors**; Everywhere TGraphAsymmErrors uses arrays for the y-Errors, my class uses two dimensional arrays (Double_t**) of which the first dimension represents the index of the error dimension and the second one the point. It is assumed that the first y-Error is the statistical one and all following are systematical ones. Therefore when the statistical errors are being computed by a function everything applies to only the first error dimension.; In case a single error on y is required (Like for fitting) the errors are being summed according to the value of fSumErrorsMode which can be at the moment TGraphMultiErrors::kOnlyFirst for only returning the error of the first error type (usally the statistic one), TGraphMultiErrors::kSquareSum for returning the squared sum of the errors of all types (Gaussian propagation) or TGraphMultiErrors::kSum for just returning the sum of the errors from all error types. **Drawing / Painting**; The painting is being performed by the functions TGraphMultiErrors::Paint, TGraphMultiErrors::PaintReverse and TGraphMultiErrors::PaintGraphMultiErrors. If t",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3449
https://github.com/root-project/root/pull/3449:1346,Availability,error,error,1346,"ymmErrors class. All functionalities of the TGraphAsymmErrors have been reimplemented. Furthermore like any other TGraph class it inherits from TGraph and has therefore all of it’s functionalities. I attached an example plot as a png picture. Unfortunatly I cannot upload the C macro here, but if you are interested you can find it on the forum: [https://root-forum.cern.ch/t/tgraphmultierrors-class-for-graphs-with-asymmetric-errors-and-multiple-different-y-error-types-e-g-statistic-and-systematic-errors/32784](https://root-forum.cern.ch/t/tgraphmultierrors-class-for-graphs-with-asymmetric-errors-and-multiple-different-y-error-types-e-g-statistic-and-systematic-errors/32784). Since the class reimplements all functionalities of TGraphAsymmErrors, you can refer to it’s documentation for most functionalities: https://root.cern.ch/doc/master/classTGraphAsymmErrors.html. **Differences to TGraphAsymmErrors**; Everywhere TGraphAsymmErrors uses arrays for the y-Errors, my class uses two dimensional arrays (Double_t**) of which the first dimension represents the index of the error dimension and the second one the point. It is assumed that the first y-Error is the statistical one and all following are systematical ones. Therefore when the statistical errors are being computed by a function everything applies to only the first error dimension.; In case a single error on y is required (Like for fitting) the errors are being summed according to the value of fSumErrorsMode which can be at the moment TGraphMultiErrors::kOnlyFirst for only returning the error of the first error type (usally the statistic one), TGraphMultiErrors::kSquareSum for returning the squared sum of the errors of all types (Gaussian propagation) or TGraphMultiErrors::kSum for just returning the sum of the errors from all error types. **Drawing / Painting**; The painting is being performed by the functions TGraphMultiErrors::Paint, TGraphMultiErrors::PaintReverse and TGraphMultiErrors::PaintGraphMultiErrors. If t",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3449
https://github.com/root-project/root/pull/3449:1423,Availability,Error,Error,1423," it’s functionalities. I attached an example plot as a png picture. Unfortunatly I cannot upload the C macro here, but if you are interested you can find it on the forum: [https://root-forum.cern.ch/t/tgraphmultierrors-class-for-graphs-with-asymmetric-errors-and-multiple-different-y-error-types-e-g-statistic-and-systematic-errors/32784](https://root-forum.cern.ch/t/tgraphmultierrors-class-for-graphs-with-asymmetric-errors-and-multiple-different-y-error-types-e-g-statistic-and-systematic-errors/32784). Since the class reimplements all functionalities of TGraphAsymmErrors, you can refer to it’s documentation for most functionalities: https://root.cern.ch/doc/master/classTGraphAsymmErrors.html. **Differences to TGraphAsymmErrors**; Everywhere TGraphAsymmErrors uses arrays for the y-Errors, my class uses two dimensional arrays (Double_t**) of which the first dimension represents the index of the error dimension and the second one the point. It is assumed that the first y-Error is the statistical one and all following are systematical ones. Therefore when the statistical errors are being computed by a function everything applies to only the first error dimension.; In case a single error on y is required (Like for fitting) the errors are being summed according to the value of fSumErrorsMode which can be at the moment TGraphMultiErrors::kOnlyFirst for only returning the error of the first error type (usally the statistic one), TGraphMultiErrors::kSquareSum for returning the squared sum of the errors of all types (Gaussian propagation) or TGraphMultiErrors::kSum for just returning the sum of the errors from all error types. **Drawing / Painting**; The painting is being performed by the functions TGraphMultiErrors::Paint, TGraphMultiErrors::PaintReverse and TGraphMultiErrors::PaintGraphMultiErrors. If this class should ever become part of ROOT the first two are to be deleted, cause there are similar functions in the class TGraphPainter and the last one is supposed to be inclu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3449
https://github.com/root-project/root/pull/3449:1524,Availability,error,errors,1524,", but if you are interested you can find it on the forum: [https://root-forum.cern.ch/t/tgraphmultierrors-class-for-graphs-with-asymmetric-errors-and-multiple-different-y-error-types-e-g-statistic-and-systematic-errors/32784](https://root-forum.cern.ch/t/tgraphmultierrors-class-for-graphs-with-asymmetric-errors-and-multiple-different-y-error-types-e-g-statistic-and-systematic-errors/32784). Since the class reimplements all functionalities of TGraphAsymmErrors, you can refer to it’s documentation for most functionalities: https://root.cern.ch/doc/master/classTGraphAsymmErrors.html. **Differences to TGraphAsymmErrors**; Everywhere TGraphAsymmErrors uses arrays for the y-Errors, my class uses two dimensional arrays (Double_t**) of which the first dimension represents the index of the error dimension and the second one the point. It is assumed that the first y-Error is the statistical one and all following are systematical ones. Therefore when the statistical errors are being computed by a function everything applies to only the first error dimension.; In case a single error on y is required (Like for fitting) the errors are being summed according to the value of fSumErrorsMode which can be at the moment TGraphMultiErrors::kOnlyFirst for only returning the error of the first error type (usally the statistic one), TGraphMultiErrors::kSquareSum for returning the squared sum of the errors of all types (Gaussian propagation) or TGraphMultiErrors::kSum for just returning the sum of the errors from all error types. **Drawing / Painting**; The painting is being performed by the functions TGraphMultiErrors::Paint, TGraphMultiErrors::PaintReverse and TGraphMultiErrors::PaintGraphMultiErrors. If this class should ever become part of ROOT the first two are to be deleted, cause there are similar functions in the class TGraphPainter and the last one is supposed to be included in the TGraphPainter class. The function TGraphMultiErrors::Paint is similar to TGraph::Paint and TGraphPaint",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3449
https://github.com/root-project/root/pull/3449:1601,Availability,error,error,1601,", but if you are interested you can find it on the forum: [https://root-forum.cern.ch/t/tgraphmultierrors-class-for-graphs-with-asymmetric-errors-and-multiple-different-y-error-types-e-g-statistic-and-systematic-errors/32784](https://root-forum.cern.ch/t/tgraphmultierrors-class-for-graphs-with-asymmetric-errors-and-multiple-different-y-error-types-e-g-statistic-and-systematic-errors/32784). Since the class reimplements all functionalities of TGraphAsymmErrors, you can refer to it’s documentation for most functionalities: https://root.cern.ch/doc/master/classTGraphAsymmErrors.html. **Differences to TGraphAsymmErrors**; Everywhere TGraphAsymmErrors uses arrays for the y-Errors, my class uses two dimensional arrays (Double_t**) of which the first dimension represents the index of the error dimension and the second one the point. It is assumed that the first y-Error is the statistical one and all following are systematical ones. Therefore when the statistical errors are being computed by a function everything applies to only the first error dimension.; In case a single error on y is required (Like for fitting) the errors are being summed according to the value of fSumErrorsMode which can be at the moment TGraphMultiErrors::kOnlyFirst for only returning the error of the first error type (usally the statistic one), TGraphMultiErrors::kSquareSum for returning the squared sum of the errors of all types (Gaussian propagation) or TGraphMultiErrors::kSum for just returning the sum of the errors from all error types. **Drawing / Painting**; The painting is being performed by the functions TGraphMultiErrors::Paint, TGraphMultiErrors::PaintReverse and TGraphMultiErrors::PaintGraphMultiErrors. If this class should ever become part of ROOT the first two are to be deleted, cause there are similar functions in the class TGraphPainter and the last one is supposed to be included in the TGraphPainter class. The function TGraphMultiErrors::Paint is similar to TGraph::Paint and TGraphPaint",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3449
https://github.com/root-project/root/pull/3449:1636,Availability,error,error,1636,"symmetric-errors-and-multiple-different-y-error-types-e-g-statistic-and-systematic-errors/32784). Since the class reimplements all functionalities of TGraphAsymmErrors, you can refer to it’s documentation for most functionalities: https://root.cern.ch/doc/master/classTGraphAsymmErrors.html. **Differences to TGraphAsymmErrors**; Everywhere TGraphAsymmErrors uses arrays for the y-Errors, my class uses two dimensional arrays (Double_t**) of which the first dimension represents the index of the error dimension and the second one the point. It is assumed that the first y-Error is the statistical one and all following are systematical ones. Therefore when the statistical errors are being computed by a function everything applies to only the first error dimension.; In case a single error on y is required (Like for fitting) the errors are being summed according to the value of fSumErrorsMode which can be at the moment TGraphMultiErrors::kOnlyFirst for only returning the error of the first error type (usally the statistic one), TGraphMultiErrors::kSquareSum for returning the squared sum of the errors of all types (Gaussian propagation) or TGraphMultiErrors::kSum for just returning the sum of the errors from all error types. **Drawing / Painting**; The painting is being performed by the functions TGraphMultiErrors::Paint, TGraphMultiErrors::PaintReverse and TGraphMultiErrors::PaintGraphMultiErrors. If this class should ever become part of ROOT the first two are to be deleted, cause there are similar functions in the class TGraphPainter and the last one is supposed to be included in the TGraphPainter class. The function TGraphMultiErrors::Paint is similar to TGraph::Paint and TGraphPainter::PaintHelper and can be deleted if the class should become part of root and TGraphMultiErrors::PaintGraphMultiErrors is being included in the TGraphPainter class.; The function TGraphMultiErrors::PaintReverse serves the same purpose as TGraphPainter::PaintReverse and should be deleted too if ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3449
https://github.com/root-project/root/pull/3449:1682,Availability,error,errors,1682,"symmetric-errors-and-multiple-different-y-error-types-e-g-statistic-and-systematic-errors/32784). Since the class reimplements all functionalities of TGraphAsymmErrors, you can refer to it’s documentation for most functionalities: https://root.cern.ch/doc/master/classTGraphAsymmErrors.html. **Differences to TGraphAsymmErrors**; Everywhere TGraphAsymmErrors uses arrays for the y-Errors, my class uses two dimensional arrays (Double_t**) of which the first dimension represents the index of the error dimension and the second one the point. It is assumed that the first y-Error is the statistical one and all following are systematical ones. Therefore when the statistical errors are being computed by a function everything applies to only the first error dimension.; In case a single error on y is required (Like for fitting) the errors are being summed according to the value of fSumErrorsMode which can be at the moment TGraphMultiErrors::kOnlyFirst for only returning the error of the first error type (usally the statistic one), TGraphMultiErrors::kSquareSum for returning the squared sum of the errors of all types (Gaussian propagation) or TGraphMultiErrors::kSum for just returning the sum of the errors from all error types. **Drawing / Painting**; The painting is being performed by the functions TGraphMultiErrors::Paint, TGraphMultiErrors::PaintReverse and TGraphMultiErrors::PaintGraphMultiErrors. If this class should ever become part of ROOT the first two are to be deleted, cause there are similar functions in the class TGraphPainter and the last one is supposed to be included in the TGraphPainter class. The function TGraphMultiErrors::Paint is similar to TGraph::Paint and TGraphPainter::PaintHelper and can be deleted if the class should become part of root and TGraphMultiErrors::PaintGraphMultiErrors is being included in the TGraphPainter class.; The function TGraphMultiErrors::PaintReverse serves the same purpose as TGraphPainter::PaintReverse and should be deleted too if ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3449
https://github.com/root-project/root/pull/3449:1827,Availability,error,error,1827,"symmetric-errors-and-multiple-different-y-error-types-e-g-statistic-and-systematic-errors/32784). Since the class reimplements all functionalities of TGraphAsymmErrors, you can refer to it’s documentation for most functionalities: https://root.cern.ch/doc/master/classTGraphAsymmErrors.html. **Differences to TGraphAsymmErrors**; Everywhere TGraphAsymmErrors uses arrays for the y-Errors, my class uses two dimensional arrays (Double_t**) of which the first dimension represents the index of the error dimension and the second one the point. It is assumed that the first y-Error is the statistical one and all following are systematical ones. Therefore when the statistical errors are being computed by a function everything applies to only the first error dimension.; In case a single error on y is required (Like for fitting) the errors are being summed according to the value of fSumErrorsMode which can be at the moment TGraphMultiErrors::kOnlyFirst for only returning the error of the first error type (usally the statistic one), TGraphMultiErrors::kSquareSum for returning the squared sum of the errors of all types (Gaussian propagation) or TGraphMultiErrors::kSum for just returning the sum of the errors from all error types. **Drawing / Painting**; The painting is being performed by the functions TGraphMultiErrors::Paint, TGraphMultiErrors::PaintReverse and TGraphMultiErrors::PaintGraphMultiErrors. If this class should ever become part of ROOT the first two are to be deleted, cause there are similar functions in the class TGraphPainter and the last one is supposed to be included in the TGraphPainter class. The function TGraphMultiErrors::Paint is similar to TGraph::Paint and TGraphPainter::PaintHelper and can be deleted if the class should become part of root and TGraphMultiErrors::PaintGraphMultiErrors is being included in the TGraphPainter class.; The function TGraphMultiErrors::PaintReverse serves the same purpose as TGraphPainter::PaintReverse and should be deleted too if ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3449
https://github.com/root-project/root/pull/3449:1846,Availability,error,error,1846,"symmetric-errors-and-multiple-different-y-error-types-e-g-statistic-and-systematic-errors/32784). Since the class reimplements all functionalities of TGraphAsymmErrors, you can refer to it’s documentation for most functionalities: https://root.cern.ch/doc/master/classTGraphAsymmErrors.html. **Differences to TGraphAsymmErrors**; Everywhere TGraphAsymmErrors uses arrays for the y-Errors, my class uses two dimensional arrays (Double_t**) of which the first dimension represents the index of the error dimension and the second one the point. It is assumed that the first y-Error is the statistical one and all following are systematical ones. Therefore when the statistical errors are being computed by a function everything applies to only the first error dimension.; In case a single error on y is required (Like for fitting) the errors are being summed according to the value of fSumErrorsMode which can be at the moment TGraphMultiErrors::kOnlyFirst for only returning the error of the first error type (usally the statistic one), TGraphMultiErrors::kSquareSum for returning the squared sum of the errors of all types (Gaussian propagation) or TGraphMultiErrors::kSum for just returning the sum of the errors from all error types. **Drawing / Painting**; The painting is being performed by the functions TGraphMultiErrors::Paint, TGraphMultiErrors::PaintReverse and TGraphMultiErrors::PaintGraphMultiErrors. If this class should ever become part of ROOT the first two are to be deleted, cause there are similar functions in the class TGraphPainter and the last one is supposed to be included in the TGraphPainter class. The function TGraphMultiErrors::Paint is similar to TGraph::Paint and TGraphPainter::PaintHelper and can be deleted if the class should become part of root and TGraphMultiErrors::PaintGraphMultiErrors is being included in the TGraphPainter class.; The function TGraphMultiErrors::PaintReverse serves the same purpose as TGraphPainter::PaintReverse and should be deleted too if ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3449
https://github.com/root-project/root/pull/3449:1952,Availability,error,errors,1952,"symmetric-errors-and-multiple-different-y-error-types-e-g-statistic-and-systematic-errors/32784). Since the class reimplements all functionalities of TGraphAsymmErrors, you can refer to it’s documentation for most functionalities: https://root.cern.ch/doc/master/classTGraphAsymmErrors.html. **Differences to TGraphAsymmErrors**; Everywhere TGraphAsymmErrors uses arrays for the y-Errors, my class uses two dimensional arrays (Double_t**) of which the first dimension represents the index of the error dimension and the second one the point. It is assumed that the first y-Error is the statistical one and all following are systematical ones. Therefore when the statistical errors are being computed by a function everything applies to only the first error dimension.; In case a single error on y is required (Like for fitting) the errors are being summed according to the value of fSumErrorsMode which can be at the moment TGraphMultiErrors::kOnlyFirst for only returning the error of the first error type (usally the statistic one), TGraphMultiErrors::kSquareSum for returning the squared sum of the errors of all types (Gaussian propagation) or TGraphMultiErrors::kSum for just returning the sum of the errors from all error types. **Drawing / Painting**; The painting is being performed by the functions TGraphMultiErrors::Paint, TGraphMultiErrors::PaintReverse and TGraphMultiErrors::PaintGraphMultiErrors. If this class should ever become part of ROOT the first two are to be deleted, cause there are similar functions in the class TGraphPainter and the last one is supposed to be included in the TGraphPainter class. The function TGraphMultiErrors::Paint is similar to TGraph::Paint and TGraphPainter::PaintHelper and can be deleted if the class should become part of root and TGraphMultiErrors::PaintGraphMultiErrors is being included in the TGraphPainter class.; The function TGraphMultiErrors::PaintReverse serves the same purpose as TGraphPainter::PaintReverse and should be deleted too if ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3449
https://github.com/root-project/root/pull/3449:2056,Availability,error,errors,2056,"symmetric-errors-and-multiple-different-y-error-types-e-g-statistic-and-systematic-errors/32784). Since the class reimplements all functionalities of TGraphAsymmErrors, you can refer to it’s documentation for most functionalities: https://root.cern.ch/doc/master/classTGraphAsymmErrors.html. **Differences to TGraphAsymmErrors**; Everywhere TGraphAsymmErrors uses arrays for the y-Errors, my class uses two dimensional arrays (Double_t**) of which the first dimension represents the index of the error dimension and the second one the point. It is assumed that the first y-Error is the statistical one and all following are systematical ones. Therefore when the statistical errors are being computed by a function everything applies to only the first error dimension.; In case a single error on y is required (Like for fitting) the errors are being summed according to the value of fSumErrorsMode which can be at the moment TGraphMultiErrors::kOnlyFirst for only returning the error of the first error type (usally the statistic one), TGraphMultiErrors::kSquareSum for returning the squared sum of the errors of all types (Gaussian propagation) or TGraphMultiErrors::kSum for just returning the sum of the errors from all error types. **Drawing / Painting**; The painting is being performed by the functions TGraphMultiErrors::Paint, TGraphMultiErrors::PaintReverse and TGraphMultiErrors::PaintGraphMultiErrors. If this class should ever become part of ROOT the first two are to be deleted, cause there are similar functions in the class TGraphPainter and the last one is supposed to be included in the TGraphPainter class. The function TGraphMultiErrors::Paint is similar to TGraph::Paint and TGraphPainter::PaintHelper and can be deleted if the class should become part of root and TGraphMultiErrors::PaintGraphMultiErrors is being included in the TGraphPainter class.; The function TGraphMultiErrors::PaintReverse serves the same purpose as TGraphPainter::PaintReverse and should be deleted too if ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3449
https://github.com/root-project/root/pull/3449:2072,Availability,error,error,2072,"symmetric-errors-and-multiple-different-y-error-types-e-g-statistic-and-systematic-errors/32784). Since the class reimplements all functionalities of TGraphAsymmErrors, you can refer to it’s documentation for most functionalities: https://root.cern.ch/doc/master/classTGraphAsymmErrors.html. **Differences to TGraphAsymmErrors**; Everywhere TGraphAsymmErrors uses arrays for the y-Errors, my class uses two dimensional arrays (Double_t**) of which the first dimension represents the index of the error dimension and the second one the point. It is assumed that the first y-Error is the statistical one and all following are systematical ones. Therefore when the statistical errors are being computed by a function everything applies to only the first error dimension.; In case a single error on y is required (Like for fitting) the errors are being summed according to the value of fSumErrorsMode which can be at the moment TGraphMultiErrors::kOnlyFirst for only returning the error of the first error type (usally the statistic one), TGraphMultiErrors::kSquareSum for returning the squared sum of the errors of all types (Gaussian propagation) or TGraphMultiErrors::kSum for just returning the sum of the errors from all error types. **Drawing / Painting**; The painting is being performed by the functions TGraphMultiErrors::Paint, TGraphMultiErrors::PaintReverse and TGraphMultiErrors::PaintGraphMultiErrors. If this class should ever become part of ROOT the first two are to be deleted, cause there are similar functions in the class TGraphPainter and the last one is supposed to be included in the TGraphPainter class. The function TGraphMultiErrors::Paint is similar to TGraph::Paint and TGraphPainter::PaintHelper and can be deleted if the class should become part of root and TGraphMultiErrors::PaintGraphMultiErrors is being included in the TGraphPainter class.; The function TGraphMultiErrors::PaintReverse serves the same purpose as TGraphPainter::PaintReverse and should be deleted too if ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3449
https://github.com/root-project/root/pull/3449:3121,Availability,error,error,3121,"ting is being performed by the functions TGraphMultiErrors::Paint, TGraphMultiErrors::PaintReverse and TGraphMultiErrors::PaintGraphMultiErrors. If this class should ever become part of ROOT the first two are to be deleted, cause there are similar functions in the class TGraphPainter and the last one is supposed to be included in the TGraphPainter class. The function TGraphMultiErrors::Paint is similar to TGraph::Paint and TGraphPainter::PaintHelper and can be deleted if the class should become part of root and TGraphMultiErrors::PaintGraphMultiErrors is being included in the TGraphPainter class.; The function TGraphMultiErrors::PaintReverse serves the same purpose as TGraphPainter::PaintReverse and should be deleted too if the class becomes part of ROOT.; The function TGraphMultiErrors::PaintGraphMultiErrors performs the actual painting and would have to be included in the TGraphPainter class. **Drawing / Painting options**; To be able to define different drawing options for the multiple error dimensions the option string can consist of multiple blocks separated by semicolons. The painting method separates the options in multiple options for each y error dimension and one for basic painting and the x errors. In case there are <= NErrorDimensions blocks given, the first block is used for basic painting and for the first dimension of y errors. Y error dimensions without an individual block are painted with “”.; Tn case there are NErrorDimensions + 1 given, the first block is used only for basic painting. The remaining blocks are distributed over the y error dimensions In case there are > NErrorDimensions + 1 blocks given an error is returned. All drawing options of TGraphAsymmErrors are implemented. For explanation of the drawing options see TGraphPainter::PaintGraphAsymmErrors.; Additionally one can specify x0 or y0 to skip points with x = 0 or y = 0 The Draw option s=%f can be used to multiply the corresponding x errors with %f. This is useful in combination with e.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3449
https://github.com/root-project/root/pull/3449:3285,Availability,error,error,3285,"ould ever become part of ROOT the first two are to be deleted, cause there are similar functions in the class TGraphPainter and the last one is supposed to be included in the TGraphPainter class. The function TGraphMultiErrors::Paint is similar to TGraph::Paint and TGraphPainter::PaintHelper and can be deleted if the class should become part of root and TGraphMultiErrors::PaintGraphMultiErrors is being included in the TGraphPainter class.; The function TGraphMultiErrors::PaintReverse serves the same purpose as TGraphPainter::PaintReverse and should be deleted too if the class becomes part of ROOT.; The function TGraphMultiErrors::PaintGraphMultiErrors performs the actual painting and would have to be included in the TGraphPainter class. **Drawing / Painting options**; To be able to define different drawing options for the multiple error dimensions the option string can consist of multiple blocks separated by semicolons. The painting method separates the options in multiple options for each y error dimension and one for basic painting and the x errors. In case there are <= NErrorDimensions blocks given, the first block is used for basic painting and for the first dimension of y errors. Y error dimensions without an individual block are painted with “”.; Tn case there are NErrorDimensions + 1 given, the first block is used only for basic painting. The remaining blocks are distributed over the y error dimensions In case there are > NErrorDimensions + 1 blocks given an error is returned. All drawing options of TGraphAsymmErrors are implemented. For explanation of the drawing options see TGraphPainter::PaintGraphAsymmErrors.; Additionally one can specify x0 or y0 to skip points with x = 0 or y = 0 The Draw option s=%f can be used to multiply the corresponding x errors with %f. This is useful in combination with e.g. option 2 if the boxes are supposed to have only half the width of the bin, in this case the option would be s=0.5. Per default the Fill and Line Styles of th",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3449
https://github.com/root-project/root/pull/3449:3338,Availability,error,errors,3338,"ould ever become part of ROOT the first two are to be deleted, cause there are similar functions in the class TGraphPainter and the last one is supposed to be included in the TGraphPainter class. The function TGraphMultiErrors::Paint is similar to TGraph::Paint and TGraphPainter::PaintHelper and can be deleted if the class should become part of root and TGraphMultiErrors::PaintGraphMultiErrors is being included in the TGraphPainter class.; The function TGraphMultiErrors::PaintReverse serves the same purpose as TGraphPainter::PaintReverse and should be deleted too if the class becomes part of ROOT.; The function TGraphMultiErrors::PaintGraphMultiErrors performs the actual painting and would have to be included in the TGraphPainter class. **Drawing / Painting options**; To be able to define different drawing options for the multiple error dimensions the option string can consist of multiple blocks separated by semicolons. The painting method separates the options in multiple options for each y error dimension and one for basic painting and the x errors. In case there are <= NErrorDimensions blocks given, the first block is used for basic painting and for the first dimension of y errors. Y error dimensions without an individual block are painted with “”.; Tn case there are NErrorDimensions + 1 given, the first block is used only for basic painting. The remaining blocks are distributed over the y error dimensions In case there are > NErrorDimensions + 1 blocks given an error is returned. All drawing options of TGraphAsymmErrors are implemented. For explanation of the drawing options see TGraphPainter::PaintGraphAsymmErrors.; Additionally one can specify x0 or y0 to skip points with x = 0 or y = 0 The Draw option s=%f can be used to multiply the corresponding x errors with %f. This is useful in combination with e.g. option 2 if the boxes are supposed to have only half the width of the bin, in this case the option would be s=0.5. Per default the Fill and Line Styles of th",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3449
https://github.com/root-project/root/pull/3449:3474,Availability,error,errors,3474,"t one is supposed to be included in the TGraphPainter class. The function TGraphMultiErrors::Paint is similar to TGraph::Paint and TGraphPainter::PaintHelper and can be deleted if the class should become part of root and TGraphMultiErrors::PaintGraphMultiErrors is being included in the TGraphPainter class.; The function TGraphMultiErrors::PaintReverse serves the same purpose as TGraphPainter::PaintReverse and should be deleted too if the class becomes part of ROOT.; The function TGraphMultiErrors::PaintGraphMultiErrors performs the actual painting and would have to be included in the TGraphPainter class. **Drawing / Painting options**; To be able to define different drawing options for the multiple error dimensions the option string can consist of multiple blocks separated by semicolons. The painting method separates the options in multiple options for each y error dimension and one for basic painting and the x errors. In case there are <= NErrorDimensions blocks given, the first block is used for basic painting and for the first dimension of y errors. Y error dimensions without an individual block are painted with “”.; Tn case there are NErrorDimensions + 1 given, the first block is used only for basic painting. The remaining blocks are distributed over the y error dimensions In case there are > NErrorDimensions + 1 blocks given an error is returned. All drawing options of TGraphAsymmErrors are implemented. For explanation of the drawing options see TGraphPainter::PaintGraphAsymmErrors.; Additionally one can specify x0 or y0 to skip points with x = 0 or y = 0 The Draw option s=%f can be used to multiply the corresponding x errors with %f. This is useful in combination with e.g. option 2 if the boxes are supposed to have only half the width of the bin, in this case the option would be s=0.5. Per default the Fill and Line Styles of the Graph are being used for all error dimensions. To use the specific ones add the draw option s to the first block.; In my example plot",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3449
https://github.com/root-project/root/pull/3449:3484,Availability,error,error,3484,"similar to TGraph::Paint and TGraphPainter::PaintHelper and can be deleted if the class should become part of root and TGraphMultiErrors::PaintGraphMultiErrors is being included in the TGraphPainter class.; The function TGraphMultiErrors::PaintReverse serves the same purpose as TGraphPainter::PaintReverse and should be deleted too if the class becomes part of ROOT.; The function TGraphMultiErrors::PaintGraphMultiErrors performs the actual painting and would have to be included in the TGraphPainter class. **Drawing / Painting options**; To be able to define different drawing options for the multiple error dimensions the option string can consist of multiple blocks separated by semicolons. The painting method separates the options in multiple options for each y error dimension and one for basic painting and the x errors. In case there are <= NErrorDimensions blocks given, the first block is used for basic painting and for the first dimension of y errors. Y error dimensions without an individual block are painted with “”.; Tn case there are NErrorDimensions + 1 given, the first block is used only for basic painting. The remaining blocks are distributed over the y error dimensions In case there are > NErrorDimensions + 1 blocks given an error is returned. All drawing options of TGraphAsymmErrors are implemented. For explanation of the drawing options see TGraphPainter::PaintGraphAsymmErrors.; Additionally one can specify x0 or y0 to skip points with x = 0 or y = 0 The Draw option s=%f can be used to multiply the corresponding x errors with %f. This is useful in combination with e.g. option 2 if the boxes are supposed to have only half the width of the bin, in this case the option would be s=0.5. Per default the Fill and Line Styles of the Graph are being used for all error dimensions. To use the specific ones add the draw option s to the first block.; In my example plot the drawing options are “A P X Y0 S ; Z ; 5 s=0.5 ; 3” which means the graph is drawn with Axes, Mark",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3449
https://github.com/root-project/root/pull/3449:3694,Availability,error,error,3694,"lass.; The function TGraphMultiErrors::PaintReverse serves the same purpose as TGraphPainter::PaintReverse and should be deleted too if the class becomes part of ROOT.; The function TGraphMultiErrors::PaintGraphMultiErrors performs the actual painting and would have to be included in the TGraphPainter class. **Drawing / Painting options**; To be able to define different drawing options for the multiple error dimensions the option string can consist of multiple blocks separated by semicolons. The painting method separates the options in multiple options for each y error dimension and one for basic painting and the x errors. In case there are <= NErrorDimensions blocks given, the first block is used for basic painting and for the first dimension of y errors. Y error dimensions without an individual block are painted with “”.; Tn case there are NErrorDimensions + 1 given, the first block is used only for basic painting. The remaining blocks are distributed over the y error dimensions In case there are > NErrorDimensions + 1 blocks given an error is returned. All drawing options of TGraphAsymmErrors are implemented. For explanation of the drawing options see TGraphPainter::PaintGraphAsymmErrors.; Additionally one can specify x0 or y0 to skip points with x = 0 or y = 0 The Draw option s=%f can be used to multiply the corresponding x errors with %f. This is useful in combination with e.g. option 2 if the boxes are supposed to have only half the width of the bin, in this case the option would be s=0.5. Per default the Fill and Line Styles of the Graph are being used for all error dimensions. To use the specific ones add the draw option s to the first block.; In my example plot the drawing options are “A P X Y0 S ; Z ; 5 s=0.5 ; 3” which means the graph is drawn with Axes, Markers, no Errors on X, no errors on points with y = 0 and individual Fill and Line attributes for all error dimensions for the general part. The first error dimension (statistical errors) is drawn with l",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3449
https://github.com/root-project/root/pull/3449:3768,Availability,error,error,3768,"lass.; The function TGraphMultiErrors::PaintReverse serves the same purpose as TGraphPainter::PaintReverse and should be deleted too if the class becomes part of ROOT.; The function TGraphMultiErrors::PaintGraphMultiErrors performs the actual painting and would have to be included in the TGraphPainter class. **Drawing / Painting options**; To be able to define different drawing options for the multiple error dimensions the option string can consist of multiple blocks separated by semicolons. The painting method separates the options in multiple options for each y error dimension and one for basic painting and the x errors. In case there are <= NErrorDimensions blocks given, the first block is used for basic painting and for the first dimension of y errors. Y error dimensions without an individual block are painted with “”.; Tn case there are NErrorDimensions + 1 given, the first block is used only for basic painting. The remaining blocks are distributed over the y error dimensions In case there are > NErrorDimensions + 1 blocks given an error is returned. All drawing options of TGraphAsymmErrors are implemented. For explanation of the drawing options see TGraphPainter::PaintGraphAsymmErrors.; Additionally one can specify x0 or y0 to skip points with x = 0 or y = 0 The Draw option s=%f can be used to multiply the corresponding x errors with %f. This is useful in combination with e.g. option 2 if the boxes are supposed to have only half the width of the bin, in this case the option would be s=0.5. Per default the Fill and Line Styles of the Graph are being used for all error dimensions. To use the specific ones add the draw option s to the first block.; In my example plot the drawing options are “A P X Y0 S ; Z ; 5 s=0.5 ; 3” which means the graph is drawn with Axes, Markers, no Errors on X, no errors on points with y = 0 and individual Fill and Line attributes for all error dimensions for the general part. The first error dimension (statistical errors) is drawn with l",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3449
https://github.com/root-project/root/pull/3449:4065,Availability,error,errors,4065,"e TGraphPainter class. **Drawing / Painting options**; To be able to define different drawing options for the multiple error dimensions the option string can consist of multiple blocks separated by semicolons. The painting method separates the options in multiple options for each y error dimension and one for basic painting and the x errors. In case there are <= NErrorDimensions blocks given, the first block is used for basic painting and for the first dimension of y errors. Y error dimensions without an individual block are painted with “”.; Tn case there are NErrorDimensions + 1 given, the first block is used only for basic painting. The remaining blocks are distributed over the y error dimensions In case there are > NErrorDimensions + 1 blocks given an error is returned. All drawing options of TGraphAsymmErrors are implemented. For explanation of the drawing options see TGraphPainter::PaintGraphAsymmErrors.; Additionally one can specify x0 or y0 to skip points with x = 0 or y = 0 The Draw option s=%f can be used to multiply the corresponding x errors with %f. This is useful in combination with e.g. option 2 if the boxes are supposed to have only half the width of the bin, in this case the option would be s=0.5. Per default the Fill and Line Styles of the Graph are being used for all error dimensions. To use the specific ones add the draw option s to the first block.; In my example plot the drawing options are “A P X Y0 S ; Z ; 5 s=0.5 ; 3” which means the graph is drawn with Axes, Markers, no Errors on X, no errors on points with y = 0 and individual Fill and Line attributes for all error dimensions for the general part. The first error dimension (statistical errors) is drawn with lines without anything on their tip. The second error dimension (Point to Point Systematics) is drawn with boxes of half the width of the X-Errors. The third error dimension (Common Systematics) is drawn as an filled error band. **Individual Fill and Line Attributes for each error dimens",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3449
https://github.com/root-project/root/pull/3449:4309,Availability,error,error,4309,"ch y error dimension and one for basic painting and the x errors. In case there are <= NErrorDimensions blocks given, the first block is used for basic painting and for the first dimension of y errors. Y error dimensions without an individual block are painted with “”.; Tn case there are NErrorDimensions + 1 given, the first block is used only for basic painting. The remaining blocks are distributed over the y error dimensions In case there are > NErrorDimensions + 1 blocks given an error is returned. All drawing options of TGraphAsymmErrors are implemented. For explanation of the drawing options see TGraphPainter::PaintGraphAsymmErrors.; Additionally one can specify x0 or y0 to skip points with x = 0 or y = 0 The Draw option s=%f can be used to multiply the corresponding x errors with %f. This is useful in combination with e.g. option 2 if the boxes are supposed to have only half the width of the bin, in this case the option would be s=0.5. Per default the Fill and Line Styles of the Graph are being used for all error dimensions. To use the specific ones add the draw option s to the first block.; In my example plot the drawing options are “A P X Y0 S ; Z ; 5 s=0.5 ; 3” which means the graph is drawn with Axes, Markers, no Errors on X, no errors on points with y = 0 and individual Fill and Line attributes for all error dimensions for the general part. The first error dimension (statistical errors) is drawn with lines without anything on their tip. The second error dimension (Point to Point Systematics) is drawn with boxes of half the width of the X-Errors. The third error dimension (Common Systematics) is drawn as an filled error band. **Individual Fill and Line Attributes for each error dimension**; This is being realized by overloading the Getter and Setter functions of TAttFill and TAttLine with an additional dimension parameter. Furthermore there are Getter and Setter functions for full TAttFill and TAttLine objects to get / set all attributes at once. To keep fu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3449
https://github.com/root-project/root/pull/3449:4523,Availability,Error,Errors,4523,"e there are NErrorDimensions + 1 given, the first block is used only for basic painting. The remaining blocks are distributed over the y error dimensions In case there are > NErrorDimensions + 1 blocks given an error is returned. All drawing options of TGraphAsymmErrors are implemented. For explanation of the drawing options see TGraphPainter::PaintGraphAsymmErrors.; Additionally one can specify x0 or y0 to skip points with x = 0 or y = 0 The Draw option s=%f can be used to multiply the corresponding x errors with %f. This is useful in combination with e.g. option 2 if the boxes are supposed to have only half the width of the bin, in this case the option would be s=0.5. Per default the Fill and Line Styles of the Graph are being used for all error dimensions. To use the specific ones add the draw option s to the first block.; In my example plot the drawing options are “A P X Y0 S ; Z ; 5 s=0.5 ; 3” which means the graph is drawn with Axes, Markers, no Errors on X, no errors on points with y = 0 and individual Fill and Line attributes for all error dimensions for the general part. The first error dimension (statistical errors) is drawn with lines without anything on their tip. The second error dimension (Point to Point Systematics) is drawn with boxes of half the width of the X-Errors. The third error dimension (Common Systematics) is drawn as an filled error band. **Individual Fill and Line Attributes for each error dimension**; This is being realized by overloading the Getter and Setter functions of TAttFill and TAttLine with an additional dimension parameter. Furthermore there are Getter and Setter functions for full TAttFill and TAttLine objects to get / set all attributes at once. To keep full compatibility with TGraphAsymmErrors by default the TAttFill and TAttLine attributes of the object are being used for all error dimensions. To activate using the individual ones add the Draw option “S” to the first block of the Draw options like in my example. I hope you fi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3449
https://github.com/root-project/root/pull/3449:4539,Availability,error,errors,4539,"e there are NErrorDimensions + 1 given, the first block is used only for basic painting. The remaining blocks are distributed over the y error dimensions In case there are > NErrorDimensions + 1 blocks given an error is returned. All drawing options of TGraphAsymmErrors are implemented. For explanation of the drawing options see TGraphPainter::PaintGraphAsymmErrors.; Additionally one can specify x0 or y0 to skip points with x = 0 or y = 0 The Draw option s=%f can be used to multiply the corresponding x errors with %f. This is useful in combination with e.g. option 2 if the boxes are supposed to have only half the width of the bin, in this case the option would be s=0.5. Per default the Fill and Line Styles of the Graph are being used for all error dimensions. To use the specific ones add the draw option s to the first block.; In my example plot the drawing options are “A P X Y0 S ; Z ; 5 s=0.5 ; 3” which means the graph is drawn with Axes, Markers, no Errors on X, no errors on points with y = 0 and individual Fill and Line attributes for all error dimensions for the general part. The first error dimension (statistical errors) is drawn with lines without anything on their tip. The second error dimension (Point to Point Systematics) is drawn with boxes of half the width of the X-Errors. The third error dimension (Common Systematics) is drawn as an filled error band. **Individual Fill and Line Attributes for each error dimension**; This is being realized by overloading the Getter and Setter functions of TAttFill and TAttLine with an additional dimension parameter. Furthermore there are Getter and Setter functions for full TAttFill and TAttLine objects to get / set all attributes at once. To keep full compatibility with TGraphAsymmErrors by default the TAttFill and TAttLine attributes of the object are being used for all error dimensions. To activate using the individual ones add the Draw option “S” to the first block of the Draw options like in my example. I hope you fi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3449
https://github.com/root-project/root/pull/3449:4615,Availability,error,error,4615,"e there are NErrorDimensions + 1 given, the first block is used only for basic painting. The remaining blocks are distributed over the y error dimensions In case there are > NErrorDimensions + 1 blocks given an error is returned. All drawing options of TGraphAsymmErrors are implemented. For explanation of the drawing options see TGraphPainter::PaintGraphAsymmErrors.; Additionally one can specify x0 or y0 to skip points with x = 0 or y = 0 The Draw option s=%f can be used to multiply the corresponding x errors with %f. This is useful in combination with e.g. option 2 if the boxes are supposed to have only half the width of the bin, in this case the option would be s=0.5. Per default the Fill and Line Styles of the Graph are being used for all error dimensions. To use the specific ones add the draw option s to the first block.; In my example plot the drawing options are “A P X Y0 S ; Z ; 5 s=0.5 ; 3” which means the graph is drawn with Axes, Markers, no Errors on X, no errors on points with y = 0 and individual Fill and Line attributes for all error dimensions for the general part. The first error dimension (statistical errors) is drawn with lines without anything on their tip. The second error dimension (Point to Point Systematics) is drawn with boxes of half the width of the X-Errors. The third error dimension (Common Systematics) is drawn as an filled error band. **Individual Fill and Line Attributes for each error dimension**; This is being realized by overloading the Getter and Setter functions of TAttFill and TAttLine with an additional dimension parameter. Furthermore there are Getter and Setter functions for full TAttFill and TAttLine objects to get / set all attributes at once. To keep full compatibility with TGraphAsymmErrors by default the TAttFill and TAttLine attributes of the object are being used for all error dimensions. To activate using the individual ones add the Draw option “S” to the first block of the Draw options like in my example. I hope you fi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3449
https://github.com/root-project/root/pull/3449:4664,Availability,error,error,4664,"mensions In case there are > NErrorDimensions + 1 blocks given an error is returned. All drawing options of TGraphAsymmErrors are implemented. For explanation of the drawing options see TGraphPainter::PaintGraphAsymmErrors.; Additionally one can specify x0 or y0 to skip points with x = 0 or y = 0 The Draw option s=%f can be used to multiply the corresponding x errors with %f. This is useful in combination with e.g. option 2 if the boxes are supposed to have only half the width of the bin, in this case the option would be s=0.5. Per default the Fill and Line Styles of the Graph are being used for all error dimensions. To use the specific ones add the draw option s to the first block.; In my example plot the drawing options are “A P X Y0 S ; Z ; 5 s=0.5 ; 3” which means the graph is drawn with Axes, Markers, no Errors on X, no errors on points with y = 0 and individual Fill and Line attributes for all error dimensions for the general part. The first error dimension (statistical errors) is drawn with lines without anything on their tip. The second error dimension (Point to Point Systematics) is drawn with boxes of half the width of the X-Errors. The third error dimension (Common Systematics) is drawn as an filled error band. **Individual Fill and Line Attributes for each error dimension**; This is being realized by overloading the Getter and Setter functions of TAttFill and TAttLine with an additional dimension parameter. Furthermore there are Getter and Setter functions for full TAttFill and TAttLine objects to get / set all attributes at once. To keep full compatibility with TGraphAsymmErrors by default the TAttFill and TAttLine attributes of the object are being used for all error dimensions. To activate using the individual ones add the Draw option “S” to the first block of the Draw options like in my example. I hope you find my class as useful as I do and vote for it to become part of ROOT in the future. :smile: . I tried to run the tests, but they failed at files",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3449
https://github.com/root-project/root/pull/3449:4693,Availability,error,errors,4693,"mensions In case there are > NErrorDimensions + 1 blocks given an error is returned. All drawing options of TGraphAsymmErrors are implemented. For explanation of the drawing options see TGraphPainter::PaintGraphAsymmErrors.; Additionally one can specify x0 or y0 to skip points with x = 0 or y = 0 The Draw option s=%f can be used to multiply the corresponding x errors with %f. This is useful in combination with e.g. option 2 if the boxes are supposed to have only half the width of the bin, in this case the option would be s=0.5. Per default the Fill and Line Styles of the Graph are being used for all error dimensions. To use the specific ones add the draw option s to the first block.; In my example plot the drawing options are “A P X Y0 S ; Z ; 5 s=0.5 ; 3” which means the graph is drawn with Axes, Markers, no Errors on X, no errors on points with y = 0 and individual Fill and Line attributes for all error dimensions for the general part. The first error dimension (statistical errors) is drawn with lines without anything on their tip. The second error dimension (Point to Point Systematics) is drawn with boxes of half the width of the X-Errors. The third error dimension (Common Systematics) is drawn as an filled error band. **Individual Fill and Line Attributes for each error dimension**; This is being realized by overloading the Getter and Setter functions of TAttFill and TAttLine with an additional dimension parameter. Furthermore there are Getter and Setter functions for full TAttFill and TAttLine objects to get / set all attributes at once. To keep full compatibility with TGraphAsymmErrors by default the TAttFill and TAttLine attributes of the object are being used for all error dimensions. To activate using the individual ones add the Draw option “S” to the first block of the Draw options like in my example. I hope you find my class as useful as I do and vote for it to become part of ROOT in the future. :smile: . I tried to run the tests, but they failed at files",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3449
https://github.com/root-project/root/pull/3449:4763,Availability,error,error,4763," of TGraphAsymmErrors are implemented. For explanation of the drawing options see TGraphPainter::PaintGraphAsymmErrors.; Additionally one can specify x0 or y0 to skip points with x = 0 or y = 0 The Draw option s=%f can be used to multiply the corresponding x errors with %f. This is useful in combination with e.g. option 2 if the boxes are supposed to have only half the width of the bin, in this case the option would be s=0.5. Per default the Fill and Line Styles of the Graph are being used for all error dimensions. To use the specific ones add the draw option s to the first block.; In my example plot the drawing options are “A P X Y0 S ; Z ; 5 s=0.5 ; 3” which means the graph is drawn with Axes, Markers, no Errors on X, no errors on points with y = 0 and individual Fill and Line attributes for all error dimensions for the general part. The first error dimension (statistical errors) is drawn with lines without anything on their tip. The second error dimension (Point to Point Systematics) is drawn with boxes of half the width of the X-Errors. The third error dimension (Common Systematics) is drawn as an filled error band. **Individual Fill and Line Attributes for each error dimension**; This is being realized by overloading the Getter and Setter functions of TAttFill and TAttLine with an additional dimension parameter. Furthermore there are Getter and Setter functions for full TAttFill and TAttLine objects to get / set all attributes at once. To keep full compatibility with TGraphAsymmErrors by default the TAttFill and TAttLine attributes of the object are being used for all error dimensions. To activate using the individual ones add the Draw option “S” to the first block of the Draw options like in my example. I hope you find my class as useful as I do and vote for it to become part of ROOT in the future. :smile: . I tried to run the tests, but they failed at files having nothing to do with my implementation. There seem to be a few problem in the master branch which w",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3449
https://github.com/root-project/root/pull/3449:4855,Availability,Error,Errors,4855," of TGraphAsymmErrors are implemented. For explanation of the drawing options see TGraphPainter::PaintGraphAsymmErrors.; Additionally one can specify x0 or y0 to skip points with x = 0 or y = 0 The Draw option s=%f can be used to multiply the corresponding x errors with %f. This is useful in combination with e.g. option 2 if the boxes are supposed to have only half the width of the bin, in this case the option would be s=0.5. Per default the Fill and Line Styles of the Graph are being used for all error dimensions. To use the specific ones add the draw option s to the first block.; In my example plot the drawing options are “A P X Y0 S ; Z ; 5 s=0.5 ; 3” which means the graph is drawn with Axes, Markers, no Errors on X, no errors on points with y = 0 and individual Fill and Line attributes for all error dimensions for the general part. The first error dimension (statistical errors) is drawn with lines without anything on their tip. The second error dimension (Point to Point Systematics) is drawn with boxes of half the width of the X-Errors. The third error dimension (Common Systematics) is drawn as an filled error band. **Individual Fill and Line Attributes for each error dimension**; This is being realized by overloading the Getter and Setter functions of TAttFill and TAttLine with an additional dimension parameter. Furthermore there are Getter and Setter functions for full TAttFill and TAttLine objects to get / set all attributes at once. To keep full compatibility with TGraphAsymmErrors by default the TAttFill and TAttLine attributes of the object are being used for all error dimensions. To activate using the individual ones add the Draw option “S” to the first block of the Draw options like in my example. I hope you find my class as useful as I do and vote for it to become part of ROOT in the future. :smile: . I tried to run the tests, but they failed at files having nothing to do with my implementation. There seem to be a few problem in the master branch which w",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3449
https://github.com/root-project/root/pull/3449:4873,Availability,error,error,4873,":PaintGraphAsymmErrors.; Additionally one can specify x0 or y0 to skip points with x = 0 or y = 0 The Draw option s=%f can be used to multiply the corresponding x errors with %f. This is useful in combination with e.g. option 2 if the boxes are supposed to have only half the width of the bin, in this case the option would be s=0.5. Per default the Fill and Line Styles of the Graph are being used for all error dimensions. To use the specific ones add the draw option s to the first block.; In my example plot the drawing options are “A P X Y0 S ; Z ; 5 s=0.5 ; 3” which means the graph is drawn with Axes, Markers, no Errors on X, no errors on points with y = 0 and individual Fill and Line attributes for all error dimensions for the general part. The first error dimension (statistical errors) is drawn with lines without anything on their tip. The second error dimension (Point to Point Systematics) is drawn with boxes of half the width of the X-Errors. The third error dimension (Common Systematics) is drawn as an filled error band. **Individual Fill and Line Attributes for each error dimension**; This is being realized by overloading the Getter and Setter functions of TAttFill and TAttLine with an additional dimension parameter. Furthermore there are Getter and Setter functions for full TAttFill and TAttLine objects to get / set all attributes at once. To keep full compatibility with TGraphAsymmErrors by default the TAttFill and TAttLine attributes of the object are being used for all error dimensions. To activate using the individual ones add the Draw option “S” to the first block of the Draw options like in my example. I hope you find my class as useful as I do and vote for it to become part of ROOT in the future. :smile: . I tried to run the tests, but they failed at files having nothing to do with my implementation. There seem to be a few problem in the master branch which would explain why the nightly build failed. I will try to investigate more. If you encounter any ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3449
https://github.com/root-project/root/pull/3449:4932,Availability,error,error,4932,":PaintGraphAsymmErrors.; Additionally one can specify x0 or y0 to skip points with x = 0 or y = 0 The Draw option s=%f can be used to multiply the corresponding x errors with %f. This is useful in combination with e.g. option 2 if the boxes are supposed to have only half the width of the bin, in this case the option would be s=0.5. Per default the Fill and Line Styles of the Graph are being used for all error dimensions. To use the specific ones add the draw option s to the first block.; In my example plot the drawing options are “A P X Y0 S ; Z ; 5 s=0.5 ; 3” which means the graph is drawn with Axes, Markers, no Errors on X, no errors on points with y = 0 and individual Fill and Line attributes for all error dimensions for the general part. The first error dimension (statistical errors) is drawn with lines without anything on their tip. The second error dimension (Point to Point Systematics) is drawn with boxes of half the width of the X-Errors. The third error dimension (Common Systematics) is drawn as an filled error band. **Individual Fill and Line Attributes for each error dimension**; This is being realized by overloading the Getter and Setter functions of TAttFill and TAttLine with an additional dimension parameter. Furthermore there are Getter and Setter functions for full TAttFill and TAttLine objects to get / set all attributes at once. To keep full compatibility with TGraphAsymmErrors by default the TAttFill and TAttLine attributes of the object are being used for all error dimensions. To activate using the individual ones add the Draw option “S” to the first block of the Draw options like in my example. I hope you find my class as useful as I do and vote for it to become part of ROOT in the future. :smile: . I tried to run the tests, but they failed at files having nothing to do with my implementation. There seem to be a few problem in the master branch which would explain why the nightly build failed. I will try to investigate more. If you encounter any ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3449
https://github.com/root-project/root/pull/3449:4991,Availability,error,error,4991,"y the corresponding x errors with %f. This is useful in combination with e.g. option 2 if the boxes are supposed to have only half the width of the bin, in this case the option would be s=0.5. Per default the Fill and Line Styles of the Graph are being used for all error dimensions. To use the specific ones add the draw option s to the first block.; In my example plot the drawing options are “A P X Y0 S ; Z ; 5 s=0.5 ; 3” which means the graph is drawn with Axes, Markers, no Errors on X, no errors on points with y = 0 and individual Fill and Line attributes for all error dimensions for the general part. The first error dimension (statistical errors) is drawn with lines without anything on their tip. The second error dimension (Point to Point Systematics) is drawn with boxes of half the width of the X-Errors. The third error dimension (Common Systematics) is drawn as an filled error band. **Individual Fill and Line Attributes for each error dimension**; This is being realized by overloading the Getter and Setter functions of TAttFill and TAttLine with an additional dimension parameter. Furthermore there are Getter and Setter functions for full TAttFill and TAttLine objects to get / set all attributes at once. To keep full compatibility with TGraphAsymmErrors by default the TAttFill and TAttLine attributes of the object are being used for all error dimensions. To activate using the individual ones add the Draw option “S” to the first block of the Draw options like in my example. I hope you find my class as useful as I do and vote for it to become part of ROOT in the future. :smile: . I tried to run the tests, but they failed at files having nothing to do with my implementation. There seem to be a few problem in the master branch which would explain why the nightly build failed. I will try to investigate more. If you encounter any problems, please contact me and I will try to resolve them. All the best,; Simon Spies. ![example](https://user-images.githubusercontent.com/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3449
https://github.com/root-project/root/pull/3449:5406,Availability,error,error,5406,"bination with e.g. option 2 if the boxes are supposed to have only half the width of the bin, in this case the option would be s=0.5. Per default the Fill and Line Styles of the Graph are being used for all error dimensions. To use the specific ones add the draw option s to the first block.; In my example plot the drawing options are “A P X Y0 S ; Z ; 5 s=0.5 ; 3” which means the graph is drawn with Axes, Markers, no Errors on X, no errors on points with y = 0 and individual Fill and Line attributes for all error dimensions for the general part. The first error dimension (statistical errors) is drawn with lines without anything on their tip. The second error dimension (Point to Point Systematics) is drawn with boxes of half the width of the X-Errors. The third error dimension (Common Systematics) is drawn as an filled error band. **Individual Fill and Line Attributes for each error dimension**; This is being realized by overloading the Getter and Setter functions of TAttFill and TAttLine with an additional dimension parameter. Furthermore there are Getter and Setter functions for full TAttFill and TAttLine objects to get / set all attributes at once. To keep full compatibility with TGraphAsymmErrors by default the TAttFill and TAttLine attributes of the object are being used for all error dimensions. To activate using the individual ones add the Draw option “S” to the first block of the Draw options like in my example. I hope you find my class as useful as I do and vote for it to become part of ROOT in the future. :smile: . I tried to run the tests, but they failed at files having nothing to do with my implementation. There seem to be a few problem in the master branch which would explain why the nightly build failed. I will try to investigate more. If you encounter any problems, please contact me and I will try to resolve them. All the best,; Simon Spies. ![example](https://user-images.githubusercontent.com/5320187/53024715-dfa23d80-345f-11e9-9fd4-cae2ef3d11a1.png)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3449
https://github.com/root-project/root/pull/3449:396,Modifiability,inherit,inherits,396,"Hello,. My implementation is named TGraphMultiErrors and is basically a TGraphAsymmErrors with the possibility to include an unlimited amount of different types of y-Errors.; The whole functionality and naming convention of my class is strongly based on the TGraphAsymmErrors class. All functionalities of the TGraphAsymmErrors have been reimplemented. Furthermore like any other TGraph class it inherits from TGraph and has therefore all of it’s functionalities. I attached an example plot as a png picture. Unfortunatly I cannot upload the C macro here, but if you are interested you can find it on the forum: [https://root-forum.cern.ch/t/tgraphmultierrors-class-for-graphs-with-asymmetric-errors-and-multiple-different-y-error-types-e-g-statistic-and-systematic-errors/32784](https://root-forum.cern.ch/t/tgraphmultierrors-class-for-graphs-with-asymmetric-errors-and-multiple-different-y-error-types-e-g-statistic-and-systematic-errors/32784). Since the class reimplements all functionalities of TGraphAsymmErrors, you can refer to it’s documentation for most functionalities: https://root.cern.ch/doc/master/classTGraphAsymmErrors.html. **Differences to TGraphAsymmErrors**; Everywhere TGraphAsymmErrors uses arrays for the y-Errors, my class uses two dimensional arrays (Double_t**) of which the first dimension represents the index of the error dimension and the second one the point. It is assumed that the first y-Error is the statistical one and all following are systematical ones. Therefore when the statistical errors are being computed by a function everything applies to only the first error dimension.; In case a single error on y is required (Like for fitting) the errors are being summed according to the value of fSumErrorsMode which can be at the moment TGraphMultiErrors::kOnlyFirst for only returning the error of the first error type (usally the statistic one), TGraphMultiErrors::kSquareSum for returning the squared sum of the errors of all types (Gaussian propagation) or TGr",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3449
https://github.com/root-project/root/pull/3449:2131,Performance,perform,performed,2131,"rors**; Everywhere TGraphAsymmErrors uses arrays for the y-Errors, my class uses two dimensional arrays (Double_t**) of which the first dimension represents the index of the error dimension and the second one the point. It is assumed that the first y-Error is the statistical one and all following are systematical ones. Therefore when the statistical errors are being computed by a function everything applies to only the first error dimension.; In case a single error on y is required (Like for fitting) the errors are being summed according to the value of fSumErrorsMode which can be at the moment TGraphMultiErrors::kOnlyFirst for only returning the error of the first error type (usally the statistic one), TGraphMultiErrors::kSquareSum for returning the squared sum of the errors of all types (Gaussian propagation) or TGraphMultiErrors::kSum for just returning the sum of the errors from all error types. **Drawing / Painting**; The painting is being performed by the functions TGraphMultiErrors::Paint, TGraphMultiErrors::PaintReverse and TGraphMultiErrors::PaintGraphMultiErrors. If this class should ever become part of ROOT the first two are to be deleted, cause there are similar functions in the class TGraphPainter and the last one is supposed to be included in the TGraphPainter class. The function TGraphMultiErrors::Paint is similar to TGraph::Paint and TGraphPainter::PaintHelper and can be deleted if the class should become part of root and TGraphMultiErrors::PaintGraphMultiErrors is being included in the TGraphPainter class.; The function TGraphMultiErrors::PaintReverse serves the same purpose as TGraphPainter::PaintReverse and should be deleted too if the class becomes part of ROOT.; The function TGraphMultiErrors::PaintGraphMultiErrors performs the actual painting and would have to be included in the TGraphPainter class. **Drawing / Painting options**; To be able to define different drawing options for the multiple error dimensions the option string can consist of mu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3449
https://github.com/root-project/root/pull/3449:2938,Performance,perform,performs,2938,"rrors of all types (Gaussian propagation) or TGraphMultiErrors::kSum for just returning the sum of the errors from all error types. **Drawing / Painting**; The painting is being performed by the functions TGraphMultiErrors::Paint, TGraphMultiErrors::PaintReverse and TGraphMultiErrors::PaintGraphMultiErrors. If this class should ever become part of ROOT the first two are to be deleted, cause there are similar functions in the class TGraphPainter and the last one is supposed to be included in the TGraphPainter class. The function TGraphMultiErrors::Paint is similar to TGraph::Paint and TGraphPainter::PaintHelper and can be deleted if the class should become part of root and TGraphMultiErrors::PaintGraphMultiErrors is being included in the TGraphPainter class.; The function TGraphMultiErrors::PaintReverse serves the same purpose as TGraphPainter::PaintReverse and should be deleted too if the class becomes part of ROOT.; The function TGraphMultiErrors::PaintGraphMultiErrors performs the actual painting and would have to be included in the TGraphPainter class. **Drawing / Painting options**; To be able to define different drawing options for the multiple error dimensions the option string can consist of multiple blocks separated by semicolons. The painting method separates the options in multiple options for each y error dimension and one for basic painting and the x errors. In case there are <= NErrorDimensions blocks given, the first block is used for basic painting and for the first dimension of y errors. Y error dimensions without an individual block are painted with “”.; Tn case there are NErrorDimensions + 1 given, the first block is used only for basic painting. The remaining blocks are distributed over the y error dimensions In case there are > NErrorDimensions + 1 blocks given an error is returned. All drawing options of TGraphAsymmErrors are implemented. For explanation of the drawing options see TGraphPainter::PaintGraphAsymmErrors.; Additionally one can speci",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3449
https://github.com/root-project/root/pull/3449:5671,Testability,test,tests,5671,"bination with e.g. option 2 if the boxes are supposed to have only half the width of the bin, in this case the option would be s=0.5. Per default the Fill and Line Styles of the Graph are being used for all error dimensions. To use the specific ones add the draw option s to the first block.; In my example plot the drawing options are “A P X Y0 S ; Z ; 5 s=0.5 ; 3” which means the graph is drawn with Axes, Markers, no Errors on X, no errors on points with y = 0 and individual Fill and Line attributes for all error dimensions for the general part. The first error dimension (statistical errors) is drawn with lines without anything on their tip. The second error dimension (Point to Point Systematics) is drawn with boxes of half the width of the X-Errors. The third error dimension (Common Systematics) is drawn as an filled error band. **Individual Fill and Line Attributes for each error dimension**; This is being realized by overloading the Getter and Setter functions of TAttFill and TAttLine with an additional dimension parameter. Furthermore there are Getter and Setter functions for full TAttFill and TAttLine objects to get / set all attributes at once. To keep full compatibility with TGraphAsymmErrors by default the TAttFill and TAttLine attributes of the object are being used for all error dimensions. To activate using the individual ones add the Draw option “S” to the first block of the Draw options like in my example. I hope you find my class as useful as I do and vote for it to become part of ROOT in the future. :smile: . I tried to run the tests, but they failed at files having nothing to do with my implementation. There seem to be a few problem in the master branch which would explain why the nightly build failed. I will try to investigate more. If you encounter any problems, please contact me and I will try to resolve them. All the best,; Simon Spies. ![example](https://user-images.githubusercontent.com/5320187/53024715-dfa23d80-345f-11e9-9fd4-cae2ef3d11a1.png)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3449
https://github.com/root-project/root/pull/3452:653,Availability,Error,Errors,653,"Hello,. First of all sorry for all the mess I made with these pull requests. This is my first try and I did not really understood how GitHub works therefore my previous pull request was this messy and I decided to withdraw it and clean everything up before I request it again. And here we are, I ran some additional bugfixing and the ROOT tests which succeeded. Furthermore I tested my new class and everything I tried worked so I think now it's time to request the pull again. **Explanation**; My implementation is named TGraphMultiErrors and is basically a TGraphAsymmErrors with the possibility to include an unlimited amount of different types of y-Errors.; The whole functionality and naming convention of my class is strongly based on the TGraphAsymmErrors class. All functionalities of the TGraphAsymmErrors have been reimplemented. Furthermore like any other TGraph class it inherits from TGraph and has therefore all of it’s functionalities. I attached an example plot as a png picture. It's macro to be produced is included in the description part of the TGraphPainter class. **Differences to TGraphAsymmErrors**; Everywhere TGraphAsymmErrors uses arrays for the y-Errors, my class uses two dimensional arrays (Double_t**) of which the first dimension represents the index of the error dimension and the second one the point. It is assumed that the first y-Error is the statistical one and all following are systematical ones. Therefore when the statistical errors are being computed by a function everything applies to only the first error dimension.; In case a single error on y is required (Like for fitting) the errors are being summed according to the value of fSumErrorsMode which can be at the moment TGraphMultiErrors::kOnlyFirst for only returning the error of the first error type (usally the statistic one), TGraphMultiErrors::kSquareSum for returning the squared sum of the errors of all types (Gaussian propagation) or TGraphMultiErrors::kSum for just returning the sum of the e",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:1175,Availability,Error,Errors,1175," to withdraw it and clean everything up before I request it again. And here we are, I ran some additional bugfixing and the ROOT tests which succeeded. Furthermore I tested my new class and everything I tried worked so I think now it's time to request the pull again. **Explanation**; My implementation is named TGraphMultiErrors and is basically a TGraphAsymmErrors with the possibility to include an unlimited amount of different types of y-Errors.; The whole functionality and naming convention of my class is strongly based on the TGraphAsymmErrors class. All functionalities of the TGraphAsymmErrors have been reimplemented. Furthermore like any other TGraph class it inherits from TGraph and has therefore all of it’s functionalities. I attached an example plot as a png picture. It's macro to be produced is included in the description part of the TGraphPainter class. **Differences to TGraphAsymmErrors**; Everywhere TGraphAsymmErrors uses arrays for the y-Errors, my class uses two dimensional arrays (Double_t**) of which the first dimension represents the index of the error dimension and the second one the point. It is assumed that the first y-Error is the statistical one and all following are systematical ones. Therefore when the statistical errors are being computed by a function everything applies to only the first error dimension.; In case a single error on y is required (Like for fitting) the errors are being summed according to the value of fSumErrorsMode which can be at the moment TGraphMultiErrors::kOnlyFirst for only returning the error of the first error type (usally the statistic one), TGraphMultiErrors::kSquareSum for returning the squared sum of the errors of all types (Gaussian propagation) or TGraphMultiErrors::kSum for just returning the sum of the errors from all error types. **Drawing / Painting**; The painting is being performed by the TGraphPainter class like for any other classes. Therefore I added the function TGraphPainter::PaintGraphMultiErrors an",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:1290,Availability,error,error,1290," to withdraw it and clean everything up before I request it again. And here we are, I ran some additional bugfixing and the ROOT tests which succeeded. Furthermore I tested my new class and everything I tried worked so I think now it's time to request the pull again. **Explanation**; My implementation is named TGraphMultiErrors and is basically a TGraphAsymmErrors with the possibility to include an unlimited amount of different types of y-Errors.; The whole functionality and naming convention of my class is strongly based on the TGraphAsymmErrors class. All functionalities of the TGraphAsymmErrors have been reimplemented. Furthermore like any other TGraph class it inherits from TGraph and has therefore all of it’s functionalities. I attached an example plot as a png picture. It's macro to be produced is included in the description part of the TGraphPainter class. **Differences to TGraphAsymmErrors**; Everywhere TGraphAsymmErrors uses arrays for the y-Errors, my class uses two dimensional arrays (Double_t**) of which the first dimension represents the index of the error dimension and the second one the point. It is assumed that the first y-Error is the statistical one and all following are systematical ones. Therefore when the statistical errors are being computed by a function everything applies to only the first error dimension.; In case a single error on y is required (Like for fitting) the errors are being summed according to the value of fSumErrorsMode which can be at the moment TGraphMultiErrors::kOnlyFirst for only returning the error of the first error type (usally the statistic one), TGraphMultiErrors::kSquareSum for returning the squared sum of the errors of all types (Gaussian propagation) or TGraphMultiErrors::kSum for just returning the sum of the errors from all error types. **Drawing / Painting**; The painting is being performed by the TGraphPainter class like for any other classes. Therefore I added the function TGraphPainter::PaintGraphMultiErrors an",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:1367,Availability,Error,Error,1367," new class and everything I tried worked so I think now it's time to request the pull again. **Explanation**; My implementation is named TGraphMultiErrors and is basically a TGraphAsymmErrors with the possibility to include an unlimited amount of different types of y-Errors.; The whole functionality and naming convention of my class is strongly based on the TGraphAsymmErrors class. All functionalities of the TGraphAsymmErrors have been reimplemented. Furthermore like any other TGraph class it inherits from TGraph and has therefore all of it’s functionalities. I attached an example plot as a png picture. It's macro to be produced is included in the description part of the TGraphPainter class. **Differences to TGraphAsymmErrors**; Everywhere TGraphAsymmErrors uses arrays for the y-Errors, my class uses two dimensional arrays (Double_t**) of which the first dimension represents the index of the error dimension and the second one the point. It is assumed that the first y-Error is the statistical one and all following are systematical ones. Therefore when the statistical errors are being computed by a function everything applies to only the first error dimension.; In case a single error on y is required (Like for fitting) the errors are being summed according to the value of fSumErrorsMode which can be at the moment TGraphMultiErrors::kOnlyFirst for only returning the error of the first error type (usally the statistic one), TGraphMultiErrors::kSquareSum for returning the squared sum of the errors of all types (Gaussian propagation) or TGraphMultiErrors::kSum for just returning the sum of the errors from all error types. **Drawing / Painting**; The painting is being performed by the TGraphPainter class like for any other classes. Therefore I added the function TGraphPainter::PaintGraphMultiErrors and included a corresponding line in the TGraphPainter::PaintHelper function. **Drawing / Painting options**; To be able to define different drawing options for the multiple erro",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:1468,Availability,error,errors,1468,"implementation is named TGraphMultiErrors and is basically a TGraphAsymmErrors with the possibility to include an unlimited amount of different types of y-Errors.; The whole functionality and naming convention of my class is strongly based on the TGraphAsymmErrors class. All functionalities of the TGraphAsymmErrors have been reimplemented. Furthermore like any other TGraph class it inherits from TGraph and has therefore all of it’s functionalities. I attached an example plot as a png picture. It's macro to be produced is included in the description part of the TGraphPainter class. **Differences to TGraphAsymmErrors**; Everywhere TGraphAsymmErrors uses arrays for the y-Errors, my class uses two dimensional arrays (Double_t**) of which the first dimension represents the index of the error dimension and the second one the point. It is assumed that the first y-Error is the statistical one and all following are systematical ones. Therefore when the statistical errors are being computed by a function everything applies to only the first error dimension.; In case a single error on y is required (Like for fitting) the errors are being summed according to the value of fSumErrorsMode which can be at the moment TGraphMultiErrors::kOnlyFirst for only returning the error of the first error type (usally the statistic one), TGraphMultiErrors::kSquareSum for returning the squared sum of the errors of all types (Gaussian propagation) or TGraphMultiErrors::kSum for just returning the sum of the errors from all error types. **Drawing / Painting**; The painting is being performed by the TGraphPainter class like for any other classes. Therefore I added the function TGraphPainter::PaintGraphMultiErrors and included a corresponding line in the TGraphPainter::PaintHelper function. **Drawing / Painting options**; To be able to define different drawing options for the multiple error dimensions the option string can consist of multiple blocks separated by semicolons. The painting method separa",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:1545,Availability,error,error,1545,"implementation is named TGraphMultiErrors and is basically a TGraphAsymmErrors with the possibility to include an unlimited amount of different types of y-Errors.; The whole functionality and naming convention of my class is strongly based on the TGraphAsymmErrors class. All functionalities of the TGraphAsymmErrors have been reimplemented. Furthermore like any other TGraph class it inherits from TGraph and has therefore all of it’s functionalities. I attached an example plot as a png picture. It's macro to be produced is included in the description part of the TGraphPainter class. **Differences to TGraphAsymmErrors**; Everywhere TGraphAsymmErrors uses arrays for the y-Errors, my class uses two dimensional arrays (Double_t**) of which the first dimension represents the index of the error dimension and the second one the point. It is assumed that the first y-Error is the statistical one and all following are systematical ones. Therefore when the statistical errors are being computed by a function everything applies to only the first error dimension.; In case a single error on y is required (Like for fitting) the errors are being summed according to the value of fSumErrorsMode which can be at the moment TGraphMultiErrors::kOnlyFirst for only returning the error of the first error type (usally the statistic one), TGraphMultiErrors::kSquareSum for returning the squared sum of the errors of all types (Gaussian propagation) or TGraphMultiErrors::kSum for just returning the sum of the errors from all error types. **Drawing / Painting**; The painting is being performed by the TGraphPainter class like for any other classes. Therefore I added the function TGraphPainter::PaintGraphMultiErrors and included a corresponding line in the TGraphPainter::PaintHelper function. **Drawing / Painting options**; To be able to define different drawing options for the multiple error dimensions the option string can consist of multiple blocks separated by semicolons. The painting method separa",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:1580,Availability,error,error,1580,"he TGraphAsymmErrors have been reimplemented. Furthermore like any other TGraph class it inherits from TGraph and has therefore all of it’s functionalities. I attached an example plot as a png picture. It's macro to be produced is included in the description part of the TGraphPainter class. **Differences to TGraphAsymmErrors**; Everywhere TGraphAsymmErrors uses arrays for the y-Errors, my class uses two dimensional arrays (Double_t**) of which the first dimension represents the index of the error dimension and the second one the point. It is assumed that the first y-Error is the statistical one and all following are systematical ones. Therefore when the statistical errors are being computed by a function everything applies to only the first error dimension.; In case a single error on y is required (Like for fitting) the errors are being summed according to the value of fSumErrorsMode which can be at the moment TGraphMultiErrors::kOnlyFirst for only returning the error of the first error type (usally the statistic one), TGraphMultiErrors::kSquareSum for returning the squared sum of the errors of all types (Gaussian propagation) or TGraphMultiErrors::kSum for just returning the sum of the errors from all error types. **Drawing / Painting**; The painting is being performed by the TGraphPainter class like for any other classes. Therefore I added the function TGraphPainter::PaintGraphMultiErrors and included a corresponding line in the TGraphPainter::PaintHelper function. **Drawing / Painting options**; To be able to define different drawing options for the multiple error dimensions the option string can consist of multiple blocks separated by semicolons. The painting method separates the options in multiple options for each y error dimension and one for basic painting and the x errors. In case there are <= NErrorDimensions blocks given, the first block is used for basic painting and for the first dimension of y errors. Y error dimensions without an individual block are p",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:1626,Availability,error,errors,1626,"he TGraphAsymmErrors have been reimplemented. Furthermore like any other TGraph class it inherits from TGraph and has therefore all of it’s functionalities. I attached an example plot as a png picture. It's macro to be produced is included in the description part of the TGraphPainter class. **Differences to TGraphAsymmErrors**; Everywhere TGraphAsymmErrors uses arrays for the y-Errors, my class uses two dimensional arrays (Double_t**) of which the first dimension represents the index of the error dimension and the second one the point. It is assumed that the first y-Error is the statistical one and all following are systematical ones. Therefore when the statistical errors are being computed by a function everything applies to only the first error dimension.; In case a single error on y is required (Like for fitting) the errors are being summed according to the value of fSumErrorsMode which can be at the moment TGraphMultiErrors::kOnlyFirst for only returning the error of the first error type (usally the statistic one), TGraphMultiErrors::kSquareSum for returning the squared sum of the errors of all types (Gaussian propagation) or TGraphMultiErrors::kSum for just returning the sum of the errors from all error types. **Drawing / Painting**; The painting is being performed by the TGraphPainter class like for any other classes. Therefore I added the function TGraphPainter::PaintGraphMultiErrors and included a corresponding line in the TGraphPainter::PaintHelper function. **Drawing / Painting options**; To be able to define different drawing options for the multiple error dimensions the option string can consist of multiple blocks separated by semicolons. The painting method separates the options in multiple options for each y error dimension and one for basic painting and the x errors. In case there are <= NErrorDimensions blocks given, the first block is used for basic painting and for the first dimension of y errors. Y error dimensions without an individual block are p",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:1771,Availability,error,error,1771,"he TGraphAsymmErrors have been reimplemented. Furthermore like any other TGraph class it inherits from TGraph and has therefore all of it’s functionalities. I attached an example plot as a png picture. It's macro to be produced is included in the description part of the TGraphPainter class. **Differences to TGraphAsymmErrors**; Everywhere TGraphAsymmErrors uses arrays for the y-Errors, my class uses two dimensional arrays (Double_t**) of which the first dimension represents the index of the error dimension and the second one the point. It is assumed that the first y-Error is the statistical one and all following are systematical ones. Therefore when the statistical errors are being computed by a function everything applies to only the first error dimension.; In case a single error on y is required (Like for fitting) the errors are being summed according to the value of fSumErrorsMode which can be at the moment TGraphMultiErrors::kOnlyFirst for only returning the error of the first error type (usally the statistic one), TGraphMultiErrors::kSquareSum for returning the squared sum of the errors of all types (Gaussian propagation) or TGraphMultiErrors::kSum for just returning the sum of the errors from all error types. **Drawing / Painting**; The painting is being performed by the TGraphPainter class like for any other classes. Therefore I added the function TGraphPainter::PaintGraphMultiErrors and included a corresponding line in the TGraphPainter::PaintHelper function. **Drawing / Painting options**; To be able to define different drawing options for the multiple error dimensions the option string can consist of multiple blocks separated by semicolons. The painting method separates the options in multiple options for each y error dimension and one for basic painting and the x errors. In case there are <= NErrorDimensions blocks given, the first block is used for basic painting and for the first dimension of y errors. Y error dimensions without an individual block are p",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:1790,Availability,error,error,1790,"he TGraphAsymmErrors have been reimplemented. Furthermore like any other TGraph class it inherits from TGraph and has therefore all of it’s functionalities. I attached an example plot as a png picture. It's macro to be produced is included in the description part of the TGraphPainter class. **Differences to TGraphAsymmErrors**; Everywhere TGraphAsymmErrors uses arrays for the y-Errors, my class uses two dimensional arrays (Double_t**) of which the first dimension represents the index of the error dimension and the second one the point. It is assumed that the first y-Error is the statistical one and all following are systematical ones. Therefore when the statistical errors are being computed by a function everything applies to only the first error dimension.; In case a single error on y is required (Like for fitting) the errors are being summed according to the value of fSumErrorsMode which can be at the moment TGraphMultiErrors::kOnlyFirst for only returning the error of the first error type (usally the statistic one), TGraphMultiErrors::kSquareSum for returning the squared sum of the errors of all types (Gaussian propagation) or TGraphMultiErrors::kSum for just returning the sum of the errors from all error types. **Drawing / Painting**; The painting is being performed by the TGraphPainter class like for any other classes. Therefore I added the function TGraphPainter::PaintGraphMultiErrors and included a corresponding line in the TGraphPainter::PaintHelper function. **Drawing / Painting options**; To be able to define different drawing options for the multiple error dimensions the option string can consist of multiple blocks separated by semicolons. The painting method separates the options in multiple options for each y error dimension and one for basic painting and the x errors. In case there are <= NErrorDimensions blocks given, the first block is used for basic painting and for the first dimension of y errors. Y error dimensions without an individual block are p",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:1896,Availability,error,errors,1896,"he TGraphAsymmErrors have been reimplemented. Furthermore like any other TGraph class it inherits from TGraph and has therefore all of it’s functionalities. I attached an example plot as a png picture. It's macro to be produced is included in the description part of the TGraphPainter class. **Differences to TGraphAsymmErrors**; Everywhere TGraphAsymmErrors uses arrays for the y-Errors, my class uses two dimensional arrays (Double_t**) of which the first dimension represents the index of the error dimension and the second one the point. It is assumed that the first y-Error is the statistical one and all following are systematical ones. Therefore when the statistical errors are being computed by a function everything applies to only the first error dimension.; In case a single error on y is required (Like for fitting) the errors are being summed according to the value of fSumErrorsMode which can be at the moment TGraphMultiErrors::kOnlyFirst for only returning the error of the first error type (usally the statistic one), TGraphMultiErrors::kSquareSum for returning the squared sum of the errors of all types (Gaussian propagation) or TGraphMultiErrors::kSum for just returning the sum of the errors from all error types. **Drawing / Painting**; The painting is being performed by the TGraphPainter class like for any other classes. Therefore I added the function TGraphPainter::PaintGraphMultiErrors and included a corresponding line in the TGraphPainter::PaintHelper function. **Drawing / Painting options**; To be able to define different drawing options for the multiple error dimensions the option string can consist of multiple blocks separated by semicolons. The painting method separates the options in multiple options for each y error dimension and one for basic painting and the x errors. In case there are <= NErrorDimensions blocks given, the first block is used for basic painting and for the first dimension of y errors. Y error dimensions without an individual block are p",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:2000,Availability,error,errors,2000,"he TGraphAsymmErrors have been reimplemented. Furthermore like any other TGraph class it inherits from TGraph and has therefore all of it’s functionalities. I attached an example plot as a png picture. It's macro to be produced is included in the description part of the TGraphPainter class. **Differences to TGraphAsymmErrors**; Everywhere TGraphAsymmErrors uses arrays for the y-Errors, my class uses two dimensional arrays (Double_t**) of which the first dimension represents the index of the error dimension and the second one the point. It is assumed that the first y-Error is the statistical one and all following are systematical ones. Therefore when the statistical errors are being computed by a function everything applies to only the first error dimension.; In case a single error on y is required (Like for fitting) the errors are being summed according to the value of fSumErrorsMode which can be at the moment TGraphMultiErrors::kOnlyFirst for only returning the error of the first error type (usally the statistic one), TGraphMultiErrors::kSquareSum for returning the squared sum of the errors of all types (Gaussian propagation) or TGraphMultiErrors::kSum for just returning the sum of the errors from all error types. **Drawing / Painting**; The painting is being performed by the TGraphPainter class like for any other classes. Therefore I added the function TGraphPainter::PaintGraphMultiErrors and included a corresponding line in the TGraphPainter::PaintHelper function. **Drawing / Painting options**; To be able to define different drawing options for the multiple error dimensions the option string can consist of multiple blocks separated by semicolons. The painting method separates the options in multiple options for each y error dimension and one for basic painting and the x errors. In case there are <= NErrorDimensions blocks given, the first block is used for basic painting and for the first dimension of y errors. Y error dimensions without an individual block are p",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:2016,Availability,error,error,2016,"he TGraphAsymmErrors have been reimplemented. Furthermore like any other TGraph class it inherits from TGraph and has therefore all of it’s functionalities. I attached an example plot as a png picture. It's macro to be produced is included in the description part of the TGraphPainter class. **Differences to TGraphAsymmErrors**; Everywhere TGraphAsymmErrors uses arrays for the y-Errors, my class uses two dimensional arrays (Double_t**) of which the first dimension represents the index of the error dimension and the second one the point. It is assumed that the first y-Error is the statistical one and all following are systematical ones. Therefore when the statistical errors are being computed by a function everything applies to only the first error dimension.; In case a single error on y is required (Like for fitting) the errors are being summed according to the value of fSumErrorsMode which can be at the moment TGraphMultiErrors::kOnlyFirst for only returning the error of the first error type (usally the statistic one), TGraphMultiErrors::kSquareSum for returning the squared sum of the errors of all types (Gaussian propagation) or TGraphMultiErrors::kSum for just returning the sum of the errors from all error types. **Drawing / Painting**; The painting is being performed by the TGraphPainter class like for any other classes. Therefore I added the function TGraphPainter::PaintGraphMultiErrors and included a corresponding line in the TGraphPainter::PaintHelper function. **Drawing / Painting options**; To be able to define different drawing options for the multiple error dimensions the option string can consist of multiple blocks separated by semicolons. The painting method separates the options in multiple options for each y error dimension and one for basic painting and the x errors. In case there are <= NErrorDimensions blocks given, the first block is used for basic painting and for the first dimension of y errors. Y error dimensions without an individual block are p",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:2382,Availability,error,error,2382,"e statistical one and all following are systematical ones. Therefore when the statistical errors are being computed by a function everything applies to only the first error dimension.; In case a single error on y is required (Like for fitting) the errors are being summed according to the value of fSumErrorsMode which can be at the moment TGraphMultiErrors::kOnlyFirst for only returning the error of the first error type (usally the statistic one), TGraphMultiErrors::kSquareSum for returning the squared sum of the errors of all types (Gaussian propagation) or TGraphMultiErrors::kSum for just returning the sum of the errors from all error types. **Drawing / Painting**; The painting is being performed by the TGraphPainter class like for any other classes. Therefore I added the function TGraphPainter::PaintGraphMultiErrors and included a corresponding line in the TGraphPainter::PaintHelper function. **Drawing / Painting options**; To be able to define different drawing options for the multiple error dimensions the option string can consist of multiple blocks separated by semicolons. The painting method separates the options in multiple options for each y error dimension and one for basic painting and the x errors. In case there are <= NErrorDimensions blocks given, the first block is used for basic painting and for the first dimension of y errors. Y error dimensions without an individual block are painted with “”.; Tn case there are NErrorDimensions + 1 given, the first block is used only for basic painting. The remaining blocks are distributed over the y error dimensions In case there are > NErrorDimensions + 1 blocks given an error is returned. All drawing options of TGraphAsymmErrors are implemented. For explanation of the drawing options see TGraphPainter::PaintGraphAsymmErrors.; Additionally one can specify x0 or y0 to skip points with x = 0 or y = 0 The Draw option s=%f can be used to multiply the corresponding x errors with %f. This is useful in combination with e.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:2546,Availability,error,error,2546,"first error dimension.; In case a single error on y is required (Like for fitting) the errors are being summed according to the value of fSumErrorsMode which can be at the moment TGraphMultiErrors::kOnlyFirst for only returning the error of the first error type (usally the statistic one), TGraphMultiErrors::kSquareSum for returning the squared sum of the errors of all types (Gaussian propagation) or TGraphMultiErrors::kSum for just returning the sum of the errors from all error types. **Drawing / Painting**; The painting is being performed by the TGraphPainter class like for any other classes. Therefore I added the function TGraphPainter::PaintGraphMultiErrors and included a corresponding line in the TGraphPainter::PaintHelper function. **Drawing / Painting options**; To be able to define different drawing options for the multiple error dimensions the option string can consist of multiple blocks separated by semicolons. The painting method separates the options in multiple options for each y error dimension and one for basic painting and the x errors. In case there are <= NErrorDimensions blocks given, the first block is used for basic painting and for the first dimension of y errors. Y error dimensions without an individual block are painted with “”.; Tn case there are NErrorDimensions + 1 given, the first block is used only for basic painting. The remaining blocks are distributed over the y error dimensions In case there are > NErrorDimensions + 1 blocks given an error is returned. All drawing options of TGraphAsymmErrors are implemented. For explanation of the drawing options see TGraphPainter::PaintGraphAsymmErrors.; Additionally one can specify x0 or y0 to skip points with x = 0 or y = 0 The Draw option s=%f can be used to multiply the corresponding x errors with %f. This is useful in combination with e.g. option 2 if the boxes are supposed to have only half the width of the bin, in this case the option would be s=0.5. Per default the Fill and Line Styles of th",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:2599,Availability,error,errors,2599,"first error dimension.; In case a single error on y is required (Like for fitting) the errors are being summed according to the value of fSumErrorsMode which can be at the moment TGraphMultiErrors::kOnlyFirst for only returning the error of the first error type (usally the statistic one), TGraphMultiErrors::kSquareSum for returning the squared sum of the errors of all types (Gaussian propagation) or TGraphMultiErrors::kSum for just returning the sum of the errors from all error types. **Drawing / Painting**; The painting is being performed by the TGraphPainter class like for any other classes. Therefore I added the function TGraphPainter::PaintGraphMultiErrors and included a corresponding line in the TGraphPainter::PaintHelper function. **Drawing / Painting options**; To be able to define different drawing options for the multiple error dimensions the option string can consist of multiple blocks separated by semicolons. The painting method separates the options in multiple options for each y error dimension and one for basic painting and the x errors. In case there are <= NErrorDimensions blocks given, the first block is used for basic painting and for the first dimension of y errors. Y error dimensions without an individual block are painted with “”.; Tn case there are NErrorDimensions + 1 given, the first block is used only for basic painting. The remaining blocks are distributed over the y error dimensions In case there are > NErrorDimensions + 1 blocks given an error is returned. All drawing options of TGraphAsymmErrors are implemented. For explanation of the drawing options see TGraphPainter::PaintGraphAsymmErrors.; Additionally one can specify x0 or y0 to skip points with x = 0 or y = 0 The Draw option s=%f can be used to multiply the corresponding x errors with %f. This is useful in combination with e.g. option 2 if the boxes are supposed to have only half the width of the bin, in this case the option would be s=0.5. Per default the Fill and Line Styles of th",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:2735,Availability,error,errors,2735,"f fSumErrorsMode which can be at the moment TGraphMultiErrors::kOnlyFirst for only returning the error of the first error type (usally the statistic one), TGraphMultiErrors::kSquareSum for returning the squared sum of the errors of all types (Gaussian propagation) or TGraphMultiErrors::kSum for just returning the sum of the errors from all error types. **Drawing / Painting**; The painting is being performed by the TGraphPainter class like for any other classes. Therefore I added the function TGraphPainter::PaintGraphMultiErrors and included a corresponding line in the TGraphPainter::PaintHelper function. **Drawing / Painting options**; To be able to define different drawing options for the multiple error dimensions the option string can consist of multiple blocks separated by semicolons. The painting method separates the options in multiple options for each y error dimension and one for basic painting and the x errors. In case there are <= NErrorDimensions blocks given, the first block is used for basic painting and for the first dimension of y errors. Y error dimensions without an individual block are painted with “”.; Tn case there are NErrorDimensions + 1 given, the first block is used only for basic painting. The remaining blocks are distributed over the y error dimensions In case there are > NErrorDimensions + 1 blocks given an error is returned. All drawing options of TGraphAsymmErrors are implemented. For explanation of the drawing options see TGraphPainter::PaintGraphAsymmErrors.; Additionally one can specify x0 or y0 to skip points with x = 0 or y = 0 The Draw option s=%f can be used to multiply the corresponding x errors with %f. This is useful in combination with e.g. option 2 if the boxes are supposed to have only half the width of the bin, in this case the option would be s=0.5. Per default the Fill and Line Styles of the Graph are being used for all error dimensions. To use the specific ones add the draw option s to the first block.; In my example plot",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:2745,Availability,error,error,2745," of the first error type (usally the statistic one), TGraphMultiErrors::kSquareSum for returning the squared sum of the errors of all types (Gaussian propagation) or TGraphMultiErrors::kSum for just returning the sum of the errors from all error types. **Drawing / Painting**; The painting is being performed by the TGraphPainter class like for any other classes. Therefore I added the function TGraphPainter::PaintGraphMultiErrors and included a corresponding line in the TGraphPainter::PaintHelper function. **Drawing / Painting options**; To be able to define different drawing options for the multiple error dimensions the option string can consist of multiple blocks separated by semicolons. The painting method separates the options in multiple options for each y error dimension and one for basic painting and the x errors. In case there are <= NErrorDimensions blocks given, the first block is used for basic painting and for the first dimension of y errors. Y error dimensions without an individual block are painted with “”.; Tn case there are NErrorDimensions + 1 given, the first block is used only for basic painting. The remaining blocks are distributed over the y error dimensions In case there are > NErrorDimensions + 1 blocks given an error is returned. All drawing options of TGraphAsymmErrors are implemented. For explanation of the drawing options see TGraphPainter::PaintGraphAsymmErrors.; Additionally one can specify x0 or y0 to skip points with x = 0 or y = 0 The Draw option s=%f can be used to multiply the corresponding x errors with %f. This is useful in combination with e.g. option 2 if the boxes are supposed to have only half the width of the bin, in this case the option would be s=0.5. Per default the Fill and Line Styles of the Graph are being used for all error dimensions. To use the specific ones add the draw option s to the first block.; In my example plot the drawing options are “a p s ; ; 5 s=0.5” which means the graph is drawn with Axes, Markers and ind",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:2955,Availability,error,error,2955,"eturning the sum of the errors from all error types. **Drawing / Painting**; The painting is being performed by the TGraphPainter class like for any other classes. Therefore I added the function TGraphPainter::PaintGraphMultiErrors and included a corresponding line in the TGraphPainter::PaintHelper function. **Drawing / Painting options**; To be able to define different drawing options for the multiple error dimensions the option string can consist of multiple blocks separated by semicolons. The painting method separates the options in multiple options for each y error dimension and one for basic painting and the x errors. In case there are <= NErrorDimensions blocks given, the first block is used for basic painting and for the first dimension of y errors. Y error dimensions without an individual block are painted with “”.; Tn case there are NErrorDimensions + 1 given, the first block is used only for basic painting. The remaining blocks are distributed over the y error dimensions In case there are > NErrorDimensions + 1 blocks given an error is returned. All drawing options of TGraphAsymmErrors are implemented. For explanation of the drawing options see TGraphPainter::PaintGraphAsymmErrors.; Additionally one can specify x0 or y0 to skip points with x = 0 or y = 0 The Draw option s=%f can be used to multiply the corresponding x errors with %f. This is useful in combination with e.g. option 2 if the boxes are supposed to have only half the width of the bin, in this case the option would be s=0.5. Per default the Fill and Line Styles of the Graph are being used for all error dimensions. To use the specific ones add the draw option s to the first block.; In my example plot the drawing options are “a p s ; ; 5 s=0.5” which means the graph is drawn with Axes, Markers and individual Fill and Line attributes for all error dimensions for the general part. The first error dimension (statistical errors) is drawn with default settings. The second error dimension (systematic err",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:3029,Availability,error,error,3029,"eturning the sum of the errors from all error types. **Drawing / Painting**; The painting is being performed by the TGraphPainter class like for any other classes. Therefore I added the function TGraphPainter::PaintGraphMultiErrors and included a corresponding line in the TGraphPainter::PaintHelper function. **Drawing / Painting options**; To be able to define different drawing options for the multiple error dimensions the option string can consist of multiple blocks separated by semicolons. The painting method separates the options in multiple options for each y error dimension and one for basic painting and the x errors. In case there are <= NErrorDimensions blocks given, the first block is used for basic painting and for the first dimension of y errors. Y error dimensions without an individual block are painted with “”.; Tn case there are NErrorDimensions + 1 given, the first block is used only for basic painting. The remaining blocks are distributed over the y error dimensions In case there are > NErrorDimensions + 1 blocks given an error is returned. All drawing options of TGraphAsymmErrors are implemented. For explanation of the drawing options see TGraphPainter::PaintGraphAsymmErrors.; Additionally one can specify x0 or y0 to skip points with x = 0 or y = 0 The Draw option s=%f can be used to multiply the corresponding x errors with %f. This is useful in combination with e.g. option 2 if the boxes are supposed to have only half the width of the bin, in this case the option would be s=0.5. Per default the Fill and Line Styles of the Graph are being used for all error dimensions. To use the specific ones add the draw option s to the first block.; In my example plot the drawing options are “a p s ; ; 5 s=0.5” which means the graph is drawn with Axes, Markers and individual Fill and Line attributes for all error dimensions for the general part. The first error dimension (statistical errors) is drawn with default settings. The second error dimension (systematic err",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:3326,Availability,error,errors,3326,":PaintHelper function. **Drawing / Painting options**; To be able to define different drawing options for the multiple error dimensions the option string can consist of multiple blocks separated by semicolons. The painting method separates the options in multiple options for each y error dimension and one for basic painting and the x errors. In case there are <= NErrorDimensions blocks given, the first block is used for basic painting and for the first dimension of y errors. Y error dimensions without an individual block are painted with “”.; Tn case there are NErrorDimensions + 1 given, the first block is used only for basic painting. The remaining blocks are distributed over the y error dimensions In case there are > NErrorDimensions + 1 blocks given an error is returned. All drawing options of TGraphAsymmErrors are implemented. For explanation of the drawing options see TGraphPainter::PaintGraphAsymmErrors.; Additionally one can specify x0 or y0 to skip points with x = 0 or y = 0 The Draw option s=%f can be used to multiply the corresponding x errors with %f. This is useful in combination with e.g. option 2 if the boxes are supposed to have only half the width of the bin, in this case the option would be s=0.5. Per default the Fill and Line Styles of the Graph are being used for all error dimensions. To use the specific ones add the draw option s to the first block.; In my example plot the drawing options are “a p s ; ; 5 s=0.5” which means the graph is drawn with Axes, Markers and individual Fill and Line attributes for all error dimensions for the general part. The first error dimension (statistical errors) is drawn with default settings. The second error dimension (systematic errors) is drawn with boxes of half the width of the X-Errors. **Individual Fill and Line Attributes for each error dimension**; This is being realized by overloading the Getter and Setter functions of TAttFill and TAttLine with an additional dimension parameter. Furthermore there are Gett",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:3570,Availability,error,error,3570,"ch y error dimension and one for basic painting and the x errors. In case there are <= NErrorDimensions blocks given, the first block is used for basic painting and for the first dimension of y errors. Y error dimensions without an individual block are painted with “”.; Tn case there are NErrorDimensions + 1 given, the first block is used only for basic painting. The remaining blocks are distributed over the y error dimensions In case there are > NErrorDimensions + 1 blocks given an error is returned. All drawing options of TGraphAsymmErrors are implemented. For explanation of the drawing options see TGraphPainter::PaintGraphAsymmErrors.; Additionally one can specify x0 or y0 to skip points with x = 0 or y = 0 The Draw option s=%f can be used to multiply the corresponding x errors with %f. This is useful in combination with e.g. option 2 if the boxes are supposed to have only half the width of the bin, in this case the option would be s=0.5. Per default the Fill and Line Styles of the Graph are being used for all error dimensions. To use the specific ones add the draw option s to the first block.; In my example plot the drawing options are “a p s ; ; 5 s=0.5” which means the graph is drawn with Axes, Markers and individual Fill and Line attributes for all error dimensions for the general part. The first error dimension (statistical errors) is drawn with default settings. The second error dimension (systematic errors) is drawn with boxes of half the width of the X-Errors. **Individual Fill and Line Attributes for each error dimension**; This is being realized by overloading the Getter and Setter functions of TAttFill and TAttLine with an additional dimension parameter. Furthermore there are Getter and Setter functions for full TAttFill and TAttLine objects to get / set all attributes at once. To keep full compatibility with TGraphAsymmErrors by default the TAttFill and TAttLine attributes of the object are being used for all error dimensions. To activate using the ind",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:3817,Availability,error,error,3817,"lock are painted with “”.; Tn case there are NErrorDimensions + 1 given, the first block is used only for basic painting. The remaining blocks are distributed over the y error dimensions In case there are > NErrorDimensions + 1 blocks given an error is returned. All drawing options of TGraphAsymmErrors are implemented. For explanation of the drawing options see TGraphPainter::PaintGraphAsymmErrors.; Additionally one can specify x0 or y0 to skip points with x = 0 or y = 0 The Draw option s=%f can be used to multiply the corresponding x errors with %f. This is useful in combination with e.g. option 2 if the boxes are supposed to have only half the width of the bin, in this case the option would be s=0.5. Per default the Fill and Line Styles of the Graph are being used for all error dimensions. To use the specific ones add the draw option s to the first block.; In my example plot the drawing options are “a p s ; ; 5 s=0.5” which means the graph is drawn with Axes, Markers and individual Fill and Line attributes for all error dimensions for the general part. The first error dimension (statistical errors) is drawn with default settings. The second error dimension (systematic errors) is drawn with boxes of half the width of the X-Errors. **Individual Fill and Line Attributes for each error dimension**; This is being realized by overloading the Getter and Setter functions of TAttFill and TAttLine with an additional dimension parameter. Furthermore there are Getter and Setter functions for full TAttFill and TAttLine objects to get / set all attributes at once. To keep full compatibility with TGraphAsymmErrors by default the TAttFill and TAttLine attributes of the object are being used for all error dimensions. To activate using the individual ones add the Draw option “S” to the first block of the Draw options like in my example. All the best,; Simon Spies. I hope you find my class as useful as I do and vote for it to become part of ROOT in the future. :smile:; ![example](htt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:3866,Availability,error,error,3866,"ic painting. The remaining blocks are distributed over the y error dimensions In case there are > NErrorDimensions + 1 blocks given an error is returned. All drawing options of TGraphAsymmErrors are implemented. For explanation of the drawing options see TGraphPainter::PaintGraphAsymmErrors.; Additionally one can specify x0 or y0 to skip points with x = 0 or y = 0 The Draw option s=%f can be used to multiply the corresponding x errors with %f. This is useful in combination with e.g. option 2 if the boxes are supposed to have only half the width of the bin, in this case the option would be s=0.5. Per default the Fill and Line Styles of the Graph are being used for all error dimensions. To use the specific ones add the draw option s to the first block.; In my example plot the drawing options are “a p s ; ; 5 s=0.5” which means the graph is drawn with Axes, Markers and individual Fill and Line attributes for all error dimensions for the general part. The first error dimension (statistical errors) is drawn with default settings. The second error dimension (systematic errors) is drawn with boxes of half the width of the X-Errors. **Individual Fill and Line Attributes for each error dimension**; This is being realized by overloading the Getter and Setter functions of TAttFill and TAttLine with an additional dimension parameter. Furthermore there are Getter and Setter functions for full TAttFill and TAttLine objects to get / set all attributes at once. To keep full compatibility with TGraphAsymmErrors by default the TAttFill and TAttLine attributes of the object are being used for all error dimensions. To activate using the individual ones add the Draw option “S” to the first block of the Draw options like in my example. All the best,; Simon Spies. I hope you find my class as useful as I do and vote for it to become part of ROOT in the future. :smile:; ![example](https://user-images.githubusercontent.com/5320187/53051016-15b0e300-349b-11e9-90d6-af75f21654a0.png); ![example]",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:3895,Availability,error,errors,3895,"ic painting. The remaining blocks are distributed over the y error dimensions In case there are > NErrorDimensions + 1 blocks given an error is returned. All drawing options of TGraphAsymmErrors are implemented. For explanation of the drawing options see TGraphPainter::PaintGraphAsymmErrors.; Additionally one can specify x0 or y0 to skip points with x = 0 or y = 0 The Draw option s=%f can be used to multiply the corresponding x errors with %f. This is useful in combination with e.g. option 2 if the boxes are supposed to have only half the width of the bin, in this case the option would be s=0.5. Per default the Fill and Line Styles of the Graph are being used for all error dimensions. To use the specific ones add the draw option s to the first block.; In my example plot the drawing options are “a p s ; ; 5 s=0.5” which means the graph is drawn with Axes, Markers and individual Fill and Line attributes for all error dimensions for the general part. The first error dimension (statistical errors) is drawn with default settings. The second error dimension (systematic errors) is drawn with boxes of half the width of the X-Errors. **Individual Fill and Line Attributes for each error dimension**; This is being realized by overloading the Getter and Setter functions of TAttFill and TAttLine with an additional dimension parameter. Furthermore there are Getter and Setter functions for full TAttFill and TAttLine objects to get / set all attributes at once. To keep full compatibility with TGraphAsymmErrors by default the TAttFill and TAttLine attributes of the object are being used for all error dimensions. To activate using the individual ones add the Draw option “S” to the first block of the Draw options like in my example. All the best,; Simon Spies. I hope you find my class as useful as I do and vote for it to become part of ROOT in the future. :smile:; ![example](https://user-images.githubusercontent.com/5320187/53051016-15b0e300-349b-11e9-90d6-af75f21654a0.png); ![example]",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:3946,Availability,error,error,3946," are > NErrorDimensions + 1 blocks given an error is returned. All drawing options of TGraphAsymmErrors are implemented. For explanation of the drawing options see TGraphPainter::PaintGraphAsymmErrors.; Additionally one can specify x0 or y0 to skip points with x = 0 or y = 0 The Draw option s=%f can be used to multiply the corresponding x errors with %f. This is useful in combination with e.g. option 2 if the boxes are supposed to have only half the width of the bin, in this case the option would be s=0.5. Per default the Fill and Line Styles of the Graph are being used for all error dimensions. To use the specific ones add the draw option s to the first block.; In my example plot the drawing options are “a p s ; ; 5 s=0.5” which means the graph is drawn with Axes, Markers and individual Fill and Line attributes for all error dimensions for the general part. The first error dimension (statistical errors) is drawn with default settings. The second error dimension (systematic errors) is drawn with boxes of half the width of the X-Errors. **Individual Fill and Line Attributes for each error dimension**; This is being realized by overloading the Getter and Setter functions of TAttFill and TAttLine with an additional dimension parameter. Furthermore there are Getter and Setter functions for full TAttFill and TAttLine objects to get / set all attributes at once. To keep full compatibility with TGraphAsymmErrors by default the TAttFill and TAttLine attributes of the object are being used for all error dimensions. To activate using the individual ones add the Draw option “S” to the first block of the Draw options like in my example. All the best,; Simon Spies. I hope you find my class as useful as I do and vote for it to become part of ROOT in the future. :smile:; ![example](https://user-images.githubusercontent.com/5320187/53051016-15b0e300-349b-11e9-90d6-af75f21654a0.png); ![example](https://user-images.githubusercontent.com/5320187/53085326-e7ff8480-3502-11e9-8945-59e025",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:3974,Availability,error,errors,3974," are > NErrorDimensions + 1 blocks given an error is returned. All drawing options of TGraphAsymmErrors are implemented. For explanation of the drawing options see TGraphPainter::PaintGraphAsymmErrors.; Additionally one can specify x0 or y0 to skip points with x = 0 or y = 0 The Draw option s=%f can be used to multiply the corresponding x errors with %f. This is useful in combination with e.g. option 2 if the boxes are supposed to have only half the width of the bin, in this case the option would be s=0.5. Per default the Fill and Line Styles of the Graph are being used for all error dimensions. To use the specific ones add the draw option s to the first block.; In my example plot the drawing options are “a p s ; ; 5 s=0.5” which means the graph is drawn with Axes, Markers and individual Fill and Line attributes for all error dimensions for the general part. The first error dimension (statistical errors) is drawn with default settings. The second error dimension (systematic errors) is drawn with boxes of half the width of the X-Errors. **Individual Fill and Line Attributes for each error dimension**; This is being realized by overloading the Getter and Setter functions of TAttFill and TAttLine with an additional dimension parameter. Furthermore there are Getter and Setter functions for full TAttFill and TAttLine objects to get / set all attributes at once. To keep full compatibility with TGraphAsymmErrors by default the TAttFill and TAttLine attributes of the object are being used for all error dimensions. To activate using the individual ones add the Draw option “S” to the first block of the Draw options like in my example. All the best,; Simon Spies. I hope you find my class as useful as I do and vote for it to become part of ROOT in the future. :smile:; ![example](https://user-images.githubusercontent.com/5320187/53051016-15b0e300-349b-11e9-90d6-af75f21654a0.png); ![example](https://user-images.githubusercontent.com/5320187/53085326-e7ff8480-3502-11e9-8945-59e025",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:4029,Availability,Error,Errors,4029," are > NErrorDimensions + 1 blocks given an error is returned. All drawing options of TGraphAsymmErrors are implemented. For explanation of the drawing options see TGraphPainter::PaintGraphAsymmErrors.; Additionally one can specify x0 or y0 to skip points with x = 0 or y = 0 The Draw option s=%f can be used to multiply the corresponding x errors with %f. This is useful in combination with e.g. option 2 if the boxes are supposed to have only half the width of the bin, in this case the option would be s=0.5. Per default the Fill and Line Styles of the Graph are being used for all error dimensions. To use the specific ones add the draw option s to the first block.; In my example plot the drawing options are “a p s ; ; 5 s=0.5” which means the graph is drawn with Axes, Markers and individual Fill and Line attributes for all error dimensions for the general part. The first error dimension (statistical errors) is drawn with default settings. The second error dimension (systematic errors) is drawn with boxes of half the width of the X-Errors. **Individual Fill and Line Attributes for each error dimension**; This is being realized by overloading the Getter and Setter functions of TAttFill and TAttLine with an additional dimension parameter. Furthermore there are Getter and Setter functions for full TAttFill and TAttLine objects to get / set all attributes at once. To keep full compatibility with TGraphAsymmErrors by default the TAttFill and TAttLine attributes of the object are being used for all error dimensions. To activate using the individual ones add the Draw option “S” to the first block of the Draw options like in my example. All the best,; Simon Spies. I hope you find my class as useful as I do and vote for it to become part of ROOT in the future. :smile:; ![example](https://user-images.githubusercontent.com/5320187/53051016-15b0e300-349b-11e9-90d6-af75f21654a0.png); ![example](https://user-images.githubusercontent.com/5320187/53085326-e7ff8480-3502-11e9-8945-59e025",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:4084,Availability,error,error,4084,"orDimensions + 1 blocks given an error is returned. All drawing options of TGraphAsymmErrors are implemented. For explanation of the drawing options see TGraphPainter::PaintGraphAsymmErrors.; Additionally one can specify x0 or y0 to skip points with x = 0 or y = 0 The Draw option s=%f can be used to multiply the corresponding x errors with %f. This is useful in combination with e.g. option 2 if the boxes are supposed to have only half the width of the bin, in this case the option would be s=0.5. Per default the Fill and Line Styles of the Graph are being used for all error dimensions. To use the specific ones add the draw option s to the first block.; In my example plot the drawing options are “a p s ; ; 5 s=0.5” which means the graph is drawn with Axes, Markers and individual Fill and Line attributes for all error dimensions for the general part. The first error dimension (statistical errors) is drawn with default settings. The second error dimension (systematic errors) is drawn with boxes of half the width of the X-Errors. **Individual Fill and Line Attributes for each error dimension**; This is being realized by overloading the Getter and Setter functions of TAttFill and TAttLine with an additional dimension parameter. Furthermore there are Getter and Setter functions for full TAttFill and TAttLine objects to get / set all attributes at once. To keep full compatibility with TGraphAsymmErrors by default the TAttFill and TAttLine attributes of the object are being used for all error dimensions. To activate using the individual ones add the Draw option “S” to the first block of the Draw options like in my example. All the best,; Simon Spies. I hope you find my class as useful as I do and vote for it to become part of ROOT in the future. :smile:; ![example](https://user-images.githubusercontent.com/5320187/53051016-15b0e300-349b-11e9-90d6-af75f21654a0.png); ![example](https://user-images.githubusercontent.com/5320187/53085326-e7ff8480-3502-11e9-8945-59e025f46cf8.png)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:4499,Availability,error,error,4499,"orDimensions + 1 blocks given an error is returned. All drawing options of TGraphAsymmErrors are implemented. For explanation of the drawing options see TGraphPainter::PaintGraphAsymmErrors.; Additionally one can specify x0 or y0 to skip points with x = 0 or y = 0 The Draw option s=%f can be used to multiply the corresponding x errors with %f. This is useful in combination with e.g. option 2 if the boxes are supposed to have only half the width of the bin, in this case the option would be s=0.5. Per default the Fill and Line Styles of the Graph are being used for all error dimensions. To use the specific ones add the draw option s to the first block.; In my example plot the drawing options are “a p s ; ; 5 s=0.5” which means the graph is drawn with Axes, Markers and individual Fill and Line attributes for all error dimensions for the general part. The first error dimension (statistical errors) is drawn with default settings. The second error dimension (systematic errors) is drawn with boxes of half the width of the X-Errors. **Individual Fill and Line Attributes for each error dimension**; This is being realized by overloading the Getter and Setter functions of TAttFill and TAttLine with an additional dimension parameter. Furthermore there are Getter and Setter functions for full TAttFill and TAttLine objects to get / set all attributes at once. To keep full compatibility with TGraphAsymmErrors by default the TAttFill and TAttLine attributes of the object are being used for all error dimensions. To activate using the individual ones add the Draw option “S” to the first block of the Draw options like in my example. All the best,; Simon Spies. I hope you find my class as useful as I do and vote for it to become part of ROOT in the future. :smile:; ![example](https://user-images.githubusercontent.com/5320187/53051016-15b0e300-349b-11e9-90d6-af75f21654a0.png); ![example](https://user-images.githubusercontent.com/5320187/53085326-e7ff8480-3502-11e9-8945-59e025f46cf8.png)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:883,Modifiability,inherit,inherits,883,"Hello,. First of all sorry for all the mess I made with these pull requests. This is my first try and I did not really understood how GitHub works therefore my previous pull request was this messy and I decided to withdraw it and clean everything up before I request it again. And here we are, I ran some additional bugfixing and the ROOT tests which succeeded. Furthermore I tested my new class and everything I tried worked so I think now it's time to request the pull again. **Explanation**; My implementation is named TGraphMultiErrors and is basically a TGraphAsymmErrors with the possibility to include an unlimited amount of different types of y-Errors.; The whole functionality and naming convention of my class is strongly based on the TGraphAsymmErrors class. All functionalities of the TGraphAsymmErrors have been reimplemented. Furthermore like any other TGraph class it inherits from TGraph and has therefore all of it’s functionalities. I attached an example plot as a png picture. It's macro to be produced is included in the description part of the TGraphPainter class. **Differences to TGraphAsymmErrors**; Everywhere TGraphAsymmErrors uses arrays for the y-Errors, my class uses two dimensional arrays (Double_t**) of which the first dimension represents the index of the error dimension and the second one the point. It is assumed that the first y-Error is the statistical one and all following are systematical ones. Therefore when the statistical errors are being computed by a function everything applies to only the first error dimension.; In case a single error on y is required (Like for fitting) the errors are being summed according to the value of fSumErrorsMode which can be at the moment TGraphMultiErrors::kOnlyFirst for only returning the error of the first error type (usally the statistic one), TGraphMultiErrors::kSquareSum for returning the squared sum of the errors of all types (Gaussian propagation) or TGraphMultiErrors::kSum for just returning the sum of the e",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:2075,Performance,perform,performed,2075,"s. **Differences to TGraphAsymmErrors**; Everywhere TGraphAsymmErrors uses arrays for the y-Errors, my class uses two dimensional arrays (Double_t**) of which the first dimension represents the index of the error dimension and the second one the point. It is assumed that the first y-Error is the statistical one and all following are systematical ones. Therefore when the statistical errors are being computed by a function everything applies to only the first error dimension.; In case a single error on y is required (Like for fitting) the errors are being summed according to the value of fSumErrorsMode which can be at the moment TGraphMultiErrors::kOnlyFirst for only returning the error of the first error type (usally the statistic one), TGraphMultiErrors::kSquareSum for returning the squared sum of the errors of all types (Gaussian propagation) or TGraphMultiErrors::kSum for just returning the sum of the errors from all error types. **Drawing / Painting**; The painting is being performed by the TGraphPainter class like for any other classes. Therefore I added the function TGraphPainter::PaintGraphMultiErrors and included a corresponding line in the TGraphPainter::PaintHelper function. **Drawing / Painting options**; To be able to define different drawing options for the multiple error dimensions the option string can consist of multiple blocks separated by semicolons. The painting method separates the options in multiple options for each y error dimension and one for basic painting and the x errors. In case there are <= NErrorDimensions blocks given, the first block is used for basic painting and for the first dimension of y errors. Y error dimensions without an individual block are painted with “”.; Tn case there are NErrorDimensions + 1 given, the first block is used only for basic painting. The remaining blocks are distributed over the y error dimensions In case there are > NErrorDimensions + 1 blocks given an error is returned. All drawing options of TGraphAsymmEr",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:339,Testability,test,tests,339,"Hello,. First of all sorry for all the mess I made with these pull requests. This is my first try and I did not really understood how GitHub works therefore my previous pull request was this messy and I decided to withdraw it and clean everything up before I request it again. And here we are, I ran some additional bugfixing and the ROOT tests which succeeded. Furthermore I tested my new class and everything I tried worked so I think now it's time to request the pull again. **Explanation**; My implementation is named TGraphMultiErrors and is basically a TGraphAsymmErrors with the possibility to include an unlimited amount of different types of y-Errors.; The whole functionality and naming convention of my class is strongly based on the TGraphAsymmErrors class. All functionalities of the TGraphAsymmErrors have been reimplemented. Furthermore like any other TGraph class it inherits from TGraph and has therefore all of it’s functionalities. I attached an example plot as a png picture. It's macro to be produced is included in the description part of the TGraphPainter class. **Differences to TGraphAsymmErrors**; Everywhere TGraphAsymmErrors uses arrays for the y-Errors, my class uses two dimensional arrays (Double_t**) of which the first dimension represents the index of the error dimension and the second one the point. It is assumed that the first y-Error is the statistical one and all following are systematical ones. Therefore when the statistical errors are being computed by a function everything applies to only the first error dimension.; In case a single error on y is required (Like for fitting) the errors are being summed according to the value of fSumErrorsMode which can be at the moment TGraphMultiErrors::kOnlyFirst for only returning the error of the first error type (usally the statistic one), TGraphMultiErrors::kSquareSum for returning the squared sum of the errors of all types (Gaussian propagation) or TGraphMultiErrors::kSum for just returning the sum of the e",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3452:376,Testability,test,tested,376,"Hello,. First of all sorry for all the mess I made with these pull requests. This is my first try and I did not really understood how GitHub works therefore my previous pull request was this messy and I decided to withdraw it and clean everything up before I request it again. And here we are, I ran some additional bugfixing and the ROOT tests which succeeded. Furthermore I tested my new class and everything I tried worked so I think now it's time to request the pull again. **Explanation**; My implementation is named TGraphMultiErrors and is basically a TGraphAsymmErrors with the possibility to include an unlimited amount of different types of y-Errors.; The whole functionality and naming convention of my class is strongly based on the TGraphAsymmErrors class. All functionalities of the TGraphAsymmErrors have been reimplemented. Furthermore like any other TGraph class it inherits from TGraph and has therefore all of it’s functionalities. I attached an example plot as a png picture. It's macro to be produced is included in the description part of the TGraphPainter class. **Differences to TGraphAsymmErrors**; Everywhere TGraphAsymmErrors uses arrays for the y-Errors, my class uses two dimensional arrays (Double_t**) of which the first dimension represents the index of the error dimension and the second one the point. It is assumed that the first y-Error is the statistical one and all following are systematical ones. Therefore when the statistical errors are being computed by a function everything applies to only the first error dimension.; In case a single error on y is required (Like for fitting) the errors are being summed according to the value of fSumErrorsMode which can be at the moment TGraphMultiErrors::kOnlyFirst for only returning the error of the first error type (usally the statistic one), TGraphMultiErrors::kSquareSum for returning the squared sum of the errors of all types (Gaussian propagation) or TGraphMultiErrors::kSum for just returning the sum of the e",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3452
https://github.com/root-project/root/pull/3463:809,Energy Efficiency,reduce,reduced,809,"Hello,. I implemented the classes TLeafF16 and TLeafD32 which allow to store floating point values using the truncation methods from TBuffer. As the names imply one is meant for the Float16_t type and the other one for the Double32_t type. The letters to be used in the leaflist are the small letters f and d which sounds reasonable to me since the capital letters F and D are being used for the regular Float_t and Double_t datatypes. Furthermore a range for the datatypes can be specified using the syntax from the TStreamerElement::GetRange() function. To avaid conflicts with the declaration of array branches the range specifier has to be attached to the data type letter instead of the variable name. I tested the implementation locally and it is working very well. The file size is being significantly reduced using the Float16_t or Double32_t implementation instead of the usual ones. I think this is quite useful since even the precision of Float_t sometimes overshoots the requirements and occupies an unnecessarily large amount of memory. All the best,; Simon Spies",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3463
https://github.com/root-project/root/pull/3463:692,Modifiability,variab,variable,692,"Hello,. I implemented the classes TLeafF16 and TLeafD32 which allow to store floating point values using the truncation methods from TBuffer. As the names imply one is meant for the Float16_t type and the other one for the Double32_t type. The letters to be used in the leaflist are the small letters f and d which sounds reasonable to me since the capital letters F and D are being used for the regular Float_t and Double_t datatypes. Furthermore a range for the datatypes can be specified using the syntax from the TStreamerElement::GetRange() function. To avaid conflicts with the declaration of array branches the range specifier has to be attached to the data type letter instead of the variable name. I tested the implementation locally and it is working very well. The file size is being significantly reduced using the Float16_t or Double32_t implementation instead of the usual ones. I think this is quite useful since even the precision of Float_t sometimes overshoots the requirements and occupies an unnecessarily large amount of memory. All the best,; Simon Spies",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3463
https://github.com/root-project/root/pull/3463:709,Testability,test,tested,709,"Hello,. I implemented the classes TLeafF16 and TLeafD32 which allow to store floating point values using the truncation methods from TBuffer. As the names imply one is meant for the Float16_t type and the other one for the Double32_t type. The letters to be used in the leaflist are the small letters f and d which sounds reasonable to me since the capital letters F and D are being used for the regular Float_t and Double_t datatypes. Furthermore a range for the datatypes can be specified using the syntax from the TStreamerElement::GetRange() function. To avaid conflicts with the declaration of array branches the range specifier has to be attached to the data type letter instead of the variable name. I tested the implementation locally and it is working very well. The file size is being significantly reduced using the Float16_t or Double32_t implementation instead of the usual ones. I think this is quite useful since even the precision of Float_t sometimes overshoots the requirements and occupies an unnecessarily large amount of memory. All the best,; Simon Spies",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3463
https://github.com/root-project/root/pull/3466:155,Integrability,synchroniz,synchronized,155,- initial port of physics-data -> EVE representation infrastructure from Fireworks;; - cleanup of TObject inheritance;; - first steps towards multi client synchronized selection support.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3466
https://github.com/root-project/root/pull/3466:106,Modifiability,inherit,inheritance,106,- initial port of physics-data -> EVE representation infrastructure from Fireworks;; - cleanup of TObject inheritance;; - first steps towards multi client synchronized selection support.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3466
https://github.com/root-project/root/pull/3467:345,Energy Efficiency,allocate,allocated,345,"the goal of this commit is to avoid too many allocations/deallocations in two cases:; 1. sophisticated expressions manipulating RVec<T> instances: churn kicks in due to temporaries; 2. RDataFrame runs with Defines returning RVec<T>s which are saved within custom columns via a copy. For every event, the old value is deallocated and the new one allocated. This change implements a thread local stack of buffers in the RAdoptAllocator.; If the allocation is smaller than RAdoptAllocator<T>::fgBuffersSize, before allocating; a fresh region of memory through the stl allocator, a pop from the aforementioned stack is tried.; At deallocation time, the memory taken from the stak, is put back in the stack.; In some sense, this is an optimisation for short (defined by RAdoptAllocator<T>::fgBuffersSize) RVec<T>s.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3467
https://github.com/root-project/root/pull/3467:30,Safety,avoid,avoid,30,"the goal of this commit is to avoid too many allocations/deallocations in two cases:; 1. sophisticated expressions manipulating RVec<T> instances: churn kicks in due to temporaries; 2. RDataFrame runs with Defines returning RVec<T>s which are saved within custom columns via a copy. For every event, the old value is deallocated and the new one allocated. This change implements a thread local stack of buffers in the RAdoptAllocator.; If the allocation is smaller than RAdoptAllocator<T>::fgBuffersSize, before allocating; a fresh region of memory through the stl allocator, a pop from the aforementioned stack is tried.; At deallocation time, the memory taken from the stak, is put back in the stack.; In some sense, this is an optimisation for short (defined by RAdoptAllocator<T>::fgBuffersSize) RVec<T>s.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3467
https://github.com/root-project/root/pull/3468:37,Integrability,depend,dependency,37,This is workaround to avoid circular dependency between v7primitives; and v7gpad. Detected by cmake on some platforms,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3468
https://github.com/root-project/root/pull/3468:22,Safety,avoid,avoid,22,This is workaround to avoid circular dependency between v7primitives; and v7gpad. Detected by cmake on some platforms,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3468
https://github.com/root-project/root/pull/3468:82,Safety,Detect,Detected,82,This is workaround to avoid circular dependency between v7primitives; and v7gpad. Detected by cmake on some platforms,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3468
https://github.com/root-project/root/pull/3470:19,Integrability,depend,dependencies,19,"There are circular dependencies, which are detected on some build platforms",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3470
https://github.com/root-project/root/pull/3470:43,Safety,detect,detected,43,"There are circular dependencies, which are detected on some build platforms",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3470
https://github.com/root-project/root/pull/3472:9,Safety,avoid,avoids,9,This fix avoids a crash when an invalid formula expression is given as input.; This ties ROOT-9990,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3472
https://github.com/root-project/root/pull/3473:85,Testability,test,test,85,"- fix compiler warnings about current eve7 code, remove some ClassDefs; - try to add test directory to eve7; - provide latest jsroot with correspondent changes in GeoPaineter for eve7; - implement toggling of nodes visibility in eve7 geometry viewer",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3473
https://github.com/root-project/root/pull/3475:75,Availability,avail,available,75,These tests ensure that the functionality of the current PyROOT is as well available in experimental PyROOT. No explicit pythonizations are added since the feature is now provided directly by CPyCppyy.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3475
https://github.com/root-project/root/pull/3475:6,Testability,test,tests,6,These tests ensure that the functionality of the current PyROOT is as well available in experimental PyROOT. No explicit pythonizations are added since the feature is now provided directly by CPyCppyy.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3475
https://github.com/root-project/root/pull/3477:437,Deployability,update,update,437,"- remove ClassDef for non-TObject files; - use `override` directive when virtual method is overriden; - use c++11 loops to iterate over containers; - avoid as much as possible usage of `iterator` class, remove them from LinkDef.h; - use `auto` as typename when iterator has to be used; - use `nullptr` instead of 0; - use more class members initializers, shrink default constructors; - more use of `std::string` instead `const char*`; - update copyright and authors blocks, adjust comments decoration",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3477
https://github.com/root-project/root/pull/3477:150,Safety,avoid,avoid,150,"- remove ClassDef for non-TObject files; - use `override` directive when virtual method is overriden; - use c++11 loops to iterate over containers; - avoid as much as possible usage of `iterator` class, remove them from LinkDef.h; - use `auto` as typename when iterator has to be used; - use `nullptr` instead of 0; - use more class members initializers, shrink default constructors; - more use of `std::string` instead `const char*`; - update copyright and authors blocks, adjust comments decoration",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3477
https://github.com/root-project/root/pull/3488:3269,Energy Efficiency,power,power,3269,"llable` decorator. In addition, you can now give the wrapped function a custom name:. ```python; @ROOT.DeclareCallable([""float""], ""float"", ""my_name""); def f(x):; return 2.0 * x. ROOT.ROOT.my_name(21) # Returns 42; ```. **DEPRECATED:**. Add workflow to invoke Python callables from C++. The mechanism builds with cling a C++ wrapper class around Python callables and publishs them to the user. See following example for the basic mechanism. ```python; import ROOT. # Because C++ is strongly typed, we have to declare the types of the inputs and the output; @ROOT.DeclareCppCallable([""float""], ""float""); def func(x):; return 2.0 * x. print(func(1.0)) # Prints 2.0; print(ROOT.PyROOT.func(1.0)) # Prints 2.0; ROOT.gInterpreter.ProcessLine(""cout << PyROOT::func(1.0) << endl;"") # Prints 2.0; ```. This allows us to run Python code in wrapped C++ workflow, e.g. for `RDataFrame`:. ```python; import ROOT; import numpy. @ROOT.DeclareCppCallable([""unsigned int""], ""float""); def func(x):; return numpy.power(x, 2). df = ROOT.RDataFrame(4).Define(""x"", ""rdfentry_"").Define(""y"", ""PyROOT::func(x)""); npy = df.AsNumpy(); print(npy[""x""]) # Prints [0, 1, 2, 3]; print(npy[""y""]) # Prints [0.0, 1.0, 4.0, 9.0]; ```. Finally, the approach is fully compatible with any custom C++ types you may have. ```python; import ROOT. ROOT.gInterpreter.Declare(""""""; struct Foo {; static const int foo = 42;; };; """"""). @ROOT.DeclareCppCallable([""Foo""], """"); def func(x):; print(x.foo). ROOT.gInterpreter.ProcessLine(""Foo x; PyROOT::func(x);"") # Prints 42; ```; There are still some things to check before merging:. - [ ] Double check reference counting; - [ ] C++ wrapper takes (lvalue) references, what happens with rvalues? What is the universal thingy?; - [ ] We put the C++ callable in the `PyROOT::` namespace. This is fine? It can be everything, even the global namespace. What is a sane solution here?; - [ ] How many copies we are doing finally? What is the performance?; - [ ] What happens in MT scenarios? Put in a test c",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:107,Integrability,interface,interface,107,"Alright, I've put in the comments from @etejedor (thanks!). Now we've a refined version regarding the user interface:. ```python; @ROOT.DeclareCppCallable([""float""], ""float""); def f(x); return 2.0 * x. # General use-cases; ROOT.CppCallable.f(21) # Returns 42; ROOT.gInterpreter.ProcessLine(""cout << CppCallable::f(21.0) << endl;"") # Prints 42.0. # Inject callable into dataframe; df = ROOT.ROOT.RDataFrame(10).Define(""x"", ""rdfentry__"").Define(""CppCallable::f(x)""); ```. You can set an optional name. ```python; @ROOT.DeclareCppCallable([""float""], ""float"", name=""g""); def f(x); return 2.0 * x. ROOT.CppCallable.g(21.0) # Returns 42; ```. By default, we try numba first and then fall back to the generic implementation. You can force only numba using `numba_only=True` as optional argument. ```python; @ROOT.DeclareCppCallable([""float""], ""float"", numba_only=True); def f(x); return 2.0 * x; ```. In addition, you can set a `verbose` flag to let PyROOT tell you if the decorator falls back to the generic implementation. ```python; @ROOT.DeclareCppCallable([""float""], ""string"", verbose=True); def f(x); return ROOT.std.string(str(x)). ROOT.CppCallable.f(x); # 1) Throws Python warning:; # /home/stefan/foo.py:5: RuntimeWarning: Failed to compile Python callable using numba. Fall back to generic implementation.; # @ROOT.DeclareCppCallable([""float""], ""string"", verbose=True); # 2) Falls back to generic impl and prints ""42"" (as string); ```. **DEPRECATED:**. I've cleaned up and improved the feature. Here's the basic workflow now:. ```python; @ROOT.DeclareCallable([""float""], ""float""); def f(x); return 2.0 * x. # General use-cases; ROOT.ROOT.f(21) # Returns 42; ROOT.gInterpreter.ProcessLine(""cout << ROOT::f(21.0) << endl;"") # Prints 42.0. # Inject callable into dataframe; df = ROOT.ROOT.RDataFrame(10).Define(""x"", ""rdfentry__"").Define(""ROOT::f(x)""); ```. The `DeclareCallable` dispatches between numba and the generic implementation. It tries to compile the thingy with numba (falls through silently",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:348,Integrability,Inject,Inject,348,"Alright, I've put in the comments from @etejedor (thanks!). Now we've a refined version regarding the user interface:. ```python; @ROOT.DeclareCppCallable([""float""], ""float""); def f(x); return 2.0 * x. # General use-cases; ROOT.CppCallable.f(21) # Returns 42; ROOT.gInterpreter.ProcessLine(""cout << CppCallable::f(21.0) << endl;"") # Prints 42.0. # Inject callable into dataframe; df = ROOT.ROOT.RDataFrame(10).Define(""x"", ""rdfentry__"").Define(""CppCallable::f(x)""); ```. You can set an optional name. ```python; @ROOT.DeclareCppCallable([""float""], ""float"", name=""g""); def f(x); return 2.0 * x. ROOT.CppCallable.g(21.0) # Returns 42; ```. By default, we try numba first and then fall back to the generic implementation. You can force only numba using `numba_only=True` as optional argument. ```python; @ROOT.DeclareCppCallable([""float""], ""float"", numba_only=True); def f(x); return 2.0 * x; ```. In addition, you can set a `verbose` flag to let PyROOT tell you if the decorator falls back to the generic implementation. ```python; @ROOT.DeclareCppCallable([""float""], ""string"", verbose=True); def f(x); return ROOT.std.string(str(x)). ROOT.CppCallable.f(x); # 1) Throws Python warning:; # /home/stefan/foo.py:5: RuntimeWarning: Failed to compile Python callable using numba. Fall back to generic implementation.; # @ROOT.DeclareCppCallable([""float""], ""string"", verbose=True); # 2) Falls back to generic impl and prints ""42"" (as string); ```. **DEPRECATED:**. I've cleaned up and improved the feature. Here's the basic workflow now:. ```python; @ROOT.DeclareCallable([""float""], ""float""); def f(x); return 2.0 * x. # General use-cases; ROOT.ROOT.f(21) # Returns 42; ROOT.gInterpreter.ProcessLine(""cout << ROOT::f(21.0) << endl;"") # Prints 42.0. # Inject callable into dataframe; df = ROOT.ROOT.RDataFrame(10).Define(""x"", ""rdfentry__"").Define(""ROOT::f(x)""); ```. The `DeclareCallable` dispatches between numba and the generic implementation. It tries to compile the thingy with numba (falls through silently",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:1742,Integrability,Inject,Inject,1742,"True` as optional argument. ```python; @ROOT.DeclareCppCallable([""float""], ""float"", numba_only=True); def f(x); return 2.0 * x; ```. In addition, you can set a `verbose` flag to let PyROOT tell you if the decorator falls back to the generic implementation. ```python; @ROOT.DeclareCppCallable([""float""], ""string"", verbose=True); def f(x); return ROOT.std.string(str(x)). ROOT.CppCallable.f(x); # 1) Throws Python warning:; # /home/stefan/foo.py:5: RuntimeWarning: Failed to compile Python callable using numba. Fall back to generic implementation.; # @ROOT.DeclareCppCallable([""float""], ""string"", verbose=True); # 2) Falls back to generic impl and prints ""42"" (as string); ```. **DEPRECATED:**. I've cleaned up and improved the feature. Here's the basic workflow now:. ```python; @ROOT.DeclareCallable([""float""], ""float""); def f(x); return 2.0 * x. # General use-cases; ROOT.ROOT.f(21) # Returns 42; ROOT.gInterpreter.ProcessLine(""cout << ROOT::f(21.0) << endl;"") # Prints 42.0. # Inject callable into dataframe; df = ROOT.ROOT.RDataFrame(10).Define(""x"", ""rdfentry__"").Define(""ROOT::f(x)""); ```. The `DeclareCallable` dispatches between numba and the generic implementation. It tries to compile the thingy with numba (falls through silently) and otherwise tries the generic implementation (fails noisily).; However, you can force using the generic implementation or numba by using the decorators `DeclareGenericCallable` and `DeclareNumbaCallable`. The interface is exactly the same than for the general `DeclareCallable` decorator. In addition, you can now give the wrapped function a custom name:. ```python; @ROOT.DeclareCallable([""float""], ""float"", ""my_name""); def f(x):; return 2.0 * x. ROOT.ROOT.my_name(21) # Returns 42; ```. **DEPRECATED:**. Add workflow to invoke Python callables from C++. The mechanism builds with cling a C++ wrapper class around Python callables and publishs them to the user. See following example for the basic mechanism. ```python; import ROOT. # Because C++ is strong",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:2214,Integrability,interface,interface,2214,"allable using numba. Fall back to generic implementation.; # @ROOT.DeclareCppCallable([""float""], ""string"", verbose=True); # 2) Falls back to generic impl and prints ""42"" (as string); ```. **DEPRECATED:**. I've cleaned up and improved the feature. Here's the basic workflow now:. ```python; @ROOT.DeclareCallable([""float""], ""float""); def f(x); return 2.0 * x. # General use-cases; ROOT.ROOT.f(21) # Returns 42; ROOT.gInterpreter.ProcessLine(""cout << ROOT::f(21.0) << endl;"") # Prints 42.0. # Inject callable into dataframe; df = ROOT.ROOT.RDataFrame(10).Define(""x"", ""rdfentry__"").Define(""ROOT::f(x)""); ```. The `DeclareCallable` dispatches between numba and the generic implementation. It tries to compile the thingy with numba (falls through silently) and otherwise tries the generic implementation (fails noisily).; However, you can force using the generic implementation or numba by using the decorators `DeclareGenericCallable` and `DeclareNumbaCallable`. The interface is exactly the same than for the general `DeclareCallable` decorator. In addition, you can now give the wrapped function a custom name:. ```python; @ROOT.DeclareCallable([""float""], ""float"", ""my_name""); def f(x):; return 2.0 * x. ROOT.ROOT.my_name(21) # Returns 42; ```. **DEPRECATED:**. Add workflow to invoke Python callables from C++. The mechanism builds with cling a C++ wrapper class around Python callables and publishs them to the user. See following example for the basic mechanism. ```python; import ROOT. # Because C++ is strongly typed, we have to declare the types of the inputs and the output; @ROOT.DeclareCppCallable([""float""], ""float""); def func(x):; return 2.0 * x. print(func(1.0)) # Prints 2.0; print(ROOT.PyROOT.func(1.0)) # Prints 2.0; ROOT.gInterpreter.ProcessLine(""cout << PyROOT::func(1.0) << endl;"") # Prints 2.0; ```. This allows us to run Python code in wrapped C++ workflow, e.g. for `RDataFrame`:. ```python; import ROOT; import numpy. @ROOT.DeclareCppCallable([""unsigned int""], ""float""); def func(",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:2328,Integrability,wrap,wrapped,2328,"ppCallable([""float""], ""string"", verbose=True); # 2) Falls back to generic impl and prints ""42"" (as string); ```. **DEPRECATED:**. I've cleaned up and improved the feature. Here's the basic workflow now:. ```python; @ROOT.DeclareCallable([""float""], ""float""); def f(x); return 2.0 * x. # General use-cases; ROOT.ROOT.f(21) # Returns 42; ROOT.gInterpreter.ProcessLine(""cout << ROOT::f(21.0) << endl;"") # Prints 42.0. # Inject callable into dataframe; df = ROOT.ROOT.RDataFrame(10).Define(""x"", ""rdfentry__"").Define(""ROOT::f(x)""); ```. The `DeclareCallable` dispatches between numba and the generic implementation. It tries to compile the thingy with numba (falls through silently) and otherwise tries the generic implementation (fails noisily).; However, you can force using the generic implementation or numba by using the decorators `DeclareGenericCallable` and `DeclareNumbaCallable`. The interface is exactly the same than for the general `DeclareCallable` decorator. In addition, you can now give the wrapped function a custom name:. ```python; @ROOT.DeclareCallable([""float""], ""float"", ""my_name""); def f(x):; return 2.0 * x. ROOT.ROOT.my_name(21) # Returns 42; ```. **DEPRECATED:**. Add workflow to invoke Python callables from C++. The mechanism builds with cling a C++ wrapper class around Python callables and publishs them to the user. See following example for the basic mechanism. ```python; import ROOT. # Because C++ is strongly typed, we have to declare the types of the inputs and the output; @ROOT.DeclareCppCallable([""float""], ""float""); def func(x):; return 2.0 * x. print(func(1.0)) # Prints 2.0; print(ROOT.PyROOT.func(1.0)) # Prints 2.0; ROOT.gInterpreter.ProcessLine(""cout << PyROOT::func(1.0) << endl;"") # Prints 2.0; ```. This allows us to run Python code in wrapped C++ workflow, e.g. for `RDataFrame`:. ```python; import ROOT; import numpy. @ROOT.DeclareCppCallable([""unsigned int""], ""float""); def func(x):; return numpy.power(x, 2). df = ROOT.RDataFrame(4).Define(""x"", ""rdfentry",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:2599,Integrability,wrap,wrapper,2599,"eneral use-cases; ROOT.ROOT.f(21) # Returns 42; ROOT.gInterpreter.ProcessLine(""cout << ROOT::f(21.0) << endl;"") # Prints 42.0. # Inject callable into dataframe; df = ROOT.ROOT.RDataFrame(10).Define(""x"", ""rdfentry__"").Define(""ROOT::f(x)""); ```. The `DeclareCallable` dispatches between numba and the generic implementation. It tries to compile the thingy with numba (falls through silently) and otherwise tries the generic implementation (fails noisily).; However, you can force using the generic implementation or numba by using the decorators `DeclareGenericCallable` and `DeclareNumbaCallable`. The interface is exactly the same than for the general `DeclareCallable` decorator. In addition, you can now give the wrapped function a custom name:. ```python; @ROOT.DeclareCallable([""float""], ""float"", ""my_name""); def f(x):; return 2.0 * x. ROOT.ROOT.my_name(21) # Returns 42; ```. **DEPRECATED:**. Add workflow to invoke Python callables from C++. The mechanism builds with cling a C++ wrapper class around Python callables and publishs them to the user. See following example for the basic mechanism. ```python; import ROOT. # Because C++ is strongly typed, we have to declare the types of the inputs and the output; @ROOT.DeclareCppCallable([""float""], ""float""); def func(x):; return 2.0 * x. print(func(1.0)) # Prints 2.0; print(ROOT.PyROOT.func(1.0)) # Prints 2.0; ROOT.gInterpreter.ProcessLine(""cout << PyROOT::func(1.0) << endl;"") # Prints 2.0; ```. This allows us to run Python code in wrapped C++ workflow, e.g. for `RDataFrame`:. ```python; import ROOT; import numpy. @ROOT.DeclareCppCallable([""unsigned int""], ""float""); def func(x):; return numpy.power(x, 2). df = ROOT.RDataFrame(4).Define(""x"", ""rdfentry_"").Define(""y"", ""PyROOT::func(x)""); npy = df.AsNumpy(); print(npy[""x""]) # Prints [0, 1, 2, 3]; print(npy[""y""]) # Prints [0.0, 1.0, 4.0, 9.0]; ```. Finally, the approach is fully compatible with any custom C++ types you may have. ```python; import ROOT. ROOT.gInterpreter.Declare(""""""; str",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:3105,Integrability,wrap,wrapped,3105,"he generic implementation or numba by using the decorators `DeclareGenericCallable` and `DeclareNumbaCallable`. The interface is exactly the same than for the general `DeclareCallable` decorator. In addition, you can now give the wrapped function a custom name:. ```python; @ROOT.DeclareCallable([""float""], ""float"", ""my_name""); def f(x):; return 2.0 * x. ROOT.ROOT.my_name(21) # Returns 42; ```. **DEPRECATED:**. Add workflow to invoke Python callables from C++. The mechanism builds with cling a C++ wrapper class around Python callables and publishs them to the user. See following example for the basic mechanism. ```python; import ROOT. # Because C++ is strongly typed, we have to declare the types of the inputs and the output; @ROOT.DeclareCppCallable([""float""], ""float""); def func(x):; return 2.0 * x. print(func(1.0)) # Prints 2.0; print(ROOT.PyROOT.func(1.0)) # Prints 2.0; ROOT.gInterpreter.ProcessLine(""cout << PyROOT::func(1.0) << endl;"") # Prints 2.0; ```. This allows us to run Python code in wrapped C++ workflow, e.g. for `RDataFrame`:. ```python; import ROOT; import numpy. @ROOT.DeclareCppCallable([""unsigned int""], ""float""); def func(x):; return numpy.power(x, 2). df = ROOT.RDataFrame(4).Define(""x"", ""rdfentry_"").Define(""y"", ""PyROOT::func(x)""); npy = df.AsNumpy(); print(npy[""x""]) # Prints [0, 1, 2, 3]; print(npy[""y""]) # Prints [0.0, 1.0, 4.0, 9.0]; ```. Finally, the approach is fully compatible with any custom C++ types you may have. ```python; import ROOT. ROOT.gInterpreter.Declare(""""""; struct Foo {; static const int foo = 42;; };; """"""). @ROOT.DeclareCppCallable([""Foo""], """"); def func(x):; print(x.foo). ROOT.gInterpreter.ProcessLine(""Foo x; PyROOT::func(x);"") # Prints 42; ```; There are still some things to check before merging:. - [ ] Double check reference counting; - [ ] C++ wrapper takes (lvalue) references, what happens with rvalues? What is the universal thingy?; - [ ] We put the C++ callable in the `PyROOT::` namespace. This is fine? It can be everything, ev",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:3908,Integrability,wrap,wrapper,3908,"m name:. ```python; @ROOT.DeclareCallable([""float""], ""float"", ""my_name""); def f(x):; return 2.0 * x. ROOT.ROOT.my_name(21) # Returns 42; ```. **DEPRECATED:**. Add workflow to invoke Python callables from C++. The mechanism builds with cling a C++ wrapper class around Python callables and publishs them to the user. See following example for the basic mechanism. ```python; import ROOT. # Because C++ is strongly typed, we have to declare the types of the inputs and the output; @ROOT.DeclareCppCallable([""float""], ""float""); def func(x):; return 2.0 * x. print(func(1.0)) # Prints 2.0; print(ROOT.PyROOT.func(1.0)) # Prints 2.0; ROOT.gInterpreter.ProcessLine(""cout << PyROOT::func(1.0) << endl;"") # Prints 2.0; ```. This allows us to run Python code in wrapped C++ workflow, e.g. for `RDataFrame`:. ```python; import ROOT; import numpy. @ROOT.DeclareCppCallable([""unsigned int""], ""float""); def func(x):; return numpy.power(x, 2). df = ROOT.RDataFrame(4).Define(""x"", ""rdfentry_"").Define(""y"", ""PyROOT::func(x)""); npy = df.AsNumpy(); print(npy[""x""]) # Prints [0, 1, 2, 3]; print(npy[""y""]) # Prints [0.0, 1.0, 4.0, 9.0]; ```. Finally, the approach is fully compatible with any custom C++ types you may have. ```python; import ROOT. ROOT.gInterpreter.Declare(""""""; struct Foo {; static const int foo = 42;; };; """"""). @ROOT.DeclareCppCallable([""Foo""], """"); def func(x):; print(x.foo). ROOT.gInterpreter.ProcessLine(""Foo x; PyROOT::func(x);"") # Prints 42; ```; There are still some things to check before merging:. - [ ] Double check reference counting; - [ ] C++ wrapper takes (lvalue) references, what happens with rvalues? What is the universal thingy?; - [ ] We put the C++ callable in the `PyROOT::` namespace. This is fine? It can be everything, even the global namespace. What is a sane solution here?; - [ ] How many copies we are doing finally? What is the performance?; - [ ] What happens in MT scenarios? Put in a test case!; - [ ] We have to ship the public cppyy interface with the ROOT headers.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:4320,Integrability,interface,interface,4320,"m name:. ```python; @ROOT.DeclareCallable([""float""], ""float"", ""my_name""); def f(x):; return 2.0 * x. ROOT.ROOT.my_name(21) # Returns 42; ```. **DEPRECATED:**. Add workflow to invoke Python callables from C++. The mechanism builds with cling a C++ wrapper class around Python callables and publishs them to the user. See following example for the basic mechanism. ```python; import ROOT. # Because C++ is strongly typed, we have to declare the types of the inputs and the output; @ROOT.DeclareCppCallable([""float""], ""float""); def func(x):; return 2.0 * x. print(func(1.0)) # Prints 2.0; print(ROOT.PyROOT.func(1.0)) # Prints 2.0; ROOT.gInterpreter.ProcessLine(""cout << PyROOT::func(1.0) << endl;"") # Prints 2.0; ```. This allows us to run Python code in wrapped C++ workflow, e.g. for `RDataFrame`:. ```python; import ROOT; import numpy. @ROOT.DeclareCppCallable([""unsigned int""], ""float""); def func(x):; return numpy.power(x, 2). df = ROOT.RDataFrame(4).Define(""x"", ""rdfentry_"").Define(""y"", ""PyROOT::func(x)""); npy = df.AsNumpy(); print(npy[""x""]) # Prints [0, 1, 2, 3]; print(npy[""y""]) # Prints [0.0, 1.0, 4.0, 9.0]; ```. Finally, the approach is fully compatible with any custom C++ types you may have. ```python; import ROOT. ROOT.gInterpreter.Declare(""""""; struct Foo {; static const int foo = 42;; };; """"""). @ROOT.DeclareCppCallable([""Foo""], """"); def func(x):; print(x.foo). ROOT.gInterpreter.ProcessLine(""Foo x; PyROOT::func(x);"") # Prints 42; ```; There are still some things to check before merging:. - [ ] Double check reference counting; - [ ] C++ wrapper takes (lvalue) references, what happens with rvalues? What is the universal thingy?; - [ ] We put the C++ callable in the `PyROOT::` namespace. This is fine? It can be everything, even the global namespace. What is a sane solution here?; - [ ] How many copies we are doing finally? What is the performance?; - [ ] What happens in MT scenarios? Put in a test case!; - [ ] We have to ship the public cppyy interface with the ROOT headers.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:4210,Performance,perform,performance,4210,"m name:. ```python; @ROOT.DeclareCallable([""float""], ""float"", ""my_name""); def f(x):; return 2.0 * x. ROOT.ROOT.my_name(21) # Returns 42; ```. **DEPRECATED:**. Add workflow to invoke Python callables from C++. The mechanism builds with cling a C++ wrapper class around Python callables and publishs them to the user. See following example for the basic mechanism. ```python; import ROOT. # Because C++ is strongly typed, we have to declare the types of the inputs and the output; @ROOT.DeclareCppCallable([""float""], ""float""); def func(x):; return 2.0 * x. print(func(1.0)) # Prints 2.0; print(ROOT.PyROOT.func(1.0)) # Prints 2.0; ROOT.gInterpreter.ProcessLine(""cout << PyROOT::func(1.0) << endl;"") # Prints 2.0; ```. This allows us to run Python code in wrapped C++ workflow, e.g. for `RDataFrame`:. ```python; import ROOT; import numpy. @ROOT.DeclareCppCallable([""unsigned int""], ""float""); def func(x):; return numpy.power(x, 2). df = ROOT.RDataFrame(4).Define(""x"", ""rdfentry_"").Define(""y"", ""PyROOT::func(x)""); npy = df.AsNumpy(); print(npy[""x""]) # Prints [0, 1, 2, 3]; print(npy[""y""]) # Prints [0.0, 1.0, 4.0, 9.0]; ```. Finally, the approach is fully compatible with any custom C++ types you may have. ```python; import ROOT. ROOT.gInterpreter.Declare(""""""; struct Foo {; static const int foo = 42;; };; """"""). @ROOT.DeclareCppCallable([""Foo""], """"); def func(x):; print(x.foo). ROOT.gInterpreter.ProcessLine(""Foo x; PyROOT::func(x);"") # Prints 42; ```; There are still some things to check before merging:. - [ ] Double check reference counting; - [ ] C++ wrapper takes (lvalue) references, what happens with rvalues? What is the universal thingy?; - [ ] We put the C++ callable in the `PyROOT::` namespace. This is fine? It can be everything, even the global namespace. What is a sane solution here?; - [ ] How many copies we are doing finally? What is the performance?; - [ ] What happens in MT scenarios? Put in a test case!; - [ ] We have to ship the public cppyy interface with the ROOT headers.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:348,Security,Inject,Inject,348,"Alright, I've put in the comments from @etejedor (thanks!). Now we've a refined version regarding the user interface:. ```python; @ROOT.DeclareCppCallable([""float""], ""float""); def f(x); return 2.0 * x. # General use-cases; ROOT.CppCallable.f(21) # Returns 42; ROOT.gInterpreter.ProcessLine(""cout << CppCallable::f(21.0) << endl;"") # Prints 42.0. # Inject callable into dataframe; df = ROOT.ROOT.RDataFrame(10).Define(""x"", ""rdfentry__"").Define(""CppCallable::f(x)""); ```. You can set an optional name. ```python; @ROOT.DeclareCppCallable([""float""], ""float"", name=""g""); def f(x); return 2.0 * x. ROOT.CppCallable.g(21.0) # Returns 42; ```. By default, we try numba first and then fall back to the generic implementation. You can force only numba using `numba_only=True` as optional argument. ```python; @ROOT.DeclareCppCallable([""float""], ""float"", numba_only=True); def f(x); return 2.0 * x; ```. In addition, you can set a `verbose` flag to let PyROOT tell you if the decorator falls back to the generic implementation. ```python; @ROOT.DeclareCppCallable([""float""], ""string"", verbose=True); def f(x); return ROOT.std.string(str(x)). ROOT.CppCallable.f(x); # 1) Throws Python warning:; # /home/stefan/foo.py:5: RuntimeWarning: Failed to compile Python callable using numba. Fall back to generic implementation.; # @ROOT.DeclareCppCallable([""float""], ""string"", verbose=True); # 2) Falls back to generic impl and prints ""42"" (as string); ```. **DEPRECATED:**. I've cleaned up and improved the feature. Here's the basic workflow now:. ```python; @ROOT.DeclareCallable([""float""], ""float""); def f(x); return 2.0 * x. # General use-cases; ROOT.ROOT.f(21) # Returns 42; ROOT.gInterpreter.ProcessLine(""cout << ROOT::f(21.0) << endl;"") # Prints 42.0. # Inject callable into dataframe; df = ROOT.ROOT.RDataFrame(10).Define(""x"", ""rdfentry__"").Define(""ROOT::f(x)""); ```. The `DeclareCallable` dispatches between numba and the generic implementation. It tries to compile the thingy with numba (falls through silently",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:1742,Security,Inject,Inject,1742,"True` as optional argument. ```python; @ROOT.DeclareCppCallable([""float""], ""float"", numba_only=True); def f(x); return 2.0 * x; ```. In addition, you can set a `verbose` flag to let PyROOT tell you if the decorator falls back to the generic implementation. ```python; @ROOT.DeclareCppCallable([""float""], ""string"", verbose=True); def f(x); return ROOT.std.string(str(x)). ROOT.CppCallable.f(x); # 1) Throws Python warning:; # /home/stefan/foo.py:5: RuntimeWarning: Failed to compile Python callable using numba. Fall back to generic implementation.; # @ROOT.DeclareCppCallable([""float""], ""string"", verbose=True); # 2) Falls back to generic impl and prints ""42"" (as string); ```. **DEPRECATED:**. I've cleaned up and improved the feature. Here's the basic workflow now:. ```python; @ROOT.DeclareCallable([""float""], ""float""); def f(x); return 2.0 * x. # General use-cases; ROOT.ROOT.f(21) # Returns 42; ROOT.gInterpreter.ProcessLine(""cout << ROOT::f(21.0) << endl;"") # Prints 42.0. # Inject callable into dataframe; df = ROOT.ROOT.RDataFrame(10).Define(""x"", ""rdfentry__"").Define(""ROOT::f(x)""); ```. The `DeclareCallable` dispatches between numba and the generic implementation. It tries to compile the thingy with numba (falls through silently) and otherwise tries the generic implementation (fails noisily).; However, you can force using the generic implementation or numba by using the decorators `DeclareGenericCallable` and `DeclareNumbaCallable`. The interface is exactly the same than for the general `DeclareCallable` decorator. In addition, you can now give the wrapped function a custom name:. ```python; @ROOT.DeclareCallable([""float""], ""float"", ""my_name""); def f(x):; return 2.0 * x. ROOT.ROOT.my_name(21) # Returns 42; ```. **DEPRECATED:**. Add workflow to invoke Python callables from C++. The mechanism builds with cling a C++ wrapper class around Python callables and publishs them to the user. See following example for the basic mechanism. ```python; import ROOT. # Because C++ is strong",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3488:4269,Testability,test,test,4269,"m name:. ```python; @ROOT.DeclareCallable([""float""], ""float"", ""my_name""); def f(x):; return 2.0 * x. ROOT.ROOT.my_name(21) # Returns 42; ```. **DEPRECATED:**. Add workflow to invoke Python callables from C++. The mechanism builds with cling a C++ wrapper class around Python callables and publishs them to the user. See following example for the basic mechanism. ```python; import ROOT. # Because C++ is strongly typed, we have to declare the types of the inputs and the output; @ROOT.DeclareCppCallable([""float""], ""float""); def func(x):; return 2.0 * x. print(func(1.0)) # Prints 2.0; print(ROOT.PyROOT.func(1.0)) # Prints 2.0; ROOT.gInterpreter.ProcessLine(""cout << PyROOT::func(1.0) << endl;"") # Prints 2.0; ```. This allows us to run Python code in wrapped C++ workflow, e.g. for `RDataFrame`:. ```python; import ROOT; import numpy. @ROOT.DeclareCppCallable([""unsigned int""], ""float""); def func(x):; return numpy.power(x, 2). df = ROOT.RDataFrame(4).Define(""x"", ""rdfentry_"").Define(""y"", ""PyROOT::func(x)""); npy = df.AsNumpy(); print(npy[""x""]) # Prints [0, 1, 2, 3]; print(npy[""y""]) # Prints [0.0, 1.0, 4.0, 9.0]; ```. Finally, the approach is fully compatible with any custom C++ types you may have. ```python; import ROOT. ROOT.gInterpreter.Declare(""""""; struct Foo {; static const int foo = 42;; };; """"""). @ROOT.DeclareCppCallable([""Foo""], """"); def func(x):; print(x.foo). ROOT.gInterpreter.ProcessLine(""Foo x; PyROOT::func(x);"") # Prints 42; ```; There are still some things to check before merging:. - [ ] Double check reference counting; - [ ] C++ wrapper takes (lvalue) references, what happens with rvalues? What is the universal thingy?; - [ ] We put the C++ callable in the `PyROOT::` namespace. This is fine? It can be everything, even the global namespace. What is a sane solution here?; - [ ] How many copies we are doing finally? What is the performance?; - [ ] What happens in MT scenarios? Put in a test case!; - [ ] We have to ship the public cppyy interface with the ROOT headers.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3488
https://github.com/root-project/root/pull/3493:412,Performance,perform,performance,412,"See old [PR#3414](https://github.com/root-project/root/pull/3414) for initial discussion. This PR cleans of the code a bit and adds tests. @josephmckenna Creating the testing code was slightly involved, hence the new PR and not asking you to submit a fix. I think the idea is a nice and natural improvement on the functionality that was already implemented. Motivation from original submitter:; > To explore the performance of a range of settings for BDTs, we often find a 0.1% background level most interesting for our physics applications for us in the ALPHA collaboration. Instead of adding one additional use case, I have added a general form such that users could set:; > // factory->OptimizeAllMethods(""SigEffAtBkgEff0001"",""Scan"");",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3493
https://github.com/root-project/root/pull/3493:689,Performance,Optimiz,OptimizeAllMethods,689,"See old [PR#3414](https://github.com/root-project/root/pull/3414) for initial discussion. This PR cleans of the code a bit and adds tests. @josephmckenna Creating the testing code was slightly involved, hence the new PR and not asking you to submit a fix. I think the idea is a nice and natural improvement on the functionality that was already implemented. Motivation from original submitter:; > To explore the performance of a range of settings for BDTs, we often find a 0.1% background level most interesting for our physics applications for us in the ALPHA collaboration. Instead of adding one additional use case, I have added a general form such that users could set:; > // factory->OptimizeAllMethods(""SigEffAtBkgEff0001"",""Scan"");",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3493
https://github.com/root-project/root/pull/3493:132,Testability,test,tests,132,"See old [PR#3414](https://github.com/root-project/root/pull/3414) for initial discussion. This PR cleans of the code a bit and adds tests. @josephmckenna Creating the testing code was slightly involved, hence the new PR and not asking you to submit a fix. I think the idea is a nice and natural improvement on the functionality that was already implemented. Motivation from original submitter:; > To explore the performance of a range of settings for BDTs, we often find a 0.1% background level most interesting for our physics applications for us in the ALPHA collaboration. Instead of adding one additional use case, I have added a general form such that users could set:; > // factory->OptimizeAllMethods(""SigEffAtBkgEff0001"",""Scan"");",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3493
https://github.com/root-project/root/pull/3493:167,Testability,test,testing,167,"See old [PR#3414](https://github.com/root-project/root/pull/3414) for initial discussion. This PR cleans of the code a bit and adds tests. @josephmckenna Creating the testing code was slightly involved, hence the new PR and not asking you to submit a fix. I think the idea is a nice and natural improvement on the functionality that was already implemented. Motivation from original submitter:; > To explore the performance of a range of settings for BDTs, we often find a 0.1% background level most interesting for our physics applications for us in the ALPHA collaboration. Instead of adding one additional use case, I have added a general form such that users could set:; > // factory->OptimizeAllMethods(""SigEffAtBkgEff0001"",""Scan"");",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3493
https://github.com/root-project/root/pull/3498:392,Deployability,install,installed,392,"1. Create `ui5` folder with all related openui5 code, move code from `etc\eve7`; 2. Create `js` folder with JavaScript ROOT code, move code from `etc/http`; 3. Introduce `webui` build config parameter, enabled when root7 or c++14 are enabled; 4. Folder `js` copied into build directory when `http` is enabled; 5. Folder `ui5` copies into build directory when `webui` is enabled; 6. When ROOT installed, `js` and `ui5` directories copied into `<prefix>` directory (platform-specific), identified as `TROOT::GetDataDir()`; 7. Try to use Component.js and manifest.json in openui5 projects, organize code with ui5-typical subfolders names.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3498
https://github.com/root-project/root/pull/3498:184,Modifiability,config,config,184,"1. Create `ui5` folder with all related openui5 code, move code from `etc\eve7`; 2. Create `js` folder with JavaScript ROOT code, move code from `etc/http`; 3. Introduce `webui` build config parameter, enabled when root7 or c++14 are enabled; 4. Folder `js` copied into build directory when `http` is enabled; 5. Folder `ui5` copies into build directory when `webui` is enabled; 6. When ROOT installed, `js` and `ui5` directories copied into `<prefix>` directory (platform-specific), identified as `TROOT::GetDataDir()`; 7. Try to use Component.js and manifest.json in openui5 projects, organize code with ui5-typical subfolders names.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3498
https://github.com/root-project/root/pull/3501:465,Testability,test,tests,465,"Quality-of-life improvement for getting typed objects from a TDirectoryFile. Essentially `GetObject` but with return value. Allows; ```; root -l tutorials/tmva/data/toy_sigbkg_categ_offset.root; root [0] _file0->Get(""TreeS""); (TObject *) 0x7f86f7d078f0; root [1] _file0->Get<TTree>(""TreeS""); (TTree *) 0x7f86f7d078f0; root [2] _file0->Get<TBranch>(""TreeS""); (TBranch *) nullptr; root [3] _file0->Get<TObject>(""TreeS""); (TObject *) 0x7f86f7d078f0; ```. Question for tests, how should these be added? I found no examples for testing GetObject. For the documentation maybe the suggested usage should be changed to `MyClass * obj = file->Get<MyClass>(""key"");` to be explicit that a pointer is returned. It currently is `auto obj = file->Get<MyClass>(""key"");`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3501
https://github.com/root-project/root/pull/3501:523,Testability,test,testing,523,"Quality-of-life improvement for getting typed objects from a TDirectoryFile. Essentially `GetObject` but with return value. Allows; ```; root -l tutorials/tmva/data/toy_sigbkg_categ_offset.root; root [0] _file0->Get(""TreeS""); (TObject *) 0x7f86f7d078f0; root [1] _file0->Get<TTree>(""TreeS""); (TTree *) 0x7f86f7d078f0; root [2] _file0->Get<TBranch>(""TreeS""); (TBranch *) nullptr; root [3] _file0->Get<TObject>(""TreeS""); (TObject *) 0x7f86f7d078f0; ```. Question for tests, how should these be added? I found no examples for testing GetObject. For the documentation maybe the suggested usage should be changed to `MyClass * obj = file->Get<MyClass>(""key"");` to be explicit that a pointer is returned. It currently is `auto obj = file->Get<MyClass>(""key"");`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3501
https://github.com/root-project/root/pull/3508:120,Availability,alive,alive,120,[ROOT-5236]; The RooProdPdf was leaking memory when caching values.; HistoToWorkspaceFactoryFast was keeping RooArgSets alive (hence never freeing memory arenas).; AsymptoticCalculator was leaking datasets.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3508
https://github.com/root-project/root/pull/3509:120,Availability,alive,alive,120,[ROOT-5236]; The RooProdPdf was leaking memory when caching values.; HistoToWorkspaceFactoryFast was keeping RooArgSets alive (hence never freeing memory arenas).; AsymptoticCalculator was leaking datasets. (cherry picked from commit 88369955a919f6457a89b28f440599da63bd2f91),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3509
https://github.com/root-project/root/pull/3510:36,Deployability,update,updates,36,Collection of various documentation updates/fixes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3510
https://github.com/root-project/root/pull/3511:23,Modifiability,inherit,inherits,23,"As all PDFs, RooAddPdf inherits the protected evaluate(). It is, however, mistakenly listed as public.; Calling it will yield a useless value, because it bypasses the usual normalisation steps applied; for other PDFs. Reducing the visibility will prevent this, and also remove it from doxygen.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3511
https://github.com/root-project/root/pull/3513:399,Modifiability,extend,extended,399,"This is an extension allowing the VMC package to run a simulation; with multiple different engines at a time. Tracks can be transferred; among engines during a simulation run based on conditions specified by; the user. Important notes on the extensions:; 1) This extension preserves backward-compatibility in the sense that; user code relying on the former version of VMC is still running; with the extended version. Was tested with GEANT3_VMC@v2-6 and; GEANT4_VMC@v3-6-p1.; 2) A shared simulation is only possible when TGeo is used for geometry; construction and navigation.; 3) A TMCManager singleton object is responsible for handling multiple; engines and can be obtained on request calling; TVirtualMCApplication::RequestManager() during construction of the; user application class.; 4) The introduced TMCParticleStatus objects hold additional; information to keep track of properties when a track is transferred; between engines.; 5) When a track is interrupted in one engine to be transferred to; another, the geometry state is cached in the form of a; TGeoBranchArray object. It will be used to initialize the navigator; when this track is picked up for further transport in the next; engine. This is especially useful/required when a track is; transferred at a volume boundary in order to be picked up in the; entered volume and not in the one just left. This is a main reason; why geometry management is forced to be done via TGeo. A more comprehensive introduction concerning the usage and; implementation in the user code can be found in the; montecarlo/vmc/README.md. Further note:; This commit also applies the clang format to the modified and new; files.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:1035,Performance,cache,cached,1035,"This is an extension allowing the VMC package to run a simulation; with multiple different engines at a time. Tracks can be transferred; among engines during a simulation run based on conditions specified by; the user. Important notes on the extensions:; 1) This extension preserves backward-compatibility in the sense that; user code relying on the former version of VMC is still running; with the extended version. Was tested with GEANT3_VMC@v2-6 and; GEANT4_VMC@v3-6-p1.; 2) A shared simulation is only possible when TGeo is used for geometry; construction and navigation.; 3) A TMCManager singleton object is responsible for handling multiple; engines and can be obtained on request calling; TVirtualMCApplication::RequestManager() during construction of the; user application class.; 4) The introduced TMCParticleStatus objects hold additional; information to keep track of properties when a track is transferred; between engines.; 5) When a track is interrupted in one engine to be transferred to; another, the geometry state is cached in the form of a; TGeoBranchArray object. It will be used to initialize the navigator; when this track is picked up for further transport in the next; engine. This is especially useful/required when a track is; transferred at a volume boundary in order to be picked up in the; entered volume and not in the one just left. This is a main reason; why geometry management is forced to be done via TGeo. A more comprehensive introduction concerning the usage and; implementation in the user code can be found in the; montecarlo/vmc/README.md. Further note:; This commit also applies the clang format to the modified and new; files.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3513:421,Testability,test,tested,421,"This is an extension allowing the VMC package to run a simulation; with multiple different engines at a time. Tracks can be transferred; among engines during a simulation run based on conditions specified by; the user. Important notes on the extensions:; 1) This extension preserves backward-compatibility in the sense that; user code relying on the former version of VMC is still running; with the extended version. Was tested with GEANT3_VMC@v2-6 and; GEANT4_VMC@v3-6-p1.; 2) A shared simulation is only possible when TGeo is used for geometry; construction and navigation.; 3) A TMCManager singleton object is responsible for handling multiple; engines and can be obtained on request calling; TVirtualMCApplication::RequestManager() during construction of the; user application class.; 4) The introduced TMCParticleStatus objects hold additional; information to keep track of properties when a track is transferred; between engines.; 5) When a track is interrupted in one engine to be transferred to; another, the geometry state is cached in the form of a; TGeoBranchArray object. It will be used to initialize the navigator; when this track is picked up for further transport in the next; engine. This is especially useful/required when a track is; transferred at a volume boundary in order to be picked up in the; entered volume and not in the one just left. This is a main reason; why geometry management is forced to be done via TGeo. A more comprehensive introduction concerning the usage and; implementation in the user code can be found in the; montecarlo/vmc/README.md. Further note:; This commit also applies the clang format to the modified and new; files.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3513
https://github.com/root-project/root/pull/3515:201,Deployability,integrat,integration,201,… case. Thanks @Axel-Naumann !. This fixes the performance issues for millions of request to the type system from cppyy if the type is for example a `std::vector<int>`. Waiting for response of Wim for integration in the official cppyy-clingwrapper repo.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3515
https://github.com/root-project/root/pull/3515:201,Integrability,integrat,integration,201,… case. Thanks @Axel-Naumann !. This fixes the performance issues for millions of request to the type system from cppyy if the type is for example a `std::vector<int>`. Waiting for response of Wim for integration in the official cppyy-clingwrapper repo.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3515
https://github.com/root-project/root/pull/3515:47,Performance,perform,performance,47,… case. Thanks @Axel-Naumann !. This fixes the performance issues for millions of request to the type system from cppyy if the type is for example a `std::vector<int>`. Waiting for response of Wim for integration in the official cppyy-clingwrapper repo.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3515
https://github.com/root-project/root/pull/3516:190,Modifiability,layers,layers,190,"As reported by @behrenhoff MethodDL did not have so far an implementation for the dropout. ; (see https://root-forum.cern.ch/t/method-kdl-in-tmva/32863); This PR fixes the dropout for dense layers, implementing what has been done for the previous MethodDNN. . The implementation removes (by setting to zero) randomly input nodes and re-scale the surviving ones by a factor 1/(1.- dropout_probability). In this way no changes are needed for testing and evaluating a trained network with dropout. . The PR applies also some other small improvements such as print out of optimizer names and some fixes in the cross-evaluation function to avoid NaN outputs.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3516
https://github.com/root-project/root/pull/3516:568,Performance,optimiz,optimizer,568,"As reported by @behrenhoff MethodDL did not have so far an implementation for the dropout. ; (see https://root-forum.cern.ch/t/method-kdl-in-tmva/32863); This PR fixes the dropout for dense layers, implementing what has been done for the previous MethodDNN. . The implementation removes (by setting to zero) randomly input nodes and re-scale the surviving ones by a factor 1/(1.- dropout_probability). In this way no changes are needed for testing and evaluating a trained network with dropout. . The PR applies also some other small improvements such as print out of optimizer names and some fixes in the cross-evaluation function to avoid NaN outputs.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3516
https://github.com/root-project/root/pull/3516:635,Safety,avoid,avoid,635,"As reported by @behrenhoff MethodDL did not have so far an implementation for the dropout. ; (see https://root-forum.cern.ch/t/method-kdl-in-tmva/32863); This PR fixes the dropout for dense layers, implementing what has been done for the previous MethodDNN. . The implementation removes (by setting to zero) randomly input nodes and re-scale the surviving ones by a factor 1/(1.- dropout_probability). In this way no changes are needed for testing and evaluating a trained network with dropout. . The PR applies also some other small improvements such as print out of optimizer names and some fixes in the cross-evaluation function to avoid NaN outputs.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3516
https://github.com/root-project/root/pull/3516:440,Testability,test,testing,440,"As reported by @behrenhoff MethodDL did not have so far an implementation for the dropout. ; (see https://root-forum.cern.ch/t/method-kdl-in-tmva/32863); This PR fixes the dropout for dense layers, implementing what has been done for the previous MethodDNN. . The implementation removes (by setting to zero) randomly input nodes and re-scale the surviving ones by a factor 1/(1.- dropout_probability). In this way no changes are needed for testing and evaluating a trained network with dropout. . The PR applies also some other small improvements such as print out of optimizer names and some fixes in the cross-evaluation function to avoid NaN outputs.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3516
https://github.com/root-project/root/pull/3517:9,Availability,error,error,9,"Fix test error:; https://epsft-jenkins.cern.ch/job/root-exp-pyroot/62/LABEL=mac1014,SPEC=default/testReport/junit/projectroot.bindings.pyroot_experimental.PyROOT/test/pyunittests_pyroot_pyz_roodatahist_ploton/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3517
https://github.com/root-project/root/pull/3517:4,Testability,test,test,4,"Fix test error:; https://epsft-jenkins.cern.ch/job/root-exp-pyroot/62/LABEL=mac1014,SPEC=default/testReport/junit/projectroot.bindings.pyroot_experimental.PyROOT/test/pyunittests_pyroot_pyz_roodatahist_ploton/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3517
https://github.com/root-project/root/pull/3517:97,Testability,test,testReport,97,"Fix test error:; https://epsft-jenkins.cern.ch/job/root-exp-pyroot/62/LABEL=mac1014,SPEC=default/testReport/junit/projectroot.bindings.pyroot_experimental.PyROOT/test/pyunittests_pyroot_pyz_roodatahist_ploton/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3517
https://github.com/root-project/root/pull/3517:162,Testability,test,test,162,"Fix test error:; https://epsft-jenkins.cern.ch/job/root-exp-pyroot/62/LABEL=mac1014,SPEC=default/testReport/junit/projectroot.bindings.pyroot_experimental.PyROOT/test/pyunittests_pyroot_pyz_roodatahist_ploton/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3517
https://github.com/root-project/root/pull/3519:55,Testability,test,tests,55,`string_view` support in Cppyy for < cxx14 fixed these tests:. https://github.com/root-project/root/pull/3455,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3519
https://github.com/root-project/root/pull/3523:227,Safety,avoid,avoid,227,If gDirectory is a nullptr use gROOT. TObject::Clone uses; TDirectory[File]::CloneObject and the TDirectoryFile object; actually change the behavior (set gFile to nullptr) in a way; that probably require significant surgery to avoid using the; virtual function.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3523
https://github.com/root-project/root/pull/3530:164,Integrability,message,message,164,"Following a ""suggestion"" by @daritter ;-). Rationale: these days, not having `DISPLAY` set is likely intentional (unlike in say good old AIX days). So printing the message ""just because"" is unlikely to be helpful. If OTOH the GUI *is* requested, printing a helpful ""you probably want `ssh -Y`"" is nice - so let's do that (in non-batch), but in `TUnixSystem::SetDisplay()`, which is invoked by the graphics initialization hook. This gets rid of all the utmp code in `rootx.cxx`, near-duplicating the code of `TUnixSystem.cxx`. Yay.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3530
https://github.com/root-project/root/pull/3532:37,Deployability,patch,patch,37,"… scope multiple times. Without this patch for Name<Content>::Inner, MakeProject was using Name<Content,::Inner>::Inner.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3532
https://github.com/root-project/root/pull/3533:103,Deployability,patch,patch,103,The user might use utilities which print on cout and expects the output; to be shown immediately. This patch automatically flushes std::cout after each execution of a wrapper.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3533
https://github.com/root-project/root/pull/3533:167,Integrability,wrap,wrapper,167,The user might use utilities which print on cout and expects the output; to be shown immediately. This patch automatically flushes std::cout after each execution of a wrapper.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3533
https://github.com/root-project/root/pull/3534:159,Deployability,patch,patch,159,"Cppyy allows to add custom pythonisations for classes, but it does not yet provide an API for adding custom type converters. Until that API exists, we need to patch Cppyy with a converter Python string -> `TString`, so that we do not have to create a `TString` in Python when calling a C++ method that expects it.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3534
https://github.com/root-project/root/pull/3535:74,Energy Efficiency,reduce,reduced,74,"Thanks to @cwiel for pointing out the issue. I've refactored the code and reduced code duplication massively. The bug is fixed by writing a pointer unequal zero in the array interface since numpy does not take this as exception. Actually, it does not matter at all what is written in the `""data""` field of the array interface since it is never accessed. Edit: Added a backport for experimental pyroot.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3535
https://github.com/root-project/root/pull/3535:174,Integrability,interface,interface,174,"Thanks to @cwiel for pointing out the issue. I've refactored the code and reduced code duplication massively. The bug is fixed by writing a pointer unequal zero in the array interface since numpy does not take this as exception. Actually, it does not matter at all what is written in the `""data""` field of the array interface since it is never accessed. Edit: Added a backport for experimental pyroot.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3535
https://github.com/root-project/root/pull/3535:316,Integrability,interface,interface,316,"Thanks to @cwiel for pointing out the issue. I've refactored the code and reduced code duplication massively. The bug is fixed by writing a pointer unequal zero in the array interface since numpy does not take this as exception. Actually, it does not matter at all what is written in the `""data""` field of the array interface since it is never accessed. Edit: Added a backport for experimental pyroot.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3535
https://github.com/root-project/root/pull/3535:50,Modifiability,refactor,refactored,50,"Thanks to @cwiel for pointing out the issue. I've refactored the code and reduced code duplication massively. The bug is fixed by writing a pointer unequal zero in the array interface since numpy does not take this as exception. Actually, it does not matter at all what is written in the `""data""` field of the array interface since it is never accessed. Edit: Added a backport for experimental pyroot.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3535
https://github.com/root-project/root/pull/3535:344,Security,access,accessed,344,"Thanks to @cwiel for pointing out the issue. I've refactored the code and reduced code duplication massively. The bug is fixed by writing a pointer unequal zero in the array interface since numpy does not take this as exception. Actually, it does not matter at all what is written in the `""data""` field of the array interface since it is never accessed. Edit: Added a backport for experimental pyroot.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3535
https://github.com/root-project/root/pull/3539:283,Availability,error,errors,283,"Either the interpreter knows them, or we alias them to `void`.; Just as before, the end result is that if users return a type; that is unknown to the interpreter from a Define, and then try; to read that Define'd column from jitted RDF nodes, the interpreter; (and consequently RDF) errors out.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3539
https://github.com/root-project/root/pull/3540:99,Availability,error,error,99,"This feature is implemented via a composite pythonizor that matches `TGraph`, `TGraph2D` and their error subclasses, and pythonises their getter methods of the X,Y,Z coordinate and error arrays, which in C++ return a pointer to double. The pythonisation consists in setting the size of the array buffer that the getter method returns, so that it is known in Python and the buffer is fully usable (its length can be obtained, it is iterable).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3540
https://github.com/root-project/root/pull/3540:181,Availability,error,error,181,"This feature is implemented via a composite pythonizor that matches `TGraph`, `TGraph2D` and their error subclasses, and pythonises their getter methods of the X,Y,Z coordinate and error arrays, which in C++ return a pointer to double. The pythonisation consists in setting the size of the array buffer that the getter method returns, so that it is known in Python and the buffer is fully usable (its length can be obtained, it is iterable).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3540
https://github.com/root-project/root/pull/3540:389,Usability,usab,usable,389,"This feature is implemented via a composite pythonizor that matches `TGraph`, `TGraph2D` and their error subclasses, and pythonises their getter methods of the X,Y,Z coordinate and error arrays, which in C++ return a pointer to double. The pythonisation consists in setting the size of the array buffer that the getter method returns, so that it is known in Python and the buffer is fully usable (its length can be obtained, it is iterable).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3540
https://github.com/root-project/root/pull/3542:283,Availability,error,errors,283,"Either the interpreter knows them, or we alias them to `void`.; Just as before, the end result is that if users return a type; that is unknown to the interpreter from a Define, and then try; to read that Define'd column from jitted RDF nodes, the interpreter; (and consequently RDF) errors out. This is missing a test.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3542
https://github.com/root-project/root/pull/3542:313,Testability,test,test,313,"Either the interpreter knows them, or we alias them to `void`.; Just as before, the end result is that if users return a type; that is unknown to the interpreter from a Define, and then try; to read that Define'd column from jitted RDF nodes, the interpreter; (and consequently RDF) errors out. This is missing a test.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3542
https://github.com/root-project/root/pull/3548:139,Modifiability,variab,variables,139,1. Make CEF display working with latest CEF code; 2. Copy all necessary CEF files into ROOT binary directory - no need to have extra shell variables when ROOT is running; 3. Adjust Qt5WebEngine code - latest Qt 5.12 more strict with custom scheme definitions; 4. Let use CEF and Qt5 displays for any http address - not only RWebWindow.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3548
https://github.com/root-project/root/pull/3551:522,Availability,error,error,522,"It fixes broken builds on Ubuntu 16:; `[ 92%] Building CXX object roofit/roofitcore/CMakeFiles/RooFitCore.dir/src/RooProdPdf.cxx.o; /mnt/build/workspace/lcg_ext_rootcov/BUILDTYPE/Release/COMPILER/native/LABEL/ubuntu16/build/projects/ROOT-HEAD/src/ROOT/HEAD/gui/webgui6/src/TWebCanvas.cxx: In member function ‘void TWebCanvas::ShowCmd(const char*, Bool_t)’:; /mnt/build/workspace/lcg_ext_rootcov/BUILDTYPE/Release/COMPILER/native/LABEL/ubuntu16/build/projects/ROOT-HEAD/src/ROOT/HEAD/gui/webgui6/src/TWebCanvas.cxx:516:77: error: ‘Warning’ was not declared in this scope; Warning(""ShowCmd"", ""Send operation not empty when try show %s"", arg); ^; `",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3551
https://github.com/root-project/root/pull/3551:179,Deployability,Release,Release,179,"It fixes broken builds on Ubuntu 16:; `[ 92%] Building CXX object roofit/roofitcore/CMakeFiles/RooFitCore.dir/src/RooProdPdf.cxx.o; /mnt/build/workspace/lcg_ext_rootcov/BUILDTYPE/Release/COMPILER/native/LABEL/ubuntu16/build/projects/ROOT-HEAD/src/ROOT/HEAD/gui/webgui6/src/TWebCanvas.cxx: In member function ‘void TWebCanvas::ShowCmd(const char*, Bool_t)’:; /mnt/build/workspace/lcg_ext_rootcov/BUILDTYPE/Release/COMPILER/native/LABEL/ubuntu16/build/projects/ROOT-HEAD/src/ROOT/HEAD/gui/webgui6/src/TWebCanvas.cxx:516:77: error: ‘Warning’ was not declared in this scope; Warning(""ShowCmd"", ""Send operation not empty when try show %s"", arg); ^; `",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3551
https://github.com/root-project/root/pull/3551:405,Deployability,Release,Release,405,"It fixes broken builds on Ubuntu 16:; `[ 92%] Building CXX object roofit/roofitcore/CMakeFiles/RooFitCore.dir/src/RooProdPdf.cxx.o; /mnt/build/workspace/lcg_ext_rootcov/BUILDTYPE/Release/COMPILER/native/LABEL/ubuntu16/build/projects/ROOT-HEAD/src/ROOT/HEAD/gui/webgui6/src/TWebCanvas.cxx: In member function ‘void TWebCanvas::ShowCmd(const char*, Bool_t)’:; /mnt/build/workspace/lcg_ext_rootcov/BUILDTYPE/Release/COMPILER/native/LABEL/ubuntu16/build/projects/ROOT-HEAD/src/ROOT/HEAD/gui/webgui6/src/TWebCanvas.cxx:516:77: error: ‘Warning’ was not declared in this scope; Warning(""ShowCmd"", ""Send operation not empty when try show %s"", arg); ^; `",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3551
https://github.com/root-project/root/pull/3553:126,Modifiability,variab,variable,126,"Main problem that cmake `list(APPEND BASE_HEADERS ...)` command was not exported to parent scope - as original `BASE_HEADERS` variable. Once done, several other dictionary options should be adjusted.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3553
https://github.com/root-project/root/pull/3555:277,Deployability,update,update,277,"Before importing cppyy from PyROOT, instead of specifying the location of the PCH, we can just use the magic word 'none' to tell cppyy not to check the PCH. In both cases, the objective is to avoid a warning from cppyy when importing it. This needs to be merged after the next update of `cppyy-backend`, when a new release is out. The related discussion with Wim is here:; https://bitbucket.org/wlav/cppyy/issues/62/new-check-in-loaderpy-uses-wrong-include",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3555
https://github.com/root-project/root/pull/3555:315,Deployability,release,release,315,"Before importing cppyy from PyROOT, instead of specifying the location of the PCH, we can just use the magic word 'none' to tell cppyy not to check the PCH. In both cases, the objective is to avoid a warning from cppyy when importing it. This needs to be merged after the next update of `cppyy-backend`, when a new release is out. The related discussion with Wim is here:; https://bitbucket.org/wlav/cppyy/issues/62/new-check-in-loaderpy-uses-wrong-include",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3555
https://github.com/root-project/root/pull/3555:429,Performance,load,loaderpy-uses-wrong-include,429,"Before importing cppyy from PyROOT, instead of specifying the location of the PCH, we can just use the magic word 'none' to tell cppyy not to check the PCH. In both cases, the objective is to avoid a warning from cppyy when importing it. This needs to be merged after the next update of `cppyy-backend`, when a new release is out. The related discussion with Wim is here:; https://bitbucket.org/wlav/cppyy/issues/62/new-check-in-loaderpy-uses-wrong-include",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3555
https://github.com/root-project/root/pull/3555:192,Safety,avoid,avoid,192,"Before importing cppyy from PyROOT, instead of specifying the location of the PCH, we can just use the magic word 'none' to tell cppyy not to check the PCH. In both cases, the objective is to avoid a warning from cppyy when importing it. This needs to be merged after the next update of `cppyy-backend`, when a new release is out. The related discussion with Wim is here:; https://bitbucket.org/wlav/cppyy/issues/62/new-check-in-loaderpy-uses-wrong-include",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3555
https://github.com/root-project/root/pull/3561:452,Availability,error,error,452,1. Do not expose special parameters to URL string - now in default HTML file special attributes can be inserted together with `JSROOT.ConnectWebWindow` call; 2. Correctly handle `#` in WebWindow URL. Such symbol used for routing inside webpage and will be often used with openui5; 3. Unify handling of URL options with RWebDisplayArgs. For now only `key` and `batch_mode` parameters are exposed to web window URL; 4. Update/extend doxygen docu; 5. Fix error in v7 CanvasPainter - v616 already fixed,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3561
https://github.com/root-project/root/pull/3561:417,Deployability,Update,Update,417,1. Do not expose special parameters to URL string - now in default HTML file special attributes can be inserted together with `JSROOT.ConnectWebWindow` call; 2. Correctly handle `#` in WebWindow URL. Such symbol used for routing inside webpage and will be often used with openui5; 3. Unify handling of URL options with RWebDisplayArgs. For now only `key` and `batch_mode` parameters are exposed to web window URL; 4. Update/extend doxygen docu; 5. Fix error in v7 CanvasPainter - v616 already fixed,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3561
https://github.com/root-project/root/pull/3561:221,Integrability,rout,routing,221,1. Do not expose special parameters to URL string - now in default HTML file special attributes can be inserted together with `JSROOT.ConnectWebWindow` call; 2. Correctly handle `#` in WebWindow URL. Such symbol used for routing inside webpage and will be often used with openui5; 3. Unify handling of URL options with RWebDisplayArgs. For now only `key` and `batch_mode` parameters are exposed to web window URL; 4. Update/extend doxygen docu; 5. Fix error in v7 CanvasPainter - v616 already fixed,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3561
https://github.com/root-project/root/pull/3561:424,Modifiability,extend,extend,424,1. Do not expose special parameters to URL string - now in default HTML file special attributes can be inserted together with `JSROOT.ConnectWebWindow` call; 2. Correctly handle `#` in WebWindow URL. Such symbol used for routing inside webpage and will be often used with openui5; 3. Unify handling of URL options with RWebDisplayArgs. For now only `key` and `batch_mode` parameters are exposed to web window URL; 4. Update/extend doxygen docu; 5. Fix error in v7 CanvasPainter - v616 already fixed,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3561
https://github.com/root-project/root/pull/3561:10,Security,expose,expose,10,1. Do not expose special parameters to URL string - now in default HTML file special attributes can be inserted together with `JSROOT.ConnectWebWindow` call; 2. Correctly handle `#` in WebWindow URL. Such symbol used for routing inside webpage and will be often used with openui5; 3. Unify handling of URL options with RWebDisplayArgs. For now only `key` and `batch_mode` parameters are exposed to web window URL; 4. Update/extend doxygen docu; 5. Fix error in v7 CanvasPainter - v616 already fixed,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3561
https://github.com/root-project/root/pull/3561:387,Security,expose,exposed,387,1. Do not expose special parameters to URL string - now in default HTML file special attributes can be inserted together with `JSROOT.ConnectWebWindow` call; 2. Correctly handle `#` in WebWindow URL. Such symbol used for routing inside webpage and will be often used with openui5; 3. Unify handling of URL options with RWebDisplayArgs. For now only `key` and `batch_mode` parameters are exposed to web window URL; 4. Update/extend doxygen docu; 5. Fix error in v7 CanvasPainter - v616 already fixed,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3561
https://github.com/root-project/root/pull/3564:283,Availability,error,errors,283,"Either the interpreter knows them, or we alias them to `void`.; Just as before, the end result is that if users return a type; that is unknown to the interpreter from a Define, and then try; to read that Define'd column from jitted RDF nodes, the interpreter; (and consequently RDF) errors out.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3564
https://github.com/root-project/root/pull/3568:143,Availability,error,error,143,This fixes ROOT-7608.; Move to protected also the functions of TH1 that do not make sense for TH2Poly.; Add a test for getting/setting the bin error,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3568
https://github.com/root-project/root/pull/3568:110,Testability,test,test,110,This fixes ROOT-7608.; Move to protected also the functions of TH1 that do not make sense for TH2Poly.; Add a test for getting/setting the bin error,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3568
https://github.com/root-project/root/pull/3570:0,Testability,Test,Tested,0,Tested with 6.16/00,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3570
https://github.com/root-project/root/pull/3575:138,Testability,test,tests,138,"This PR changes the way CPyCppyy is built to also generate its pcm and rootmap files. This is relevant to fix the `roottest-python-cling` tests, which use `TPython`, now in CPyCppyy. Moreover, the PR includes a few relevant CPyCppyy headers in the PCH and sets the `CLING_STANDARD_PCH`, to prevent Cppyy from checking the PCH, in the environment scripts of ROOT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3575
https://github.com/root-project/root/pull/3577:151,Availability,Error,Error,151,"[ 47%] Built target rootcling_stage1; Scanning dependencies of target G__Core; [ 47%] Generating G__Core.cxx, ../lib/libCore.rootmap, ../lib/Core.pcm; Error in <CheckModuleValid>: Couldn't find module with name 'Core' in modulemap!; core/CMakeFiles/G__Core.dir/build.make:453: recipe for target 'core/G__Core.cxx' failed; make[2]: *** [core/G__Core.cxx] Error 1; CMakeFiles/Makefile2:15584: recipe for target 'core/CMakeFiles/G__Core.dir/all' failed; make[1]: *** [core/CMakeFiles/G__Core.dir/all] Error 2; Makefile:151: recipe for target 'all' failed; make: *** [all] Error 2",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3577
https://github.com/root-project/root/pull/3577:354,Availability,Error,Error,354,"[ 47%] Built target rootcling_stage1; Scanning dependencies of target G__Core; [ 47%] Generating G__Core.cxx, ../lib/libCore.rootmap, ../lib/Core.pcm; Error in <CheckModuleValid>: Couldn't find module with name 'Core' in modulemap!; core/CMakeFiles/G__Core.dir/build.make:453: recipe for target 'core/G__Core.cxx' failed; make[2]: *** [core/G__Core.cxx] Error 1; CMakeFiles/Makefile2:15584: recipe for target 'core/CMakeFiles/G__Core.dir/all' failed; make[1]: *** [core/CMakeFiles/G__Core.dir/all] Error 2; Makefile:151: recipe for target 'all' failed; make: *** [all] Error 2",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3577
https://github.com/root-project/root/pull/3577:498,Availability,Error,Error,498,"[ 47%] Built target rootcling_stage1; Scanning dependencies of target G__Core; [ 47%] Generating G__Core.cxx, ../lib/libCore.rootmap, ../lib/Core.pcm; Error in <CheckModuleValid>: Couldn't find module with name 'Core' in modulemap!; core/CMakeFiles/G__Core.dir/build.make:453: recipe for target 'core/G__Core.cxx' failed; make[2]: *** [core/G__Core.cxx] Error 1; CMakeFiles/Makefile2:15584: recipe for target 'core/CMakeFiles/G__Core.dir/all' failed; make[1]: *** [core/CMakeFiles/G__Core.dir/all] Error 2; Makefile:151: recipe for target 'all' failed; make: *** [all] Error 2",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3577
https://github.com/root-project/root/pull/3577:569,Availability,Error,Error,569,"[ 47%] Built target rootcling_stage1; Scanning dependencies of target G__Core; [ 47%] Generating G__Core.cxx, ../lib/libCore.rootmap, ../lib/Core.pcm; Error in <CheckModuleValid>: Couldn't find module with name 'Core' in modulemap!; core/CMakeFiles/G__Core.dir/build.make:453: recipe for target 'core/G__Core.cxx' failed; make[2]: *** [core/G__Core.cxx] Error 1; CMakeFiles/Makefile2:15584: recipe for target 'core/CMakeFiles/G__Core.dir/all' failed; make[1]: *** [core/CMakeFiles/G__Core.dir/all] Error 2; Makefile:151: recipe for target 'all' failed; make: *** [all] Error 2",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3577
https://github.com/root-project/root/pull/3577:47,Integrability,depend,dependencies,47,"[ 47%] Built target rootcling_stage1; Scanning dependencies of target G__Core; [ 47%] Generating G__Core.cxx, ../lib/libCore.rootmap, ../lib/Core.pcm; Error in <CheckModuleValid>: Couldn't find module with name 'Core' in modulemap!; core/CMakeFiles/G__Core.dir/build.make:453: recipe for target 'core/G__Core.cxx' failed; make[2]: *** [core/G__Core.cxx] Error 1; CMakeFiles/Makefile2:15584: recipe for target 'core/CMakeFiles/G__Core.dir/all' failed; make[1]: *** [core/CMakeFiles/G__Core.dir/all] Error 2; Makefile:151: recipe for target 'all' failed; make: *** [all] Error 2",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3577
https://github.com/root-project/root/pull/3578:241,Availability,error,error,241,"$ find /usr -name ""cuchar""; /usr/include/c++/8/cuchar; /usr/include/c++/7/cuchar; /usr/include/c++/6/cuchar. PR fixes a broken CI build on Ubuntu 16 (gcc 5.4): /mnt/build/workspace/root-pullrequests-build/build/include/stl.modulemap:366:12: error: header 'cuchar' not found",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3578
https://github.com/root-project/root/pull/3579:78,Availability,error,error,78,"When updating `cppyy-backend` to v1.7.3 in PyROOT experimental, a compilation error appears because of a missing functionality in `TCling`, in particular a method to get using declarations of namespaces. This functionality was added to Cppyy's ROOT recently, and a patch was created for it:; https://bitbucket.org/wlav/cppyy-backend/src/59a4a747d03c6e94eaaa28062daf83104334f27d/cling/patches/using_directives.diff. This PR proposes to add such functionality to mainstream ROOT. . Inviting @Axel-Naumann and @wlav to the party.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:265,Deployability,patch,patch,265,"When updating `cppyy-backend` to v1.7.3 in PyROOT experimental, a compilation error appears because of a missing functionality in `TCling`, in particular a method to get using declarations of namespaces. This functionality was added to Cppyy's ROOT recently, and a patch was created for it:; https://bitbucket.org/wlav/cppyy-backend/src/59a4a747d03c6e94eaaa28062daf83104334f27d/cling/patches/using_directives.diff. This PR proposes to add such functionality to mainstream ROOT. . Inviting @Axel-Naumann and @wlav to the party.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3579:384,Deployability,patch,patches,384,"When updating `cppyy-backend` to v1.7.3 in PyROOT experimental, a compilation error appears because of a missing functionality in `TCling`, in particular a method to get using declarations of namespaces. This functionality was added to Cppyy's ROOT recently, and a patch was created for it:; https://bitbucket.org/wlav/cppyy-backend/src/59a4a747d03c6e94eaaa28062daf83104334f27d/cling/patches/using_directives.diff. This PR proposes to add such functionality to mainstream ROOT. . Inviting @Axel-Naumann and @wlav to the party.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3579
https://github.com/root-project/root/pull/3581:228,Availability,failure,failures,228,"This is a cherry pick of the `loader.py` in cppyy-backend version clingwrapper-1.7.2, which has the new treatment of `CLING_STANDARD_PCH` and its setting to `'none'` to prevent the PCH check by Cppyy. It should fix the new test failures that appeared last night in the experimental PyROOT builds. https://epsft-jenkins.cern.ch/job/root-exp-pyroot/76/. A complete update will come for the three packages of Cppyy once the functionality of this PR:; https://github.com/root-project/root/pull/3579; is merged into `TCling`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3581
https://github.com/root-project/root/pull/3581:363,Deployability,update,update,363,"This is a cherry pick of the `loader.py` in cppyy-backend version clingwrapper-1.7.2, which has the new treatment of `CLING_STANDARD_PCH` and its setting to `'none'` to prevent the PCH check by Cppyy. It should fix the new test failures that appeared last night in the experimental PyROOT builds. https://epsft-jenkins.cern.ch/job/root-exp-pyroot/76/. A complete update will come for the three packages of Cppyy once the functionality of this PR:; https://github.com/root-project/root/pull/3579; is merged into `TCling`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3581
https://github.com/root-project/root/pull/3581:30,Performance,load,loader,30,"This is a cherry pick of the `loader.py` in cppyy-backend version clingwrapper-1.7.2, which has the new treatment of `CLING_STANDARD_PCH` and its setting to `'none'` to prevent the PCH check by Cppyy. It should fix the new test failures that appeared last night in the experimental PyROOT builds. https://epsft-jenkins.cern.ch/job/root-exp-pyroot/76/. A complete update will come for the three packages of Cppyy once the functionality of this PR:; https://github.com/root-project/root/pull/3579; is merged into `TCling`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3581
https://github.com/root-project/root/pull/3581:223,Testability,test,test,223,"This is a cherry pick of the `loader.py` in cppyy-backend version clingwrapper-1.7.2, which has the new treatment of `CLING_STANDARD_PCH` and its setting to `'none'` to prevent the PCH check by Cppyy. It should fix the new test failures that appeared last night in the experimental PyROOT builds. https://epsft-jenkins.cern.ch/job/root-exp-pyroot/76/. A complete update will come for the three packages of Cppyy once the functionality of this PR:; https://github.com/root-project/root/pull/3579; is merged into `TCling`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3581
https://github.com/root-project/root/pull/3585:815,Deployability,release,release,815,In order to fix ROOT-10034 a new Executor class has been created.; The class wraps the TExecutor types of ROOT and create in MT running a TThreadExecutor or a TSequentialExecutor. ; This allows to use exactly same code in all TMVA depending on sequential or MT running. ; In addition now the TMVA::Config can control the MT running. The behaviour is the following: ; - ROOT::IsImplicitMTEnabled() = false TMVA uses TSequentialExecutor (no MT); - ROOT::IsImplicitMTEnabled() = true TMVA uses TThreadExecutor with the number of threads provided in ROOT::EnableImplicitMT; - TMVA::gConfig.EnableMT(nthreads) : run MT using TThreadExecutor with nthreads (if the ROOT thread pool has not been created before) otherwise use existing pool; - TMVA::gConfig.DisableMT() - delete TThreadExecutor if it has been created (i.e. release the thread pool) and use TSequentialExecutor,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3585
https://github.com/root-project/root/pull/3585:77,Integrability,wrap,wraps,77,In order to fix ROOT-10034 a new Executor class has been created.; The class wraps the TExecutor types of ROOT and create in MT running a TThreadExecutor or a TSequentialExecutor. ; This allows to use exactly same code in all TMVA depending on sequential or MT running. ; In addition now the TMVA::Config can control the MT running. The behaviour is the following: ; - ROOT::IsImplicitMTEnabled() = false TMVA uses TSequentialExecutor (no MT); - ROOT::IsImplicitMTEnabled() = true TMVA uses TThreadExecutor with the number of threads provided in ROOT::EnableImplicitMT; - TMVA::gConfig.EnableMT(nthreads) : run MT using TThreadExecutor with nthreads (if the ROOT thread pool has not been created before) otherwise use existing pool; - TMVA::gConfig.DisableMT() - delete TThreadExecutor if it has been created (i.e. release the thread pool) and use TSequentialExecutor,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3585
https://github.com/root-project/root/pull/3585:231,Integrability,depend,depending,231,In order to fix ROOT-10034 a new Executor class has been created.; The class wraps the TExecutor types of ROOT and create in MT running a TThreadExecutor or a TSequentialExecutor. ; This allows to use exactly same code in all TMVA depending on sequential or MT running. ; In addition now the TMVA::Config can control the MT running. The behaviour is the following: ; - ROOT::IsImplicitMTEnabled() = false TMVA uses TSequentialExecutor (no MT); - ROOT::IsImplicitMTEnabled() = true TMVA uses TThreadExecutor with the number of threads provided in ROOT::EnableImplicitMT; - TMVA::gConfig.EnableMT(nthreads) : run MT using TThreadExecutor with nthreads (if the ROOT thread pool has not been created before) otherwise use existing pool; - TMVA::gConfig.DisableMT() - delete TThreadExecutor if it has been created (i.e. release the thread pool) and use TSequentialExecutor,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3585
https://github.com/root-project/root/pull/3585:298,Modifiability,Config,Config,298,In order to fix ROOT-10034 a new Executor class has been created.; The class wraps the TExecutor types of ROOT and create in MT running a TThreadExecutor or a TSequentialExecutor. ; This allows to use exactly same code in all TMVA depending on sequential or MT running. ; In addition now the TMVA::Config can control the MT running. The behaviour is the following: ; - ROOT::IsImplicitMTEnabled() = false TMVA uses TSequentialExecutor (no MT); - ROOT::IsImplicitMTEnabled() = true TMVA uses TThreadExecutor with the number of threads provided in ROOT::EnableImplicitMT; - TMVA::gConfig.EnableMT(nthreads) : run MT using TThreadExecutor with nthreads (if the ROOT thread pool has not been created before) otherwise use existing pool; - TMVA::gConfig.DisableMT() - delete TThreadExecutor if it has been created (i.e. release the thread pool) and use TSequentialExecutor,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3585
https://github.com/root-project/root/pull/3586:27,Availability,fault,fault,27,"Before:; ```; Segmentation fault; ```. After:; ```; rootcling_stage1 0x000000010ea2ba98 llvm::sys::PrintStackTrace(llvm::raw_ostream&) + 40; 1 rootcling_stage1 0x000000010ea2ad46 llvm::sys::RunSignalHandlers() + 86; 2 rootcling_stage1 0x000000010ea2bffe SignalHandler(int) + 270; 3 libsystem_platform.dylib 0x00007fff65610b3d _sigtramp + 29; 4 rootcling_stage1 0x000000010c7b68dd clang::operator==(clang::QualType const&, clang::QualType const&) + 29; 5 rootcling_stage1 0x000000010d531b20 clang::Preprocessor::getModuleHeaderToIncludeForDiagnostics(clang::SourceLocation, clang::Module*, clang::SourceLocation) + 48; 6 rootcling_stage1 0x000000010d95bfc7 clang::Sema::diagnoseMissingImport(clang::SourceLocation, clang::NamedDecl*, clang::SourceLocation, llvm::ArrayRef<clang::Module*>, clang::Sema::MissingImportKind, bool) + 535; 7 rootcling_stage1 0x000000010d95b6eb clang::Sema::diagnoseMissingImport(clang::SourceLocation, clang::NamedDecl*, clang::Sema::MissingImportKind, bool) + 395; 8 rootcling_stage1 0x000000010d95b199 clang::Sema::diagnoseTypo(clang::TypoCorrection const&, clang::PartialDiagnostic const&, clang::PartialDiagnostic const&, bool) + 441; 9 rootcling_stage1 0x000000010d95af83 clang::Sema::diagnoseTypo(clang::TypoCorrection const&, clang::PartialDiagnostic const&, bool) + 51; 10 rootcling_stage1 0x000000010d6f0a39 clang::Sema::DiagnoseUnknownTypeName(clang::IdentifierInfo*&, clang::SourceLocation, clang::Scope*, clang::CXXScopeSpec*, clang::OpaquePtr<clang::QualType>&, bool) + 985; 11 rootcling_stage1 0x000000010d57ef20 clang::Parser::ParseImplicitInt(clang::DeclSpec&, clang::CXXScopeSpec*, clang::Parser::ParsedTemplateInfo const&, clang::AccessSpecifier, clang::Parser::DeclSpecContext, clang::Parser::ParsedAttributesWithRange&) + 2288; 12 rootcling_stage1 0x000000010d579427 clang::Parser::ParseDeclarationSpecifiers(clang::DeclSpec&, clang::Parser::ParsedTemplateInfo const&, clang::AccessSpecifier, clang::Parser::DeclSpecContext, clang::Parser::LateParsedAttr",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3586
https://github.com/root-project/root/pull/3586:5021,Integrability,Message,MessageTypes,5021,I/Users/vvassilev/workspace/sources/root -I/Users/vvassilev/workspace/builds/root/etc/cling/ -I/Users/vvassilev/workspace/builds/root/include -I/Users/vvassilev/workspace/sources/root/builtins/zlib -I/Users/vvassilev/workspace/sources/root/core/base/inc -I/Users/vvassilev/workspace/sources/root/core/clib/inc -I/Users/vvassilev/workspace/sources/root/core/cont/inc -I/Users/vvassilev/workspace/sources/root/core/foundation/inc -I/Users/vvassilev/workspace/sources/root/core/macosx/inc -I/Users/vvassilev/workspace/sources/root/core/unix/inc -I/Users/vvassilev/workspace/sources/root/core/winnt/inc -I/Users/vvassilev/workspace/sources/root/core/clingutils/inc -I/Users/vvassilev/workspace/sources/root/core/meta/inc -I/Users/vvassilev/workspace/sources/root/core/textinput/inc -I/Users/vvassilev/workspace/sources/root/core -writeEmptyRootPCM -DSYSTEM_TYPE_macosx ROOT/StringConv.hxx ROOT/TExecutor.hxx ROOT/TSequentialExecutor.hxx Buttons.h Bytes.h Byteswap.h Gtypes.h GuiTypes.h KeySymbols.h MessageTypes.h Riostream.h Rtypes.h TApplication.h TApplicationImp.h TAtt3D.h TAttAxis.h TAttBBox2D.h TAttBBox.h TAttFill.h TAttLine.h TAttMarker.h TAttPad.h TAttText.h TBase64.h TBenchmark.h TBrowser.h TBrowserImp.h TBuffer3D.h TBuffer3DTypes.h TBuffer.h TCanvasImp.h TColorGradient.h TColor.h TContextMenu.h TContextMenuImp.h TControlBarImp.h TDatime.h TDirectory.h TEnv.h TError.h TException.h TExec.h TFileCollection.h TFileInfo.h TFolder.h TGuiFactory.h TInetAddress.h TInspectorImp.h TMacro.h TMathBase.h TMD5.h TMemberInspector.h TMessageHandler.h TNamed.h TNotifyLink.h TObject.h TObjectSpy.h TObjString.h TParameter.h TPluginManager.h TPoint.h TPRegexp.h TProcessID.h TProcessUUID.h TQClass.h TQCommand.h TQConnection.h TQObject.h TRedirectOutputGuard.h TRefCnt.h TRef.h TRegexp.h TRemoteObject.h TROOT.h TRootIOCtor.h TStopwatch.h TStorage.h TString.h TStringLong.h TStyle.h TSysEvtHandler.h TSystemDirectory.h TSystemFile.h TSystem.h TTask.h TThreadSlots.h TTime.h TTimer.h TTimeStamp.h TUri.h T,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3586
https://github.com/root-project/root/pull/3586:1675,Security,Access,AccessSpecifier,1675,"gImport(clang::SourceLocation, clang::NamedDecl*, clang::SourceLocation, llvm::ArrayRef<clang::Module*>, clang::Sema::MissingImportKind, bool) + 535; 7 rootcling_stage1 0x000000010d95b6eb clang::Sema::diagnoseMissingImport(clang::SourceLocation, clang::NamedDecl*, clang::Sema::MissingImportKind, bool) + 395; 8 rootcling_stage1 0x000000010d95b199 clang::Sema::diagnoseTypo(clang::TypoCorrection const&, clang::PartialDiagnostic const&, clang::PartialDiagnostic const&, bool) + 441; 9 rootcling_stage1 0x000000010d95af83 clang::Sema::diagnoseTypo(clang::TypoCorrection const&, clang::PartialDiagnostic const&, bool) + 51; 10 rootcling_stage1 0x000000010d6f0a39 clang::Sema::DiagnoseUnknownTypeName(clang::IdentifierInfo*&, clang::SourceLocation, clang::Scope*, clang::CXXScopeSpec*, clang::OpaquePtr<clang::QualType>&, bool) + 985; 11 rootcling_stage1 0x000000010d57ef20 clang::Parser::ParseImplicitInt(clang::DeclSpec&, clang::CXXScopeSpec*, clang::Parser::ParsedTemplateInfo const&, clang::AccessSpecifier, clang::Parser::DeclSpecContext, clang::Parser::ParsedAttributesWithRange&) + 2288; 12 rootcling_stage1 0x000000010d579427 clang::Parser::ParseDeclarationSpecifiers(clang::DeclSpec&, clang::Parser::ParsedTemplateInfo const&, clang::AccessSpecifier, clang::Parser::DeclSpecContext, clang::Parser::LateParsedAttrList*) + 6855; 13 rootcling_stage1 0x000000010d5f8a6a clang::Parser::ParseDeclOrFunctionDefInternal(clang::Parser::ParsedAttributesWithRange&, clang::ParsingDeclSpec&, clang::AccessSpecifier) + 138; 14 rootcling_stage1 0x000000010d5f8725 clang::Parser::ParseDeclarationOrFunctionDefinition(clang::Parser::ParsedAttributesWithRange&, clang::ParsingDeclSpec*, clang::AccessSpecifier) + 373; 15 rootcling_stage1 0x000000010d5f7477 clang::Parser::ParseExternalDeclaration(clang::Parser::ParsedAttributesWithRange&, clang::ParsingDeclSpec*) + 2423; 16 rootcling_stage1 0x000000010d5f641c clang::Parser::ParseTopLevelDecl(clang::OpaquePtr<clang::DeclGroupRef>&) + 588; 17 rootcling_stage1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3586
https://github.com/root-project/root/pull/3586:1923,Security,Access,AccessSpecifier,1923,"ang::NamedDecl*, clang::Sema::MissingImportKind, bool) + 395; 8 rootcling_stage1 0x000000010d95b199 clang::Sema::diagnoseTypo(clang::TypoCorrection const&, clang::PartialDiagnostic const&, clang::PartialDiagnostic const&, bool) + 441; 9 rootcling_stage1 0x000000010d95af83 clang::Sema::diagnoseTypo(clang::TypoCorrection const&, clang::PartialDiagnostic const&, bool) + 51; 10 rootcling_stage1 0x000000010d6f0a39 clang::Sema::DiagnoseUnknownTypeName(clang::IdentifierInfo*&, clang::SourceLocation, clang::Scope*, clang::CXXScopeSpec*, clang::OpaquePtr<clang::QualType>&, bool) + 985; 11 rootcling_stage1 0x000000010d57ef20 clang::Parser::ParseImplicitInt(clang::DeclSpec&, clang::CXXScopeSpec*, clang::Parser::ParsedTemplateInfo const&, clang::AccessSpecifier, clang::Parser::DeclSpecContext, clang::Parser::ParsedAttributesWithRange&) + 2288; 12 rootcling_stage1 0x000000010d579427 clang::Parser::ParseDeclarationSpecifiers(clang::DeclSpec&, clang::Parser::ParsedTemplateInfo const&, clang::AccessSpecifier, clang::Parser::DeclSpecContext, clang::Parser::LateParsedAttrList*) + 6855; 13 rootcling_stage1 0x000000010d5f8a6a clang::Parser::ParseDeclOrFunctionDefInternal(clang::Parser::ParsedAttributesWithRange&, clang::ParsingDeclSpec&, clang::AccessSpecifier) + 138; 14 rootcling_stage1 0x000000010d5f8725 clang::Parser::ParseDeclarationOrFunctionDefinition(clang::Parser::ParsedAttributesWithRange&, clang::ParsingDeclSpec*, clang::AccessSpecifier) + 373; 15 rootcling_stage1 0x000000010d5f7477 clang::Parser::ParseExternalDeclaration(clang::Parser::ParsedAttributesWithRange&, clang::ParsingDeclSpec*) + 2423; 16 rootcling_stage1 0x000000010d5f641c clang::Parser::ParseTopLevelDecl(clang::OpaquePtr<clang::DeclGroupRef>&) + 588; 17 rootcling_stage1 0x000000010cd68a90 cling::IncrementalParser::ParseInternal(llvm::StringRef) + 2704; 18 rootcling_stage1 0x000000010cd6ca91 cling::IncrementalParser::Compile(llvm::StringRef, cling::CompilationOptions const&) + 81; 19 rootcling_stage1 0x000000010cd",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3586
https://github.com/root-project/root/pull/3586:2176,Security,Access,AccessSpecifier,2176," 0x000000010d95af83 clang::Sema::diagnoseTypo(clang::TypoCorrection const&, clang::PartialDiagnostic const&, bool) + 51; 10 rootcling_stage1 0x000000010d6f0a39 clang::Sema::DiagnoseUnknownTypeName(clang::IdentifierInfo*&, clang::SourceLocation, clang::Scope*, clang::CXXScopeSpec*, clang::OpaquePtr<clang::QualType>&, bool) + 985; 11 rootcling_stage1 0x000000010d57ef20 clang::Parser::ParseImplicitInt(clang::DeclSpec&, clang::CXXScopeSpec*, clang::Parser::ParsedTemplateInfo const&, clang::AccessSpecifier, clang::Parser::DeclSpecContext, clang::Parser::ParsedAttributesWithRange&) + 2288; 12 rootcling_stage1 0x000000010d579427 clang::Parser::ParseDeclarationSpecifiers(clang::DeclSpec&, clang::Parser::ParsedTemplateInfo const&, clang::AccessSpecifier, clang::Parser::DeclSpecContext, clang::Parser::LateParsedAttrList*) + 6855; 13 rootcling_stage1 0x000000010d5f8a6a clang::Parser::ParseDeclOrFunctionDefInternal(clang::Parser::ParsedAttributesWithRange&, clang::ParsingDeclSpec&, clang::AccessSpecifier) + 138; 14 rootcling_stage1 0x000000010d5f8725 clang::Parser::ParseDeclarationOrFunctionDefinition(clang::Parser::ParsedAttributesWithRange&, clang::ParsingDeclSpec*, clang::AccessSpecifier) + 373; 15 rootcling_stage1 0x000000010d5f7477 clang::Parser::ParseExternalDeclaration(clang::Parser::ParsedAttributesWithRange&, clang::ParsingDeclSpec*) + 2423; 16 rootcling_stage1 0x000000010d5f641c clang::Parser::ParseTopLevelDecl(clang::OpaquePtr<clang::DeclGroupRef>&) + 588; 17 rootcling_stage1 0x000000010cd68a90 cling::IncrementalParser::ParseInternal(llvm::StringRef) + 2704; 18 rootcling_stage1 0x000000010cd6ca91 cling::IncrementalParser::Compile(llvm::StringRef, cling::CompilationOptions const&) + 81; 19 rootcling_stage1 0x000000010cd94044 cling::Interpreter::DeclareInternal(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, cling::CompilationOptions const&, cling::Transaction**) const + 884; 20 rootcling_stage1 0x000000010cd9110e cling::In",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3586
https://github.com/root-project/root/pull/3586:2366,Security,Access,AccessSpecifier,2366,"peName(clang::IdentifierInfo*&, clang::SourceLocation, clang::Scope*, clang::CXXScopeSpec*, clang::OpaquePtr<clang::QualType>&, bool) + 985; 11 rootcling_stage1 0x000000010d57ef20 clang::Parser::ParseImplicitInt(clang::DeclSpec&, clang::CXXScopeSpec*, clang::Parser::ParsedTemplateInfo const&, clang::AccessSpecifier, clang::Parser::DeclSpecContext, clang::Parser::ParsedAttributesWithRange&) + 2288; 12 rootcling_stage1 0x000000010d579427 clang::Parser::ParseDeclarationSpecifiers(clang::DeclSpec&, clang::Parser::ParsedTemplateInfo const&, clang::AccessSpecifier, clang::Parser::DeclSpecContext, clang::Parser::LateParsedAttrList*) + 6855; 13 rootcling_stage1 0x000000010d5f8a6a clang::Parser::ParseDeclOrFunctionDefInternal(clang::Parser::ParsedAttributesWithRange&, clang::ParsingDeclSpec&, clang::AccessSpecifier) + 138; 14 rootcling_stage1 0x000000010d5f8725 clang::Parser::ParseDeclarationOrFunctionDefinition(clang::Parser::ParsedAttributesWithRange&, clang::ParsingDeclSpec*, clang::AccessSpecifier) + 373; 15 rootcling_stage1 0x000000010d5f7477 clang::Parser::ParseExternalDeclaration(clang::Parser::ParsedAttributesWithRange&, clang::ParsingDeclSpec*) + 2423; 16 rootcling_stage1 0x000000010d5f641c clang::Parser::ParseTopLevelDecl(clang::OpaquePtr<clang::DeclGroupRef>&) + 588; 17 rootcling_stage1 0x000000010cd68a90 cling::IncrementalParser::ParseInternal(llvm::StringRef) + 2704; 18 rootcling_stage1 0x000000010cd6ca91 cling::IncrementalParser::Compile(llvm::StringRef, cling::CompilationOptions const&) + 81; 19 rootcling_stage1 0x000000010cd94044 cling::Interpreter::DeclareInternal(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, cling::CompilationOptions const&, cling::Transaction**) const + 884; 20 rootcling_stage1 0x000000010cd9110e cling::Interpreter::declare(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, cling::Transaction**) + 110; 21 rootcling_stage1 0x000000010c964389 RootCling",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3586
https://github.com/root-project/root/pull/3587:123,Availability,error,errors,123,Duplicating Cling_Runtime and Cling_Runtime_Extra in both module.modulemap; and module.modulemap.build causes redefinition errors if -Dbuiltin_clang=Off.; We should not duplicate the cling runtime modules in both modulemaps.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3587
https://github.com/root-project/root/pull/3589:158,Availability,error,error,158,This reverts commit 3efc1356fcd48771c821314fab6c4427078480bd. `/mnt/build/night/LABEL/ROOT-ubuntu18.04/SPEC/rtcxxmod/root/tutorials/hist/ContourList.C:23:19: error: expected unqualified-id; const Double_t PI = TMath::Pi();; /usr/share/R/include/R_ext/Constants.h:36:24: note: expanded from macro 'PI'; #define PI M_PI; /usr/include/math.h:777:16: note: expanded from macro M_PI; CMake Error at /mnt/build/night/LABEL/ROOT-ubuntu18.04/SPEC/rtcxxmod/root/cmake/modules/RootTestDriver.cmake:230 (message):; error code: 1`,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3589
https://github.com/root-project/root/pull/3589:385,Availability,Error,Error,385,This reverts commit 3efc1356fcd48771c821314fab6c4427078480bd. `/mnt/build/night/LABEL/ROOT-ubuntu18.04/SPEC/rtcxxmod/root/tutorials/hist/ContourList.C:23:19: error: expected unqualified-id; const Double_t PI = TMath::Pi();; /usr/share/R/include/R_ext/Constants.h:36:24: note: expanded from macro 'PI'; #define PI M_PI; /usr/include/math.h:777:16: note: expanded from macro M_PI; CMake Error at /mnt/build/night/LABEL/ROOT-ubuntu18.04/SPEC/rtcxxmod/root/cmake/modules/RootTestDriver.cmake:230 (message):; error code: 1`,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3589
https://github.com/root-project/root/pull/3589:504,Availability,error,error,504,This reverts commit 3efc1356fcd48771c821314fab6c4427078480bd. `/mnt/build/night/LABEL/ROOT-ubuntu18.04/SPEC/rtcxxmod/root/tutorials/hist/ContourList.C:23:19: error: expected unqualified-id; const Double_t PI = TMath::Pi();; /usr/share/R/include/R_ext/Constants.h:36:24: note: expanded from macro 'PI'; #define PI M_PI; /usr/include/math.h:777:16: note: expanded from macro M_PI; CMake Error at /mnt/build/night/LABEL/ROOT-ubuntu18.04/SPEC/rtcxxmod/root/cmake/modules/RootTestDriver.cmake:230 (message):; error code: 1`,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3589
https://github.com/root-project/root/pull/3589:493,Integrability,message,message,493,This reverts commit 3efc1356fcd48771c821314fab6c4427078480bd. `/mnt/build/night/LABEL/ROOT-ubuntu18.04/SPEC/rtcxxmod/root/tutorials/hist/ContourList.C:23:19: error: expected unqualified-id; const Double_t PI = TMath::Pi();; /usr/share/R/include/R_ext/Constants.h:36:24: note: expanded from macro 'PI'; #define PI M_PI; /usr/include/math.h:777:16: note: expanded from macro M_PI; CMake Error at /mnt/build/night/LABEL/ROOT-ubuntu18.04/SPEC/rtcxxmod/root/cmake/modules/RootTestDriver.cmake:230 (message):; error code: 1`,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3589
https://github.com/root-project/root/pull/3591:269,Integrability,depend,depend,269,"This pull request is a attempt to fix the problem described here:; https://root-forum.cern.ch/t/graphical-and-variable-cuts-in-ttree-draw/32862. When a selection including a graphical cut and and other cut is done on a tree having array variables, the selected entries depend in the order in which the graphical and the normal cut are done. The simplest macro showing the problem (using the root file attached to the forum) is:. ```; {; auto file = new TFile(""ptmac.root"");; auto C = new TCanvas();; C->Divide(2,1);. TCutG *gcut = new TCutG(""CUTG"",5);; gcut->SetVarX(""z"");; gcut->SetVarY(""theta"");; gcut->SetPoint(0,-30,2);; gcut->SetPoint(1,-10,5);; gcut->SetPoint(2,-5,40);; gcut->SetPoint(3,-50,25);; gcut->SetPoint(4,-30,2);. C->cd(1); tree->Draw(""z"",""z>-20 && CUTG"","""",10000);; C->cd(2); tree->Draw(""z"",""CUTG && z>-20"","""",10000);; }; ```. without this fix the two plots are different whereas they should be the same. . Not being an expert in that part of the ROOT code, I am not completely sure this fix is the best.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3591
https://github.com/root-project/root/pull/3591:110,Modifiability,variab,variable-cuts-in-ttree-draw,110,"This pull request is a attempt to fix the problem described here:; https://root-forum.cern.ch/t/graphical-and-variable-cuts-in-ttree-draw/32862. When a selection including a graphical cut and and other cut is done on a tree having array variables, the selected entries depend in the order in which the graphical and the normal cut are done. The simplest macro showing the problem (using the root file attached to the forum) is:. ```; {; auto file = new TFile(""ptmac.root"");; auto C = new TCanvas();; C->Divide(2,1);. TCutG *gcut = new TCutG(""CUTG"",5);; gcut->SetVarX(""z"");; gcut->SetVarY(""theta"");; gcut->SetPoint(0,-30,2);; gcut->SetPoint(1,-10,5);; gcut->SetPoint(2,-5,40);; gcut->SetPoint(3,-50,25);; gcut->SetPoint(4,-30,2);. C->cd(1); tree->Draw(""z"",""z>-20 && CUTG"","""",10000);; C->cd(2); tree->Draw(""z"",""CUTG && z>-20"","""",10000);; }; ```. without this fix the two plots are different whereas they should be the same. . Not being an expert in that part of the ROOT code, I am not completely sure this fix is the best.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3591
https://github.com/root-project/root/pull/3591:237,Modifiability,variab,variables,237,"This pull request is a attempt to fix the problem described here:; https://root-forum.cern.ch/t/graphical-and-variable-cuts-in-ttree-draw/32862. When a selection including a graphical cut and and other cut is done on a tree having array variables, the selected entries depend in the order in which the graphical and the normal cut are done. The simplest macro showing the problem (using the root file attached to the forum) is:. ```; {; auto file = new TFile(""ptmac.root"");; auto C = new TCanvas();; C->Divide(2,1);. TCutG *gcut = new TCutG(""CUTG"",5);; gcut->SetVarX(""z"");; gcut->SetVarY(""theta"");; gcut->SetPoint(0,-30,2);; gcut->SetPoint(1,-10,5);; gcut->SetPoint(2,-5,40);; gcut->SetPoint(3,-50,25);; gcut->SetPoint(4,-30,2);. C->cd(1); tree->Draw(""z"",""z>-20 && CUTG"","""",10000);; C->cd(2); tree->Draw(""z"",""CUTG && z>-20"","""",10000);; }; ```. without this fix the two plots are different whereas they should be the same. . Not being an expert in that part of the ROOT code, I am not completely sure this fix is the best.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3591
https://github.com/root-project/root/pull/3591:345,Usability,simpl,simplest,345,"This pull request is a attempt to fix the problem described here:; https://root-forum.cern.ch/t/graphical-and-variable-cuts-in-ttree-draw/32862. When a selection including a graphical cut and and other cut is done on a tree having array variables, the selected entries depend in the order in which the graphical and the normal cut are done. The simplest macro showing the problem (using the root file attached to the forum) is:. ```; {; auto file = new TFile(""ptmac.root"");; auto C = new TCanvas();; C->Divide(2,1);. TCutG *gcut = new TCutG(""CUTG"",5);; gcut->SetVarX(""z"");; gcut->SetVarY(""theta"");; gcut->SetPoint(0,-30,2);; gcut->SetPoint(1,-10,5);; gcut->SetPoint(2,-5,40);; gcut->SetPoint(3,-50,25);; gcut->SetPoint(4,-30,2);. C->cd(1); tree->Draw(""z"",""z>-20 && CUTG"","""",10000);; C->cd(2); tree->Draw(""z"",""CUTG && z>-20"","""",10000);; }; ```. without this fix the two plots are different whereas they should be the same. . Not being an expert in that part of the ROOT code, I am not completely sure this fix is the best.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3591
https://github.com/root-project/root/pull/3593:184,Deployability,patch,patch,184,The getNameAsString interface causes a lot of temporary allocations.; The analysis if a decl is a cling-style wrapper can work only on a; simple declarations on the global scope. This patch filters out complex declarations (eg in namespaces) and; checks only the identifier content. The patch reduces the memory footprint difference shown in root-project/root#3012.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3593
https://github.com/root-project/root/pull/3593:287,Deployability,patch,patch,287,The getNameAsString interface causes a lot of temporary allocations.; The analysis if a decl is a cling-style wrapper can work only on a; simple declarations on the global scope. This patch filters out complex declarations (eg in namespaces) and; checks only the identifier content. The patch reduces the memory footprint difference shown in root-project/root#3012.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3593
https://github.com/root-project/root/pull/3593:293,Energy Efficiency,reduce,reduces,293,The getNameAsString interface causes a lot of temporary allocations.; The analysis if a decl is a cling-style wrapper can work only on a; simple declarations on the global scope. This patch filters out complex declarations (eg in namespaces) and; checks only the identifier content. The patch reduces the memory footprint difference shown in root-project/root#3012.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3593
https://github.com/root-project/root/pull/3593:20,Integrability,interface,interface,20,The getNameAsString interface causes a lot of temporary allocations.; The analysis if a decl is a cling-style wrapper can work only on a; simple declarations on the global scope. This patch filters out complex declarations (eg in namespaces) and; checks only the identifier content. The patch reduces the memory footprint difference shown in root-project/root#3012.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3593
https://github.com/root-project/root/pull/3593:110,Integrability,wrap,wrapper,110,The getNameAsString interface causes a lot of temporary allocations.; The analysis if a decl is a cling-style wrapper can work only on a; simple declarations on the global scope. This patch filters out complex declarations (eg in namespaces) and; checks only the identifier content. The patch reduces the memory footprint difference shown in root-project/root#3012.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3593
https://github.com/root-project/root/pull/3593:138,Usability,simpl,simple,138,The getNameAsString interface causes a lot of temporary allocations.; The analysis if a decl is a cling-style wrapper can work only on a; simple declarations on the global scope. This patch filters out complex declarations (eg in namespaces) and; checks only the identifier content. The patch reduces the memory footprint difference shown in root-project/root#3012.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3593
https://github.com/root-project/root/pull/3594:37,Availability,error,error-prone,37,"...wherever it's more readable, less error-prone than the alternatives.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3594
https://github.com/root-project/root/pull/3595:695,Availability,error,error,695,"While testing my packages which use PyROOT, I stumbled across a little problem with ROOT and pytest which I propose to fix. Assume you have this very minimal (basically empty) python package:; ```; .; ├── setup.py; └── tests; └── test_test.py. 1 directory, 2 files; ```; Content of `setup.py`:; ```python; from setuptools import setup, find_packages. setup(; name=""root_cleanup_test"",; packages=find_packages(),; setup_requires=[""pytest-runner""],; test_suite=""tests"",; ); ```; Content of `test_test.py`; ```; import unittest; import ROOT. class TestTest(unittest.TestCase):; def test_test(self):; pass; ```. Now if you run the tests with `python setup.py pytest` which gives you the warning and error I attach to the bottom of this post. I think this is maybe related to some multithreading in the pytest runner. When you run the test alone with `pytest tests/test_test.py`, you won't get the error. My setup: ROOT 6.16/00 and Python 3.7. Let me know if I can do anything else to test this! It would be great if pytest works smoothly with ROOT. ````; ========== warnings summary ==========; /usr/lib/python3.7/site-packages/ROOT.py:98: DeprecationWarning: invalid escape sequence \S; message='class \S* already in TClassTable$' ). -- Docs: https://docs.pytest.org/en/latest/warnings.html; ========== 1 passed, 1 warnings in 0.41 seconds ==========; Error in atexit._run_exitfuncs:; Traceback (most recent call last):; File ""/usr/lib/python3.7/site-packages/ROOT.py"", line 782, in cleanup; facade = sys.modules[ __name__ ]; KeyError: ""ROOT""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3595
https://github.com/root-project/root/pull/3595:893,Availability,error,error,893,"While testing my packages which use PyROOT, I stumbled across a little problem with ROOT and pytest which I propose to fix. Assume you have this very minimal (basically empty) python package:; ```; .; ├── setup.py; └── tests; └── test_test.py. 1 directory, 2 files; ```; Content of `setup.py`:; ```python; from setuptools import setup, find_packages. setup(; name=""root_cleanup_test"",; packages=find_packages(),; setup_requires=[""pytest-runner""],; test_suite=""tests"",; ); ```; Content of `test_test.py`; ```; import unittest; import ROOT. class TestTest(unittest.TestCase):; def test_test(self):; pass; ```. Now if you run the tests with `python setup.py pytest` which gives you the warning and error I attach to the bottom of this post. I think this is maybe related to some multithreading in the pytest runner. When you run the test alone with `pytest tests/test_test.py`, you won't get the error. My setup: ROOT 6.16/00 and Python 3.7. Let me know if I can do anything else to test this! It would be great if pytest works smoothly with ROOT. ````; ========== warnings summary ==========; /usr/lib/python3.7/site-packages/ROOT.py:98: DeprecationWarning: invalid escape sequence \S; message='class \S* already in TClassTable$' ). -- Docs: https://docs.pytest.org/en/latest/warnings.html; ========== 1 passed, 1 warnings in 0.41 seconds ==========; Error in atexit._run_exitfuncs:; Traceback (most recent call last):; File ""/usr/lib/python3.7/site-packages/ROOT.py"", line 782, in cleanup; facade = sys.modules[ __name__ ]; KeyError: ""ROOT""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3595
https://github.com/root-project/root/pull/3595:1349,Availability,Error,Error,1349,"While testing my packages which use PyROOT, I stumbled across a little problem with ROOT and pytest which I propose to fix. Assume you have this very minimal (basically empty) python package:; ```; .; ├── setup.py; └── tests; └── test_test.py. 1 directory, 2 files; ```; Content of `setup.py`:; ```python; from setuptools import setup, find_packages. setup(; name=""root_cleanup_test"",; packages=find_packages(),; setup_requires=[""pytest-runner""],; test_suite=""tests"",; ); ```; Content of `test_test.py`; ```; import unittest; import ROOT. class TestTest(unittest.TestCase):; def test_test(self):; pass; ```. Now if you run the tests with `python setup.py pytest` which gives you the warning and error I attach to the bottom of this post. I think this is maybe related to some multithreading in the pytest runner. When you run the test alone with `pytest tests/test_test.py`, you won't get the error. My setup: ROOT 6.16/00 and Python 3.7. Let me know if I can do anything else to test this! It would be great if pytest works smoothly with ROOT. ````; ========== warnings summary ==========; /usr/lib/python3.7/site-packages/ROOT.py:98: DeprecationWarning: invalid escape sequence \S; message='class \S* already in TClassTable$' ). -- Docs: https://docs.pytest.org/en/latest/warnings.html; ========== 1 passed, 1 warnings in 0.41 seconds ==========; Error in atexit._run_exitfuncs:; Traceback (most recent call last):; File ""/usr/lib/python3.7/site-packages/ROOT.py"", line 782, in cleanup; facade = sys.modules[ __name__ ]; KeyError: ""ROOT""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3595
https://github.com/root-project/root/pull/3595:1184,Integrability,message,message,1184,"While testing my packages which use PyROOT, I stumbled across a little problem with ROOT and pytest which I propose to fix. Assume you have this very minimal (basically empty) python package:; ```; .; ├── setup.py; └── tests; └── test_test.py. 1 directory, 2 files; ```; Content of `setup.py`:; ```python; from setuptools import setup, find_packages. setup(; name=""root_cleanup_test"",; packages=find_packages(),; setup_requires=[""pytest-runner""],; test_suite=""tests"",; ); ```; Content of `test_test.py`; ```; import unittest; import ROOT. class TestTest(unittest.TestCase):; def test_test(self):; pass; ```. Now if you run the tests with `python setup.py pytest` which gives you the warning and error I attach to the bottom of this post. I think this is maybe related to some multithreading in the pytest runner. When you run the test alone with `pytest tests/test_test.py`, you won't get the error. My setup: ROOT 6.16/00 and Python 3.7. Let me know if I can do anything else to test this! It would be great if pytest works smoothly with ROOT. ````; ========== warnings summary ==========; /usr/lib/python3.7/site-packages/ROOT.py:98: DeprecationWarning: invalid escape sequence \S; message='class \S* already in TClassTable$' ). -- Docs: https://docs.pytest.org/en/latest/warnings.html; ========== 1 passed, 1 warnings in 0.41 seconds ==========; Error in atexit._run_exitfuncs:; Traceback (most recent call last):; File ""/usr/lib/python3.7/site-packages/ROOT.py"", line 782, in cleanup; facade = sys.modules[ __name__ ]; KeyError: ""ROOT""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3595
https://github.com/root-project/root/pull/3595:6,Testability,test,testing,6,"While testing my packages which use PyROOT, I stumbled across a little problem with ROOT and pytest which I propose to fix. Assume you have this very minimal (basically empty) python package:; ```; .; ├── setup.py; └── tests; └── test_test.py. 1 directory, 2 files; ```; Content of `setup.py`:; ```python; from setuptools import setup, find_packages. setup(; name=""root_cleanup_test"",; packages=find_packages(),; setup_requires=[""pytest-runner""],; test_suite=""tests"",; ); ```; Content of `test_test.py`; ```; import unittest; import ROOT. class TestTest(unittest.TestCase):; def test_test(self):; pass; ```. Now if you run the tests with `python setup.py pytest` which gives you the warning and error I attach to the bottom of this post. I think this is maybe related to some multithreading in the pytest runner. When you run the test alone with `pytest tests/test_test.py`, you won't get the error. My setup: ROOT 6.16/00 and Python 3.7. Let me know if I can do anything else to test this! It would be great if pytest works smoothly with ROOT. ````; ========== warnings summary ==========; /usr/lib/python3.7/site-packages/ROOT.py:98: DeprecationWarning: invalid escape sequence \S; message='class \S* already in TClassTable$' ). -- Docs: https://docs.pytest.org/en/latest/warnings.html; ========== 1 passed, 1 warnings in 0.41 seconds ==========; Error in atexit._run_exitfuncs:; Traceback (most recent call last):; File ""/usr/lib/python3.7/site-packages/ROOT.py"", line 782, in cleanup; facade = sys.modules[ __name__ ]; KeyError: ""ROOT""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3595
https://github.com/root-project/root/pull/3595:219,Testability,test,tests,219,"While testing my packages which use PyROOT, I stumbled across a little problem with ROOT and pytest which I propose to fix. Assume you have this very minimal (basically empty) python package:; ```; .; ├── setup.py; └── tests; └── test_test.py. 1 directory, 2 files; ```; Content of `setup.py`:; ```python; from setuptools import setup, find_packages. setup(; name=""root_cleanup_test"",; packages=find_packages(),; setup_requires=[""pytest-runner""],; test_suite=""tests"",; ); ```; Content of `test_test.py`; ```; import unittest; import ROOT. class TestTest(unittest.TestCase):; def test_test(self):; pass; ```. Now if you run the tests with `python setup.py pytest` which gives you the warning and error I attach to the bottom of this post. I think this is maybe related to some multithreading in the pytest runner. When you run the test alone with `pytest tests/test_test.py`, you won't get the error. My setup: ROOT 6.16/00 and Python 3.7. Let me know if I can do anything else to test this! It would be great if pytest works smoothly with ROOT. ````; ========== warnings summary ==========; /usr/lib/python3.7/site-packages/ROOT.py:98: DeprecationWarning: invalid escape sequence \S; message='class \S* already in TClassTable$' ). -- Docs: https://docs.pytest.org/en/latest/warnings.html; ========== 1 passed, 1 warnings in 0.41 seconds ==========; Error in atexit._run_exitfuncs:; Traceback (most recent call last):; File ""/usr/lib/python3.7/site-packages/ROOT.py"", line 782, in cleanup; facade = sys.modules[ __name__ ]; KeyError: ""ROOT""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3595
https://github.com/root-project/root/pull/3595:460,Testability,test,tests,460,"While testing my packages which use PyROOT, I stumbled across a little problem with ROOT and pytest which I propose to fix. Assume you have this very minimal (basically empty) python package:; ```; .; ├── setup.py; └── tests; └── test_test.py. 1 directory, 2 files; ```; Content of `setup.py`:; ```python; from setuptools import setup, find_packages. setup(; name=""root_cleanup_test"",; packages=find_packages(),; setup_requires=[""pytest-runner""],; test_suite=""tests"",; ); ```; Content of `test_test.py`; ```; import unittest; import ROOT. class TestTest(unittest.TestCase):; def test_test(self):; pass; ```. Now if you run the tests with `python setup.py pytest` which gives you the warning and error I attach to the bottom of this post. I think this is maybe related to some multithreading in the pytest runner. When you run the test alone with `pytest tests/test_test.py`, you won't get the error. My setup: ROOT 6.16/00 and Python 3.7. Let me know if I can do anything else to test this! It would be great if pytest works smoothly with ROOT. ````; ========== warnings summary ==========; /usr/lib/python3.7/site-packages/ROOT.py:98: DeprecationWarning: invalid escape sequence \S; message='class \S* already in TClassTable$' ). -- Docs: https://docs.pytest.org/en/latest/warnings.html; ========== 1 passed, 1 warnings in 0.41 seconds ==========; Error in atexit._run_exitfuncs:; Traceback (most recent call last):; File ""/usr/lib/python3.7/site-packages/ROOT.py"", line 782, in cleanup; facade = sys.modules[ __name__ ]; KeyError: ""ROOT""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3595
https://github.com/root-project/root/pull/3595:545,Testability,Test,TestTest,545,"While testing my packages which use PyROOT, I stumbled across a little problem with ROOT and pytest which I propose to fix. Assume you have this very minimal (basically empty) python package:; ```; .; ├── setup.py; └── tests; └── test_test.py. 1 directory, 2 files; ```; Content of `setup.py`:; ```python; from setuptools import setup, find_packages. setup(; name=""root_cleanup_test"",; packages=find_packages(),; setup_requires=[""pytest-runner""],; test_suite=""tests"",; ); ```; Content of `test_test.py`; ```; import unittest; import ROOT. class TestTest(unittest.TestCase):; def test_test(self):; pass; ```. Now if you run the tests with `python setup.py pytest` which gives you the warning and error I attach to the bottom of this post. I think this is maybe related to some multithreading in the pytest runner. When you run the test alone with `pytest tests/test_test.py`, you won't get the error. My setup: ROOT 6.16/00 and Python 3.7. Let me know if I can do anything else to test this! It would be great if pytest works smoothly with ROOT. ````; ========== warnings summary ==========; /usr/lib/python3.7/site-packages/ROOT.py:98: DeprecationWarning: invalid escape sequence \S; message='class \S* already in TClassTable$' ). -- Docs: https://docs.pytest.org/en/latest/warnings.html; ========== 1 passed, 1 warnings in 0.41 seconds ==========; Error in atexit._run_exitfuncs:; Traceback (most recent call last):; File ""/usr/lib/python3.7/site-packages/ROOT.py"", line 782, in cleanup; facade = sys.modules[ __name__ ]; KeyError: ""ROOT""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3595
https://github.com/root-project/root/pull/3595:563,Testability,Test,TestCase,563,"While testing my packages which use PyROOT, I stumbled across a little problem with ROOT and pytest which I propose to fix. Assume you have this very minimal (basically empty) python package:; ```; .; ├── setup.py; └── tests; └── test_test.py. 1 directory, 2 files; ```; Content of `setup.py`:; ```python; from setuptools import setup, find_packages. setup(; name=""root_cleanup_test"",; packages=find_packages(),; setup_requires=[""pytest-runner""],; test_suite=""tests"",; ); ```; Content of `test_test.py`; ```; import unittest; import ROOT. class TestTest(unittest.TestCase):; def test_test(self):; pass; ```. Now if you run the tests with `python setup.py pytest` which gives you the warning and error I attach to the bottom of this post. I think this is maybe related to some multithreading in the pytest runner. When you run the test alone with `pytest tests/test_test.py`, you won't get the error. My setup: ROOT 6.16/00 and Python 3.7. Let me know if I can do anything else to test this! It would be great if pytest works smoothly with ROOT. ````; ========== warnings summary ==========; /usr/lib/python3.7/site-packages/ROOT.py:98: DeprecationWarning: invalid escape sequence \S; message='class \S* already in TClassTable$' ). -- Docs: https://docs.pytest.org/en/latest/warnings.html; ========== 1 passed, 1 warnings in 0.41 seconds ==========; Error in atexit._run_exitfuncs:; Traceback (most recent call last):; File ""/usr/lib/python3.7/site-packages/ROOT.py"", line 782, in cleanup; facade = sys.modules[ __name__ ]; KeyError: ""ROOT""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3595
https://github.com/root-project/root/pull/3595:627,Testability,test,tests,627,"While testing my packages which use PyROOT, I stumbled across a little problem with ROOT and pytest which I propose to fix. Assume you have this very minimal (basically empty) python package:; ```; .; ├── setup.py; └── tests; └── test_test.py. 1 directory, 2 files; ```; Content of `setup.py`:; ```python; from setuptools import setup, find_packages. setup(; name=""root_cleanup_test"",; packages=find_packages(),; setup_requires=[""pytest-runner""],; test_suite=""tests"",; ); ```; Content of `test_test.py`; ```; import unittest; import ROOT. class TestTest(unittest.TestCase):; def test_test(self):; pass; ```. Now if you run the tests with `python setup.py pytest` which gives you the warning and error I attach to the bottom of this post. I think this is maybe related to some multithreading in the pytest runner. When you run the test alone with `pytest tests/test_test.py`, you won't get the error. My setup: ROOT 6.16/00 and Python 3.7. Let me know if I can do anything else to test this! It would be great if pytest works smoothly with ROOT. ````; ========== warnings summary ==========; /usr/lib/python3.7/site-packages/ROOT.py:98: DeprecationWarning: invalid escape sequence \S; message='class \S* already in TClassTable$' ). -- Docs: https://docs.pytest.org/en/latest/warnings.html; ========== 1 passed, 1 warnings in 0.41 seconds ==========; Error in atexit._run_exitfuncs:; Traceback (most recent call last):; File ""/usr/lib/python3.7/site-packages/ROOT.py"", line 782, in cleanup; facade = sys.modules[ __name__ ]; KeyError: ""ROOT""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3595
https://github.com/root-project/root/pull/3595:830,Testability,test,test,830,"While testing my packages which use PyROOT, I stumbled across a little problem with ROOT and pytest which I propose to fix. Assume you have this very minimal (basically empty) python package:; ```; .; ├── setup.py; └── tests; └── test_test.py. 1 directory, 2 files; ```; Content of `setup.py`:; ```python; from setuptools import setup, find_packages. setup(; name=""root_cleanup_test"",; packages=find_packages(),; setup_requires=[""pytest-runner""],; test_suite=""tests"",; ); ```; Content of `test_test.py`; ```; import unittest; import ROOT. class TestTest(unittest.TestCase):; def test_test(self):; pass; ```. Now if you run the tests with `python setup.py pytest` which gives you the warning and error I attach to the bottom of this post. I think this is maybe related to some multithreading in the pytest runner. When you run the test alone with `pytest tests/test_test.py`, you won't get the error. My setup: ROOT 6.16/00 and Python 3.7. Let me know if I can do anything else to test this! It would be great if pytest works smoothly with ROOT. ````; ========== warnings summary ==========; /usr/lib/python3.7/site-packages/ROOT.py:98: DeprecationWarning: invalid escape sequence \S; message='class \S* already in TClassTable$' ). -- Docs: https://docs.pytest.org/en/latest/warnings.html; ========== 1 passed, 1 warnings in 0.41 seconds ==========; Error in atexit._run_exitfuncs:; Traceback (most recent call last):; File ""/usr/lib/python3.7/site-packages/ROOT.py"", line 782, in cleanup; facade = sys.modules[ __name__ ]; KeyError: ""ROOT""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3595
https://github.com/root-project/root/pull/3595:854,Testability,test,tests,854,"While testing my packages which use PyROOT, I stumbled across a little problem with ROOT and pytest which I propose to fix. Assume you have this very minimal (basically empty) python package:; ```; .; ├── setup.py; └── tests; └── test_test.py. 1 directory, 2 files; ```; Content of `setup.py`:; ```python; from setuptools import setup, find_packages. setup(; name=""root_cleanup_test"",; packages=find_packages(),; setup_requires=[""pytest-runner""],; test_suite=""tests"",; ); ```; Content of `test_test.py`; ```; import unittest; import ROOT. class TestTest(unittest.TestCase):; def test_test(self):; pass; ```. Now if you run the tests with `python setup.py pytest` which gives you the warning and error I attach to the bottom of this post. I think this is maybe related to some multithreading in the pytest runner. When you run the test alone with `pytest tests/test_test.py`, you won't get the error. My setup: ROOT 6.16/00 and Python 3.7. Let me know if I can do anything else to test this! It would be great if pytest works smoothly with ROOT. ````; ========== warnings summary ==========; /usr/lib/python3.7/site-packages/ROOT.py:98: DeprecationWarning: invalid escape sequence \S; message='class \S* already in TClassTable$' ). -- Docs: https://docs.pytest.org/en/latest/warnings.html; ========== 1 passed, 1 warnings in 0.41 seconds ==========; Error in atexit._run_exitfuncs:; Traceback (most recent call last):; File ""/usr/lib/python3.7/site-packages/ROOT.py"", line 782, in cleanup; facade = sys.modules[ __name__ ]; KeyError: ""ROOT""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3595
https://github.com/root-project/root/pull/3595:980,Testability,test,test,980,"While testing my packages which use PyROOT, I stumbled across a little problem with ROOT and pytest which I propose to fix. Assume you have this very minimal (basically empty) python package:; ```; .; ├── setup.py; └── tests; └── test_test.py. 1 directory, 2 files; ```; Content of `setup.py`:; ```python; from setuptools import setup, find_packages. setup(; name=""root_cleanup_test"",; packages=find_packages(),; setup_requires=[""pytest-runner""],; test_suite=""tests"",; ); ```; Content of `test_test.py`; ```; import unittest; import ROOT. class TestTest(unittest.TestCase):; def test_test(self):; pass; ```. Now if you run the tests with `python setup.py pytest` which gives you the warning and error I attach to the bottom of this post. I think this is maybe related to some multithreading in the pytest runner. When you run the test alone with `pytest tests/test_test.py`, you won't get the error. My setup: ROOT 6.16/00 and Python 3.7. Let me know if I can do anything else to test this! It would be great if pytest works smoothly with ROOT. ````; ========== warnings summary ==========; /usr/lib/python3.7/site-packages/ROOT.py:98: DeprecationWarning: invalid escape sequence \S; message='class \S* already in TClassTable$' ). -- Docs: https://docs.pytest.org/en/latest/warnings.html; ========== 1 passed, 1 warnings in 0.41 seconds ==========; Error in atexit._run_exitfuncs:; Traceback (most recent call last):; File ""/usr/lib/python3.7/site-packages/ROOT.py"", line 782, in cleanup; facade = sys.modules[ __name__ ]; KeyError: ""ROOT""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3595
https://github.com/root-project/root/pull/3596:164,Deployability,Release,Release,164,this commit suggests to prefer the usage of ROOT::Math::TLorentzVector; specialisations instead of the TLorentzVector class given the; advantages of the former.; - Release notes are changes; - The documentation of TLorentzVector updated to point to the specialisations of ROOT::Math::TLorentzVector; - The RDF tutorials using TLorentzVector upgraded,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3596
https://github.com/root-project/root/pull/3596:229,Deployability,update,updated,229,this commit suggests to prefer the usage of ROOT::Math::TLorentzVector; specialisations instead of the TLorentzVector class given the; advantages of the former.; - Release notes are changes; - The documentation of TLorentzVector updated to point to the specialisations of ROOT::Math::TLorentzVector; - The RDF tutorials using TLorentzVector upgraded,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3596
https://github.com/root-project/root/pull/3596:341,Deployability,upgrade,upgraded,341,this commit suggests to prefer the usage of ROOT::Math::TLorentzVector; specialisations instead of the TLorentzVector class given the; advantages of the former.; - Release notes are changes; - The documentation of TLorentzVector updated to point to the specialisations of ROOT::Math::TLorentzVector; - The RDF tutorials using TLorentzVector upgraded,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3596
https://github.com/root-project/root/pull/3599:319,Availability,error,error,319,"This reverts commit 3854aa142b82202d36d066ad9ce80f57a00f8276.; It fixes:; ""While building module 'Cling_Interpreter' imported from /.../root/core/metacling/src/TClingCallbacks.h:12:; In file included from <module-includes>:11:. /.../root/interpreter/cling/include/cling/Interpreter/DynamicLookupRuntimeUniverse.h:13:2: error: ""This file must not be included by compiled programs."". ^; While building module 'Cling_Interpreter' imported from /.../root/core/metacling/src/TClingCallbacks.h:12:; In file included from <module-includes>:17:""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3599
https://github.com/root-project/root/pull/3600:370,Availability,error,error,370,"From V.Vasilev, it fixes:; [ 72%] Building CXX object interpreter/llvm/src/tools/clang/lib/CodeGen/CMakeFiles/clangCodeGen.dir/CodeGenModule.cpp.o; While building module 'Cling_Interpreter' imported from /.../root/core/clingutils/src/RStl.cxx:25:; In file included from <module-includes>:5:; /.../root/interpreter/cling/include/cling/Interpreter/RuntimeUniverse.h:13:2: error: ""This file must not be included by compiled programs.""; #error ""This file must not be included by compiled programs.""; ^",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3600
https://github.com/root-project/root/pull/3600:434,Availability,error,error,434,"From V.Vasilev, it fixes:; [ 72%] Building CXX object interpreter/llvm/src/tools/clang/lib/CodeGen/CMakeFiles/clangCodeGen.dir/CodeGenModule.cpp.o; While building module 'Cling_Interpreter' imported from /.../root/core/clingutils/src/RStl.cxx:25:; In file included from <module-includes>:5:; /.../root/interpreter/cling/include/cling/Interpreter/RuntimeUniverse.h:13:2: error: ""This file must not be included by compiled programs.""; #error ""This file must not be included by compiled programs.""; ^",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3600
https://github.com/root-project/root/pull/3602:22,Energy Efficiency,green,green,22,~~This PR should turn green when [ROOT-9790](https://sft.its.cern.ch/jira/browse/ROOT-9790) is resolved.~~ A temporary workaround for greedy jitting of `Cache` and `Snapshot` has been added.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3602
https://github.com/root-project/root/pull/3602:153,Performance,Cache,Cache,153,~~This PR should turn green when [ROOT-9790](https://sft.its.cern.ch/jira/browse/ROOT-9790) is resolved.~~ A temporary workaround for greedy jitting of `Cache` and `Snapshot` has been added.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3602
https://github.com/root-project/root/pull/3603:191,Safety,unsafe,unsafe,191,"`GetEntriesFast` is not as fast as it could be: it constructs and; destructs a `TReadLockGuard`, and might need to modify `TObjArray::fLast`.; This PR introduced `GetEntriesUnsafe`, a thread-unsafe version of `GetEntriesFast`; that side-steps these operations when possible. Measurements for the benchmarks in the `philippe` branch of the [df_bench](https://gitlab.com/bluehood/df_bench) repository:. With `GetEntriesFast`:; ```; -----------------------------------------------------------------------------------; Benchmark Time CPU Iterations; -----------------------------------------------------------------------------------; TreeGetEntryOneBranch 192943 ns 192939 ns 3664; TreeGetEntryTwoBranchesAndAllStatusFalse 110524 ns 110521 ns 6433; TreeGetEntryTwoBranches 195864 ns 195859 ns 3430; TreeGetEntryTwoBranchesWithoutSetStatus 317772 ns 317761 ns 2095; BranchGetEntryOneBranch 103652 ns 103650 ns 6730; BranchGetEntryTwoBranches 104072 ns 104070 ns 6707; ```. With `GetEntriesUnsafe`:; ```; -----------------------------------------------------------------------------------; Benchmark Time CPU Iterations; -----------------------------------------------------------------------------------; TreeGetEntryOneBranch 152708 ns 152690 ns 4579; TreeGetEntryTwoBranchesAndAllStatusFalse 91277 ns 91274 ns 7731; TreeGetEntryTwoBranches 173940 ns 173922 ns 4024; TreeGetEntryTwoBranchesWithoutSetStatus 279271 ns 279261 ns 2514; BranchGetEntryOneBranch 104515 ns 104503 ns 6721; BranchGetEntryTwoBranches 104180 ns 104177 ns 6652; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3603
https://github.com/root-project/root/pull/3603:296,Testability,benchmark,benchmarks,296,"`GetEntriesFast` is not as fast as it could be: it constructs and; destructs a `TReadLockGuard`, and might need to modify `TObjArray::fLast`.; This PR introduced `GetEntriesUnsafe`, a thread-unsafe version of `GetEntriesFast`; that side-steps these operations when possible. Measurements for the benchmarks in the `philippe` branch of the [df_bench](https://gitlab.com/bluehood/df_bench) repository:. With `GetEntriesFast`:; ```; -----------------------------------------------------------------------------------; Benchmark Time CPU Iterations; -----------------------------------------------------------------------------------; TreeGetEntryOneBranch 192943 ns 192939 ns 3664; TreeGetEntryTwoBranchesAndAllStatusFalse 110524 ns 110521 ns 6433; TreeGetEntryTwoBranches 195864 ns 195859 ns 3430; TreeGetEntryTwoBranchesWithoutSetStatus 317772 ns 317761 ns 2095; BranchGetEntryOneBranch 103652 ns 103650 ns 6730; BranchGetEntryTwoBranches 104072 ns 104070 ns 6707; ```. With `GetEntriesUnsafe`:; ```; -----------------------------------------------------------------------------------; Benchmark Time CPU Iterations; -----------------------------------------------------------------------------------; TreeGetEntryOneBranch 152708 ns 152690 ns 4579; TreeGetEntryTwoBranchesAndAllStatusFalse 91277 ns 91274 ns 7731; TreeGetEntryTwoBranches 173940 ns 173922 ns 4024; TreeGetEntryTwoBranchesWithoutSetStatus 279271 ns 279261 ns 2514; BranchGetEntryOneBranch 104515 ns 104503 ns 6721; BranchGetEntryTwoBranches 104180 ns 104177 ns 6652; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3603
https://github.com/root-project/root/pull/3603:515,Testability,Benchmark,Benchmark,515,"`GetEntriesFast` is not as fast as it could be: it constructs and; destructs a `TReadLockGuard`, and might need to modify `TObjArray::fLast`.; This PR introduced `GetEntriesUnsafe`, a thread-unsafe version of `GetEntriesFast`; that side-steps these operations when possible. Measurements for the benchmarks in the `philippe` branch of the [df_bench](https://gitlab.com/bluehood/df_bench) repository:. With `GetEntriesFast`:; ```; -----------------------------------------------------------------------------------; Benchmark Time CPU Iterations; -----------------------------------------------------------------------------------; TreeGetEntryOneBranch 192943 ns 192939 ns 3664; TreeGetEntryTwoBranchesAndAllStatusFalse 110524 ns 110521 ns 6433; TreeGetEntryTwoBranches 195864 ns 195859 ns 3430; TreeGetEntryTwoBranchesWithoutSetStatus 317772 ns 317761 ns 2095; BranchGetEntryOneBranch 103652 ns 103650 ns 6730; BranchGetEntryTwoBranches 104072 ns 104070 ns 6707; ```. With `GetEntriesUnsafe`:; ```; -----------------------------------------------------------------------------------; Benchmark Time CPU Iterations; -----------------------------------------------------------------------------------; TreeGetEntryOneBranch 152708 ns 152690 ns 4579; TreeGetEntryTwoBranchesAndAllStatusFalse 91277 ns 91274 ns 7731; TreeGetEntryTwoBranches 173940 ns 173922 ns 4024; TreeGetEntryTwoBranchesWithoutSetStatus 279271 ns 279261 ns 2514; BranchGetEntryOneBranch 104515 ns 104503 ns 6721; BranchGetEntryTwoBranches 104180 ns 104177 ns 6652; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3603
https://github.com/root-project/root/pull/3603:1085,Testability,Benchmark,Benchmark,1085,"`GetEntriesFast` is not as fast as it could be: it constructs and; destructs a `TReadLockGuard`, and might need to modify `TObjArray::fLast`.; This PR introduced `GetEntriesUnsafe`, a thread-unsafe version of `GetEntriesFast`; that side-steps these operations when possible. Measurements for the benchmarks in the `philippe` branch of the [df_bench](https://gitlab.com/bluehood/df_bench) repository:. With `GetEntriesFast`:; ```; -----------------------------------------------------------------------------------; Benchmark Time CPU Iterations; -----------------------------------------------------------------------------------; TreeGetEntryOneBranch 192943 ns 192939 ns 3664; TreeGetEntryTwoBranchesAndAllStatusFalse 110524 ns 110521 ns 6433; TreeGetEntryTwoBranches 195864 ns 195859 ns 3430; TreeGetEntryTwoBranchesWithoutSetStatus 317772 ns 317761 ns 2095; BranchGetEntryOneBranch 103652 ns 103650 ns 6730; BranchGetEntryTwoBranches 104072 ns 104070 ns 6707; ```. With `GetEntriesUnsafe`:; ```; -----------------------------------------------------------------------------------; Benchmark Time CPU Iterations; -----------------------------------------------------------------------------------; TreeGetEntryOneBranch 152708 ns 152690 ns 4579; TreeGetEntryTwoBranchesAndAllStatusFalse 91277 ns 91274 ns 7731; TreeGetEntryTwoBranches 173940 ns 173922 ns 4024; TreeGetEntryTwoBranchesWithoutSetStatus 279271 ns 279261 ns 2514; BranchGetEntryOneBranch 104515 ns 104503 ns 6721; BranchGetEntryTwoBranches 104180 ns 104177 ns 6652; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3603
https://github.com/root-project/root/pull/3605:90,Availability,error,error,90,"/build/jenkins/night/LABEL/mac1014/SPEC/cxxmod-noimt/root/test/testGenVectorVc.cxx:194:1: error: redefinition of 'Point' as different kind of symbol; using Point = ROOT::Math::PositionVector3D<ROOT::Math::Cartesian3D<T>, ROOT::Math::DefaultCoordinateSystemTag>;; ^; In module 'Darwin' imported from /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/assert.h:42:; /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/MacTypes.h:538:8: note: previous definition is here; struct Point {; ^",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3605
https://github.com/root-project/root/pull/3605:58,Testability,test,test,58,"/build/jenkins/night/LABEL/mac1014/SPEC/cxxmod-noimt/root/test/testGenVectorVc.cxx:194:1: error: redefinition of 'Point' as different kind of symbol; using Point = ROOT::Math::PositionVector3D<ROOT::Math::Cartesian3D<T>, ROOT::Math::DefaultCoordinateSystemTag>;; ^; In module 'Darwin' imported from /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/assert.h:42:; /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/MacTypes.h:538:8: note: previous definition is here; struct Point {; ^",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3605
https://github.com/root-project/root/pull/3605:63,Testability,test,testGenVectorVc,63,"/build/jenkins/night/LABEL/mac1014/SPEC/cxxmod-noimt/root/test/testGenVectorVc.cxx:194:1: error: redefinition of 'Point' as different kind of symbol; using Point = ROOT::Math::PositionVector3D<ROOT::Math::Cartesian3D<T>, ROOT::Math::DefaultCoordinateSystemTag>;; ^; In module 'Darwin' imported from /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/assert.h:42:; /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/MacTypes.h:538:8: note: previous definition is here; struct Point {; ^",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3605
https://github.com/root-project/root/pull/3605:368,Testability,assert,assert,368,"/build/jenkins/night/LABEL/mac1014/SPEC/cxxmod-noimt/root/test/testGenVectorVc.cxx:194:1: error: redefinition of 'Point' as different kind of symbol; using Point = ROOT::Math::PositionVector3D<ROOT::Math::Cartesian3D<T>, ROOT::Math::DefaultCoordinateSystemTag>;; ^; In module 'Darwin' imported from /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/assert.h:42:; /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/MacTypes.h:538:8: note: previous definition is here; struct Point {; ^",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3605
https://github.com/root-project/root/pull/3611:12,Deployability,update,updates,12,"Add pending updates of the RooFit documentation such as fixing typos, adding clarifications and pulling comments outside of functions such that doxygen can find them. Meant to be an NFC, but run CI to be sure.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3611
https://github.com/root-project/root/pull/3616:254,Energy Efficiency,reduce,reduces,254,"Currently, if ::Name() interface is called we pretty print the Decl name. This is suboptimal because it causes many memory allocations for something which is essentially immutable. This PR introduces step-by-step working cache if ::Name() was called. It reduces the temporary memory allocations by 12 Mb in standard ROOT and 130Mb in -Druntime_cxxmodules=On cache. The benchmarking test was provided by @pcanal in #3012. It is important to reduce the temporary allocations because they can contribute to increasing of the peak memory usage of ROOT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3616
https://github.com/root-project/root/pull/3616:440,Energy Efficiency,reduce,reduce,440,"Currently, if ::Name() interface is called we pretty print the Decl name. This is suboptimal because it causes many memory allocations for something which is essentially immutable. This PR introduces step-by-step working cache if ::Name() was called. It reduces the temporary memory allocations by 12 Mb in standard ROOT and 130Mb in -Druntime_cxxmodules=On cache. The benchmarking test was provided by @pcanal in #3012. It is important to reduce the temporary allocations because they can contribute to increasing of the peak memory usage of ROOT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3616
https://github.com/root-project/root/pull/3616:23,Integrability,interface,interface,23,"Currently, if ::Name() interface is called we pretty print the Decl name. This is suboptimal because it causes many memory allocations for something which is essentially immutable. This PR introduces step-by-step working cache if ::Name() was called. It reduces the temporary memory allocations by 12 Mb in standard ROOT and 130Mb in -Druntime_cxxmodules=On cache. The benchmarking test was provided by @pcanal in #3012. It is important to reduce the temporary allocations because they can contribute to increasing of the peak memory usage of ROOT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3616
https://github.com/root-project/root/pull/3616:221,Performance,cache,cache,221,"Currently, if ::Name() interface is called we pretty print the Decl name. This is suboptimal because it causes many memory allocations for something which is essentially immutable. This PR introduces step-by-step working cache if ::Name() was called. It reduces the temporary memory allocations by 12 Mb in standard ROOT and 130Mb in -Druntime_cxxmodules=On cache. The benchmarking test was provided by @pcanal in #3012. It is important to reduce the temporary allocations because they can contribute to increasing of the peak memory usage of ROOT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3616
https://github.com/root-project/root/pull/3616:358,Performance,cache,cache,358,"Currently, if ::Name() interface is called we pretty print the Decl name. This is suboptimal because it causes many memory allocations for something which is essentially immutable. This PR introduces step-by-step working cache if ::Name() was called. It reduces the temporary memory allocations by 12 Mb in standard ROOT and 130Mb in -Druntime_cxxmodules=On cache. The benchmarking test was provided by @pcanal in #3012. It is important to reduce the temporary allocations because they can contribute to increasing of the peak memory usage of ROOT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3616
https://github.com/root-project/root/pull/3616:369,Testability,benchmark,benchmarking,369,"Currently, if ::Name() interface is called we pretty print the Decl name. This is suboptimal because it causes many memory allocations for something which is essentially immutable. This PR introduces step-by-step working cache if ::Name() was called. It reduces the temporary memory allocations by 12 Mb in standard ROOT and 130Mb in -Druntime_cxxmodules=On cache. The benchmarking test was provided by @pcanal in #3012. It is important to reduce the temporary allocations because they can contribute to increasing of the peak memory usage of ROOT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3616
https://github.com/root-project/root/pull/3616:382,Testability,test,test,382,"Currently, if ::Name() interface is called we pretty print the Decl name. This is suboptimal because it causes many memory allocations for something which is essentially immutable. This PR introduces step-by-step working cache if ::Name() was called. It reduces the temporary memory allocations by 12 Mb in standard ROOT and 130Mb in -Druntime_cxxmodules=On cache. The benchmarking test was provided by @pcanal in #3012. It is important to reduce the temporary allocations because they can contribute to increasing of the peak memory usage of ROOT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3616
https://github.com/root-project/root/pull/3619:176,Deployability,update,update,176,"This is a follow-up on 8c9c1a3fbe3a1c5704635f8941abeb9596104c77. At the moment, the derived class StreamerInfo contains the base class version number :(; This means we need to update the derived class version number when the base class number increases ... This solves the problem seen at: https://root-forum.cern.ch/t/problem-in-opening-past-rootfile-tclonesarray-with-th1s-with-root-v6-16-and-ubuntu18/33293/1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3619
https://github.com/root-project/root/pull/3620:176,Deployability,update,update,176,"This is a follow-up on 8c9c1a3fbe3a1c5704635f8941abeb9596104c77. At the moment, the derived class StreamerInfo contains the base class version number :(; This means we need to update the derived class version number when the base class number increases ... This solves the problem seen at: https://root-forum.cern.ch/t/problem-in-opening-past-rootfile-tclonesarray-with-th1s-with-root-v6-16-and-ubuntu18/33293/1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3620
https://github.com/root-project/root/pull/3621:176,Deployability,update,update,176,"This is a follow-up on 8c9c1a3fbe3a1c5704635f8941abeb9596104c77. At the moment, the derived class StreamerInfo contains the base class version number :(; This means we need to update the derived class version number when the base class number increases ... This solves the problem seen at: https://root-forum.cern.ch/t/problem-in-opening-past-rootfile-tclonesarray-with-th1s-with-root-v6-16-and-ubuntu18/33293/1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3621
https://github.com/root-project/root/pull/3622:200,Deployability,patch,patch,200,"…ied. We cannot merge both codepaths because root.exe should always run with modules; if -Druntime_cxxmodules is specified, however, rootcling enables modules only; if -cxxmodule flag is passed. This patch fixes asserts when ROOT is built in -Druntime_cxxmodules=On but; no -cxxmodule flag is specified (in tree/test for instance).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3622
https://github.com/root-project/root/pull/3622:212,Testability,assert,asserts,212,"…ied. We cannot merge both codepaths because root.exe should always run with modules; if -Druntime_cxxmodules is specified, however, rootcling enables modules only; if -cxxmodule flag is passed. This patch fixes asserts when ROOT is built in -Druntime_cxxmodules=On but; no -cxxmodule flag is specified (in tree/test for instance).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3622
https://github.com/root-project/root/pull/3622:312,Testability,test,test,312,"…ied. We cannot merge both codepaths because root.exe should always run with modules; if -Druntime_cxxmodules is specified, however, rootcling enables modules only; if -cxxmodule flag is passed. This patch fixes asserts when ROOT is built in -Druntime_cxxmodules=On but; no -cxxmodule flag is specified (in tree/test for instance).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3622
https://github.com/root-project/root/pull/3624:193,Availability,failure,failures,193,"This was appending ""roottest"" to the filter string, instead of *also* filtering ""roottest"".; roottest dictionaries will always have full path names, so veto ""/roottest/"".; Fixes 19 incremental failures that ceb925ae1e claimed to fix:. projectroot.roottest.root.meta.roottest_root_meta_drawing; projectroot.roottest.root.tree.split.roottest_root_tree_split_make; projectroot.roottest.root.treeformula.parse.roottest_root_treeformula_parse_make; projectroot.roottest.root.treeformula.sync.roottest_root_treeformula_sync_make; projectroot.roottest.root.tree.selector.roottest_root_tree_selector_make; projectroot.roottest.root.io.fakeClass.roottest_root_io_fakeClass_make; projectroot.roottest.root.tree.addresses.roottest_root_tree_addresses_make; projectroot.roottest.root.treeformula.retobj.roottest_root_treeformula_retobj_make; projectroot.roottest.root.treeproxy.roottest_root_treeproxy_make; projectroot.roottest.root.treeformula.schemaEvolution.roottest_root_treeformula_schemaEvolution_make; projectroot.roottest.root.tree.evolution.roottest_root_tree_evolution_make; projectroot.roottest.root.treeformula.array.roottest_root_treeformula_array_make; projectroot.roottest.root.meta.tclass.roottest_root_meta_tclass_execState; projectroot.roottest.root.meta.roottest_root_meta_runautoload_auto; projectroot.roottest.root.collection.roottest_root_collection_execMissing; projectroot.test.test_stresstmva_interpreted; projectroot.roottest.root.io.evolution.roottest_root_io_evolution_make; projectroot.roottest.root.io.datamodelevolution.roottest_root_io_datamodelevolution_make; projectroot.roottest.root.tree.friend.roottest_root_tree_friend_make.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3624
https://github.com/root-project/root/pull/3624:1386,Testability,test,test,1386,"This was appending ""roottest"" to the filter string, instead of *also* filtering ""roottest"".; roottest dictionaries will always have full path names, so veto ""/roottest/"".; Fixes 19 incremental failures that ceb925ae1e claimed to fix:. projectroot.roottest.root.meta.roottest_root_meta_drawing; projectroot.roottest.root.tree.split.roottest_root_tree_split_make; projectroot.roottest.root.treeformula.parse.roottest_root_treeformula_parse_make; projectroot.roottest.root.treeformula.sync.roottest_root_treeformula_sync_make; projectroot.roottest.root.tree.selector.roottest_root_tree_selector_make; projectroot.roottest.root.io.fakeClass.roottest_root_io_fakeClass_make; projectroot.roottest.root.tree.addresses.roottest_root_tree_addresses_make; projectroot.roottest.root.treeformula.retobj.roottest_root_treeformula_retobj_make; projectroot.roottest.root.treeproxy.roottest_root_treeproxy_make; projectroot.roottest.root.treeformula.schemaEvolution.roottest_root_treeformula_schemaEvolution_make; projectroot.roottest.root.tree.evolution.roottest_root_tree_evolution_make; projectroot.roottest.root.treeformula.array.roottest_root_treeformula_array_make; projectroot.roottest.root.meta.tclass.roottest_root_meta_tclass_execState; projectroot.roottest.root.meta.roottest_root_meta_runautoload_auto; projectroot.roottest.root.collection.roottest_root_collection_execMissing; projectroot.test.test_stresstmva_interpreted; projectroot.roottest.root.io.evolution.roottest_root_io_evolution_make; projectroot.roottest.root.io.datamodelevolution.roottest_root_io_datamodelevolution_make; projectroot.roottest.root.tree.friend.roottest_root_tree_friend_make.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3624
https://github.com/root-project/root/pull/3625:330,Deployability,release,released,330,- when ROOT::IsEnableImplicitMT() TMVA will run by default in MT; - when TMVA::gConfig().EnableMT(0) or TMVA::gConfig().EnableMT(nthreads > 1) TMVA will run in MT independently of ROOT::IsEnabledImplicitMT(); - when TMVA::gConfig().EnableMT(1) or TMVA::gConfig().DisableMT() TMVA will run sequentially and its thread pool will be released,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3625
https://github.com/root-project/root/pull/3626:124,Modifiability,variab,variables,124,"Fix the replacement of S,B with x,y in formula used for performance metrics when S and B appear in function name and not as variables. ; Example: RooStats::AsimovSignificance(S,B) which has a S in its function name",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3626
https://github.com/root-project/root/pull/3626:56,Performance,perform,performance,56,"Fix the replacement of S,B with x,y in formula used for performance metrics when S and B appear in function name and not as variables. ; Example: RooStats::AsimovSignificance(S,B) which has a S in its function name",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3626
https://github.com/root-project/root/pull/3631:89,Integrability,depend,depends,89,Add python version of RDF tutorial producing dimuon spectrum from CMS Open Data. This PR depends on #3571.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3631
https://github.com/root-project/root/pull/3633:239,Deployability,install,installed,239,"This adds gdb pretty printers for a few objects such as TString and TNamed, as well; as a couple of RooFit objects. gdb can automatically load them if `add-auto-load-safe-path`; is set to ROOT's lib directory.; The printers should only be installed during debug builds. A couple of things are still unclear:; - `file(COPY ...` is used to copy the printers into the build directory. This will only run when cmake is run, but not during make. The pretty-printers will therefore not get updated. Is that a problem? A solution should be to create targets that are being kept up-to-date by make.; - Is it correct to use `install(FILES ...)` to install?; - I added a roottest that starts root.exe in gdb, and tries to load the printers. This may fail; o With old gdbs; o With release builds. gdb should fail to load the printers because they are not installed. Probably, the test should be disabled during release builds. Let's see if it fails as expected.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3633
https://github.com/root-project/root/pull/3633:484,Deployability,update,updated,484,"This adds gdb pretty printers for a few objects such as TString and TNamed, as well; as a couple of RooFit objects. gdb can automatically load them if `add-auto-load-safe-path`; is set to ROOT's lib directory.; The printers should only be installed during debug builds. A couple of things are still unclear:; - `file(COPY ...` is used to copy the printers into the build directory. This will only run when cmake is run, but not during make. The pretty-printers will therefore not get updated. Is that a problem? A solution should be to create targets that are being kept up-to-date by make.; - Is it correct to use `install(FILES ...)` to install?; - I added a roottest that starts root.exe in gdb, and tries to load the printers. This may fail; o With old gdbs; o With release builds. gdb should fail to load the printers because they are not installed. Probably, the test should be disabled during release builds. Let's see if it fails as expected.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3633
https://github.com/root-project/root/pull/3633:616,Deployability,install,install,616,"This adds gdb pretty printers for a few objects such as TString and TNamed, as well; as a couple of RooFit objects. gdb can automatically load them if `add-auto-load-safe-path`; is set to ROOT's lib directory.; The printers should only be installed during debug builds. A couple of things are still unclear:; - `file(COPY ...` is used to copy the printers into the build directory. This will only run when cmake is run, but not during make. The pretty-printers will therefore not get updated. Is that a problem? A solution should be to create targets that are being kept up-to-date by make.; - Is it correct to use `install(FILES ...)` to install?; - I added a roottest that starts root.exe in gdb, and tries to load the printers. This may fail; o With old gdbs; o With release builds. gdb should fail to load the printers because they are not installed. Probably, the test should be disabled during release builds. Let's see if it fails as expected.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3633
https://github.com/root-project/root/pull/3633:639,Deployability,install,install,639,"This adds gdb pretty printers for a few objects such as TString and TNamed, as well; as a couple of RooFit objects. gdb can automatically load them if `add-auto-load-safe-path`; is set to ROOT's lib directory.; The printers should only be installed during debug builds. A couple of things are still unclear:; - `file(COPY ...` is used to copy the printers into the build directory. This will only run when cmake is run, but not during make. The pretty-printers will therefore not get updated. Is that a problem? A solution should be to create targets that are being kept up-to-date by make.; - Is it correct to use `install(FILES ...)` to install?; - I added a roottest that starts root.exe in gdb, and tries to load the printers. This may fail; o With old gdbs; o With release builds. gdb should fail to load the printers because they are not installed. Probably, the test should be disabled during release builds. Let's see if it fails as expected.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3633
https://github.com/root-project/root/pull/3633:770,Deployability,release,release,770,"This adds gdb pretty printers for a few objects such as TString and TNamed, as well; as a couple of RooFit objects. gdb can automatically load them if `add-auto-load-safe-path`; is set to ROOT's lib directory.; The printers should only be installed during debug builds. A couple of things are still unclear:; - `file(COPY ...` is used to copy the printers into the build directory. This will only run when cmake is run, but not during make. The pretty-printers will therefore not get updated. Is that a problem? A solution should be to create targets that are being kept up-to-date by make.; - Is it correct to use `install(FILES ...)` to install?; - I added a roottest that starts root.exe in gdb, and tries to load the printers. This may fail; o With old gdbs; o With release builds. gdb should fail to load the printers because they are not installed. Probably, the test should be disabled during release builds. Let's see if it fails as expected.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3633
https://github.com/root-project/root/pull/3633:844,Deployability,install,installed,844,"This adds gdb pretty printers for a few objects such as TString and TNamed, as well; as a couple of RooFit objects. gdb can automatically load them if `add-auto-load-safe-path`; is set to ROOT's lib directory.; The printers should only be installed during debug builds. A couple of things are still unclear:; - `file(COPY ...` is used to copy the printers into the build directory. This will only run when cmake is run, but not during make. The pretty-printers will therefore not get updated. Is that a problem? A solution should be to create targets that are being kept up-to-date by make.; - Is it correct to use `install(FILES ...)` to install?; - I added a roottest that starts root.exe in gdb, and tries to load the printers. This may fail; o With old gdbs; o With release builds. gdb should fail to load the printers because they are not installed. Probably, the test should be disabled during release builds. Let's see if it fails as expected.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3633
https://github.com/root-project/root/pull/3633:900,Deployability,release,release,900,"This adds gdb pretty printers for a few objects such as TString and TNamed, as well; as a couple of RooFit objects. gdb can automatically load them if `add-auto-load-safe-path`; is set to ROOT's lib directory.; The printers should only be installed during debug builds. A couple of things are still unclear:; - `file(COPY ...` is used to copy the printers into the build directory. This will only run when cmake is run, but not during make. The pretty-printers will therefore not get updated. Is that a problem? A solution should be to create targets that are being kept up-to-date by make.; - Is it correct to use `install(FILES ...)` to install?; - I added a roottest that starts root.exe in gdb, and tries to load the printers. This may fail; o With old gdbs; o With release builds. gdb should fail to load the printers because they are not installed. Probably, the test should be disabled during release builds. Let's see if it fails as expected.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3633
https://github.com/root-project/root/pull/3633:138,Performance,load,load,138,"This adds gdb pretty printers for a few objects such as TString and TNamed, as well; as a couple of RooFit objects. gdb can automatically load them if `add-auto-load-safe-path`; is set to ROOT's lib directory.; The printers should only be installed during debug builds. A couple of things are still unclear:; - `file(COPY ...` is used to copy the printers into the build directory. This will only run when cmake is run, but not during make. The pretty-printers will therefore not get updated. Is that a problem? A solution should be to create targets that are being kept up-to-date by make.; - Is it correct to use `install(FILES ...)` to install?; - I added a roottest that starts root.exe in gdb, and tries to load the printers. This may fail; o With old gdbs; o With release builds. gdb should fail to load the printers because they are not installed. Probably, the test should be disabled during release builds. Let's see if it fails as expected.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3633
https://github.com/root-project/root/pull/3633:161,Performance,load,load-safe-path,161,"This adds gdb pretty printers for a few objects such as TString and TNamed, as well; as a couple of RooFit objects. gdb can automatically load them if `add-auto-load-safe-path`; is set to ROOT's lib directory.; The printers should only be installed during debug builds. A couple of things are still unclear:; - `file(COPY ...` is used to copy the printers into the build directory. This will only run when cmake is run, but not during make. The pretty-printers will therefore not get updated. Is that a problem? A solution should be to create targets that are being kept up-to-date by make.; - Is it correct to use `install(FILES ...)` to install?; - I added a roottest that starts root.exe in gdb, and tries to load the printers. This may fail; o With old gdbs; o With release builds. gdb should fail to load the printers because they are not installed. Probably, the test should be disabled during release builds. Let's see if it fails as expected.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3633
https://github.com/root-project/root/pull/3633:712,Performance,load,load,712,"This adds gdb pretty printers for a few objects such as TString and TNamed, as well; as a couple of RooFit objects. gdb can automatically load them if `add-auto-load-safe-path`; is set to ROOT's lib directory.; The printers should only be installed during debug builds. A couple of things are still unclear:; - `file(COPY ...` is used to copy the printers into the build directory. This will only run when cmake is run, but not during make. The pretty-printers will therefore not get updated. Is that a problem? A solution should be to create targets that are being kept up-to-date by make.; - Is it correct to use `install(FILES ...)` to install?; - I added a roottest that starts root.exe in gdb, and tries to load the printers. This may fail; o With old gdbs; o With release builds. gdb should fail to load the printers because they are not installed. Probably, the test should be disabled during release builds. Let's see if it fails as expected.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3633
https://github.com/root-project/root/pull/3633:805,Performance,load,load,805,"This adds gdb pretty printers for a few objects such as TString and TNamed, as well; as a couple of RooFit objects. gdb can automatically load them if `add-auto-load-safe-path`; is set to ROOT's lib directory.; The printers should only be installed during debug builds. A couple of things are still unclear:; - `file(COPY ...` is used to copy the printers into the build directory. This will only run when cmake is run, but not during make. The pretty-printers will therefore not get updated. Is that a problem? A solution should be to create targets that are being kept up-to-date by make.; - Is it correct to use `install(FILES ...)` to install?; - I added a roottest that starts root.exe in gdb, and tries to load the printers. This may fail; o With old gdbs; o With release builds. gdb should fail to load the printers because they are not installed. Probably, the test should be disabled during release builds. Let's see if it fails as expected.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3633
https://github.com/root-project/root/pull/3633:166,Safety,safe,safe-path,166,"This adds gdb pretty printers for a few objects such as TString and TNamed, as well; as a couple of RooFit objects. gdb can automatically load them if `add-auto-load-safe-path`; is set to ROOT's lib directory.; The printers should only be installed during debug builds. A couple of things are still unclear:; - `file(COPY ...` is used to copy the printers into the build directory. This will only run when cmake is run, but not during make. The pretty-printers will therefore not get updated. Is that a problem? A solution should be to create targets that are being kept up-to-date by make.; - Is it correct to use `install(FILES ...)` to install?; - I added a roottest that starts root.exe in gdb, and tries to load the printers. This may fail; o With old gdbs; o With release builds. gdb should fail to load the printers because they are not installed. Probably, the test should be disabled during release builds. Let's see if it fails as expected.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3633
https://github.com/root-project/root/pull/3633:869,Testability,test,test,869,"This adds gdb pretty printers for a few objects such as TString and TNamed, as well; as a couple of RooFit objects. gdb can automatically load them if `add-auto-load-safe-path`; is set to ROOT's lib directory.; The printers should only be installed during debug builds. A couple of things are still unclear:; - `file(COPY ...` is used to copy the printers into the build directory. This will only run when cmake is run, but not during make. The pretty-printers will therefore not get updated. Is that a problem? A solution should be to create targets that are being kept up-to-date by make.; - Is it correct to use `install(FILES ...)` to install?; - I added a roottest that starts root.exe in gdb, and tries to load the printers. This may fail; o With old gdbs; o With release builds. gdb should fail to load the printers because they are not installed. Probably, the test should be disabled during release builds. Let's see if it fails as expected.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3633
https://github.com/root-project/root/pull/3635:165,Availability,ERROR,ERROR,165,"This commit reduces ExcludeModules, which reduces dependency on rootmap files. These modules contain global variables which conflict with users' code such as PI and ERROR. This commit also undefines them.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3635
https://github.com/root-project/root/pull/3635:12,Energy Efficiency,reduce,reduces,12,"This commit reduces ExcludeModules, which reduces dependency on rootmap files. These modules contain global variables which conflict with users' code such as PI and ERROR. This commit also undefines them.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3635
https://github.com/root-project/root/pull/3635:42,Energy Efficiency,reduce,reduces,42,"This commit reduces ExcludeModules, which reduces dependency on rootmap files. These modules contain global variables which conflict with users' code such as PI and ERROR. This commit also undefines them.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3635
https://github.com/root-project/root/pull/3635:50,Integrability,depend,dependency,50,"This commit reduces ExcludeModules, which reduces dependency on rootmap files. These modules contain global variables which conflict with users' code such as PI and ERROR. This commit also undefines them.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3635
https://github.com/root-project/root/pull/3635:108,Modifiability,variab,variables,108,"This commit reduces ExcludeModules, which reduces dependency on rootmap files. These modules contain global variables which conflict with users' code such as PI and ERROR. This commit also undefines them.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3635
https://github.com/root-project/root/pull/3636:1408,Availability,error,error,1408,"onary build twice.; See the result of $ grep -r ""Generating G__Imt"" core/imt; core/imt/CMakeFiles/Imt.dir/build.make:@$(CMAKE_COMMAND) -E cmake_echo_color --switch=$(COLOR) --blue --bold --progress-dir=/Users/axel/build/root/cmake/CMakeFiles --progress-num=$(CMAKE_PROGRESS_1) ""Generating G__Imt.cxx, ../../lib/libImt.rootmap""; core/imt/CMakeFiles/G__Imt.dir/build.make:@$(CMAKE_COMMAND) -E cmake_echo_color --switch=$(COLOR) --blue --bold --progress-dir=/Users/axel/build/root/cmake/CMakeFiles --progress-num=$(CMAKE_PROGRESS_1) ""Generating G__Imt.cxx, ../../lib/libImt.rootmap"". With this change, G__Imt.cxx has only one target:; $ grep -r ""Generating G__Imt"" core/imt; core/imt/CMakeFiles/G__Imt.dir/build.make:@$(CMAKE_COMMAND) -E cmake_echo_color --switch=$(COLOR) --blue --bold --progress-dir=/Users/axel/build/root/cmake/CMakeFiles --progress-num=$(CMAKE_PROGRESS_1) ""Generating G__Imt.cxx, ../../lib/libImt.rootmap"". This fixes sporadic build problems due to two targets creating the same output file concurrently:; [ 73%] Generating G__Imt.cxx, ../../lib/libImt.rootmap; Scanning dependencies of target G__Imt; [ 73%] Generating G__Imt.cxx, ../../lib/libImt.rootmap; [ 73%] Building CXX object core/imt/CMakeFiles/Imt.dir/G__Imt.cxx.o; g++: error: /mnt/build/workspace/lcg_release_tar/BUILDTYPE/Debug/COMPILER/native/LABEL/ubuntu16/build/projects/ROOT-6.16.00/src/ROOT-6.16.00-build/core/imt/G__Imt.cxx: No such file or directory; g++: fatal error: no input files; compilation terminated.; core/imt/CMakeFiles/Imt.dir/build.make:106: recipe for target 'core/imt/CMakeFiles/Imt.dir/G__Imt.cxx.o' failed; make[5]: *** [core/imt/CMakeFiles/Imt.dir/G__Imt.cxx.o] Error 1; [ 73%] Built target G__Imt; make[5]: Target 'core/imt/CMakeFiles/Imt.dir/build' not remade because of errors.; CMakeFiles/Makefile2:18311: recipe for target 'core/imt/CMakeFiles/Imt.dir/all' failed; make[4]: *** [core/imt/CMakeFiles/Imt.dir/all] Error 2. (cherry picked from commit a3e7a3c535b80c3a6cf0883a0bf8de66eca7d93f)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3636
https://github.com/root-project/root/pull/3636:1609,Availability,error,error,1609,"onary build twice.; See the result of $ grep -r ""Generating G__Imt"" core/imt; core/imt/CMakeFiles/Imt.dir/build.make:@$(CMAKE_COMMAND) -E cmake_echo_color --switch=$(COLOR) --blue --bold --progress-dir=/Users/axel/build/root/cmake/CMakeFiles --progress-num=$(CMAKE_PROGRESS_1) ""Generating G__Imt.cxx, ../../lib/libImt.rootmap""; core/imt/CMakeFiles/G__Imt.dir/build.make:@$(CMAKE_COMMAND) -E cmake_echo_color --switch=$(COLOR) --blue --bold --progress-dir=/Users/axel/build/root/cmake/CMakeFiles --progress-num=$(CMAKE_PROGRESS_1) ""Generating G__Imt.cxx, ../../lib/libImt.rootmap"". With this change, G__Imt.cxx has only one target:; $ grep -r ""Generating G__Imt"" core/imt; core/imt/CMakeFiles/G__Imt.dir/build.make:@$(CMAKE_COMMAND) -E cmake_echo_color --switch=$(COLOR) --blue --bold --progress-dir=/Users/axel/build/root/cmake/CMakeFiles --progress-num=$(CMAKE_PROGRESS_1) ""Generating G__Imt.cxx, ../../lib/libImt.rootmap"". This fixes sporadic build problems due to two targets creating the same output file concurrently:; [ 73%] Generating G__Imt.cxx, ../../lib/libImt.rootmap; Scanning dependencies of target G__Imt; [ 73%] Generating G__Imt.cxx, ../../lib/libImt.rootmap; [ 73%] Building CXX object core/imt/CMakeFiles/Imt.dir/G__Imt.cxx.o; g++: error: /mnt/build/workspace/lcg_release_tar/BUILDTYPE/Debug/COMPILER/native/LABEL/ubuntu16/build/projects/ROOT-6.16.00/src/ROOT-6.16.00-build/core/imt/G__Imt.cxx: No such file or directory; g++: fatal error: no input files; compilation terminated.; core/imt/CMakeFiles/Imt.dir/build.make:106: recipe for target 'core/imt/CMakeFiles/Imt.dir/G__Imt.cxx.o' failed; make[5]: *** [core/imt/CMakeFiles/Imt.dir/G__Imt.cxx.o] Error 1; [ 73%] Built target G__Imt; make[5]: Target 'core/imt/CMakeFiles/Imt.dir/build' not remade because of errors.; CMakeFiles/Makefile2:18311: recipe for target 'core/imt/CMakeFiles/Imt.dir/all' failed; make[4]: *** [core/imt/CMakeFiles/Imt.dir/all] Error 2. (cherry picked from commit a3e7a3c535b80c3a6cf0883a0bf8de66eca7d93f)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3636
https://github.com/root-project/root/pull/3636:1826,Availability,Error,Error,1826,"onary build twice.; See the result of $ grep -r ""Generating G__Imt"" core/imt; core/imt/CMakeFiles/Imt.dir/build.make:@$(CMAKE_COMMAND) -E cmake_echo_color --switch=$(COLOR) --blue --bold --progress-dir=/Users/axel/build/root/cmake/CMakeFiles --progress-num=$(CMAKE_PROGRESS_1) ""Generating G__Imt.cxx, ../../lib/libImt.rootmap""; core/imt/CMakeFiles/G__Imt.dir/build.make:@$(CMAKE_COMMAND) -E cmake_echo_color --switch=$(COLOR) --blue --bold --progress-dir=/Users/axel/build/root/cmake/CMakeFiles --progress-num=$(CMAKE_PROGRESS_1) ""Generating G__Imt.cxx, ../../lib/libImt.rootmap"". With this change, G__Imt.cxx has only one target:; $ grep -r ""Generating G__Imt"" core/imt; core/imt/CMakeFiles/G__Imt.dir/build.make:@$(CMAKE_COMMAND) -E cmake_echo_color --switch=$(COLOR) --blue --bold --progress-dir=/Users/axel/build/root/cmake/CMakeFiles --progress-num=$(CMAKE_PROGRESS_1) ""Generating G__Imt.cxx, ../../lib/libImt.rootmap"". This fixes sporadic build problems due to two targets creating the same output file concurrently:; [ 73%] Generating G__Imt.cxx, ../../lib/libImt.rootmap; Scanning dependencies of target G__Imt; [ 73%] Generating G__Imt.cxx, ../../lib/libImt.rootmap; [ 73%] Building CXX object core/imt/CMakeFiles/Imt.dir/G__Imt.cxx.o; g++: error: /mnt/build/workspace/lcg_release_tar/BUILDTYPE/Debug/COMPILER/native/LABEL/ubuntu16/build/projects/ROOT-6.16.00/src/ROOT-6.16.00-build/core/imt/G__Imt.cxx: No such file or directory; g++: fatal error: no input files; compilation terminated.; core/imt/CMakeFiles/Imt.dir/build.make:106: recipe for target 'core/imt/CMakeFiles/Imt.dir/G__Imt.cxx.o' failed; make[5]: *** [core/imt/CMakeFiles/Imt.dir/G__Imt.cxx.o] Error 1; [ 73%] Built target G__Imt; make[5]: Target 'core/imt/CMakeFiles/Imt.dir/build' not remade because of errors.; CMakeFiles/Makefile2:18311: recipe for target 'core/imt/CMakeFiles/Imt.dir/all' failed; make[4]: *** [core/imt/CMakeFiles/Imt.dir/all] Error 2. (cherry picked from commit a3e7a3c535b80c3a6cf0883a0bf8de66eca7d93f)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3636
https://github.com/root-project/root/pull/3636:1937,Availability,error,errors,1937,"onary build twice.; See the result of $ grep -r ""Generating G__Imt"" core/imt; core/imt/CMakeFiles/Imt.dir/build.make:@$(CMAKE_COMMAND) -E cmake_echo_color --switch=$(COLOR) --blue --bold --progress-dir=/Users/axel/build/root/cmake/CMakeFiles --progress-num=$(CMAKE_PROGRESS_1) ""Generating G__Imt.cxx, ../../lib/libImt.rootmap""; core/imt/CMakeFiles/G__Imt.dir/build.make:@$(CMAKE_COMMAND) -E cmake_echo_color --switch=$(COLOR) --blue --bold --progress-dir=/Users/axel/build/root/cmake/CMakeFiles --progress-num=$(CMAKE_PROGRESS_1) ""Generating G__Imt.cxx, ../../lib/libImt.rootmap"". With this change, G__Imt.cxx has only one target:; $ grep -r ""Generating G__Imt"" core/imt; core/imt/CMakeFiles/G__Imt.dir/build.make:@$(CMAKE_COMMAND) -E cmake_echo_color --switch=$(COLOR) --blue --bold --progress-dir=/Users/axel/build/root/cmake/CMakeFiles --progress-num=$(CMAKE_PROGRESS_1) ""Generating G__Imt.cxx, ../../lib/libImt.rootmap"". This fixes sporadic build problems due to two targets creating the same output file concurrently:; [ 73%] Generating G__Imt.cxx, ../../lib/libImt.rootmap; Scanning dependencies of target G__Imt; [ 73%] Generating G__Imt.cxx, ../../lib/libImt.rootmap; [ 73%] Building CXX object core/imt/CMakeFiles/Imt.dir/G__Imt.cxx.o; g++: error: /mnt/build/workspace/lcg_release_tar/BUILDTYPE/Debug/COMPILER/native/LABEL/ubuntu16/build/projects/ROOT-6.16.00/src/ROOT-6.16.00-build/core/imt/G__Imt.cxx: No such file or directory; g++: fatal error: no input files; compilation terminated.; core/imt/CMakeFiles/Imt.dir/build.make:106: recipe for target 'core/imt/CMakeFiles/Imt.dir/G__Imt.cxx.o' failed; make[5]: *** [core/imt/CMakeFiles/Imt.dir/G__Imt.cxx.o] Error 1; [ 73%] Built target G__Imt; make[5]: Target 'core/imt/CMakeFiles/Imt.dir/build' not remade because of errors.; CMakeFiles/Makefile2:18311: recipe for target 'core/imt/CMakeFiles/Imt.dir/all' failed; make[4]: *** [core/imt/CMakeFiles/Imt.dir/all] Error 2. (cherry picked from commit a3e7a3c535b80c3a6cf0883a0bf8de66eca7d93f)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3636
https://github.com/root-project/root/pull/3636:2081,Availability,Error,Error,2081,"onary build twice.; See the result of $ grep -r ""Generating G__Imt"" core/imt; core/imt/CMakeFiles/Imt.dir/build.make:@$(CMAKE_COMMAND) -E cmake_echo_color --switch=$(COLOR) --blue --bold --progress-dir=/Users/axel/build/root/cmake/CMakeFiles --progress-num=$(CMAKE_PROGRESS_1) ""Generating G__Imt.cxx, ../../lib/libImt.rootmap""; core/imt/CMakeFiles/G__Imt.dir/build.make:@$(CMAKE_COMMAND) -E cmake_echo_color --switch=$(COLOR) --blue --bold --progress-dir=/Users/axel/build/root/cmake/CMakeFiles --progress-num=$(CMAKE_PROGRESS_1) ""Generating G__Imt.cxx, ../../lib/libImt.rootmap"". With this change, G__Imt.cxx has only one target:; $ grep -r ""Generating G__Imt"" core/imt; core/imt/CMakeFiles/G__Imt.dir/build.make:@$(CMAKE_COMMAND) -E cmake_echo_color --switch=$(COLOR) --blue --bold --progress-dir=/Users/axel/build/root/cmake/CMakeFiles --progress-num=$(CMAKE_PROGRESS_1) ""Generating G__Imt.cxx, ../../lib/libImt.rootmap"". This fixes sporadic build problems due to two targets creating the same output file concurrently:; [ 73%] Generating G__Imt.cxx, ../../lib/libImt.rootmap; Scanning dependencies of target G__Imt; [ 73%] Generating G__Imt.cxx, ../../lib/libImt.rootmap; [ 73%] Building CXX object core/imt/CMakeFiles/Imt.dir/G__Imt.cxx.o; g++: error: /mnt/build/workspace/lcg_release_tar/BUILDTYPE/Debug/COMPILER/native/LABEL/ubuntu16/build/projects/ROOT-6.16.00/src/ROOT-6.16.00-build/core/imt/G__Imt.cxx: No such file or directory; g++: fatal error: no input files; compilation terminated.; core/imt/CMakeFiles/Imt.dir/build.make:106: recipe for target 'core/imt/CMakeFiles/Imt.dir/G__Imt.cxx.o' failed; make[5]: *** [core/imt/CMakeFiles/Imt.dir/G__Imt.cxx.o] Error 1; [ 73%] Built target G__Imt; make[5]: Target 'core/imt/CMakeFiles/Imt.dir/build' not remade because of errors.; CMakeFiles/Makefile2:18311: recipe for target 'core/imt/CMakeFiles/Imt.dir/all' failed; make[4]: *** [core/imt/CMakeFiles/Imt.dir/all] Error 2. (cherry picked from commit a3e7a3c535b80c3a6cf0883a0bf8de66eca7d93f)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3636
https://github.com/root-project/root/pull/3636:46,Integrability,depend,dependency,46,"ROOT_LINKER_LIBRARY implicitly adds G__XYZ as dependency if that target exists.; This causes Imt to depend both on G__Imt and G__Imt.cxx, triggering the dictionary build twice.; See the result of $ grep -r ""Generating G__Imt"" core/imt; core/imt/CMakeFiles/Imt.dir/build.make:@$(CMAKE_COMMAND) -E cmake_echo_color --switch=$(COLOR) --blue --bold --progress-dir=/Users/axel/build/root/cmake/CMakeFiles --progress-num=$(CMAKE_PROGRESS_1) ""Generating G__Imt.cxx, ../../lib/libImt.rootmap""; core/imt/CMakeFiles/G__Imt.dir/build.make:@$(CMAKE_COMMAND) -E cmake_echo_color --switch=$(COLOR) --blue --bold --progress-dir=/Users/axel/build/root/cmake/CMakeFiles --progress-num=$(CMAKE_PROGRESS_1) ""Generating G__Imt.cxx, ../../lib/libImt.rootmap"". With this change, G__Imt.cxx has only one target:; $ grep -r ""Generating G__Imt"" core/imt; core/imt/CMakeFiles/G__Imt.dir/build.make:@$(CMAKE_COMMAND) -E cmake_echo_color --switch=$(COLOR) --blue --bold --progress-dir=/Users/axel/build/root/cmake/CMakeFiles --progress-num=$(CMAKE_PROGRESS_1) ""Generating G__Imt.cxx, ../../lib/libImt.rootmap"". This fixes sporadic build problems due to two targets creating the same output file concurrently:; [ 73%] Generating G__Imt.cxx, ../../lib/libImt.rootmap; Scanning dependencies of target G__Imt; [ 73%] Generating G__Imt.cxx, ../../lib/libImt.rootmap; [ 73%] Building CXX object core/imt/CMakeFiles/Imt.dir/G__Imt.cxx.o; g++: error: /mnt/build/workspace/lcg_release_tar/BUILDTYPE/Debug/COMPILER/native/LABEL/ubuntu16/build/projects/ROOT-6.16.00/src/ROOT-6.16.00-build/core/imt/G__Imt.cxx: No such file or directory; g++: fatal error: no input files; compilation terminated.; core/imt/CMakeFiles/Imt.dir/build.make:106: recipe for target 'core/imt/CMakeFiles/Imt.dir/G__Imt.cxx.o' failed; make[5]: *** [core/imt/CMakeFiles/Imt.dir/G__Imt.cxx.o] Error 1; [ 73%] Built target G__Imt; make[5]: Target 'core/imt/CMakeFiles/Imt.dir/build' not remade because of errors.; CMakeFiles/Makefile2:18311: recipe for target 'core/imt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3636
https://github.com/root-project/root/pull/3636:100,Integrability,depend,depend,100,"ROOT_LINKER_LIBRARY implicitly adds G__XYZ as dependency if that target exists.; This causes Imt to depend both on G__Imt and G__Imt.cxx, triggering the dictionary build twice.; See the result of $ grep -r ""Generating G__Imt"" core/imt; core/imt/CMakeFiles/Imt.dir/build.make:@$(CMAKE_COMMAND) -E cmake_echo_color --switch=$(COLOR) --blue --bold --progress-dir=/Users/axel/build/root/cmake/CMakeFiles --progress-num=$(CMAKE_PROGRESS_1) ""Generating G__Imt.cxx, ../../lib/libImt.rootmap""; core/imt/CMakeFiles/G__Imt.dir/build.make:@$(CMAKE_COMMAND) -E cmake_echo_color --switch=$(COLOR) --blue --bold --progress-dir=/Users/axel/build/root/cmake/CMakeFiles --progress-num=$(CMAKE_PROGRESS_1) ""Generating G__Imt.cxx, ../../lib/libImt.rootmap"". With this change, G__Imt.cxx has only one target:; $ grep -r ""Generating G__Imt"" core/imt; core/imt/CMakeFiles/G__Imt.dir/build.make:@$(CMAKE_COMMAND) -E cmake_echo_color --switch=$(COLOR) --blue --bold --progress-dir=/Users/axel/build/root/cmake/CMakeFiles --progress-num=$(CMAKE_PROGRESS_1) ""Generating G__Imt.cxx, ../../lib/libImt.rootmap"". This fixes sporadic build problems due to two targets creating the same output file concurrently:; [ 73%] Generating G__Imt.cxx, ../../lib/libImt.rootmap; Scanning dependencies of target G__Imt; [ 73%] Generating G__Imt.cxx, ../../lib/libImt.rootmap; [ 73%] Building CXX object core/imt/CMakeFiles/Imt.dir/G__Imt.cxx.o; g++: error: /mnt/build/workspace/lcg_release_tar/BUILDTYPE/Debug/COMPILER/native/LABEL/ubuntu16/build/projects/ROOT-6.16.00/src/ROOT-6.16.00-build/core/imt/G__Imt.cxx: No such file or directory; g++: fatal error: no input files; compilation terminated.; core/imt/CMakeFiles/Imt.dir/build.make:106: recipe for target 'core/imt/CMakeFiles/Imt.dir/G__Imt.cxx.o' failed; make[5]: *** [core/imt/CMakeFiles/Imt.dir/G__Imt.cxx.o] Error 1; [ 73%] Built target G__Imt; make[5]: Target 'core/imt/CMakeFiles/Imt.dir/build' not remade because of errors.; CMakeFiles/Makefile2:18311: recipe for target 'core/imt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3636
https://github.com/root-project/root/pull/3636:1247,Integrability,depend,dependencies,1247,"onary build twice.; See the result of $ grep -r ""Generating G__Imt"" core/imt; core/imt/CMakeFiles/Imt.dir/build.make:@$(CMAKE_COMMAND) -E cmake_echo_color --switch=$(COLOR) --blue --bold --progress-dir=/Users/axel/build/root/cmake/CMakeFiles --progress-num=$(CMAKE_PROGRESS_1) ""Generating G__Imt.cxx, ../../lib/libImt.rootmap""; core/imt/CMakeFiles/G__Imt.dir/build.make:@$(CMAKE_COMMAND) -E cmake_echo_color --switch=$(COLOR) --blue --bold --progress-dir=/Users/axel/build/root/cmake/CMakeFiles --progress-num=$(CMAKE_PROGRESS_1) ""Generating G__Imt.cxx, ../../lib/libImt.rootmap"". With this change, G__Imt.cxx has only one target:; $ grep -r ""Generating G__Imt"" core/imt; core/imt/CMakeFiles/G__Imt.dir/build.make:@$(CMAKE_COMMAND) -E cmake_echo_color --switch=$(COLOR) --blue --bold --progress-dir=/Users/axel/build/root/cmake/CMakeFiles --progress-num=$(CMAKE_PROGRESS_1) ""Generating G__Imt.cxx, ../../lib/libImt.rootmap"". This fixes sporadic build problems due to two targets creating the same output file concurrently:; [ 73%] Generating G__Imt.cxx, ../../lib/libImt.rootmap; Scanning dependencies of target G__Imt; [ 73%] Generating G__Imt.cxx, ../../lib/libImt.rootmap; [ 73%] Building CXX object core/imt/CMakeFiles/Imt.dir/G__Imt.cxx.o; g++: error: /mnt/build/workspace/lcg_release_tar/BUILDTYPE/Debug/COMPILER/native/LABEL/ubuntu16/build/projects/ROOT-6.16.00/src/ROOT-6.16.00-build/core/imt/G__Imt.cxx: No such file or directory; g++: fatal error: no input files; compilation terminated.; core/imt/CMakeFiles/Imt.dir/build.make:106: recipe for target 'core/imt/CMakeFiles/Imt.dir/G__Imt.cxx.o' failed; make[5]: *** [core/imt/CMakeFiles/Imt.dir/G__Imt.cxx.o] Error 1; [ 73%] Built target G__Imt; make[5]: Target 'core/imt/CMakeFiles/Imt.dir/build' not remade because of errors.; CMakeFiles/Makefile2:18311: recipe for target 'core/imt/CMakeFiles/Imt.dir/all' failed; make[4]: *** [core/imt/CMakeFiles/Imt.dir/all] Error 2. (cherry picked from commit a3e7a3c535b80c3a6cf0883a0bf8de66eca7d93f)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3636
https://github.com/root-project/root/pull/3636:1167,Performance,concurren,concurrently,1167,"ring the dictionary build twice.; See the result of $ grep -r ""Generating G__Imt"" core/imt; core/imt/CMakeFiles/Imt.dir/build.make:@$(CMAKE_COMMAND) -E cmake_echo_color --switch=$(COLOR) --blue --bold --progress-dir=/Users/axel/build/root/cmake/CMakeFiles --progress-num=$(CMAKE_PROGRESS_1) ""Generating G__Imt.cxx, ../../lib/libImt.rootmap""; core/imt/CMakeFiles/G__Imt.dir/build.make:@$(CMAKE_COMMAND) -E cmake_echo_color --switch=$(COLOR) --blue --bold --progress-dir=/Users/axel/build/root/cmake/CMakeFiles --progress-num=$(CMAKE_PROGRESS_1) ""Generating G__Imt.cxx, ../../lib/libImt.rootmap"". With this change, G__Imt.cxx has only one target:; $ grep -r ""Generating G__Imt"" core/imt; core/imt/CMakeFiles/G__Imt.dir/build.make:@$(CMAKE_COMMAND) -E cmake_echo_color --switch=$(COLOR) --blue --bold --progress-dir=/Users/axel/build/root/cmake/CMakeFiles --progress-num=$(CMAKE_PROGRESS_1) ""Generating G__Imt.cxx, ../../lib/libImt.rootmap"". This fixes sporadic build problems due to two targets creating the same output file concurrently:; [ 73%] Generating G__Imt.cxx, ../../lib/libImt.rootmap; Scanning dependencies of target G__Imt; [ 73%] Generating G__Imt.cxx, ../../lib/libImt.rootmap; [ 73%] Building CXX object core/imt/CMakeFiles/Imt.dir/G__Imt.cxx.o; g++: error: /mnt/build/workspace/lcg_release_tar/BUILDTYPE/Debug/COMPILER/native/LABEL/ubuntu16/build/projects/ROOT-6.16.00/src/ROOT-6.16.00-build/core/imt/G__Imt.cxx: No such file or directory; g++: fatal error: no input files; compilation terminated.; core/imt/CMakeFiles/Imt.dir/build.make:106: recipe for target 'core/imt/CMakeFiles/Imt.dir/G__Imt.cxx.o' failed; make[5]: *** [core/imt/CMakeFiles/Imt.dir/G__Imt.cxx.o] Error 1; [ 73%] Built target G__Imt; make[5]: Target 'core/imt/CMakeFiles/Imt.dir/build' not remade because of errors.; CMakeFiles/Makefile2:18311: recipe for target 'core/imt/CMakeFiles/Imt.dir/all' failed; make[4]: *** [core/imt/CMakeFiles/Imt.dir/all] Error 2. (cherry picked from commit a3e7a3c535b80c3a6cf0883a0bf8",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3636
https://github.com/root-project/root/pull/3640:199,Availability,redundant,redundant,199,"Ported from Cppyy patch by @wlav :`; https://bitbucket.org/wlav/cppyy-backend/src/master/cling/patches/using_decls.diff. Adds an iterator for using declarations to `TClingMethodInfo`. it should make redundant the pythonisations that add the method overloads from a base class to the derived class that uses them:; https://github.com/root-project/root/blob/master/bindings/pyroot_experimental/PyROOT/src/PyzPythonHelpers.cxx#L113. Instead of relying on pythonisations for specific classes, this PR adds the necessary logic to have this functionality solved in a generic way in the bindings.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3640
https://github.com/root-project/root/pull/3640:18,Deployability,patch,patch,18,"Ported from Cppyy patch by @wlav :`; https://bitbucket.org/wlav/cppyy-backend/src/master/cling/patches/using_decls.diff. Adds an iterator for using declarations to `TClingMethodInfo`. it should make redundant the pythonisations that add the method overloads from a base class to the derived class that uses them:; https://github.com/root-project/root/blob/master/bindings/pyroot_experimental/PyROOT/src/PyzPythonHelpers.cxx#L113. Instead of relying on pythonisations for specific classes, this PR adds the necessary logic to have this functionality solved in a generic way in the bindings.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3640
https://github.com/root-project/root/pull/3640:95,Deployability,patch,patches,95,"Ported from Cppyy patch by @wlav :`; https://bitbucket.org/wlav/cppyy-backend/src/master/cling/patches/using_decls.diff. Adds an iterator for using declarations to `TClingMethodInfo`. it should make redundant the pythonisations that add the method overloads from a base class to the derived class that uses them:; https://github.com/root-project/root/blob/master/bindings/pyroot_experimental/PyROOT/src/PyzPythonHelpers.cxx#L113. Instead of relying on pythonisations for specific classes, this PR adds the necessary logic to have this functionality solved in a generic way in the bindings.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3640
https://github.com/root-project/root/pull/3640:199,Safety,redund,redundant,199,"Ported from Cppyy patch by @wlav :`; https://bitbucket.org/wlav/cppyy-backend/src/master/cling/patches/using_decls.diff. Adds an iterator for using declarations to `TClingMethodInfo`. it should make redundant the pythonisations that add the method overloads from a base class to the derived class that uses them:; https://github.com/root-project/root/blob/master/bindings/pyroot_experimental/PyROOT/src/PyzPythonHelpers.cxx#L113. Instead of relying on pythonisations for specific classes, this PR adds the necessary logic to have this functionality solved in a generic way in the bindings.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3640
https://github.com/root-project/root/pull/3640:516,Testability,log,logic,516,"Ported from Cppyy patch by @wlav :`; https://bitbucket.org/wlav/cppyy-backend/src/master/cling/patches/using_decls.diff. Adds an iterator for using declarations to `TClingMethodInfo`. it should make redundant the pythonisations that add the method overloads from a base class to the derived class that uses them:; https://github.com/root-project/root/blob/master/bindings/pyroot_experimental/PyROOT/src/PyzPythonHelpers.cxx#L113. Instead of relying on pythonisations for specific classes, this PR adds the necessary logic to have this functionality solved in a generic way in the bindings.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3640
https://github.com/root-project/root/pull/3648:292,Deployability,Update,Update,292,"* Decouple browsing and geometry drawing functionality; * Try to provide generic browsing module (server and client), using ui5 TreeTable; * Support partial and full loading of browsing structures (depending on size); * Support online and offline operations (later used for web snapshots); * Update JSROOT with latest three.js r102",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3648
https://github.com/root-project/root/pull/3648:198,Integrability,depend,depending,198,"* Decouple browsing and geometry drawing functionality; * Try to provide generic browsing module (server and client), using ui5 TreeTable; * Support partial and full loading of browsing structures (depending on size); * Support online and offline operations (later used for web snapshots); * Update JSROOT with latest three.js r102",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3648
https://github.com/root-project/root/pull/3648:166,Performance,load,loading,166,"* Decouple browsing and geometry drawing functionality; * Try to provide generic browsing module (server and client), using ui5 TreeTable; * Support partial and full loading of browsing structures (depending on size); * Support online and offline operations (later used for web snapshots); * Update JSROOT with latest three.js r102",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3648
https://github.com/root-project/root/pull/3652:8,Deployability,release,release,8,"The new release includes some improvements in both Forward and; Reverse mode:; * Extend the way to specify a dependent variables. Consider function, `double f(double x, double y, double z) {...}`, `clad::differentiate(f, ""z"")` is equivalent to `clad::differentiate(f, 2)`. `clad::gradient(f, ""x, y"")` differentiates with respect to `x` and `y` but not `z`. The gradient results are stored in a `_result` parameter in the same order as `x` and `y` were specified. Namely, the result of `x` is stored in `_result[0]` and the result of `y` in `_result[1]`. If we invert the arguments specified in the string to `clad::gradient(f, ""y, x"")` the results will be stored inversely.; * Enable recursive differentiation.; * Support single- and multi-dimensional arrays -- works for arrays with constant size like `double A[] = {1, 2, 3};`, `double A[3];` or `double A[1][2][3][4];`. See more at: https://github.com/vgvassilev/clad/blob/v0.5/docs/ReleaseNotes.md. Kudos go to @efremale!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3652
https://github.com/root-project/root/pull/3652:936,Deployability,Release,ReleaseNotes,936,"The new release includes some improvements in both Forward and; Reverse mode:; * Extend the way to specify a dependent variables. Consider function, `double f(double x, double y, double z) {...}`, `clad::differentiate(f, ""z"")` is equivalent to `clad::differentiate(f, 2)`. `clad::gradient(f, ""x, y"")` differentiates with respect to `x` and `y` but not `z`. The gradient results are stored in a `_result` parameter in the same order as `x` and `y` were specified. Namely, the result of `x` is stored in `_result[0]` and the result of `y` in `_result[1]`. If we invert the arguments specified in the string to `clad::gradient(f, ""y, x"")` the results will be stored inversely.; * Enable recursive differentiation.; * Support single- and multi-dimensional arrays -- works for arrays with constant size like `double A[] = {1, 2, 3};`, `double A[3];` or `double A[1][2][3][4];`. See more at: https://github.com/vgvassilev/clad/blob/v0.5/docs/ReleaseNotes.md. Kudos go to @efremale!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3652
https://github.com/root-project/root/pull/3652:109,Integrability,depend,dependent,109,"The new release includes some improvements in both Forward and; Reverse mode:; * Extend the way to specify a dependent variables. Consider function, `double f(double x, double y, double z) {...}`, `clad::differentiate(f, ""z"")` is equivalent to `clad::differentiate(f, 2)`. `clad::gradient(f, ""x, y"")` differentiates with respect to `x` and `y` but not `z`. The gradient results are stored in a `_result` parameter in the same order as `x` and `y` were specified. Namely, the result of `x` is stored in `_result[0]` and the result of `y` in `_result[1]`. If we invert the arguments specified in the string to `clad::gradient(f, ""y, x"")` the results will be stored inversely.; * Enable recursive differentiation.; * Support single- and multi-dimensional arrays -- works for arrays with constant size like `double A[] = {1, 2, 3};`, `double A[3];` or `double A[1][2][3][4];`. See more at: https://github.com/vgvassilev/clad/blob/v0.5/docs/ReleaseNotes.md. Kudos go to @efremale!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3652
https://github.com/root-project/root/pull/3652:81,Modifiability,Extend,Extend,81,"The new release includes some improvements in both Forward and; Reverse mode:; * Extend the way to specify a dependent variables. Consider function, `double f(double x, double y, double z) {...}`, `clad::differentiate(f, ""z"")` is equivalent to `clad::differentiate(f, 2)`. `clad::gradient(f, ""x, y"")` differentiates with respect to `x` and `y` but not `z`. The gradient results are stored in a `_result` parameter in the same order as `x` and `y` were specified. Namely, the result of `x` is stored in `_result[0]` and the result of `y` in `_result[1]`. If we invert the arguments specified in the string to `clad::gradient(f, ""y, x"")` the results will be stored inversely.; * Enable recursive differentiation.; * Support single- and multi-dimensional arrays -- works for arrays with constant size like `double A[] = {1, 2, 3};`, `double A[3];` or `double A[1][2][3][4];`. See more at: https://github.com/vgvassilev/clad/blob/v0.5/docs/ReleaseNotes.md. Kudos go to @efremale!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3652
https://github.com/root-project/root/pull/3652:119,Modifiability,variab,variables,119,"The new release includes some improvements in both Forward and; Reverse mode:; * Extend the way to specify a dependent variables. Consider function, `double f(double x, double y, double z) {...}`, `clad::differentiate(f, ""z"")` is equivalent to `clad::differentiate(f, 2)`. `clad::gradient(f, ""x, y"")` differentiates with respect to `x` and `y` but not `z`. The gradient results are stored in a `_result` parameter in the same order as `x` and `y` were specified. Namely, the result of `x` is stored in `_result[0]` and the result of `y` in `_result[1]`. If we invert the arguments specified in the string to `clad::gradient(f, ""y, x"")` the results will be stored inversely.; * Enable recursive differentiation.; * Support single- and multi-dimensional arrays -- works for arrays with constant size like `double A[] = {1, 2, 3};`, `double A[3];` or `double A[1][2][3][4];`. See more at: https://github.com/vgvassilev/clad/blob/v0.5/docs/ReleaseNotes.md. Kudos go to @efremale!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3652
https://github.com/root-project/root/pull/3657:246,Deployability,update,updated,246,"When a RooDataSet is constructed without a weight variable, weights are ignored when events; are added to the dataset. Now, there will be a clear warning notifying the user that an event; weight is being ignored.; The documentation has also been updated. See also:; https://root-forum.cern.ch/t/fit-to-a-weighted-unbinned-data-set/33495",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3657
https://github.com/root-project/root/pull/3657:50,Modifiability,variab,variable,50,"When a RooDataSet is constructed without a weight variable, weights are ignored when events; are added to the dataset. Now, there will be a clear warning notifying the user that an event; weight is being ignored.; The documentation has also been updated. See also:; https://root-forum.cern.ch/t/fit-to-a-weighted-unbinned-data-set/33495",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3657
https://github.com/root-project/root/pull/3657:140,Usability,clear,clear,140,"When a RooDataSet is constructed without a weight variable, weights are ignored when events; are added to the dataset. Now, there will be a clear warning notifying the user that an event; weight is being ignored.; The documentation has also been updated. See also:; https://root-forum.cern.ch/t/fit-to-a-weighted-unbinned-data-set/33495",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3657
https://github.com/root-project/root/pull/3658:115,Security,access,accesses,115,This prevents the vector to be reallocated if the size exceeds the capacity of; the vector causing invalid pointer accesses. Fixes ROOT-7749.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3658
https://github.com/root-project/root/pull/3659:9,Testability,test,test,9,"Instead, test for libC++ and language version.; This fixes MacOS builds with >=C++14 and tests enabled.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3659
https://github.com/root-project/root/pull/3659:89,Testability,test,tests,89,"Instead, test for libC++ and language version.; This fixes MacOS builds with >=C++14 and tests enabled.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3659
https://github.com/root-project/root/pull/3661:21,Safety,risk,risk,21,otherwise there is a risk of overcommiting the machine with too many workers.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3661
https://github.com/root-project/root/pull/3662:11,Deployability,release,release,11,The RooFit release notes were slightly outdated after the deprecation; macro R__SUGGEST_ALTERNATIVE had been merged.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3662
https://github.com/root-project/root/pull/3664:8,Deployability,update,updates,8,"This PR updates the Cppyy packages to the following versions:; - cppyy 1.4.7; - cppyy-backend 1.8.1 (clingwrapper); - CPyCppyy 1.7.1. This update brings several fixes/features, including:; - @bellenot 's fixes for Windows; - Fixes for overload resolution when implicit conversion can be applied; - Improved template support; - Fixes to remove compiler warnings; - and many more. After this PR is merged, another PR (https://github.com/root-project/root/pull/3640) will be necessary to support using declarations for methods. The corresponding patch in cppyy is being updated at the moment. Piggybacked with in this PR there is also a fix for getting using directives of namespaces when those namespaces are nested.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3664
https://github.com/root-project/root/pull/3664:139,Deployability,update,update,139,"This PR updates the Cppyy packages to the following versions:; - cppyy 1.4.7; - cppyy-backend 1.8.1 (clingwrapper); - CPyCppyy 1.7.1. This update brings several fixes/features, including:; - @bellenot 's fixes for Windows; - Fixes for overload resolution when implicit conversion can be applied; - Improved template support; - Fixes to remove compiler warnings; - and many more. After this PR is merged, another PR (https://github.com/root-project/root/pull/3640) will be necessary to support using declarations for methods. The corresponding patch in cppyy is being updated at the moment. Piggybacked with in this PR there is also a fix for getting using directives of namespaces when those namespaces are nested.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3664
https://github.com/root-project/root/pull/3664:543,Deployability,patch,patch,543,"This PR updates the Cppyy packages to the following versions:; - cppyy 1.4.7; - cppyy-backend 1.8.1 (clingwrapper); - CPyCppyy 1.7.1. This update brings several fixes/features, including:; - @bellenot 's fixes for Windows; - Fixes for overload resolution when implicit conversion can be applied; - Improved template support; - Fixes to remove compiler warnings; - and many more. After this PR is merged, another PR (https://github.com/root-project/root/pull/3640) will be necessary to support using declarations for methods. The corresponding patch in cppyy is being updated at the moment. Piggybacked with in this PR there is also a fix for getting using directives of namespaces when those namespaces are nested.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3664
https://github.com/root-project/root/pull/3664:567,Deployability,update,updated,567,"This PR updates the Cppyy packages to the following versions:; - cppyy 1.4.7; - cppyy-backend 1.8.1 (clingwrapper); - CPyCppyy 1.7.1. This update brings several fixes/features, including:; - @bellenot 's fixes for Windows; - Fixes for overload resolution when implicit conversion can be applied; - Improved template support; - Fixes to remove compiler warnings; - and many more. After this PR is merged, another PR (https://github.com/root-project/root/pull/3640) will be necessary to support using declarations for methods. The corresponding patch in cppyy is being updated at the moment. Piggybacked with in this PR there is also a fix for getting using directives of namespaces when those namespaces are nested.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3664
https://github.com/root-project/root/pull/3669:90,Availability,alive,alive,90,"This PR supersedes #3424. The reference counting is greatly improved and the data is kept alive until the datasource dies, which gets delete at the end of the lifetime of the computational graph. See here for the use-case:. ```python; import ROOT; import numpy. data = {; ""x"": numpy.array([1, 2, 3]),; ""y"": numpy.array([4, 5, 6]); }. df = ROOT.ROOT.RDF.MakeNumpyDataFrame(data); df = df.Define(""z"", ""x + y""). print(df.Mean(""z"").GetValue()) # Returns 7.0; ```. The feature plays well along with the `RDataFrame.AsNumpy` feature:. ```python; import ROOT. df = ROOT.ROOT.RDataFrame(10).Define(""x"", ""(int)rdfentry_""); data = df.AsNumpy(). df2 = ROOT.ROOT.RDF.MakeNumpyDataFrame(data); df2.Snapshot(""tree"", ""file.root""); ```. TODO:. - [x] Figure out how to install the header needed for the `NumyDataSource`; - [x] How to call the header (current name `MakeNumpyDataFrame.hxx`)? We should put it in a scope.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3669
https://github.com/root-project/root/pull/3669:752,Deployability,install,install,752,"This PR supersedes #3424. The reference counting is greatly improved and the data is kept alive until the datasource dies, which gets delete at the end of the lifetime of the computational graph. See here for the use-case:. ```python; import ROOT; import numpy. data = {; ""x"": numpy.array([1, 2, 3]),; ""y"": numpy.array([4, 5, 6]); }. df = ROOT.ROOT.RDF.MakeNumpyDataFrame(data); df = df.Define(""z"", ""x + y""). print(df.Mean(""z"").GetValue()) # Returns 7.0; ```. The feature plays well along with the `RDataFrame.AsNumpy` feature:. ```python; import ROOT. df = ROOT.ROOT.RDataFrame(10).Define(""x"", ""(int)rdfentry_""); data = df.AsNumpy(). df2 = ROOT.ROOT.RDF.MakeNumpyDataFrame(data); df2.Snapshot(""tree"", ""file.root""); ```. TODO:. - [x] Figure out how to install the header needed for the `NumyDataSource`; - [x] How to call the header (current name `MakeNumpyDataFrame.hxx`)? We should put it in a scope.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3669
https://github.com/root-project/root/pull/3670:50,Integrability,interface,interface,50,"Add `long long` and `unsigned long long` to array interface. In PyROOT, these types are normalized to the ROOT types `Long64_t` and `ULong64_t`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3670
https://github.com/root-project/root/pull/3683:2,Testability,test,test,2,"A test is still missing, I'll add it.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3683
https://github.com/root-project/root/pull/3687:100,Availability,redundant,redundant,100,This patch makes the implementation reusable and ready to configure it such; that we can remove the redundant information for modules.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3687
https://github.com/root-project/root/pull/3687:5,Deployability,patch,patch,5,This patch makes the implementation reusable and ready to configure it such; that we can remove the redundant information for modules.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3687
https://github.com/root-project/root/pull/3687:58,Modifiability,config,configure,58,This patch makes the implementation reusable and ready to configure it such; that we can remove the redundant information for modules.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3687
https://github.com/root-project/root/pull/3687:100,Safety,redund,redundant,100,This patch makes the implementation reusable and ready to configure it such; that we can remove the redundant information for modules.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3687
https://github.com/root-project/root/pull/3691:125,Integrability,depend,dependent,125,Moved TPDGCode.h (used in 'pythia6' and 'pythia8') from 'vmc' to to 'eg'; this makes all other libraries in 'montecarlo' not dependent on 'vmc',MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3691
https://github.com/root-project/root/pull/3694:321,Testability,test,test,321,"Please have a look at this simplification commit. . I am not 100% happy with the new names I have introduced. A similiar commit should be made for Classification as well. The EvaluateAllMethods functions is still a monster. As for the modification in the AdaBoost: that is the only untested change in this commit (please test the change). For easier reviewing, I have separated this pull in 4 commits. The clang-format just changes whitespace. The main commit is ""[TMVA] Simplify code for regression summary"". Why this commit?; ##############; Reason was the wrong order of results. There were not ordered by RMS. Looking at the code revealed the mess :-)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3694
https://github.com/root-project/root/pull/3694:27,Usability,simpl,simplification,27,"Please have a look at this simplification commit. . I am not 100% happy with the new names I have introduced. A similiar commit should be made for Classification as well. The EvaluateAllMethods functions is still a monster. As for the modification in the AdaBoost: that is the only untested change in this commit (please test the change). For easier reviewing, I have separated this pull in 4 commits. The clang-format just changes whitespace. The main commit is ""[TMVA] Simplify code for regression summary"". Why this commit?; ##############; Reason was the wrong order of results. There were not ordered by RMS. Looking at the code revealed the mess :-)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3694
https://github.com/root-project/root/pull/3694:471,Usability,Simpl,Simplify,471,"Please have a look at this simplification commit. . I am not 100% happy with the new names I have introduced. A similiar commit should be made for Classification as well. The EvaluateAllMethods functions is still a monster. As for the modification in the AdaBoost: that is the only untested change in this commit (please test the change). For easier reviewing, I have separated this pull in 4 commits. The clang-format just changes whitespace. The main commit is ""[TMVA] Simplify code for regression summary"". Why this commit?; ##############; Reason was the wrong order of results. There were not ordered by RMS. Looking at the code revealed the mess :-)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3694
https://github.com/root-project/root/pull/3695:5,Deployability,patch,patch,5,This patch actually loads the modulemap as previously it wrongly detected; it was already loaded.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3695
https://github.com/root-project/root/pull/3695:20,Performance,load,loads,20,This patch actually loads the modulemap as previously it wrongly detected; it was already loaded.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3695
https://github.com/root-project/root/pull/3695:90,Performance,load,loaded,90,This patch actually loads the modulemap as previously it wrongly detected; it was already loaded.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3695
https://github.com/root-project/root/pull/3695:65,Safety,detect,detected,65,This patch actually loads the modulemap as previously it wrongly detected; it was already loaded.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3695
https://github.com/root-project/root/pull/3702:201,Availability,error,error,201,"Base classes for attributes defined in gpad, but also some classes like; RPad uses line or fill attributes. Later attributes can be extracted; into separate library. Should resolve circular dependency error, detected only on Windows",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3702
https://github.com/root-project/root/pull/3702:190,Integrability,depend,dependency,190,"Base classes for attributes defined in gpad, but also some classes like; RPad uses line or fill attributes. Later attributes can be extracted; into separate library. Should resolve circular dependency error, detected only on Windows",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3702
https://github.com/root-project/root/pull/3702:208,Safety,detect,detected,208,"Base classes for attributes defined in gpad, but also some classes like; RPad uses line or fill attributes. Later attributes can be extracted; into separate library. Should resolve circular dependency error, detected only on Windows",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3702
https://github.com/root-project/root/pull/3703:248,Availability,error,error,248,Latest binary of Apache Arrow actually has test-utils.h in arrow/compute/. [ 94%] Building CXX object tree/dataframe/test/CMakeFiles/dataframe_interface.dir/dataframe_interface.cxx.o; /.../root/tree/dataframe/test/datasource_arrow.cxx:14:10: fatal error: arrow/test-util.h: No such file or directory; #include <arrow/test-util.h>; ^~~~~~~~~~~~~~~~~~~; compilation terminated.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3703
https://github.com/root-project/root/pull/3703:43,Testability,test,test-utils,43,Latest binary of Apache Arrow actually has test-utils.h in arrow/compute/. [ 94%] Building CXX object tree/dataframe/test/CMakeFiles/dataframe_interface.dir/dataframe_interface.cxx.o; /.../root/tree/dataframe/test/datasource_arrow.cxx:14:10: fatal error: arrow/test-util.h: No such file or directory; #include <arrow/test-util.h>; ^~~~~~~~~~~~~~~~~~~; compilation terminated.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3703
https://github.com/root-project/root/pull/3703:117,Testability,test,test,117,Latest binary of Apache Arrow actually has test-utils.h in arrow/compute/. [ 94%] Building CXX object tree/dataframe/test/CMakeFiles/dataframe_interface.dir/dataframe_interface.cxx.o; /.../root/tree/dataframe/test/datasource_arrow.cxx:14:10: fatal error: arrow/test-util.h: No such file or directory; #include <arrow/test-util.h>; ^~~~~~~~~~~~~~~~~~~; compilation terminated.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3703
https://github.com/root-project/root/pull/3703:209,Testability,test,test,209,Latest binary of Apache Arrow actually has test-utils.h in arrow/compute/. [ 94%] Building CXX object tree/dataframe/test/CMakeFiles/dataframe_interface.dir/dataframe_interface.cxx.o; /.../root/tree/dataframe/test/datasource_arrow.cxx:14:10: fatal error: arrow/test-util.h: No such file or directory; #include <arrow/test-util.h>; ^~~~~~~~~~~~~~~~~~~; compilation terminated.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3703
https://github.com/root-project/root/pull/3703:261,Testability,test,test-util,261,Latest binary of Apache Arrow actually has test-utils.h in arrow/compute/. [ 94%] Building CXX object tree/dataframe/test/CMakeFiles/dataframe_interface.dir/dataframe_interface.cxx.o; /.../root/tree/dataframe/test/datasource_arrow.cxx:14:10: fatal error: arrow/test-util.h: No such file or directory; #include <arrow/test-util.h>; ^~~~~~~~~~~~~~~~~~~; compilation terminated.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3703
https://github.com/root-project/root/pull/3703:317,Testability,test,test-util,317,Latest binary of Apache Arrow actually has test-utils.h in arrow/compute/. [ 94%] Building CXX object tree/dataframe/test/CMakeFiles/dataframe_interface.dir/dataframe_interface.cxx.o; /.../root/tree/dataframe/test/datasource_arrow.cxx:14:10: fatal error: arrow/test-util.h: No such file or directory; #include <arrow/test-util.h>; ^~~~~~~~~~~~~~~~~~~; compilation terminated.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3703
https://github.com/root-project/root/pull/3704:113,Testability,test,tests,113,"Problem is visible only on CERN VM infrastructure and currently is under investigation, for 32b Docker container tests are passing.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3704
https://github.com/root-project/root/pull/3707:911,Integrability,message,message,911,"Dear ROOT maintainers, . The TTreeSQL class seems a bit broken. ; - It does not support sqlite (which nowadays might be the most likely format someone might use a TTree for) because of the way it parses columns. ; - Some of the data type conversions don't make sense to me (but maybe I misunderstand). In particular the string conversions don't seem like they'd work. . Here is a commit to address those issues. I wanted to also add proper support for database date/datetime/timestamp types (right now I turn them into a string) but I was not sure how to do that. I think what would work is to have an e.g. TDateSQL class that uses a TString for storage (since I believe that's what the SQL API right now would give us) that could then be transparently converted to TDatime or TTimeStamp as needed. This would be easy to implement, but I have not yet because there must be a better way... . Below is the commit message. There are also a few typo fixes that I included. . This commit has a few changes:; -Column names are now obtained from the Table metadata, ensuring that sqlite will work properly; -Variable length strings are properly supported (using TString); -The data type mapping was modified to make a bit more sense (in my opinion), but could still use some work.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3707
https://github.com/root-project/root/pull/3707:1101,Modifiability,Variab,Variable,1101,"Dear ROOT maintainers, . The TTreeSQL class seems a bit broken. ; - It does not support sqlite (which nowadays might be the most likely format someone might use a TTree for) because of the way it parses columns. ; - Some of the data type conversions don't make sense to me (but maybe I misunderstand). In particular the string conversions don't seem like they'd work. . Here is a commit to address those issues. I wanted to also add proper support for database date/datetime/timestamp types (right now I turn them into a string) but I was not sure how to do that. I think what would work is to have an e.g. TDateSQL class that uses a TString for storage (since I believe that's what the SQL API right now would give us) that could then be transparently converted to TDatime or TTimeStamp as needed. This would be easy to implement, but I have not yet because there must be a better way... . Below is the commit message. There are also a few typo fixes that I included. . This commit has a few changes:; -Column names are now obtained from the Table metadata, ensuring that sqlite will work properly; -Variable length strings are properly supported (using TString); -The data type mapping was modified to make a bit more sense (in my opinion), but could still use some work.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3707
https://github.com/root-project/root/pull/3714:44,Performance,load,loaded,44,"Currently modules in ACLiC are not properly loaded, that's why we; suppress the diagnostic if the library was ACLiC-generated.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3714
https://github.com/root-project/root/pull/3722:0,Modifiability,Variab,Variables,0,Variables are detected as used initialized if initialization is done via; a call to the interpreter.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3722
https://github.com/root-project/root/pull/3722:14,Safety,detect,detected,14,Variables are detected as used initialized if initialization is done via; a call to the interpreter.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3722
https://github.com/root-project/root/pull/3726:115,Security,access,accesses,115,This prevents the vector to be reallocated if the size exceeds the capacity of; the vector causing invalid pointer accesses. Fixes ROOT-7749. Backport requested https://sft.its.cern.ch/jira/browse/ROOT-10080,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3726
https://github.com/root-project/root/pull/3727:115,Security,access,accesses,115,This prevents the vector to be reallocated if the size exceeds the capacity of; the vector causing invalid pointer accesses. Fixes ROOT-7749. Backport requested https://sft.its.cern.ch/jira/browse/ROOT-10080,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3727
https://github.com/root-project/root/pull/3728:115,Security,access,accesses,115,This prevents the vector to be reallocated if the size exceeds the capacity of; the vector causing invalid pointer accesses. Fixes ROOT-7749. Backport requested in https://sft.its.cern.ch/jira/browse/ROOT-10080,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3728
https://github.com/root-project/root/pull/3731:292,Availability,error,error,292,"The `RPyROOTApplication` is a `TApplication` that sets up the nuts and bolts for interactive ROOT use from Python, closely following `TRint`. This PR adds the basic behaviour for `TApplication` implemented in C++, i.e. parsing of arguments, configuration of some ROOT globals and setup of an error message handler that is able to translate ROOT warnings into Python warnings. The custom parsing of arguments can be disabled by the user by specifying a configuration option after importing ROOT:; ```python; import ROOT; ROOT.PyConfig.IgnoreCommandLineOptions = True; ```. Moreover, this PR also brings in some logic that is located in `ROOT.py` in the current PyROOT. Such logic makes it possible to use ROOT interactive graphics from Python. The graphics are activated only if the batch mode is off, and they are configured by means of hooks: no thread is explicitly created to process the GUI events as before. The batch mode can be activated by doing:; ```python; import ROOT; ROOT.gROOT.SetBatch(True); ```; or in the command line:; ```bash; > python my_script.py -b; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3731
https://github.com/root-project/root/pull/3731:241,Deployability,configurat,configuration,241,"The `RPyROOTApplication` is a `TApplication` that sets up the nuts and bolts for interactive ROOT use from Python, closely following `TRint`. This PR adds the basic behaviour for `TApplication` implemented in C++, i.e. parsing of arguments, configuration of some ROOT globals and setup of an error message handler that is able to translate ROOT warnings into Python warnings. The custom parsing of arguments can be disabled by the user by specifying a configuration option after importing ROOT:; ```python; import ROOT; ROOT.PyConfig.IgnoreCommandLineOptions = True; ```. Moreover, this PR also brings in some logic that is located in `ROOT.py` in the current PyROOT. Such logic makes it possible to use ROOT interactive graphics from Python. The graphics are activated only if the batch mode is off, and they are configured by means of hooks: no thread is explicitly created to process the GUI events as before. The batch mode can be activated by doing:; ```python; import ROOT; ROOT.gROOT.SetBatch(True); ```; or in the command line:; ```bash; > python my_script.py -b; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3731
https://github.com/root-project/root/pull/3731:452,Deployability,configurat,configuration,452,"The `RPyROOTApplication` is a `TApplication` that sets up the nuts and bolts for interactive ROOT use from Python, closely following `TRint`. This PR adds the basic behaviour for `TApplication` implemented in C++, i.e. parsing of arguments, configuration of some ROOT globals and setup of an error message handler that is able to translate ROOT warnings into Python warnings. The custom parsing of arguments can be disabled by the user by specifying a configuration option after importing ROOT:; ```python; import ROOT; ROOT.PyConfig.IgnoreCommandLineOptions = True; ```. Moreover, this PR also brings in some logic that is located in `ROOT.py` in the current PyROOT. Such logic makes it possible to use ROOT interactive graphics from Python. The graphics are activated only if the batch mode is off, and they are configured by means of hooks: no thread is explicitly created to process the GUI events as before. The batch mode can be activated by doing:; ```python; import ROOT; ROOT.gROOT.SetBatch(True); ```; or in the command line:; ```bash; > python my_script.py -b; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3731
https://github.com/root-project/root/pull/3731:298,Integrability,message,message,298,"The `RPyROOTApplication` is a `TApplication` that sets up the nuts and bolts for interactive ROOT use from Python, closely following `TRint`. This PR adds the basic behaviour for `TApplication` implemented in C++, i.e. parsing of arguments, configuration of some ROOT globals and setup of an error message handler that is able to translate ROOT warnings into Python warnings. The custom parsing of arguments can be disabled by the user by specifying a configuration option after importing ROOT:; ```python; import ROOT; ROOT.PyConfig.IgnoreCommandLineOptions = True; ```. Moreover, this PR also brings in some logic that is located in `ROOT.py` in the current PyROOT. Such logic makes it possible to use ROOT interactive graphics from Python. The graphics are activated only if the batch mode is off, and they are configured by means of hooks: no thread is explicitly created to process the GUI events as before. The batch mode can be activated by doing:; ```python; import ROOT; ROOT.gROOT.SetBatch(True); ```; or in the command line:; ```bash; > python my_script.py -b; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3731
https://github.com/root-project/root/pull/3731:241,Modifiability,config,configuration,241,"The `RPyROOTApplication` is a `TApplication` that sets up the nuts and bolts for interactive ROOT use from Python, closely following `TRint`. This PR adds the basic behaviour for `TApplication` implemented in C++, i.e. parsing of arguments, configuration of some ROOT globals and setup of an error message handler that is able to translate ROOT warnings into Python warnings. The custom parsing of arguments can be disabled by the user by specifying a configuration option after importing ROOT:; ```python; import ROOT; ROOT.PyConfig.IgnoreCommandLineOptions = True; ```. Moreover, this PR also brings in some logic that is located in `ROOT.py` in the current PyROOT. Such logic makes it possible to use ROOT interactive graphics from Python. The graphics are activated only if the batch mode is off, and they are configured by means of hooks: no thread is explicitly created to process the GUI events as before. The batch mode can be activated by doing:; ```python; import ROOT; ROOT.gROOT.SetBatch(True); ```; or in the command line:; ```bash; > python my_script.py -b; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3731
https://github.com/root-project/root/pull/3731:452,Modifiability,config,configuration,452,"The `RPyROOTApplication` is a `TApplication` that sets up the nuts and bolts for interactive ROOT use from Python, closely following `TRint`. This PR adds the basic behaviour for `TApplication` implemented in C++, i.e. parsing of arguments, configuration of some ROOT globals and setup of an error message handler that is able to translate ROOT warnings into Python warnings. The custom parsing of arguments can be disabled by the user by specifying a configuration option after importing ROOT:; ```python; import ROOT; ROOT.PyConfig.IgnoreCommandLineOptions = True; ```. Moreover, this PR also brings in some logic that is located in `ROOT.py` in the current PyROOT. Such logic makes it possible to use ROOT interactive graphics from Python. The graphics are activated only if the batch mode is off, and they are configured by means of hooks: no thread is explicitly created to process the GUI events as before. The batch mode can be activated by doing:; ```python; import ROOT; ROOT.gROOT.SetBatch(True); ```; or in the command line:; ```bash; > python my_script.py -b; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3731
https://github.com/root-project/root/pull/3731:814,Modifiability,config,configured,814,"The `RPyROOTApplication` is a `TApplication` that sets up the nuts and bolts for interactive ROOT use from Python, closely following `TRint`. This PR adds the basic behaviour for `TApplication` implemented in C++, i.e. parsing of arguments, configuration of some ROOT globals and setup of an error message handler that is able to translate ROOT warnings into Python warnings. The custom parsing of arguments can be disabled by the user by specifying a configuration option after importing ROOT:; ```python; import ROOT; ROOT.PyConfig.IgnoreCommandLineOptions = True; ```. Moreover, this PR also brings in some logic that is located in `ROOT.py` in the current PyROOT. Such logic makes it possible to use ROOT interactive graphics from Python. The graphics are activated only if the batch mode is off, and they are configured by means of hooks: no thread is explicitly created to process the GUI events as before. The batch mode can be activated by doing:; ```python; import ROOT; ROOT.gROOT.SetBatch(True); ```; or in the command line:; ```bash; > python my_script.py -b; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3731
https://github.com/root-project/root/pull/3731:610,Testability,log,logic,610,"The `RPyROOTApplication` is a `TApplication` that sets up the nuts and bolts for interactive ROOT use from Python, closely following `TRint`. This PR adds the basic behaviour for `TApplication` implemented in C++, i.e. parsing of arguments, configuration of some ROOT globals and setup of an error message handler that is able to translate ROOT warnings into Python warnings. The custom parsing of arguments can be disabled by the user by specifying a configuration option after importing ROOT:; ```python; import ROOT; ROOT.PyConfig.IgnoreCommandLineOptions = True; ```. Moreover, this PR also brings in some logic that is located in `ROOT.py` in the current PyROOT. Such logic makes it possible to use ROOT interactive graphics from Python. The graphics are activated only if the batch mode is off, and they are configured by means of hooks: no thread is explicitly created to process the GUI events as before. The batch mode can be activated by doing:; ```python; import ROOT; ROOT.gROOT.SetBatch(True); ```; or in the command line:; ```bash; > python my_script.py -b; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3731
https://github.com/root-project/root/pull/3731:673,Testability,log,logic,673,"The `RPyROOTApplication` is a `TApplication` that sets up the nuts and bolts for interactive ROOT use from Python, closely following `TRint`. This PR adds the basic behaviour for `TApplication` implemented in C++, i.e. parsing of arguments, configuration of some ROOT globals and setup of an error message handler that is able to translate ROOT warnings into Python warnings. The custom parsing of arguments can be disabled by the user by specifying a configuration option after importing ROOT:; ```python; import ROOT; ROOT.PyConfig.IgnoreCommandLineOptions = True; ```. Moreover, this PR also brings in some logic that is located in `ROOT.py` in the current PyROOT. Such logic makes it possible to use ROOT interactive graphics from Python. The graphics are activated only if the batch mode is off, and they are configured by means of hooks: no thread is explicitly created to process the GUI events as before. The batch mode can be activated by doing:; ```python; import ROOT; ROOT.gROOT.SetBatch(True); ```; or in the command line:; ```bash; > python my_script.py -b; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3731
https://github.com/root-project/root/pull/3733:7,Availability,failure,failures,7,Fixing failures in stress-test:; `; Error in <TCling::RegisterModule>: cannot find dictionary module libEvent_rdict.pcm; `,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3733
https://github.com/root-project/root/pull/3733:36,Availability,Error,Error,36,Fixing failures in stress-test:; `; Error in <TCling::RegisterModule>: cannot find dictionary module libEvent_rdict.pcm; `,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3733
https://github.com/root-project/root/pull/3733:26,Testability,test,test,26,Fixing failures in stress-test:; `; Error in <TCling::RegisterModule>: cannot find dictionary module libEvent_rdict.pcm; `,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3733
https://github.com/root-project/root/pull/3734:101,Availability,failure,failures,101,"…overy."". This reverts commit 77b8755f36e2313b757fed4068114c28caa16de1. Breaks windows, and has some failures in stress tests. Investigating.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3734
https://github.com/root-project/root/pull/3734:120,Testability,test,tests,120,"…overy."". This reverts commit 77b8755f36e2313b757fed4068114c28caa16de1. Breaks windows, and has some failures in stress tests. Investigating.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3734
https://github.com/root-project/root/pull/3738:153,Deployability,update,updated,153,"[ROOT-10093] When generating events with simultaneous PDFs that contain; further simultaneous PDFs, the category tags of each generated event have to be updated to yield a usable dataset.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3738
https://github.com/root-project/root/pull/3738:172,Usability,usab,usable,172,"[ROOT-10093] When generating events with simultaneous PDFs that contain; further simultaneous PDFs, the category tags of each generated event have to be updated to yield a usable dataset.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3738
https://github.com/root-project/root/pull/3739:151,Deployability,update,updated,151,"[ROOT-10093] When generating events with simultaneous PDFs that contain; simultaneous PDFs as children, the category tags for the children have to; be updated before being written into a dataset. Otherwise, a dataset with; wrong category labels is obtained. (cherry picked from commit 0a107acffd708818361dfbfefc2369fa45e9306f)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3739
https://github.com/root-project/root/pull/3742:147,Deployability,update,updated,147,"When the mempool for RooArgSet was modernised to prevent crashes during the teardown of; global statics, the macro name for RooSetProxy didn't get updated. Therefore, new-ed; RooSetProxys will also end up in the mempool, which was not intended.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3742
https://github.com/root-project/root/pull/3743:9,Testability,test,test,9,"increase test coverage accordingly and add 2 tutorials, one in C++ and one in Python.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3743
https://github.com/root-project/root/pull/3744:168,Deployability,update,update,168,"Now TWebCanvas only able to serve data for the web clients, but not allowed to change data in the TCanvas. This means:; - no new objects; - no context menu; - no range update; - no any attributes updates; - no any command execution. Full-functional implementation, based on TWebCanvas, will be maintained outside ROOT here:; https://github.com/linev/go4/tree/master/webgui6",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3744
https://github.com/root-project/root/pull/3744:196,Deployability,update,updates,196,"Now TWebCanvas only able to serve data for the web clients, but not allowed to change data in the TCanvas. This means:; - no new objects; - no context menu; - no range update; - no any attributes updates; - no any command execution. Full-functional implementation, based on TWebCanvas, will be maintained outside ROOT here:; https://github.com/linev/go4/tree/master/webgui6",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3744
https://github.com/root-project/root/pull/3745:66,Integrability,message,message,66,This can be done at compile time with a static_assert too but the message offered to the user is not as clear.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3745
https://github.com/root-project/root/pull/3745:104,Usability,clear,clear,104,This can be done at compile time with a static_assert too but the message offered to the user is not as clear.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3745
https://github.com/root-project/root/pull/3746:7,Availability,error,error,7,Prompt error message and stop the event loop instead.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3746
https://github.com/root-project/root/pull/3746:13,Integrability,message,message,13,Prompt error message and stop the event loop instead.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3746
https://github.com/root-project/root/pull/3747:399,Availability,redundant,redundant,399,We implement a workaround for ctest. ROOT_ADD_TEST cmake macro adds a test executable by invoking CMAKE_COMMAND -DCMD=... This breaks our FindLibraryName function which depends on dladdr and the cmake executable confuses it. This branch is not taken outside of ctest where the code just works. This was broken before but worked because we scanned all possible dynamic paths for rdict files which is redundant.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3747
https://github.com/root-project/root/pull/3747:169,Integrability,depend,depends,169,We implement a workaround for ctest. ROOT_ADD_TEST cmake macro adds a test executable by invoking CMAKE_COMMAND -DCMD=... This breaks our FindLibraryName function which depends on dladdr and the cmake executable confuses it. This branch is not taken outside of ctest where the code just works. This was broken before but worked because we scanned all possible dynamic paths for rdict files which is redundant.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3747
https://github.com/root-project/root/pull/3747:399,Safety,redund,redundant,399,We implement a workaround for ctest. ROOT_ADD_TEST cmake macro adds a test executable by invoking CMAKE_COMMAND -DCMD=... This breaks our FindLibraryName function which depends on dladdr and the cmake executable confuses it. This branch is not taken outside of ctest where the code just works. This was broken before but worked because we scanned all possible dynamic paths for rdict files which is redundant.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3747
https://github.com/root-project/root/pull/3747:70,Testability,test,test,70,We implement a workaround for ctest. ROOT_ADD_TEST cmake macro adds a test executable by invoking CMAKE_COMMAND -DCMD=... This breaks our FindLibraryName function which depends on dladdr and the cmake executable confuses it. This branch is not taken outside of ctest where the code just works. This was broken before but worked because we scanned all possible dynamic paths for rdict files which is redundant.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3747
https://github.com/root-project/root/pull/3753:11,Deployability,update,update,11,Plus small update in ui5 code - use JSROOT inspector.; Update 6.18 release notes,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3753
https://github.com/root-project/root/pull/3753:55,Deployability,Update,Update,55,Plus small update in ui5 code - use JSROOT inspector.; Update 6.18 release notes,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3753
https://github.com/root-project/root/pull/3753:67,Deployability,release,release,67,Plus small update in ui5 code - use JSROOT inspector.; Update 6.18 release notes,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3753
https://github.com/root-project/root/pull/3757:5,Energy Efficiency,reduce,reduces,5,This reduces dependency on rootmap files,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3757
https://github.com/root-project/root/pull/3757:13,Integrability,depend,dependency,13,This reduces dependency on rootmap files,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3757
https://github.com/root-project/root/pull/3759:227,Modifiability,flexible,flexible,227,"Use exactly the same BrowserModel for implementing hierarchy browser in both components; Code is maintained with RBrowser, Geometry viewer reuses components.; C++ I/O classes also moved to RBrowserItem.hxx, make I/O model more flexible to support fully different items in the future.; Simplify data structures in RBrowser, first sorting approach is shown",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3759
https://github.com/root-project/root/pull/3759:285,Usability,Simpl,Simplify,285,"Use exactly the same BrowserModel for implementing hierarchy browser in both components; Code is maintained with RBrowser, Geometry viewer reuses components.; C++ I/O classes also moved to RBrowserItem.hxx, make I/O model more flexible to support fully different items in the future.; Simplify data structures in RBrowser, first sorting approach is shown",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3759
https://github.com/root-project/root/pull/3760:14,Safety,avoid,avoid,14,new branch to avoid warning about missing roottest PR.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3760
https://github.com/root-project/root/pull/3763:98,Deployability,install,installed,98,"This syncs `core/imt/CMakeLists.txt` with the `master` branch, which does not have the problem of installed ROOT pointing to the build directory.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3763
https://github.com/root-project/root/pull/3764:6,Deployability,update,update,6,"I may update with more commits later, but feel free to review current changes. Fixes [ROOT-9086](https://sft.its.cern.ch/jira/browse/ROOT-9086).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3764
https://github.com/root-project/root/pull/3765:53,Availability,redundant,redundant,53,"When composing the expressions to jit autoparsing is redundant as we; know what and when to synthesize. This patch has two effects, first it limits the recursive behavior of; autoparse and autoload (useful for modules); and secondly avoids deep call; chains of virtual function calls. EDIT: Rationale -- I was working on a new, cxxmodules-based implementation of TCling::GetClassSharedLibs which does not rely on rootmap files. I had to debug a few failures in RDF and I noticed the recursive calls to autoparse and autoload always without success. I thought it might be a simplification (and performance optimization) if we disabled that part.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3765
https://github.com/root-project/root/pull/3765:449,Availability,failure,failures,449,"When composing the expressions to jit autoparsing is redundant as we; know what and when to synthesize. This patch has two effects, first it limits the recursive behavior of; autoparse and autoload (useful for modules); and secondly avoids deep call; chains of virtual function calls. EDIT: Rationale -- I was working on a new, cxxmodules-based implementation of TCling::GetClassSharedLibs which does not rely on rootmap files. I had to debug a few failures in RDF and I noticed the recursive calls to autoparse and autoload always without success. I thought it might be a simplification (and performance optimization) if we disabled that part.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3765
https://github.com/root-project/root/pull/3765:109,Deployability,patch,patch,109,"When composing the expressions to jit autoparsing is redundant as we; know what and when to synthesize. This patch has two effects, first it limits the recursive behavior of; autoparse and autoload (useful for modules); and secondly avoids deep call; chains of virtual function calls. EDIT: Rationale -- I was working on a new, cxxmodules-based implementation of TCling::GetClassSharedLibs which does not rely on rootmap files. I had to debug a few failures in RDF and I noticed the recursive calls to autoparse and autoload always without success. I thought it might be a simplification (and performance optimization) if we disabled that part.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3765
https://github.com/root-project/root/pull/3765:593,Performance,perform,performance,593,"When composing the expressions to jit autoparsing is redundant as we; know what and when to synthesize. This patch has two effects, first it limits the recursive behavior of; autoparse and autoload (useful for modules); and secondly avoids deep call; chains of virtual function calls. EDIT: Rationale -- I was working on a new, cxxmodules-based implementation of TCling::GetClassSharedLibs which does not rely on rootmap files. I had to debug a few failures in RDF and I noticed the recursive calls to autoparse and autoload always without success. I thought it might be a simplification (and performance optimization) if we disabled that part.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3765
https://github.com/root-project/root/pull/3765:605,Performance,optimiz,optimization,605,"When composing the expressions to jit autoparsing is redundant as we; know what and when to synthesize. This patch has two effects, first it limits the recursive behavior of; autoparse and autoload (useful for modules); and secondly avoids deep call; chains of virtual function calls. EDIT: Rationale -- I was working on a new, cxxmodules-based implementation of TCling::GetClassSharedLibs which does not rely on rootmap files. I had to debug a few failures in RDF and I noticed the recursive calls to autoparse and autoload always without success. I thought it might be a simplification (and performance optimization) if we disabled that part.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3765
https://github.com/root-project/root/pull/3765:53,Safety,redund,redundant,53,"When composing the expressions to jit autoparsing is redundant as we; know what and when to synthesize. This patch has two effects, first it limits the recursive behavior of; autoparse and autoload (useful for modules); and secondly avoids deep call; chains of virtual function calls. EDIT: Rationale -- I was working on a new, cxxmodules-based implementation of TCling::GetClassSharedLibs which does not rely on rootmap files. I had to debug a few failures in RDF and I noticed the recursive calls to autoparse and autoload always without success. I thought it might be a simplification (and performance optimization) if we disabled that part.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3765
https://github.com/root-project/root/pull/3765:233,Safety,avoid,avoids,233,"When composing the expressions to jit autoparsing is redundant as we; know what and when to synthesize. This patch has two effects, first it limits the recursive behavior of; autoparse and autoload (useful for modules); and secondly avoids deep call; chains of virtual function calls. EDIT: Rationale -- I was working on a new, cxxmodules-based implementation of TCling::GetClassSharedLibs which does not rely on rootmap files. I had to debug a few failures in RDF and I noticed the recursive calls to autoparse and autoload always without success. I thought it might be a simplification (and performance optimization) if we disabled that part.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3765
https://github.com/root-project/root/pull/3765:573,Usability,simpl,simplification,573,"When composing the expressions to jit autoparsing is redundant as we; know what and when to synthesize. This patch has two effects, first it limits the recursive behavior of; autoparse and autoload (useful for modules); and secondly avoids deep call; chains of virtual function calls. EDIT: Rationale -- I was working on a new, cxxmodules-based implementation of TCling::GetClassSharedLibs which does not rely on rootmap files. I had to debug a few failures in RDF and I noticed the recursive calls to autoparse and autoload always without success. I thought it might be a simplification (and performance optimization) if we disabled that part.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3765
https://github.com/root-project/root/pull/3769:98,Testability,log,logic,98,Note the separate commits are intended to simplify bisecting if necessary as this is very fragile logic in ROOT.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3769
https://github.com/root-project/root/pull/3769:42,Usability,simpl,simplify,42,Note the separate commits are intended to simplify bisecting if necessary as this is very fragile logic in ROOT.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3769
https://github.com/root-project/root/pull/3774:34,Integrability,depend,depends,34,This PR has misc improvements and depends on PR #3769.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3774
https://github.com/root-project/root/pull/3775:11,Performance,scalab,scalable,11,"use a more scalable implementation for RooChebychev which allows use of; Chebychev polynomial of arbitrarily high orders; also the extra effort; for every new order used is constant, so the effort (CPU) for evaluating; a RooChebychev grows linearly with the highest order Chebychev order; used, and comes in at only a couple of FLOPS per order (getting the; value of the coefficients is likely much more expensive). FMA is used if supported by the underlying architecture/compiler,; otherwise the code falls back to normal floating point arithmetic. RooChebychev is used in the stressRooFit test, which continues to run just fine.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3775
https://github.com/root-project/root/pull/3775:591,Testability,test,test,591,"use a more scalable implementation for RooChebychev which allows use of; Chebychev polynomial of arbitrarily high orders; also the extra effort; for every new order used is constant, so the effort (CPU) for evaluating; a RooChebychev grows linearly with the highest order Chebychev order; used, and comes in at only a couple of FLOPS per order (getting the; value of the coefficients is likely much more expensive). FMA is used if supported by the underlying architecture/compiler,; otherwise the code falls back to normal floating point arithmetic. RooChebychev is used in the stressRooFit test, which continues to run just fine.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3775
https://github.com/root-project/root/pull/3776:5,Deployability,patch,patch,5,"This patch came from Sean Benson and Wouter Verkerke, and is needed; to allow LHCb's P2VV-style analyses to have different time acceptances; for different categories of events. All tests continue to pass.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3776
https://github.com/root-project/root/pull/3776:181,Testability,test,tests,181,"This patch came from Sean Benson and Wouter Verkerke, and is needed; to allow LHCb's P2VV-style analyses to have different time acceptances; for different categories of events. All tests continue to pass.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3776
https://github.com/root-project/root/pull/3781:107,Security,access,accessors,107,Protection in TGDMLWrite for optical surfaces for nodes not connected to the geometry hierarchy. Added few accessors for material properties,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3781
https://github.com/root-project/root/pull/3783:47,Deployability,release,release,47,@etejedor Shall we add a PyROOT section to the release notes?,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3783
https://github.com/root-project/root/pull/3785:199,Deployability,release,released,199,"Locking on a child view while inside the parent's -drawRect:; was always looking horrendously (alas, this is how ROOT text; rendering is implemented in TGTextView et al.). Finally,; with macOS 10.14 released, after all these years of horrors, it; stopped working at all. While it's still quite crappy that; TGTextView tries to render text in its child window - TGViewFrame; - it does not mean literally we physically have to do this. A; little cheat and we render in the correct view instead. This PR fixes ROOT-10052 and ROOT-9976",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3785
https://github.com/root-project/root/pull/3789:19,Modifiability,refactor,refactoring,19,"this PR contains a refactoring and a fix for the issue, which is a workaround for another bug which causes it and is unrelated (ROOT-10113) :); For now, the TTree case only is covered and the TChain one is still disabled, but it's good to start testing the code!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3789
https://github.com/root-project/root/pull/3789:245,Testability,test,testing,245,"this PR contains a refactoring and a fix for the issue, which is a workaround for another bug which causes it and is unrelated (ROOT-10113) :); For now, the TTree case only is covered and the TChain one is still disabled, but it's good to start testing the code!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3789
https://github.com/root-project/root/pull/3790:5,Safety,avoid,avoids,5,This avoids bloating the history with blank space commits.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3790
https://github.com/root-project/root/pull/3795:22,Testability,test,tested,22,"Previous changes were tested with Qt 5.12, which is very new and very rare up to now.; Plus there are new functions, which were not exists before",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3795
https://github.com/root-project/root/pull/3798:0,Integrability,Depend,Depends,0,Depends on #3043,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3798
https://github.com/root-project/root/pull/3801:137,Availability,error,error,137,On my systems (RHEL7 and Android Termux) PAGE_SIZE is defined to 4096 in /usr/include/sys/user.h . The enum then produces a compile-term error.; Adding this change resolves this error for me.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3801
https://github.com/root-project/root/pull/3801:178,Availability,error,error,178,On my systems (RHEL7 and Android Termux) PAGE_SIZE is defined to 4096 in /usr/include/sys/user.h . The enum then produces a compile-term error.; Adding this change resolves this error for me.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3801
https://github.com/root-project/root/pull/3802:5,Deployability,patch,patch,5,This patch fixes an assertion in the incremental builds.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3802
https://github.com/root-project/root/pull/3802:20,Testability,assert,assertion,20,This patch fixes an assertion in the incremental builds.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3802
https://github.com/root-project/root/pull/3804:117,Deployability,release,release,117,"Deprecate VMC, remove remnant of already removed options, and remove deprecated options not yet removed for the next release. The only remaining option is memstat, which I will do in a separate pull request.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3804
https://github.com/root-project/root/pull/3807:62,Deployability,install,installed,62,This works better for me (i.e. I have multiple clang versions installed and it works as well). Please check that it works for you and let me know so I can merge. The Jenkins builds are not able to actually test this.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3807
https://github.com/root-project/root/pull/3807:206,Testability,test,test,206,This works better for me (i.e. I have multiple clang versions installed and it works as well). Please check that it works for you and let me know so I can merge. The Jenkins builds are not able to actually test this.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3807
https://github.com/root-project/root/pull/3809:55,Deployability,update,updated,55,"Documentation present in the TStatistic files has been updated to match Doxygen syntax. Data members with a little description are now visible in the docs, Class member functions documentation has been; pulled out of their definitions and changed a bit to better explain the algorithms involved.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3809
https://github.com/root-project/root/pull/3810:84,Usability,clear,clear,84,"TF1 objects, created in the TFitEditor, were not destroyed properly.; Also use more clear c++11 syntax for STL containers; Do not generate long names like ""PrevFit-7-PrevFit-5-PrevFit-1"" for fit functions",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3810
https://github.com/root-project/root/pull/3811:70,Deployability,patch,patch,70,"Dropbox folders (among others) can contain parentheses.; Without this patch, ROOT and cling misinterpret those directories as arguments.; Instead, first find the end of the "".x"" line.; If the previous token was a closing paren, we assume that the preceding; tokens (up to the non-nested opening paren) belong to the argument.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3811
https://github.com/root-project/root/pull/3815:232,Deployability,update,updated,232,The TStatistic class now includes computation of minimum and maximum values; of the vector passed to the constructor. These values have been added both to the `Print` and `Merge` functions. The testTStatistic.cxx test file has been updated accordingly to check that the class; correctly computes min and max values.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3815
https://github.com/root-project/root/pull/3815:194,Testability,test,testTStatistic,194,The TStatistic class now includes computation of minimum and maximum values; of the vector passed to the constructor. These values have been added both to the `Print` and `Merge` functions. The testTStatistic.cxx test file has been updated accordingly to check that the class; correctly computes min and max values.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3815
https://github.com/root-project/root/pull/3815:213,Testability,test,test,213,The TStatistic class now includes computation of minimum and maximum values; of the vector passed to the constructor. These values have been added both to the `Print` and `Merge` functions. The testTStatistic.cxx test file has been updated accordingly to check that the class; correctly computes min and max values.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3815
https://github.com/root-project/root/pull/3816:74,Usability,guid,guide,74,There are some grammatical mistakes and cases of misspelling in the users-guide directory. I corrected the misspellings and corrected the grammar in some of the sentences.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3816
https://github.com/root-project/root/pull/3819:41,Deployability,install,install,41,"As a side-effect, this change solves the install problem with a missing; tree/forest/inc directory.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3819
https://github.com/root-project/root/pull/3823:60,Availability,down,down,60,the tutorials look great. This PR aims to further slim them down to make them even better where possible.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3823
https://github.com/root-project/root/pull/3827:351,Integrability,depend,dependencies,351,"Old versions of Vdt (0.4.1 and below) do not export version information, but ROOT needs 0.4.0 at least, because of the vdt/tanh.h header, so we deduce the version based on the existence of that header and require the minimum version that ROOT needs. This file now also creates an imported; target that can be used within ROOT to link against VDT with dependencies taken care of automatically. Fixes [ROOT-9885](https://sft.its.cern.ch/jira/browse/ROOT-9885).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3827
https://github.com/root-project/root/pull/3828:56,Availability,error,errors,56,"Davix 0.6.8 introduced regressions that lead to runtime errors with ROOT, although the code still compiles. The first fixed version is 0.7.1. Fixes: [ROOT-9780](https://sft.its.cern.ch/jira/browse/ROOT-9780). Related issue: [ROOT-9730](https://sft.its.cern.ch/jira/browse/ROOT-9730).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3828
https://github.com/root-project/root/pull/3829:142,Integrability,interface,interface,142,"Remove class hierarchy in RFieldValue. The templated, type-safe; inherited classes made the design vulnerable to slicing, because the; RField interface uses the base class. Instead, we use now templated; constructors and templated member functions in RFieldValue.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3829
https://github.com/root-project/root/pull/3829:65,Modifiability,inherit,inherited,65,"Remove class hierarchy in RFieldValue. The templated, type-safe; inherited classes made the design vulnerable to slicing, because the; RField interface uses the base class. Instead, we use now templated; constructors and templated member functions in RFieldValue.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3829
https://github.com/root-project/root/pull/3829:59,Safety,safe,safe,59,"Remove class hierarchy in RFieldValue. The templated, type-safe; inherited classes made the design vulnerable to slicing, because the; RField interface uses the base class. Instead, we use now templated; constructors and templated member functions in RFieldValue.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3829
https://github.com/root-project/root/pull/3832:152,Testability,test,tests,152,New functionality and fixes in experimental PyROOT and Cppyy to make `roottest-python-cpp-cpp` and `roottest-python-cpp-cpp11` pass. The changes in the tests themselves coming in another PR for roottest:; https://github.com/root-project/roottest/pull/326,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3832
https://github.com/root-project/root/pull/3838:151,Availability,error,error,151,"When building ROOT on slc6, it will detect and use xz (version 4.999.9) provided by OS, which is reported to have compatibility issues (`R__unzipLZMA: error 8 in lzma_code`). The proposed change fixes that by using CMake's own module (present since CMake 3.0.2) for detecting xz *and* checking it's version.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3838
https://github.com/root-project/root/pull/3838:36,Safety,detect,detect,36,"When building ROOT on slc6, it will detect and use xz (version 4.999.9) provided by OS, which is reported to have compatibility issues (`R__unzipLZMA: error 8 in lzma_code`). The proposed change fixes that by using CMake's own module (present since CMake 3.0.2) for detecting xz *and* checking it's version.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3838
https://github.com/root-project/root/pull/3838:266,Safety,detect,detecting,266,"When building ROOT on slc6, it will detect and use xz (version 4.999.9) provided by OS, which is reported to have compatibility issues (`R__unzipLZMA: error 8 in lzma_code`). The proposed change fixes that by using CMake's own module (present since CMake 3.0.2) for detecting xz *and* checking it's version.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3838
https://github.com/root-project/root/pull/3845:204,Usability,simpl,simple,204,"Reverting RVec's SBO implementation until we have a proper fix for the crashes seen in ROOT-10079.; ROOT-10079 also reports the discussion and measurements that motivate the reverts. The reverts were not simple: it's a lot of changes and subsequent unrelated commits overwrote part of them (e.g. a change in implementation of `Combinations`, a renaming of many preprocessor flags from `TVec` to `RVec`). I hope I didn't screw it up.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3845
https://github.com/root-project/root/pull/3849:27,Energy Efficiency,allocate,allocate,27,Calling e.g. Border() will allocate the relevant attribute and return a reference.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3849
https://github.com/root-project/root/pull/3850:437,Availability,avail,available,437,ACLiC now synthesizes a modulemap with a suffix _ACLiC_dict.modulemap. The file contains the source file to be compiled and the corresponding library.; ; The modulemap is then passed to rootcling via -fmodule-map-file= flag to avoid naming clashes with possibly existing other modulemap files.; ; This patch teaches cling to work with the -fmodule-map-file= flag.; ; ACLiC supports automatic inclusion of Rtypes.h (making ClassDef macro available). Modules are built in isolation and are resilient to #include of Rtypes.h at rootcling startup time. We make module Core (containing Rtypes.h) visible via a newly implemented callback. Depends on #3798,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3850
https://github.com/root-project/root/pull/3850:488,Availability,resilien,resilient,488,ACLiC now synthesizes a modulemap with a suffix _ACLiC_dict.modulemap. The file contains the source file to be compiled and the corresponding library.; ; The modulemap is then passed to rootcling via -fmodule-map-file= flag to avoid naming clashes with possibly existing other modulemap files.; ; This patch teaches cling to work with the -fmodule-map-file= flag.; ; ACLiC supports automatic inclusion of Rtypes.h (making ClassDef macro available). Modules are built in isolation and are resilient to #include of Rtypes.h at rootcling startup time. We make module Core (containing Rtypes.h) visible via a newly implemented callback. Depends on #3798,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3850
https://github.com/root-project/root/pull/3850:302,Deployability,patch,patch,302,ACLiC now synthesizes a modulemap with a suffix _ACLiC_dict.modulemap. The file contains the source file to be compiled and the corresponding library.; ; The modulemap is then passed to rootcling via -fmodule-map-file= flag to avoid naming clashes with possibly existing other modulemap files.; ; This patch teaches cling to work with the -fmodule-map-file= flag.; ; ACLiC supports automatic inclusion of Rtypes.h (making ClassDef macro available). Modules are built in isolation and are resilient to #include of Rtypes.h at rootcling startup time. We make module Core (containing Rtypes.h) visible via a newly implemented callback. Depends on #3798,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3850
https://github.com/root-project/root/pull/3850:633,Integrability,Depend,Depends,633,ACLiC now synthesizes a modulemap with a suffix _ACLiC_dict.modulemap. The file contains the source file to be compiled and the corresponding library.; ; The modulemap is then passed to rootcling via -fmodule-map-file= flag to avoid naming clashes with possibly existing other modulemap files.; ; This patch teaches cling to work with the -fmodule-map-file= flag.; ; ACLiC supports automatic inclusion of Rtypes.h (making ClassDef macro available). Modules are built in isolation and are resilient to #include of Rtypes.h at rootcling startup time. We make module Core (containing Rtypes.h) visible via a newly implemented callback. Depends on #3798,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3850
https://github.com/root-project/root/pull/3850:227,Safety,avoid,avoid,227,ACLiC now synthesizes a modulemap with a suffix _ACLiC_dict.modulemap. The file contains the source file to be compiled and the corresponding library.; ; The modulemap is then passed to rootcling via -fmodule-map-file= flag to avoid naming clashes with possibly existing other modulemap files.; ; This patch teaches cling to work with the -fmodule-map-file= flag.; ; ACLiC supports automatic inclusion of Rtypes.h (making ClassDef macro available). Modules are built in isolation and are resilient to #include of Rtypes.h at rootcling startup time. We make module Core (containing Rtypes.h) visible via a newly implemented callback. Depends on #3798,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3850
https://github.com/root-project/root/pull/3851:390,Testability,test,tests,390,"The Johnson PDF is frequently used in LHCb, who mostly implement it using a TFormula.; This has negative impact on speed and the precision for integrals, because these can only be done numerically.; Here, it is added as compiled code, with an optimised generator function that gets around the wasteful accept/reject method, with much more precise analytical integrals, as well as precision tests.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3851
https://github.com/root-project/root/pull/3853:82,Availability,error,error,82,"This fixes ROOT-9839 by computing an optimal stepwise depending on the result fit error. ; Now for parameter which have a very small error the step size is correctly estimated. ; The difference can be seen by fitting a gaussian with very small sigma (~ 10^-5) and computing the; confidence intervals. . Also the fixed parameters are now correctly handled, although before, their contribution was not included due to their zero value in the covariance matrix",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3853
https://github.com/root-project/root/pull/3853:133,Availability,error,error,133,"This fixes ROOT-9839 by computing an optimal stepwise depending on the result fit error. ; Now for parameter which have a very small error the step size is correctly estimated. ; The difference can be seen by fitting a gaussian with very small sigma (~ 10^-5) and computing the; confidence intervals. . Also the fixed parameters are now correctly handled, although before, their contribution was not included due to their zero value in the covariance matrix",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3853
https://github.com/root-project/root/pull/3853:54,Integrability,depend,depending,54,"This fixes ROOT-9839 by computing an optimal stepwise depending on the result fit error. ; Now for parameter which have a very small error the step size is correctly estimated. ; The difference can be seen by fitting a gaussian with very small sigma (~ 10^-5) and computing the; confidence intervals. . Also the fixed parameters are now correctly handled, although before, their contribution was not included due to their zero value in the covariance matrix",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3853
https://github.com/root-project/root/pull/3859:176,Safety,sanity check,sanity checks,176,"HistFactory normally collects histograms automatically, but not if; `HistoToWorkspaceFactoryFast::MakeSingleChannelWorkspace` is used.; This commit fixes this defect, and adds sanity checks.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3859
https://github.com/root-project/root/pull/3860:219,Modifiability,variab,variables,219,"As suggested by Axel:; TGDimension.h: Remove the copy constructors (rely on the compiler generated ones), add default (non virtual) destructors, and remove useless ClassDefs; TGCanvas.cxx, TGListTree.cxx: Remove unused variables (fixes [-Wunused-but-set-variable] warnings)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3860
https://github.com/root-project/root/pull/3860:254,Modifiability,variab,variable,254,"As suggested by Axel:; TGDimension.h: Remove the copy constructors (rely on the compiler generated ones), add default (non virtual) destructors, and remove useless ClassDefs; TGCanvas.cxx, TGListTree.cxx: Remove unused variables (fixes [-Wunused-but-set-variable] warnings)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3860
https://github.com/root-project/root/pull/3864:116,Deployability,patch,patches,116,"This was the intent, the regex was simply broken and did not take the trailing versioning part into account.; Now, -patches as minor "".99"", otherwise as expected.; This can be improved in the future by also adding the commit count to patches, aka 6.16.06.42 for the 42th commit after 6.16.06.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3864
https://github.com/root-project/root/pull/3864:234,Deployability,patch,patches,234,"This was the intent, the regex was simply broken and did not take the trailing versioning part into account.; Now, -patches as minor "".99"", otherwise as expected.; This can be improved in the future by also adding the commit count to patches, aka 6.16.06.42 for the 42th commit after 6.16.06.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3864
https://github.com/root-project/root/pull/3864:35,Usability,simpl,simply,35,"This was the intent, the regex was simply broken and did not take the trailing versioning part into account.; Now, -patches as minor "".99"", otherwise as expected.; This can be improved in the future by also adding the commit count to patches, aka 6.16.06.42 for the 42th commit after 6.16.06.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3864
https://github.com/root-project/root/pull/3865:5,Deployability,patch,patch,5,This patch moves code which does similar things into standalone routines. This; way we make more clear the intent of use.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3865
https://github.com/root-project/root/pull/3865:64,Integrability,rout,routines,64,This patch moves code which does similar things into standalone routines. This; way we make more clear the intent of use.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3865
https://github.com/root-project/root/pull/3865:97,Usability,clear,clear,97,This patch moves code which does similar things into standalone routines. This; way we make more clear the intent of use.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3865
https://github.com/root-project/root/pull/3869:263,Security,secur,secure,263,"Alternatively we could enlarge the buffer for `snprintf`. However, this would change the print-out since the truncation feature of `snprintf` is a feature. @lmoneta What do you think?. Edit: The truncation warnings can be found here: https://sft.its.cern.ch/jira/secure/attachment/22139/build.log",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3869
https://github.com/root-project/root/pull/3869:293,Testability,log,log,293,"Alternatively we could enlarge the buffer for `snprintf`. However, this would change the print-out since the truncation feature of `snprintf` is a feature. @lmoneta What do you think?. Edit: The truncation warnings can be found here: https://sft.its.cern.ch/jira/secure/attachment/22139/build.log",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3869
https://github.com/root-project/root/pull/3873:5,Deployability,patch,patch,5,This patch should fix an assert in the incrementals.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3873
https://github.com/root-project/root/pull/3873:25,Testability,assert,assert,25,This patch should fix an assert in the incrementals.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3873
https://github.com/root-project/root/pull/3883:41,Usability,Simpl,Simplify,41,Suppress gcc9 warnings in THistPainter.; Simplify the code.; Provides a better fix for very long stats parameters names.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3883
https://github.com/root-project/root/pull/3889:5,Deployability,patch,patch,5,This patch should fix an assert in the incrementals.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3889
https://github.com/root-project/root/pull/3889:25,Testability,assert,assert,25,This patch should fix an assert in the incrementals.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3889
https://github.com/root-project/root/pull/3896:425,Availability,failure,failure,425,"We might be in a situation where we linked the library into an executable and; our trigger function is inside it. There is no point in trying to load rdict; and pcm files as it will fail. In that case we exit early avoiding the; invalid state pointed by an assert. This patch is another try to fix the assert in the incrementals. @Axel-Naumann, I have tested and this patch fixes the assert. However it does not fix the test failure. I checked with a local alternative patch which did not have the early exit but just avoided the LoadPCM section and the test fails in the same way.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3896
https://github.com/root-project/root/pull/3896:270,Deployability,patch,patch,270,"We might be in a situation where we linked the library into an executable and; our trigger function is inside it. There is no point in trying to load rdict; and pcm files as it will fail. In that case we exit early avoiding the; invalid state pointed by an assert. This patch is another try to fix the assert in the incrementals. @Axel-Naumann, I have tested and this patch fixes the assert. However it does not fix the test failure. I checked with a local alternative patch which did not have the early exit but just avoided the LoadPCM section and the test fails in the same way.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3896
https://github.com/root-project/root/pull/3896:368,Deployability,patch,patch,368,"We might be in a situation where we linked the library into an executable and; our trigger function is inside it. There is no point in trying to load rdict; and pcm files as it will fail. In that case we exit early avoiding the; invalid state pointed by an assert. This patch is another try to fix the assert in the incrementals. @Axel-Naumann, I have tested and this patch fixes the assert. However it does not fix the test failure. I checked with a local alternative patch which did not have the early exit but just avoided the LoadPCM section and the test fails in the same way.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3896
https://github.com/root-project/root/pull/3896:469,Deployability,patch,patch,469,"We might be in a situation where we linked the library into an executable and; our trigger function is inside it. There is no point in trying to load rdict; and pcm files as it will fail. In that case we exit early avoiding the; invalid state pointed by an assert. This patch is another try to fix the assert in the incrementals. @Axel-Naumann, I have tested and this patch fixes the assert. However it does not fix the test failure. I checked with a local alternative patch which did not have the early exit but just avoided the LoadPCM section and the test fails in the same way.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3896
https://github.com/root-project/root/pull/3896:145,Performance,load,load,145,"We might be in a situation where we linked the library into an executable and; our trigger function is inside it. There is no point in trying to load rdict; and pcm files as it will fail. In that case we exit early avoiding the; invalid state pointed by an assert. This patch is another try to fix the assert in the incrementals. @Axel-Naumann, I have tested and this patch fixes the assert. However it does not fix the test failure. I checked with a local alternative patch which did not have the early exit but just avoided the LoadPCM section and the test fails in the same way.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3896
https://github.com/root-project/root/pull/3896:530,Performance,Load,LoadPCM,530,"We might be in a situation where we linked the library into an executable and; our trigger function is inside it. There is no point in trying to load rdict; and pcm files as it will fail. In that case we exit early avoiding the; invalid state pointed by an assert. This patch is another try to fix the assert in the incrementals. @Axel-Naumann, I have tested and this patch fixes the assert. However it does not fix the test failure. I checked with a local alternative patch which did not have the early exit but just avoided the LoadPCM section and the test fails in the same way.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3896
https://github.com/root-project/root/pull/3896:215,Safety,avoid,avoiding,215,"We might be in a situation where we linked the library into an executable and; our trigger function is inside it. There is no point in trying to load rdict; and pcm files as it will fail. In that case we exit early avoiding the; invalid state pointed by an assert. This patch is another try to fix the assert in the incrementals. @Axel-Naumann, I have tested and this patch fixes the assert. However it does not fix the test failure. I checked with a local alternative patch which did not have the early exit but just avoided the LoadPCM section and the test fails in the same way.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3896
https://github.com/root-project/root/pull/3896:518,Safety,avoid,avoided,518,"We might be in a situation where we linked the library into an executable and; our trigger function is inside it. There is no point in trying to load rdict; and pcm files as it will fail. In that case we exit early avoiding the; invalid state pointed by an assert. This patch is another try to fix the assert in the incrementals. @Axel-Naumann, I have tested and this patch fixes the assert. However it does not fix the test failure. I checked with a local alternative patch which did not have the early exit but just avoided the LoadPCM section and the test fails in the same way.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3896
https://github.com/root-project/root/pull/3896:257,Testability,assert,assert,257,"We might be in a situation where we linked the library into an executable and; our trigger function is inside it. There is no point in trying to load rdict; and pcm files as it will fail. In that case we exit early avoiding the; invalid state pointed by an assert. This patch is another try to fix the assert in the incrementals. @Axel-Naumann, I have tested and this patch fixes the assert. However it does not fix the test failure. I checked with a local alternative patch which did not have the early exit but just avoided the LoadPCM section and the test fails in the same way.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3896
https://github.com/root-project/root/pull/3896:302,Testability,assert,assert,302,"We might be in a situation where we linked the library into an executable and; our trigger function is inside it. There is no point in trying to load rdict; and pcm files as it will fail. In that case we exit early avoiding the; invalid state pointed by an assert. This patch is another try to fix the assert in the incrementals. @Axel-Naumann, I have tested and this patch fixes the assert. However it does not fix the test failure. I checked with a local alternative patch which did not have the early exit but just avoided the LoadPCM section and the test fails in the same way.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3896
https://github.com/root-project/root/pull/3896:352,Testability,test,tested,352,"We might be in a situation where we linked the library into an executable and; our trigger function is inside it. There is no point in trying to load rdict; and pcm files as it will fail. In that case we exit early avoiding the; invalid state pointed by an assert. This patch is another try to fix the assert in the incrementals. @Axel-Naumann, I have tested and this patch fixes the assert. However it does not fix the test failure. I checked with a local alternative patch which did not have the early exit but just avoided the LoadPCM section and the test fails in the same way.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3896
https://github.com/root-project/root/pull/3896:384,Testability,assert,assert,384,"We might be in a situation where we linked the library into an executable and; our trigger function is inside it. There is no point in trying to load rdict; and pcm files as it will fail. In that case we exit early avoiding the; invalid state pointed by an assert. This patch is another try to fix the assert in the incrementals. @Axel-Naumann, I have tested and this patch fixes the assert. However it does not fix the test failure. I checked with a local alternative patch which did not have the early exit but just avoided the LoadPCM section and the test fails in the same way.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3896
https://github.com/root-project/root/pull/3896:420,Testability,test,test,420,"We might be in a situation where we linked the library into an executable and; our trigger function is inside it. There is no point in trying to load rdict; and pcm files as it will fail. In that case we exit early avoiding the; invalid state pointed by an assert. This patch is another try to fix the assert in the incrementals. @Axel-Naumann, I have tested and this patch fixes the assert. However it does not fix the test failure. I checked with a local alternative patch which did not have the early exit but just avoided the LoadPCM section and the test fails in the same way.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3896
https://github.com/root-project/root/pull/3896:554,Testability,test,test,554,"We might be in a situation where we linked the library into an executable and; our trigger function is inside it. There is no point in trying to load rdict; and pcm files as it will fail. In that case we exit early avoiding the; invalid state pointed by an assert. This patch is another try to fix the assert in the incrementals. @Axel-Naumann, I have tested and this patch fixes the assert. However it does not fix the test failure. I checked with a local alternative patch which did not have the early exit but just avoided the LoadPCM section and the test fails in the same way.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3896
https://github.com/root-project/root/pull/3898:20,Deployability,patch,patches,20,PR against v6-18-00-patches,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3898
https://github.com/root-project/root/pull/3899:176,Safety,sanity check,sanity checks,176,"HistFactory normally collects histograms automatically, but not if; `HistoToWorkspaceFactoryFast::MakeSingleChannelWorkspace` is used.; This commit fixes this defect, and adds sanity checks. ROOT-10162. (cherry picked from commit 0f59f6b678ddbd95df0a1319eabbe4772b4b7541)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3899
https://github.com/root-project/root/pull/3901:296,Deployability,patch,patches,296,"* use m.SplitApp for main layout; * provide info page to draw separate geometry node and extra info; * experimental support of TGeoShape transport to client instead of binary data; * try to transport binary as std::vector<unsigned char> in JSON, ok for small data; * latest JSROOT as in v6-18-00-patches branch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3901
https://github.com/root-project/root/pull/3904:173,Availability,error,error,173,Methods from TH1 that are using GetNbinsX and GetNbinsY that do not make sense for a TH2Poly and will compute sometiung wrong. They are re-implemented now in TH2Poly and an error message is printed. . This fixes ROOT-7139,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3904
https://github.com/root-project/root/pull/3904:179,Integrability,message,message,179,Methods from TH1 that are using GetNbinsX and GetNbinsY that do not make sense for a TH2Poly and will compute sometiung wrong. They are re-implemented now in TH2Poly and an error message is printed. . This fixes ROOT-7139,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3904
https://github.com/root-project/root/pull/3905:72,Deployability,integrat,integrating,72,RooRealIntegral was configured to forcefully select all components when integrating.; This is not desired if single components should be projected out. The default has been; set to not select all components. This fixes ROOT-10098.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3905
https://github.com/root-project/root/pull/3905:72,Integrability,integrat,integrating,72,RooRealIntegral was configured to forcefully select all components when integrating.; This is not desired if single components should be projected out. The default has been; set to not select all components. This fixes ROOT-10098.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3905
https://github.com/root-project/root/pull/3905:20,Modifiability,config,configured,20,RooRealIntegral was configured to forcefully select all components when integrating.; This is not desired if single components should be projected out. The default has been; set to not select all components. This fixes ROOT-10098.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3905
https://github.com/root-project/root/pull/3908:72,Deployability,integrat,integrating,72,RooRealIntegral was configured to forcefully select all components when integrating.; This is not desired if single components should be projected out. The default has been; set to not select all components. This is meant to fix ROOT-10098.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3908
https://github.com/root-project/root/pull/3908:72,Integrability,integrat,integrating,72,RooRealIntegral was configured to forcefully select all components when integrating.; This is not desired if single components should be projected out. The default has been; set to not select all components. This is meant to fix ROOT-10098.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3908
https://github.com/root-project/root/pull/3908:20,Modifiability,config,configured,20,RooRealIntegral was configured to forcefully select all components when integrating.; This is not desired if single components should be projected out. The default has been; set to not select all components. This is meant to fix ROOT-10098.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3908
https://github.com/root-project/root/pull/3911:106,Testability,test,tests,106,This is a continuation of https://github.com/root-project/root/pull/3858/ with some fixes for the failing tests:. - projectroot.roottest.cling.functionTemplate.roottest_cling_functionTemplate_cintrun; - projectroot.roottest.cling.functionTemplate.roottest_cling_functionTemplate_testcint; - projectroot.roottest.python.basic.roottest_python_basic_overload; - projectroot.roottest.python.cpp.roottest_python_cpp_advanced,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3911
https://github.com/root-project/root/pull/3912:70,Availability,error,errors,70,"When HistFactory constructs gamma parameters, they don't have initial errors.; When trying to plot the prefit model, the missing errors will make problems.; By assigning the relative errors caused by the constraint terms, pre-fit plots; will succeed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3912
https://github.com/root-project/root/pull/3912:129,Availability,error,errors,129,"When HistFactory constructs gamma parameters, they don't have initial errors.; When trying to plot the prefit model, the missing errors will make problems.; By assigning the relative errors caused by the constraint terms, pre-fit plots; will succeed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3912
https://github.com/root-project/root/pull/3912:183,Availability,error,errors,183,"When HistFactory constructs gamma parameters, they don't have initial errors.; When trying to plot the prefit model, the missing errors will make problems.; By assigning the relative errors caused by the constraint terms, pre-fit plots; will succeed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3912
https://github.com/root-project/root/pull/3913:24,Integrability,message,messages,24,"HistFactory is spamming messages to cout when hist2workspace runs.; - A new message topic HistFactory was added to RooFit's message streams,; which allows to suppress these messages.; - ObjectHandling messages are now automatically suppressed when HistFactory runs.; - Documentation of ParamHistFunction improved a bit.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3913
https://github.com/root-project/root/pull/3913:76,Integrability,message,message,76,"HistFactory is spamming messages to cout when hist2workspace runs.; - A new message topic HistFactory was added to RooFit's message streams,; which allows to suppress these messages.; - ObjectHandling messages are now automatically suppressed when HistFactory runs.; - Documentation of ParamHistFunction improved a bit.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3913
https://github.com/root-project/root/pull/3913:124,Integrability,message,message,124,"HistFactory is spamming messages to cout when hist2workspace runs.; - A new message topic HistFactory was added to RooFit's message streams,; which allows to suppress these messages.; - ObjectHandling messages are now automatically suppressed when HistFactory runs.; - Documentation of ParamHistFunction improved a bit.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3913
https://github.com/root-project/root/pull/3913:173,Integrability,message,messages,173,"HistFactory is spamming messages to cout when hist2workspace runs.; - A new message topic HistFactory was added to RooFit's message streams,; which allows to suppress these messages.; - ObjectHandling messages are now automatically suppressed when HistFactory runs.; - Documentation of ParamHistFunction improved a bit.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3913
https://github.com/root-project/root/pull/3913:201,Integrability,message,messages,201,"HistFactory is spamming messages to cout when hist2workspace runs.; - A new message topic HistFactory was added to RooFit's message streams,; which allows to suppress these messages.; - ObjectHandling messages are now automatically suppressed when HistFactory runs.; - Documentation of ParamHistFunction improved a bit.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3913
https://github.com/root-project/root/pull/3920:88,Modifiability,inherit,inherited,88,"Because the TImage Title has a special use (not used to store a title), the ls() method inherited from TObject crashed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3920
https://github.com/root-project/root/pull/3922:553,Availability,error,error,553,"The RooFit ""plotOn"" plotting engine is very useful to visualize RooFit objects.; However, there is currently a strict separation between ""Data-like"" objects (which can only really be drawn with points) and ""Function-like"" objects (which can only really be drawn as lines and areas).; However, in techniques like unfolding, ""data"" is often times corrected data, and hence might actually be a function-type object in RooFit.; With this PR, functionality is added to RooAbsReal::plotOn that allows to plot functions ""data-like"", with data points including error bars when using the draw option ""P"", which was previously unusable.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3922
https://github.com/root-project/root/pull/3923:4,Deployability,Update,Update,4,### Update: Week 1 . - Implemented class structure for LSTM . - Implemented forward pass for LSTM,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3923
https://github.com/root-project/root/pull/3924:524,Deployability,update,updates,524,[Work Product] This pull request contains the code pertaining to the GSoC 2019 project [Development of LSTM and GRU layers in TMVA](https://summerofcode.withgoogle.com/projects/#5680527699345408). It implements the following features:. - LSTM layer for cpu and ref architecture types and tests for the same; - GRU layer for cpu and ref architecture types and tests for the same. Implementation for CUDA architecture is still WIP. The last commit is **Added comments**(9c94d63). These features are yet to be merged. Detailed updates can be found on my [blog post](https://surya2191997.github.io/),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3924
https://github.com/root-project/root/pull/3924:116,Modifiability,layers,layers,116,[Work Product] This pull request contains the code pertaining to the GSoC 2019 project [Development of LSTM and GRU layers in TMVA](https://summerofcode.withgoogle.com/projects/#5680527699345408). It implements the following features:. - LSTM layer for cpu and ref architecture types and tests for the same; - GRU layer for cpu and ref architecture types and tests for the same. Implementation for CUDA architecture is still WIP. The last commit is **Added comments**(9c94d63). These features are yet to be merged. Detailed updates can be found on my [blog post](https://surya2191997.github.io/),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3924
https://github.com/root-project/root/pull/3924:288,Testability,test,tests,288,[Work Product] This pull request contains the code pertaining to the GSoC 2019 project [Development of LSTM and GRU layers in TMVA](https://summerofcode.withgoogle.com/projects/#5680527699345408). It implements the following features:. - LSTM layer for cpu and ref architecture types and tests for the same; - GRU layer for cpu and ref architecture types and tests for the same. Implementation for CUDA architecture is still WIP. The last commit is **Added comments**(9c94d63). These features are yet to be merged. Detailed updates can be found on my [blog post](https://surya2191997.github.io/),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3924
https://github.com/root-project/root/pull/3924:359,Testability,test,tests,359,[Work Product] This pull request contains the code pertaining to the GSoC 2019 project [Development of LSTM and GRU layers in TMVA](https://summerofcode.withgoogle.com/projects/#5680527699345408). It implements the following features:. - LSTM layer for cpu and ref architecture types and tests for the same; - GRU layer for cpu and ref architecture types and tests for the same. Implementation for CUDA architecture is still WIP. The last commit is **Added comments**(9c94d63). These features are yet to be merged. Detailed updates can be found on my [blog post](https://surya2191997.github.io/),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3924
https://github.com/root-project/root/pull/3926:13,Deployability,install,installed,13,"When CUDA is installed on macOS, `clang -v` prints also the version of CUDA that is found, which breaks version detection. As a workaround, `clang --version` prints the same information, but without printing the CUDA version. Fixes: [ROOT-9678](https://sft.its.cern.ch/jira/browse/ROOT-9678).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3926
https://github.com/root-project/root/pull/3926:112,Safety,detect,detection,112,"When CUDA is installed on macOS, `clang -v` prints also the version of CUDA that is found, which breaks version detection. As a workaround, `clang --version` prints the same information, but without printing the CUDA version. Fixes: [ROOT-9678](https://sft.its.cern.ch/jira/browse/ROOT-9678).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3926
https://github.com/root-project/root/pull/3928:303,Modifiability,config,configure,303,For some applications large binary buffer need to be transferred ; with JSON. Standard solution is base64 coding. It can be enabled by; JSON_base64 string in class comments or with kBase64 = 30 value in; compress parameter. Also provide convenience methods `StoreObject()`/`RestoreObject()`; to be able configure different TBufferJSON properties before streaming objects.; Only for special use-cases. Also include fixe from #3916,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3928
https://github.com/root-project/root/pull/3938:165,Usability,simpl,simple,165,"When running eve7 application snapshot, server does not have functionality at all.; Therefore special highlight or selection requests cannot be processed.; Also add simple checks when selection is not possible.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3938
https://github.com/root-project/root/pull/3939:194,Usability,simpl,simple,194,"Same as #3938, but for 6.18; When running eve7 application snapshot, server does not have functionality at all.; Therefore special highlight or selection requests cannot be processed.; Also add simple checks when selection is not possible.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3939
https://github.com/root-project/root/pull/3946:14,Safety,detect,detected,14,"Previously it detected the change of entry by comparing the 'current' instance to the last 'instance'; recorded. If all instance are used, this worked perfectly. If the instance are used sparsely (eg. with; selection in TTree::Draw) then from entry to the other, the 'first' instance used in an entry might be later/higher; than the last 'instance' used in the previous entry. This corrects the behavior introduced in 064e0a7d49b08e03667f9312421b6fb5b8d82285. This fixes ROOT-10170",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3946
https://github.com/root-project/root/pull/3948:72,Deployability,integrat,integrating,72,RooRealIntegral was configured to forcefully select all components when integrating.; This is not desired if single components should be projected out. The default has been; set to not select all components. This fixes ROOT-10098. (cherry picked from commit 68f2aea99f92e9e90e345658d154164c3c96fa82),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3948
https://github.com/root-project/root/pull/3948:72,Integrability,integrat,integrating,72,RooRealIntegral was configured to forcefully select all components when integrating.; This is not desired if single components should be projected out. The default has been; set to not select all components. This fixes ROOT-10098. (cherry picked from commit 68f2aea99f92e9e90e345658d154164c3c96fa82),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3948
https://github.com/root-project/root/pull/3948:20,Modifiability,config,configured,20,RooRealIntegral was configured to forcefully select all components when integrating.; This is not desired if single components should be projected out. The default has been; set to not select all components. This fixes ROOT-10098. (cherry picked from commit 68f2aea99f92e9e90e345658d154164c3c96fa82),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3948
https://github.com/root-project/root/pull/3950:116,Deployability,update,updated,116,"Because of ROOT-10144, the unit test for RooJohnson crashes occasionally.; Unless TFormula v5 is fixed or RooFit is updated to use TFormula v6 (ROOT-10164),; the test needs to stay disabled.; This is ROOT-10173.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3950
https://github.com/root-project/root/pull/3950:32,Testability,test,test,32,"Because of ROOT-10144, the unit test for RooJohnson crashes occasionally.; Unless TFormula v5 is fixed or RooFit is updated to use TFormula v6 (ROOT-10164),; the test needs to stay disabled.; This is ROOT-10173.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3950
https://github.com/root-project/root/pull/3950:162,Testability,test,test,162,"Because of ROOT-10144, the unit test for RooJohnson crashes occasionally.; Unless TFormula v5 is fixed or RooFit is updated to use TFormula v6 (ROOT-10164),; the test needs to stay disabled.; This is ROOT-10173.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3950
https://github.com/root-project/root/pull/3954:55,Safety,detect,detectors,55,This function is needed for newly introduced sensitive detectors framework; to provide a hook for a central call to fill ROOT trees before resetting data; in sensitive detector's end of event.; It would be nice if it could be still included in 6.18,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3954
https://github.com/root-project/root/pull/3954:168,Safety,detect,detector,168,This function is needed for newly introduced sensitive detectors framework; to provide a hook for a central call to fill ROOT trees before resetting data; in sensitive detector's end of event.; It would be nice if it could be still included in 6.18,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3954
https://github.com/root-project/root/pull/3955:168,Testability,test,test,168,In some cases when the polygons are just a few points some of the internal arrays indices got negative values. For instance this was the case with the example $ROOTSYS/test/delaunayTriangulation.cxx,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3955
https://github.com/root-project/root/pull/3957:26,Availability,avail,available,26,"Because RDataFrame is not available on 32bit, we have to disable the; experimental parts of TMVA which are dependent on it as well.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3957
https://github.com/root-project/root/pull/3957:107,Integrability,depend,dependent,107,"Because RDataFrame is not available on 32bit, we have to disable the; experimental parts of TMVA which are dependent on it as well.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3957
https://github.com/root-project/root/pull/3962:303,Deployability,update,updated,303,"The sum of all the values passed to fill the `TStatistic` object has been added as a class data member. Meanwhile, `Fill`,`Print`, and `Merge` functions have been changed to accomodate the new statistic. The sum is initialized to zero when calling the constructor of TStatistic. Docs and test have been updated; accordingly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3962
https://github.com/root-project/root/pull/3962:288,Testability,test,test,288,"The sum of all the values passed to fill the `TStatistic` object has been added as a class data member. Meanwhile, `Fill`,`Print`, and `Merge` functions have been changed to accomodate the new statistic. The sum is initialized to zero when calling the constructor of TStatistic. Docs and test have been updated; accordingly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3962
https://github.com/root-project/root/pull/3963:33,Testability,test,test,33,"The attempt to fix the following test that was failing:; roottest-python-basic-operator; led to the necessity of adding the possibility for the user to call a namespace inside cppyy.gbl.ROOT by simply typing ROOT.Namespace instead of ROOT.ROOT.Namespace. ; Two bugs in cppyy were also found during this attempt, both fixed by the maintainer of the repo.; The test mentioned above now succeeds.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3963
https://github.com/root-project/root/pull/3963:359,Testability,test,test,359,"The attempt to fix the following test that was failing:; roottest-python-basic-operator; led to the necessity of adding the possibility for the user to call a namespace inside cppyy.gbl.ROOT by simply typing ROOT.Namespace instead of ROOT.ROOT.Namespace. ; Two bugs in cppyy were also found during this attempt, both fixed by the maintainer of the repo.; The test mentioned above now succeeds.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3963
https://github.com/root-project/root/pull/3963:194,Usability,simpl,simply,194,"The attempt to fix the following test that was failing:; roottest-python-basic-operator; led to the necessity of adding the possibility for the user to call a namespace inside cppyy.gbl.ROOT by simply typing ROOT.Namespace instead of ROOT.ROOT.Namespace. ; Two bugs in cppyy were also found during this attempt, both fixed by the maintainer of the repo.; The test mentioned above now succeeds.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3963
https://github.com/root-project/root/pull/3965:99,Integrability,Depend,Depends,99,When we have a module file we store the rdict in it and reference it through a 'virtual' TMemFile. Depends on #3891,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3965
https://github.com/root-project/root/pull/3966:232,Availability,avail,available,232,Improve the parsing of the string for defining the layers in MethodDL. Now it is possible to read strings defined as in the previous MethodDNN . Change TMVAClassification to use MethodDL. ; - enable CPU and GPU based DL if they are available in ROOT,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3966
https://github.com/root-project/root/pull/3966:51,Modifiability,layers,layers,51,Improve the parsing of the string for defining the layers in MethodDL. Now it is possible to read strings defined as in the previous MethodDNN . Change TMVAClassification to use MethodDL. ; - enable CPU and GPU based DL if they are available in ROOT,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3966
https://github.com/root-project/root/pull/3967:5,Deployability,patch,patch,5,This patch enables the module file to mmap the rdict memory region before the; request to load it.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3967
https://github.com/root-project/root/pull/3967:90,Performance,load,load,90,This patch enables the module file to mmap the rdict memory region before the; request to load it.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3967
https://github.com/root-project/root/pull/3976:243,Security,access,access,243,"RooArgSets could not be constructed from STL collections and initialiser; lists. This fixes this shortcoming. The same holds for adding multiple; elements from a collection.; Further, operator[] was overloaded to react both to index and name; access.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3976
https://github.com/root-project/root/pull/3977:5,Deployability,patch,patch,5,This patch makes it more difficult for people to avoid the 'automatic' memory; ownership done by TMemFile. It forces people to explicitly construct the; data structure describing memory blob and makes it easier to grep for.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3977
https://github.com/root-project/root/pull/3977:49,Safety,avoid,avoid,49,This patch makes it more difficult for people to avoid the 'automatic' memory; ownership done by TMemFile. It forces people to explicitly construct the; data structure describing memory blob and makes it easier to grep for.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3977
https://github.com/root-project/root/pull/3980:8,Testability,test,tests,8,"The two tests mentioned in the title were fixed after the corrections implemented for pythonizations of templated classes and try/exception blocks in Cppyy, on top of which the possibility to use ROOT.Namespace instead of ROOT.ROOT.Namespace was added.; Commits that fixed the tests:; 832989cd2cd3dea7a2f96aa53272ecdd34e45b8b; f45d07c7a0b2414159e81a957a4fe86afc63fa87; f45d07c7a0b2414159e81a957a4fe86afc63fa87",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3980
https://github.com/root-project/root/pull/3980:277,Testability,test,tests,277,"The two tests mentioned in the title were fixed after the corrections implemented for pythonizations of templated classes and try/exception blocks in Cppyy, on top of which the possibility to use ROOT.Namespace instead of ROOT.ROOT.Namespace was added.; Commits that fixed the tests:; 832989cd2cd3dea7a2f96aa53272ecdd34e45b8b; f45d07c7a0b2414159e81a957a4fe86afc63fa87; f45d07c7a0b2414159e81a957a4fe86afc63fa87",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3980
https://github.com/root-project/root/pull/3981:76,Integrability,wrap,wrap,76,This PR fixes the delition of the internal function pointer that is used to wrap C/C++ functions in TF1. ; Also the copying of the function is now fixed and the intgernal structure is corrected copy when copying TF1 objects. . Also re-define some internal functions as protected that by mistakes they were declared public. . This PR fixes ROOT-10191,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3981
https://github.com/root-project/root/pull/3982:152,Availability,repair,repairs,152,"Revert ""[cxxmodules] Fix R.M by displacing TEmulatedTuple only withou…t cxxmodules"". This reverts commit a74297ac32fbe9f1aec0be246d0bef1c430b9bc6. This repairs the support for I/O of std::tuple. The previous code leads to; the actual std::tuple implementation to be attempted (and failing) to be used; for I/O:. See https://epsft-jenkins.cern.ch/job/root-pullrequests-build/59119/testReport/projectroot.roottest.root.io/tuple/roottest_root_io_tuple_make/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3982
https://github.com/root-project/root/pull/3982:380,Testability,test,testReport,380,"Revert ""[cxxmodules] Fix R.M by displacing TEmulatedTuple only withou…t cxxmodules"". This reverts commit a74297ac32fbe9f1aec0be246d0bef1c430b9bc6. This repairs the support for I/O of std::tuple. The previous code leads to; the actual std::tuple implementation to be attempted (and failing) to be used; for I/O:. See https://epsft-jenkins.cern.ch/job/root-pullrequests-build/59119/testReport/projectroot.roottest.root.io/tuple/roottest_root_io_tuple_make/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3982
https://github.com/root-project/root/pull/3986:228,Deployability,install,installed,228,"When `builtin_vdt=ON`, vdt headers are in `${CMAKE_BINARY_DIR}/include` and `libvdt.so` is in `${CMAKE_BINARY_DIR}/lib`, so we don't need to add the extra include directory and can link using just the library name. Once ROOT is installed, the Vdt headers and library will be along with ROOT ones, so they can also be found without needing anything else. Fixes: [ROOT-10197](https://sft.its.cern.ch/jira/browse/ROOT-10197).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3986
https://github.com/root-project/root/pull/3990:684,Deployability,Patch,Patch,684,"This fixes a bug visible only in runtime_cxxmodules where the include guards; are ignored. This can happen when we are building a two modules which need; the same definition. In this case the usual include guards will only work if; we call a proper `#include ""something""` and this something should be defined; in a modulemap. There is no better solution for this at the moment. This is a rare case which; will likely not affect external use-cases. Revert ""[cxxmodules] Fix R.M by displacing TEmulatedTuple only without cxxmodules"". This reverts commit a74297ac32fbe9f1aec0be246d0bef1c430b9bc6 and puts in place; a better fix. Now roottest-root-io-tuple-make should work with modules. Patch by Philippe Canal and me!. This PR should supersede PR#3982.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3990
https://github.com/root-project/root/pull/3995:20,Integrability,interface,interface,20,Adds a STL iterator interface to RTensor iterating over the given view of the data. Still incomplete since not the full interface of the iterator is implemented.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3995
https://github.com/root-project/root/pull/3995:120,Integrability,interface,interface,120,Adds a STL iterator interface to RTensor iterating over the given view of the data. Still incomplete since not the full interface of the iterator is implemented.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3995
https://github.com/root-project/root/pull/3996:68,Availability,error,error-when-expected,68,"See https://stackoverflow.com/questions/31143820/cmake-not-throwing-error-when-expected; This was fixed in later CMake versions: Result variables of both names (`<PackageName>_FOUND`, `<PACKAGENAME>_FOUND`) are always set for compatibility",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3996
https://github.com/root-project/root/pull/3996:136,Modifiability,variab,variables,136,"See https://stackoverflow.com/questions/31143820/cmake-not-throwing-error-when-expected; This was fixed in later CMake versions: Result variables of both names (`<PackageName>_FOUND`, `<PACKAGENAME>_FOUND`) are always set for compatibility",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3996
https://github.com/root-project/root/pull/3998:63,Usability,learn,learning,63,This PR add support for batch normalisation for MethodDL (deep learning in TMVA); The code has been developed mainly by Liam Bartsch (trainee in June 2019),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3998
https://github.com/root-project/root/pull/3999:447,Deployability,Update,Update,447,"- Add a tutorial for the Barlow-Beeston method, rf709_BarlowBeeston.C.; - Remove legacy iterators from RooHistConstraint and RooParamHistFunc,; which are used to implement the Barlow-Beeston method.; - Replace iterative logGamma in RooHistConstraint by std::lgamma; - Make sure that bins with zero entries don't get touched by MINUIT.; This reduces the number of degenerate parameters without any effect, and; stabilises the covariance matrix.; - Update documentation of the respective classes.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3999
https://github.com/root-project/root/pull/3999:341,Energy Efficiency,reduce,reduces,341,"- Add a tutorial for the Barlow-Beeston method, rf709_BarlowBeeston.C.; - Remove legacy iterators from RooHistConstraint and RooParamHistFunc,; which are used to implement the Barlow-Beeston method.; - Replace iterative logGamma in RooHistConstraint by std::lgamma; - Make sure that bins with zero entries don't get touched by MINUIT.; This reduces the number of degenerate parameters without any effect, and; stabilises the covariance matrix.; - Update documentation of the respective classes.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3999
https://github.com/root-project/root/pull/3999:220,Testability,log,logGamma,220,"- Add a tutorial for the Barlow-Beeston method, rf709_BarlowBeeston.C.; - Remove legacy iterators from RooHistConstraint and RooParamHistFunc,; which are used to implement the Barlow-Beeston method.; - Replace iterative logGamma in RooHistConstraint by std::lgamma; - Make sure that bins with zero entries don't get touched by MINUIT.; This reduces the number of degenerate parameters without any effect, and; stabilises the covariance matrix.; - Update documentation of the respective classes.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/3999
https://github.com/root-project/root/pull/4000:5,Deployability,integrat,integrating,5,"When integrating a region next to a narrow Crystal Ball shape, the integral; can evaluate to zero. Since RooFit cannot deal with zero integrals,; the CBShape will now return the smallest possible double. See also https://root-forum.cern.ch/t/fit-a-double-crystal-ball-with-roofitranges/34599",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4000
https://github.com/root-project/root/pull/4000:5,Integrability,integrat,integrating,5,"When integrating a region next to a narrow Crystal Ball shape, the integral; can evaluate to zero. Since RooFit cannot deal with zero integrals,; the CBShape will now return the smallest possible double. See also https://root-forum.cern.ch/t/fit-a-double-crystal-ball-with-roofitranges/34599",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4000
https://github.com/root-project/root/pull/4005:0,Integrability,Depend,Depends,0,Depends on #3850.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4005
https://github.com/root-project/root/pull/4006:649,Availability,error,error,649,"Allow to select the system of units in TGeo at run-time and allow to switch to; Geant4 (mm,ns,MeV) from the TGeo default TGeo (mm,s,keV). Example:; ```; #include ""TGeant4SystemOfUnits.h""; ....; TGeant4Unit::setUnitType(TGeant4Unit::kTGeant4Units); ```; Then the material properties shall be as described in TGeant4SystemOfUnits.h. The default is:; ```; #include ""TGeoSystemOfUnits.h""; ....; TGeo4Unit::setUnitType(TGeoUnit::kTGeoUnits); ```; Please note: ; 1) This code is not necessary. If users do nothing the behavior stays as it is now.; 2) Units have to be set *before* the first TElement or TMaterial constructor is called,; Otherwise a fatal error is issued (TError::Fatal).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4006
https://github.com/root-project/root/pull/4007:93,Safety,safe,safely,93,RooThresholdCategory cannot be successfully streamed because not all members are initialized safely in the default constructor. This PR fixes that.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4007
https://github.com/root-project/root/pull/4011:137,Modifiability,config,config,137,When compiling for conda we enable C++17 support but the compiler only supports `--std=cxx1z`. . Uses the same [fix as is used for `root-config`](https://github.com/root-project/root/blob/88ed0c6ea16f962b89168417bfff23891429dd63/cmake/modules/RootConfiguration.cmake#L570).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4011
https://github.com/root-project/root/pull/4013:103,Modifiability,config,config,103,Currently if `CMAKE_SYSTEM_PROCESSOR` is not set ROOT silently falls back to returning `-m32` in `root-config --cflags` among other things. This can easily happen when cross-compiling and caused an issue in the first build of 6.18.00 for Conda (see https://github.com/conda-forge/root-feedstock/issues/41). I think it would be safer to fail immediately if the architecture is not recognised rather than allowing this to be missed and this is the approach used [elsewhere](https://boringssl.googlesource.com/boringssl/+/2272/CMakeLists.txt).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4013
https://github.com/root-project/root/pull/4013:327,Safety,safe,safer,327,Currently if `CMAKE_SYSTEM_PROCESSOR` is not set ROOT silently falls back to returning `-m32` in `root-config --cflags` among other things. This can easily happen when cross-compiling and caused an issue in the first build of 6.18.00 for Conda (see https://github.com/conda-forge/root-feedstock/issues/41). I think it would be safer to fail immediately if the architecture is not recognised rather than allowing this to be missed and this is the approach used [elsewhere](https://boringssl.googlesource.com/boringssl/+/2272/CMakeLists.txt).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4013
https://github.com/root-project/root/pull/4014:286,Deployability,Release,ReleasePage,286,"Change primary responsible for page memory management from page pool to page storage. This is a preparation for asynchronous interfaces. In the new scheme, RColumn uses `RPageStorage::ReservePage` (writing) or `RPageStorage::PopulatePage` (reading) to allocate pages and `RPageStorage::ReleasePage` for freeing them. The page storage, in turn, may use a shared page pool. In this case, ownership of a page's memory is transferred to the page pool, which will free a page if there are no further users. Addresses ROOT-10205",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4014
https://github.com/root-project/root/pull/4014:252,Energy Efficiency,allocate,allocate,252,"Change primary responsible for page memory management from page pool to page storage. This is a preparation for asynchronous interfaces. In the new scheme, RColumn uses `RPageStorage::ReservePage` (writing) or `RPageStorage::PopulatePage` (reading) to allocate pages and `RPageStorage::ReleasePage` for freeing them. The page storage, in turn, may use a shared page pool. In this case, ownership of a page's memory is transferred to the page pool, which will free a page if there are no further users. Addresses ROOT-10205",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4014
https://github.com/root-project/root/pull/4014:125,Integrability,interface,interfaces,125,"Change primary responsible for page memory management from page pool to page storage. This is a preparation for asynchronous interfaces. In the new scheme, RColumn uses `RPageStorage::ReservePage` (writing) or `RPageStorage::PopulatePage` (reading) to allocate pages and `RPageStorage::ReleasePage` for freeing them. The page storage, in turn, may use a shared page pool. In this case, ownership of a page's memory is transferred to the page pool, which will free a page if there are no further users. Addresses ROOT-10205",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4014
https://github.com/root-project/root/pull/4015:55,Energy Efficiency,power,power,55,"At the moment, it's not really possible to implement a power law or a exponential of a polynomial (as used, for example, in the ATLAS H->yy analysis) without using RooGenericPdf.; This PR adds two new Pdf classes that implement an exponential polynomial and a power law.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4015
https://github.com/root-project/root/pull/4015:260,Energy Efficiency,power,power,260,"At the moment, it's not really possible to implement a power law or a exponential of a polynomial (as used, for example, in the ATLAS H->yy analysis) without using RooGenericPdf.; This PR adds two new Pdf classes that implement an exponential polynomial and a power law.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4015
https://github.com/root-project/root/pull/4016:38,Energy Efficiency,efficient,efficient,38,"The global module index represents an efficient on-disk hash table which stores identifier->module mapping. Every time clang finds a unknown identifier we are informed and we can load the corresponding module on demand. This way we can provide minimal set of loaded modules. Currently, we see that for hsimple.C only the half of the modules are loaded. This can be further improved because we currently load all modules which have an identifier, that is when looking for (for example TPad) we will load all modules which have the identifier TPad, including modules which contain only a forward declaration of it.; ; Kudos Arpitha Raghunandan (@arpi-r)!. We still need some performance measurements but the preliminary results are promising. Performance; ===. Methodology; ---. We have a forwarding root.exe which essentially calls /usr/bin/time -v root.exe $@. We have processed and stored this information in csv files. We have run in three modes:; 1) root master without modules (modulesoff); 2) root master with modules (moduleson); 3) root master with this PR with modules (gmi). Run on `Ubuntu 18.10 on Intel® Core™ i5-8250U CPU @ 1.60GHz × 8`. Results Interpretation; ---; A general comparison between 2) and 3) show that this PR makes ROOT about 3% faster and 25% more memory efficient. A general comparison between 1) and 3) shows that modules are still less efficient in a few cases which is expected because the PR loads more modules than it should. This will be addressed in subsequent PRs. A good trend is that some test already show that 3) is better than 1). The raw data could be found [here](https://docs.google.com/spreadsheets/d/12tZ_tmenR7fytcZpigfLOarNq1tIqPubTXWWMwz8lJg/edit#gid=1476035460). [work was done by Arpitha Raghunandan (@arpi-r)]. Depends on #4005.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4016
https://github.com/root-project/root/pull/4016:1283,Energy Efficiency,efficient,efficient,1283,"The global module index represents an efficient on-disk hash table which stores identifier->module mapping. Every time clang finds a unknown identifier we are informed and we can load the corresponding module on demand. This way we can provide minimal set of loaded modules. Currently, we see that for hsimple.C only the half of the modules are loaded. This can be further improved because we currently load all modules which have an identifier, that is when looking for (for example TPad) we will load all modules which have the identifier TPad, including modules which contain only a forward declaration of it.; ; Kudos Arpitha Raghunandan (@arpi-r)!. We still need some performance measurements but the preliminary results are promising. Performance; ===. Methodology; ---. We have a forwarding root.exe which essentially calls /usr/bin/time -v root.exe $@. We have processed and stored this information in csv files. We have run in three modes:; 1) root master without modules (modulesoff); 2) root master with modules (moduleson); 3) root master with this PR with modules (gmi). Run on `Ubuntu 18.10 on Intel® Core™ i5-8250U CPU @ 1.60GHz × 8`. Results Interpretation; ---; A general comparison between 2) and 3) show that this PR makes ROOT about 3% faster and 25% more memory efficient. A general comparison between 1) and 3) shows that modules are still less efficient in a few cases which is expected because the PR loads more modules than it should. This will be addressed in subsequent PRs. A good trend is that some test already show that 3) is better than 1). The raw data could be found [here](https://docs.google.com/spreadsheets/d/12tZ_tmenR7fytcZpigfLOarNq1tIqPubTXWWMwz8lJg/edit#gid=1476035460). [work was done by Arpitha Raghunandan (@arpi-r)]. Depends on #4005.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4016
https://github.com/root-project/root/pull/4016:1367,Energy Efficiency,efficient,efficient,1367,"The global module index represents an efficient on-disk hash table which stores identifier->module mapping. Every time clang finds a unknown identifier we are informed and we can load the corresponding module on demand. This way we can provide minimal set of loaded modules. Currently, we see that for hsimple.C only the half of the modules are loaded. This can be further improved because we currently load all modules which have an identifier, that is when looking for (for example TPad) we will load all modules which have the identifier TPad, including modules which contain only a forward declaration of it.; ; Kudos Arpitha Raghunandan (@arpi-r)!. We still need some performance measurements but the preliminary results are promising. Performance; ===. Methodology; ---. We have a forwarding root.exe which essentially calls /usr/bin/time -v root.exe $@. We have processed and stored this information in csv files. We have run in three modes:; 1) root master without modules (modulesoff); 2) root master with modules (moduleson); 3) root master with this PR with modules (gmi). Run on `Ubuntu 18.10 on Intel® Core™ i5-8250U CPU @ 1.60GHz × 8`. Results Interpretation; ---; A general comparison between 2) and 3) show that this PR makes ROOT about 3% faster and 25% more memory efficient. A general comparison between 1) and 3) shows that modules are still less efficient in a few cases which is expected because the PR loads more modules than it should. This will be addressed in subsequent PRs. A good trend is that some test already show that 3) is better than 1). The raw data could be found [here](https://docs.google.com/spreadsheets/d/12tZ_tmenR7fytcZpigfLOarNq1tIqPubTXWWMwz8lJg/edit#gid=1476035460). [work was done by Arpitha Raghunandan (@arpi-r)]. Depends on #4005.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4016
https://github.com/root-project/root/pull/4016:1764,Integrability,Depend,Depends,1764,"The global module index represents an efficient on-disk hash table which stores identifier->module mapping. Every time clang finds a unknown identifier we are informed and we can load the corresponding module on demand. This way we can provide minimal set of loaded modules. Currently, we see that for hsimple.C only the half of the modules are loaded. This can be further improved because we currently load all modules which have an identifier, that is when looking for (for example TPad) we will load all modules which have the identifier TPad, including modules which contain only a forward declaration of it.; ; Kudos Arpitha Raghunandan (@arpi-r)!. We still need some performance measurements but the preliminary results are promising. Performance; ===. Methodology; ---. We have a forwarding root.exe which essentially calls /usr/bin/time -v root.exe $@. We have processed and stored this information in csv files. We have run in three modes:; 1) root master without modules (modulesoff); 2) root master with modules (moduleson); 3) root master with this PR with modules (gmi). Run on `Ubuntu 18.10 on Intel® Core™ i5-8250U CPU @ 1.60GHz × 8`. Results Interpretation; ---; A general comparison between 2) and 3) show that this PR makes ROOT about 3% faster and 25% more memory efficient. A general comparison between 1) and 3) shows that modules are still less efficient in a few cases which is expected because the PR loads more modules than it should. This will be addressed in subsequent PRs. A good trend is that some test already show that 3) is better than 1). The raw data could be found [here](https://docs.google.com/spreadsheets/d/12tZ_tmenR7fytcZpigfLOarNq1tIqPubTXWWMwz8lJg/edit#gid=1476035460). [work was done by Arpitha Raghunandan (@arpi-r)]. Depends on #4005.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4016
https://github.com/root-project/root/pull/4016:179,Performance,load,load,179,"The global module index represents an efficient on-disk hash table which stores identifier->module mapping. Every time clang finds a unknown identifier we are informed and we can load the corresponding module on demand. This way we can provide minimal set of loaded modules. Currently, we see that for hsimple.C only the half of the modules are loaded. This can be further improved because we currently load all modules which have an identifier, that is when looking for (for example TPad) we will load all modules which have the identifier TPad, including modules which contain only a forward declaration of it.; ; Kudos Arpitha Raghunandan (@arpi-r)!. We still need some performance measurements but the preliminary results are promising. Performance; ===. Methodology; ---. We have a forwarding root.exe which essentially calls /usr/bin/time -v root.exe $@. We have processed and stored this information in csv files. We have run in three modes:; 1) root master without modules (modulesoff); 2) root master with modules (moduleson); 3) root master with this PR with modules (gmi). Run on `Ubuntu 18.10 on Intel® Core™ i5-8250U CPU @ 1.60GHz × 8`. Results Interpretation; ---; A general comparison between 2) and 3) show that this PR makes ROOT about 3% faster and 25% more memory efficient. A general comparison between 1) and 3) shows that modules are still less efficient in a few cases which is expected because the PR loads more modules than it should. This will be addressed in subsequent PRs. A good trend is that some test already show that 3) is better than 1). The raw data could be found [here](https://docs.google.com/spreadsheets/d/12tZ_tmenR7fytcZpigfLOarNq1tIqPubTXWWMwz8lJg/edit#gid=1476035460). [work was done by Arpitha Raghunandan (@arpi-r)]. Depends on #4005.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4016
https://github.com/root-project/root/pull/4016:259,Performance,load,loaded,259,"The global module index represents an efficient on-disk hash table which stores identifier->module mapping. Every time clang finds a unknown identifier we are informed and we can load the corresponding module on demand. This way we can provide minimal set of loaded modules. Currently, we see that for hsimple.C only the half of the modules are loaded. This can be further improved because we currently load all modules which have an identifier, that is when looking for (for example TPad) we will load all modules which have the identifier TPad, including modules which contain only a forward declaration of it.; ; Kudos Arpitha Raghunandan (@arpi-r)!. We still need some performance measurements but the preliminary results are promising. Performance; ===. Methodology; ---. We have a forwarding root.exe which essentially calls /usr/bin/time -v root.exe $@. We have processed and stored this information in csv files. We have run in three modes:; 1) root master without modules (modulesoff); 2) root master with modules (moduleson); 3) root master with this PR with modules (gmi). Run on `Ubuntu 18.10 on Intel® Core™ i5-8250U CPU @ 1.60GHz × 8`. Results Interpretation; ---; A general comparison between 2) and 3) show that this PR makes ROOT about 3% faster and 25% more memory efficient. A general comparison between 1) and 3) shows that modules are still less efficient in a few cases which is expected because the PR loads more modules than it should. This will be addressed in subsequent PRs. A good trend is that some test already show that 3) is better than 1). The raw data could be found [here](https://docs.google.com/spreadsheets/d/12tZ_tmenR7fytcZpigfLOarNq1tIqPubTXWWMwz8lJg/edit#gid=1476035460). [work was done by Arpitha Raghunandan (@arpi-r)]. Depends on #4005.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4016
https://github.com/root-project/root/pull/4016:345,Performance,load,loaded,345,"The global module index represents an efficient on-disk hash table which stores identifier->module mapping. Every time clang finds a unknown identifier we are informed and we can load the corresponding module on demand. This way we can provide minimal set of loaded modules. Currently, we see that for hsimple.C only the half of the modules are loaded. This can be further improved because we currently load all modules which have an identifier, that is when looking for (for example TPad) we will load all modules which have the identifier TPad, including modules which contain only a forward declaration of it.; ; Kudos Arpitha Raghunandan (@arpi-r)!. We still need some performance measurements but the preliminary results are promising. Performance; ===. Methodology; ---. We have a forwarding root.exe which essentially calls /usr/bin/time -v root.exe $@. We have processed and stored this information in csv files. We have run in three modes:; 1) root master without modules (modulesoff); 2) root master with modules (moduleson); 3) root master with this PR with modules (gmi). Run on `Ubuntu 18.10 on Intel® Core™ i5-8250U CPU @ 1.60GHz × 8`. Results Interpretation; ---; A general comparison between 2) and 3) show that this PR makes ROOT about 3% faster and 25% more memory efficient. A general comparison between 1) and 3) shows that modules are still less efficient in a few cases which is expected because the PR loads more modules than it should. This will be addressed in subsequent PRs. A good trend is that some test already show that 3) is better than 1). The raw data could be found [here](https://docs.google.com/spreadsheets/d/12tZ_tmenR7fytcZpigfLOarNq1tIqPubTXWWMwz8lJg/edit#gid=1476035460). [work was done by Arpitha Raghunandan (@arpi-r)]. Depends on #4005.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4016
https://github.com/root-project/root/pull/4016:403,Performance,load,load,403,"The global module index represents an efficient on-disk hash table which stores identifier->module mapping. Every time clang finds a unknown identifier we are informed and we can load the corresponding module on demand. This way we can provide minimal set of loaded modules. Currently, we see that for hsimple.C only the half of the modules are loaded. This can be further improved because we currently load all modules which have an identifier, that is when looking for (for example TPad) we will load all modules which have the identifier TPad, including modules which contain only a forward declaration of it.; ; Kudos Arpitha Raghunandan (@arpi-r)!. We still need some performance measurements but the preliminary results are promising. Performance; ===. Methodology; ---. We have a forwarding root.exe which essentially calls /usr/bin/time -v root.exe $@. We have processed and stored this information in csv files. We have run in three modes:; 1) root master without modules (modulesoff); 2) root master with modules (moduleson); 3) root master with this PR with modules (gmi). Run on `Ubuntu 18.10 on Intel® Core™ i5-8250U CPU @ 1.60GHz × 8`. Results Interpretation; ---; A general comparison between 2) and 3) show that this PR makes ROOT about 3% faster and 25% more memory efficient. A general comparison between 1) and 3) shows that modules are still less efficient in a few cases which is expected because the PR loads more modules than it should. This will be addressed in subsequent PRs. A good trend is that some test already show that 3) is better than 1). The raw data could be found [here](https://docs.google.com/spreadsheets/d/12tZ_tmenR7fytcZpigfLOarNq1tIqPubTXWWMwz8lJg/edit#gid=1476035460). [work was done by Arpitha Raghunandan (@arpi-r)]. Depends on #4005.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4016
https://github.com/root-project/root/pull/4016:498,Performance,load,load,498,"The global module index represents an efficient on-disk hash table which stores identifier->module mapping. Every time clang finds a unknown identifier we are informed and we can load the corresponding module on demand. This way we can provide minimal set of loaded modules. Currently, we see that for hsimple.C only the half of the modules are loaded. This can be further improved because we currently load all modules which have an identifier, that is when looking for (for example TPad) we will load all modules which have the identifier TPad, including modules which contain only a forward declaration of it.; ; Kudos Arpitha Raghunandan (@arpi-r)!. We still need some performance measurements but the preliminary results are promising. Performance; ===. Methodology; ---. We have a forwarding root.exe which essentially calls /usr/bin/time -v root.exe $@. We have processed and stored this information in csv files. We have run in three modes:; 1) root master without modules (modulesoff); 2) root master with modules (moduleson); 3) root master with this PR with modules (gmi). Run on `Ubuntu 18.10 on Intel® Core™ i5-8250U CPU @ 1.60GHz × 8`. Results Interpretation; ---; A general comparison between 2) and 3) show that this PR makes ROOT about 3% faster and 25% more memory efficient. A general comparison between 1) and 3) shows that modules are still less efficient in a few cases which is expected because the PR loads more modules than it should. This will be addressed in subsequent PRs. A good trend is that some test already show that 3) is better than 1). The raw data could be found [here](https://docs.google.com/spreadsheets/d/12tZ_tmenR7fytcZpigfLOarNq1tIqPubTXWWMwz8lJg/edit#gid=1476035460). [work was done by Arpitha Raghunandan (@arpi-r)]. Depends on #4005.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4016
https://github.com/root-project/root/pull/4016:673,Performance,perform,performance,673,"The global module index represents an efficient on-disk hash table which stores identifier->module mapping. Every time clang finds a unknown identifier we are informed and we can load the corresponding module on demand. This way we can provide minimal set of loaded modules. Currently, we see that for hsimple.C only the half of the modules are loaded. This can be further improved because we currently load all modules which have an identifier, that is when looking for (for example TPad) we will load all modules which have the identifier TPad, including modules which contain only a forward declaration of it.; ; Kudos Arpitha Raghunandan (@arpi-r)!. We still need some performance measurements but the preliminary results are promising. Performance; ===. Methodology; ---. We have a forwarding root.exe which essentially calls /usr/bin/time -v root.exe $@. We have processed and stored this information in csv files. We have run in three modes:; 1) root master without modules (modulesoff); 2) root master with modules (moduleson); 3) root master with this PR with modules (gmi). Run on `Ubuntu 18.10 on Intel® Core™ i5-8250U CPU @ 1.60GHz × 8`. Results Interpretation; ---; A general comparison between 2) and 3) show that this PR makes ROOT about 3% faster and 25% more memory efficient. A general comparison between 1) and 3) shows that modules are still less efficient in a few cases which is expected because the PR loads more modules than it should. This will be addressed in subsequent PRs. A good trend is that some test already show that 3) is better than 1). The raw data could be found [here](https://docs.google.com/spreadsheets/d/12tZ_tmenR7fytcZpigfLOarNq1tIqPubTXWWMwz8lJg/edit#gid=1476035460). [work was done by Arpitha Raghunandan (@arpi-r)]. Depends on #4005.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4016
https://github.com/root-project/root/pull/4016:741,Performance,Perform,Performance,741,"The global module index represents an efficient on-disk hash table which stores identifier->module mapping. Every time clang finds a unknown identifier we are informed and we can load the corresponding module on demand. This way we can provide minimal set of loaded modules. Currently, we see that for hsimple.C only the half of the modules are loaded. This can be further improved because we currently load all modules which have an identifier, that is when looking for (for example TPad) we will load all modules which have the identifier TPad, including modules which contain only a forward declaration of it.; ; Kudos Arpitha Raghunandan (@arpi-r)!. We still need some performance measurements but the preliminary results are promising. Performance; ===. Methodology; ---. We have a forwarding root.exe which essentially calls /usr/bin/time -v root.exe $@. We have processed and stored this information in csv files. We have run in three modes:; 1) root master without modules (modulesoff); 2) root master with modules (moduleson); 3) root master with this PR with modules (gmi). Run on `Ubuntu 18.10 on Intel® Core™ i5-8250U CPU @ 1.60GHz × 8`. Results Interpretation; ---; A general comparison between 2) and 3) show that this PR makes ROOT about 3% faster and 25% more memory efficient. A general comparison between 1) and 3) shows that modules are still less efficient in a few cases which is expected because the PR loads more modules than it should. This will be addressed in subsequent PRs. A good trend is that some test already show that 3) is better than 1). The raw data could be found [here](https://docs.google.com/spreadsheets/d/12tZ_tmenR7fytcZpigfLOarNq1tIqPubTXWWMwz8lJg/edit#gid=1476035460). [work was done by Arpitha Raghunandan (@arpi-r)]. Depends on #4005.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4016
https://github.com/root-project/root/pull/4016:1425,Performance,load,loads,1425,"The global module index represents an efficient on-disk hash table which stores identifier->module mapping. Every time clang finds a unknown identifier we are informed and we can load the corresponding module on demand. This way we can provide minimal set of loaded modules. Currently, we see that for hsimple.C only the half of the modules are loaded. This can be further improved because we currently load all modules which have an identifier, that is when looking for (for example TPad) we will load all modules which have the identifier TPad, including modules which contain only a forward declaration of it.; ; Kudos Arpitha Raghunandan (@arpi-r)!. We still need some performance measurements but the preliminary results are promising. Performance; ===. Methodology; ---. We have a forwarding root.exe which essentially calls /usr/bin/time -v root.exe $@. We have processed and stored this information in csv files. We have run in three modes:; 1) root master without modules (modulesoff); 2) root master with modules (moduleson); 3) root master with this PR with modules (gmi). Run on `Ubuntu 18.10 on Intel® Core™ i5-8250U CPU @ 1.60GHz × 8`. Results Interpretation; ---; A general comparison between 2) and 3) show that this PR makes ROOT about 3% faster and 25% more memory efficient. A general comparison between 1) and 3) shows that modules are still less efficient in a few cases which is expected because the PR loads more modules than it should. This will be addressed in subsequent PRs. A good trend is that some test already show that 3) is better than 1). The raw data could be found [here](https://docs.google.com/spreadsheets/d/12tZ_tmenR7fytcZpigfLOarNq1tIqPubTXWWMwz8lJg/edit#gid=1476035460). [work was done by Arpitha Raghunandan (@arpi-r)]. Depends on #4005.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4016
https://github.com/root-project/root/pull/4016:56,Security,hash,hash,56,"The global module index represents an efficient on-disk hash table which stores identifier->module mapping. Every time clang finds a unknown identifier we are informed and we can load the corresponding module on demand. This way we can provide minimal set of loaded modules. Currently, we see that for hsimple.C only the half of the modules are loaded. This can be further improved because we currently load all modules which have an identifier, that is when looking for (for example TPad) we will load all modules which have the identifier TPad, including modules which contain only a forward declaration of it.; ; Kudos Arpitha Raghunandan (@arpi-r)!. We still need some performance measurements but the preliminary results are promising. Performance; ===. Methodology; ---. We have a forwarding root.exe which essentially calls /usr/bin/time -v root.exe $@. We have processed and stored this information in csv files. We have run in three modes:; 1) root master without modules (modulesoff); 2) root master with modules (moduleson); 3) root master with this PR with modules (gmi). Run on `Ubuntu 18.10 on Intel® Core™ i5-8250U CPU @ 1.60GHz × 8`. Results Interpretation; ---; A general comparison between 2) and 3) show that this PR makes ROOT about 3% faster and 25% more memory efficient. A general comparison between 1) and 3) shows that modules are still less efficient in a few cases which is expected because the PR loads more modules than it should. This will be addressed in subsequent PRs. A good trend is that some test already show that 3) is better than 1). The raw data could be found [here](https://docs.google.com/spreadsheets/d/12tZ_tmenR7fytcZpigfLOarNq1tIqPubTXWWMwz8lJg/edit#gid=1476035460). [work was done by Arpitha Raghunandan (@arpi-r)]. Depends on #4005.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4016
https://github.com/root-project/root/pull/4016:1528,Testability,test,test,1528,"The global module index represents an efficient on-disk hash table which stores identifier->module mapping. Every time clang finds a unknown identifier we are informed and we can load the corresponding module on demand. This way we can provide minimal set of loaded modules. Currently, we see that for hsimple.C only the half of the modules are loaded. This can be further improved because we currently load all modules which have an identifier, that is when looking for (for example TPad) we will load all modules which have the identifier TPad, including modules which contain only a forward declaration of it.; ; Kudos Arpitha Raghunandan (@arpi-r)!. We still need some performance measurements but the preliminary results are promising. Performance; ===. Methodology; ---. We have a forwarding root.exe which essentially calls /usr/bin/time -v root.exe $@. We have processed and stored this information in csv files. We have run in three modes:; 1) root master without modules (modulesoff); 2) root master with modules (moduleson); 3) root master with this PR with modules (gmi). Run on `Ubuntu 18.10 on Intel® Core™ i5-8250U CPU @ 1.60GHz × 8`. Results Interpretation; ---; A general comparison between 2) and 3) show that this PR makes ROOT about 3% faster and 25% more memory efficient. A general comparison between 1) and 3) shows that modules are still less efficient in a few cases which is expected because the PR loads more modules than it should. This will be addressed in subsequent PRs. A good trend is that some test already show that 3) is better than 1). The raw data could be found [here](https://docs.google.com/spreadsheets/d/12tZ_tmenR7fytcZpigfLOarNq1tIqPubTXWWMwz8lJg/edit#gid=1476035460). [work was done by Arpitha Raghunandan (@arpi-r)]. Depends on #4005.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4016
https://github.com/root-project/root/pull/4017:76,Modifiability,plugin,plugins,76,After #3961 one should inform users that method not yet implemented for all plugins; Also fix introduced compiler warnings,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4017
https://github.com/root-project/root/pull/4019:51,Availability,avail,available,51,"The `df103_NanoAODHiggsAnalysis` tutorial, already available in C++, has been converted to PyROOT. In this tutorial, many functions are called as arguments to nodes in the RDataFrame computational graph. In Python, these could be either written as multiline strings and then exposed to the C++ interpeter one by one with `gInterpreter.Processline()`, or put all together in one C++ header which is then declared to the interpreter via `gInterpreter.Declare()`. This second approach has been pursued, thus there are two files making up the Python version of the tutorial: one `.h` file for the header and one `.py` file for the analysis itself.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4019
https://github.com/root-project/root/pull/4019:275,Security,expose,exposed,275,"The `df103_NanoAODHiggsAnalysis` tutorial, already available in C++, has been converted to PyROOT. In this tutorial, many functions are called as arguments to nodes in the RDataFrame computational graph. In Python, these could be either written as multiline strings and then exposed to the C++ interpeter one by one with `gInterpreter.Processline()`, or put all together in one C++ header which is then declared to the interpreter via `gInterpreter.Declare()`. This second approach has been pursued, thus there are two files making up the Python version of the tutorial: one `.h` file for the header and one `.py` file for the analysis itself.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4019
https://github.com/root-project/root/pull/4022:9,Usability,simpl,simple,9,It shows simple communication between c++ server and JS client,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4022
https://github.com/root-project/root/pull/4023:30,Usability,simpl,simple,30,Need an REveDataItem index in simple proxy builder in order to reuse common elements in same scene.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4023
https://github.com/root-project/root/pull/4025:0,Testability,Test,Test,0,"Test fails on aarch64 and ppc64le on Fedora 30 and Fedora rawhide:; Test 3 : Purge, Reuse of gaps in TFile......................... FAILED; File size= 52010 (expected 51886 +/- 100); Comp Fact= 2.00 (expected 2.1 +/- 0.3)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4025
https://github.com/root-project/root/pull/4025:68,Testability,Test,Test,68,"Test fails on aarch64 and ppc64le on Fedora 30 and Fedora rawhide:; Test 3 : Purge, Reuse of gaps in TFile......................... FAILED; File size= 52010 (expected 51886 +/- 100); Comp Fact= 2.00 (expected 2.1 +/- 0.3)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4025
https://github.com/root-project/root/pull/4026:513,Availability,down,download,513,* Remove man pages for non-existing binaries; They might have existed in the past: g2rootold genmap proofserva roota. * Install generated man pages in the correct subdirectory (man/man1). * Use the correct library name in the plugin definitions. * Remove obsolete plugin definition; libPeac was removed in version 5.34.01. * Simplify rule; No need to exclude files that no longer exists. * TWebVirtualX was removed - remove plugin definition using it; See commit a07af0afbe2e26237bf8ca059abc34255378a070. * Don't download input file if it already exists; This allows running the tests with pre-fetched file in environments without network - like e.g. the Fedora package build server. * Python 3 compatibility,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4026
https://github.com/root-project/root/pull/4026:120,Deployability,Install,Install,120,* Remove man pages for non-existing binaries; They might have existed in the past: g2rootold genmap proofserva roota. * Install generated man pages in the correct subdirectory (man/man1). * Use the correct library name in the plugin definitions. * Remove obsolete plugin definition; libPeac was removed in version 5.34.01. * Simplify rule; No need to exclude files that no longer exists. * TWebVirtualX was removed - remove plugin definition using it; See commit a07af0afbe2e26237bf8ca059abc34255378a070. * Don't download input file if it already exists; This allows running the tests with pre-fetched file in environments without network - like e.g. the Fedora package build server. * Python 3 compatibility,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4026
https://github.com/root-project/root/pull/4026:226,Modifiability,plugin,plugin,226,* Remove man pages for non-existing binaries; They might have existed in the past: g2rootold genmap proofserva roota. * Install generated man pages in the correct subdirectory (man/man1). * Use the correct library name in the plugin definitions. * Remove obsolete plugin definition; libPeac was removed in version 5.34.01. * Simplify rule; No need to exclude files that no longer exists. * TWebVirtualX was removed - remove plugin definition using it; See commit a07af0afbe2e26237bf8ca059abc34255378a070. * Don't download input file if it already exists; This allows running the tests with pre-fetched file in environments without network - like e.g. the Fedora package build server. * Python 3 compatibility,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4026
https://github.com/root-project/root/pull/4026:264,Modifiability,plugin,plugin,264,* Remove man pages for non-existing binaries; They might have existed in the past: g2rootold genmap proofserva roota. * Install generated man pages in the correct subdirectory (man/man1). * Use the correct library name in the plugin definitions. * Remove obsolete plugin definition; libPeac was removed in version 5.34.01. * Simplify rule; No need to exclude files that no longer exists. * TWebVirtualX was removed - remove plugin definition using it; See commit a07af0afbe2e26237bf8ca059abc34255378a070. * Don't download input file if it already exists; This allows running the tests with pre-fetched file in environments without network - like e.g. the Fedora package build server. * Python 3 compatibility,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4026
https://github.com/root-project/root/pull/4026:424,Modifiability,plugin,plugin,424,* Remove man pages for non-existing binaries; They might have existed in the past: g2rootold genmap proofserva roota. * Install generated man pages in the correct subdirectory (man/man1). * Use the correct library name in the plugin definitions. * Remove obsolete plugin definition; libPeac was removed in version 5.34.01. * Simplify rule; No need to exclude files that no longer exists. * TWebVirtualX was removed - remove plugin definition using it; See commit a07af0afbe2e26237bf8ca059abc34255378a070. * Don't download input file if it already exists; This allows running the tests with pre-fetched file in environments without network - like e.g. the Fedora package build server. * Python 3 compatibility,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4026
https://github.com/root-project/root/pull/4026:579,Testability,test,tests,579,* Remove man pages for non-existing binaries; They might have existed in the past: g2rootold genmap proofserva roota. * Install generated man pages in the correct subdirectory (man/man1). * Use the correct library name in the plugin definitions. * Remove obsolete plugin definition; libPeac was removed in version 5.34.01. * Simplify rule; No need to exclude files that no longer exists. * TWebVirtualX was removed - remove plugin definition using it; See commit a07af0afbe2e26237bf8ca059abc34255378a070. * Don't download input file if it already exists; This allows running the tests with pre-fetched file in environments without network - like e.g. the Fedora package build server. * Python 3 compatibility,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4026
https://github.com/root-project/root/pull/4026:325,Usability,Simpl,Simplify,325,* Remove man pages for non-existing binaries; They might have existed in the past: g2rootold genmap proofserva roota. * Install generated man pages in the correct subdirectory (man/man1). * Use the correct library name in the plugin definitions. * Remove obsolete plugin definition; libPeac was removed in version 5.34.01. * Simplify rule; No need to exclude files that no longer exists. * TWebVirtualX was removed - remove plugin definition using it; See commit a07af0afbe2e26237bf8ca059abc34255378a070. * Don't download input file if it already exists; This allows running the tests with pre-fetched file in environments without network - like e.g. the Fedora package build server. * Python 3 compatibility,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4026
https://github.com/root-project/root/pull/4029:41,Testability,test,test,41,Does this make sense? Could increase our test coverage.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4029
https://github.com/root-project/root/pull/4031:87,Integrability,interface,interface,87,"Provide access to whether the enum is a scoped enum through TEnum::Property().; Add an interface to determine the underlying type of an enum, as EDataType.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4031
https://github.com/root-project/root/pull/4031:8,Security,access,access,8,"Provide access to whether the enum is a scoped enum through TEnum::Property().; Add an interface to determine the underlying type of an enum, as EDataType.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4031
https://github.com/root-project/root/pull/4035:67,Safety,Avoid,Avoid,67,"Introduce special handler for connecting and disconnecting events; Avoid usage of predefined ""CONN_READY"" and ""CONN_CLOSED"" arguments; Adjust existing widgets and tutorials; These changes in callbacks **brakes backward compatibility** - in my mind, it was necessary. Hide RWebWindowsManager for ordinary users - provide convenience `RWebWindow::Create()` and `RWebWindow::TerinateROOT()` methods. Now one can include just `ROOT/RWebWindow.hxx` to get all necessary functionality. Provide tutorial with simple openui5 panel - of course, using new methods",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4035
https://github.com/root-project/root/pull/4035:502,Usability,simpl,simple,502,"Introduce special handler for connecting and disconnecting events; Avoid usage of predefined ""CONN_READY"" and ""CONN_CLOSED"" arguments; Adjust existing widgets and tutorials; These changes in callbacks **brakes backward compatibility** - in my mind, it was necessary. Hide RWebWindowsManager for ordinary users - provide convenience `RWebWindow::Create()` and `RWebWindow::TerinateROOT()` methods. Now one can include just `ROOT/RWebWindow.hxx` to get all necessary functionality. Provide tutorial with simple openui5 panel - of course, using new methods",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4035
https://github.com/root-project/root/pull/4037:1214,Availability,error,errors,1214,"I am trying to refactor the old code of ROOT I/O for compression but the even the simplest change has side effects across the code base so I would like to reach a consensus regarding how changes should be done. The changes of this PR are based on top of another PR https://github.com/root-project/root/pull/3947 for adding support for ZSTD so for our goal just focus on the following commits. ### Removed pointers and unsigned chars https://github.com/fylux/root/commit/155c405ba6beb21075f436a0380d1cb8378213c3; Most of the compression functions take pointers for values that should be constant, mainly the source and target size of the compression buffer.; Also there is a mess in the compression algorithms since consider the buffers as unsigned chars, and other as chars. The type does not matter since we are only working with bytes but we should use only one to avoid all the casting that we find across the code base. ## TODO; - Decide what type should be given for `tgtsize` and `srcsize`. The most suitable could be unsigned but perhaps in some section of the code a negative value is used to represent something.; - Instead of using `&irep` for returning information about the compressed size or possible errors better make that the function instead of being void is int so the return value would be `&irep`.; - ZLIB right now does not have separated files but it is embedded inside RZIP what is not desirable. It would be better to make it follow the same structure of LZ4 or LZMA.; - What is the current value of maintaining the legacy algorithm (from 1990) of ROOT compression? If it is maintained it would be nice to make it more readable and follow the same structure and naming as the rest of compression algorithm.; - [To be extended]",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4037
https://github.com/root-project/root/pull/4037:15,Modifiability,refactor,refactor,15,"I am trying to refactor the old code of ROOT I/O for compression but the even the simplest change has side effects across the code base so I would like to reach a consensus regarding how changes should be done. The changes of this PR are based on top of another PR https://github.com/root-project/root/pull/3947 for adding support for ZSTD so for our goal just focus on the following commits. ### Removed pointers and unsigned chars https://github.com/fylux/root/commit/155c405ba6beb21075f436a0380d1cb8378213c3; Most of the compression functions take pointers for values that should be constant, mainly the source and target size of the compression buffer.; Also there is a mess in the compression algorithms since consider the buffers as unsigned chars, and other as chars. The type does not matter since we are only working with bytes but we should use only one to avoid all the casting that we find across the code base. ## TODO; - Decide what type should be given for `tgtsize` and `srcsize`. The most suitable could be unsigned but perhaps in some section of the code a negative value is used to represent something.; - Instead of using `&irep` for returning information about the compressed size or possible errors better make that the function instead of being void is int so the return value would be `&irep`.; - ZLIB right now does not have separated files but it is embedded inside RZIP what is not desirable. It would be better to make it follow the same structure of LZ4 or LZMA.; - What is the current value of maintaining the legacy algorithm (from 1990) of ROOT compression? If it is maintained it would be nice to make it more readable and follow the same structure and naming as the rest of compression algorithm.; - [To be extended]",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4037
https://github.com/root-project/root/pull/4037:1741,Modifiability,extend,extended,1741,"I am trying to refactor the old code of ROOT I/O for compression but the even the simplest change has side effects across the code base so I would like to reach a consensus regarding how changes should be done. The changes of this PR are based on top of another PR https://github.com/root-project/root/pull/3947 for adding support for ZSTD so for our goal just focus on the following commits. ### Removed pointers and unsigned chars https://github.com/fylux/root/commit/155c405ba6beb21075f436a0380d1cb8378213c3; Most of the compression functions take pointers for values that should be constant, mainly the source and target size of the compression buffer.; Also there is a mess in the compression algorithms since consider the buffers as unsigned chars, and other as chars. The type does not matter since we are only working with bytes but we should use only one to avoid all the casting that we find across the code base. ## TODO; - Decide what type should be given for `tgtsize` and `srcsize`. The most suitable could be unsigned but perhaps in some section of the code a negative value is used to represent something.; - Instead of using `&irep` for returning information about the compressed size or possible errors better make that the function instead of being void is int so the return value would be `&irep`.; - ZLIB right now does not have separated files but it is embedded inside RZIP what is not desirable. It would be better to make it follow the same structure of LZ4 or LZMA.; - What is the current value of maintaining the legacy algorithm (from 1990) of ROOT compression? If it is maintained it would be nice to make it more readable and follow the same structure and naming as the rest of compression algorithm.; - [To be extended]",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4037
https://github.com/root-project/root/pull/4037:867,Safety,avoid,avoid,867,"I am trying to refactor the old code of ROOT I/O for compression but the even the simplest change has side effects across the code base so I would like to reach a consensus regarding how changes should be done. The changes of this PR are based on top of another PR https://github.com/root-project/root/pull/3947 for adding support for ZSTD so for our goal just focus on the following commits. ### Removed pointers and unsigned chars https://github.com/fylux/root/commit/155c405ba6beb21075f436a0380d1cb8378213c3; Most of the compression functions take pointers for values that should be constant, mainly the source and target size of the compression buffer.; Also there is a mess in the compression algorithms since consider the buffers as unsigned chars, and other as chars. The type does not matter since we are only working with bytes but we should use only one to avoid all the casting that we find across the code base. ## TODO; - Decide what type should be given for `tgtsize` and `srcsize`. The most suitable could be unsigned but perhaps in some section of the code a negative value is used to represent something.; - Instead of using `&irep` for returning information about the compressed size or possible errors better make that the function instead of being void is int so the return value would be `&irep`.; - ZLIB right now does not have separated files but it is embedded inside RZIP what is not desirable. It would be better to make it follow the same structure of LZ4 or LZMA.; - What is the current value of maintaining the legacy algorithm (from 1990) of ROOT compression? If it is maintained it would be nice to make it more readable and follow the same structure and naming as the rest of compression algorithm.; - [To be extended]",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4037
https://github.com/root-project/root/pull/4037:82,Usability,simpl,simplest,82,"I am trying to refactor the old code of ROOT I/O for compression but the even the simplest change has side effects across the code base so I would like to reach a consensus regarding how changes should be done. The changes of this PR are based on top of another PR https://github.com/root-project/root/pull/3947 for adding support for ZSTD so for our goal just focus on the following commits. ### Removed pointers and unsigned chars https://github.com/fylux/root/commit/155c405ba6beb21075f436a0380d1cb8378213c3; Most of the compression functions take pointers for values that should be constant, mainly the source and target size of the compression buffer.; Also there is a mess in the compression algorithms since consider the buffers as unsigned chars, and other as chars. The type does not matter since we are only working with bytes but we should use only one to avoid all the casting that we find across the code base. ## TODO; - Decide what type should be given for `tgtsize` and `srcsize`. The most suitable could be unsigned but perhaps in some section of the code a negative value is used to represent something.; - Instead of using `&irep` for returning information about the compressed size or possible errors better make that the function instead of being void is int so the return value would be `&irep`.; - ZLIB right now does not have separated files but it is embedded inside RZIP what is not desirable. It would be better to make it follow the same structure of LZ4 or LZMA.; - What is the current value of maintaining the legacy algorithm (from 1990) of ROOT compression? If it is maintained it would be nice to make it more readable and follow the same structure and naming as the rest of compression algorithm.; - [To be extended]",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4037
https://github.com/root-project/root/pull/4039:0,Deployability,Patch,Patch,0,Patch for 6.18 version will follow,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4039
https://github.com/root-project/root/pull/4043:12,Integrability,interface,interface,12,* Add array interface; * Add `__getitem__` magic; * Add tests,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4043
https://github.com/root-project/root/pull/4043:56,Testability,test,tests,56,* Add array interface; * Add `__getitem__` magic; * Add tests,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4043
https://github.com/root-project/root/pull/4047:69,Usability,clear,clear,69,"Newest qt 5.13.0 crashes here during exit.; Disable it, while is not clear if defaultProfile can be still used -; seems to be not",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4047
https://github.com/root-project/root/pull/4048:358,Modifiability,config,configure,358,"I think it would be really nice to be compliant with other Python packages and provide a `__version__` magic for the ROOT module. ~~But be careful: This comes at the cost of a direct use of ROOT at startup time (non-lazy! Am I right?). I don't see how we could do this besides doing some template/macro magic and copying the version number to the sources at configure time.~~. Since the ROOT module is actually a class instance, we can add a `property`, which is evaluated lazily. Nice! :). And added tests for the ROOT module!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4048
https://github.com/root-project/root/pull/4048:501,Testability,test,tests,501,"I think it would be really nice to be compliant with other Python packages and provide a `__version__` magic for the ROOT module. ~~But be careful: This comes at the cost of a direct use of ROOT at startup time (non-lazy! Am I right?). I don't see how we could do this besides doing some template/macro magic and copying the version number to the sources at configure time.~~. Since the ROOT module is actually a class instance, we can add a `property`, which is evaluated lazily. Nice! :). And added tests for the ROOT module!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4048
https://github.com/root-project/root/pull/4049:186,Deployability,patch,patch,186,"- When `CMAKE_CXX_FLAGS` are defined at the command line, the; build-type-specific flags will be appended to `CMAKE_CXX_FLAGS`,; possibly overriding all flags set by users.; - With this patch, pre-defined ROOT flags are prepended, giving; users the option to override flags like -O2.; - Further, a status message is printed when ROOT overrides the build type and the final compiler flags are also printed in the correct order. Previously, these flags were printed wrongly, giving the false impression that the user could override e.g. the `-O` flags.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4049
https://github.com/root-project/root/pull/4049:305,Integrability,message,message,305,"- When `CMAKE_CXX_FLAGS` are defined at the command line, the; build-type-specific flags will be appended to `CMAKE_CXX_FLAGS`,; possibly overriding all flags set by users.; - With this patch, pre-defined ROOT flags are prepended, giving; users the option to override flags like -O2.; - Further, a status message is printed when ROOT overrides the build type and the final compiler flags are also printed in the correct order. Previously, these flags were printed wrongly, giving the false impression that the user could override e.g. the `-O` flags.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4049
https://github.com/root-project/root/pull/4050:34,Deployability,install,installed,34,"This is necessary to avoid ROOT's installed cmake modules to point to the build directory when using builtin GSL, since `$GSL_LIBRARIES` is the full path to `<BINARY_DIR>/lib/libgsl.so` when using builtin GSL.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4050
https://github.com/root-project/root/pull/4050:21,Safety,avoid,avoid,21,"This is necessary to avoid ROOT's installed cmake modules to point to the build directory when using builtin GSL, since `$GSL_LIBRARIES` is the full path to `<BINARY_DIR>/lib/libgsl.so` when using builtin GSL.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4050
https://github.com/root-project/root/pull/4051:8,Deployability,update,updates,8,This PR updates Cppyy to the following versions:; - cppyy to 1.4.2; - cppyy-backend to clingwrapper-1.9.0; - CPyCppyy to 1.8.2,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4051
https://github.com/root-project/root/pull/4056:57,Energy Efficiency,monitor,monitoring,57,"Now JSROOT.TGeoPainter can be used with THttpServer for ""monitoring"" of; geometry object. Exactly like a histogram, TGeoManager can be regularly; received and dsiplayed. Also tracks can be monitored together; Provide tutorial macro",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4056
https://github.com/root-project/root/pull/4056:189,Energy Efficiency,monitor,monitored,189,"Now JSROOT.TGeoPainter can be used with THttpServer for ""monitoring"" of; geometry object. Exactly like a histogram, TGeoManager can be regularly; received and dsiplayed. Also tracks can be monitored together; Provide tutorial macro",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4056
https://github.com/root-project/root/pull/4059:218,Performance,optimiz,optimization,218,"REveManager sends BeginChanges before sending the change content, and sends EndChanges after changes have been applied. The end redraw callback loops over changes scenes and repaints them. This change also contains an optimization in table view: bind table to its model only at the time of construction or a change of the displayed collection.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4059
https://github.com/root-project/root/pull/4060:174,Availability,error,errors,174,"I am refactoring the old code of ROOT I/O for compression. Some part of the code are up to 30 years old and from my experience that the C style code that is used is prone to errors for developers that are not familiar with the code. Since one of the goals of ROOT is to be maintainable, I think that this can be very helpful.; Nonetheless, even the simplest change has side effects across the code base so I would like to reach a consensus regarding how changes should be done. The changes that have been done so far are the following:. ### Removed pointers https://github.com/fylux/root/commit/155c405ba6beb21075f436a0380d1cb8378213c3; Most of the compression functions take pointers for values that should be constant, mainly the source and target size of the compression buffer. Also, the irep now is a reference rather than a pointer. However, I think that it would be better to make the function not void and instead of using irep just return a value. ## TODO; - Decide what type should be given for `tgtsize` and `srcsize`. The most suitable could be const unsigned but perhaps in some section of the code a negative value is used to represent something.; - Instead of using `&irep` for returning information about the compressed size or possible errors better make that the function instead of being void is int so the return value would be `&irep`.; - ZLIB right now does not have separated files but it is embedded inside RZIP what is not desirable. It would be better to make it follow the same structure of LZ4 or LZMA.; - [To be extended]",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4060
https://github.com/root-project/root/pull/4060:1253,Availability,error,errors,1253,"I am refactoring the old code of ROOT I/O for compression. Some part of the code are up to 30 years old and from my experience that the C style code that is used is prone to errors for developers that are not familiar with the code. Since one of the goals of ROOT is to be maintainable, I think that this can be very helpful.; Nonetheless, even the simplest change has side effects across the code base so I would like to reach a consensus regarding how changes should be done. The changes that have been done so far are the following:. ### Removed pointers https://github.com/fylux/root/commit/155c405ba6beb21075f436a0380d1cb8378213c3; Most of the compression functions take pointers for values that should be constant, mainly the source and target size of the compression buffer. Also, the irep now is a reference rather than a pointer. However, I think that it would be better to make the function not void and instead of using irep just return a value. ## TODO; - Decide what type should be given for `tgtsize` and `srcsize`. The most suitable could be const unsigned but perhaps in some section of the code a negative value is used to represent something.; - Instead of using `&irep` for returning information about the compressed size or possible errors better make that the function instead of being void is int so the return value would be `&irep`.; - ZLIB right now does not have separated files but it is embedded inside RZIP what is not desirable. It would be better to make it follow the same structure of LZ4 or LZMA.; - [To be extended]",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4060
https://github.com/root-project/root/pull/4060:5,Modifiability,refactor,refactoring,5,"I am refactoring the old code of ROOT I/O for compression. Some part of the code are up to 30 years old and from my experience that the C style code that is used is prone to errors for developers that are not familiar with the code. Since one of the goals of ROOT is to be maintainable, I think that this can be very helpful.; Nonetheless, even the simplest change has side effects across the code base so I would like to reach a consensus regarding how changes should be done. The changes that have been done so far are the following:. ### Removed pointers https://github.com/fylux/root/commit/155c405ba6beb21075f436a0380d1cb8378213c3; Most of the compression functions take pointers for values that should be constant, mainly the source and target size of the compression buffer. Also, the irep now is a reference rather than a pointer. However, I think that it would be better to make the function not void and instead of using irep just return a value. ## TODO; - Decide what type should be given for `tgtsize` and `srcsize`. The most suitable could be const unsigned but perhaps in some section of the code a negative value is used to represent something.; - Instead of using `&irep` for returning information about the compressed size or possible errors better make that the function instead of being void is int so the return value would be `&irep`.; - ZLIB right now does not have separated files but it is embedded inside RZIP what is not desirable. It would be better to make it follow the same structure of LZ4 or LZMA.; - [To be extended]",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4060
https://github.com/root-project/root/pull/4060:273,Modifiability,maintainab,maintainable,273,"I am refactoring the old code of ROOT I/O for compression. Some part of the code are up to 30 years old and from my experience that the C style code that is used is prone to errors for developers that are not familiar with the code. Since one of the goals of ROOT is to be maintainable, I think that this can be very helpful.; Nonetheless, even the simplest change has side effects across the code base so I would like to reach a consensus regarding how changes should be done. The changes that have been done so far are the following:. ### Removed pointers https://github.com/fylux/root/commit/155c405ba6beb21075f436a0380d1cb8378213c3; Most of the compression functions take pointers for values that should be constant, mainly the source and target size of the compression buffer. Also, the irep now is a reference rather than a pointer. However, I think that it would be better to make the function not void and instead of using irep just return a value. ## TODO; - Decide what type should be given for `tgtsize` and `srcsize`. The most suitable could be const unsigned but perhaps in some section of the code a negative value is used to represent something.; - Instead of using `&irep` for returning information about the compressed size or possible errors better make that the function instead of being void is int so the return value would be `&irep`.; - ZLIB right now does not have separated files but it is embedded inside RZIP what is not desirable. It would be better to make it follow the same structure of LZ4 or LZMA.; - [To be extended]",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4060
https://github.com/root-project/root/pull/4060:1541,Modifiability,extend,extended,1541,"I am refactoring the old code of ROOT I/O for compression. Some part of the code are up to 30 years old and from my experience that the C style code that is used is prone to errors for developers that are not familiar with the code. Since one of the goals of ROOT is to be maintainable, I think that this can be very helpful.; Nonetheless, even the simplest change has side effects across the code base so I would like to reach a consensus regarding how changes should be done. The changes that have been done so far are the following:. ### Removed pointers https://github.com/fylux/root/commit/155c405ba6beb21075f436a0380d1cb8378213c3; Most of the compression functions take pointers for values that should be constant, mainly the source and target size of the compression buffer. Also, the irep now is a reference rather than a pointer. However, I think that it would be better to make the function not void and instead of using irep just return a value. ## TODO; - Decide what type should be given for `tgtsize` and `srcsize`. The most suitable could be const unsigned but perhaps in some section of the code a negative value is used to represent something.; - Instead of using `&irep` for returning information about the compressed size or possible errors better make that the function instead of being void is int so the return value would be `&irep`.; - ZLIB right now does not have separated files but it is embedded inside RZIP what is not desirable. It would be better to make it follow the same structure of LZ4 or LZMA.; - [To be extended]",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4060
https://github.com/root-project/root/pull/4060:349,Usability,simpl,simplest,349,"I am refactoring the old code of ROOT I/O for compression. Some part of the code are up to 30 years old and from my experience that the C style code that is used is prone to errors for developers that are not familiar with the code. Since one of the goals of ROOT is to be maintainable, I think that this can be very helpful.; Nonetheless, even the simplest change has side effects across the code base so I would like to reach a consensus regarding how changes should be done. The changes that have been done so far are the following:. ### Removed pointers https://github.com/fylux/root/commit/155c405ba6beb21075f436a0380d1cb8378213c3; Most of the compression functions take pointers for values that should be constant, mainly the source and target size of the compression buffer. Also, the irep now is a reference rather than a pointer. However, I think that it would be better to make the function not void and instead of using irep just return a value. ## TODO; - Decide what type should be given for `tgtsize` and `srcsize`. The most suitable could be const unsigned but perhaps in some section of the code a negative value is used to represent something.; - Instead of using `&irep` for returning information about the compressed size or possible errors better make that the function instead of being void is int so the return value would be `&irep`.; - ZLIB right now does not have separated files but it is embedded inside RZIP what is not desirable. It would be better to make it follow the same structure of LZ4 or LZMA.; - [To be extended]",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4060
https://github.com/root-project/root/pull/4062:118,Deployability,configurat,configuration,118,Fix a long standing issue with popup (and context) menus popping up on wrong display on Windows with multiple display configuration,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4062
https://github.com/root-project/root/pull/4062:118,Modifiability,config,configuration,118,Fix a long standing issue with popup (and context) menus popping up on wrong display on Windows with multiple display configuration,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4062
https://github.com/root-project/root/pull/4063:62,Performance,load,loaded,62,"When specified, all kinds of JS scripts and ui5 files will be loaded from; URL path, which includes such version tag. Therefore when version is; changed in C++, all related scripts will be automatically reloaded. . This helps to solve browser cache problem, especially for; development phase. Normally browser heavily uses cached files, but if; one changes these files, one should explain every user that he/she must; clear the cache. With provided solution no any user intervention are; required.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4063
https://github.com/root-project/root/pull/4063:243,Performance,cache,cache,243,"When specified, all kinds of JS scripts and ui5 files will be loaded from; URL path, which includes such version tag. Therefore when version is; changed in C++, all related scripts will be automatically reloaded. . This helps to solve browser cache problem, especially for; development phase. Normally browser heavily uses cached files, but if; one changes these files, one should explain every user that he/she must; clear the cache. With provided solution no any user intervention are; required.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4063
https://github.com/root-project/root/pull/4063:323,Performance,cache,cached,323,"When specified, all kinds of JS scripts and ui5 files will be loaded from; URL path, which includes such version tag. Therefore when version is; changed in C++, all related scripts will be automatically reloaded. . This helps to solve browser cache problem, especially for; development phase. Normally browser heavily uses cached files, but if; one changes these files, one should explain every user that he/she must; clear the cache. With provided solution no any user intervention are; required.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4063
https://github.com/root-project/root/pull/4063:428,Performance,cache,cache,428,"When specified, all kinds of JS scripts and ui5 files will be loaded from; URL path, which includes such version tag. Therefore when version is; changed in C++, all related scripts will be automatically reloaded. . This helps to solve browser cache problem, especially for; development phase. Normally browser heavily uses cached files, but if; one changes these files, one should explain every user that he/she must; clear the cache. With provided solution no any user intervention are; required.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4063
https://github.com/root-project/root/pull/4063:418,Usability,clear,clear,418,"When specified, all kinds of JS scripts and ui5 files will be loaded from; URL path, which includes such version tag. Therefore when version is; changed in C++, all related scripts will be automatically reloaded. . This helps to solve browser cache problem, especially for; development phase. Normally browser heavily uses cached files, but if; one changes these files, one should explain every user that he/she must; clear the cache. With provided solution no any user intervention are; required.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4063
https://github.com/root-project/root/pull/4065:92,Deployability,integrat,integrating,92,"The integral of the crystal ball shape might vanish quickly due to; a finite precision when integrating far from the centre.; This leads to divisions by zero.; Now, a very small value is returned.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4065
https://github.com/root-project/root/pull/4065:92,Integrability,integrat,integrating,92,"The integral of the crystal ball shape might vanish quickly due to; a finite precision when integrating far from the centre.; This leads to divisions by zero.; Now, a very small value is returned.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4065
https://github.com/root-project/root/pull/4068:112,Deployability,patch,patch,112,"Fixes ~20 from 100 existing warnings on Windows, ; remaining warnings are from llvm and clang, which is hard to patch now.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4068
https://github.com/root-project/root/pull/4071:769,Deployability,update,updated,769,"This PR continues the work started in #4019 . The discussed changes have been applied. . Regarding the usage of a header just for the Python version of the tutorial, for the moment the name of the header has been extended with ""_python"". Plus, the comments at the top already stressed the fact that it is declared in the Python version. Of course the C++ version could be refactored in order to declare the header as well, at the moment the only main difference would be that in C++ some filtering functions are written as lambdas, while in Python they have been added as free functions in the header and then get declared to the interpreter. In general, the following suggested changes have been applied:; 1. The tutorial is now PEP8 compliant; 2. The header has been updated with the latest version of the C++ tutorial ([commit](https://github.com/root-project/root/commit/bd821cc6ec7ce18d0105ca97959a7ed9fb0a7004)); 3. Weights are now passed as formatted strings of constant values to the `Histo1D` functions; 4. Path to the header *should* be platform independent. Further suggestions are deeply appreciated",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4071
https://github.com/root-project/root/pull/4071:213,Modifiability,extend,extended,213,"This PR continues the work started in #4019 . The discussed changes have been applied. . Regarding the usage of a header just for the Python version of the tutorial, for the moment the name of the header has been extended with ""_python"". Plus, the comments at the top already stressed the fact that it is declared in the Python version. Of course the C++ version could be refactored in order to declare the header as well, at the moment the only main difference would be that in C++ some filtering functions are written as lambdas, while in Python they have been added as free functions in the header and then get declared to the interpreter. In general, the following suggested changes have been applied:; 1. The tutorial is now PEP8 compliant; 2. The header has been updated with the latest version of the C++ tutorial ([commit](https://github.com/root-project/root/commit/bd821cc6ec7ce18d0105ca97959a7ed9fb0a7004)); 3. Weights are now passed as formatted strings of constant values to the `Histo1D` functions; 4. Path to the header *should* be platform independent. Further suggestions are deeply appreciated",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4071
https://github.com/root-project/root/pull/4071:372,Modifiability,refactor,refactored,372,"This PR continues the work started in #4019 . The discussed changes have been applied. . Regarding the usage of a header just for the Python version of the tutorial, for the moment the name of the header has been extended with ""_python"". Plus, the comments at the top already stressed the fact that it is declared in the Python version. Of course the C++ version could be refactored in order to declare the header as well, at the moment the only main difference would be that in C++ some filtering functions are written as lambdas, while in Python they have been added as free functions in the header and then get declared to the interpreter. In general, the following suggested changes have been applied:; 1. The tutorial is now PEP8 compliant; 2. The header has been updated with the latest version of the C++ tutorial ([commit](https://github.com/root-project/root/commit/bd821cc6ec7ce18d0105ca97959a7ed9fb0a7004)); 3. Weights are now passed as formatted strings of constant values to the `Histo1D` functions; 4. Path to the header *should* be platform independent. Further suggestions are deeply appreciated",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4071
https://github.com/root-project/root/pull/4072:4,Testability,test,test,4,"The test mentioned above was rewritten in order to pass in Experimental PyROOT.; What made the test passing in the current PyROOT and failing in the Experimental one is the absence in Cppyy of a converter function which works with Python objects of type NoneType and is fired in lines like the following:; `leg.AddEntry(L[0].Draw(), "" L_{0}(x)"", ""l"")`; The presence of this function basically splits the above command like the following: ; 1. the function is drawn on the canvas with the command; `L[0].Draw()`; 2. the entry is added to the legend with the command; `leg.AddEntry(None, "" L_{0}(x)"", ""l"")`; Since it's also conceptually wrong to put the Draw() method as argument of the AddEntry function, it was decided to do the two things separately with a loop over the elements of the L list.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4072
https://github.com/root-project/root/pull/4072:95,Testability,test,test,95,"The test mentioned above was rewritten in order to pass in Experimental PyROOT.; What made the test passing in the current PyROOT and failing in the Experimental one is the absence in Cppyy of a converter function which works with Python objects of type NoneType and is fired in lines like the following:; `leg.AddEntry(L[0].Draw(), "" L_{0}(x)"", ""l"")`; The presence of this function basically splits the above command like the following: ; 1. the function is drawn on the canvas with the command; `L[0].Draw()`; 2. the entry is added to the legend with the command; `leg.AddEntry(None, "" L_{0}(x)"", ""l"")`; Since it's also conceptually wrong to put the Draw() method as argument of the AddEntry function, it was decided to do the two things separately with a loop over the elements of the L list.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4072
https://github.com/root-project/root/pull/4074:212,Deployability,canary,canary,212,"If the constructor of the contained object is not run (e.g. because; assembling its arguments triggered an exception), the dtor must not; be run when destructing the cling::Value. Detect this case by imprinting; canary bytes into the contained object bytes: if they have changed,; run the dtor, if not assume that the constructor has failed. This will cause false positives in those cases where the constructor; is not modifying the first object bytes: in these cases, the dtor; is not run even though the ctor is run. That is still better than; the other case (where the dtor crashes because no ctor was run).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4074
https://github.com/root-project/root/pull/4074:180,Safety,Detect,Detect,180,"If the constructor of the contained object is not run (e.g. because; assembling its arguments triggered an exception), the dtor must not; be run when destructing the cling::Value. Detect this case by imprinting; canary bytes into the contained object bytes: if they have changed,; run the dtor, if not assume that the constructor has failed. This will cause false positives in those cases where the constructor; is not modifying the first object bytes: in these cases, the dtor; is not run even though the ctor is run. That is still better than; the other case (where the dtor crashes because no ctor was run).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4074
https://github.com/root-project/root/pull/4078:0,Deployability,Update,Update,0,Update of the previous pull request #4077,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4078
https://github.com/root-project/root/pull/4079:62,Testability,Test,Tested,62,This changes are need for collection_proxies.C demo to work.; Tested this on Fedora 30.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4079
https://github.com/root-project/root/pull/4081:132,Usability,user-friendly,user-friendly,132,"RNTuple stores data in a directory. Upon opening this directory in TBrowser, not the opaque internal keys should be displayed but a user-friendly representation of the ntuple structure (fields). Thus, a new TDirectoryFile bit is introduced that should indicate to the TBrowser that an object of the type set in the directory's title shall take care of the in-directory browsing. @bellenot @Axel-Naumann Please have a look.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4081
https://github.com/root-project/root/pull/4083:217,Deployability,patch,patch,217,"Hi @Axel-Naumann,. This is not really a pull request but I thought it might be a good way to get feedback from you guys and maybe some help improving it. This is not meant for merging, we are fine with an out of tree patch for now, but we would of course be very happy if something like this becomes upstream eventually. This is a very ""hacky"" try to be able to create ROOT files with; deterministic checksum that is not dependent on timestamp or hostname or; anything: Create a file with the same content twice on different; machines should yield the same checksum (assuming they have the same root file format version and same class definitions ...). We cannot really modify the software using these checksums and it's not just ROOT files but also other files in there so a distinction between ""content checksum"" and ""file checksum"" would be rather tricky. That's why we went for the brutal approach. We need this mostly for small files in a well controlled environment:; The file is created in one place at one time and not incrementally over; a long time, no threads. . So we would be fine with a global flag to not store time dependent information in files but it is of course ugly. A slightly less horrific version might be to have a `TDeterministicFile` which behaves like `TFile` with the only difference that it has a zeros for dates/uuids but I don't know the classes well enough to judge if that is feasible.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4083
https://github.com/root-project/root/pull/4083:421,Integrability,depend,dependent,421,"Hi @Axel-Naumann,. This is not really a pull request but I thought it might be a good way to get feedback from you guys and maybe some help improving it. This is not meant for merging, we are fine with an out of tree patch for now, but we would of course be very happy if something like this becomes upstream eventually. This is a very ""hacky"" try to be able to create ROOT files with; deterministic checksum that is not dependent on timestamp or hostname or; anything: Create a file with the same content twice on different; machines should yield the same checksum (assuming they have the same root file format version and same class definitions ...). We cannot really modify the software using these checksums and it's not just ROOT files but also other files in there so a distinction between ""content checksum"" and ""file checksum"" would be rather tricky. That's why we went for the brutal approach. We need this mostly for small files in a well controlled environment:; The file is created in one place at one time and not incrementally over; a long time, no threads. . So we would be fine with a global flag to not store time dependent information in files but it is of course ugly. A slightly less horrific version might be to have a `TDeterministicFile` which behaves like `TFile` with the only difference that it has a zeros for dates/uuids but I don't know the classes well enough to judge if that is feasible.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4083
https://github.com/root-project/root/pull/4083:1131,Integrability,depend,dependent,1131,"Hi @Axel-Naumann,. This is not really a pull request but I thought it might be a good way to get feedback from you guys and maybe some help improving it. This is not meant for merging, we are fine with an out of tree patch for now, but we would of course be very happy if something like this becomes upstream eventually. This is a very ""hacky"" try to be able to create ROOT files with; deterministic checksum that is not dependent on timestamp or hostname or; anything: Create a file with the same content twice on different; machines should yield the same checksum (assuming they have the same root file format version and same class definitions ...). We cannot really modify the software using these checksums and it's not just ROOT files but also other files in there so a distinction between ""content checksum"" and ""file checksum"" would be rather tricky. That's why we went for the brutal approach. We need this mostly for small files in a well controlled environment:; The file is created in one place at one time and not incrementally over; a long time, no threads. . So we would be fine with a global flag to not store time dependent information in files but it is of course ugly. A slightly less horrific version might be to have a `TDeterministicFile` which behaves like `TFile` with the only difference that it has a zeros for dates/uuids but I don't know the classes well enough to judge if that is feasible.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4083
https://github.com/root-project/root/pull/4083:400,Security,checksum,checksum,400,"Hi @Axel-Naumann,. This is not really a pull request but I thought it might be a good way to get feedback from you guys and maybe some help improving it. This is not meant for merging, we are fine with an out of tree patch for now, but we would of course be very happy if something like this becomes upstream eventually. This is a very ""hacky"" try to be able to create ROOT files with; deterministic checksum that is not dependent on timestamp or hostname or; anything: Create a file with the same content twice on different; machines should yield the same checksum (assuming they have the same root file format version and same class definitions ...). We cannot really modify the software using these checksums and it's not just ROOT files but also other files in there so a distinction between ""content checksum"" and ""file checksum"" would be rather tricky. That's why we went for the brutal approach. We need this mostly for small files in a well controlled environment:; The file is created in one place at one time and not incrementally over; a long time, no threads. . So we would be fine with a global flag to not store time dependent information in files but it is of course ugly. A slightly less horrific version might be to have a `TDeterministicFile` which behaves like `TFile` with the only difference that it has a zeros for dates/uuids but I don't know the classes well enough to judge if that is feasible.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4083
https://github.com/root-project/root/pull/4083:557,Security,checksum,checksum,557,"Hi @Axel-Naumann,. This is not really a pull request but I thought it might be a good way to get feedback from you guys and maybe some help improving it. This is not meant for merging, we are fine with an out of tree patch for now, but we would of course be very happy if something like this becomes upstream eventually. This is a very ""hacky"" try to be able to create ROOT files with; deterministic checksum that is not dependent on timestamp or hostname or; anything: Create a file with the same content twice on different; machines should yield the same checksum (assuming they have the same root file format version and same class definitions ...). We cannot really modify the software using these checksums and it's not just ROOT files but also other files in there so a distinction between ""content checksum"" and ""file checksum"" would be rather tricky. That's why we went for the brutal approach. We need this mostly for small files in a well controlled environment:; The file is created in one place at one time and not incrementally over; a long time, no threads. . So we would be fine with a global flag to not store time dependent information in files but it is of course ugly. A slightly less horrific version might be to have a `TDeterministicFile` which behaves like `TFile` with the only difference that it has a zeros for dates/uuids but I don't know the classes well enough to judge if that is feasible.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4083
https://github.com/root-project/root/pull/4083:702,Security,checksum,checksums,702,"Hi @Axel-Naumann,. This is not really a pull request but I thought it might be a good way to get feedback from you guys and maybe some help improving it. This is not meant for merging, we are fine with an out of tree patch for now, but we would of course be very happy if something like this becomes upstream eventually. This is a very ""hacky"" try to be able to create ROOT files with; deterministic checksum that is not dependent on timestamp or hostname or; anything: Create a file with the same content twice on different; machines should yield the same checksum (assuming they have the same root file format version and same class definitions ...). We cannot really modify the software using these checksums and it's not just ROOT files but also other files in there so a distinction between ""content checksum"" and ""file checksum"" would be rather tricky. That's why we went for the brutal approach. We need this mostly for small files in a well controlled environment:; The file is created in one place at one time and not incrementally over; a long time, no threads. . So we would be fine with a global flag to not store time dependent information in files but it is of course ugly. A slightly less horrific version might be to have a `TDeterministicFile` which behaves like `TFile` with the only difference that it has a zeros for dates/uuids but I don't know the classes well enough to judge if that is feasible.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4083
https://github.com/root-project/root/pull/4083:805,Security,checksum,checksum,805,"Hi @Axel-Naumann,. This is not really a pull request but I thought it might be a good way to get feedback from you guys and maybe some help improving it. This is not meant for merging, we are fine with an out of tree patch for now, but we would of course be very happy if something like this becomes upstream eventually. This is a very ""hacky"" try to be able to create ROOT files with; deterministic checksum that is not dependent on timestamp or hostname or; anything: Create a file with the same content twice on different; machines should yield the same checksum (assuming they have the same root file format version and same class definitions ...). We cannot really modify the software using these checksums and it's not just ROOT files but also other files in there so a distinction between ""content checksum"" and ""file checksum"" would be rather tricky. That's why we went for the brutal approach. We need this mostly for small files in a well controlled environment:; The file is created in one place at one time and not incrementally over; a long time, no threads. . So we would be fine with a global flag to not store time dependent information in files but it is of course ugly. A slightly less horrific version might be to have a `TDeterministicFile` which behaves like `TFile` with the only difference that it has a zeros for dates/uuids but I don't know the classes well enough to judge if that is feasible.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4083
https://github.com/root-project/root/pull/4083:825,Security,checksum,checksum,825,"Hi @Axel-Naumann,. This is not really a pull request but I thought it might be a good way to get feedback from you guys and maybe some help improving it. This is not meant for merging, we are fine with an out of tree patch for now, but we would of course be very happy if something like this becomes upstream eventually. This is a very ""hacky"" try to be able to create ROOT files with; deterministic checksum that is not dependent on timestamp or hostname or; anything: Create a file with the same content twice on different; machines should yield the same checksum (assuming they have the same root file format version and same class definitions ...). We cannot really modify the software using these checksums and it's not just ROOT files but also other files in there so a distinction between ""content checksum"" and ""file checksum"" would be rather tricky. That's why we went for the brutal approach. We need this mostly for small files in a well controlled environment:; The file is created in one place at one time and not incrementally over; a long time, no threads. . So we would be fine with a global flag to not store time dependent information in files but it is of course ugly. A slightly less horrific version might be to have a `TDeterministicFile` which behaves like `TFile` with the only difference that it has a zeros for dates/uuids but I don't know the classes well enough to judge if that is feasible.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4083
https://github.com/root-project/root/pull/4083:97,Usability,feedback,feedback,97,"Hi @Axel-Naumann,. This is not really a pull request but I thought it might be a good way to get feedback from you guys and maybe some help improving it. This is not meant for merging, we are fine with an out of tree patch for now, but we would of course be very happy if something like this becomes upstream eventually. This is a very ""hacky"" try to be able to create ROOT files with; deterministic checksum that is not dependent on timestamp or hostname or; anything: Create a file with the same content twice on different; machines should yield the same checksum (assuming they have the same root file format version and same class definitions ...). We cannot really modify the software using these checksums and it's not just ROOT files but also other files in there so a distinction between ""content checksum"" and ""file checksum"" would be rather tricky. That's why we went for the brutal approach. We need this mostly for small files in a well controlled environment:; The file is created in one place at one time and not incrementally over; a long time, no threads. . So we would be fine with a global flag to not store time dependent information in files but it is of course ugly. A slightly less horrific version might be to have a `TDeterministicFile` which behaves like `TFile` with the only difference that it has a zeros for dates/uuids but I don't know the classes well enough to judge if that is feasible.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4083
https://github.com/root-project/root/pull/4084:156,Performance,perform,performed,156,"The tutorials ""tutorial-pyroot-geometry-py"" and ""tutorial-pyroot-na49view-py"" were failing in Experimental PyROOT because of the absence of an extra lookup performed inside gROOT, which was implemented in the old PyROOT in the function LookupCppInstance(). ; It was decided to solve this problem by adding this third lookup to the _fallback_getattr() function inside _facade.py. ; This also allow to get an object inside gROOT by simply typing:; `ROOT.a`; instead of ; `ROOT.gROOT.FindObject(a)`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4084
https://github.com/root-project/root/pull/4084:430,Usability,simpl,simply,430,"The tutorials ""tutorial-pyroot-geometry-py"" and ""tutorial-pyroot-na49view-py"" were failing in Experimental PyROOT because of the absence of an extra lookup performed inside gROOT, which was implemented in the old PyROOT in the function LookupCppInstance(). ; It was decided to solve this problem by adding this third lookup to the _fallback_getattr() function inside _facade.py. ; This also allow to get an object inside gROOT by simply typing:; `ROOT.a`; instead of ; `ROOT.gROOT.FindObject(a)`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4084
https://github.com/root-project/root/pull/4088:26,Performance,perform,performance,26,"We would like to get some performance evaluations from the cmssw side. This PR is a continuation from PR #3012 . @smuzaffar, @mrodozov, could you build ROOT's cxxmodule IB against this PR and see if there are performance difference with and without this PR?",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4088
https://github.com/root-project/root/pull/4088:209,Performance,perform,performance,209,"We would like to get some performance evaluations from the cmssw side. This PR is a continuation from PR #3012 . @smuzaffar, @mrodozov, could you build ROOT's cxxmodule IB against this PR and see if there are performance difference with and without this PR?",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4088
https://github.com/root-project/root/pull/4091:21,Performance,perform,performance,21,It contains multiple performance improvements comparing to lz4 1.8.5.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4091
https://github.com/root-project/root/pull/4092:4,Availability,avail,available,4,Not available in ROOT's minimal cmake version.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4092
https://github.com/root-project/root/pull/4094:336,Availability,mainten,maintenance,336,"This is first attempt to provide support of custom classes in web-based canvas; For now one has to register list of such classes and provide JavaScript code where painters are implemented. . Similar approach can be implemented in the future for ROOT7 RCanvas.; Probably, such custom JS code can be ""embed"" directly into C++ code making maintenance much easier. Update JSROOT with many improvements for TGeo monitoring",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4094
https://github.com/root-project/root/pull/4094:361,Deployability,Update,Update,361,"This is first attempt to provide support of custom classes in web-based canvas; For now one has to register list of such classes and provide JavaScript code where painters are implemented. . Similar approach can be implemented in the future for ROOT7 RCanvas.; Probably, such custom JS code can be ""embed"" directly into C++ code making maintenance much easier. Update JSROOT with many improvements for TGeo monitoring",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4094
https://github.com/root-project/root/pull/4094:407,Energy Efficiency,monitor,monitoring,407,"This is first attempt to provide support of custom classes in web-based canvas; For now one has to register list of such classes and provide JavaScript code where painters are implemented. . Similar approach can be implemented in the future for ROOT7 RCanvas.; Probably, such custom JS code can be ""embed"" directly into C++ code making maintenance much easier. Update JSROOT with many improvements for TGeo monitoring",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4094
https://github.com/root-project/root/pull/4097:174,Deployability,Update,Update,174,- Move LZMA to use modules from CMake instead of custom find modules; - Define R__HAVE_CONFIG with a `#cmakedefine` to avoid incompatibilities when compiling against ROOT; - Update required version of CMake in `ROOTUseFile.cmake`,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4097
https://github.com/root-project/root/pull/4097:119,Safety,avoid,avoid,119,- Move LZMA to use modules from CMake instead of custom find modules; - Define R__HAVE_CONFIG with a `#cmakedefine` to avoid incompatibilities when compiling against ROOT; - Update required version of CMake in `ROOTUseFile.cmake`,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4097
https://github.com/root-project/root/pull/4099:204,Deployability,install,installing,204,"ROOT CMake modules are really only used during the build. Users only need `ROOTConfig.cmake` and related files like `ROOTConfig-{version,targets*}.cmake`, `ROOTUseFile.cmake`, and `RootMacros.cmake`. Not installing the internal modules gives us more freedom to change them without worrying about breaking backward compatibility for users. Fixes: https://sft.its.cern.ch/jira/browse/ROOT-9828",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4099
https://github.com/root-project/root/pull/4103:232,Testability,test,test,232,"Here is an example of setting custom openui5 client GUI:. auto eveMng = REX::REveManager::Create();; eveMng->AddLocation(""mydir/"", ""/home/alja/root-dev/EveWebApp/ui5"");; eveMng->SetDefaultHtmlPage(""file:mydir/xxx.html"");; ; Here is test repository:; https://github.com/alja/EveWebApp",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4103
https://github.com/root-project/root/pull/4107:297,Availability,error,error,297,"- When a plot in overlapping ranges is requested, the normalisation is not; computed correctly. Now, any overlap between plot ranges is removed; before plotting.; - [RF4756] When integrating a peaked function in a side band, the normalisation integral; might vanish. This will raise an evaluation error. Now, if the function; value also vanishes, this is accepted without error.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4107
https://github.com/root-project/root/pull/4107:372,Availability,error,error,372,"- When a plot in overlapping ranges is requested, the normalisation is not; computed correctly. Now, any overlap between plot ranges is removed; before plotting.; - [RF4756] When integrating a peaked function in a side band, the normalisation integral; might vanish. This will raise an evaluation error. Now, if the function; value also vanishes, this is accepted without error.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4107
https://github.com/root-project/root/pull/4107:179,Deployability,integrat,integrating,179,"- When a plot in overlapping ranges is requested, the normalisation is not; computed correctly. Now, any overlap between plot ranges is removed; before plotting.; - [RF4756] When integrating a peaked function in a side band, the normalisation integral; might vanish. This will raise an evaluation error. Now, if the function; value also vanishes, this is accepted without error.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4107
https://github.com/root-project/root/pull/4107:179,Integrability,integrat,integrating,179,"- When a plot in overlapping ranges is requested, the normalisation is not; computed correctly. Now, any overlap between plot ranges is removed; before plotting.; - [RF4756] When integrating a peaked function in a side band, the normalisation integral; might vanish. This will raise an evaluation error. Now, if the function; value also vanishes, this is accepted without error.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4107
https://github.com/root-project/root/pull/4108:41,Modifiability,inherit,inherit,41,"This will allow the dictionary target to inherit properties such as include directories, etc, from its associated library target.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4108
https://github.com/root-project/root/pull/4109:0,Security,Expose,Expose,0,Expose Cppyy's memory policy symbols in the ROOT facade to collaborate with:; https://github.com/root-project/roottest/pull/357,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4109
https://github.com/root-project/root/pull/4112:632,Deployability,patch,patch,632,"GNU ld has a way to control the symbol versions by 'fixing' the library; appending @@somelib_version. In practice, ROOT's libraries contain a lot of undefined symbols which; are supposed to be resolved either in libc or glibc which are system; libraries. Our symbol dependency chain builder does not look into system; libraries for performance (and legacy reasons). Thus the undefined symbols; from the C/C++ runtime cause us to scan every time all non-system libraries; when we know what would be the outcome. More information can be found in the binutils documentation:; https://sourceware.org/binutils/docs/ld/VERSION.html. This patch optimizes dependency resolution speed for libTreePlayer by 450%",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4112
https://github.com/root-project/root/pull/4112:266,Integrability,depend,dependency,266,"GNU ld has a way to control the symbol versions by 'fixing' the library; appending @@somelib_version. In practice, ROOT's libraries contain a lot of undefined symbols which; are supposed to be resolved either in libc or glibc which are system; libraries. Our symbol dependency chain builder does not look into system; libraries for performance (and legacy reasons). Thus the undefined symbols; from the C/C++ runtime cause us to scan every time all non-system libraries; when we know what would be the outcome. More information can be found in the binutils documentation:; https://sourceware.org/binutils/docs/ld/VERSION.html. This patch optimizes dependency resolution speed for libTreePlayer by 450%",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4112
https://github.com/root-project/root/pull/4112:648,Integrability,depend,dependency,648,"GNU ld has a way to control the symbol versions by 'fixing' the library; appending @@somelib_version. In practice, ROOT's libraries contain a lot of undefined symbols which; are supposed to be resolved either in libc or glibc which are system; libraries. Our symbol dependency chain builder does not look into system; libraries for performance (and legacy reasons). Thus the undefined symbols; from the C/C++ runtime cause us to scan every time all non-system libraries; when we know what would be the outcome. More information can be found in the binutils documentation:; https://sourceware.org/binutils/docs/ld/VERSION.html. This patch optimizes dependency resolution speed for libTreePlayer by 450%",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4112
https://github.com/root-project/root/pull/4112:332,Performance,perform,performance,332,"GNU ld has a way to control the symbol versions by 'fixing' the library; appending @@somelib_version. In practice, ROOT's libraries contain a lot of undefined symbols which; are supposed to be resolved either in libc or glibc which are system; libraries. Our symbol dependency chain builder does not look into system; libraries for performance (and legacy reasons). Thus the undefined symbols; from the C/C++ runtime cause us to scan every time all non-system libraries; when we know what would be the outcome. More information can be found in the binutils documentation:; https://sourceware.org/binutils/docs/ld/VERSION.html. This patch optimizes dependency resolution speed for libTreePlayer by 450%",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4112
https://github.com/root-project/root/pull/4112:638,Performance,optimiz,optimizes,638,"GNU ld has a way to control the symbol versions by 'fixing' the library; appending @@somelib_version. In practice, ROOT's libraries contain a lot of undefined symbols which; are supposed to be resolved either in libc or glibc which are system; libraries. Our symbol dependency chain builder does not look into system; libraries for performance (and legacy reasons). Thus the undefined symbols; from the C/C++ runtime cause us to scan every time all non-system libraries; when we know what would be the outcome. More information can be found in the binutils documentation:; https://sourceware.org/binutils/docs/ld/VERSION.html. This patch optimizes dependency resolution speed for libTreePlayer by 450%",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4112
https://github.com/root-project/root/pull/4117:283,Testability,test,test,283,We incorporate a commit made originally in Cppyy in order to fix a difference of behavior between Linux and MacOs machines. For the full details please refer to:. https://bitbucket.org/wlav/cppyy/issues/132/missing-assignment-of-tp_iternext-in. This commit should make the following test:. tutorial-vecops-vo004_SortAndSelect-py. succeed also on MacOs machines.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4117
https://github.com/root-project/root/pull/4119:124,Testability,log,logic,124,"- [ROOT-10242] RooMCStudy crashes when pulls for a parameter that cannot; have a pull distribution are requested. This adds logic to generate a; proper pull distribution, and returns a blank plot if no pull; distribution can be generated.; - [ROOT-8777] Also fix a rogue cout in RooMCStudy.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4119
https://github.com/root-project/root/pull/4121:243,Integrability,inject,inject,243,"As reported here:. https://sft.its.cern.ch/jira/browse/ROOT-8935. when looking up an enum, the current PyROOT returns an unsigned integer. The changes of this PR, migrated from current Cppyy, allow to create an enum type during the lookup and inject the enum values in it. This is done both for global and non-global lookups. This PR also includes a fix to get the underlying type of the enum when picking a converter for its values.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4121
https://github.com/root-project/root/pull/4121:243,Security,inject,inject,243,"As reported here:. https://sft.its.cern.ch/jira/browse/ROOT-8935. when looking up an enum, the current PyROOT returns an unsigned integer. The changes of this PR, migrated from current Cppyy, allow to create an enum type during the lookup and inject the enum values in it. This is done both for global and non-global lookups. This PR also includes a fix to get the underlying type of the enum when picking a converter for its values.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4121
https://github.com/root-project/root/pull/4123:0,Testability,Test,Test,0,Test mentioned in the title was enabled. This was done by changing the way we call the method Take() of the RDF objects. In new Cppyy the type of a templated method needs to be put in square brackets.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4123
https://github.com/root-project/root/pull/4130:56,Testability,test,testSummary,56,Fixes following failing nightlies: http://cdash.cern.ch/testSummary.php?project=1&name=tutorial-dataframe-df103_NanoAODHiggsAnalysis-py&date=2019-07-30,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4130
https://github.com/root-project/root/pull/4131:39,Availability,down,download,39,By default QWebEngine does not process download actions.; Required when png image created directly from JSROOT code.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4131
https://github.com/root-project/root/pull/4132:6,Testability,test,testing,6,"After testing it, the IS_SYMLINK part is no longer necessary.; It's also better to just move the check as early as possible,; and not try to remove anything, as that doesn't work anyway,; since CMake creates the files and directories only at the end.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4132
https://github.com/root-project/root/pull/4134:307,Integrability,depend,depend,307,"Introduces an RNTupleDescriptor directory class that stores the field structure, the attached columns and their structure, as well as the cluster structure. The descriptor can be used independently of the concrete page storage implementation. Serialization and deserialization of header and footer does not depend on libCore. Along the way, this PR also straightens up naming: field names are now relative to their parent fields, i.e. fields are identified by (name, parent id). Columns have no names anymore. Columns are identified by (field id, column index). At some point we can add the possibility to address nested fields by a fully qualified name, e.g. in views. At the moment that's not yet necessary.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4134
https://github.com/root-project/root/pull/4136:216,Energy Efficiency,reduce,reduces,216,The POSIX does not contains /dev/random [1]. Moreover the /dev/random; might not have write permissions. The better way is to use an another; solution which is based on the msync system call [2]. Also this solution; reduces the number of context switching. [1] -- https://pubs.opengroup.org/onlinepubs/9699919799/basedefs/V1_chap10.html; [2] -- https://pubs.opengroup.org/onlinepubs/009695399/functions/msync.html,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4136
https://github.com/root-project/root/pull/4137:4,Modifiability,variab,variables,4,The variables in the call to TMVA::Reader::AdVariable have to be booked by the; expressions originally used in training not by the title. TMVA::Reader has an; internal check whether these are correct (even though the information is; never used).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4137
https://github.com/root-project/root/pull/4139:14,Testability,test,test,14,The following test:. pyunittests-dataframe-histograms. was fixed by the commit mentioned in the title.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4139
https://github.com/root-project/root/pull/4141:207,Modifiability,Variab,VariableNormalizeTransform,207,"Add scaling VarTransform functionality to TMVA preproccessing (like normalisation it linearly scales the data but the sign of the input and output data is retained). I have added to the functionality of the VariableNormalizeTransform class in the style of the VariableGaussTransform class to transform data such that it remains in the range of [-1,1], there is no offset, so the sign of the input data is unchanged by the transformation. . This is proving essential for my neural network analyses that treat a detector hit data like an image classification problem and use ReLU activation functions at the beginning of my network. I have also added a description to the TMVA documentation",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4141
https://github.com/root-project/root/pull/4141:260,Modifiability,Variab,VariableGaussTransform,260,"Add scaling VarTransform functionality to TMVA preproccessing (like normalisation it linearly scales the data but the sign of the input and output data is retained). I have added to the functionality of the VariableNormalizeTransform class in the style of the VariableGaussTransform class to transform data such that it remains in the range of [-1,1], there is no offset, so the sign of the input data is unchanged by the transformation. . This is proving essential for my neural network analyses that treat a detector hit data like an image classification problem and use ReLU activation functions at the beginning of my network. I have also added a description to the TMVA documentation",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4141
https://github.com/root-project/root/pull/4141:510,Safety,detect,detector,510,"Add scaling VarTransform functionality to TMVA preproccessing (like normalisation it linearly scales the data but the sign of the input and output data is retained). I have added to the functionality of the VariableNormalizeTransform class in the style of the VariableGaussTransform class to transform data such that it remains in the range of [-1,1], there is no offset, so the sign of the input data is unchanged by the transformation. . This is proving essential for my neural network analyses that treat a detector hit data like an image classification problem and use ReLU activation functions at the beginning of my network. I have also added a description to the TMVA documentation",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4141
https://github.com/root-project/root/pull/4143:35,Safety,Avoid,Avoids,35,Can be activated for RWebWindow. ; Avoids blocking of application code due-to single slow client.; Use `cond.notify_all()` only when really condition in the wait state,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4143
https://github.com/root-project/root/pull/4146:70,Testability,log,logic,70,"Binary data has to be transferred as separate data packet; This makes logic complicated especially when many small raw packets should be used; Using `JSON_base64` marker in class info, one can insert raw data in ROOT JSON and ; use such binary at the place. This significantly simplifies data handling. ; Same approach can be later used for eve7",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4146
https://github.com/root-project/root/pull/4146:277,Usability,simpl,simplifies,277,"Binary data has to be transferred as separate data packet; This makes logic complicated especially when many small raw packets should be used; Using `JSON_base64` marker in class info, one can insert raw data in ROOT JSON and ; use such binary at the place. This significantly simplifies data handling. ; Same approach can be later used for eve7",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4146
https://github.com/root-project/root/pull/4148:218,Availability,failure,failure,218,"Due to a pythonization not yet carried from old to experimental PyROOT, multiple calls of the same object from a TFile done e.g in the usual way `file.object` used to retrieve copies of the same object, leading to the failure of a test.; The pythonization of the TDirectoryFile:Get() method was thus added; in this way, also the TFile class inherits it.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4148
https://github.com/root-project/root/pull/4148:341,Modifiability,inherit,inherits,341,"Due to a pythonization not yet carried from old to experimental PyROOT, multiple calls of the same object from a TFile done e.g in the usual way `file.object` used to retrieve copies of the same object, leading to the failure of a test.; The pythonization of the TDirectoryFile:Get() method was thus added; in this way, also the TFile class inherits it.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4148
https://github.com/root-project/root/pull/4148:231,Testability,test,test,231,"Due to a pythonization not yet carried from old to experimental PyROOT, multiple calls of the same object from a TFile done e.g in the usual way `file.object` used to retrieve copies of the same object, leading to the failure of a test.; The pythonization of the TDirectoryFile:Get() method was thus added; in this way, also the TFile class inherits it.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4148
https://github.com/root-project/root/pull/4156:270,Performance,cache,caches,270,"Due to a failing test and the resulting investigation, we decide to change the pythonization of Get() and __getattr__ in the classes TDirectory, TDirectoryFile and TFile.; The situation is now the following:; . - __getattr__ : TDirectory --> TDirectoryFile --> TFile; - caches the returned object for future attempts; - raises AttributeError if object not found; ; - Get() : TDirectoryFile --> TFile; - does not cache the returned object; - returns nullptr if object not found. A new test to check the caching functionality has been added.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4156
https://github.com/root-project/root/pull/4156:412,Performance,cache,cache,412,"Due to a failing test and the resulting investigation, we decide to change the pythonization of Get() and __getattr__ in the classes TDirectory, TDirectoryFile and TFile.; The situation is now the following:; . - __getattr__ : TDirectory --> TDirectoryFile --> TFile; - caches the returned object for future attempts; - raises AttributeError if object not found; ; - Get() : TDirectoryFile --> TFile; - does not cache the returned object; - returns nullptr if object not found. A new test to check the caching functionality has been added.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4156
https://github.com/root-project/root/pull/4156:17,Testability,test,test,17,"Due to a failing test and the resulting investigation, we decide to change the pythonization of Get() and __getattr__ in the classes TDirectory, TDirectoryFile and TFile.; The situation is now the following:; . - __getattr__ : TDirectory --> TDirectoryFile --> TFile; - caches the returned object for future attempts; - raises AttributeError if object not found; ; - Get() : TDirectoryFile --> TFile; - does not cache the returned object; - returns nullptr if object not found. A new test to check the caching functionality has been added.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4156
https://github.com/root-project/root/pull/4156:484,Testability,test,test,484,"Due to a failing test and the resulting investigation, we decide to change the pythonization of Get() and __getattr__ in the classes TDirectory, TDirectoryFile and TFile.; The situation is now the following:; . - __getattr__ : TDirectory --> TDirectoryFile --> TFile; - caches the returned object for future attempts; - raises AttributeError if object not found; ; - Get() : TDirectoryFile --> TFile; - does not cache the returned object; - returns nullptr if object not found. A new test to check the caching functionality has been added.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4156
https://github.com/root-project/root/pull/4159:224,Availability,Failure,Failure,224,"Assuming that `page_size` is a power of 2, the calculation of the base address of the page can be simplified and avoid a division. According to POSIX, either `MS_SYNC` or `MS_ASYNC` must be specified when calling `msync()`. Failure to include one of these flags will cause `msync()` to fail on some systems. When `msync()` returns -1, the pointer is only considered invalid when errno is set to `ENOMEM`. In principle, the other possible values for errno won't happen, but if they do, that should be considered an error, hence the assert condition needed an update. `EBUSY` shouldn't happen since we do not add `MS_INVALIDATE` to flags, and `EINVAL` shouldn't happen because we always pass a multiple of the page size to msync(). `EFAULT` is only used in Linux 2.4.18 and earlier instead of `ENOMEM`. See #4136 for more information.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4159
https://github.com/root-project/root/pull/4159:514,Availability,error,error,514,"Assuming that `page_size` is a power of 2, the calculation of the base address of the page can be simplified and avoid a division. According to POSIX, either `MS_SYNC` or `MS_ASYNC` must be specified when calling `msync()`. Failure to include one of these flags will cause `msync()` to fail on some systems. When `msync()` returns -1, the pointer is only considered invalid when errno is set to `ENOMEM`. In principle, the other possible values for errno won't happen, but if they do, that should be considered an error, hence the assert condition needed an update. `EBUSY` shouldn't happen since we do not add `MS_INVALIDATE` to flags, and `EINVAL` shouldn't happen because we always pass a multiple of the page size to msync(). `EFAULT` is only used in Linux 2.4.18 and earlier instead of `ENOMEM`. See #4136 for more information.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4159
https://github.com/root-project/root/pull/4159:558,Deployability,update,update,558,"Assuming that `page_size` is a power of 2, the calculation of the base address of the page can be simplified and avoid a division. According to POSIX, either `MS_SYNC` or `MS_ASYNC` must be specified when calling `msync()`. Failure to include one of these flags will cause `msync()` to fail on some systems. When `msync()` returns -1, the pointer is only considered invalid when errno is set to `ENOMEM`. In principle, the other possible values for errno won't happen, but if they do, that should be considered an error, hence the assert condition needed an update. `EBUSY` shouldn't happen since we do not add `MS_INVALIDATE` to flags, and `EINVAL` shouldn't happen because we always pass a multiple of the page size to msync(). `EFAULT` is only used in Linux 2.4.18 and earlier instead of `ENOMEM`. See #4136 for more information.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4159
https://github.com/root-project/root/pull/4159:31,Energy Efficiency,power,power,31,"Assuming that `page_size` is a power of 2, the calculation of the base address of the page can be simplified and avoid a division. According to POSIX, either `MS_SYNC` or `MS_ASYNC` must be specified when calling `msync()`. Failure to include one of these flags will cause `msync()` to fail on some systems. When `msync()` returns -1, the pointer is only considered invalid when errno is set to `ENOMEM`. In principle, the other possible values for errno won't happen, but if they do, that should be considered an error, hence the assert condition needed an update. `EBUSY` shouldn't happen since we do not add `MS_INVALIDATE` to flags, and `EINVAL` shouldn't happen because we always pass a multiple of the page size to msync(). `EFAULT` is only used in Linux 2.4.18 and earlier instead of `ENOMEM`. See #4136 for more information.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4159
https://github.com/root-project/root/pull/4159:113,Safety,avoid,avoid,113,"Assuming that `page_size` is a power of 2, the calculation of the base address of the page can be simplified and avoid a division. According to POSIX, either `MS_SYNC` or `MS_ASYNC` must be specified when calling `msync()`. Failure to include one of these flags will cause `msync()` to fail on some systems. When `msync()` returns -1, the pointer is only considered invalid when errno is set to `ENOMEM`. In principle, the other possible values for errno won't happen, but if they do, that should be considered an error, hence the assert condition needed an update. `EBUSY` shouldn't happen since we do not add `MS_INVALIDATE` to flags, and `EINVAL` shouldn't happen because we always pass a multiple of the page size to msync(). `EFAULT` is only used in Linux 2.4.18 and earlier instead of `ENOMEM`. See #4136 for more information.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4159
https://github.com/root-project/root/pull/4159:531,Testability,assert,assert,531,"Assuming that `page_size` is a power of 2, the calculation of the base address of the page can be simplified and avoid a division. According to POSIX, either `MS_SYNC` or `MS_ASYNC` must be specified when calling `msync()`. Failure to include one of these flags will cause `msync()` to fail on some systems. When `msync()` returns -1, the pointer is only considered invalid when errno is set to `ENOMEM`. In principle, the other possible values for errno won't happen, but if they do, that should be considered an error, hence the assert condition needed an update. `EBUSY` shouldn't happen since we do not add `MS_INVALIDATE` to flags, and `EINVAL` shouldn't happen because we always pass a multiple of the page size to msync(). `EFAULT` is only used in Linux 2.4.18 and earlier instead of `ENOMEM`. See #4136 for more information.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4159
https://github.com/root-project/root/pull/4159:98,Usability,simpl,simplified,98,"Assuming that `page_size` is a power of 2, the calculation of the base address of the page can be simplified and avoid a division. According to POSIX, either `MS_SYNC` or `MS_ASYNC` must be specified when calling `msync()`. Failure to include one of these flags will cause `msync()` to fail on some systems. When `msync()` returns -1, the pointer is only considered invalid when errno is set to `ENOMEM`. In principle, the other possible values for errno won't happen, but if they do, that should be considered an error, hence the assert condition needed an update. `EBUSY` shouldn't happen since we do not add `MS_INVALIDATE` to flags, and `EINVAL` shouldn't happen because we always pass a multiple of the page size to msync(). `EFAULT` is only used in Linux 2.4.18 and earlier instead of `ENOMEM`. See #4136 for more information.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4159
https://github.com/root-project/root/pull/4160:18,Integrability,interface,interface,18,- TGDMLWrite: Fix interface to write partial trees. Partial trees must be identified by a TGeoNode and not by a TGeoVolume. Otherwise surfaces cannot be attached to the top level nodes of a partial tree.; - TGDMLWrite: add values of material/surface property tables to output; - TGDMLWrite: add output of CONST properties; - TGDMLParse: protect against trailing '\n' and other white spaces when reading property table values,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4160
https://github.com/root-project/root/pull/4163:207,Deployability,install,installations,207,"The change of the interface of TGDMLWrite is in conflict with old DD4hep versions. To temporarily overcome this problem the old interface is kept. ; The old interface however should be removed when standard installations use a compatible pairs of DD4hep and ROOT >= 6.20. DD4hep when using ROOT 6.20.0 or greater will only use the new interface, where a partial tree is exported to GDML identified by it's TGeoNode instance.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4163
https://github.com/root-project/root/pull/4163:18,Integrability,interface,interface,18,"The change of the interface of TGDMLWrite is in conflict with old DD4hep versions. To temporarily overcome this problem the old interface is kept. ; The old interface however should be removed when standard installations use a compatible pairs of DD4hep and ROOT >= 6.20. DD4hep when using ROOT 6.20.0 or greater will only use the new interface, where a partial tree is exported to GDML identified by it's TGeoNode instance.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4163
https://github.com/root-project/root/pull/4163:128,Integrability,interface,interface,128,"The change of the interface of TGDMLWrite is in conflict with old DD4hep versions. To temporarily overcome this problem the old interface is kept. ; The old interface however should be removed when standard installations use a compatible pairs of DD4hep and ROOT >= 6.20. DD4hep when using ROOT 6.20.0 or greater will only use the new interface, where a partial tree is exported to GDML identified by it's TGeoNode instance.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4163
https://github.com/root-project/root/pull/4163:157,Integrability,interface,interface,157,"The change of the interface of TGDMLWrite is in conflict with old DD4hep versions. To temporarily overcome this problem the old interface is kept. ; The old interface however should be removed when standard installations use a compatible pairs of DD4hep and ROOT >= 6.20. DD4hep when using ROOT 6.20.0 or greater will only use the new interface, where a partial tree is exported to GDML identified by it's TGeoNode instance.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4163
https://github.com/root-project/root/pull/4163:335,Integrability,interface,interface,335,"The change of the interface of TGDMLWrite is in conflict with old DD4hep versions. To temporarily overcome this problem the old interface is kept. ; The old interface however should be removed when standard installations use a compatible pairs of DD4hep and ROOT >= 6.20. DD4hep when using ROOT 6.20.0 or greater will only use the new interface, where a partial tree is exported to GDML identified by it's TGeoNode instance.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4163
https://github.com/root-project/root/pull/4166:615,Deployability,Update,Update,615,"Use RWebWindow for main widget with buttons, help widget with infos and web-based geometry viewer for geometry display. This requires number of changes in base RWebWindow class:. 1. Let configure position and size of RWebWindow, including support in chrome, CEF and Qt5; 2. Make more methods in RWebWindow `const`, declaring used mutexes `mutable`; 3. Let submit data to web window, which is started but not yet connected to server. Redesign visiible nodes selection algorithm in geometry viewer. Now logic is similar to normal TGeoPainter of ROOT. Plus extra control over maximal allowed number of faces/vertices. Update JSROOT with latest changes",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4166
https://github.com/root-project/root/pull/4166:186,Modifiability,config,configure,186,"Use RWebWindow for main widget with buttons, help widget with infos and web-based geometry viewer for geometry display. This requires number of changes in base RWebWindow class:. 1. Let configure position and size of RWebWindow, including support in chrome, CEF and Qt5; 2. Make more methods in RWebWindow `const`, declaring used mutexes `mutable`; 3. Let submit data to web window, which is started but not yet connected to server. Redesign visiible nodes selection algorithm in geometry viewer. Now logic is similar to normal TGeoPainter of ROOT. Plus extra control over maximal allowed number of faces/vertices. Update JSROOT with latest changes",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4166
https://github.com/root-project/root/pull/4166:501,Testability,log,logic,501,"Use RWebWindow for main widget with buttons, help widget with infos and web-based geometry viewer for geometry display. This requires number of changes in base RWebWindow class:. 1. Let configure position and size of RWebWindow, including support in chrome, CEF and Qt5; 2. Make more methods in RWebWindow `const`, declaring used mutexes `mutable`; 3. Let submit data to web window, which is started but not yet connected to server. Redesign visiible nodes selection algorithm in geometry viewer. Now logic is similar to normal TGeoPainter of ROOT. Plus extra control over maximal allowed number of faces/vertices. Update JSROOT with latest changes",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4166
https://github.com/root-project/root/pull/4167:188,Availability,error,errors,188,"Clarifies the behavior of `wgtError` in `RooDataSet::add`, which is rather unintuitive. (See [this post in the forum](https://root-forum.cern.ch/t/unexpected-behavior-in-roodataset-weight-errors/35576).)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4167
https://github.com/root-project/root/pull/4170:196,Availability,error,error-prone,196,"Copy constructor and assign operators for TGeoVolume, TGeoNode, TGeoVoxelFinder have ownership problem. Anyway it is not recommended to use these methods with TGeo classes,; therefore just remove error-prone implementations completely and forbid them. Can have side effect, if there are any user code with classes derived from TGeoVolume or TGeoNode",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4170
https://github.com/root-project/root/pull/4171:758,Availability,avail,available,758,"The argument parsing in rootcling has become quite hard (if not impossible) to maintain. This PR replaces the handmade argument parsing with the [LLVM's CommandLine](https://github.com/root-project/root/blob/master/interpreter/llvm/src/docs/CommandLine.rst) framework.; Use the llvm command line option parser and phase out the hand crafted one. It uses declarative-style option specification, improves type-safety and most importantly moves out from rootcling the cumbersome argument parsing logic. One of the major advantages is that help messages are automatically generated:; ```; OVERVIEW: rootcling; USAGE: rootcling [options] <output dictionary file> <list of dictionary header files> <LinkDef file>; ; OPTIONS:; ; Generic Options:; ; -help - Display available options (-help-hidden for more); -help-list - Display list of available options (-help-list-hidden for more); -version - Display the version of this program; ; rootcling common options:; ; -D=<string> - Specify defined macros.; -I=<string> - Specify an include path.; -W=<string> - Specify compiler diagnostics options.; -c - Deprecated, legacy flag which is ignored.; -cxxmodule - Generate a C++ module.; -excludePath=<string> - Do not store the <path> in the dictionary.; -f - Overwrite <file>s.; -failOnWarnings - Fail if there are warnings.; -inlineInputHeader - Does not generate #include <header> but expands the header content.; -interpreteronly - Generate minimal dictionary for interactivity (without IO information).; -m=<string> - The list of dependent modules of the dictionary.; -multiDict - If this library has multiple separate LinkDef files.; -noIncludePaths - Do not store include paths but rely on the env variable ROOT_INCLUDE_PATH.; -p - Deprecated, legacy flag which is ignored.; -rmf=<string> - Generate a rootmap file with the specified name.; -rml=<string> - Generate rootmap file.; -s=<string> - The path to the library of the built dictionary.; -selSyntaxOnly - Check the selection syntax only.; -split - Sp",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4171
https://github.com/root-project/root/pull/4171:830,Availability,avail,available,830,"The argument parsing in rootcling has become quite hard (if not impossible) to maintain. This PR replaces the handmade argument parsing with the [LLVM's CommandLine](https://github.com/root-project/root/blob/master/interpreter/llvm/src/docs/CommandLine.rst) framework.; Use the llvm command line option parser and phase out the hand crafted one. It uses declarative-style option specification, improves type-safety and most importantly moves out from rootcling the cumbersome argument parsing logic. One of the major advantages is that help messages are automatically generated:; ```; OVERVIEW: rootcling; USAGE: rootcling [options] <output dictionary file> <list of dictionary header files> <LinkDef file>; ; OPTIONS:; ; Generic Options:; ; -help - Display available options (-help-hidden for more); -help-list - Display list of available options (-help-list-hidden for more); -version - Display the version of this program; ; rootcling common options:; ; -D=<string> - Specify defined macros.; -I=<string> - Specify an include path.; -W=<string> - Specify compiler diagnostics options.; -c - Deprecated, legacy flag which is ignored.; -cxxmodule - Generate a C++ module.; -excludePath=<string> - Do not store the <path> in the dictionary.; -f - Overwrite <file>s.; -failOnWarnings - Fail if there are warnings.; -inlineInputHeader - Does not generate #include <header> but expands the header content.; -interpreteronly - Generate minimal dictionary for interactivity (without IO information).; -m=<string> - The list of dependent modules of the dictionary.; -multiDict - If this library has multiple separate LinkDef files.; -noIncludePaths - Do not store include paths but rely on the env variable ROOT_INCLUDE_PATH.; -p - Deprecated, legacy flag which is ignored.; -rmf=<string> - Generate a rootmap file with the specified name.; -rml=<string> - Generate rootmap file.; -s=<string> - The path to the library of the built dictionary.; -selSyntaxOnly - Check the selection syntax only.; -split - Sp",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4171
https://github.com/root-project/root/pull/4171:2155,Availability,error,errors,2155,"le - Generate a C++ module.; -excludePath=<string> - Do not store the <path> in the dictionary.; -f - Overwrite <file>s.; -failOnWarnings - Fail if there are warnings.; -inlineInputHeader - Does not generate #include <header> but expands the header content.; -interpreteronly - Generate minimal dictionary for interactivity (without IO information).; -m=<string> - The list of dependent modules of the dictionary.; -multiDict - If this library has multiple separate LinkDef files.; -noIncludePaths - Do not store include paths but rely on the env variable ROOT_INCLUDE_PATH.; -p - Deprecated, legacy flag which is ignored.; -rmf=<string> - Generate a rootmap file with the specified name.; -rml=<string> - Generate rootmap file.; -s=<string> - The path to the library of the built dictionary.; -selSyntaxOnly - Check the selection syntax only.; -split - Split the dictionary into two parts: one containing the IO (ClassDef)information and another the interactivity support.; Choose verbosity level:; -v - Show errors (default).; -v0 - Show only fatal errors.; -v1 - Show errors (the same as -v).; -v2 - Show warnings.; -v3 - Show notes.; -v4 - Show information.; ```; ; This patch deprecates:; 1) +P, +V, +STUB, -gccxml, -cint, -reflex -- they are old CINT legacy options which had no meaning in rootcling.; 2) -p, -c -- remove old options used by rootcling -generate-pch as now the build system does not export its lists of flags directly to roocling.; ; The implementation of 2) was quite permissive as it tried to send all possible unknown options directly to rootcling. As a side effect of reworking of 2) we can restrict the options being sent and unknown options are not sent to rootcling anymore, improving encapsulation.; ; If there is a need to do so please contact us or use the EXTRA_CLING_ARGS env option. PS: The end goal is fixing the incremental builds when -Druntime_cxxmodules=On. We will have something like `rootcling --bare-cling=""-fmodules -fno-implicit-module-maps -fmodule-map-",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4171
https://github.com/root-project/root/pull/4171:2196,Availability,error,errors,2196,"; -excludePath=<string> - Do not store the <path> in the dictionary.; -f - Overwrite <file>s.; -failOnWarnings - Fail if there are warnings.; -inlineInputHeader - Does not generate #include <header> but expands the header content.; -interpreteronly - Generate minimal dictionary for interactivity (without IO information).; -m=<string> - The list of dependent modules of the dictionary.; -multiDict - If this library has multiple separate LinkDef files.; -noIncludePaths - Do not store include paths but rely on the env variable ROOT_INCLUDE_PATH.; -p - Deprecated, legacy flag which is ignored.; -rmf=<string> - Generate a rootmap file with the specified name.; -rml=<string> - Generate rootmap file.; -s=<string> - The path to the library of the built dictionary.; -selSyntaxOnly - Check the selection syntax only.; -split - Split the dictionary into two parts: one containing the IO (ClassDef)information and another the interactivity support.; Choose verbosity level:; -v - Show errors (default).; -v0 - Show only fatal errors.; -v1 - Show errors (the same as -v).; -v2 - Show warnings.; -v3 - Show notes.; -v4 - Show information.; ```; ; This patch deprecates:; 1) +P, +V, +STUB, -gccxml, -cint, -reflex -- they are old CINT legacy options which had no meaning in rootcling.; 2) -p, -c -- remove old options used by rootcling -generate-pch as now the build system does not export its lists of flags directly to roocling.; ; The implementation of 2) was quite permissive as it tried to send all possible unknown options directly to rootcling. As a side effect of reworking of 2) we can restrict the options being sent and unknown options are not sent to rootcling anymore, improving encapsulation.; ; If there is a need to do so please contact us or use the EXTRA_CLING_ARGS env option. PS: The end goal is fixing the incremental builds when -Druntime_cxxmodules=On. We will have something like `rootcling --bare-cling=""-fmodules -fno-implicit-module-maps -fmodule-map-file=... -emit-module=std`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4171
https://github.com/root-project/root/pull/4171:2216,Availability,error,errors,2216,"; -excludePath=<string> - Do not store the <path> in the dictionary.; -f - Overwrite <file>s.; -failOnWarnings - Fail if there are warnings.; -inlineInputHeader - Does not generate #include <header> but expands the header content.; -interpreteronly - Generate minimal dictionary for interactivity (without IO information).; -m=<string> - The list of dependent modules of the dictionary.; -multiDict - If this library has multiple separate LinkDef files.; -noIncludePaths - Do not store include paths but rely on the env variable ROOT_INCLUDE_PATH.; -p - Deprecated, legacy flag which is ignored.; -rmf=<string> - Generate a rootmap file with the specified name.; -rml=<string> - Generate rootmap file.; -s=<string> - The path to the library of the built dictionary.; -selSyntaxOnly - Check the selection syntax only.; -split - Split the dictionary into two parts: one containing the IO (ClassDef)information and another the interactivity support.; Choose verbosity level:; -v - Show errors (default).; -v0 - Show only fatal errors.; -v1 - Show errors (the same as -v).; -v2 - Show warnings.; -v3 - Show notes.; -v4 - Show information.; ```; ; This patch deprecates:; 1) +P, +V, +STUB, -gccxml, -cint, -reflex -- they are old CINT legacy options which had no meaning in rootcling.; 2) -p, -c -- remove old options used by rootcling -generate-pch as now the build system does not export its lists of flags directly to roocling.; ; The implementation of 2) was quite permissive as it tried to send all possible unknown options directly to rootcling. As a side effect of reworking of 2) we can restrict the options being sent and unknown options are not sent to rootcling anymore, improving encapsulation.; ; If there is a need to do so please contact us or use the EXTRA_CLING_ARGS env option. PS: The end goal is fixing the incremental builds when -Druntime_cxxmodules=On. We will have something like `rootcling --bare-cling=""-fmodules -fno-implicit-module-maps -fmodule-map-file=... -emit-module=std`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4171
https://github.com/root-project/root/pull/4171:2320,Deployability,patch,patch,2320,"; -excludePath=<string> - Do not store the <path> in the dictionary.; -f - Overwrite <file>s.; -failOnWarnings - Fail if there are warnings.; -inlineInputHeader - Does not generate #include <header> but expands the header content.; -interpreteronly - Generate minimal dictionary for interactivity (without IO information).; -m=<string> - The list of dependent modules of the dictionary.; -multiDict - If this library has multiple separate LinkDef files.; -noIncludePaths - Do not store include paths but rely on the env variable ROOT_INCLUDE_PATH.; -p - Deprecated, legacy flag which is ignored.; -rmf=<string> - Generate a rootmap file with the specified name.; -rml=<string> - Generate rootmap file.; -s=<string> - The path to the library of the built dictionary.; -selSyntaxOnly - Check the selection syntax only.; -split - Split the dictionary into two parts: one containing the IO (ClassDef)information and another the interactivity support.; Choose verbosity level:; -v - Show errors (default).; -v0 - Show only fatal errors.; -v1 - Show errors (the same as -v).; -v2 - Show warnings.; -v3 - Show notes.; -v4 - Show information.; ```; ; This patch deprecates:; 1) +P, +V, +STUB, -gccxml, -cint, -reflex -- they are old CINT legacy options which had no meaning in rootcling.; 2) -p, -c -- remove old options used by rootcling -generate-pch as now the build system does not export its lists of flags directly to roocling.; ; The implementation of 2) was quite permissive as it tried to send all possible unknown options directly to rootcling. As a side effect of reworking of 2) we can restrict the options being sent and unknown options are not sent to rootcling anymore, improving encapsulation.; ; If there is a need to do so please contact us or use the EXTRA_CLING_ARGS env option. PS: The end goal is fixing the incremental builds when -Druntime_cxxmodules=On. We will have something like `rootcling --bare-cling=""-fmodules -fno-implicit-module-maps -fmodule-map-file=... -emit-module=std`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4171
https://github.com/root-project/root/pull/4171:541,Integrability,message,messages,541,"The argument parsing in rootcling has become quite hard (if not impossible) to maintain. This PR replaces the handmade argument parsing with the [LLVM's CommandLine](https://github.com/root-project/root/blob/master/interpreter/llvm/src/docs/CommandLine.rst) framework.; Use the llvm command line option parser and phase out the hand crafted one. It uses declarative-style option specification, improves type-safety and most importantly moves out from rootcling the cumbersome argument parsing logic. One of the major advantages is that help messages are automatically generated:; ```; OVERVIEW: rootcling; USAGE: rootcling [options] <output dictionary file> <list of dictionary header files> <LinkDef file>; ; OPTIONS:; ; Generic Options:; ; -help - Display available options (-help-hidden for more); -help-list - Display list of available options (-help-list-hidden for more); -version - Display the version of this program; ; rootcling common options:; ; -D=<string> - Specify defined macros.; -I=<string> - Specify an include path.; -W=<string> - Specify compiler diagnostics options.; -c - Deprecated, legacy flag which is ignored.; -cxxmodule - Generate a C++ module.; -excludePath=<string> - Do not store the <path> in the dictionary.; -f - Overwrite <file>s.; -failOnWarnings - Fail if there are warnings.; -inlineInputHeader - Does not generate #include <header> but expands the header content.; -interpreteronly - Generate minimal dictionary for interactivity (without IO information).; -m=<string> - The list of dependent modules of the dictionary.; -multiDict - If this library has multiple separate LinkDef files.; -noIncludePaths - Do not store include paths but rely on the env variable ROOT_INCLUDE_PATH.; -p - Deprecated, legacy flag which is ignored.; -rmf=<string> - Generate a rootmap file with the specified name.; -rml=<string> - Generate rootmap file.; -s=<string> - The path to the library of the built dictionary.; -selSyntaxOnly - Check the selection syntax only.; -split - Sp",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4171
https://github.com/root-project/root/pull/4171:1522,Integrability,depend,dependent,1522,"s is that help messages are automatically generated:; ```; OVERVIEW: rootcling; USAGE: rootcling [options] <output dictionary file> <list of dictionary header files> <LinkDef file>; ; OPTIONS:; ; Generic Options:; ; -help - Display available options (-help-hidden for more); -help-list - Display list of available options (-help-list-hidden for more); -version - Display the version of this program; ; rootcling common options:; ; -D=<string> - Specify defined macros.; -I=<string> - Specify an include path.; -W=<string> - Specify compiler diagnostics options.; -c - Deprecated, legacy flag which is ignored.; -cxxmodule - Generate a C++ module.; -excludePath=<string> - Do not store the <path> in the dictionary.; -f - Overwrite <file>s.; -failOnWarnings - Fail if there are warnings.; -inlineInputHeader - Does not generate #include <header> but expands the header content.; -interpreteronly - Generate minimal dictionary for interactivity (without IO information).; -m=<string> - The list of dependent modules of the dictionary.; -multiDict - If this library has multiple separate LinkDef files.; -noIncludePaths - Do not store include paths but rely on the env variable ROOT_INCLUDE_PATH.; -p - Deprecated, legacy flag which is ignored.; -rmf=<string> - Generate a rootmap file with the specified name.; -rml=<string> - Generate rootmap file.; -s=<string> - The path to the library of the built dictionary.; -selSyntaxOnly - Check the selection syntax only.; -split - Split the dictionary into two parts: one containing the IO (ClassDef)information and another the interactivity support.; Choose verbosity level:; -v - Show errors (default).; -v0 - Show only fatal errors.; -v1 - Show errors (the same as -v).; -v2 - Show warnings.; -v3 - Show notes.; -v4 - Show information.; ```; ; This patch deprecates:; 1) +P, +V, +STUB, -gccxml, -cint, -reflex -- they are old CINT legacy options which had no meaning in rootcling.; 2) -p, -c -- remove old options used by rootcling -generate-pch as now th",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4171
https://github.com/root-project/root/pull/4171:1692,Modifiability,variab,variable,1692,"onary header files> <LinkDef file>; ; OPTIONS:; ; Generic Options:; ; -help - Display available options (-help-hidden for more); -help-list - Display list of available options (-help-list-hidden for more); -version - Display the version of this program; ; rootcling common options:; ; -D=<string> - Specify defined macros.; -I=<string> - Specify an include path.; -W=<string> - Specify compiler diagnostics options.; -c - Deprecated, legacy flag which is ignored.; -cxxmodule - Generate a C++ module.; -excludePath=<string> - Do not store the <path> in the dictionary.; -f - Overwrite <file>s.; -failOnWarnings - Fail if there are warnings.; -inlineInputHeader - Does not generate #include <header> but expands the header content.; -interpreteronly - Generate minimal dictionary for interactivity (without IO information).; -m=<string> - The list of dependent modules of the dictionary.; -multiDict - If this library has multiple separate LinkDef files.; -noIncludePaths - Do not store include paths but rely on the env variable ROOT_INCLUDE_PATH.; -p - Deprecated, legacy flag which is ignored.; -rmf=<string> - Generate a rootmap file with the specified name.; -rml=<string> - Generate rootmap file.; -s=<string> - The path to the library of the built dictionary.; -selSyntaxOnly - Check the selection syntax only.; -split - Split the dictionary into two parts: one containing the IO (ClassDef)information and another the interactivity support.; Choose verbosity level:; -v - Show errors (default).; -v0 - Show only fatal errors.; -v1 - Show errors (the same as -v).; -v2 - Show warnings.; -v3 - Show notes.; -v4 - Show information.; ```; ; This patch deprecates:; 1) +P, +V, +STUB, -gccxml, -cint, -reflex -- they are old CINT legacy options which had no meaning in rootcling.; 2) -p, -c -- remove old options used by rootcling -generate-pch as now the build system does not export its lists of flags directly to roocling.; ; The implementation of 2) was quite permissive as it tried to send all p",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4171
https://github.com/root-project/root/pull/4171:408,Safety,safe,safety,408,"The argument parsing in rootcling has become quite hard (if not impossible) to maintain. This PR replaces the handmade argument parsing with the [LLVM's CommandLine](https://github.com/root-project/root/blob/master/interpreter/llvm/src/docs/CommandLine.rst) framework.; Use the llvm command line option parser and phase out the hand crafted one. It uses declarative-style option specification, improves type-safety and most importantly moves out from rootcling the cumbersome argument parsing logic. One of the major advantages is that help messages are automatically generated:; ```; OVERVIEW: rootcling; USAGE: rootcling [options] <output dictionary file> <list of dictionary header files> <LinkDef file>; ; OPTIONS:; ; Generic Options:; ; -help - Display available options (-help-hidden for more); -help-list - Display list of available options (-help-list-hidden for more); -version - Display the version of this program; ; rootcling common options:; ; -D=<string> - Specify defined macros.; -I=<string> - Specify an include path.; -W=<string> - Specify compiler diagnostics options.; -c - Deprecated, legacy flag which is ignored.; -cxxmodule - Generate a C++ module.; -excludePath=<string> - Do not store the <path> in the dictionary.; -f - Overwrite <file>s.; -failOnWarnings - Fail if there are warnings.; -inlineInputHeader - Does not generate #include <header> but expands the header content.; -interpreteronly - Generate minimal dictionary for interactivity (without IO information).; -m=<string> - The list of dependent modules of the dictionary.; -multiDict - If this library has multiple separate LinkDef files.; -noIncludePaths - Do not store include paths but rely on the env variable ROOT_INCLUDE_PATH.; -p - Deprecated, legacy flag which is ignored.; -rmf=<string> - Generate a rootmap file with the specified name.; -rml=<string> - Generate rootmap file.; -s=<string> - The path to the library of the built dictionary.; -selSyntaxOnly - Check the selection syntax only.; -split - Sp",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4171
https://github.com/root-project/root/pull/4171:493,Testability,log,logic,493,"The argument parsing in rootcling has become quite hard (if not impossible) to maintain. This PR replaces the handmade argument parsing with the [LLVM's CommandLine](https://github.com/root-project/root/blob/master/interpreter/llvm/src/docs/CommandLine.rst) framework.; Use the llvm command line option parser and phase out the hand crafted one. It uses declarative-style option specification, improves type-safety and most importantly moves out from rootcling the cumbersome argument parsing logic. One of the major advantages is that help messages are automatically generated:; ```; OVERVIEW: rootcling; USAGE: rootcling [options] <output dictionary file> <list of dictionary header files> <LinkDef file>; ; OPTIONS:; ; Generic Options:; ; -help - Display available options (-help-hidden for more); -help-list - Display list of available options (-help-list-hidden for more); -version - Display the version of this program; ; rootcling common options:; ; -D=<string> - Specify defined macros.; -I=<string> - Specify an include path.; -W=<string> - Specify compiler diagnostics options.; -c - Deprecated, legacy flag which is ignored.; -cxxmodule - Generate a C++ module.; -excludePath=<string> - Do not store the <path> in the dictionary.; -f - Overwrite <file>s.; -failOnWarnings - Fail if there are warnings.; -inlineInputHeader - Does not generate #include <header> but expands the header content.; -interpreteronly - Generate minimal dictionary for interactivity (without IO information).; -m=<string> - The list of dependent modules of the dictionary.; -multiDict - If this library has multiple separate LinkDef files.; -noIncludePaths - Do not store include paths but rely on the env variable ROOT_INCLUDE_PATH.; -p - Deprecated, legacy flag which is ignored.; -rmf=<string> - Generate a rootmap file with the specified name.; -rml=<string> - Generate rootmap file.; -s=<string> - The path to the library of the built dictionary.; -selSyntaxOnly - Check the selection syntax only.; -split - Sp",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4171
https://github.com/root-project/root/pull/4171:2351,Testability,STUB,STUB,2351,"; -excludePath=<string> - Do not store the <path> in the dictionary.; -f - Overwrite <file>s.; -failOnWarnings - Fail if there are warnings.; -inlineInputHeader - Does not generate #include <header> but expands the header content.; -interpreteronly - Generate minimal dictionary for interactivity (without IO information).; -m=<string> - The list of dependent modules of the dictionary.; -multiDict - If this library has multiple separate LinkDef files.; -noIncludePaths - Do not store include paths but rely on the env variable ROOT_INCLUDE_PATH.; -p - Deprecated, legacy flag which is ignored.; -rmf=<string> - Generate a rootmap file with the specified name.; -rml=<string> - Generate rootmap file.; -s=<string> - The path to the library of the built dictionary.; -selSyntaxOnly - Check the selection syntax only.; -split - Split the dictionary into two parts: one containing the IO (ClassDef)information and another the interactivity support.; Choose verbosity level:; -v - Show errors (default).; -v0 - Show only fatal errors.; -v1 - Show errors (the same as -v).; -v2 - Show warnings.; -v3 - Show notes.; -v4 - Show information.; ```; ; This patch deprecates:; 1) +P, +V, +STUB, -gccxml, -cint, -reflex -- they are old CINT legacy options which had no meaning in rootcling.; 2) -p, -c -- remove old options used by rootcling -generate-pch as now the build system does not export its lists of flags directly to roocling.; ; The implementation of 2) was quite permissive as it tried to send all possible unknown options directly to rootcling. As a side effect of reworking of 2) we can restrict the options being sent and unknown options are not sent to rootcling anymore, improving encapsulation.; ; If there is a need to do so please contact us or use the EXTRA_CLING_ARGS env option. PS: The end goal is fixing the incremental builds when -Druntime_cxxmodules=On. We will have something like `rootcling --bare-cling=""-fmodules -fno-implicit-module-maps -fmodule-map-file=... -emit-module=std`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4171
https://github.com/root-project/root/pull/4172:23,Availability,failure,failure,23,Typical copy-and-paste failure,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4172
https://github.com/root-project/root/pull/4173:395,Performance,Optimiz,Optimize,395,"In most cases there is no need to generate raw data (vertices and triangles) for TGeoShape on the server side. JSROOT has complete logic to support all kind of TGeoShape classes. Therefore just TGeoShape instance send to client in JSON format. Only for TGeoCompositeShape plain ROOT code is better, therefore enabled by default. . Provide control when server-side or client-side code is used. ; Optimize JSON size - exclude typeinfo for most classes. ; Fix JSROOT code for TGeoArb8 class",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4173
https://github.com/root-project/root/pull/4173:131,Testability,log,logic,131,"In most cases there is no need to generate raw data (vertices and triangles) for TGeoShape on the server side. JSROOT has complete logic to support all kind of TGeoShape classes. Therefore just TGeoShape instance send to client in JSON format. Only for TGeoCompositeShape plain ROOT code is better, therefore enabled by default. . Provide control when server-side or client-side code is used. ; Optimize JSON size - exclude typeinfo for most classes. ; Fix JSROOT code for TGeoArb8 class",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4173
https://github.com/root-project/root/pull/4174:1127,Deployability,update,updated,1127,"The RCutFlowReport class could benefit of a Merge method since it would ease the implementation of the Report RDataFrame operation in a distributed environment.; In a situation where two chunks of a dataset have been processed separately, a report for each chunk would only contain filtering information of that chunk. In this case, merging the two reports together should provide general information on the cut flow of the entire dataset. Right now, the Merge function works as follows:; It takes another RCutFlowReport as argument (passed by reference).; The fCutInfos member of the current RCutFlowReport is stored in a temporary variable and then cleared.; For each TCutInfo, another TCutInfo with the same name is searched in the other report.; The information on all the entries and the passed entries is then summed up between the two objects.; Finally a new TCutInfo with the resulting information is added to the initial RCutFlowReport. The clearing of fCutInfos is needed since the fPass and fAll members of TCutInfo are const.; If seen appropriate, the const keyword can be removed, then the fCutInfos could be just updated each time. A very simple test has been added. TODO:; - [ ] Add more thorough tests.; - [ ] Decide on the return type of the Merge function (now is void).; - [ ] Possibly overload the function with RCutFlowReport* as argument.; - [ ] Finally add documentation when everything is set.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4174
https://github.com/root-project/root/pull/4174:633,Modifiability,variab,variable,633,"The RCutFlowReport class could benefit of a Merge method since it would ease the implementation of the Report RDataFrame operation in a distributed environment.; In a situation where two chunks of a dataset have been processed separately, a report for each chunk would only contain filtering information of that chunk. In this case, merging the two reports together should provide general information on the cut flow of the entire dataset. Right now, the Merge function works as follows:; It takes another RCutFlowReport as argument (passed by reference).; The fCutInfos member of the current RCutFlowReport is stored in a temporary variable and then cleared.; For each TCutInfo, another TCutInfo with the same name is searched in the other report.; The information on all the entries and the passed entries is then summed up between the two objects.; Finally a new TCutInfo with the resulting information is added to the initial RCutFlowReport. The clearing of fCutInfos is needed since the fPass and fAll members of TCutInfo are const.; If seen appropriate, the const keyword can be removed, then the fCutInfos could be just updated each time. A very simple test has been added. TODO:; - [ ] Add more thorough tests.; - [ ] Decide on the return type of the Merge function (now is void).; - [ ] Possibly overload the function with RCutFlowReport* as argument.; - [ ] Finally add documentation when everything is set.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4174
https://github.com/root-project/root/pull/4174:1160,Testability,test,test,1160,"The RCutFlowReport class could benefit of a Merge method since it would ease the implementation of the Report RDataFrame operation in a distributed environment.; In a situation where two chunks of a dataset have been processed separately, a report for each chunk would only contain filtering information of that chunk. In this case, merging the two reports together should provide general information on the cut flow of the entire dataset. Right now, the Merge function works as follows:; It takes another RCutFlowReport as argument (passed by reference).; The fCutInfos member of the current RCutFlowReport is stored in a temporary variable and then cleared.; For each TCutInfo, another TCutInfo with the same name is searched in the other report.; The information on all the entries and the passed entries is then summed up between the two objects.; Finally a new TCutInfo with the resulting information is added to the initial RCutFlowReport. The clearing of fCutInfos is needed since the fPass and fAll members of TCutInfo are const.; If seen appropriate, the const keyword can be removed, then the fCutInfos could be just updated each time. A very simple test has been added. TODO:; - [ ] Add more thorough tests.; - [ ] Decide on the return type of the Merge function (now is void).; - [ ] Possibly overload the function with RCutFlowReport* as argument.; - [ ] Finally add documentation when everything is set.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4174
https://github.com/root-project/root/pull/4174:1212,Testability,test,tests,1212,"The RCutFlowReport class could benefit of a Merge method since it would ease the implementation of the Report RDataFrame operation in a distributed environment.; In a situation where two chunks of a dataset have been processed separately, a report for each chunk would only contain filtering information of that chunk. In this case, merging the two reports together should provide general information on the cut flow of the entire dataset. Right now, the Merge function works as follows:; It takes another RCutFlowReport as argument (passed by reference).; The fCutInfos member of the current RCutFlowReport is stored in a temporary variable and then cleared.; For each TCutInfo, another TCutInfo with the same name is searched in the other report.; The information on all the entries and the passed entries is then summed up between the two objects.; Finally a new TCutInfo with the resulting information is added to the initial RCutFlowReport. The clearing of fCutInfos is needed since the fPass and fAll members of TCutInfo are const.; If seen appropriate, the const keyword can be removed, then the fCutInfos could be just updated each time. A very simple test has been added. TODO:; - [ ] Add more thorough tests.; - [ ] Decide on the return type of the Merge function (now is void).; - [ ] Possibly overload the function with RCutFlowReport* as argument.; - [ ] Finally add documentation when everything is set.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4174
https://github.com/root-project/root/pull/4174:651,Usability,clear,cleared,651,"The RCutFlowReport class could benefit of a Merge method since it would ease the implementation of the Report RDataFrame operation in a distributed environment.; In a situation where two chunks of a dataset have been processed separately, a report for each chunk would only contain filtering information of that chunk. In this case, merging the two reports together should provide general information on the cut flow of the entire dataset. Right now, the Merge function works as follows:; It takes another RCutFlowReport as argument (passed by reference).; The fCutInfos member of the current RCutFlowReport is stored in a temporary variable and then cleared.; For each TCutInfo, another TCutInfo with the same name is searched in the other report.; The information on all the entries and the passed entries is then summed up between the two objects.; Finally a new TCutInfo with the resulting information is added to the initial RCutFlowReport. The clearing of fCutInfos is needed since the fPass and fAll members of TCutInfo are const.; If seen appropriate, the const keyword can be removed, then the fCutInfos could be just updated each time. A very simple test has been added. TODO:; - [ ] Add more thorough tests.; - [ ] Decide on the return type of the Merge function (now is void).; - [ ] Possibly overload the function with RCutFlowReport* as argument.; - [ ] Finally add documentation when everything is set.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4174
https://github.com/root-project/root/pull/4174:950,Usability,clear,clearing,950,"The RCutFlowReport class could benefit of a Merge method since it would ease the implementation of the Report RDataFrame operation in a distributed environment.; In a situation where two chunks of a dataset have been processed separately, a report for each chunk would only contain filtering information of that chunk. In this case, merging the two reports together should provide general information on the cut flow of the entire dataset. Right now, the Merge function works as follows:; It takes another RCutFlowReport as argument (passed by reference).; The fCutInfos member of the current RCutFlowReport is stored in a temporary variable and then cleared.; For each TCutInfo, another TCutInfo with the same name is searched in the other report.; The information on all the entries and the passed entries is then summed up between the two objects.; Finally a new TCutInfo with the resulting information is added to the initial RCutFlowReport. The clearing of fCutInfos is needed since the fPass and fAll members of TCutInfo are const.; If seen appropriate, the const keyword can be removed, then the fCutInfos could be just updated each time. A very simple test has been added. TODO:; - [ ] Add more thorough tests.; - [ ] Decide on the return type of the Merge function (now is void).; - [ ] Possibly overload the function with RCutFlowReport* as argument.; - [ ] Finally add documentation when everything is set.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4174
https://github.com/root-project/root/pull/4174:1153,Usability,simpl,simple,1153,"The RCutFlowReport class could benefit of a Merge method since it would ease the implementation of the Report RDataFrame operation in a distributed environment.; In a situation where two chunks of a dataset have been processed separately, a report for each chunk would only contain filtering information of that chunk. In this case, merging the two reports together should provide general information on the cut flow of the entire dataset. Right now, the Merge function works as follows:; It takes another RCutFlowReport as argument (passed by reference).; The fCutInfos member of the current RCutFlowReport is stored in a temporary variable and then cleared.; For each TCutInfo, another TCutInfo with the same name is searched in the other report.; The information on all the entries and the passed entries is then summed up between the two objects.; Finally a new TCutInfo with the resulting information is added to the initial RCutFlowReport. The clearing of fCutInfos is needed since the fPass and fAll members of TCutInfo are const.; If seen appropriate, the const keyword can be removed, then the fCutInfos could be just updated each time. A very simple test has been added. TODO:; - [ ] Add more thorough tests.; - [ ] Decide on the return type of the Merge function (now is void).; - [ ] Possibly overload the function with RCutFlowReport* as argument.; - [ ] Finally add documentation when everything is set.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4174
https://github.com/root-project/root/pull/4175:194,Deployability,patch,patch,194,When reading rdict files from the module we use the module name to form an; entry in a pending rdict map. It is later used when a library is loaded to; locate the corresponding rdict file. This patch resolves a potential symlinks and allows ROOT to find its rdict; files. It fixes the cmssw C++ modules setup.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4175
https://github.com/root-project/root/pull/4175:141,Performance,load,loaded,141,When reading rdict files from the module we use the module name to form an; entry in a pending rdict map. It is later used when a library is loaded to; locate the corresponding rdict file. This patch resolves a potential symlinks and allows ROOT to find its rdict; files. It fixes the cmssw C++ modules setup.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4175
https://github.com/root-project/root/pull/4178:14,Availability,error,errors,14,"- When weight errors are added to a RooDataSet, but the dataset hasn't; been set up to store weights, these are silently ignored. Users will now; see warnings.; - After adding the last event, the weight variable will keep the value; of the weight error until a new error is set. RooDataSet::add(); therefore now resets weight and weight error after adding an entry. [ROOT-10259]",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4178
https://github.com/root-project/root/pull/4178:247,Availability,error,error,247,"- When weight errors are added to a RooDataSet, but the dataset hasn't; been set up to store weights, these are silently ignored. Users will now; see warnings.; - After adding the last event, the weight variable will keep the value; of the weight error until a new error is set. RooDataSet::add(); therefore now resets weight and weight error after adding an entry. [ROOT-10259]",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4178
https://github.com/root-project/root/pull/4178:265,Availability,error,error,265,"- When weight errors are added to a RooDataSet, but the dataset hasn't; been set up to store weights, these are silently ignored. Users will now; see warnings.; - After adding the last event, the weight variable will keep the value; of the weight error until a new error is set. RooDataSet::add(); therefore now resets weight and weight error after adding an entry. [ROOT-10259]",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4178
https://github.com/root-project/root/pull/4178:337,Availability,error,error,337,"- When weight errors are added to a RooDataSet, but the dataset hasn't; been set up to store weights, these are silently ignored. Users will now; see warnings.; - After adding the last event, the weight variable will keep the value; of the weight error until a new error is set. RooDataSet::add(); therefore now resets weight and weight error after adding an entry. [ROOT-10259]",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4178
https://github.com/root-project/root/pull/4178:203,Modifiability,variab,variable,203,"- When weight errors are added to a RooDataSet, but the dataset hasn't; been set up to store weights, these are silently ignored. Users will now; see warnings.; - After adding the last event, the weight variable will keep the value; of the weight error until a new error is set. RooDataSet::add(); therefore now resets weight and weight error after adding an entry. [ROOT-10259]",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4178
https://github.com/root-project/root/pull/4179:122,Deployability,Update,Update,122,"- Replace the old TFormula-v5-derived RooFormula by a small class that; creates a TFormula v6 [ROOT-10164,ROOT-10144].; - Update documentation for GenericPdf and FormulaVar accordingly.; - Fix small memory leak in RooAbsData.; - The This allows re-enabling the RooJohnson unit test that's based on; RooFormula [ROOT-10173]. It was further tested that [ROOT-8291] doesn't occur with the new; formula when it is serialised.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4179
https://github.com/root-project/root/pull/4179:277,Testability,test,test,277,"- Replace the old TFormula-v5-derived RooFormula by a small class that; creates a TFormula v6 [ROOT-10164,ROOT-10144].; - Update documentation for GenericPdf and FormulaVar accordingly.; - Fix small memory leak in RooAbsData.; - The This allows re-enabling the RooJohnson unit test that's based on; RooFormula [ROOT-10173]. It was further tested that [ROOT-8291] doesn't occur with the new; formula when it is serialised.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4179
https://github.com/root-project/root/pull/4179:339,Testability,test,tested,339,"- Replace the old TFormula-v5-derived RooFormula by a small class that; creates a TFormula v6 [ROOT-10164,ROOT-10144].; - Update documentation for GenericPdf and FormulaVar accordingly.; - Fix small memory leak in RooAbsData.; - The This allows re-enabling the RooJohnson unit test that's based on; RooFormula [ROOT-10173]. It was further tested that [ROOT-8291] doesn't occur with the new; formula when it is serialised.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4179
https://github.com/root-project/root/pull/4182:72,Testability,test,tests,72,"Sometime ROOT wrongly assign kIsOnHeap bit to object, making json-based tests failing.; While these bits must be on after object reading, there is no sense preserve them.; Making JSON code more compact. Instead of:. ""fBits"": 50331649,. one will get:. ""fBits"": 1,. Should solve sporadic problems with roottest.; roottest has to be modified after that PR",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4182
https://github.com/root-project/root/pull/4186:73,Integrability,interface,interface,73,* Reuse REveData table in REveTableProxyBuilder::Build() function; * Add interface in REveManager for client version,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4186
https://github.com/root-project/root/pull/4187:370,Deployability,install,installed,370,"Following our discussions, this is the proposed change to disable the splash screen by default. Most users use `root -l` to get rid of the splash screen in any case. As mentioned in the discussions, it is still possible to see the splash screen with `root -a` or from a `TBrowser`, by going to *Browser Help* → *About ROOT*. If you want to check out this change, I have installed ROOT 6.18 with this change into CVMFS.; You can run it on Linux with (no setup required):; ```; $ /cvmfs/sft.cern.ch/lcg/contrib/gentoo/linux/x86_64/usr/lib/root/6.18/bin/root; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4187
https://github.com/root-project/root/pull/4188:119,Deployability,patch,patch,119,Backport of the TCling changes in https://github.com/root-project/root/pull/4051/. This incorporate the changes of the patch:; https://bitbucket.org/wlav/cppyy-backend/src/master/cling/patches/templ_ctor.diff,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4188
https://github.com/root-project/root/pull/4188:185,Deployability,patch,patches,185,Backport of the TCling changes in https://github.com/root-project/root/pull/4051/. This incorporate the changes of the patch:; https://bitbucket.org/wlav/cppyy-backend/src/master/cling/patches/templ_ctor.diff,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4188
https://github.com/root-project/root/pull/4195:136,Performance,Load,LoadMacro,136,"As discussed here:. https://bitbucket.org/wlav/cppyy/issues/65. some functions/classes in Cppyy's `TPython` are broken, e.g. `Import`, `LoadMacro` and `TPyClassGenerator`. They rely on some ROOT meta functionality that should be now be hidden to CPyCppyy, but they have not been reimplemented yet. Therefore, this PR disables the build of Cppyy's `TPython` and ports the `TPython` present in the old PyROOT to the new Cppyy API, so that all the functionality is still provided.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4195
https://github.com/root-project/root/pull/4196:106,Modifiability,variab,variables,106,"Currently, all user-provided build flags are overwritten without notice.; By making the build flags cache variables, they are only set if the user; didn't set them explicitly.; Further, the printing of the build flags now also correctly prints the; flags being set by the build type.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4196
https://github.com/root-project/root/pull/4196:100,Performance,cache,cache,100,"Currently, all user-provided build flags are overwritten without notice.; By making the build flags cache variables, they are only set if the user; didn't set them explicitly.; Further, the printing of the build flags now also correctly prints the; flags being set by the build type.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4196
https://github.com/root-project/root/pull/4197:34,Integrability,wrap,wrapper,34,"We renamed the class of the numpy wrapper object to numpy.array so that; the wrapping is hidden from the user. However, this breaks pickling of; the object since the class name does not match the name of the true; class. Removing the renaming solves the issue. Now, the returned array; is not called numpy.array but ndarray. This PR fixes current and experimental PyROOT. @etejedor @maxgalli I think this is a feasible solution since the name of the class is anyway only visible in the `__repr__` representation and numpy.array is as good as ndarray since both indicate to the user that the object behaves like a numpy array. Jira ticket can be found here: https://sft.its.cern.ch/jira/browse/ROOT-10268",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4197
https://github.com/root-project/root/pull/4197:77,Integrability,wrap,wrapping,77,"We renamed the class of the numpy wrapper object to numpy.array so that; the wrapping is hidden from the user. However, this breaks pickling of; the object since the class name does not match the name of the true; class. Removing the renaming solves the issue. Now, the returned array; is not called numpy.array but ndarray. This PR fixes current and experimental PyROOT. @etejedor @maxgalli I think this is a feasible solution since the name of the class is anyway only visible in the `__repr__` representation and numpy.array is as good as ndarray since both indicate to the user that the object behaves like a numpy array. Jira ticket can be found here: https://sft.its.cern.ch/jira/browse/ROOT-10268",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4197
https://github.com/root-project/root/pull/4202:89,Security,access,accessed,89,"As reported by ROOT-8935, when an enum is in a namespace and the; values of the enum are accessed via the namespace, the underlying; type of the enum is not taken into account. With this fix, we check the underlying type of the enum in; PropertyProxy::Set before creating the converter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4202
https://github.com/root-project/root/pull/4206:89,Security,access,accessed,89,"As reported by ROOT-8935, when an enum is in a namespace and the; values of the enum are accessed via the namespace, the underlying; type of the enum is not taken into account. With this fix, we check the underlying type of the enum in; PropertyProxy::Set before creating the converter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4206
https://github.com/root-project/root/pull/4208:72,Performance,concurren,concurrent,72,"Use random numbers in the file names created during unit tests, so that concurrent unit tests don't remove each others files.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4208
https://github.com/root-project/root/pull/4208:57,Testability,test,tests,57,"Use random numbers in the file names created during unit tests, so that concurrent unit tests don't remove each others files.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4208
https://github.com/root-project/root/pull/4208:88,Testability,test,tests,88,"Use random numbers in the file names created during unit tests, so that concurrent unit tests don't remove each others files.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4208
https://github.com/root-project/root/pull/4211:138,Deployability,integrat,integration,138,"This is a proof of concept for a part of a TMVA GUI replacement. The basic ideas:; - Make it modular, no monolithic tool; - Provide tight integration with RDataFrame. I copy below the tutorial that I've added in the PR. Known issues:; - The automatic range for the histos is very weird.; - Naming of the class is not optimal. ```cpp; void tmva005_RVariablePlotter(); // Initialize ROOT dataframes from signal and background datasets; const std::string filename = ""http://root.cern.ch/files/tmva_class_example.root"";; ROOT::RDataFrame sig1(""TreeS"", filename);; ROOT::RDataFrame bkg1(""TreeB"", filename);. // Apply transformations on the datasets to be included in the study; auto transform = [](auto df) { return df.Define(""var5"", ""var1 * var2""); };; auto sig2 = transform(sig1);; auto bkg2 = transform(bkg1);; auto sig3 = sig2.Filter(""var1 > 0"");. // Create a variable plotter object giving the dataframes and the class labels.; RVariablePlotter plotter({sig2, bkg2, sig3},; {""Signal"", ""Background"", ""Signal (var1 > 0)""});. // Create a canvas with four pads for plotting; auto c = new TCanvas("""", """", 1200, 800);; c->Divide(3, 2);. // Place plots on the pads of the canvas; const std::vector<std::string> variables = {""var1"", ""var2"", ""var3"", ""var4"", ""var5""};; for (unsigned int i = 0; i < variables.size(); i++) {; c->cd(i + 1);; plotter.Draw(variables[i]);; }; c->cd(6);; plotter.DrawLegend();; c->DrawClone();; }; ```. ![x](https://user-images.githubusercontent.com/6951222/63058987-7b33d880-beee-11e9-974d-264d06ea0869.png)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4211
https://github.com/root-project/root/pull/4211:138,Integrability,integrat,integration,138,"This is a proof of concept for a part of a TMVA GUI replacement. The basic ideas:; - Make it modular, no monolithic tool; - Provide tight integration with RDataFrame. I copy below the tutorial that I've added in the PR. Known issues:; - The automatic range for the histos is very weird.; - Naming of the class is not optimal. ```cpp; void tmva005_RVariablePlotter(); // Initialize ROOT dataframes from signal and background datasets; const std::string filename = ""http://root.cern.ch/files/tmva_class_example.root"";; ROOT::RDataFrame sig1(""TreeS"", filename);; ROOT::RDataFrame bkg1(""TreeB"", filename);. // Apply transformations on the datasets to be included in the study; auto transform = [](auto df) { return df.Define(""var5"", ""var1 * var2""); };; auto sig2 = transform(sig1);; auto bkg2 = transform(bkg1);; auto sig3 = sig2.Filter(""var1 > 0"");. // Create a variable plotter object giving the dataframes and the class labels.; RVariablePlotter plotter({sig2, bkg2, sig3},; {""Signal"", ""Background"", ""Signal (var1 > 0)""});. // Create a canvas with four pads for plotting; auto c = new TCanvas("""", """", 1200, 800);; c->Divide(3, 2);. // Place plots on the pads of the canvas; const std::vector<std::string> variables = {""var1"", ""var2"", ""var3"", ""var4"", ""var5""};; for (unsigned int i = 0; i < variables.size(); i++) {; c->cd(i + 1);; plotter.Draw(variables[i]);; }; c->cd(6);; plotter.DrawLegend();; c->DrawClone();; }; ```. ![x](https://user-images.githubusercontent.com/6951222/63058987-7b33d880-beee-11e9-974d-264d06ea0869.png)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4211
https://github.com/root-project/root/pull/4211:859,Modifiability,variab,variable,859,"This is a proof of concept for a part of a TMVA GUI replacement. The basic ideas:; - Make it modular, no monolithic tool; - Provide tight integration with RDataFrame. I copy below the tutorial that I've added in the PR. Known issues:; - The automatic range for the histos is very weird.; - Naming of the class is not optimal. ```cpp; void tmva005_RVariablePlotter(); // Initialize ROOT dataframes from signal and background datasets; const std::string filename = ""http://root.cern.ch/files/tmva_class_example.root"";; ROOT::RDataFrame sig1(""TreeS"", filename);; ROOT::RDataFrame bkg1(""TreeB"", filename);. // Apply transformations on the datasets to be included in the study; auto transform = [](auto df) { return df.Define(""var5"", ""var1 * var2""); };; auto sig2 = transform(sig1);; auto bkg2 = transform(bkg1);; auto sig3 = sig2.Filter(""var1 > 0"");. // Create a variable plotter object giving the dataframes and the class labels.; RVariablePlotter plotter({sig2, bkg2, sig3},; {""Signal"", ""Background"", ""Signal (var1 > 0)""});. // Create a canvas with four pads for plotting; auto c = new TCanvas("""", """", 1200, 800);; c->Divide(3, 2);. // Place plots on the pads of the canvas; const std::vector<std::string> variables = {""var1"", ""var2"", ""var3"", ""var4"", ""var5""};; for (unsigned int i = 0; i < variables.size(); i++) {; c->cd(i + 1);; plotter.Draw(variables[i]);; }; c->cd(6);; plotter.DrawLegend();; c->DrawClone();; }; ```. ![x](https://user-images.githubusercontent.com/6951222/63058987-7b33d880-beee-11e9-974d-264d06ea0869.png)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4211
https://github.com/root-project/root/pull/4211:1204,Modifiability,variab,variables,1204,"This is a proof of concept for a part of a TMVA GUI replacement. The basic ideas:; - Make it modular, no monolithic tool; - Provide tight integration with RDataFrame. I copy below the tutorial that I've added in the PR. Known issues:; - The automatic range for the histos is very weird.; - Naming of the class is not optimal. ```cpp; void tmva005_RVariablePlotter(); // Initialize ROOT dataframes from signal and background datasets; const std::string filename = ""http://root.cern.ch/files/tmva_class_example.root"";; ROOT::RDataFrame sig1(""TreeS"", filename);; ROOT::RDataFrame bkg1(""TreeB"", filename);. // Apply transformations on the datasets to be included in the study; auto transform = [](auto df) { return df.Define(""var5"", ""var1 * var2""); };; auto sig2 = transform(sig1);; auto bkg2 = transform(bkg1);; auto sig3 = sig2.Filter(""var1 > 0"");. // Create a variable plotter object giving the dataframes and the class labels.; RVariablePlotter plotter({sig2, bkg2, sig3},; {""Signal"", ""Background"", ""Signal (var1 > 0)""});. // Create a canvas with four pads for plotting; auto c = new TCanvas("""", """", 1200, 800);; c->Divide(3, 2);. // Place plots on the pads of the canvas; const std::vector<std::string> variables = {""var1"", ""var2"", ""var3"", ""var4"", ""var5""};; for (unsigned int i = 0; i < variables.size(); i++) {; c->cd(i + 1);; plotter.Draw(variables[i]);; }; c->cd(6);; plotter.DrawLegend();; c->DrawClone();; }; ```. ![x](https://user-images.githubusercontent.com/6951222/63058987-7b33d880-beee-11e9-974d-264d06ea0869.png)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4211
https://github.com/root-project/root/pull/4211:1288,Modifiability,variab,variables,1288,"This is a proof of concept for a part of a TMVA GUI replacement. The basic ideas:; - Make it modular, no monolithic tool; - Provide tight integration with RDataFrame. I copy below the tutorial that I've added in the PR. Known issues:; - The automatic range for the histos is very weird.; - Naming of the class is not optimal. ```cpp; void tmva005_RVariablePlotter(); // Initialize ROOT dataframes from signal and background datasets; const std::string filename = ""http://root.cern.ch/files/tmva_class_example.root"";; ROOT::RDataFrame sig1(""TreeS"", filename);; ROOT::RDataFrame bkg1(""TreeB"", filename);. // Apply transformations on the datasets to be included in the study; auto transform = [](auto df) { return df.Define(""var5"", ""var1 * var2""); };; auto sig2 = transform(sig1);; auto bkg2 = transform(bkg1);; auto sig3 = sig2.Filter(""var1 > 0"");. // Create a variable plotter object giving the dataframes and the class labels.; RVariablePlotter plotter({sig2, bkg2, sig3},; {""Signal"", ""Background"", ""Signal (var1 > 0)""});. // Create a canvas with four pads for plotting; auto c = new TCanvas("""", """", 1200, 800);; c->Divide(3, 2);. // Place plots on the pads of the canvas; const std::vector<std::string> variables = {""var1"", ""var2"", ""var3"", ""var4"", ""var5""};; for (unsigned int i = 0; i < variables.size(); i++) {; c->cd(i + 1);; plotter.Draw(variables[i]);; }; c->cd(6);; plotter.DrawLegend();; c->DrawClone();; }; ```. ![x](https://user-images.githubusercontent.com/6951222/63058987-7b33d880-beee-11e9-974d-264d06ea0869.png)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4211
https://github.com/root-project/root/pull/4211:1342,Modifiability,variab,variables,1342,"This is a proof of concept for a part of a TMVA GUI replacement. The basic ideas:; - Make it modular, no monolithic tool; - Provide tight integration with RDataFrame. I copy below the tutorial that I've added in the PR. Known issues:; - The automatic range for the histos is very weird.; - Naming of the class is not optimal. ```cpp; void tmva005_RVariablePlotter(); // Initialize ROOT dataframes from signal and background datasets; const std::string filename = ""http://root.cern.ch/files/tmva_class_example.root"";; ROOT::RDataFrame sig1(""TreeS"", filename);; ROOT::RDataFrame bkg1(""TreeB"", filename);. // Apply transformations on the datasets to be included in the study; auto transform = [](auto df) { return df.Define(""var5"", ""var1 * var2""); };; auto sig2 = transform(sig1);; auto bkg2 = transform(bkg1);; auto sig3 = sig2.Filter(""var1 > 0"");. // Create a variable plotter object giving the dataframes and the class labels.; RVariablePlotter plotter({sig2, bkg2, sig3},; {""Signal"", ""Background"", ""Signal (var1 > 0)""});. // Create a canvas with four pads for plotting; auto c = new TCanvas("""", """", 1200, 800);; c->Divide(3, 2);. // Place plots on the pads of the canvas; const std::vector<std::string> variables = {""var1"", ""var2"", ""var3"", ""var4"", ""var5""};; for (unsigned int i = 0; i < variables.size(); i++) {; c->cd(i + 1);; plotter.Draw(variables[i]);; }; c->cd(6);; plotter.DrawLegend();; c->DrawClone();; }; ```. ![x](https://user-images.githubusercontent.com/6951222/63058987-7b33d880-beee-11e9-974d-264d06ea0869.png)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4211
https://github.com/root-project/root/pull/4212:48,Availability,error,error,48,"Because of limited flaoting point precision, an error message was issued; on 32 bit architectures. The concerned check for equality check is now; a bit more forgiving.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4212
https://github.com/root-project/root/pull/4212:54,Integrability,message,message,54,"Because of limited flaoting point precision, an error message was issued; on 32 bit architectures. The concerned check for equality check is now; a bit more forgiving.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4212
https://github.com/root-project/root/pull/4215:5,Deployability,patch,patch,5,This patch should fix ROOT-10272.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4215
https://github.com/root-project/root/pull/4218:48,Availability,error,error,48,"Because of limited floating point precision, an error message was issued; on 32 bit architectures. The concerned check for equality is now; a bit more forgiving. (cherry picked from commit b8235e91725d94dc6231e8006e2de53dc1b2671e)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4218
https://github.com/root-project/root/pull/4218:54,Integrability,message,message,54,"Because of limited floating point precision, an error message was issued; on 32 bit architectures. The concerned check for equality is now; a bit more forgiving. (cherry picked from commit b8235e91725d94dc6231e8006e2de53dc1b2671e)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4218
https://github.com/root-project/root/pull/4219:265,Deployability,patch,patch,265,Rootcling builds a set of modules implicitly based on #including of a header; contained in the nominated module. The build system has no way to track such; dependencies and even if it could there would be no rule to execute to; regenerate the outdated module. This patch extends rootcling to also keep track of the implicitly generated; modules and delete them (to regenerate them). A more sustainable solution is to; request each module to be built explicitly which requires a bit of refactoring; in rootcling.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4219
https://github.com/root-project/root/pull/4219:390,Energy Efficiency,sustainab,sustainable,390,Rootcling builds a set of modules implicitly based on #including of a header; contained in the nominated module. The build system has no way to track such; dependencies and even if it could there would be no rule to execute to; regenerate the outdated module. This patch extends rootcling to also keep track of the implicitly generated; modules and delete them (to regenerate them). A more sustainable solution is to; request each module to be built explicitly which requires a bit of refactoring; in rootcling.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4219
https://github.com/root-project/root/pull/4219:156,Integrability,depend,dependencies,156,Rootcling builds a set of modules implicitly based on #including of a header; contained in the nominated module. The build system has no way to track such; dependencies and even if it could there would be no rule to execute to; regenerate the outdated module. This patch extends rootcling to also keep track of the implicitly generated; modules and delete them (to regenerate them). A more sustainable solution is to; request each module to be built explicitly which requires a bit of refactoring; in rootcling.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4219
https://github.com/root-project/root/pull/4219:271,Modifiability,extend,extends,271,Rootcling builds a set of modules implicitly based on #including of a header; contained in the nominated module. The build system has no way to track such; dependencies and even if it could there would be no rule to execute to; regenerate the outdated module. This patch extends rootcling to also keep track of the implicitly generated; modules and delete them (to regenerate them). A more sustainable solution is to; request each module to be built explicitly which requires a bit of refactoring; in rootcling.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4219
https://github.com/root-project/root/pull/4219:485,Modifiability,refactor,refactoring,485,Rootcling builds a set of modules implicitly based on #including of a header; contained in the nominated module. The build system has no way to track such; dependencies and even if it could there would be no rule to execute to; regenerate the outdated module. This patch extends rootcling to also keep track of the implicitly generated; modules and delete them (to regenerate them). A more sustainable solution is to; request each module to be built explicitly which requires a bit of refactoring; in rootcling.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4219
https://github.com/root-project/root/pull/4220:29,Safety,avoid,avoiding,29,This mitigates ROOT-10269 by avoiding nested task execution due; to a parallel Snapshot.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4220
https://github.com/root-project/root/pull/4221:29,Safety,avoid,avoiding,29,This mitigates ROOT-10269 by avoiding nested task execution due; to a parallel Snapshot.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4221
https://github.com/root-project/root/pull/4222:164,Deployability,patch,patch,164,"For some reason, calling `isInlined()` member function on an `operator new()` FunctionDecl does not return the expected result for an inline-defined function. This patch workarounds the aforementioned problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4222
https://github.com/root-project/root/pull/4223:167,Integrability,interface,interface,167,Use very nice feature of openui5 SplitApp to manage different pages together!. * Re-implement GUI which was designed before using dat.GUI.; * Change a lot TGeoPainter interface - especially for setting control parameters; * Newest JSROOT code with several improvements,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4223
https://github.com/root-project/root/pull/4224:117,Testability,log,logging,117,"Problem: When creating the separate factory for per-fold output, the silent flag was given. This suppresses all TMVA logging output (touches global state). Solution: The silent flag is not passed to the per-fold factory automatically anymore.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4224
https://github.com/root-project/root/pull/4230:32,Integrability,depend,dependencies,32,This removes the false positive dependencies in the rootbench builds.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4230
https://github.com/root-project/root/pull/4239:190,Integrability,interface,interface,190,"While TBuffer has many virtual methods, provide `override` and `final` specifiers for all derived classes. This will help to maintain code in the future - any bogus changes in TBuffer class interface will be reported already during compilation.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4239
https://github.com/root-project/root/pull/4243:30,Deployability,Release,Release,30,"- When the LLVM_BUILD_TYPE is Release, but the CXX_FLAGS are empty, a; warning is issued.; - When configuring, fix the order in which compiler flags are printed. This is the issue mentioned on mattermost. Axel proposed to issue a warning in this case. The question is if this warning catches all cases where build types might be set up wrongly or if the `CMAKE_CXX_FLAGS_${LLVM_BUILD_TYPE}` should be tested.; I also fixed the order in which the compiler flags are printed. I didn't get to this before cache-variable PR where I promised to do this got merged.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4243
https://github.com/root-project/root/pull/4243:98,Modifiability,config,configuring,98,"- When the LLVM_BUILD_TYPE is Release, but the CXX_FLAGS are empty, a; warning is issued.; - When configuring, fix the order in which compiler flags are printed. This is the issue mentioned on mattermost. Axel proposed to issue a warning in this case. The question is if this warning catches all cases where build types might be set up wrongly or if the `CMAKE_CXX_FLAGS_${LLVM_BUILD_TYPE}` should be tested.; I also fixed the order in which the compiler flags are printed. I didn't get to this before cache-variable PR where I promised to do this got merged.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4243
https://github.com/root-project/root/pull/4243:508,Modifiability,variab,variable,508,"- When the LLVM_BUILD_TYPE is Release, but the CXX_FLAGS are empty, a; warning is issued.; - When configuring, fix the order in which compiler flags are printed. This is the issue mentioned on mattermost. Axel proposed to issue a warning in this case. The question is if this warning catches all cases where build types might be set up wrongly or if the `CMAKE_CXX_FLAGS_${LLVM_BUILD_TYPE}` should be tested.; I also fixed the order in which the compiler flags are printed. I didn't get to this before cache-variable PR where I promised to do this got merged.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4243
https://github.com/root-project/root/pull/4243:502,Performance,cache,cache-variable,502,"- When the LLVM_BUILD_TYPE is Release, but the CXX_FLAGS are empty, a; warning is issued.; - When configuring, fix the order in which compiler flags are printed. This is the issue mentioned on mattermost. Axel proposed to issue a warning in this case. The question is if this warning catches all cases where build types might be set up wrongly or if the `CMAKE_CXX_FLAGS_${LLVM_BUILD_TYPE}` should be tested.; I also fixed the order in which the compiler flags are printed. I didn't get to this before cache-variable PR where I promised to do this got merged.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4243
https://github.com/root-project/root/pull/4243:401,Testability,test,tested,401,"- When the LLVM_BUILD_TYPE is Release, but the CXX_FLAGS are empty, a; warning is issued.; - When configuring, fix the order in which compiler flags are printed. This is the issue mentioned on mattermost. Axel proposed to issue a warning in this case. The question is if this warning catches all cases where build types might be set up wrongly or if the `CMAKE_CXX_FLAGS_${LLVM_BUILD_TYPE}` should be tested.; I also fixed the order in which the compiler flags are printed. I didn't get to this before cache-variable PR where I promised to do this got merged.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4243
https://github.com/root-project/root/pull/4244:202,Testability,test,tests,202,"- When trying to execute a macro with .x and the corresponding function is; not found, a more informative warning is issued.; - Further, the interpreter can now fall back to main() if defined. In local tests, I didn't manage to trigger a clash with the ""real"" main. I tried to define both; - `int main()` and; - `int main(int argc, char** argv)`,; but it just compiles and does the right thing (either it calls with the correct parameters or it complains that the parameters don't match).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4244
https://github.com/root-project/root/pull/4246:101,Integrability,inject,injection,101,"This PR completes the fix provided for ROOT-8935 with another fix for ROOT-10279, by preventing; the injection of the constants of a scoped enum into the scope of the enum. The bug surfaced as a result of modifying `PropertyProxy::Set` to fix ROOT-9835. There is still a pending issue identified while testing the fixes above: when a scoped enum belongs to the global namespace, once we do a lookup of that scoped enum its constants are added to the global space too and can be accessed as `ROOT.constant_name`, which is wrong. A subsequent PR will fix this issue.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4246
https://github.com/root-project/root/pull/4246:101,Security,inject,injection,101,"This PR completes the fix provided for ROOT-8935 with another fix for ROOT-10279, by preventing; the injection of the constants of a scoped enum into the scope of the enum. The bug surfaced as a result of modifying `PropertyProxy::Set` to fix ROOT-9835. There is still a pending issue identified while testing the fixes above: when a scoped enum belongs to the global namespace, once we do a lookup of that scoped enum its constants are added to the global space too and can be accessed as `ROOT.constant_name`, which is wrong. A subsequent PR will fix this issue.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4246
https://github.com/root-project/root/pull/4246:478,Security,access,accessed,478,"This PR completes the fix provided for ROOT-8935 with another fix for ROOT-10279, by preventing; the injection of the constants of a scoped enum into the scope of the enum. The bug surfaced as a result of modifying `PropertyProxy::Set` to fix ROOT-9835. There is still a pending issue identified while testing the fixes above: when a scoped enum belongs to the global namespace, once we do a lookup of that scoped enum its constants are added to the global space too and can be accessed as `ROOT.constant_name`, which is wrong. A subsequent PR will fix this issue.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4246
https://github.com/root-project/root/pull/4246:302,Testability,test,testing,302,"This PR completes the fix provided for ROOT-8935 with another fix for ROOT-10279, by preventing; the injection of the constants of a scoped enum into the scope of the enum. The bug surfaced as a result of modifying `PropertyProxy::Set` to fix ROOT-9835. There is still a pending issue identified while testing the fixes above: when a scoped enum belongs to the global namespace, once we do a lookup of that scoped enum its constants are added to the global space too and can be accessed as `ROOT.constant_name`, which is wrong. A subsequent PR will fix this issue.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4246
https://github.com/root-project/root/pull/4248:239,Integrability,depend,depends,239,This PR is a WIP for implementing dictionary reusing within a branch in ZSTD. The work is based on previous work of Brian for the Compression Engine although it does not make use of any of the functions associated with training. This work depends on: https://github.com/root-project/root/pull/3947. Two extra file are added (ZSTDEngine2.hxx/cxx) that provide the infrastructure to perform a detailed analysis of the compression and decompression at basket level. An analysis related with the current performance of this implementation can be found [here](https://gist.github.com/fylux/ac92de799ac3e9d3e81d5edeeeef46f6).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4248
https://github.com/root-project/root/pull/4248:381,Performance,perform,perform,381,This PR is a WIP for implementing dictionary reusing within a branch in ZSTD. The work is based on previous work of Brian for the Compression Engine although it does not make use of any of the functions associated with training. This work depends on: https://github.com/root-project/root/pull/3947. Two extra file are added (ZSTDEngine2.hxx/cxx) that provide the infrastructure to perform a detailed analysis of the compression and decompression at basket level. An analysis related with the current performance of this implementation can be found [here](https://gist.github.com/fylux/ac92de799ac3e9d3e81d5edeeeef46f6).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4248
https://github.com/root-project/root/pull/4248:500,Performance,perform,performance,500,This PR is a WIP for implementing dictionary reusing within a branch in ZSTD. The work is based on previous work of Brian for the Compression Engine although it does not make use of any of the functions associated with training. This work depends on: https://github.com/root-project/root/pull/3947. Two extra file are added (ZSTDEngine2.hxx/cxx) that provide the infrastructure to perform a detailed analysis of the compression and decompression at basket level. An analysis related with the current performance of this implementation can be found [here](https://gist.github.com/fylux/ac92de799ac3e9d3e81d5edeeeef46f6).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4248
https://github.com/root-project/root/pull/4249:28,Deployability,configurat,configuration,28,"1. Let interactively change configuration for draw object selection - like visibility level or maximal number of nodes. All these parameters combined together in configuration object, which can be send to server as JSON.; 2. Show actual statistic about number of meshes and faces in produced three.js geometry; 3. Let configure different light source (like in normal geometry viewer); 4. Provide JSROOT with correspondent changes",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4249
https://github.com/root-project/root/pull/4249:162,Deployability,configurat,configuration,162,"1. Let interactively change configuration for draw object selection - like visibility level or maximal number of nodes. All these parameters combined together in configuration object, which can be send to server as JSON.; 2. Show actual statistic about number of meshes and faces in produced three.js geometry; 3. Let configure different light source (like in normal geometry viewer); 4. Provide JSROOT with correspondent changes",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4249
https://github.com/root-project/root/pull/4249:28,Modifiability,config,configuration,28,"1. Let interactively change configuration for draw object selection - like visibility level or maximal number of nodes. All these parameters combined together in configuration object, which can be send to server as JSON.; 2. Show actual statistic about number of meshes and faces in produced three.js geometry; 3. Let configure different light source (like in normal geometry viewer); 4. Provide JSROOT with correspondent changes",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4249
https://github.com/root-project/root/pull/4249:162,Modifiability,config,configuration,162,"1. Let interactively change configuration for draw object selection - like visibility level or maximal number of nodes. All these parameters combined together in configuration object, which can be send to server as JSON.; 2. Show actual statistic about number of meshes and faces in produced three.js geometry; 3. Let configure different light source (like in normal geometry viewer); 4. Provide JSROOT with correspondent changes",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4249
https://github.com/root-project/root/pull/4249:318,Modifiability,config,configure,318,"1. Let interactively change configuration for draw object selection - like visibility level or maximal number of nodes. All these parameters combined together in configuration object, which can be send to server as JSON.; 2. Show actual statistic about number of meshes and faces in produced three.js geometry; 3. Let configure different light source (like in normal geometry viewer); 4. Provide JSROOT with correspondent changes",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4249
https://github.com/root-project/root/pull/4252:11,Testability,test,test,11,New google test for TH2Poly::Add (against ROOT-10280),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4252
https://github.com/root-project/root/pull/4254:51,Integrability,message,message,51,"We get these symbols even for a simple hello world message. While it is not clear if we can skip all weak undefined symbols, we can certainly skip those which get resolved to libgcj.so and libitm.so. Oddly enough gcc emits a weak undefined symbol to _Jv_RegisterClasses (resolved in libgcj.so) which is some gcc/java library. _ITM_deregisterTMCloneTable and _ITM_registerTMCloneTable are emitted because (resolved in libitm.so) of pointer arithmetics for transactional memory support. The current understanding is that we can safely omit these when harvesting library dependencies. This should fix the rootbench builds.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4254
https://github.com/root-project/root/pull/4254:568,Integrability,depend,dependencies,568,"We get these symbols even for a simple hello world message. While it is not clear if we can skip all weak undefined symbols, we can certainly skip those which get resolved to libgcj.so and libitm.so. Oddly enough gcc emits a weak undefined symbol to _Jv_RegisterClasses (resolved in libgcj.so) which is some gcc/java library. _ITM_deregisterTMCloneTable and _ITM_registerTMCloneTable are emitted because (resolved in libitm.so) of pointer arithmetics for transactional memory support. The current understanding is that we can safely omit these when harvesting library dependencies. This should fix the rootbench builds.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4254
https://github.com/root-project/root/pull/4254:526,Safety,safe,safely,526,"We get these symbols even for a simple hello world message. While it is not clear if we can skip all weak undefined symbols, we can certainly skip those which get resolved to libgcj.so and libitm.so. Oddly enough gcc emits a weak undefined symbol to _Jv_RegisterClasses (resolved in libgcj.so) which is some gcc/java library. _ITM_deregisterTMCloneTable and _ITM_registerTMCloneTable are emitted because (resolved in libitm.so) of pointer arithmetics for transactional memory support. The current understanding is that we can safely omit these when harvesting library dependencies. This should fix the rootbench builds.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4254
https://github.com/root-project/root/pull/4254:32,Usability,simpl,simple,32,"We get these symbols even for a simple hello world message. While it is not clear if we can skip all weak undefined symbols, we can certainly skip those which get resolved to libgcj.so and libitm.so. Oddly enough gcc emits a weak undefined symbol to _Jv_RegisterClasses (resolved in libgcj.so) which is some gcc/java library. _ITM_deregisterTMCloneTable and _ITM_registerTMCloneTable are emitted because (resolved in libitm.so) of pointer arithmetics for transactional memory support. The current understanding is that we can safely omit these when harvesting library dependencies. This should fix the rootbench builds.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4254
https://github.com/root-project/root/pull/4254:76,Usability,clear,clear,76,"We get these symbols even for a simple hello world message. While it is not clear if we can skip all weak undefined symbols, we can certainly skip those which get resolved to libgcj.so and libitm.so. Oddly enough gcc emits a weak undefined symbol to _Jv_RegisterClasses (resolved in libgcj.so) which is some gcc/java library. _ITM_deregisterTMCloneTable and _ITM_registerTMCloneTable are emitted because (resolved in libitm.so) of pointer arithmetics for transactional memory support. The current understanding is that we can safely omit these when harvesting library dependencies. This should fix the rootbench builds.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4254
https://github.com/root-project/root/pull/4257:59,Availability,failure,failure,59,"(reported by -Wimplicit-int-float-conversion). Fixing next failure (http://cdash.cern.ch/testDetails.php?test=69494934&build=706195):; -- TEST COMMAND -- ; cd /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core; /usr/bin/timeout -s USR2 270s root.exe -e '#define ClingWorkAroundMissingDynamicScope' -e '#define ClingWorkAroundUnnamedInclude' -e '#define ClingWorkAroundMissingSmartInclude' -e '#define ClingWorkAroundNoDotInclude' -e '#define ClingWorkAroundMissingAutoLoadingForTemplates' -e '#define ClingWorkAroundAutoParseUsingNamespace' -e '#define ClingWorkAroundTClassUpdateDouble32' -e '#define ClingWorkAroundAutoParseDeclaration' -e '#define ClingWorkAroundMissingUnloading' -e '#define ClingWorkAroundBrokenUnnamedReturn' -e '#define ClingWorkAroundUnnamedDetection2' -e 'gSystem->SetBuildDir(""/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"",true)' -e 'gSystem->AddDynamicPath(""/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"")' -e 'gROOT->SetMacroPath(""/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core"")' -e 'gInterpreter->AddIncludePath(""-I/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"")' -e 'gSystem->AddIncludePath(""-I/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"")' -q -l -b /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx+; -- BEGIN TEST OUTPUT --. Processing /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx+...; Checking FromHumanReadableSize; Checking ToHumanReadableSize; Checking 1024 vs 1.024KiB an 1KB; Checking 2097152 vs 2.09715MiB an 2MB; Checking 4294967296 vs 4.29497GiB an 4GB; Checking 8796093022208 vs 8.7960",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4257
https://github.com/root-project/root/pull/4257:2456,Availability,ERROR,ERROR,2456,00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx+; -- BEGIN TEST OUTPUT --. Processing /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx+...; Checking FromHumanReadableSize; Checking ToHumanReadableSize; Checking 1024 vs 1.024KiB an 1KB; Checking 2097152 vs 2.09715MiB an 2MB; Checking 4294967296 vs 4.29497GiB an 4GB; Checking 8796093022208 vs 8.79609TiB an 8TB; Checking 18014398509481984 vs 18.0144EiB an 16EB; Checking 16 vs 16B and 16B; Checking 24576 vs 24.576KiB and 24KB; Checking 3.77487e+07 vs 37.7487MiB and 36MB; Checking 5.79821e+10 vs 57.9821GiB and 54GB; Checking 8.90604e+13 vs 89.0604TiB and 81TB; Checking 1.36797e+17 vs 136.797EiB and 121.5EB; Checking 2.1012e+20 vs 210.12ZiB and 182.25ZB; Checking 3.22744e+23 vs 322.744YiB and 273.375YB; (int) 0. -- END TEST OUTPUT --; -- BEGIN TEST ERROR --; Info in <TUnixSystem::ACLiC>: creating shared library /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core/assertHumanReadable_cxx.so; In file included from /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core/assertHumanReadable_cxx_ACLiC_dict.cxx:41:; In file included from /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx:1:; [NON-XML-CHAR-0x1B][1m/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/include/ROOT/StringConv.hxx:103:18: [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][0;1;35mwarning: [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][1mimplicit conversion from 'long long' to 'double' changes value from 9223372036854775807 to 9223372036854775808 [-Wimplicit-int-float-conversion][NON-XML-CHAR-0x1B][0m; if (v < std::numeric_limits<T>::max()) {; [NON-XML-CHAR-0x1B][0;1;32m ~ ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~; [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][1m/mnt/build,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4257
https://github.com/root-project/root/pull/4257:4003,Availability,ERROR,ERROR,4003,"5.79821e+10 vs 57.9821GiB and 54GB; Checking 8.90604e+13 vs 89.0604TiB and 81TB; Checking 1.36797e+17 vs 136.797EiB and 121.5EB; Checking 2.1012e+20 vs 210.12ZiB and 182.25ZB; Checking 3.22744e+23 vs 322.744YiB and 273.375YB; (int) 0. -- END TEST OUTPUT --; -- BEGIN TEST ERROR --; Info in <TUnixSystem::ACLiC>: creating shared library /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core/assertHumanReadable_cxx.so; In file included from /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core/assertHumanReadable_cxx_ACLiC_dict.cxx:41:; In file included from /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx:1:; [NON-XML-CHAR-0x1B][1m/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/include/ROOT/StringConv.hxx:103:18: [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][0;1;35mwarning: [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][1mimplicit conversion from 'long long' to 'double' changes value from 9223372036854775807 to 9223372036854775808 [-Wimplicit-int-float-conversion][NON-XML-CHAR-0x1B][0m; if (v < std::numeric_limits<T>::max()) {; [NON-XML-CHAR-0x1B][0;1;32m ~ ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~; [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][1m/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx:9:29: [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][0;1;30mnote: [NON-XML-CHAR-0x1B][0min instantiation of function template specialization 'ROOT::FromHumanReadableSize<long long>' requested here[NON-XML-CHAR-0x1B][0m; auto parseResult = ROOT::FromHumanReadableSize(input,res);; [NON-XML-CHAR-0x1B][0;1;32m ^; [NON-XML-CHAR-0x1B][0m1 warning generated. -- END TEST ERROR --; CMake Error at /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/root/cmake/modules/RootTestDriver.cmake:179 (message):; Unexpected error output",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4257
https://github.com/root-project/root/pull/4257:4019,Availability,Error,Error,4019,"5.79821e+10 vs 57.9821GiB and 54GB; Checking 8.90604e+13 vs 89.0604TiB and 81TB; Checking 1.36797e+17 vs 136.797EiB and 121.5EB; Checking 2.1012e+20 vs 210.12ZiB and 182.25ZB; Checking 3.22744e+23 vs 322.744YiB and 273.375YB; (int) 0. -- END TEST OUTPUT --; -- BEGIN TEST ERROR --; Info in <TUnixSystem::ACLiC>: creating shared library /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core/assertHumanReadable_cxx.so; In file included from /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core/assertHumanReadable_cxx_ACLiC_dict.cxx:41:; In file included from /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx:1:; [NON-XML-CHAR-0x1B][1m/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/include/ROOT/StringConv.hxx:103:18: [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][0;1;35mwarning: [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][1mimplicit conversion from 'long long' to 'double' changes value from 9223372036854775807 to 9223372036854775808 [-Wimplicit-int-float-conversion][NON-XML-CHAR-0x1B][0m; if (v < std::numeric_limits<T>::max()) {; [NON-XML-CHAR-0x1B][0;1;32m ~ ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~; [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][1m/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx:9:29: [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][0;1;30mnote: [NON-XML-CHAR-0x1B][0min instantiation of function template specialization 'ROOT::FromHumanReadableSize<long long>' requested here[NON-XML-CHAR-0x1B][0m; auto parseResult = ROOT::FromHumanReadableSize(input,res);; [NON-XML-CHAR-0x1B][0;1;32m ^; [NON-XML-CHAR-0x1B][0m1 warning generated. -- END TEST ERROR --; CMake Error at /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/root/cmake/modules/RootTestDriver.cmake:179 (message):; Unexpected error output",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4257
https://github.com/root-project/root/pull/4257:4172,Availability,error,error,4172,"5.79821e+10 vs 57.9821GiB and 54GB; Checking 8.90604e+13 vs 89.0604TiB and 81TB; Checking 1.36797e+17 vs 136.797EiB and 121.5EB; Checking 2.1012e+20 vs 210.12ZiB and 182.25ZB; Checking 3.22744e+23 vs 322.744YiB and 273.375YB; (int) 0. -- END TEST OUTPUT --; -- BEGIN TEST ERROR --; Info in <TUnixSystem::ACLiC>: creating shared library /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core/assertHumanReadable_cxx.so; In file included from /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core/assertHumanReadable_cxx_ACLiC_dict.cxx:41:; In file included from /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx:1:; [NON-XML-CHAR-0x1B][1m/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/include/ROOT/StringConv.hxx:103:18: [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][0;1;35mwarning: [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][1mimplicit conversion from 'long long' to 'double' changes value from 9223372036854775807 to 9223372036854775808 [-Wimplicit-int-float-conversion][NON-XML-CHAR-0x1B][0m; if (v < std::numeric_limits<T>::max()) {; [NON-XML-CHAR-0x1B][0;1;32m ~ ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~; [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][1m/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx:9:29: [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][0;1;30mnote: [NON-XML-CHAR-0x1B][0min instantiation of function template specialization 'ROOT::FromHumanReadableSize<long long>' requested here[NON-XML-CHAR-0x1B][0m; auto parseResult = ROOT::FromHumanReadableSize(input,res);; [NON-XML-CHAR-0x1B][0;1;32m ^; [NON-XML-CHAR-0x1B][0m1 warning generated. -- END TEST ERROR --; CMake Error at /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/root/cmake/modules/RootTestDriver.cmake:179 (message):; Unexpected error output",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4257
https://github.com/root-project/root/pull/4257:185,Deployability,patch,patches,185,"(reported by -Wimplicit-int-float-conversion). Fixing next failure (http://cdash.cern.ch/testDetails.php?test=69494934&build=706195):; -- TEST COMMAND -- ; cd /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core; /usr/bin/timeout -s USR2 270s root.exe -e '#define ClingWorkAroundMissingDynamicScope' -e '#define ClingWorkAroundUnnamedInclude' -e '#define ClingWorkAroundMissingSmartInclude' -e '#define ClingWorkAroundNoDotInclude' -e '#define ClingWorkAroundMissingAutoLoadingForTemplates' -e '#define ClingWorkAroundAutoParseUsingNamespace' -e '#define ClingWorkAroundTClassUpdateDouble32' -e '#define ClingWorkAroundAutoParseDeclaration' -e '#define ClingWorkAroundMissingUnloading' -e '#define ClingWorkAroundBrokenUnnamedReturn' -e '#define ClingWorkAroundUnnamedDetection2' -e 'gSystem->SetBuildDir(""/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"",true)' -e 'gSystem->AddDynamicPath(""/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"")' -e 'gROOT->SetMacroPath(""/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core"")' -e 'gInterpreter->AddIncludePath(""-I/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"")' -e 'gSystem->AddIncludePath(""-I/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"")' -q -l -b /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx+; -- BEGIN TEST OUTPUT --. Processing /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx+...; Checking FromHumanReadableSize; Checking ToHumanReadableSize; Checking 1024 vs 1.024KiB an 1KB; Checking 2097152 vs 2.09715MiB an 2MB; Checking 4294967296 vs 4.29497GiB an 4GB; Checking 8796093022208 vs 8.7960",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4257
https://github.com/root-project/root/pull/4257:881,Deployability,patch,patches,881,"(reported by -Wimplicit-int-float-conversion). Fixing next failure (http://cdash.cern.ch/testDetails.php?test=69494934&build=706195):; -- TEST COMMAND -- ; cd /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core; /usr/bin/timeout -s USR2 270s root.exe -e '#define ClingWorkAroundMissingDynamicScope' -e '#define ClingWorkAroundUnnamedInclude' -e '#define ClingWorkAroundMissingSmartInclude' -e '#define ClingWorkAroundNoDotInclude' -e '#define ClingWorkAroundMissingAutoLoadingForTemplates' -e '#define ClingWorkAroundAutoParseUsingNamespace' -e '#define ClingWorkAroundTClassUpdateDouble32' -e '#define ClingWorkAroundAutoParseDeclaration' -e '#define ClingWorkAroundMissingUnloading' -e '#define ClingWorkAroundBrokenUnnamedReturn' -e '#define ClingWorkAroundUnnamedDetection2' -e 'gSystem->SetBuildDir(""/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"",true)' -e 'gSystem->AddDynamicPath(""/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"")' -e 'gROOT->SetMacroPath(""/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core"")' -e 'gInterpreter->AddIncludePath(""-I/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"")' -e 'gSystem->AddIncludePath(""-I/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"")' -q -l -b /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx+; -- BEGIN TEST OUTPUT --. Processing /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx+...; Checking FromHumanReadableSize; Checking ToHumanReadableSize; Checking 1024 vs 1.024KiB an 1KB; Checking 2097152 vs 2.09715MiB an 2MB; Checking 4294967296 vs 4.29497GiB an 4GB; Checking 8796093022208 vs 8.7960",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4257
https://github.com/root-project/root/pull/4257:1020,Deployability,patch,patches,1020,"(reported by -Wimplicit-int-float-conversion). Fixing next failure (http://cdash.cern.ch/testDetails.php?test=69494934&build=706195):; -- TEST COMMAND -- ; cd /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core; /usr/bin/timeout -s USR2 270s root.exe -e '#define ClingWorkAroundMissingDynamicScope' -e '#define ClingWorkAroundUnnamedInclude' -e '#define ClingWorkAroundMissingSmartInclude' -e '#define ClingWorkAroundNoDotInclude' -e '#define ClingWorkAroundMissingAutoLoadingForTemplates' -e '#define ClingWorkAroundAutoParseUsingNamespace' -e '#define ClingWorkAroundTClassUpdateDouble32' -e '#define ClingWorkAroundAutoParseDeclaration' -e '#define ClingWorkAroundMissingUnloading' -e '#define ClingWorkAroundBrokenUnnamedReturn' -e '#define ClingWorkAroundUnnamedDetection2' -e 'gSystem->SetBuildDir(""/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"",true)' -e 'gSystem->AddDynamicPath(""/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"")' -e 'gROOT->SetMacroPath(""/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core"")' -e 'gInterpreter->AddIncludePath(""-I/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"")' -e 'gSystem->AddIncludePath(""-I/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"")' -q -l -b /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx+; -- BEGIN TEST OUTPUT --. Processing /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx+...; Checking FromHumanReadableSize; Checking ToHumanReadableSize; Checking 1024 vs 1.024KiB an 1KB; Checking 2097152 vs 2.09715MiB an 2MB; Checking 4294967296 vs 4.29497GiB an 4GB; Checking 8796093022208 vs 8.7960",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4257
https://github.com/root-project/root/pull/4257:1150,Deployability,patch,patches,1150,"(reported by -Wimplicit-int-float-conversion). Fixing next failure (http://cdash.cern.ch/testDetails.php?test=69494934&build=706195):; -- TEST COMMAND -- ; cd /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core; /usr/bin/timeout -s USR2 270s root.exe -e '#define ClingWorkAroundMissingDynamicScope' -e '#define ClingWorkAroundUnnamedInclude' -e '#define ClingWorkAroundMissingSmartInclude' -e '#define ClingWorkAroundNoDotInclude' -e '#define ClingWorkAroundMissingAutoLoadingForTemplates' -e '#define ClingWorkAroundAutoParseUsingNamespace' -e '#define ClingWorkAroundTClassUpdateDouble32' -e '#define ClingWorkAroundAutoParseDeclaration' -e '#define ClingWorkAroundMissingUnloading' -e '#define ClingWorkAroundBrokenUnnamedReturn' -e '#define ClingWorkAroundUnnamedDetection2' -e 'gSystem->SetBuildDir(""/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"",true)' -e 'gSystem->AddDynamicPath(""/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"")' -e 'gROOT->SetMacroPath(""/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core"")' -e 'gInterpreter->AddIncludePath(""-I/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"")' -e 'gSystem->AddIncludePath(""-I/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"")' -q -l -b /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx+; -- BEGIN TEST OUTPUT --. Processing /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx+...; Checking FromHumanReadableSize; Checking ToHumanReadableSize; Checking 1024 vs 1.024KiB an 1KB; Checking 2097152 vs 2.09715MiB an 2MB; Checking 4294967296 vs 4.29497GiB an 4GB; Checking 8796093022208 vs 8.7960",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4257
https://github.com/root-project/root/pull/4257:1285,Deployability,patch,patches,1285,"(reported by -Wimplicit-int-float-conversion). Fixing next failure (http://cdash.cern.ch/testDetails.php?test=69494934&build=706195):; -- TEST COMMAND -- ; cd /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core; /usr/bin/timeout -s USR2 270s root.exe -e '#define ClingWorkAroundMissingDynamicScope' -e '#define ClingWorkAroundUnnamedInclude' -e '#define ClingWorkAroundMissingSmartInclude' -e '#define ClingWorkAroundNoDotInclude' -e '#define ClingWorkAroundMissingAutoLoadingForTemplates' -e '#define ClingWorkAroundAutoParseUsingNamespace' -e '#define ClingWorkAroundTClassUpdateDouble32' -e '#define ClingWorkAroundAutoParseDeclaration' -e '#define ClingWorkAroundMissingUnloading' -e '#define ClingWorkAroundBrokenUnnamedReturn' -e '#define ClingWorkAroundUnnamedDetection2' -e 'gSystem->SetBuildDir(""/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"",true)' -e 'gSystem->AddDynamicPath(""/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"")' -e 'gROOT->SetMacroPath(""/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core"")' -e 'gInterpreter->AddIncludePath(""-I/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"")' -e 'gSystem->AddIncludePath(""-I/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"")' -q -l -b /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx+; -- BEGIN TEST OUTPUT --. Processing /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx+...; Checking FromHumanReadableSize; Checking ToHumanReadableSize; Checking 1024 vs 1.024KiB an 1KB; Checking 2097152 vs 2.09715MiB an 2MB; Checking 4294967296 vs 4.29497GiB an 4GB; Checking 8796093022208 vs 8.7960",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4257
https://github.com/root-project/root/pull/4257:1421,Deployability,patch,patches,1421,"(reported by -Wimplicit-int-float-conversion). Fixing next failure (http://cdash.cern.ch/testDetails.php?test=69494934&build=706195):; -- TEST COMMAND -- ; cd /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core; /usr/bin/timeout -s USR2 270s root.exe -e '#define ClingWorkAroundMissingDynamicScope' -e '#define ClingWorkAroundUnnamedInclude' -e '#define ClingWorkAroundMissingSmartInclude' -e '#define ClingWorkAroundNoDotInclude' -e '#define ClingWorkAroundMissingAutoLoadingForTemplates' -e '#define ClingWorkAroundAutoParseUsingNamespace' -e '#define ClingWorkAroundTClassUpdateDouble32' -e '#define ClingWorkAroundAutoParseDeclaration' -e '#define ClingWorkAroundMissingUnloading' -e '#define ClingWorkAroundBrokenUnnamedReturn' -e '#define ClingWorkAroundUnnamedDetection2' -e 'gSystem->SetBuildDir(""/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"",true)' -e 'gSystem->AddDynamicPath(""/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"")' -e 'gROOT->SetMacroPath(""/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core"")' -e 'gInterpreter->AddIncludePath(""-I/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"")' -e 'gSystem->AddIncludePath(""-I/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"")' -q -l -b /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx+; -- BEGIN TEST OUTPUT --. Processing /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx+...; Checking FromHumanReadableSize; Checking ToHumanReadableSize; Checking 1024 vs 1.024KiB an 1KB; Checking 2097152 vs 2.09715MiB an 2MB; Checking 4294967296 vs 4.29497GiB an 4GB; Checking 8796093022208 vs 8.7960",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4257
https://github.com/root-project/root/pull/4257:1535,Deployability,patch,patches,1535,"(reported by -Wimplicit-int-float-conversion). Fixing next failure (http://cdash.cern.ch/testDetails.php?test=69494934&build=706195):; -- TEST COMMAND -- ; cd /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core; /usr/bin/timeout -s USR2 270s root.exe -e '#define ClingWorkAroundMissingDynamicScope' -e '#define ClingWorkAroundUnnamedInclude' -e '#define ClingWorkAroundMissingSmartInclude' -e '#define ClingWorkAroundNoDotInclude' -e '#define ClingWorkAroundMissingAutoLoadingForTemplates' -e '#define ClingWorkAroundAutoParseUsingNamespace' -e '#define ClingWorkAroundTClassUpdateDouble32' -e '#define ClingWorkAroundAutoParseDeclaration' -e '#define ClingWorkAroundMissingUnloading' -e '#define ClingWorkAroundBrokenUnnamedReturn' -e '#define ClingWorkAroundUnnamedDetection2' -e 'gSystem->SetBuildDir(""/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"",true)' -e 'gSystem->AddDynamicPath(""/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"")' -e 'gROOT->SetMacroPath(""/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core"")' -e 'gInterpreter->AddIncludePath(""-I/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"")' -e 'gSystem->AddIncludePath(""-I/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"")' -q -l -b /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx+; -- BEGIN TEST OUTPUT --. Processing /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx+...; Checking FromHumanReadableSize; Checking ToHumanReadableSize; Checking 1024 vs 1.024KiB an 1KB; Checking 2097152 vs 2.09715MiB an 2MB; Checking 4294967296 vs 4.29497GiB an 4GB; Checking 8796093022208 vs 8.7960",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4257
https://github.com/root-project/root/pull/4257:1693,Deployability,patch,patches,1693,"ssingUnloading' -e '#define ClingWorkAroundBrokenUnnamedReturn' -e '#define ClingWorkAroundUnnamedDetection2' -e 'gSystem->SetBuildDir(""/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"",true)' -e 'gSystem->AddDynamicPath(""/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"")' -e 'gROOT->SetMacroPath(""/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core"")' -e 'gInterpreter->AddIncludePath(""-I/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"")' -e 'gSystem->AddIncludePath(""-I/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"")' -q -l -b /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx+; -- BEGIN TEST OUTPUT --. Processing /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx+...; Checking FromHumanReadableSize; Checking ToHumanReadableSize; Checking 1024 vs 1.024KiB an 1KB; Checking 2097152 vs 2.09715MiB an 2MB; Checking 4294967296 vs 4.29497GiB an 4GB; Checking 8796093022208 vs 8.79609TiB an 8TB; Checking 18014398509481984 vs 18.0144EiB an 16EB; Checking 16 vs 16B and 16B; Checking 24576 vs 24.576KiB and 24KB; Checking 3.77487e+07 vs 37.7487MiB and 36MB; Checking 5.79821e+10 vs 57.9821GiB and 54GB; Checking 8.90604e+13 vs 89.0604TiB and 81TB; Checking 1.36797e+17 vs 136.797EiB and 121.5EB; Checking 2.1012e+20 vs 210.12ZiB and 182.25ZB; Checking 3.22744e+23 vs 322.744YiB and 273.375YB; (int) 0. -- END TEST OUTPUT --; -- BEGIN TEST ERROR --; Info in <TUnixSystem::ACLiC>: creating shared library /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core/assertHumanReadable_cxx.so; In file included from /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ub",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4257
https://github.com/root-project/root/pull/4257:2546,Deployability,patch,patches,2546,00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx+; -- BEGIN TEST OUTPUT --. Processing /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx+...; Checking FromHumanReadableSize; Checking ToHumanReadableSize; Checking 1024 vs 1.024KiB an 1KB; Checking 2097152 vs 2.09715MiB an 2MB; Checking 4294967296 vs 4.29497GiB an 4GB; Checking 8796093022208 vs 8.79609TiB an 8TB; Checking 18014398509481984 vs 18.0144EiB an 16EB; Checking 16 vs 16B and 16B; Checking 24576 vs 24.576KiB and 24KB; Checking 3.77487e+07 vs 37.7487MiB and 36MB; Checking 5.79821e+10 vs 57.9821GiB and 54GB; Checking 8.90604e+13 vs 89.0604TiB and 81TB; Checking 1.36797e+17 vs 136.797EiB and 121.5EB; Checking 2.1012e+20 vs 210.12ZiB and 182.25ZB; Checking 3.22744e+23 vs 322.744YiB and 273.375YB; (int) 0. -- END TEST OUTPUT --; -- BEGIN TEST ERROR --; Info in <TUnixSystem::ACLiC>: creating shared library /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core/assertHumanReadable_cxx.so; In file included from /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core/assertHumanReadable_cxx_ACLiC_dict.cxx:41:; In file included from /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx:1:; [NON-XML-CHAR-0x1B][1m/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/include/ROOT/StringConv.hxx:103:18: [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][0;1;35mwarning: [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][1mimplicit conversion from 'long long' to 'double' changes value from 9223372036854775807 to 9223372036854775808 [-Wimplicit-int-float-conversion][NON-XML-CHAR-0x1B][0m; if (v < std::numeric_limits<T>::max()) {; [NON-XML-CHAR-0x1B][0;1;32m ~ ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~; [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][1m/mnt/build,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4257
https://github.com/root-project/root/pull/4257:2698,Deployability,patch,patches,2698,gHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx+...; Checking FromHumanReadableSize; Checking ToHumanReadableSize; Checking 1024 vs 1.024KiB an 1KB; Checking 2097152 vs 2.09715MiB an 2MB; Checking 4294967296 vs 4.29497GiB an 4GB; Checking 8796093022208 vs 8.79609TiB an 8TB; Checking 18014398509481984 vs 18.0144EiB an 16EB; Checking 16 vs 16B and 16B; Checking 24576 vs 24.576KiB and 24KB; Checking 3.77487e+07 vs 37.7487MiB and 36MB; Checking 5.79821e+10 vs 57.9821GiB and 54GB; Checking 8.90604e+13 vs 89.0604TiB and 81TB; Checking 1.36797e+17 vs 136.797EiB and 121.5EB; Checking 2.1012e+20 vs 210.12ZiB and 182.25ZB; Checking 3.22744e+23 vs 322.744YiB and 273.375YB; (int) 0. -- END TEST OUTPUT --; -- BEGIN TEST ERROR --; Info in <TUnixSystem::ACLiC>: creating shared library /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core/assertHumanReadable_cxx.so; In file included from /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core/assertHumanReadable_cxx_ACLiC_dict.cxx:41:; In file included from /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx:1:; [NON-XML-CHAR-0x1B][1m/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/include/ROOT/StringConv.hxx:103:18: [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][0;1;35mwarning: [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][1mimplicit conversion from 'long long' to 'double' changes value from 9223372036854775807 to 9223372036854775808 [-Wimplicit-int-float-conversion][NON-XML-CHAR-0x1B][0m; if (v < std::numeric_limits<T>::max()) {; [NON-XML-CHAR-0x1B][0;1;32m ~ ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~; [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][1m/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx:9:29: [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][0;1;30mnote: [NON-XML-CHAR-0x1B][0min ,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4257
https://github.com/root-project/root/pull/4257:2866,Deployability,patch,patches,2866, 1KB; Checking 2097152 vs 2.09715MiB an 2MB; Checking 4294967296 vs 4.29497GiB an 4GB; Checking 8796093022208 vs 8.79609TiB an 8TB; Checking 18014398509481984 vs 18.0144EiB an 16EB; Checking 16 vs 16B and 16B; Checking 24576 vs 24.576KiB and 24KB; Checking 3.77487e+07 vs 37.7487MiB and 36MB; Checking 5.79821e+10 vs 57.9821GiB and 54GB; Checking 8.90604e+13 vs 89.0604TiB and 81TB; Checking 1.36797e+17 vs 136.797EiB and 121.5EB; Checking 2.1012e+20 vs 210.12ZiB and 182.25ZB; Checking 3.22744e+23 vs 322.744YiB and 273.375YB; (int) 0. -- END TEST OUTPUT --; -- BEGIN TEST ERROR --; Info in <TUnixSystem::ACLiC>: creating shared library /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core/assertHumanReadable_cxx.so; In file included from /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core/assertHumanReadable_cxx_ACLiC_dict.cxx:41:; In file included from /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx:1:; [NON-XML-CHAR-0x1B][1m/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/include/ROOT/StringConv.hxx:103:18: [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][0;1;35mwarning: [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][1mimplicit conversion from 'long long' to 'double' changes value from 9223372036854775807 to 9223372036854775808 [-Wimplicit-int-float-conversion][NON-XML-CHAR-0x1B][0m; if (v < std::numeric_limits<T>::max()) {; [NON-XML-CHAR-0x1B][0;1;32m ~ ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~; [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][1m/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx:9:29: [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][0;1;30mnote: [NON-XML-CHAR-0x1B][0min instantiation of function template specialization 'ROOT::FromHumanReadableSize<long long>' requested here[NON-XML-CHAR-0x1B][0m; auto parseResult = ROOT::F,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4257
https://github.com/root-project/root/pull/4257:3012,Deployability,patch,patches,3012,"8014398509481984 vs 18.0144EiB an 16EB; Checking 16 vs 16B and 16B; Checking 24576 vs 24.576KiB and 24KB; Checking 3.77487e+07 vs 37.7487MiB and 36MB; Checking 5.79821e+10 vs 57.9821GiB and 54GB; Checking 8.90604e+13 vs 89.0604TiB and 81TB; Checking 1.36797e+17 vs 136.797EiB and 121.5EB; Checking 2.1012e+20 vs 210.12ZiB and 182.25ZB; Checking 3.22744e+23 vs 322.744YiB and 273.375YB; (int) 0. -- END TEST OUTPUT --; -- BEGIN TEST ERROR --; Info in <TUnixSystem::ACLiC>: creating shared library /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core/assertHumanReadable_cxx.so; In file included from /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core/assertHumanReadable_cxx_ACLiC_dict.cxx:41:; In file included from /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx:1:; [NON-XML-CHAR-0x1B][1m/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/include/ROOT/StringConv.hxx:103:18: [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][0;1;35mwarning: [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][1mimplicit conversion from 'long long' to 'double' changes value from 9223372036854775807 to 9223372036854775808 [-Wimplicit-int-float-conversion][NON-XML-CHAR-0x1B][0m; if (v < std::numeric_limits<T>::max()) {; [NON-XML-CHAR-0x1B][0;1;32m ~ ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~; [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][1m/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx:9:29: [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][0;1;30mnote: [NON-XML-CHAR-0x1B][0min instantiation of function template specialization 'ROOT::FromHumanReadableSize<long long>' requested here[NON-XML-CHAR-0x1B][0m; auto parseResult = ROOT::FromHumanReadableSize(input,res);; [NON-XML-CHAR-0x1B][0;1;32m ^; [NON-XML-CHAR-0x1B][0m1 warning generated. -- END TEST ERROR --; CMake Error ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4257
https://github.com/root-project/root/pull/4257:3548,Deployability,patch,patches,3548,"5.79821e+10 vs 57.9821GiB and 54GB; Checking 8.90604e+13 vs 89.0604TiB and 81TB; Checking 1.36797e+17 vs 136.797EiB and 121.5EB; Checking 2.1012e+20 vs 210.12ZiB and 182.25ZB; Checking 3.22744e+23 vs 322.744YiB and 273.375YB; (int) 0. -- END TEST OUTPUT --; -- BEGIN TEST ERROR --; Info in <TUnixSystem::ACLiC>: creating shared library /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core/assertHumanReadable_cxx.so; In file included from /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core/assertHumanReadable_cxx_ACLiC_dict.cxx:41:; In file included from /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx:1:; [NON-XML-CHAR-0x1B][1m/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/include/ROOT/StringConv.hxx:103:18: [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][0;1;35mwarning: [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][1mimplicit conversion from 'long long' to 'double' changes value from 9223372036854775807 to 9223372036854775808 [-Wimplicit-int-float-conversion][NON-XML-CHAR-0x1B][0m; if (v < std::numeric_limits<T>::max()) {; [NON-XML-CHAR-0x1B][0;1;32m ~ ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~; [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][1m/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx:9:29: [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][0;1;30mnote: [NON-XML-CHAR-0x1B][0min instantiation of function template specialization 'ROOT::FromHumanReadableSize<long long>' requested here[NON-XML-CHAR-0x1B][0m; auto parseResult = ROOT::FromHumanReadableSize(input,res);; [NON-XML-CHAR-0x1B][0;1;32m ^; [NON-XML-CHAR-0x1B][0m1 warning generated. -- END TEST ERROR --; CMake Error at /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/root/cmake/modules/RootTestDriver.cmake:179 (message):; Unexpected error output",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4257
https://github.com/root-project/root/pull/4257:4054,Deployability,patch,patches,4054,"5.79821e+10 vs 57.9821GiB and 54GB; Checking 8.90604e+13 vs 89.0604TiB and 81TB; Checking 1.36797e+17 vs 136.797EiB and 121.5EB; Checking 2.1012e+20 vs 210.12ZiB and 182.25ZB; Checking 3.22744e+23 vs 322.744YiB and 273.375YB; (int) 0. -- END TEST OUTPUT --; -- BEGIN TEST ERROR --; Info in <TUnixSystem::ACLiC>: creating shared library /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core/assertHumanReadable_cxx.so; In file included from /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core/assertHumanReadable_cxx_ACLiC_dict.cxx:41:; In file included from /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx:1:; [NON-XML-CHAR-0x1B][1m/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/include/ROOT/StringConv.hxx:103:18: [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][0;1;35mwarning: [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][1mimplicit conversion from 'long long' to 'double' changes value from 9223372036854775807 to 9223372036854775808 [-Wimplicit-int-float-conversion][NON-XML-CHAR-0x1B][0m; if (v < std::numeric_limits<T>::max()) {; [NON-XML-CHAR-0x1B][0;1;32m ~ ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~; [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][1m/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx:9:29: [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][0;1;30mnote: [NON-XML-CHAR-0x1B][0min instantiation of function template specialization 'ROOT::FromHumanReadableSize<long long>' requested here[NON-XML-CHAR-0x1B][0m; auto parseResult = ROOT::FromHumanReadableSize(input,res);; [NON-XML-CHAR-0x1B][0;1;32m ^; [NON-XML-CHAR-0x1B][0m1 warning generated. -- END TEST ERROR --; CMake Error at /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/root/cmake/modules/RootTestDriver.cmake:179 (message):; Unexpected error output",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4257
https://github.com/root-project/root/pull/4257:4150,Integrability,message,message,4150,"5.79821e+10 vs 57.9821GiB and 54GB; Checking 8.90604e+13 vs 89.0604TiB and 81TB; Checking 1.36797e+17 vs 136.797EiB and 121.5EB; Checking 2.1012e+20 vs 210.12ZiB and 182.25ZB; Checking 3.22744e+23 vs 322.744YiB and 273.375YB; (int) 0. -- END TEST OUTPUT --; -- BEGIN TEST ERROR --; Info in <TUnixSystem::ACLiC>: creating shared library /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core/assertHumanReadable_cxx.so; In file included from /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core/assertHumanReadable_cxx_ACLiC_dict.cxx:41:; In file included from /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx:1:; [NON-XML-CHAR-0x1B][1m/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/include/ROOT/StringConv.hxx:103:18: [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][0;1;35mwarning: [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][1mimplicit conversion from 'long long' to 'double' changes value from 9223372036854775807 to 9223372036854775808 [-Wimplicit-int-float-conversion][NON-XML-CHAR-0x1B][0m; if (v < std::numeric_limits<T>::max()) {; [NON-XML-CHAR-0x1B][0;1;32m ~ ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~; [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][1m/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx:9:29: [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][0;1;30mnote: [NON-XML-CHAR-0x1B][0min instantiation of function template specialization 'ROOT::FromHumanReadableSize<long long>' requested here[NON-XML-CHAR-0x1B][0m; auto parseResult = ROOT::FromHumanReadableSize(input,res);; [NON-XML-CHAR-0x1B][0;1;32m ^; [NON-XML-CHAR-0x1B][0m1 warning generated. -- END TEST ERROR --; CMake Error at /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/root/cmake/modules/RootTestDriver.cmake:179 (message):; Unexpected error output",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4257
https://github.com/root-project/root/pull/4257:271,Safety,timeout,timeout,271,"(reported by -Wimplicit-int-float-conversion). Fixing next failure (http://cdash.cern.ch/testDetails.php?test=69494934&build=706195):; -- TEST COMMAND -- ; cd /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core; /usr/bin/timeout -s USR2 270s root.exe -e '#define ClingWorkAroundMissingDynamicScope' -e '#define ClingWorkAroundUnnamedInclude' -e '#define ClingWorkAroundMissingSmartInclude' -e '#define ClingWorkAroundNoDotInclude' -e '#define ClingWorkAroundMissingAutoLoadingForTemplates' -e '#define ClingWorkAroundAutoParseUsingNamespace' -e '#define ClingWorkAroundTClassUpdateDouble32' -e '#define ClingWorkAroundAutoParseDeclaration' -e '#define ClingWorkAroundMissingUnloading' -e '#define ClingWorkAroundBrokenUnnamedReturn' -e '#define ClingWorkAroundUnnamedDetection2' -e 'gSystem->SetBuildDir(""/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"",true)' -e 'gSystem->AddDynamicPath(""/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"")' -e 'gROOT->SetMacroPath(""/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core"")' -e 'gInterpreter->AddIncludePath(""-I/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"")' -e 'gSystem->AddIncludePath(""-I/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"")' -q -l -b /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx+; -- BEGIN TEST OUTPUT --. Processing /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx+...; Checking FromHumanReadableSize; Checking ToHumanReadableSize; Checking 1024 vs 1.024KiB an 1KB; Checking 2097152 vs 2.09715MiB an 2MB; Checking 4294967296 vs 4.29497GiB an 4GB; Checking 8796093022208 vs 8.7960",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4257
https://github.com/root-project/root/pull/4257:89,Testability,test,testDetails,89,"(reported by -Wimplicit-int-float-conversion). Fixing next failure (http://cdash.cern.ch/testDetails.php?test=69494934&build=706195):; -- TEST COMMAND -- ; cd /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core; /usr/bin/timeout -s USR2 270s root.exe -e '#define ClingWorkAroundMissingDynamicScope' -e '#define ClingWorkAroundUnnamedInclude' -e '#define ClingWorkAroundMissingSmartInclude' -e '#define ClingWorkAroundNoDotInclude' -e '#define ClingWorkAroundMissingAutoLoadingForTemplates' -e '#define ClingWorkAroundAutoParseUsingNamespace' -e '#define ClingWorkAroundTClassUpdateDouble32' -e '#define ClingWorkAroundAutoParseDeclaration' -e '#define ClingWorkAroundMissingUnloading' -e '#define ClingWorkAroundBrokenUnnamedReturn' -e '#define ClingWorkAroundUnnamedDetection2' -e 'gSystem->SetBuildDir(""/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"",true)' -e 'gSystem->AddDynamicPath(""/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"")' -e 'gROOT->SetMacroPath(""/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core"")' -e 'gInterpreter->AddIncludePath(""-I/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"")' -e 'gSystem->AddIncludePath(""-I/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"")' -q -l -b /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx+; -- BEGIN TEST OUTPUT --. Processing /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx+...; Checking FromHumanReadableSize; Checking ToHumanReadableSize; Checking 1024 vs 1.024KiB an 1KB; Checking 2097152 vs 2.09715MiB an 2MB; Checking 4294967296 vs 4.29497GiB an 4GB; Checking 8796093022208 vs 8.7960",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4257
https://github.com/root-project/root/pull/4257:105,Testability,test,test,105,"(reported by -Wimplicit-int-float-conversion). Fixing next failure (http://cdash.cern.ch/testDetails.php?test=69494934&build=706195):; -- TEST COMMAND -- ; cd /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core; /usr/bin/timeout -s USR2 270s root.exe -e '#define ClingWorkAroundMissingDynamicScope' -e '#define ClingWorkAroundUnnamedInclude' -e '#define ClingWorkAroundMissingSmartInclude' -e '#define ClingWorkAroundNoDotInclude' -e '#define ClingWorkAroundMissingAutoLoadingForTemplates' -e '#define ClingWorkAroundAutoParseUsingNamespace' -e '#define ClingWorkAroundTClassUpdateDouble32' -e '#define ClingWorkAroundAutoParseDeclaration' -e '#define ClingWorkAroundMissingUnloading' -e '#define ClingWorkAroundBrokenUnnamedReturn' -e '#define ClingWorkAroundUnnamedDetection2' -e 'gSystem->SetBuildDir(""/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"",true)' -e 'gSystem->AddDynamicPath(""/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"")' -e 'gROOT->SetMacroPath(""/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core"")' -e 'gInterpreter->AddIncludePath(""-I/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"")' -e 'gSystem->AddIncludePath(""-I/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"")' -q -l -b /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx+; -- BEGIN TEST OUTPUT --. Processing /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx+...; Checking FromHumanReadableSize; Checking ToHumanReadableSize; Checking 1024 vs 1.024KiB an 1KB; Checking 2097152 vs 2.09715MiB an 2MB; Checking 4294967296 vs 4.29497GiB an 4GB; Checking 8796093022208 vs 8.7960",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4257
https://github.com/root-project/root/pull/4257:138,Testability,TEST,TEST,138,"(reported by -Wimplicit-int-float-conversion). Fixing next failure (http://cdash.cern.ch/testDetails.php?test=69494934&build=706195):; -- TEST COMMAND -- ; cd /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core; /usr/bin/timeout -s USR2 270s root.exe -e '#define ClingWorkAroundMissingDynamicScope' -e '#define ClingWorkAroundUnnamedInclude' -e '#define ClingWorkAroundMissingSmartInclude' -e '#define ClingWorkAroundNoDotInclude' -e '#define ClingWorkAroundMissingAutoLoadingForTemplates' -e '#define ClingWorkAroundAutoParseUsingNamespace' -e '#define ClingWorkAroundTClassUpdateDouble32' -e '#define ClingWorkAroundAutoParseDeclaration' -e '#define ClingWorkAroundMissingUnloading' -e '#define ClingWorkAroundBrokenUnnamedReturn' -e '#define ClingWorkAroundUnnamedDetection2' -e 'gSystem->SetBuildDir(""/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"",true)' -e 'gSystem->AddDynamicPath(""/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"")' -e 'gROOT->SetMacroPath(""/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core"")' -e 'gInterpreter->AddIncludePath(""-I/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"")' -e 'gSystem->AddIncludePath(""-I/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"")' -q -l -b /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx+; -- BEGIN TEST OUTPUT --. Processing /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx+...; Checking FromHumanReadableSize; Checking ToHumanReadableSize; Checking 1024 vs 1.024KiB an 1KB; Checking 2097152 vs 2.09715MiB an 2MB; Checking 4294967296 vs 4.29497GiB an 4GB; Checking 8796093022208 vs 8.7960",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4257
https://github.com/root-project/root/pull/4257:1605,Testability,assert,assertHumanReadable,1605,"(reported by -Wimplicit-int-float-conversion). Fixing next failure (http://cdash.cern.ch/testDetails.php?test=69494934&build=706195):; -- TEST COMMAND -- ; cd /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core; /usr/bin/timeout -s USR2 270s root.exe -e '#define ClingWorkAroundMissingDynamicScope' -e '#define ClingWorkAroundUnnamedInclude' -e '#define ClingWorkAroundMissingSmartInclude' -e '#define ClingWorkAroundNoDotInclude' -e '#define ClingWorkAroundMissingAutoLoadingForTemplates' -e '#define ClingWorkAroundAutoParseUsingNamespace' -e '#define ClingWorkAroundTClassUpdateDouble32' -e '#define ClingWorkAroundAutoParseDeclaration' -e '#define ClingWorkAroundMissingUnloading' -e '#define ClingWorkAroundBrokenUnnamedReturn' -e '#define ClingWorkAroundUnnamedDetection2' -e 'gSystem->SetBuildDir(""/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"",true)' -e 'gSystem->AddDynamicPath(""/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"")' -e 'gROOT->SetMacroPath(""/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core"")' -e 'gInterpreter->AddIncludePath(""-I/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"")' -e 'gSystem->AddIncludePath(""-I/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"")' -q -l -b /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx+; -- BEGIN TEST OUTPUT --. Processing /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx+...; Checking FromHumanReadableSize; Checking ToHumanReadableSize; Checking 1024 vs 1.024KiB an 1KB; Checking 2097152 vs 2.09715MiB an 2MB; Checking 4294967296 vs 4.29497GiB an 4GB; Checking 8796093022208 vs 8.7960",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4257
https://github.com/root-project/root/pull/4257:1640,Testability,TEST,TEST,1640," -e '#define ClingWorkAroundAutoParseDeclaration' -e '#define ClingWorkAroundMissingUnloading' -e '#define ClingWorkAroundBrokenUnnamedReturn' -e '#define ClingWorkAroundUnnamedDetection2' -e 'gSystem->SetBuildDir(""/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"",true)' -e 'gSystem->AddDynamicPath(""/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"")' -e 'gROOT->SetMacroPath(""/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core"")' -e 'gInterpreter->AddIncludePath(""-I/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"")' -e 'gSystem->AddIncludePath(""-I/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"")' -q -l -b /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx+; -- BEGIN TEST OUTPUT --. Processing /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx+...; Checking FromHumanReadableSize; Checking ToHumanReadableSize; Checking 1024 vs 1.024KiB an 1KB; Checking 2097152 vs 2.09715MiB an 2MB; Checking 4294967296 vs 4.29497GiB an 4GB; Checking 8796093022208 vs 8.79609TiB an 8TB; Checking 18014398509481984 vs 18.0144EiB an 16EB; Checking 16 vs 16B and 16B; Checking 24576 vs 24.576KiB and 24KB; Checking 3.77487e+07 vs 37.7487MiB and 36MB; Checking 5.79821e+10 vs 57.9821GiB and 54GB; Checking 8.90604e+13 vs 89.0604TiB and 81TB; Checking 1.36797e+17 vs 136.797EiB and 121.5EB; Checking 2.1012e+20 vs 210.12ZiB and 182.25ZB; Checking 3.22744e+23 vs 322.744YiB and 273.375YB; (int) 0. -- END TEST OUTPUT --; -- BEGIN TEST ERROR --; Info in <TUnixSystem::ACLiC>: creating shared library /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core/assertHumanReadabl",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4257
https://github.com/root-project/root/pull/4257:1763,Testability,assert,assertHumanReadable,1763,"ssingUnloading' -e '#define ClingWorkAroundBrokenUnnamedReturn' -e '#define ClingWorkAroundUnnamedDetection2' -e 'gSystem->SetBuildDir(""/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"",true)' -e 'gSystem->AddDynamicPath(""/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"")' -e 'gROOT->SetMacroPath(""/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core"")' -e 'gInterpreter->AddIncludePath(""-I/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"")' -e 'gSystem->AddIncludePath(""-I/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core"")' -q -l -b /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx+; -- BEGIN TEST OUTPUT --. Processing /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx+...; Checking FromHumanReadableSize; Checking ToHumanReadableSize; Checking 1024 vs 1.024KiB an 1KB; Checking 2097152 vs 2.09715MiB an 2MB; Checking 4294967296 vs 4.29497GiB an 4GB; Checking 8796093022208 vs 8.79609TiB an 8TB; Checking 18014398509481984 vs 18.0144EiB an 16EB; Checking 16 vs 16B and 16B; Checking 24576 vs 24.576KiB and 24KB; Checking 3.77487e+07 vs 37.7487MiB and 36MB; Checking 5.79821e+10 vs 57.9821GiB and 54GB; Checking 8.90604e+13 vs 89.0604TiB and 81TB; Checking 1.36797e+17 vs 136.797EiB and 121.5EB; Checking 2.1012e+20 vs 210.12ZiB and 182.25ZB; Checking 3.22744e+23 vs 322.744YiB and 273.375YB; (int) 0. -- END TEST OUTPUT --; -- BEGIN TEST ERROR --; Info in <TUnixSystem::ACLiC>: creating shared library /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core/assertHumanReadable_cxx.so; In file included from /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ub",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4257
https://github.com/root-project/root/pull/4257:2426,Testability,TEST,TEST,2426,00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx+; -- BEGIN TEST OUTPUT --. Processing /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx+...; Checking FromHumanReadableSize; Checking ToHumanReadableSize; Checking 1024 vs 1.024KiB an 1KB; Checking 2097152 vs 2.09715MiB an 2MB; Checking 4294967296 vs 4.29497GiB an 4GB; Checking 8796093022208 vs 8.79609TiB an 8TB; Checking 18014398509481984 vs 18.0144EiB an 16EB; Checking 16 vs 16B and 16B; Checking 24576 vs 24.576KiB and 24KB; Checking 3.77487e+07 vs 37.7487MiB and 36MB; Checking 5.79821e+10 vs 57.9821GiB and 54GB; Checking 8.90604e+13 vs 89.0604TiB and 81TB; Checking 1.36797e+17 vs 136.797EiB and 121.5EB; Checking 2.1012e+20 vs 210.12ZiB and 182.25ZB; Checking 3.22744e+23 vs 322.744YiB and 273.375YB; (int) 0. -- END TEST OUTPUT --; -- BEGIN TEST ERROR --; Info in <TUnixSystem::ACLiC>: creating shared library /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core/assertHumanReadable_cxx.so; In file included from /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core/assertHumanReadable_cxx_ACLiC_dict.cxx:41:; In file included from /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx:1:; [NON-XML-CHAR-0x1B][1m/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/include/ROOT/StringConv.hxx:103:18: [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][0;1;35mwarning: [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][1mimplicit conversion from 'long long' to 'double' changes value from 9223372036854775807 to 9223372036854775808 [-Wimplicit-int-float-conversion][NON-XML-CHAR-0x1B][0m; if (v < std::numeric_limits<T>::max()) {; [NON-XML-CHAR-0x1B][0;1;32m ~ ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~; [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][1m/mnt/build,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4257
https://github.com/root-project/root/pull/4257:2451,Testability,TEST,TEST,2451,00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx+; -- BEGIN TEST OUTPUT --. Processing /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx+...; Checking FromHumanReadableSize; Checking ToHumanReadableSize; Checking 1024 vs 1.024KiB an 1KB; Checking 2097152 vs 2.09715MiB an 2MB; Checking 4294967296 vs 4.29497GiB an 4GB; Checking 8796093022208 vs 8.79609TiB an 8TB; Checking 18014398509481984 vs 18.0144EiB an 16EB; Checking 16 vs 16B and 16B; Checking 24576 vs 24.576KiB and 24KB; Checking 3.77487e+07 vs 37.7487MiB and 36MB; Checking 5.79821e+10 vs 57.9821GiB and 54GB; Checking 8.90604e+13 vs 89.0604TiB and 81TB; Checking 1.36797e+17 vs 136.797EiB and 121.5EB; Checking 2.1012e+20 vs 210.12ZiB and 182.25ZB; Checking 3.22744e+23 vs 322.744YiB and 273.375YB; (int) 0. -- END TEST OUTPUT --; -- BEGIN TEST ERROR --; Info in <TUnixSystem::ACLiC>: creating shared library /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core/assertHumanReadable_cxx.so; In file included from /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core/assertHumanReadable_cxx_ACLiC_dict.cxx:41:; In file included from /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx:1:; [NON-XML-CHAR-0x1B][1m/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/include/ROOT/StringConv.hxx:103:18: [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][0;1;35mwarning: [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][1mimplicit conversion from 'long long' to 'double' changes value from 9223372036854775807 to 9223372036854775808 [-Wimplicit-int-float-conversion][NON-XML-CHAR-0x1B][0m; if (v < std::numeric_limits<T>::max()) {; [NON-XML-CHAR-0x1B][0;1;32m ~ ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~; [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][1m/mnt/build,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4257
https://github.com/root-project/root/pull/4257:2936,Testability,assert,assertHumanReadable,2936, 1KB; Checking 2097152 vs 2.09715MiB an 2MB; Checking 4294967296 vs 4.29497GiB an 4GB; Checking 8796093022208 vs 8.79609TiB an 8TB; Checking 18014398509481984 vs 18.0144EiB an 16EB; Checking 16 vs 16B and 16B; Checking 24576 vs 24.576KiB and 24KB; Checking 3.77487e+07 vs 37.7487MiB and 36MB; Checking 5.79821e+10 vs 57.9821GiB and 54GB; Checking 8.90604e+13 vs 89.0604TiB and 81TB; Checking 1.36797e+17 vs 136.797EiB and 121.5EB; Checking 2.1012e+20 vs 210.12ZiB and 182.25ZB; Checking 3.22744e+23 vs 322.744YiB and 273.375YB; (int) 0. -- END TEST OUTPUT --; -- BEGIN TEST ERROR --; Info in <TUnixSystem::ACLiC>: creating shared library /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core/assertHumanReadable_cxx.so; In file included from /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core/assertHumanReadable_cxx_ACLiC_dict.cxx:41:; In file included from /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx:1:; [NON-XML-CHAR-0x1B][1m/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/include/ROOT/StringConv.hxx:103:18: [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][0;1;35mwarning: [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][1mimplicit conversion from 'long long' to 'double' changes value from 9223372036854775807 to 9223372036854775808 [-Wimplicit-int-float-conversion][NON-XML-CHAR-0x1B][0m; if (v < std::numeric_limits<T>::max()) {; [NON-XML-CHAR-0x1B][0;1;32m ~ ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~; [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][1m/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx:9:29: [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][0;1;30mnote: [NON-XML-CHAR-0x1B][0min instantiation of function template specialization 'ROOT::FromHumanReadableSize<long long>' requested here[NON-XML-CHAR-0x1B][0m; auto parseResult = ROOT::F,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4257
https://github.com/root-project/root/pull/4257:3618,Testability,assert,assertHumanReadable,3618,"5.79821e+10 vs 57.9821GiB and 54GB; Checking 8.90604e+13 vs 89.0604TiB and 81TB; Checking 1.36797e+17 vs 136.797EiB and 121.5EB; Checking 2.1012e+20 vs 210.12ZiB and 182.25ZB; Checking 3.22744e+23 vs 322.744YiB and 273.375YB; (int) 0. -- END TEST OUTPUT --; -- BEGIN TEST ERROR --; Info in <TUnixSystem::ACLiC>: creating shared library /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core/assertHumanReadable_cxx.so; In file included from /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core/assertHumanReadable_cxx_ACLiC_dict.cxx:41:; In file included from /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx:1:; [NON-XML-CHAR-0x1B][1m/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/include/ROOT/StringConv.hxx:103:18: [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][0;1;35mwarning: [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][1mimplicit conversion from 'long long' to 'double' changes value from 9223372036854775807 to 9223372036854775808 [-Wimplicit-int-float-conversion][NON-XML-CHAR-0x1B][0m; if (v < std::numeric_limits<T>::max()) {; [NON-XML-CHAR-0x1B][0;1;32m ~ ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~; [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][1m/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx:9:29: [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][0;1;30mnote: [NON-XML-CHAR-0x1B][0min instantiation of function template specialization 'ROOT::FromHumanReadableSize<long long>' requested here[NON-XML-CHAR-0x1B][0m; auto parseResult = ROOT::FromHumanReadableSize(input,res);; [NON-XML-CHAR-0x1B][0;1;32m ^; [NON-XML-CHAR-0x1B][0m1 warning generated. -- END TEST ERROR --; CMake Error at /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/root/cmake/modules/RootTestDriver.cmake:179 (message):; Unexpected error output",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4257
https://github.com/root-project/root/pull/4257:3998,Testability,TEST,TEST,3998,"5.79821e+10 vs 57.9821GiB and 54GB; Checking 8.90604e+13 vs 89.0604TiB and 81TB; Checking 1.36797e+17 vs 136.797EiB and 121.5EB; Checking 2.1012e+20 vs 210.12ZiB and 182.25ZB; Checking 3.22744e+23 vs 322.744YiB and 273.375YB; (int) 0. -- END TEST OUTPUT --; -- BEGIN TEST ERROR --; Info in <TUnixSystem::ACLiC>: creating shared library /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core/assertHumanReadable_cxx.so; In file included from /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/roottest/root/core/assertHumanReadable_cxx_ACLiC_dict.cxx:41:; In file included from /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx:1:; [NON-XML-CHAR-0x1B][1m/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/build/include/ROOT/StringConv.hxx:103:18: [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][0;1;35mwarning: [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][1mimplicit conversion from 'long long' to 'double' changes value from 9223372036854775807 to 9223372036854775808 [-Wimplicit-int-float-conversion][NON-XML-CHAR-0x1B][0m; if (v < std::numeric_limits<T>::max()) {; [NON-XML-CHAR-0x1B][0;1;32m ~ ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~; [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][1m/mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/roottest/root/core/assertHumanReadable.cxx:9:29: [NON-XML-CHAR-0x1B][0m[NON-XML-CHAR-0x1B][0;1;30mnote: [NON-XML-CHAR-0x1B][0min instantiation of function template specialization 'ROOT::FromHumanReadableSize<long long>' requested here[NON-XML-CHAR-0x1B][0m; auto parseResult = ROOT::FromHumanReadableSize(input,res);; [NON-XML-CHAR-0x1B][0;1;32m ^; [NON-XML-CHAR-0x1B][0m1 warning generated. -- END TEST ERROR --; CMake Error at /mnt/build/wsincrv6-18-00-patches/LABEL/ROOT-ubuntu1804-clangHEAD/SPEC/noimt/root/cmake/modules/RootTestDriver.cmake:179 (message):; Unexpected error output",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4257
https://github.com/root-project/root/pull/4259:261,Availability,error,error,261,"This reverts commit 1e8c04dd4beff8fc3d34cfd21e45358e85ae0f79.; In this commit, main idea was to use clang binary to retrieve information; about resource-clang-dir. Sadly ROOT patched LLVM/Clang is built; without clang binary and ROOT CMake crash then with next error:. -- /home/oksana/CERN_sources/llvm-clang-root/inst/bin; CMake Error at core/clingutils/CMakeLists.txt:80 (message):; Cannot determine clang resource directory path",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4259
https://github.com/root-project/root/pull/4259:330,Availability,Error,Error,330,"This reverts commit 1e8c04dd4beff8fc3d34cfd21e45358e85ae0f79.; In this commit, main idea was to use clang binary to retrieve information; about resource-clang-dir. Sadly ROOT patched LLVM/Clang is built; without clang binary and ROOT CMake crash then with next error:. -- /home/oksana/CERN_sources/llvm-clang-root/inst/bin; CMake Error at core/clingutils/CMakeLists.txt:80 (message):; Cannot determine clang resource directory path",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4259
https://github.com/root-project/root/pull/4259:175,Deployability,patch,patched,175,"This reverts commit 1e8c04dd4beff8fc3d34cfd21e45358e85ae0f79.; In this commit, main idea was to use clang binary to retrieve information; about resource-clang-dir. Sadly ROOT patched LLVM/Clang is built; without clang binary and ROOT CMake crash then with next error:. -- /home/oksana/CERN_sources/llvm-clang-root/inst/bin; CMake Error at core/clingutils/CMakeLists.txt:80 (message):; Cannot determine clang resource directory path",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4259
https://github.com/root-project/root/pull/4259:374,Integrability,message,message,374,"This reverts commit 1e8c04dd4beff8fc3d34cfd21e45358e85ae0f79.; In this commit, main idea was to use clang binary to retrieve information; about resource-clang-dir. Sadly ROOT patched LLVM/Clang is built; without clang binary and ROOT CMake crash then with next error:. -- /home/oksana/CERN_sources/llvm-clang-root/inst/bin; CMake Error at core/clingutils/CMakeLists.txt:80 (message):; Cannot determine clang resource directory path",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4259
https://github.com/root-project/root/pull/4264:1130,Availability,avail,available,1130,"This PR updates Cppyy and adapts experimental PyROOT to the changes. It also re-enables a few tests. The following PRs merged and issues fixed in Cppyy are incorporated by this update:. https://bitbucket.org/wlav/cpycppyy/pull-requests/24/fixes-for-memoryregulator-recursiveremove; https://bitbucket.org/wlav/cpycppyy/pull-requests/25/proposal-for-setting-hooks-for-custom. https://bitbucket.org/wlav/cppyy/issues/113/assignment-to-c-global-from-python-does; https://bitbucket.org/wlav/cppyy/issues/115/instantiation-for-c-float-picked-when; https://bitbucket.org/wlav/cppyy/issues/121/dir-does-not-return-auto-instantiated; https://bitbucket.org/wlav/cppyy/issues/131/problem-constructing-object-of-templated; https://bitbucket.org/wlav/cppyy/issues/138/crash-when-deleting-an-object-of-a-python; https://bitbucket.org/wlav/cppyy/issues/139/wrong-overload-picked-when-passing-object. There is still one more pending issue, introduced recently in Cppyy, which affects a few tests:; https://bitbucket.org/wlav/cppyy/issues/136/item-assignment-not-working-in-templated; Those tests have been disabled temporarily. Once a bug fix is available it will be ported right away to experimental PyROOT's Cppyy.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4264
https://github.com/root-project/root/pull/4264:8,Deployability,update,updates,8,"This PR updates Cppyy and adapts experimental PyROOT to the changes. It also re-enables a few tests. The following PRs merged and issues fixed in Cppyy are incorporated by this update:. https://bitbucket.org/wlav/cpycppyy/pull-requests/24/fixes-for-memoryregulator-recursiveremove; https://bitbucket.org/wlav/cpycppyy/pull-requests/25/proposal-for-setting-hooks-for-custom. https://bitbucket.org/wlav/cppyy/issues/113/assignment-to-c-global-from-python-does; https://bitbucket.org/wlav/cppyy/issues/115/instantiation-for-c-float-picked-when; https://bitbucket.org/wlav/cppyy/issues/121/dir-does-not-return-auto-instantiated; https://bitbucket.org/wlav/cppyy/issues/131/problem-constructing-object-of-templated; https://bitbucket.org/wlav/cppyy/issues/138/crash-when-deleting-an-object-of-a-python; https://bitbucket.org/wlav/cppyy/issues/139/wrong-overload-picked-when-passing-object. There is still one more pending issue, introduced recently in Cppyy, which affects a few tests:; https://bitbucket.org/wlav/cppyy/issues/136/item-assignment-not-working-in-templated; Those tests have been disabled temporarily. Once a bug fix is available it will be ported right away to experimental PyROOT's Cppyy.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4264
https://github.com/root-project/root/pull/4264:177,Deployability,update,update,177,"This PR updates Cppyy and adapts experimental PyROOT to the changes. It also re-enables a few tests. The following PRs merged and issues fixed in Cppyy are incorporated by this update:. https://bitbucket.org/wlav/cpycppyy/pull-requests/24/fixes-for-memoryregulator-recursiveremove; https://bitbucket.org/wlav/cpycppyy/pull-requests/25/proposal-for-setting-hooks-for-custom. https://bitbucket.org/wlav/cppyy/issues/113/assignment-to-c-global-from-python-does; https://bitbucket.org/wlav/cppyy/issues/115/instantiation-for-c-float-picked-when; https://bitbucket.org/wlav/cppyy/issues/121/dir-does-not-return-auto-instantiated; https://bitbucket.org/wlav/cppyy/issues/131/problem-constructing-object-of-templated; https://bitbucket.org/wlav/cppyy/issues/138/crash-when-deleting-an-object-of-a-python; https://bitbucket.org/wlav/cppyy/issues/139/wrong-overload-picked-when-passing-object. There is still one more pending issue, introduced recently in Cppyy, which affects a few tests:; https://bitbucket.org/wlav/cppyy/issues/136/item-assignment-not-working-in-templated; Those tests have been disabled temporarily. Once a bug fix is available it will be ported right away to experimental PyROOT's Cppyy.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4264
https://github.com/root-project/root/pull/4264:26,Energy Efficiency,adapt,adapts,26,"This PR updates Cppyy and adapts experimental PyROOT to the changes. It also re-enables a few tests. The following PRs merged and issues fixed in Cppyy are incorporated by this update:. https://bitbucket.org/wlav/cpycppyy/pull-requests/24/fixes-for-memoryregulator-recursiveremove; https://bitbucket.org/wlav/cpycppyy/pull-requests/25/proposal-for-setting-hooks-for-custom. https://bitbucket.org/wlav/cppyy/issues/113/assignment-to-c-global-from-python-does; https://bitbucket.org/wlav/cppyy/issues/115/instantiation-for-c-float-picked-when; https://bitbucket.org/wlav/cppyy/issues/121/dir-does-not-return-auto-instantiated; https://bitbucket.org/wlav/cppyy/issues/131/problem-constructing-object-of-templated; https://bitbucket.org/wlav/cppyy/issues/138/crash-when-deleting-an-object-of-a-python; https://bitbucket.org/wlav/cppyy/issues/139/wrong-overload-picked-when-passing-object. There is still one more pending issue, introduced recently in Cppyy, which affects a few tests:; https://bitbucket.org/wlav/cppyy/issues/136/item-assignment-not-working-in-templated; Those tests have been disabled temporarily. Once a bug fix is available it will be ported right away to experimental PyROOT's Cppyy.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4264
https://github.com/root-project/root/pull/4264:26,Modifiability,adapt,adapts,26,"This PR updates Cppyy and adapts experimental PyROOT to the changes. It also re-enables a few tests. The following PRs merged and issues fixed in Cppyy are incorporated by this update:. https://bitbucket.org/wlav/cpycppyy/pull-requests/24/fixes-for-memoryregulator-recursiveremove; https://bitbucket.org/wlav/cpycppyy/pull-requests/25/proposal-for-setting-hooks-for-custom. https://bitbucket.org/wlav/cppyy/issues/113/assignment-to-c-global-from-python-does; https://bitbucket.org/wlav/cppyy/issues/115/instantiation-for-c-float-picked-when; https://bitbucket.org/wlav/cppyy/issues/121/dir-does-not-return-auto-instantiated; https://bitbucket.org/wlav/cppyy/issues/131/problem-constructing-object-of-templated; https://bitbucket.org/wlav/cppyy/issues/138/crash-when-deleting-an-object-of-a-python; https://bitbucket.org/wlav/cppyy/issues/139/wrong-overload-picked-when-passing-object. There is still one more pending issue, introduced recently in Cppyy, which affects a few tests:; https://bitbucket.org/wlav/cppyy/issues/136/item-assignment-not-working-in-templated; Those tests have been disabled temporarily. Once a bug fix is available it will be ported right away to experimental PyROOT's Cppyy.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4264
https://github.com/root-project/root/pull/4264:94,Testability,test,tests,94,"This PR updates Cppyy and adapts experimental PyROOT to the changes. It also re-enables a few tests. The following PRs merged and issues fixed in Cppyy are incorporated by this update:. https://bitbucket.org/wlav/cpycppyy/pull-requests/24/fixes-for-memoryregulator-recursiveremove; https://bitbucket.org/wlav/cpycppyy/pull-requests/25/proposal-for-setting-hooks-for-custom. https://bitbucket.org/wlav/cppyy/issues/113/assignment-to-c-global-from-python-does; https://bitbucket.org/wlav/cppyy/issues/115/instantiation-for-c-float-picked-when; https://bitbucket.org/wlav/cppyy/issues/121/dir-does-not-return-auto-instantiated; https://bitbucket.org/wlav/cppyy/issues/131/problem-constructing-object-of-templated; https://bitbucket.org/wlav/cppyy/issues/138/crash-when-deleting-an-object-of-a-python; https://bitbucket.org/wlav/cppyy/issues/139/wrong-overload-picked-when-passing-object. There is still one more pending issue, introduced recently in Cppyy, which affects a few tests:; https://bitbucket.org/wlav/cppyy/issues/136/item-assignment-not-working-in-templated; Those tests have been disabled temporarily. Once a bug fix is available it will be ported right away to experimental PyROOT's Cppyy.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4264
https://github.com/root-project/root/pull/4264:974,Testability,test,tests,974,"This PR updates Cppyy and adapts experimental PyROOT to the changes. It also re-enables a few tests. The following PRs merged and issues fixed in Cppyy are incorporated by this update:. https://bitbucket.org/wlav/cpycppyy/pull-requests/24/fixes-for-memoryregulator-recursiveremove; https://bitbucket.org/wlav/cpycppyy/pull-requests/25/proposal-for-setting-hooks-for-custom. https://bitbucket.org/wlav/cppyy/issues/113/assignment-to-c-global-from-python-does; https://bitbucket.org/wlav/cppyy/issues/115/instantiation-for-c-float-picked-when; https://bitbucket.org/wlav/cppyy/issues/121/dir-does-not-return-auto-instantiated; https://bitbucket.org/wlav/cppyy/issues/131/problem-constructing-object-of-templated; https://bitbucket.org/wlav/cppyy/issues/138/crash-when-deleting-an-object-of-a-python; https://bitbucket.org/wlav/cppyy/issues/139/wrong-overload-picked-when-passing-object. There is still one more pending issue, introduced recently in Cppyy, which affects a few tests:; https://bitbucket.org/wlav/cppyy/issues/136/item-assignment-not-working-in-templated; Those tests have been disabled temporarily. Once a bug fix is available it will be ported right away to experimental PyROOT's Cppyy.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4264
https://github.com/root-project/root/pull/4264:1074,Testability,test,tests,1074,"This PR updates Cppyy and adapts experimental PyROOT to the changes. It also re-enables a few tests. The following PRs merged and issues fixed in Cppyy are incorporated by this update:. https://bitbucket.org/wlav/cpycppyy/pull-requests/24/fixes-for-memoryregulator-recursiveremove; https://bitbucket.org/wlav/cpycppyy/pull-requests/25/proposal-for-setting-hooks-for-custom. https://bitbucket.org/wlav/cppyy/issues/113/assignment-to-c-global-from-python-does; https://bitbucket.org/wlav/cppyy/issues/115/instantiation-for-c-float-picked-when; https://bitbucket.org/wlav/cppyy/issues/121/dir-does-not-return-auto-instantiated; https://bitbucket.org/wlav/cppyy/issues/131/problem-constructing-object-of-templated; https://bitbucket.org/wlav/cppyy/issues/138/crash-when-deleting-an-object-of-a-python; https://bitbucket.org/wlav/cppyy/issues/139/wrong-overload-picked-when-passing-object. There is still one more pending issue, introduced recently in Cppyy, which affects a few tests:; https://bitbucket.org/wlav/cppyy/issues/136/item-assignment-not-working-in-templated; Those tests have been disabled temporarily. Once a bug fix is available it will be ported right away to experimental PyROOT's Cppyy.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4264
https://github.com/root-project/root/pull/4269:42,Security,expose,expose,42,Since root-project/root@10a0dec we do not expose flags from the build system; directly to rootcling. We use that opportunity to simplify the setup while; preparing rootcling for the new argument parser.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4269
https://github.com/root-project/root/pull/4269:128,Usability,simpl,simplify,128,Since root-project/root@10a0dec we do not expose flags from the build system; directly to rootcling. We use that opportunity to simplify the setup while; preparing rootcling for the new argument parser.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4269
https://github.com/root-project/root/pull/4270:0,Integrability,Depend,Depends,0,Depends on #4269,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4270
https://github.com/root-project/root/pull/4271:18,Deployability,update,update,18,Add requirejs and update _getUID() function,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4271
https://github.com/root-project/root/pull/4273:84,Security,access,accessing,84,In particular. - Add support for 8 bit unsigned integer; - Add support for directly accessing a class member with a view,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4273
https://github.com/root-project/root/pull/4279:611,Deployability,install,installation,611,"The commits in this PR contain the necessary steps performed in order to allow the user to build PyROOT with more than one versions of Python. The version in use can be changed with the usual `source thisroot.sh` preceded by the specific Python version, e.g.:; `ROOT_PYTHON_VERSION=3.6 source bin/thisroot.sh`; performed inside the build directory. ; Quick summary of the commits:; (1) set the necessary CMake variables to build the PyROOT libraries in lib/pythonX.Y; (2) modify thisroot.sh to allow the user to select the Python version; (3) necessary changes to pyunittests and tutorials CMake variables; (4) installation",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4279
https://github.com/root-project/root/pull/4279:410,Modifiability,variab,variables,410,"The commits in this PR contain the necessary steps performed in order to allow the user to build PyROOT with more than one versions of Python. The version in use can be changed with the usual `source thisroot.sh` preceded by the specific Python version, e.g.:; `ROOT_PYTHON_VERSION=3.6 source bin/thisroot.sh`; performed inside the build directory. ; Quick summary of the commits:; (1) set the necessary CMake variables to build the PyROOT libraries in lib/pythonX.Y; (2) modify thisroot.sh to allow the user to select the Python version; (3) necessary changes to pyunittests and tutorials CMake variables; (4) installation",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4279
https://github.com/root-project/root/pull/4279:596,Modifiability,variab,variables,596,"The commits in this PR contain the necessary steps performed in order to allow the user to build PyROOT with more than one versions of Python. The version in use can be changed with the usual `source thisroot.sh` preceded by the specific Python version, e.g.:; `ROOT_PYTHON_VERSION=3.6 source bin/thisroot.sh`; performed inside the build directory. ; Quick summary of the commits:; (1) set the necessary CMake variables to build the PyROOT libraries in lib/pythonX.Y; (2) modify thisroot.sh to allow the user to select the Python version; (3) necessary changes to pyunittests and tutorials CMake variables; (4) installation",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4279
https://github.com/root-project/root/pull/4279:51,Performance,perform,performed,51,"The commits in this PR contain the necessary steps performed in order to allow the user to build PyROOT with more than one versions of Python. The version in use can be changed with the usual `source thisroot.sh` preceded by the specific Python version, e.g.:; `ROOT_PYTHON_VERSION=3.6 source bin/thisroot.sh`; performed inside the build directory. ; Quick summary of the commits:; (1) set the necessary CMake variables to build the PyROOT libraries in lib/pythonX.Y; (2) modify thisroot.sh to allow the user to select the Python version; (3) necessary changes to pyunittests and tutorials CMake variables; (4) installation",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4279
https://github.com/root-project/root/pull/4279:311,Performance,perform,performed,311,"The commits in this PR contain the necessary steps performed in order to allow the user to build PyROOT with more than one versions of Python. The version in use can be changed with the usual `source thisroot.sh` preceded by the specific Python version, e.g.:; `ROOT_PYTHON_VERSION=3.6 source bin/thisroot.sh`; performed inside the build directory. ; Quick summary of the commits:; (1) set the necessary CMake variables to build the PyROOT libraries in lib/pythonX.Y; (2) modify thisroot.sh to allow the user to select the Python version; (3) necessary changes to pyunittests and tutorials CMake variables; (4) installation",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4279
https://github.com/root-project/root/pull/4283:110,Testability,test,test,110,"Run a first round of CI for the new RooFit feature. As it is an opt-in feature, the first round should mainly test that it doesn't break anything.; Several tests where batch evaluations are switched on are coming soon.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4283
https://github.com/root-project/root/pull/4283:156,Testability,test,tests,156,"Run a first round of CI for the new RooFit feature. As it is an opt-in feature, the first round should mainly test that it doesn't break anything.; Several tests where batch evaluations are switched on are coming soon.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4283
https://github.com/root-project/root/pull/4285:13,Usability,Clear,Clear,13,Make sure to Clear the list 'extrainfos' before any of its content is deleted. See https://root-forum.cern.ch/t/tfile-makeproject-severely-broken-in-root-6-08-06-6-18-00/34924,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4285
https://github.com/root-project/root/pull/4288:21,Integrability,depend,depending,21,"In cmssw we see that depending on the invoking code the trigger function is; resolved sometimes with the symlink-ed path and sometimes without. This can be observed in the cmssw biglib setup where all plugin libraries; are assembled into a single library to yield performance improvement of (10%). This is seen in cms-sw/cmsdist#5172 where libHistPainter_rdict.pcm is not; found in the fPendingRdicts because it was registered with the 'other'; path. cc: @davidlange6, @smuzaffar.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4288
https://github.com/root-project/root/pull/4288:201,Modifiability,plugin,plugin,201,"In cmssw we see that depending on the invoking code the trigger function is; resolved sometimes with the symlink-ed path and sometimes without. This can be observed in the cmssw biglib setup where all plugin libraries; are assembled into a single library to yield performance improvement of (10%). This is seen in cms-sw/cmsdist#5172 where libHistPainter_rdict.pcm is not; found in the fPendingRdicts because it was registered with the 'other'; path. cc: @davidlange6, @smuzaffar.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4288
https://github.com/root-project/root/pull/4288:264,Performance,perform,performance,264,"In cmssw we see that depending on the invoking code the trigger function is; resolved sometimes with the symlink-ed path and sometimes without. This can be observed in the cmssw biglib setup where all plugin libraries; are assembled into a single library to yield performance improvement of (10%). This is seen in cms-sw/cmsdist#5172 where libHistPainter_rdict.pcm is not; found in the fPendingRdicts because it was registered with the 'other'; path. cc: @davidlange6, @smuzaffar.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4288
https://github.com/root-project/root/pull/4290:6,Performance,optimiz,optimization,6,Wrong optimization was used.; Fixes https://root-forum.cern.ch/t/35782/,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4290
https://github.com/root-project/root/pull/4292:6,Performance,optimiz,optimization,6,Wrong optimization was used.; Fixes https://root-forum.cern.ch/t/35782/. @Axel-Naumann Can you open branch for commits again?,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4292
https://github.com/root-project/root/pull/4293:354,Performance,optimiz,optimized,354,"**Edit:** After rebasing to current master, everything is fine (fixed the memory regulation). The port is rather straight forward, however, the tutorial `pyroot002_TTreeAsMatrix.py` fails during shutdown with following backtrace:. ```; #6 0x0000000004c6c270 in ?? (); #7 0x00007f958582abc0 in TClass::Destructor (this=0x4ae4ee0, obj=0x4c64ee0, dtorOnly=<optimized out>) at /home/stefan/root-dev/core/meta/src/TClass.cxx:5211; #8 0x00007f9579d01e7f in CPyCppyy::op_dealloc_nofree (pyobj=pyobj; entry=0x7f956c67acf8) at /home/stefan/root-dev/bindings/pyroot_experimental/cppyy/CPyCppyy/src/CPPInstance.cxx:45; #9 0x00007f9579d01f69 in CPyCppyy::op_dealloc (pyobj=0x7f956c67acf8) at /home/stefan/root-dev/bindings/pyroot_experimental/cppyy/CPyCppyy/src/CPPInstance.cxx:149; #10 0x00000000004f7592 in ?? (); #11 0x00000000004fc33a in _PyModule_Clear (); #12 0x00000000004fb9d3 in PyImport_Cleanup (); #13 0x00000000004f8e14 in Py_Finalize (); #14 0x00000000004938ec in Py_Main (); #15 0x00007f9586fd9830 in __libc_start_main (main=0x4934c0 <main>, argc=2, argv=0x7fffc2505518, init=<optimized out>, fini=<optimized out>, rtld_fini=<optimized out>, stack_end=0x7fffc2505508) at ../csu/libc-start.c:291; #16 0x00000000004933e9 in _start (); ```. I've ported as well the tests, these are fine.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4293
https://github.com/root-project/root/pull/4293:1079,Performance,optimiz,optimized,1079,"**Edit:** After rebasing to current master, everything is fine (fixed the memory regulation). The port is rather straight forward, however, the tutorial `pyroot002_TTreeAsMatrix.py` fails during shutdown with following backtrace:. ```; #6 0x0000000004c6c270 in ?? (); #7 0x00007f958582abc0 in TClass::Destructor (this=0x4ae4ee0, obj=0x4c64ee0, dtorOnly=<optimized out>) at /home/stefan/root-dev/core/meta/src/TClass.cxx:5211; #8 0x00007f9579d01e7f in CPyCppyy::op_dealloc_nofree (pyobj=pyobj; entry=0x7f956c67acf8) at /home/stefan/root-dev/bindings/pyroot_experimental/cppyy/CPyCppyy/src/CPPInstance.cxx:45; #9 0x00007f9579d01f69 in CPyCppyy::op_dealloc (pyobj=0x7f956c67acf8) at /home/stefan/root-dev/bindings/pyroot_experimental/cppyy/CPyCppyy/src/CPPInstance.cxx:149; #10 0x00000000004f7592 in ?? (); #11 0x00000000004fc33a in _PyModule_Clear (); #12 0x00000000004fb9d3 in PyImport_Cleanup (); #13 0x00000000004f8e14 in Py_Finalize (); #14 0x00000000004938ec in Py_Main (); #15 0x00007f9586fd9830 in __libc_start_main (main=0x4934c0 <main>, argc=2, argv=0x7fffc2505518, init=<optimized out>, fini=<optimized out>, rtld_fini=<optimized out>, stack_end=0x7fffc2505508) at ../csu/libc-start.c:291; #16 0x00000000004933e9 in _start (); ```. I've ported as well the tests, these are fine.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4293
https://github.com/root-project/root/pull/4293:1101,Performance,optimiz,optimized,1101,"**Edit:** After rebasing to current master, everything is fine (fixed the memory regulation). The port is rather straight forward, however, the tutorial `pyroot002_TTreeAsMatrix.py` fails during shutdown with following backtrace:. ```; #6 0x0000000004c6c270 in ?? (); #7 0x00007f958582abc0 in TClass::Destructor (this=0x4ae4ee0, obj=0x4c64ee0, dtorOnly=<optimized out>) at /home/stefan/root-dev/core/meta/src/TClass.cxx:5211; #8 0x00007f9579d01e7f in CPyCppyy::op_dealloc_nofree (pyobj=pyobj; entry=0x7f956c67acf8) at /home/stefan/root-dev/bindings/pyroot_experimental/cppyy/CPyCppyy/src/CPPInstance.cxx:45; #9 0x00007f9579d01f69 in CPyCppyy::op_dealloc (pyobj=0x7f956c67acf8) at /home/stefan/root-dev/bindings/pyroot_experimental/cppyy/CPyCppyy/src/CPPInstance.cxx:149; #10 0x00000000004f7592 in ?? (); #11 0x00000000004fc33a in _PyModule_Clear (); #12 0x00000000004fb9d3 in PyImport_Cleanup (); #13 0x00000000004f8e14 in Py_Finalize (); #14 0x00000000004938ec in Py_Main (); #15 0x00007f9586fd9830 in __libc_start_main (main=0x4934c0 <main>, argc=2, argv=0x7fffc2505518, init=<optimized out>, fini=<optimized out>, rtld_fini=<optimized out>, stack_end=0x7fffc2505508) at ../csu/libc-start.c:291; #16 0x00000000004933e9 in _start (); ```. I've ported as well the tests, these are fine.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4293
https://github.com/root-project/root/pull/4293:1128,Performance,optimiz,optimized,1128,"**Edit:** After rebasing to current master, everything is fine (fixed the memory regulation). The port is rather straight forward, however, the tutorial `pyroot002_TTreeAsMatrix.py` fails during shutdown with following backtrace:. ```; #6 0x0000000004c6c270 in ?? (); #7 0x00007f958582abc0 in TClass::Destructor (this=0x4ae4ee0, obj=0x4c64ee0, dtorOnly=<optimized out>) at /home/stefan/root-dev/core/meta/src/TClass.cxx:5211; #8 0x00007f9579d01e7f in CPyCppyy::op_dealloc_nofree (pyobj=pyobj; entry=0x7f956c67acf8) at /home/stefan/root-dev/bindings/pyroot_experimental/cppyy/CPyCppyy/src/CPPInstance.cxx:45; #9 0x00007f9579d01f69 in CPyCppyy::op_dealloc (pyobj=0x7f956c67acf8) at /home/stefan/root-dev/bindings/pyroot_experimental/cppyy/CPyCppyy/src/CPPInstance.cxx:149; #10 0x00000000004f7592 in ?? (); #11 0x00000000004fc33a in _PyModule_Clear (); #12 0x00000000004fb9d3 in PyImport_Cleanup (); #13 0x00000000004f8e14 in Py_Finalize (); #14 0x00000000004938ec in Py_Main (); #15 0x00007f9586fd9830 in __libc_start_main (main=0x4934c0 <main>, argc=2, argv=0x7fffc2505518, init=<optimized out>, fini=<optimized out>, rtld_fini=<optimized out>, stack_end=0x7fffc2505508) at ../csu/libc-start.c:291; #16 0x00000000004933e9 in _start (); ```. I've ported as well the tests, these are fine.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4293
https://github.com/root-project/root/pull/4293:1264,Testability,test,tests,1264,"**Edit:** After rebasing to current master, everything is fine (fixed the memory regulation). The port is rather straight forward, however, the tutorial `pyroot002_TTreeAsMatrix.py` fails during shutdown with following backtrace:. ```; #6 0x0000000004c6c270 in ?? (); #7 0x00007f958582abc0 in TClass::Destructor (this=0x4ae4ee0, obj=0x4c64ee0, dtorOnly=<optimized out>) at /home/stefan/root-dev/core/meta/src/TClass.cxx:5211; #8 0x00007f9579d01e7f in CPyCppyy::op_dealloc_nofree (pyobj=pyobj; entry=0x7f956c67acf8) at /home/stefan/root-dev/bindings/pyroot_experimental/cppyy/CPyCppyy/src/CPPInstance.cxx:45; #9 0x00007f9579d01f69 in CPyCppyy::op_dealloc (pyobj=0x7f956c67acf8) at /home/stefan/root-dev/bindings/pyroot_experimental/cppyy/CPyCppyy/src/CPPInstance.cxx:149; #10 0x00000000004f7592 in ?? (); #11 0x00000000004fc33a in _PyModule_Clear (); #12 0x00000000004fb9d3 in PyImport_Cleanup (); #13 0x00000000004f8e14 in Py_Finalize (); #14 0x00000000004938ec in Py_Main (); #15 0x00007f9586fd9830 in __libc_start_main (main=0x4934c0 <main>, argc=2, argv=0x7fffc2505518, init=<optimized out>, fini=<optimized out>, rtld_fini=<optimized out>, stack_end=0x7fffc2505508) at ../csu/libc-start.c:291; #16 0x00000000004933e9 in _start (); ```. I've ported as well the tests, these are fine.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4293
https://github.com/root-project/root/pull/4294:425,Deployability,patch,patch,425,"This PR and their roottest sibling PR contain fixes for the following tests:. Roottest python basic tests:; - roottest-python-basic-basic; - roottest-python-basic-overload. Roofit tutorials fixed by the addition of a pythonisation to get the using declarations of `RooAbsData` into `RooDataHist`. This pythonisation will not be needed anymore when a general solution is provided by the bindings, mainly by merging this Cppyy patch into ROOT: https://bitbucket.org/wlav/cppyy-backend/src/master/cling/patches/using_decls.diff; - tutorial-roofit-rf106_plotdecoration-py; - tutorial-roofit-rf610_visualerror-py; - pyunittests-pyroot-pyz-roodatahist-ploton; - tutorial-roofit-rf315_projectpdf-py; - tutorial-roofit-rf402_datahandling-py. Related to https://bitbucket.org/wlav/cppyy/issues/66/cppoverload-addmethod-cppoverload-clears; - tutorial-roofit-rf307_fullpereventerrors-py; - tutorial-roofit-rf706_histpdf-py. Some fixes for the following test, although it still can't be re-enabled due to https://bitbucket.org/wlav/cppyy/issues/145/enum-values-not-defined-as-constants; - roottest-python-basic-datatype. Some fixes for the following test, but still can't be re-enabled (more issues to investigate):; - roottest-python-regression-regression",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4294
https://github.com/root-project/root/pull/4294:500,Deployability,patch,patches,500,"This PR and their roottest sibling PR contain fixes for the following tests:. Roottest python basic tests:; - roottest-python-basic-basic; - roottest-python-basic-overload. Roofit tutorials fixed by the addition of a pythonisation to get the using declarations of `RooAbsData` into `RooDataHist`. This pythonisation will not be needed anymore when a general solution is provided by the bindings, mainly by merging this Cppyy patch into ROOT: https://bitbucket.org/wlav/cppyy-backend/src/master/cling/patches/using_decls.diff; - tutorial-roofit-rf106_plotdecoration-py; - tutorial-roofit-rf610_visualerror-py; - pyunittests-pyroot-pyz-roodatahist-ploton; - tutorial-roofit-rf315_projectpdf-py; - tutorial-roofit-rf402_datahandling-py. Related to https://bitbucket.org/wlav/cppyy/issues/66/cppoverload-addmethod-cppoverload-clears; - tutorial-roofit-rf307_fullpereventerrors-py; - tutorial-roofit-rf706_histpdf-py. Some fixes for the following test, although it still can't be re-enabled due to https://bitbucket.org/wlav/cppyy/issues/145/enum-values-not-defined-as-constants; - roottest-python-basic-datatype. Some fixes for the following test, but still can't be re-enabled (more issues to investigate):; - roottest-python-regression-regression",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4294
https://github.com/root-project/root/pull/4294:70,Testability,test,tests,70,"This PR and their roottest sibling PR contain fixes for the following tests:. Roottest python basic tests:; - roottest-python-basic-basic; - roottest-python-basic-overload. Roofit tutorials fixed by the addition of a pythonisation to get the using declarations of `RooAbsData` into `RooDataHist`. This pythonisation will not be needed anymore when a general solution is provided by the bindings, mainly by merging this Cppyy patch into ROOT: https://bitbucket.org/wlav/cppyy-backend/src/master/cling/patches/using_decls.diff; - tutorial-roofit-rf106_plotdecoration-py; - tutorial-roofit-rf610_visualerror-py; - pyunittests-pyroot-pyz-roodatahist-ploton; - tutorial-roofit-rf315_projectpdf-py; - tutorial-roofit-rf402_datahandling-py. Related to https://bitbucket.org/wlav/cppyy/issues/66/cppoverload-addmethod-cppoverload-clears; - tutorial-roofit-rf307_fullpereventerrors-py; - tutorial-roofit-rf706_histpdf-py. Some fixes for the following test, although it still can't be re-enabled due to https://bitbucket.org/wlav/cppyy/issues/145/enum-values-not-defined-as-constants; - roottest-python-basic-datatype. Some fixes for the following test, but still can't be re-enabled (more issues to investigate):; - roottest-python-regression-regression",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4294
https://github.com/root-project/root/pull/4294:100,Testability,test,tests,100,"This PR and their roottest sibling PR contain fixes for the following tests:. Roottest python basic tests:; - roottest-python-basic-basic; - roottest-python-basic-overload. Roofit tutorials fixed by the addition of a pythonisation to get the using declarations of `RooAbsData` into `RooDataHist`. This pythonisation will not be needed anymore when a general solution is provided by the bindings, mainly by merging this Cppyy patch into ROOT: https://bitbucket.org/wlav/cppyy-backend/src/master/cling/patches/using_decls.diff; - tutorial-roofit-rf106_plotdecoration-py; - tutorial-roofit-rf610_visualerror-py; - pyunittests-pyroot-pyz-roodatahist-ploton; - tutorial-roofit-rf315_projectpdf-py; - tutorial-roofit-rf402_datahandling-py. Related to https://bitbucket.org/wlav/cppyy/issues/66/cppoverload-addmethod-cppoverload-clears; - tutorial-roofit-rf307_fullpereventerrors-py; - tutorial-roofit-rf706_histpdf-py. Some fixes for the following test, although it still can't be re-enabled due to https://bitbucket.org/wlav/cppyy/issues/145/enum-values-not-defined-as-constants; - roottest-python-basic-datatype. Some fixes for the following test, but still can't be re-enabled (more issues to investigate):; - roottest-python-regression-regression",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4294
https://github.com/root-project/root/pull/4294:942,Testability,test,test,942,"This PR and their roottest sibling PR contain fixes for the following tests:. Roottest python basic tests:; - roottest-python-basic-basic; - roottest-python-basic-overload. Roofit tutorials fixed by the addition of a pythonisation to get the using declarations of `RooAbsData` into `RooDataHist`. This pythonisation will not be needed anymore when a general solution is provided by the bindings, mainly by merging this Cppyy patch into ROOT: https://bitbucket.org/wlav/cppyy-backend/src/master/cling/patches/using_decls.diff; - tutorial-roofit-rf106_plotdecoration-py; - tutorial-roofit-rf610_visualerror-py; - pyunittests-pyroot-pyz-roodatahist-ploton; - tutorial-roofit-rf315_projectpdf-py; - tutorial-roofit-rf402_datahandling-py. Related to https://bitbucket.org/wlav/cppyy/issues/66/cppoverload-addmethod-cppoverload-clears; - tutorial-roofit-rf307_fullpereventerrors-py; - tutorial-roofit-rf706_histpdf-py. Some fixes for the following test, although it still can't be re-enabled due to https://bitbucket.org/wlav/cppyy/issues/145/enum-values-not-defined-as-constants; - roottest-python-basic-datatype. Some fixes for the following test, but still can't be re-enabled (more issues to investigate):; - roottest-python-regression-regression",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4294
https://github.com/root-project/root/pull/4294:1138,Testability,test,test,1138,"This PR and their roottest sibling PR contain fixes for the following tests:. Roottest python basic tests:; - roottest-python-basic-basic; - roottest-python-basic-overload. Roofit tutorials fixed by the addition of a pythonisation to get the using declarations of `RooAbsData` into `RooDataHist`. This pythonisation will not be needed anymore when a general solution is provided by the bindings, mainly by merging this Cppyy patch into ROOT: https://bitbucket.org/wlav/cppyy-backend/src/master/cling/patches/using_decls.diff; - tutorial-roofit-rf106_plotdecoration-py; - tutorial-roofit-rf610_visualerror-py; - pyunittests-pyroot-pyz-roodatahist-ploton; - tutorial-roofit-rf315_projectpdf-py; - tutorial-roofit-rf402_datahandling-py. Related to https://bitbucket.org/wlav/cppyy/issues/66/cppoverload-addmethod-cppoverload-clears; - tutorial-roofit-rf307_fullpereventerrors-py; - tutorial-roofit-rf706_histpdf-py. Some fixes for the following test, although it still can't be re-enabled due to https://bitbucket.org/wlav/cppyy/issues/145/enum-values-not-defined-as-constants; - roottest-python-basic-datatype. Some fixes for the following test, but still can't be re-enabled (more issues to investigate):; - roottest-python-regression-regression",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4294
https://github.com/root-project/root/pull/4294:822,Usability,clear,clears,822,"This PR and their roottest sibling PR contain fixes for the following tests:. Roottest python basic tests:; - roottest-python-basic-basic; - roottest-python-basic-overload. Roofit tutorials fixed by the addition of a pythonisation to get the using declarations of `RooAbsData` into `RooDataHist`. This pythonisation will not be needed anymore when a general solution is provided by the bindings, mainly by merging this Cppyy patch into ROOT: https://bitbucket.org/wlav/cppyy-backend/src/master/cling/patches/using_decls.diff; - tutorial-roofit-rf106_plotdecoration-py; - tutorial-roofit-rf610_visualerror-py; - pyunittests-pyroot-pyz-roodatahist-ploton; - tutorial-roofit-rf315_projectpdf-py; - tutorial-roofit-rf402_datahandling-py. Related to https://bitbucket.org/wlav/cppyy/issues/66/cppoverload-addmethod-cppoverload-clears; - tutorial-roofit-rf307_fullpereventerrors-py; - tutorial-roofit-rf706_histpdf-py. Some fixes for the following test, although it still can't be re-enabled due to https://bitbucket.org/wlav/cppyy/issues/145/enum-values-not-defined-as-constants; - roottest-python-basic-datatype. Some fixes for the following test, but still can't be re-enabled (more issues to investigate):; - roottest-python-regression-regression",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4294
https://github.com/root-project/root/pull/4299:156,Integrability,depend,dependencies,156,"This turned out to be quite a bit harder to fix than I anticipated, but now almost all headers should be picked from the source directory, and many missing dependencies were added. After I also fix `ROOT_GENERATE_EXECUTABLE()` to use headers from the source directory, then generate headers out of `${CMAKE_BINARY_DIR}/include` and add them to their respective owning targets, we should be able to move the headers to the build directory only at the very end of the build in order to make ROOT usable from the build directory. However, in order to catch missing includes and other dependencies at build time, we need to keep using headers from the source directory only during the build.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4299
https://github.com/root-project/root/pull/4299:581,Integrability,depend,dependencies,581,"This turned out to be quite a bit harder to fix than I anticipated, but now almost all headers should be picked from the source directory, and many missing dependencies were added. After I also fix `ROOT_GENERATE_EXECUTABLE()` to use headers from the source directory, then generate headers out of `${CMAKE_BINARY_DIR}/include` and add them to their respective owning targets, we should be able to move the headers to the build directory only at the very end of the build in order to make ROOT usable from the build directory. However, in order to catch missing includes and other dependencies at build time, we need to keep using headers from the source directory only during the build.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4299
https://github.com/root-project/root/pull/4299:494,Usability,usab,usable,494,"This turned out to be quite a bit harder to fix than I anticipated, but now almost all headers should be picked from the source directory, and many missing dependencies were added. After I also fix `ROOT_GENERATE_EXECUTABLE()` to use headers from the source directory, then generate headers out of `${CMAKE_BINARY_DIR}/include` and add them to their respective owning targets, we should be able to move the headers to the build directory only at the very end of the build in order to make ROOT usable from the build directory. However, in order to catch missing includes and other dependencies at build time, we need to keep using headers from the source directory only during the build.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4299
https://github.com/root-project/root/pull/4300:87,Safety,safe,safe,87,Adds infrastructure to instrument code parts with counters and timers -- either thread-safe atomics or simple integers. Adds a few key counters to the raw page source.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4300
https://github.com/root-project/root/pull/4300:103,Usability,simpl,simple,103,Adds infrastructure to instrument code parts with counters and timers -- either thread-safe atomics or simple integers. Adds a few key counters to the raw page source.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4300
https://github.com/root-project/root/pull/4304:20,Energy Efficiency,adapt,adapted,20,…totype. Picked and adapted from Cppyy: try to get the requested method with; GetMethodWithPrototype with prototypes that consider reference; parameters too.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4304
https://github.com/root-project/root/pull/4304:20,Modifiability,adapt,adapted,20,…totype. Picked and adapted from Cppyy: try to get the requested method with; GetMethodWithPrototype with prototypes that consider reference; parameters too.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4304
https://github.com/root-project/root/pull/4305:66,Usability,clear,clearly,66,* use default members initializers; * use `override` specifier to clearly identify re-implemented methods; * use `nullptr` instead of 0 for all pointer values; * provide `= delete` specifier for non-implemented copy constructor and assign operators,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4305
https://github.com/root-project/root/pull/4310:90,Integrability,interface,interface,90,"Avoid connecting the DNS and avoid using getaddrinfo and instead scan the list of network interface. In many cases those 2 operations were taking a significant amount of time during startup (in few cases; more than 5s). In some cases (e.g. MacOS and possibly other WiFi use) the hostname is actually not registered and; consequently the search failed anyway .... One drawback of the scan is that there is no cheap way to tell which of the IP4 addresses listed is; the 'public' address since only information are IP, port and name ... and the name is more or so; arbitrary (different on BSD and linux, depends on VPN or bridge, etc) ... so for now we just (try; to) skip the loopback interface. A better technique (which would lead again to a 'spurrious' startup delay) is to open a socket to; a known server (eg google's DNS 8.8.8.8) and then interogate the socket to find out the IP seen; by the server.; For example with (https://stackoverflow.com/questions/212528/get-the-ip-address-of-the-machine); ```; void GetPrimaryIp(char* buffer, size_t buflen); {; assert(buflen >= 16);. int sock = socket(AF_INET, SOCK_DGRAM, 0);; assert(sock != -1);. const char* kGoogleDnsIp = 8.8.8.8;; uint16_t kDnsPort = 53;; struct sockaddr_in serv;; memset(&serv, 0, sizeof(serv));; serv.sin_family = AF_INET;; serv.sin_addr.s_addr = inet_addr(kGoogleDnsIp);; serv.sin_port = htons(kDnsPort);. int err = connect(sock, (const sockaddr*) &serv, sizeof(serv));; assert(err != -1);. sockaddr_in name;; socklen_t namelen = sizeof(name);; err = getsockname(sock, (sockaddr*) &name, &namelen);; assert(err != -1);. const char* p = inet_ntop(AF_INET, &name.sin_addr, buffer, buflen);; assert(p);. close(sock);; }; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4310
https://github.com/root-project/root/pull/4310:601,Integrability,depend,depends,601,"Avoid connecting the DNS and avoid using getaddrinfo and instead scan the list of network interface. In many cases those 2 operations were taking a significant amount of time during startup (in few cases; more than 5s). In some cases (e.g. MacOS and possibly other WiFi use) the hostname is actually not registered and; consequently the search failed anyway .... One drawback of the scan is that there is no cheap way to tell which of the IP4 addresses listed is; the 'public' address since only information are IP, port and name ... and the name is more or so; arbitrary (different on BSD and linux, depends on VPN or bridge, etc) ... so for now we just (try; to) skip the loopback interface. A better technique (which would lead again to a 'spurrious' startup delay) is to open a socket to; a known server (eg google's DNS 8.8.8.8) and then interogate the socket to find out the IP seen; by the server.; For example with (https://stackoverflow.com/questions/212528/get-the-ip-address-of-the-machine); ```; void GetPrimaryIp(char* buffer, size_t buflen); {; assert(buflen >= 16);. int sock = socket(AF_INET, SOCK_DGRAM, 0);; assert(sock != -1);. const char* kGoogleDnsIp = 8.8.8.8;; uint16_t kDnsPort = 53;; struct sockaddr_in serv;; memset(&serv, 0, sizeof(serv));; serv.sin_family = AF_INET;; serv.sin_addr.s_addr = inet_addr(kGoogleDnsIp);; serv.sin_port = htons(kDnsPort);. int err = connect(sock, (const sockaddr*) &serv, sizeof(serv));; assert(err != -1);. sockaddr_in name;; socklen_t namelen = sizeof(name);; err = getsockname(sock, (sockaddr*) &name, &namelen);; assert(err != -1);. const char* p = inet_ntop(AF_INET, &name.sin_addr, buffer, buflen);; assert(p);. close(sock);; }; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4310
https://github.com/root-project/root/pull/4310:619,Integrability,bridg,bridge,619,"Avoid connecting the DNS and avoid using getaddrinfo and instead scan the list of network interface. In many cases those 2 operations were taking a significant amount of time during startup (in few cases; more than 5s). In some cases (e.g. MacOS and possibly other WiFi use) the hostname is actually not registered and; consequently the search failed anyway .... One drawback of the scan is that there is no cheap way to tell which of the IP4 addresses listed is; the 'public' address since only information are IP, port and name ... and the name is more or so; arbitrary (different on BSD and linux, depends on VPN or bridge, etc) ... so for now we just (try; to) skip the loopback interface. A better technique (which would lead again to a 'spurrious' startup delay) is to open a socket to; a known server (eg google's DNS 8.8.8.8) and then interogate the socket to find out the IP seen; by the server.; For example with (https://stackoverflow.com/questions/212528/get-the-ip-address-of-the-machine); ```; void GetPrimaryIp(char* buffer, size_t buflen); {; assert(buflen >= 16);. int sock = socket(AF_INET, SOCK_DGRAM, 0);; assert(sock != -1);. const char* kGoogleDnsIp = 8.8.8.8;; uint16_t kDnsPort = 53;; struct sockaddr_in serv;; memset(&serv, 0, sizeof(serv));; serv.sin_family = AF_INET;; serv.sin_addr.s_addr = inet_addr(kGoogleDnsIp);; serv.sin_port = htons(kDnsPort);. int err = connect(sock, (const sockaddr*) &serv, sizeof(serv));; assert(err != -1);. sockaddr_in name;; socklen_t namelen = sizeof(name);; err = getsockname(sock, (sockaddr*) &name, &namelen);; assert(err != -1);. const char* p = inet_ntop(AF_INET, &name.sin_addr, buffer, buflen);; assert(p);. close(sock);; }; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4310
https://github.com/root-project/root/pull/4310:683,Integrability,interface,interface,683,"Avoid connecting the DNS and avoid using getaddrinfo and instead scan the list of network interface. In many cases those 2 operations were taking a significant amount of time during startup (in few cases; more than 5s). In some cases (e.g. MacOS and possibly other WiFi use) the hostname is actually not registered and; consequently the search failed anyway .... One drawback of the scan is that there is no cheap way to tell which of the IP4 addresses listed is; the 'public' address since only information are IP, port and name ... and the name is more or so; arbitrary (different on BSD and linux, depends on VPN or bridge, etc) ... so for now we just (try; to) skip the loopback interface. A better technique (which would lead again to a 'spurrious' startup delay) is to open a socket to; a known server (eg google's DNS 8.8.8.8) and then interogate the socket to find out the IP seen; by the server.; For example with (https://stackoverflow.com/questions/212528/get-the-ip-address-of-the-machine); ```; void GetPrimaryIp(char* buffer, size_t buflen); {; assert(buflen >= 16);. int sock = socket(AF_INET, SOCK_DGRAM, 0);; assert(sock != -1);. const char* kGoogleDnsIp = 8.8.8.8;; uint16_t kDnsPort = 53;; struct sockaddr_in serv;; memset(&serv, 0, sizeof(serv));; serv.sin_family = AF_INET;; serv.sin_addr.s_addr = inet_addr(kGoogleDnsIp);; serv.sin_port = htons(kDnsPort);. int err = connect(sock, (const sockaddr*) &serv, sizeof(serv));; assert(err != -1);. sockaddr_in name;; socklen_t namelen = sizeof(name);; err = getsockname(sock, (sockaddr*) &name, &namelen);; assert(err != -1);. const char* p = inet_ntop(AF_INET, &name.sin_addr, buffer, buflen);; assert(p);. close(sock);; }; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4310
https://github.com/root-project/root/pull/4310:0,Safety,Avoid,Avoid,0,"Avoid connecting the DNS and avoid using getaddrinfo and instead scan the list of network interface. In many cases those 2 operations were taking a significant amount of time during startup (in few cases; more than 5s). In some cases (e.g. MacOS and possibly other WiFi use) the hostname is actually not registered and; consequently the search failed anyway .... One drawback of the scan is that there is no cheap way to tell which of the IP4 addresses listed is; the 'public' address since only information are IP, port and name ... and the name is more or so; arbitrary (different on BSD and linux, depends on VPN or bridge, etc) ... so for now we just (try; to) skip the loopback interface. A better technique (which would lead again to a 'spurrious' startup delay) is to open a socket to; a known server (eg google's DNS 8.8.8.8) and then interogate the socket to find out the IP seen; by the server.; For example with (https://stackoverflow.com/questions/212528/get-the-ip-address-of-the-machine); ```; void GetPrimaryIp(char* buffer, size_t buflen); {; assert(buflen >= 16);. int sock = socket(AF_INET, SOCK_DGRAM, 0);; assert(sock != -1);. const char* kGoogleDnsIp = 8.8.8.8;; uint16_t kDnsPort = 53;; struct sockaddr_in serv;; memset(&serv, 0, sizeof(serv));; serv.sin_family = AF_INET;; serv.sin_addr.s_addr = inet_addr(kGoogleDnsIp);; serv.sin_port = htons(kDnsPort);. int err = connect(sock, (const sockaddr*) &serv, sizeof(serv));; assert(err != -1);. sockaddr_in name;; socklen_t namelen = sizeof(name);; err = getsockname(sock, (sockaddr*) &name, &namelen);; assert(err != -1);. const char* p = inet_ntop(AF_INET, &name.sin_addr, buffer, buflen);; assert(p);. close(sock);; }; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4310
https://github.com/root-project/root/pull/4310:29,Safety,avoid,avoid,29,"Avoid connecting the DNS and avoid using getaddrinfo and instead scan the list of network interface. In many cases those 2 operations were taking a significant amount of time during startup (in few cases; more than 5s). In some cases (e.g. MacOS and possibly other WiFi use) the hostname is actually not registered and; consequently the search failed anyway .... One drawback of the scan is that there is no cheap way to tell which of the IP4 addresses listed is; the 'public' address since only information are IP, port and name ... and the name is more or so; arbitrary (different on BSD and linux, depends on VPN or bridge, etc) ... so for now we just (try; to) skip the loopback interface. A better technique (which would lead again to a 'spurrious' startup delay) is to open a socket to; a known server (eg google's DNS 8.8.8.8) and then interogate the socket to find out the IP seen; by the server.; For example with (https://stackoverflow.com/questions/212528/get-the-ip-address-of-the-machine); ```; void GetPrimaryIp(char* buffer, size_t buflen); {; assert(buflen >= 16);. int sock = socket(AF_INET, SOCK_DGRAM, 0);; assert(sock != -1);. const char* kGoogleDnsIp = 8.8.8.8;; uint16_t kDnsPort = 53;; struct sockaddr_in serv;; memset(&serv, 0, sizeof(serv));; serv.sin_family = AF_INET;; serv.sin_addr.s_addr = inet_addr(kGoogleDnsIp);; serv.sin_port = htons(kDnsPort);. int err = connect(sock, (const sockaddr*) &serv, sizeof(serv));; assert(err != -1);. sockaddr_in name;; socklen_t namelen = sizeof(name);; err = getsockname(sock, (sockaddr*) &name, &namelen);; assert(err != -1);. const char* p = inet_ntop(AF_INET, &name.sin_addr, buffer, buflen);; assert(p);. close(sock);; }; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4310
https://github.com/root-project/root/pull/4310:1059,Testability,assert,assert,1059,"Avoid connecting the DNS and avoid using getaddrinfo and instead scan the list of network interface. In many cases those 2 operations were taking a significant amount of time during startup (in few cases; more than 5s). In some cases (e.g. MacOS and possibly other WiFi use) the hostname is actually not registered and; consequently the search failed anyway .... One drawback of the scan is that there is no cheap way to tell which of the IP4 addresses listed is; the 'public' address since only information are IP, port and name ... and the name is more or so; arbitrary (different on BSD and linux, depends on VPN or bridge, etc) ... so for now we just (try; to) skip the loopback interface. A better technique (which would lead again to a 'spurrious' startup delay) is to open a socket to; a known server (eg google's DNS 8.8.8.8) and then interogate the socket to find out the IP seen; by the server.; For example with (https://stackoverflow.com/questions/212528/get-the-ip-address-of-the-machine); ```; void GetPrimaryIp(char* buffer, size_t buflen); {; assert(buflen >= 16);. int sock = socket(AF_INET, SOCK_DGRAM, 0);; assert(sock != -1);. const char* kGoogleDnsIp = 8.8.8.8;; uint16_t kDnsPort = 53;; struct sockaddr_in serv;; memset(&serv, 0, sizeof(serv));; serv.sin_family = AF_INET;; serv.sin_addr.s_addr = inet_addr(kGoogleDnsIp);; serv.sin_port = htons(kDnsPort);. int err = connect(sock, (const sockaddr*) &serv, sizeof(serv));; assert(err != -1);. sockaddr_in name;; socklen_t namelen = sizeof(name);; err = getsockname(sock, (sockaddr*) &name, &namelen);; assert(err != -1);. const char* p = inet_ntop(AF_INET, &name.sin_addr, buffer, buflen);; assert(p);. close(sock);; }; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4310
https://github.com/root-project/root/pull/4310:1126,Testability,assert,assert,1126,"Avoid connecting the DNS and avoid using getaddrinfo and instead scan the list of network interface. In many cases those 2 operations were taking a significant amount of time during startup (in few cases; more than 5s). In some cases (e.g. MacOS and possibly other WiFi use) the hostname is actually not registered and; consequently the search failed anyway .... One drawback of the scan is that there is no cheap way to tell which of the IP4 addresses listed is; the 'public' address since only information are IP, port and name ... and the name is more or so; arbitrary (different on BSD and linux, depends on VPN or bridge, etc) ... so for now we just (try; to) skip the loopback interface. A better technique (which would lead again to a 'spurrious' startup delay) is to open a socket to; a known server (eg google's DNS 8.8.8.8) and then interogate the socket to find out the IP seen; by the server.; For example with (https://stackoverflow.com/questions/212528/get-the-ip-address-of-the-machine); ```; void GetPrimaryIp(char* buffer, size_t buflen); {; assert(buflen >= 16);. int sock = socket(AF_INET, SOCK_DGRAM, 0);; assert(sock != -1);. const char* kGoogleDnsIp = 8.8.8.8;; uint16_t kDnsPort = 53;; struct sockaddr_in serv;; memset(&serv, 0, sizeof(serv));; serv.sin_family = AF_INET;; serv.sin_addr.s_addr = inet_addr(kGoogleDnsIp);; serv.sin_port = htons(kDnsPort);. int err = connect(sock, (const sockaddr*) &serv, sizeof(serv));; assert(err != -1);. sockaddr_in name;; socklen_t namelen = sizeof(name);; err = getsockname(sock, (sockaddr*) &name, &namelen);; assert(err != -1);. const char* p = inet_ntop(AF_INET, &name.sin_addr, buffer, buflen);; assert(p);. close(sock);; }; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4310
https://github.com/root-project/root/pull/4310:1444,Testability,assert,assert,1444,"Avoid connecting the DNS and avoid using getaddrinfo and instead scan the list of network interface. In many cases those 2 operations were taking a significant amount of time during startup (in few cases; more than 5s). In some cases (e.g. MacOS and possibly other WiFi use) the hostname is actually not registered and; consequently the search failed anyway .... One drawback of the scan is that there is no cheap way to tell which of the IP4 addresses listed is; the 'public' address since only information are IP, port and name ... and the name is more or so; arbitrary (different on BSD and linux, depends on VPN or bridge, etc) ... so for now we just (try; to) skip the loopback interface. A better technique (which would lead again to a 'spurrious' startup delay) is to open a socket to; a known server (eg google's DNS 8.8.8.8) and then interogate the socket to find out the IP seen; by the server.; For example with (https://stackoverflow.com/questions/212528/get-the-ip-address-of-the-machine); ```; void GetPrimaryIp(char* buffer, size_t buflen); {; assert(buflen >= 16);. int sock = socket(AF_INET, SOCK_DGRAM, 0);; assert(sock != -1);. const char* kGoogleDnsIp = 8.8.8.8;; uint16_t kDnsPort = 53;; struct sockaddr_in serv;; memset(&serv, 0, sizeof(serv));; serv.sin_family = AF_INET;; serv.sin_addr.s_addr = inet_addr(kGoogleDnsIp);; serv.sin_port = htons(kDnsPort);. int err = connect(sock, (const sockaddr*) &serv, sizeof(serv));; assert(err != -1);. sockaddr_in name;; socklen_t namelen = sizeof(name);; err = getsockname(sock, (sockaddr*) &name, &namelen);; assert(err != -1);. const char* p = inet_ntop(AF_INET, &name.sin_addr, buffer, buflen);; assert(p);. close(sock);; }; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4310
https://github.com/root-project/root/pull/4310:1573,Testability,assert,assert,1573,"Avoid connecting the DNS and avoid using getaddrinfo and instead scan the list of network interface. In many cases those 2 operations were taking a significant amount of time during startup (in few cases; more than 5s). In some cases (e.g. MacOS and possibly other WiFi use) the hostname is actually not registered and; consequently the search failed anyway .... One drawback of the scan is that there is no cheap way to tell which of the IP4 addresses listed is; the 'public' address since only information are IP, port and name ... and the name is more or so; arbitrary (different on BSD and linux, depends on VPN or bridge, etc) ... so for now we just (try; to) skip the loopback interface. A better technique (which would lead again to a 'spurrious' startup delay) is to open a socket to; a known server (eg google's DNS 8.8.8.8) and then interogate the socket to find out the IP seen; by the server.; For example with (https://stackoverflow.com/questions/212528/get-the-ip-address-of-the-machine); ```; void GetPrimaryIp(char* buffer, size_t buflen); {; assert(buflen >= 16);. int sock = socket(AF_INET, SOCK_DGRAM, 0);; assert(sock != -1);. const char* kGoogleDnsIp = 8.8.8.8;; uint16_t kDnsPort = 53;; struct sockaddr_in serv;; memset(&serv, 0, sizeof(serv));; serv.sin_family = AF_INET;; serv.sin_addr.s_addr = inet_addr(kGoogleDnsIp);; serv.sin_port = htons(kDnsPort);. int err = connect(sock, (const sockaddr*) &serv, sizeof(serv));; assert(err != -1);. sockaddr_in name;; socklen_t namelen = sizeof(name);; err = getsockname(sock, (sockaddr*) &name, &namelen);; assert(err != -1);. const char* p = inet_ntop(AF_INET, &name.sin_addr, buffer, buflen);; assert(p);. close(sock);; }; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4310
https://github.com/root-project/root/pull/4310:1662,Testability,assert,assert,1662,"Avoid connecting the DNS and avoid using getaddrinfo and instead scan the list of network interface. In many cases those 2 operations were taking a significant amount of time during startup (in few cases; more than 5s). In some cases (e.g. MacOS and possibly other WiFi use) the hostname is actually not registered and; consequently the search failed anyway .... One drawback of the scan is that there is no cheap way to tell which of the IP4 addresses listed is; the 'public' address since only information are IP, port and name ... and the name is more or so; arbitrary (different on BSD and linux, depends on VPN or bridge, etc) ... so for now we just (try; to) skip the loopback interface. A better technique (which would lead again to a 'spurrious' startup delay) is to open a socket to; a known server (eg google's DNS 8.8.8.8) and then interogate the socket to find out the IP seen; by the server.; For example with (https://stackoverflow.com/questions/212528/get-the-ip-address-of-the-machine); ```; void GetPrimaryIp(char* buffer, size_t buflen); {; assert(buflen >= 16);. int sock = socket(AF_INET, SOCK_DGRAM, 0);; assert(sock != -1);. const char* kGoogleDnsIp = 8.8.8.8;; uint16_t kDnsPort = 53;; struct sockaddr_in serv;; memset(&serv, 0, sizeof(serv));; serv.sin_family = AF_INET;; serv.sin_addr.s_addr = inet_addr(kGoogleDnsIp);; serv.sin_port = htons(kDnsPort);. int err = connect(sock, (const sockaddr*) &serv, sizeof(serv));; assert(err != -1);. sockaddr_in name;; socklen_t namelen = sizeof(name);; err = getsockname(sock, (sockaddr*) &name, &namelen);; assert(err != -1);. const char* p = inet_ntop(AF_INET, &name.sin_addr, buffer, buflen);; assert(p);. close(sock);; }; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4310
https://github.com/root-project/root/pull/4316:57,Availability,failure,failure,57,"The commit mentioned in the title was leading to a build failure, fixed with this PR.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4316
https://github.com/root-project/root/pull/4318:393,Safety,avoid,avoid,393,"As pointed out in ROOT-10294, when using the CMSSW environment,; the lookup of an enum constant in the list of attributes of; the namespace does not succeed. This commit passes on the TEnum obtained when creating the; namespace proxy to the addition of the enum constants as; properties of the namespace, so that the underlying type of; the enum can be taken from the TEnum, and therefore we; avoid the lookup in the list of attributes of the namespace.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4318
https://github.com/root-project/root/pull/4320:272,Safety,avoid,avoid,272,"see https://sft.its.cern.ch/jira/browse/ROOT-10300. If sub-class of TObject uses `=default` specifier for default constructor, all members (including from TObject) are initialized. By this special logic for TObject::kIsOnHeap bit is corrupted. The only solution for now - avoid such `= default` specifier.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4320
https://github.com/root-project/root/pull/4320:197,Testability,log,logic,197,"see https://sft.its.cern.ch/jira/browse/ROOT-10300. If sub-class of TObject uses `=default` specifier for default constructor, all members (including from TObject) are initialized. By this special logic for TObject::kIsOnHeap bit is corrupted. The only solution for now - avoid such `= default` specifier.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4320
https://github.com/root-project/root/pull/4330:18,Integrability,message,messages,18,Please see commit messages for more details.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4330
https://github.com/root-project/root/pull/4337:494,Integrability,interface,interface,494,"Feature: Save training progress to root file, present it in TMVAGui. Add training history object for TMVA, here I incorporate usage to log DNN epoch performance with DNN_CPU and PyKeras. The tool is intended to be general enough that it can be used by any ML algorithm. For example, XGBoost could also record its progress per iteration with this object. A request for this functionality can be found on the root forums; https://root-forum.cern.ch/t/how-to-get-training-history-using-tmva-keras-interface/28799. My solution does not require tensorboard and records are stored within the root file. Test:; ```; . bin/thisroot.sh; cd tutorials/tmva/; make; ./TMVAClassification; root -l; TMVA::TMVAGui(""TMVA.root""); //Click on Training History... See the DNN_CPU_valError and trainingError plotted, not that data points are only added for every epoch printed in MethodDNN.cxx ; .q. cd keras; python ClassificationKeras.py; root -l; TMVA::TMVAGui(""TMVA.root""); //Click on Training History... See Keras training history for PyKeras_val_acc, PyKeras_acc, PyKeras_loss and PyKeras_val_loss; ```. Feedback welcomed",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4337
https://github.com/root-project/root/pull/4337:149,Performance,perform,performance,149,"Feature: Save training progress to root file, present it in TMVAGui. Add training history object for TMVA, here I incorporate usage to log DNN epoch performance with DNN_CPU and PyKeras. The tool is intended to be general enough that it can be used by any ML algorithm. For example, XGBoost could also record its progress per iteration with this object. A request for this functionality can be found on the root forums; https://root-forum.cern.ch/t/how-to-get-training-history-using-tmva-keras-interface/28799. My solution does not require tensorboard and records are stored within the root file. Test:; ```; . bin/thisroot.sh; cd tutorials/tmva/; make; ./TMVAClassification; root -l; TMVA::TMVAGui(""TMVA.root""); //Click on Training History... See the DNN_CPU_valError and trainingError plotted, not that data points are only added for every epoch printed in MethodDNN.cxx ; .q. cd keras; python ClassificationKeras.py; root -l; TMVA::TMVAGui(""TMVA.root""); //Click on Training History... See Keras training history for PyKeras_val_acc, PyKeras_acc, PyKeras_loss and PyKeras_val_loss; ```. Feedback welcomed",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4337
https://github.com/root-project/root/pull/4337:135,Testability,log,log,135,"Feature: Save training progress to root file, present it in TMVAGui. Add training history object for TMVA, here I incorporate usage to log DNN epoch performance with DNN_CPU and PyKeras. The tool is intended to be general enough that it can be used by any ML algorithm. For example, XGBoost could also record its progress per iteration with this object. A request for this functionality can be found on the root forums; https://root-forum.cern.ch/t/how-to-get-training-history-using-tmva-keras-interface/28799. My solution does not require tensorboard and records are stored within the root file. Test:; ```; . bin/thisroot.sh; cd tutorials/tmva/; make; ./TMVAClassification; root -l; TMVA::TMVAGui(""TMVA.root""); //Click on Training History... See the DNN_CPU_valError and trainingError plotted, not that data points are only added for every epoch printed in MethodDNN.cxx ; .q. cd keras; python ClassificationKeras.py; root -l; TMVA::TMVAGui(""TMVA.root""); //Click on Training History... See Keras training history for PyKeras_val_acc, PyKeras_acc, PyKeras_loss and PyKeras_val_loss; ```. Feedback welcomed",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4337
https://github.com/root-project/root/pull/4337:597,Testability,Test,Test,597,"Feature: Save training progress to root file, present it in TMVAGui. Add training history object for TMVA, here I incorporate usage to log DNN epoch performance with DNN_CPU and PyKeras. The tool is intended to be general enough that it can be used by any ML algorithm. For example, XGBoost could also record its progress per iteration with this object. A request for this functionality can be found on the root forums; https://root-forum.cern.ch/t/how-to-get-training-history-using-tmva-keras-interface/28799. My solution does not require tensorboard and records are stored within the root file. Test:; ```; . bin/thisroot.sh; cd tutorials/tmva/; make; ./TMVAClassification; root -l; TMVA::TMVAGui(""TMVA.root""); //Click on Training History... See the DNN_CPU_valError and trainingError plotted, not that data points are only added for every epoch printed in MethodDNN.cxx ; .q. cd keras; python ClassificationKeras.py; root -l; TMVA::TMVAGui(""TMVA.root""); //Click on Training History... See Keras training history for PyKeras_val_acc, PyKeras_acc, PyKeras_loss and PyKeras_val_loss; ```. Feedback welcomed",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4337
https://github.com/root-project/root/pull/4337:1089,Usability,Feedback,Feedback,1089,"Feature: Save training progress to root file, present it in TMVAGui. Add training history object for TMVA, here I incorporate usage to log DNN epoch performance with DNN_CPU and PyKeras. The tool is intended to be general enough that it can be used by any ML algorithm. For example, XGBoost could also record its progress per iteration with this object. A request for this functionality can be found on the root forums; https://root-forum.cern.ch/t/how-to-get-training-history-using-tmva-keras-interface/28799. My solution does not require tensorboard and records are stored within the root file. Test:; ```; . bin/thisroot.sh; cd tutorials/tmva/; make; ./TMVAClassification; root -l; TMVA::TMVAGui(""TMVA.root""); //Click on Training History... See the DNN_CPU_valError and trainingError plotted, not that data points are only added for every epoch printed in MethodDNN.cxx ; .q. cd keras; python ClassificationKeras.py; root -l; TMVA::TMVAGui(""TMVA.root""); //Click on Training History... See Keras training history for PyKeras_val_acc, PyKeras_acc, PyKeras_loss and PyKeras_val_loss; ```. Feedback welcomed",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4337
https://github.com/root-project/root/pull/4339:868,Availability,failure,failure,868,"Over the years we have a pathological issue with cling when it calls directly; compiler API. Most of the API assume they are called from code residing in a; text file. This code has valid source locations which can be used for; comparisons and things like point of instantiation for template instantiations. This means that whenever a clang API requires a valid source location, cling; should have an interface which gives a pseudo-valid, commonly-rooted unique; source location. We are bitten by this fact when preloading modules as if we have diagnostics; they cannot be ordered due to the fact that the compared decls from two; different modules do not have a common includer. This patch avoids using an API and relies on a textual form which does not have; this problem at the cost of synthesizing an extra string. This should fix the roottest python stl-stl test failure in the incremental builds.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4339
https://github.com/root-project/root/pull/4339:685,Deployability,patch,patch,685,"Over the years we have a pathological issue with cling when it calls directly; compiler API. Most of the API assume they are called from code residing in a; text file. This code has valid source locations which can be used for; comparisons and things like point of instantiation for template instantiations. This means that whenever a clang API requires a valid source location, cling; should have an interface which gives a pseudo-valid, commonly-rooted unique; source location. We are bitten by this fact when preloading modules as if we have diagnostics; they cannot be ordered due to the fact that the compared decls from two; different modules do not have a common includer. This patch avoids using an API and relies on a textual form which does not have; this problem at the cost of synthesizing an extra string. This should fix the roottest python stl-stl test failure in the incremental builds.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4339
https://github.com/root-project/root/pull/4339:401,Integrability,interface,interface,401,"Over the years we have a pathological issue with cling when it calls directly; compiler API. Most of the API assume they are called from code residing in a; text file. This code has valid source locations which can be used for; comparisons and things like point of instantiation for template instantiations. This means that whenever a clang API requires a valid source location, cling; should have an interface which gives a pseudo-valid, commonly-rooted unique; source location. We are bitten by this fact when preloading modules as if we have diagnostics; they cannot be ordered due to the fact that the compared decls from two; different modules do not have a common includer. This patch avoids using an API and relies on a textual form which does not have; this problem at the cost of synthesizing an extra string. This should fix the roottest python stl-stl test failure in the incremental builds.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4339
https://github.com/root-project/root/pull/4339:691,Safety,avoid,avoids,691,"Over the years we have a pathological issue with cling when it calls directly; compiler API. Most of the API assume they are called from code residing in a; text file. This code has valid source locations which can be used for; comparisons and things like point of instantiation for template instantiations. This means that whenever a clang API requires a valid source location, cling; should have an interface which gives a pseudo-valid, commonly-rooted unique; source location. We are bitten by this fact when preloading modules as if we have diagnostics; they cannot be ordered due to the fact that the compared decls from two; different modules do not have a common includer. This patch avoids using an API and relies on a textual form which does not have; this problem at the cost of synthesizing an extra string. This should fix the roottest python stl-stl test failure in the incremental builds.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4339
https://github.com/root-project/root/pull/4339:863,Testability,test,test,863,"Over the years we have a pathological issue with cling when it calls directly; compiler API. Most of the API assume they are called from code residing in a; text file. This code has valid source locations which can be used for; comparisons and things like point of instantiation for template instantiations. This means that whenever a clang API requires a valid source location, cling; should have an interface which gives a pseudo-valid, commonly-rooted unique; source location. We are bitten by this fact when preloading modules as if we have diagnostics; they cannot be ordered due to the fact that the compared decls from two; different modules do not have a common includer. This patch avoids using an API and relies on a textual form which does not have; this problem at the cost of synthesizing an extra string. This should fix the roottest python stl-stl test failure in the incremental builds.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4339
https://github.com/root-project/root/pull/4342:11,Integrability,message,message,11,See commit message for more details.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4342
https://github.com/root-project/root/pull/4349:25,Availability,failure,failures,25,Should address the Gaudi failures reported in ROOT-10303.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4349
https://github.com/root-project/root/pull/4351:2890,Availability,echo,echo,2890,"ils.py. ### Setup script for ubuntu 18.04; It sets up a new machine, installing everything in the home folder. Please modify for your needs.; ```bash; #!/bin/bash; cd; # can be ran with yes | bash this_file.sh # to say yes when prompted. sudo apt update ; yes | sudo apt upgrade. # Install all the stuff with apt. sudo apt install clang # to use clang; sudo apt install g++-7 gcc-7 # to use gcc; sudo apt install libx11-dev build-essential cmake ; sudo apt install git dpkg-dev cmake binutils libx11-dev libxpm-dev \; libxft-dev libxext-dev; sudo apt-get install gfortran libssl-dev libpcre3-dev \; xlibmesa-glu-dev libglew1.5-dev libftgl-dev \; libmysqlclient-dev libfftw3-dev libcfitsio-dev \; graphviz-dev libavahi-compat-libdnssd-dev \; libldap2-dev python-dev libxml2-dev libkrb5-dev \; libgsl0-dev libqt4-dev; sudo apt install gdb. sudo apt install libstdc++ # then add flag -stdlib=libstdc++. wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh; (echo ''; echo 'yes'; echo ''; echo 'yes';) | bash ./Miniconda3-latest-Linux-x86_64.sh; source .bashrc; source activate base; pip install numpy sklearn xgboost matplotlib. #################################### install projects #############################3; # Get ROOT; cd; git clone git@github.com:LucaZampieri/root.git. # build with gcc; mkdir build_gcc && cd build_gcc && cmake ../root && make -j8. ## Google bench; cd; # Check out the library.; git clone https://github.com/google/benchmark.git; # Benchmark requires Google Test as a dependency. Add the source tree as a subdirectory.; git clone https://github.com/google/googletest.git benchmark/googletest. # Go to the library root directory; cd benchmark ; mkdir build_gcc; cd build_gcc ; cmake -DCMAKE_BUILD_TYPE=Release ../root && make -j8. # XGBoost; cd; git clone --recursive https://github.com/dmlc/xgboost; cd xgboost; mkdir build_gcc; cd build_gcc; cmake -DCMAKE_BUILD_TYPE=Release ../. # Setup aliases; echo ""alias bdt='cd ~/root/tmva/tmva/src/BDT'"" >> ~/.bas",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4351
https://github.com/root-project/root/pull/4351:2899,Availability,echo,echo,2899,"ils.py. ### Setup script for ubuntu 18.04; It sets up a new machine, installing everything in the home folder. Please modify for your needs.; ```bash; #!/bin/bash; cd; # can be ran with yes | bash this_file.sh # to say yes when prompted. sudo apt update ; yes | sudo apt upgrade. # Install all the stuff with apt. sudo apt install clang # to use clang; sudo apt install g++-7 gcc-7 # to use gcc; sudo apt install libx11-dev build-essential cmake ; sudo apt install git dpkg-dev cmake binutils libx11-dev libxpm-dev \; libxft-dev libxext-dev; sudo apt-get install gfortran libssl-dev libpcre3-dev \; xlibmesa-glu-dev libglew1.5-dev libftgl-dev \; libmysqlclient-dev libfftw3-dev libcfitsio-dev \; graphviz-dev libavahi-compat-libdnssd-dev \; libldap2-dev python-dev libxml2-dev libkrb5-dev \; libgsl0-dev libqt4-dev; sudo apt install gdb. sudo apt install libstdc++ # then add flag -stdlib=libstdc++. wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh; (echo ''; echo 'yes'; echo ''; echo 'yes';) | bash ./Miniconda3-latest-Linux-x86_64.sh; source .bashrc; source activate base; pip install numpy sklearn xgboost matplotlib. #################################### install projects #############################3; # Get ROOT; cd; git clone git@github.com:LucaZampieri/root.git. # build with gcc; mkdir build_gcc && cd build_gcc && cmake ../root && make -j8. ## Google bench; cd; # Check out the library.; git clone https://github.com/google/benchmark.git; # Benchmark requires Google Test as a dependency. Add the source tree as a subdirectory.; git clone https://github.com/google/googletest.git benchmark/googletest. # Go to the library root directory; cd benchmark ; mkdir build_gcc; cd build_gcc ; cmake -DCMAKE_BUILD_TYPE=Release ../root && make -j8. # XGBoost; cd; git clone --recursive https://github.com/dmlc/xgboost; cd xgboost; mkdir build_gcc; cd build_gcc; cmake -DCMAKE_BUILD_TYPE=Release ../. # Setup aliases; echo ""alias bdt='cd ~/root/tmva/tmva/src/BDT'"" >> ~/.bas",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4351
https://github.com/root-project/root/pull/4351:2911,Availability,echo,echo,2911,"ils.py. ### Setup script for ubuntu 18.04; It sets up a new machine, installing everything in the home folder. Please modify for your needs.; ```bash; #!/bin/bash; cd; # can be ran with yes | bash this_file.sh # to say yes when prompted. sudo apt update ; yes | sudo apt upgrade. # Install all the stuff with apt. sudo apt install clang # to use clang; sudo apt install g++-7 gcc-7 # to use gcc; sudo apt install libx11-dev build-essential cmake ; sudo apt install git dpkg-dev cmake binutils libx11-dev libxpm-dev \; libxft-dev libxext-dev; sudo apt-get install gfortran libssl-dev libpcre3-dev \; xlibmesa-glu-dev libglew1.5-dev libftgl-dev \; libmysqlclient-dev libfftw3-dev libcfitsio-dev \; graphviz-dev libavahi-compat-libdnssd-dev \; libldap2-dev python-dev libxml2-dev libkrb5-dev \; libgsl0-dev libqt4-dev; sudo apt install gdb. sudo apt install libstdc++ # then add flag -stdlib=libstdc++. wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh; (echo ''; echo 'yes'; echo ''; echo 'yes';) | bash ./Miniconda3-latest-Linux-x86_64.sh; source .bashrc; source activate base; pip install numpy sklearn xgboost matplotlib. #################################### install projects #############################3; # Get ROOT; cd; git clone git@github.com:LucaZampieri/root.git. # build with gcc; mkdir build_gcc && cd build_gcc && cmake ../root && make -j8. ## Google bench; cd; # Check out the library.; git clone https://github.com/google/benchmark.git; # Benchmark requires Google Test as a dependency. Add the source tree as a subdirectory.; git clone https://github.com/google/googletest.git benchmark/googletest. # Go to the library root directory; cd benchmark ; mkdir build_gcc; cd build_gcc ; cmake -DCMAKE_BUILD_TYPE=Release ../root && make -j8. # XGBoost; cd; git clone --recursive https://github.com/dmlc/xgboost; cd xgboost; mkdir build_gcc; cd build_gcc; cmake -DCMAKE_BUILD_TYPE=Release ../. # Setup aliases; echo ""alias bdt='cd ~/root/tmva/tmva/src/BDT'"" >> ~/.bas",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4351
https://github.com/root-project/root/pull/4351:2920,Availability,echo,echo,2920,"ils.py. ### Setup script for ubuntu 18.04; It sets up a new machine, installing everything in the home folder. Please modify for your needs.; ```bash; #!/bin/bash; cd; # can be ran with yes | bash this_file.sh # to say yes when prompted. sudo apt update ; yes | sudo apt upgrade. # Install all the stuff with apt. sudo apt install clang # to use clang; sudo apt install g++-7 gcc-7 # to use gcc; sudo apt install libx11-dev build-essential cmake ; sudo apt install git dpkg-dev cmake binutils libx11-dev libxpm-dev \; libxft-dev libxext-dev; sudo apt-get install gfortran libssl-dev libpcre3-dev \; xlibmesa-glu-dev libglew1.5-dev libftgl-dev \; libmysqlclient-dev libfftw3-dev libcfitsio-dev \; graphviz-dev libavahi-compat-libdnssd-dev \; libldap2-dev python-dev libxml2-dev libkrb5-dev \; libgsl0-dev libqt4-dev; sudo apt install gdb. sudo apt install libstdc++ # then add flag -stdlib=libstdc++. wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh; (echo ''; echo 'yes'; echo ''; echo 'yes';) | bash ./Miniconda3-latest-Linux-x86_64.sh; source .bashrc; source activate base; pip install numpy sklearn xgboost matplotlib. #################################### install projects #############################3; # Get ROOT; cd; git clone git@github.com:LucaZampieri/root.git. # build with gcc; mkdir build_gcc && cd build_gcc && cmake ../root && make -j8. ## Google bench; cd; # Check out the library.; git clone https://github.com/google/benchmark.git; # Benchmark requires Google Test as a dependency. Add the source tree as a subdirectory.; git clone https://github.com/google/googletest.git benchmark/googletest. # Go to the library root directory; cd benchmark ; mkdir build_gcc; cd build_gcc ; cmake -DCMAKE_BUILD_TYPE=Release ../root && make -j8. # XGBoost; cd; git clone --recursive https://github.com/dmlc/xgboost; cd xgboost; mkdir build_gcc; cd build_gcc; cmake -DCMAKE_BUILD_TYPE=Release ../. # Setup aliases; echo ""alias bdt='cd ~/root/tmva/tmva/src/BDT'"" >> ~/.bas",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4351
https://github.com/root-project/root/pull/4351:3857,Availability,echo,echo,3857,"git dpkg-dev cmake binutils libx11-dev libxpm-dev \; libxft-dev libxext-dev; sudo apt-get install gfortran libssl-dev libpcre3-dev \; xlibmesa-glu-dev libglew1.5-dev libftgl-dev \; libmysqlclient-dev libfftw3-dev libcfitsio-dev \; graphviz-dev libavahi-compat-libdnssd-dev \; libldap2-dev python-dev libxml2-dev libkrb5-dev \; libgsl0-dev libqt4-dev; sudo apt install gdb. sudo apt install libstdc++ # then add flag -stdlib=libstdc++. wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh; (echo ''; echo 'yes'; echo ''; echo 'yes';) | bash ./Miniconda3-latest-Linux-x86_64.sh; source .bashrc; source activate base; pip install numpy sklearn xgboost matplotlib. #################################### install projects #############################3; # Get ROOT; cd; git clone git@github.com:LucaZampieri/root.git. # build with gcc; mkdir build_gcc && cd build_gcc && cmake ../root && make -j8. ## Google bench; cd; # Check out the library.; git clone https://github.com/google/benchmark.git; # Benchmark requires Google Test as a dependency. Add the source tree as a subdirectory.; git clone https://github.com/google/googletest.git benchmark/googletest. # Go to the library root directory; cd benchmark ; mkdir build_gcc; cd build_gcc ; cmake -DCMAKE_BUILD_TYPE=Release ../root && make -j8. # XGBoost; cd; git clone --recursive https://github.com/dmlc/xgboost; cd xgboost; mkdir build_gcc; cd build_gcc; cmake -DCMAKE_BUILD_TYPE=Release ../. # Setup aliases; echo ""alias bdt='cd ~/root/tmva/tmva/src/BDT'"" >> ~/.bashrc; source .bashrc. # Add the folders missing from github (add them directly in github?) ; cd; bdt ; git checkout backend/FastInference; mkdir build. # For ROOT; echo 'export ROOTSYS=""~/root/""' >> ~/.bashrc; echo 'export ROOTBUILD=""~/build_gcc/""' >> ~/.bashrc; echo 'source $ROOTBUILD/bin/thisroot.sh' >> ~/.bashrc. echo 'export XGBOOST_ROOT=""~/xgboost""' >> ~/.bashrc. echo 'export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:~/xgboost/lib/' >> ~/.bashrc. source .bashrc; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4351
https://github.com/root-project/root/pull/4351:4076,Availability,echo,echo,4076,"git dpkg-dev cmake binutils libx11-dev libxpm-dev \; libxft-dev libxext-dev; sudo apt-get install gfortran libssl-dev libpcre3-dev \; xlibmesa-glu-dev libglew1.5-dev libftgl-dev \; libmysqlclient-dev libfftw3-dev libcfitsio-dev \; graphviz-dev libavahi-compat-libdnssd-dev \; libldap2-dev python-dev libxml2-dev libkrb5-dev \; libgsl0-dev libqt4-dev; sudo apt install gdb. sudo apt install libstdc++ # then add flag -stdlib=libstdc++. wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh; (echo ''; echo 'yes'; echo ''; echo 'yes';) | bash ./Miniconda3-latest-Linux-x86_64.sh; source .bashrc; source activate base; pip install numpy sklearn xgboost matplotlib. #################################### install projects #############################3; # Get ROOT; cd; git clone git@github.com:LucaZampieri/root.git. # build with gcc; mkdir build_gcc && cd build_gcc && cmake ../root && make -j8. ## Google bench; cd; # Check out the library.; git clone https://github.com/google/benchmark.git; # Benchmark requires Google Test as a dependency. Add the source tree as a subdirectory.; git clone https://github.com/google/googletest.git benchmark/googletest. # Go to the library root directory; cd benchmark ; mkdir build_gcc; cd build_gcc ; cmake -DCMAKE_BUILD_TYPE=Release ../root && make -j8. # XGBoost; cd; git clone --recursive https://github.com/dmlc/xgboost; cd xgboost; mkdir build_gcc; cd build_gcc; cmake -DCMAKE_BUILD_TYPE=Release ../. # Setup aliases; echo ""alias bdt='cd ~/root/tmva/tmva/src/BDT'"" >> ~/.bashrc; source .bashrc. # Add the folders missing from github (add them directly in github?) ; cd; bdt ; git checkout backend/FastInference; mkdir build. # For ROOT; echo 'export ROOTSYS=""~/root/""' >> ~/.bashrc; echo 'export ROOTBUILD=""~/build_gcc/""' >> ~/.bashrc; echo 'source $ROOTBUILD/bin/thisroot.sh' >> ~/.bashrc. echo 'export XGBOOST_ROOT=""~/xgboost""' >> ~/.bashrc. echo 'export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:~/xgboost/lib/' >> ~/.bashrc. source .bashrc; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4351
https://github.com/root-project/root/pull/4351:4122,Availability,echo,echo,4122,"git dpkg-dev cmake binutils libx11-dev libxpm-dev \; libxft-dev libxext-dev; sudo apt-get install gfortran libssl-dev libpcre3-dev \; xlibmesa-glu-dev libglew1.5-dev libftgl-dev \; libmysqlclient-dev libfftw3-dev libcfitsio-dev \; graphviz-dev libavahi-compat-libdnssd-dev \; libldap2-dev python-dev libxml2-dev libkrb5-dev \; libgsl0-dev libqt4-dev; sudo apt install gdb. sudo apt install libstdc++ # then add flag -stdlib=libstdc++. wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh; (echo ''; echo 'yes'; echo ''; echo 'yes';) | bash ./Miniconda3-latest-Linux-x86_64.sh; source .bashrc; source activate base; pip install numpy sklearn xgboost matplotlib. #################################### install projects #############################3; # Get ROOT; cd; git clone git@github.com:LucaZampieri/root.git. # build with gcc; mkdir build_gcc && cd build_gcc && cmake ../root && make -j8. ## Google bench; cd; # Check out the library.; git clone https://github.com/google/benchmark.git; # Benchmark requires Google Test as a dependency. Add the source tree as a subdirectory.; git clone https://github.com/google/googletest.git benchmark/googletest. # Go to the library root directory; cd benchmark ; mkdir build_gcc; cd build_gcc ; cmake -DCMAKE_BUILD_TYPE=Release ../root && make -j8. # XGBoost; cd; git clone --recursive https://github.com/dmlc/xgboost; cd xgboost; mkdir build_gcc; cd build_gcc; cmake -DCMAKE_BUILD_TYPE=Release ../. # Setup aliases; echo ""alias bdt='cd ~/root/tmva/tmva/src/BDT'"" >> ~/.bashrc; source .bashrc. # Add the folders missing from github (add them directly in github?) ; cd; bdt ; git checkout backend/FastInference; mkdir build. # For ROOT; echo 'export ROOTSYS=""~/root/""' >> ~/.bashrc; echo 'export ROOTBUILD=""~/build_gcc/""' >> ~/.bashrc; echo 'source $ROOTBUILD/bin/thisroot.sh' >> ~/.bashrc. echo 'export XGBOOST_ROOT=""~/xgboost""' >> ~/.bashrc. echo 'export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:~/xgboost/lib/' >> ~/.bashrc. source .bashrc; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4351
https://github.com/root-project/root/pull/4351:4175,Availability,echo,echo,4175,"git dpkg-dev cmake binutils libx11-dev libxpm-dev \; libxft-dev libxext-dev; sudo apt-get install gfortran libssl-dev libpcre3-dev \; xlibmesa-glu-dev libglew1.5-dev libftgl-dev \; libmysqlclient-dev libfftw3-dev libcfitsio-dev \; graphviz-dev libavahi-compat-libdnssd-dev \; libldap2-dev python-dev libxml2-dev libkrb5-dev \; libgsl0-dev libqt4-dev; sudo apt install gdb. sudo apt install libstdc++ # then add flag -stdlib=libstdc++. wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh; (echo ''; echo 'yes'; echo ''; echo 'yes';) | bash ./Miniconda3-latest-Linux-x86_64.sh; source .bashrc; source activate base; pip install numpy sklearn xgboost matplotlib. #################################### install projects #############################3; # Get ROOT; cd; git clone git@github.com:LucaZampieri/root.git. # build with gcc; mkdir build_gcc && cd build_gcc && cmake ../root && make -j8. ## Google bench; cd; # Check out the library.; git clone https://github.com/google/benchmark.git; # Benchmark requires Google Test as a dependency. Add the source tree as a subdirectory.; git clone https://github.com/google/googletest.git benchmark/googletest. # Go to the library root directory; cd benchmark ; mkdir build_gcc; cd build_gcc ; cmake -DCMAKE_BUILD_TYPE=Release ../root && make -j8. # XGBoost; cd; git clone --recursive https://github.com/dmlc/xgboost; cd xgboost; mkdir build_gcc; cd build_gcc; cmake -DCMAKE_BUILD_TYPE=Release ../. # Setup aliases; echo ""alias bdt='cd ~/root/tmva/tmva/src/BDT'"" >> ~/.bashrc; source .bashrc. # Add the folders missing from github (add them directly in github?) ; cd; bdt ; git checkout backend/FastInference; mkdir build. # For ROOT; echo 'export ROOTSYS=""~/root/""' >> ~/.bashrc; echo 'export ROOTBUILD=""~/build_gcc/""' >> ~/.bashrc; echo 'source $ROOTBUILD/bin/thisroot.sh' >> ~/.bashrc. echo 'export XGBOOST_ROOT=""~/xgboost""' >> ~/.bashrc. echo 'export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:~/xgboost/lib/' >> ~/.bashrc. source .bashrc; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4351
https://github.com/root-project/root/pull/4351:4230,Availability,echo,echo,4230,"git dpkg-dev cmake binutils libx11-dev libxpm-dev \; libxft-dev libxext-dev; sudo apt-get install gfortran libssl-dev libpcre3-dev \; xlibmesa-glu-dev libglew1.5-dev libftgl-dev \; libmysqlclient-dev libfftw3-dev libcfitsio-dev \; graphviz-dev libavahi-compat-libdnssd-dev \; libldap2-dev python-dev libxml2-dev libkrb5-dev \; libgsl0-dev libqt4-dev; sudo apt install gdb. sudo apt install libstdc++ # then add flag -stdlib=libstdc++. wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh; (echo ''; echo 'yes'; echo ''; echo 'yes';) | bash ./Miniconda3-latest-Linux-x86_64.sh; source .bashrc; source activate base; pip install numpy sklearn xgboost matplotlib. #################################### install projects #############################3; # Get ROOT; cd; git clone git@github.com:LucaZampieri/root.git. # build with gcc; mkdir build_gcc && cd build_gcc && cmake ../root && make -j8. ## Google bench; cd; # Check out the library.; git clone https://github.com/google/benchmark.git; # Benchmark requires Google Test as a dependency. Add the source tree as a subdirectory.; git clone https://github.com/google/googletest.git benchmark/googletest. # Go to the library root directory; cd benchmark ; mkdir build_gcc; cd build_gcc ; cmake -DCMAKE_BUILD_TYPE=Release ../root && make -j8. # XGBoost; cd; git clone --recursive https://github.com/dmlc/xgboost; cd xgboost; mkdir build_gcc; cd build_gcc; cmake -DCMAKE_BUILD_TYPE=Release ../. # Setup aliases; echo ""alias bdt='cd ~/root/tmva/tmva/src/BDT'"" >> ~/.bashrc; source .bashrc. # Add the folders missing from github (add them directly in github?) ; cd; bdt ; git checkout backend/FastInference; mkdir build. # For ROOT; echo 'export ROOTSYS=""~/root/""' >> ~/.bashrc; echo 'export ROOTBUILD=""~/build_gcc/""' >> ~/.bashrc; echo 'source $ROOTBUILD/bin/thisroot.sh' >> ~/.bashrc. echo 'export XGBOOST_ROOT=""~/xgboost""' >> ~/.bashrc. echo 'export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:~/xgboost/lib/' >> ~/.bashrc. source .bashrc; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4351
https://github.com/root-project/root/pull/4351:4283,Availability,echo,echo,4283,"git dpkg-dev cmake binutils libx11-dev libxpm-dev \; libxft-dev libxext-dev; sudo apt-get install gfortran libssl-dev libpcre3-dev \; xlibmesa-glu-dev libglew1.5-dev libftgl-dev \; libmysqlclient-dev libfftw3-dev libcfitsio-dev \; graphviz-dev libavahi-compat-libdnssd-dev \; libldap2-dev python-dev libxml2-dev libkrb5-dev \; libgsl0-dev libqt4-dev; sudo apt install gdb. sudo apt install libstdc++ # then add flag -stdlib=libstdc++. wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh; (echo ''; echo 'yes'; echo ''; echo 'yes';) | bash ./Miniconda3-latest-Linux-x86_64.sh; source .bashrc; source activate base; pip install numpy sklearn xgboost matplotlib. #################################### install projects #############################3; # Get ROOT; cd; git clone git@github.com:LucaZampieri/root.git. # build with gcc; mkdir build_gcc && cd build_gcc && cmake ../root && make -j8. ## Google bench; cd; # Check out the library.; git clone https://github.com/google/benchmark.git; # Benchmark requires Google Test as a dependency. Add the source tree as a subdirectory.; git clone https://github.com/google/googletest.git benchmark/googletest. # Go to the library root directory; cd benchmark ; mkdir build_gcc; cd build_gcc ; cmake -DCMAKE_BUILD_TYPE=Release ../root && make -j8. # XGBoost; cd; git clone --recursive https://github.com/dmlc/xgboost; cd xgboost; mkdir build_gcc; cd build_gcc; cmake -DCMAKE_BUILD_TYPE=Release ../. # Setup aliases; echo ""alias bdt='cd ~/root/tmva/tmva/src/BDT'"" >> ~/.bashrc; source .bashrc. # Add the folders missing from github (add them directly in github?) ; cd; bdt ; git checkout backend/FastInference; mkdir build. # For ROOT; echo 'export ROOTSYS=""~/root/""' >> ~/.bashrc; echo 'export ROOTBUILD=""~/build_gcc/""' >> ~/.bashrc; echo 'source $ROOTBUILD/bin/thisroot.sh' >> ~/.bashrc. echo 'export XGBOOST_ROOT=""~/xgboost""' >> ~/.bashrc. echo 'export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:~/xgboost/lib/' >> ~/.bashrc. source .bashrc; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4351
https://github.com/root-project/root/pull/4351:156,Deployability,integrat,integrate,156,"# This PR is not meant to be merged but for documentation purposes. Implementation of fast inference for Decision Trees.; @stwunsch will make another PR to integrate properly into the root system.; ## Getting started; Required additional librairies; - ROOT; - for running tests you need Google Tests; - for running benchs, you need Google Benchs and XGBoost. ### Run tests ; Update the makefile in the tests folder, then execute `make clean && make && ./testAll.exe`; At the end of this text is a setup file for a new installation of ubuntu 18.04. ### Code structure; Here below we show the structure of the repository with the files of interest.; .; ├── bench.py; ├── bench.sh; ├── build/; ├── data/; ├── experiments/; │ ├── arrayBdtPreds.cxx; │ ├── data/; │ ├── generate_data.py; │ ├── makefile; │ ├── readme.md; │ ├── run_all.sh; │ └── setup.h; ├── figures/; ├── generated_files/; ├── include/; │ ├── BranchedTree.hxx; │ ├── BranchlessTree.hxx; │ ├── CodeGeneratorsJIT.hxx; │ ├── ForestHelpers.hxx; │ ├── json.hpp; │ ├── RForestInference.hxx; │ └── TreeHelpers.hxx; ├── makefile_bench.make; ├── README.md; ├── run.sh; ├── src/; │ └── benchmark.cxx; ├── tests/; │ ├── build/; │ ├── data/; │ │ ├── events.csv; │ │ ├── model.json; │ │ ├── model.rabbit; │ │ ├── multiclass_events.csv; │ │ ├── multiclass_model.json; │ │ ├── multiclass_model.rabbit; │ │ ├── multiclass_python_groundtruths.csv; │ │ ├── multiclass_python_predictions.csv; │ │ ├── multiclass_python_scores.csv; │ │ ├── python_predictions.csv; │ │ ├── regression_events.csv; │ │ ├── regression_model.json; │ │ ├── regression_model.rabbit; │ │ ├── regression_python_groundtruths.csv; │ │ ├── regression_python_predictions.csv; │ │ ├── regression_python_scores.csv; │ ├── forestBDTest.hxx; │ ├── helpersBDTest.hxx; │ ├── makefile; │ ├── readme.md; │ ├── RegressionBDTest.hxx; │ ├── run_all.sh; │ ├── testAll.cxx; ├── train_classifiers_examples.py; └── utils.py. ### Setup script for ubuntu 18.04; It sets up a new machine, installing everythi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4351
https://github.com/root-project/root/pull/4351:375,Deployability,Update,Update,375,"# This PR is not meant to be merged but for documentation purposes. Implementation of fast inference for Decision Trees.; @stwunsch will make another PR to integrate properly into the root system.; ## Getting started; Required additional librairies; - ROOT; - for running tests you need Google Tests; - for running benchs, you need Google Benchs and XGBoost. ### Run tests ; Update the makefile in the tests folder, then execute `make clean && make && ./testAll.exe`; At the end of this text is a setup file for a new installation of ubuntu 18.04. ### Code structure; Here below we show the structure of the repository with the files of interest.; .; ├── bench.py; ├── bench.sh; ├── build/; ├── data/; ├── experiments/; │ ├── arrayBdtPreds.cxx; │ ├── data/; │ ├── generate_data.py; │ ├── makefile; │ ├── readme.md; │ ├── run_all.sh; │ └── setup.h; ├── figures/; ├── generated_files/; ├── include/; │ ├── BranchedTree.hxx; │ ├── BranchlessTree.hxx; │ ├── CodeGeneratorsJIT.hxx; │ ├── ForestHelpers.hxx; │ ├── json.hpp; │ ├── RForestInference.hxx; │ └── TreeHelpers.hxx; ├── makefile_bench.make; ├── README.md; ├── run.sh; ├── src/; │ └── benchmark.cxx; ├── tests/; │ ├── build/; │ ├── data/; │ │ ├── events.csv; │ │ ├── model.json; │ │ ├── model.rabbit; │ │ ├── multiclass_events.csv; │ │ ├── multiclass_model.json; │ │ ├── multiclass_model.rabbit; │ │ ├── multiclass_python_groundtruths.csv; │ │ ├── multiclass_python_predictions.csv; │ │ ├── multiclass_python_scores.csv; │ │ ├── python_predictions.csv; │ │ ├── regression_events.csv; │ │ ├── regression_model.json; │ │ ├── regression_model.rabbit; │ │ ├── regression_python_groundtruths.csv; │ │ ├── regression_python_predictions.csv; │ │ ├── regression_python_scores.csv; │ ├── forestBDTest.hxx; │ ├── helpersBDTest.hxx; │ ├── makefile; │ ├── readme.md; │ ├── RegressionBDTest.hxx; │ ├── run_all.sh; │ ├── testAll.cxx; ├── train_classifiers_examples.py; └── utils.py. ### Setup script for ubuntu 18.04; It sets up a new machine, installing everythi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4351
https://github.com/root-project/root/pull/4351:518,Deployability,install,installation,518,"# This PR is not meant to be merged but for documentation purposes. Implementation of fast inference for Decision Trees.; @stwunsch will make another PR to integrate properly into the root system.; ## Getting started; Required additional librairies; - ROOT; - for running tests you need Google Tests; - for running benchs, you need Google Benchs and XGBoost. ### Run tests ; Update the makefile in the tests folder, then execute `make clean && make && ./testAll.exe`; At the end of this text is a setup file for a new installation of ubuntu 18.04. ### Code structure; Here below we show the structure of the repository with the files of interest.; .; ├── bench.py; ├── bench.sh; ├── build/; ├── data/; ├── experiments/; │ ├── arrayBdtPreds.cxx; │ ├── data/; │ ├── generate_data.py; │ ├── makefile; │ ├── readme.md; │ ├── run_all.sh; │ └── setup.h; ├── figures/; ├── generated_files/; ├── include/; │ ├── BranchedTree.hxx; │ ├── BranchlessTree.hxx; │ ├── CodeGeneratorsJIT.hxx; │ ├── ForestHelpers.hxx; │ ├── json.hpp; │ ├── RForestInference.hxx; │ └── TreeHelpers.hxx; ├── makefile_bench.make; ├── README.md; ├── run.sh; ├── src/; │ └── benchmark.cxx; ├── tests/; │ ├── build/; │ ├── data/; │ │ ├── events.csv; │ │ ├── model.json; │ │ ├── model.rabbit; │ │ ├── multiclass_events.csv; │ │ ├── multiclass_model.json; │ │ ├── multiclass_model.rabbit; │ │ ├── multiclass_python_groundtruths.csv; │ │ ├── multiclass_python_predictions.csv; │ │ ├── multiclass_python_scores.csv; │ │ ├── python_predictions.csv; │ │ ├── regression_events.csv; │ │ ├── regression_model.json; │ │ ├── regression_model.rabbit; │ │ ├── regression_python_groundtruths.csv; │ │ ├── regression_python_predictions.csv; │ │ ├── regression_python_scores.csv; │ ├── forestBDTest.hxx; │ ├── helpersBDTest.hxx; │ ├── makefile; │ ├── readme.md; │ ├── RegressionBDTest.hxx; │ ├── run_all.sh; │ ├── testAll.cxx; ├── train_classifiers_examples.py; └── utils.py. ### Setup script for ubuntu 18.04; It sets up a new machine, installing everythi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4351
https://github.com/root-project/root/pull/4351:1982,Deployability,install,installing,1982,"stHelpers.hxx; │ ├── json.hpp; │ ├── RForestInference.hxx; │ └── TreeHelpers.hxx; ├── makefile_bench.make; ├── README.md; ├── run.sh; ├── src/; │ └── benchmark.cxx; ├── tests/; │ ├── build/; │ ├── data/; │ │ ├── events.csv; │ │ ├── model.json; │ │ ├── model.rabbit; │ │ ├── multiclass_events.csv; │ │ ├── multiclass_model.json; │ │ ├── multiclass_model.rabbit; │ │ ├── multiclass_python_groundtruths.csv; │ │ ├── multiclass_python_predictions.csv; │ │ ├── multiclass_python_scores.csv; │ │ ├── python_predictions.csv; │ │ ├── regression_events.csv; │ │ ├── regression_model.json; │ │ ├── regression_model.rabbit; │ │ ├── regression_python_groundtruths.csv; │ │ ├── regression_python_predictions.csv; │ │ ├── regression_python_scores.csv; │ ├── forestBDTest.hxx; │ ├── helpersBDTest.hxx; │ ├── makefile; │ ├── readme.md; │ ├── RegressionBDTest.hxx; │ ├── run_all.sh; │ ├── testAll.cxx; ├── train_classifiers_examples.py; └── utils.py. ### Setup script for ubuntu 18.04; It sets up a new machine, installing everything in the home folder. Please modify for your needs.; ```bash; #!/bin/bash; cd; # can be ran with yes | bash this_file.sh # to say yes when prompted. sudo apt update ; yes | sudo apt upgrade. # Install all the stuff with apt. sudo apt install clang # to use clang; sudo apt install g++-7 gcc-7 # to use gcc; sudo apt install libx11-dev build-essential cmake ; sudo apt install git dpkg-dev cmake binutils libx11-dev libxpm-dev \; libxft-dev libxext-dev; sudo apt-get install gfortran libssl-dev libpcre3-dev \; xlibmesa-glu-dev libglew1.5-dev libftgl-dev \; libmysqlclient-dev libfftw3-dev libcfitsio-dev \; graphviz-dev libavahi-compat-libdnssd-dev \; libldap2-dev python-dev libxml2-dev libkrb5-dev \; libgsl0-dev libqt4-dev; sudo apt install gdb. sudo apt install libstdc++ # then add flag -stdlib=libstdc++. wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh; (echo ''; echo 'yes'; echo ''; echo 'yes';) | bash ./Miniconda3-latest-Linux-x86_64.sh; source .bas",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4351
https://github.com/root-project/root/pull/4351:2160,Deployability,update,update,2160,"uild/; │ ├── data/; │ │ ├── events.csv; │ │ ├── model.json; │ │ ├── model.rabbit; │ │ ├── multiclass_events.csv; │ │ ├── multiclass_model.json; │ │ ├── multiclass_model.rabbit; │ │ ├── multiclass_python_groundtruths.csv; │ │ ├── multiclass_python_predictions.csv; │ │ ├── multiclass_python_scores.csv; │ │ ├── python_predictions.csv; │ │ ├── regression_events.csv; │ │ ├── regression_model.json; │ │ ├── regression_model.rabbit; │ │ ├── regression_python_groundtruths.csv; │ │ ├── regression_python_predictions.csv; │ │ ├── regression_python_scores.csv; │ ├── forestBDTest.hxx; │ ├── helpersBDTest.hxx; │ ├── makefile; │ ├── readme.md; │ ├── RegressionBDTest.hxx; │ ├── run_all.sh; │ ├── testAll.cxx; ├── train_classifiers_examples.py; └── utils.py. ### Setup script for ubuntu 18.04; It sets up a new machine, installing everything in the home folder. Please modify for your needs.; ```bash; #!/bin/bash; cd; # can be ran with yes | bash this_file.sh # to say yes when prompted. sudo apt update ; yes | sudo apt upgrade. # Install all the stuff with apt. sudo apt install clang # to use clang; sudo apt install g++-7 gcc-7 # to use gcc; sudo apt install libx11-dev build-essential cmake ; sudo apt install git dpkg-dev cmake binutils libx11-dev libxpm-dev \; libxft-dev libxext-dev; sudo apt-get install gfortran libssl-dev libpcre3-dev \; xlibmesa-glu-dev libglew1.5-dev libftgl-dev \; libmysqlclient-dev libfftw3-dev libcfitsio-dev \; graphviz-dev libavahi-compat-libdnssd-dev \; libldap2-dev python-dev libxml2-dev libkrb5-dev \; libgsl0-dev libqt4-dev; sudo apt install gdb. sudo apt install libstdc++ # then add flag -stdlib=libstdc++. wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh; (echo ''; echo 'yes'; echo ''; echo 'yes';) | bash ./Miniconda3-latest-Linux-x86_64.sh; source .bashrc; source activate base; pip install numpy sklearn xgboost matplotlib. #################################### install projects #############################3; # Get ROOT; cd; git clon",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4351
https://github.com/root-project/root/pull/4351:2184,Deployability,upgrade,upgrade,2184,"uild/; │ ├── data/; │ │ ├── events.csv; │ │ ├── model.json; │ │ ├── model.rabbit; │ │ ├── multiclass_events.csv; │ │ ├── multiclass_model.json; │ │ ├── multiclass_model.rabbit; │ │ ├── multiclass_python_groundtruths.csv; │ │ ├── multiclass_python_predictions.csv; │ │ ├── multiclass_python_scores.csv; │ │ ├── python_predictions.csv; │ │ ├── regression_events.csv; │ │ ├── regression_model.json; │ │ ├── regression_model.rabbit; │ │ ├── regression_python_groundtruths.csv; │ │ ├── regression_python_predictions.csv; │ │ ├── regression_python_scores.csv; │ ├── forestBDTest.hxx; │ ├── helpersBDTest.hxx; │ ├── makefile; │ ├── readme.md; │ ├── RegressionBDTest.hxx; │ ├── run_all.sh; │ ├── testAll.cxx; ├── train_classifiers_examples.py; └── utils.py. ### Setup script for ubuntu 18.04; It sets up a new machine, installing everything in the home folder. Please modify for your needs.; ```bash; #!/bin/bash; cd; # can be ran with yes | bash this_file.sh # to say yes when prompted. sudo apt update ; yes | sudo apt upgrade. # Install all the stuff with apt. sudo apt install clang # to use clang; sudo apt install g++-7 gcc-7 # to use gcc; sudo apt install libx11-dev build-essential cmake ; sudo apt install git dpkg-dev cmake binutils libx11-dev libxpm-dev \; libxft-dev libxext-dev; sudo apt-get install gfortran libssl-dev libpcre3-dev \; xlibmesa-glu-dev libglew1.5-dev libftgl-dev \; libmysqlclient-dev libfftw3-dev libcfitsio-dev \; graphviz-dev libavahi-compat-libdnssd-dev \; libldap2-dev python-dev libxml2-dev libkrb5-dev \; libgsl0-dev libqt4-dev; sudo apt install gdb. sudo apt install libstdc++ # then add flag -stdlib=libstdc++. wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh; (echo ''; echo 'yes'; echo ''; echo 'yes';) | bash ./Miniconda3-latest-Linux-x86_64.sh; source .bashrc; source activate base; pip install numpy sklearn xgboost matplotlib. #################################### install projects #############################3; # Get ROOT; cd; git clon",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4351
https://github.com/root-project/root/pull/4351:2195,Deployability,Install,Install,2195,"; │ │ ├── model.json; │ │ ├── model.rabbit; │ │ ├── multiclass_events.csv; │ │ ├── multiclass_model.json; │ │ ├── multiclass_model.rabbit; │ │ ├── multiclass_python_groundtruths.csv; │ │ ├── multiclass_python_predictions.csv; │ │ ├── multiclass_python_scores.csv; │ │ ├── python_predictions.csv; │ │ ├── regression_events.csv; │ │ ├── regression_model.json; │ │ ├── regression_model.rabbit; │ │ ├── regression_python_groundtruths.csv; │ │ ├── regression_python_predictions.csv; │ │ ├── regression_python_scores.csv; │ ├── forestBDTest.hxx; │ ├── helpersBDTest.hxx; │ ├── makefile; │ ├── readme.md; │ ├── RegressionBDTest.hxx; │ ├── run_all.sh; │ ├── testAll.cxx; ├── train_classifiers_examples.py; └── utils.py. ### Setup script for ubuntu 18.04; It sets up a new machine, installing everything in the home folder. Please modify for your needs.; ```bash; #!/bin/bash; cd; # can be ran with yes | bash this_file.sh # to say yes when prompted. sudo apt update ; yes | sudo apt upgrade. # Install all the stuff with apt. sudo apt install clang # to use clang; sudo apt install g++-7 gcc-7 # to use gcc; sudo apt install libx11-dev build-essential cmake ; sudo apt install git dpkg-dev cmake binutils libx11-dev libxpm-dev \; libxft-dev libxext-dev; sudo apt-get install gfortran libssl-dev libpcre3-dev \; xlibmesa-glu-dev libglew1.5-dev libftgl-dev \; libmysqlclient-dev libfftw3-dev libcfitsio-dev \; graphviz-dev libavahi-compat-libdnssd-dev \; libldap2-dev python-dev libxml2-dev libkrb5-dev \; libgsl0-dev libqt4-dev; sudo apt install gdb. sudo apt install libstdc++ # then add flag -stdlib=libstdc++. wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh; (echo ''; echo 'yes'; echo ''; echo 'yes';) | bash ./Miniconda3-latest-Linux-x86_64.sh; source .bashrc; source activate base; pip install numpy sklearn xgboost matplotlib. #################################### install projects #############################3; # Get ROOT; cd; git clone git@github.com:LucaZampieri/root.git",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4351
https://github.com/root-project/root/pull/4351:2236,Deployability,install,install,2236,"uths.csv; │ │ ├── multiclass_python_predictions.csv; │ │ ├── multiclass_python_scores.csv; │ │ ├── python_predictions.csv; │ │ ├── regression_events.csv; │ │ ├── regression_model.json; │ │ ├── regression_model.rabbit; │ │ ├── regression_python_groundtruths.csv; │ │ ├── regression_python_predictions.csv; │ │ ├── regression_python_scores.csv; │ ├── forestBDTest.hxx; │ ├── helpersBDTest.hxx; │ ├── makefile; │ ├── readme.md; │ ├── RegressionBDTest.hxx; │ ├── run_all.sh; │ ├── testAll.cxx; ├── train_classifiers_examples.py; └── utils.py. ### Setup script for ubuntu 18.04; It sets up a new machine, installing everything in the home folder. Please modify for your needs.; ```bash; #!/bin/bash; cd; # can be ran with yes | bash this_file.sh # to say yes when prompted. sudo apt update ; yes | sudo apt upgrade. # Install all the stuff with apt. sudo apt install clang # to use clang; sudo apt install g++-7 gcc-7 # to use gcc; sudo apt install libx11-dev build-essential cmake ; sudo apt install git dpkg-dev cmake binutils libx11-dev libxpm-dev \; libxft-dev libxext-dev; sudo apt-get install gfortran libssl-dev libpcre3-dev \; xlibmesa-glu-dev libglew1.5-dev libftgl-dev \; libmysqlclient-dev libfftw3-dev libcfitsio-dev \; graphviz-dev libavahi-compat-libdnssd-dev \; libldap2-dev python-dev libxml2-dev libkrb5-dev \; libgsl0-dev libqt4-dev; sudo apt install gdb. sudo apt install libstdc++ # then add flag -stdlib=libstdc++. wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh; (echo ''; echo 'yes'; echo ''; echo 'yes';) | bash ./Miniconda3-latest-Linux-x86_64.sh; source .bashrc; source activate base; pip install numpy sklearn xgboost matplotlib. #################################### install projects #############################3; # Get ROOT; cd; git clone git@github.com:LucaZampieri/root.git. # build with gcc; mkdir build_gcc && cd build_gcc && cmake ../root && make -j8. ## Google bench; cd; # Check out the library.; git clone https://github.com/google/benchmar",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4351
https://github.com/root-project/root/pull/4351:2275,Deployability,install,install,2275,"uths.csv; │ │ ├── multiclass_python_predictions.csv; │ │ ├── multiclass_python_scores.csv; │ │ ├── python_predictions.csv; │ │ ├── regression_events.csv; │ │ ├── regression_model.json; │ │ ├── regression_model.rabbit; │ │ ├── regression_python_groundtruths.csv; │ │ ├── regression_python_predictions.csv; │ │ ├── regression_python_scores.csv; │ ├── forestBDTest.hxx; │ ├── helpersBDTest.hxx; │ ├── makefile; │ ├── readme.md; │ ├── RegressionBDTest.hxx; │ ├── run_all.sh; │ ├── testAll.cxx; ├── train_classifiers_examples.py; └── utils.py. ### Setup script for ubuntu 18.04; It sets up a new machine, installing everything in the home folder. Please modify for your needs.; ```bash; #!/bin/bash; cd; # can be ran with yes | bash this_file.sh # to say yes when prompted. sudo apt update ; yes | sudo apt upgrade. # Install all the stuff with apt. sudo apt install clang # to use clang; sudo apt install g++-7 gcc-7 # to use gcc; sudo apt install libx11-dev build-essential cmake ; sudo apt install git dpkg-dev cmake binutils libx11-dev libxpm-dev \; libxft-dev libxext-dev; sudo apt-get install gfortran libssl-dev libpcre3-dev \; xlibmesa-glu-dev libglew1.5-dev libftgl-dev \; libmysqlclient-dev libfftw3-dev libcfitsio-dev \; graphviz-dev libavahi-compat-libdnssd-dev \; libldap2-dev python-dev libxml2-dev libkrb5-dev \; libgsl0-dev libqt4-dev; sudo apt install gdb. sudo apt install libstdc++ # then add flag -stdlib=libstdc++. wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh; (echo ''; echo 'yes'; echo ''; echo 'yes';) | bash ./Miniconda3-latest-Linux-x86_64.sh; source .bashrc; source activate base; pip install numpy sklearn xgboost matplotlib. #################################### install projects #############################3; # Get ROOT; cd; git clone git@github.com:LucaZampieri/root.git. # build with gcc; mkdir build_gcc && cd build_gcc && cmake ../root && make -j8. ## Google bench; cd; # Check out the library.; git clone https://github.com/google/benchmar",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4351
https://github.com/root-project/root/pull/4351:2318,Deployability,install,install,2318,"uths.csv; │ │ ├── multiclass_python_predictions.csv; │ │ ├── multiclass_python_scores.csv; │ │ ├── python_predictions.csv; │ │ ├── regression_events.csv; │ │ ├── regression_model.json; │ │ ├── regression_model.rabbit; │ │ ├── regression_python_groundtruths.csv; │ │ ├── regression_python_predictions.csv; │ │ ├── regression_python_scores.csv; │ ├── forestBDTest.hxx; │ ├── helpersBDTest.hxx; │ ├── makefile; │ ├── readme.md; │ ├── RegressionBDTest.hxx; │ ├── run_all.sh; │ ├── testAll.cxx; ├── train_classifiers_examples.py; └── utils.py. ### Setup script for ubuntu 18.04; It sets up a new machine, installing everything in the home folder. Please modify for your needs.; ```bash; #!/bin/bash; cd; # can be ran with yes | bash this_file.sh # to say yes when prompted. sudo apt update ; yes | sudo apt upgrade. # Install all the stuff with apt. sudo apt install clang # to use clang; sudo apt install g++-7 gcc-7 # to use gcc; sudo apt install libx11-dev build-essential cmake ; sudo apt install git dpkg-dev cmake binutils libx11-dev libxpm-dev \; libxft-dev libxext-dev; sudo apt-get install gfortran libssl-dev libpcre3-dev \; xlibmesa-glu-dev libglew1.5-dev libftgl-dev \; libmysqlclient-dev libfftw3-dev libcfitsio-dev \; graphviz-dev libavahi-compat-libdnssd-dev \; libldap2-dev python-dev libxml2-dev libkrb5-dev \; libgsl0-dev libqt4-dev; sudo apt install gdb. sudo apt install libstdc++ # then add flag -stdlib=libstdc++. wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh; (echo ''; echo 'yes'; echo ''; echo 'yes';) | bash ./Miniconda3-latest-Linux-x86_64.sh; source .bashrc; source activate base; pip install numpy sklearn xgboost matplotlib. #################################### install projects #############################3; # Get ROOT; cd; git clone git@github.com:LucaZampieri/root.git. # build with gcc; mkdir build_gcc && cd build_gcc && cmake ../root && make -j8. ## Google bench; cd; # Check out the library.; git clone https://github.com/google/benchmar",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4351
https://github.com/root-project/root/pull/4351:2370,Deployability,install,install,2370,"uths.csv; │ │ ├── multiclass_python_predictions.csv; │ │ ├── multiclass_python_scores.csv; │ │ ├── python_predictions.csv; │ │ ├── regression_events.csv; │ │ ├── regression_model.json; │ │ ├── regression_model.rabbit; │ │ ├── regression_python_groundtruths.csv; │ │ ├── regression_python_predictions.csv; │ │ ├── regression_python_scores.csv; │ ├── forestBDTest.hxx; │ ├── helpersBDTest.hxx; │ ├── makefile; │ ├── readme.md; │ ├── RegressionBDTest.hxx; │ ├── run_all.sh; │ ├── testAll.cxx; ├── train_classifiers_examples.py; └── utils.py. ### Setup script for ubuntu 18.04; It sets up a new machine, installing everything in the home folder. Please modify for your needs.; ```bash; #!/bin/bash; cd; # can be ran with yes | bash this_file.sh # to say yes when prompted. sudo apt update ; yes | sudo apt upgrade. # Install all the stuff with apt. sudo apt install clang # to use clang; sudo apt install g++-7 gcc-7 # to use gcc; sudo apt install libx11-dev build-essential cmake ; sudo apt install git dpkg-dev cmake binutils libx11-dev libxpm-dev \; libxft-dev libxext-dev; sudo apt-get install gfortran libssl-dev libpcre3-dev \; xlibmesa-glu-dev libglew1.5-dev libftgl-dev \; libmysqlclient-dev libfftw3-dev libcfitsio-dev \; graphviz-dev libavahi-compat-libdnssd-dev \; libldap2-dev python-dev libxml2-dev libkrb5-dev \; libgsl0-dev libqt4-dev; sudo apt install gdb. sudo apt install libstdc++ # then add flag -stdlib=libstdc++. wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh; (echo ''; echo 'yes'; echo ''; echo 'yes';) | bash ./Miniconda3-latest-Linux-x86_64.sh; source .bashrc; source activate base; pip install numpy sklearn xgboost matplotlib. #################################### install projects #############################3; # Get ROOT; cd; git clone git@github.com:LucaZampieri/root.git. # build with gcc; mkdir build_gcc && cd build_gcc && cmake ../root && make -j8. ## Google bench; cd; # Check out the library.; git clone https://github.com/google/benchmar",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4351
https://github.com/root-project/root/pull/4351:2468,Deployability,install,install,2468,"uths.csv; │ │ ├── multiclass_python_predictions.csv; │ │ ├── multiclass_python_scores.csv; │ │ ├── python_predictions.csv; │ │ ├── regression_events.csv; │ │ ├── regression_model.json; │ │ ├── regression_model.rabbit; │ │ ├── regression_python_groundtruths.csv; │ │ ├── regression_python_predictions.csv; │ │ ├── regression_python_scores.csv; │ ├── forestBDTest.hxx; │ ├── helpersBDTest.hxx; │ ├── makefile; │ ├── readme.md; │ ├── RegressionBDTest.hxx; │ ├── run_all.sh; │ ├── testAll.cxx; ├── train_classifiers_examples.py; └── utils.py. ### Setup script for ubuntu 18.04; It sets up a new machine, installing everything in the home folder. Please modify for your needs.; ```bash; #!/bin/bash; cd; # can be ran with yes | bash this_file.sh # to say yes when prompted. sudo apt update ; yes | sudo apt upgrade. # Install all the stuff with apt. sudo apt install clang # to use clang; sudo apt install g++-7 gcc-7 # to use gcc; sudo apt install libx11-dev build-essential cmake ; sudo apt install git dpkg-dev cmake binutils libx11-dev libxpm-dev \; libxft-dev libxext-dev; sudo apt-get install gfortran libssl-dev libpcre3-dev \; xlibmesa-glu-dev libglew1.5-dev libftgl-dev \; libmysqlclient-dev libfftw3-dev libcfitsio-dev \; graphviz-dev libavahi-compat-libdnssd-dev \; libldap2-dev python-dev libxml2-dev libkrb5-dev \; libgsl0-dev libqt4-dev; sudo apt install gdb. sudo apt install libstdc++ # then add flag -stdlib=libstdc++. wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh; (echo ''; echo 'yes'; echo ''; echo 'yes';) | bash ./Miniconda3-latest-Linux-x86_64.sh; source .bashrc; source activate base; pip install numpy sklearn xgboost matplotlib. #################################### install projects #############################3; # Get ROOT; cd; git clone git@github.com:LucaZampieri/root.git. # build with gcc; mkdir build_gcc && cd build_gcc && cmake ../root && make -j8. ## Google bench; cd; # Check out the library.; git clone https://github.com/google/benchmar",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4351
https://github.com/root-project/root/pull/4351:2738,Deployability,install,install,2738,"│ │ ├── regression_python_predictions.csv; │ │ ├── regression_python_scores.csv; │ ├── forestBDTest.hxx; │ ├── helpersBDTest.hxx; │ ├── makefile; │ ├── readme.md; │ ├── RegressionBDTest.hxx; │ ├── run_all.sh; │ ├── testAll.cxx; ├── train_classifiers_examples.py; └── utils.py. ### Setup script for ubuntu 18.04; It sets up a new machine, installing everything in the home folder. Please modify for your needs.; ```bash; #!/bin/bash; cd; # can be ran with yes | bash this_file.sh # to say yes when prompted. sudo apt update ; yes | sudo apt upgrade. # Install all the stuff with apt. sudo apt install clang # to use clang; sudo apt install g++-7 gcc-7 # to use gcc; sudo apt install libx11-dev build-essential cmake ; sudo apt install git dpkg-dev cmake binutils libx11-dev libxpm-dev \; libxft-dev libxext-dev; sudo apt-get install gfortran libssl-dev libpcre3-dev \; xlibmesa-glu-dev libglew1.5-dev libftgl-dev \; libmysqlclient-dev libfftw3-dev libcfitsio-dev \; graphviz-dev libavahi-compat-libdnssd-dev \; libldap2-dev python-dev libxml2-dev libkrb5-dev \; libgsl0-dev libqt4-dev; sudo apt install gdb. sudo apt install libstdc++ # then add flag -stdlib=libstdc++. wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh; (echo ''; echo 'yes'; echo ''; echo 'yes';) | bash ./Miniconda3-latest-Linux-x86_64.sh; source .bashrc; source activate base; pip install numpy sklearn xgboost matplotlib. #################################### install projects #############################3; # Get ROOT; cd; git clone git@github.com:LucaZampieri/root.git. # build with gcc; mkdir build_gcc && cd build_gcc && cmake ../root && make -j8. ## Google bench; cd; # Check out the library.; git clone https://github.com/google/benchmark.git; # Benchmark requires Google Test as a dependency. Add the source tree as a subdirectory.; git clone https://github.com/google/googletest.git benchmark/googletest. # Go to the library root directory; cd benchmark ; mkdir build_gcc; cd build_gcc ; cmake -DC",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4351
https://github.com/root-project/root/pull/4351:2760,Deployability,install,install,2760,"akefile; │ ├── readme.md; │ ├── RegressionBDTest.hxx; │ ├── run_all.sh; │ ├── testAll.cxx; ├── train_classifiers_examples.py; └── utils.py. ### Setup script for ubuntu 18.04; It sets up a new machine, installing everything in the home folder. Please modify for your needs.; ```bash; #!/bin/bash; cd; # can be ran with yes | bash this_file.sh # to say yes when prompted. sudo apt update ; yes | sudo apt upgrade. # Install all the stuff with apt. sudo apt install clang # to use clang; sudo apt install g++-7 gcc-7 # to use gcc; sudo apt install libx11-dev build-essential cmake ; sudo apt install git dpkg-dev cmake binutils libx11-dev libxpm-dev \; libxft-dev libxext-dev; sudo apt-get install gfortran libssl-dev libpcre3-dev \; xlibmesa-glu-dev libglew1.5-dev libftgl-dev \; libmysqlclient-dev libfftw3-dev libcfitsio-dev \; graphviz-dev libavahi-compat-libdnssd-dev \; libldap2-dev python-dev libxml2-dev libkrb5-dev \; libgsl0-dev libqt4-dev; sudo apt install gdb. sudo apt install libstdc++ # then add flag -stdlib=libstdc++. wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh; (echo ''; echo 'yes'; echo ''; echo 'yes';) | bash ./Miniconda3-latest-Linux-x86_64.sh; source .bashrc; source activate base; pip install numpy sklearn xgboost matplotlib. #################################### install projects #############################3; # Get ROOT; cd; git clone git@github.com:LucaZampieri/root.git. # build with gcc; mkdir build_gcc && cd build_gcc && cmake ../root && make -j8. ## Google bench; cd; # Check out the library.; git clone https://github.com/google/benchmark.git; # Benchmark requires Google Test as a dependency. Add the source tree as a subdirectory.; git clone https://github.com/google/googletest.git benchmark/googletest. # Go to the library root directory; cd benchmark ; mkdir build_gcc; cd build_gcc ; cmake -DCMAKE_BUILD_TYPE=Release ../root && make -j8. # XGBoost; cd; git clone --recursive https://github.com/dmlc/xgboost; cd xgboost; mkdir buil",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4351
https://github.com/root-project/root/pull/4351:3019,Deployability,install,install,3019,". Please modify for your needs.; ```bash; #!/bin/bash; cd; # can be ran with yes | bash this_file.sh # to say yes when prompted. sudo apt update ; yes | sudo apt upgrade. # Install all the stuff with apt. sudo apt install clang # to use clang; sudo apt install g++-7 gcc-7 # to use gcc; sudo apt install libx11-dev build-essential cmake ; sudo apt install git dpkg-dev cmake binutils libx11-dev libxpm-dev \; libxft-dev libxext-dev; sudo apt-get install gfortran libssl-dev libpcre3-dev \; xlibmesa-glu-dev libglew1.5-dev libftgl-dev \; libmysqlclient-dev libfftw3-dev libcfitsio-dev \; graphviz-dev libavahi-compat-libdnssd-dev \; libldap2-dev python-dev libxml2-dev libkrb5-dev \; libgsl0-dev libqt4-dev; sudo apt install gdb. sudo apt install libstdc++ # then add flag -stdlib=libstdc++. wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh; (echo ''; echo 'yes'; echo ''; echo 'yes';) | bash ./Miniconda3-latest-Linux-x86_64.sh; source .bashrc; source activate base; pip install numpy sklearn xgboost matplotlib. #################################### install projects #############################3; # Get ROOT; cd; git clone git@github.com:LucaZampieri/root.git. # build with gcc; mkdir build_gcc && cd build_gcc && cmake ../root && make -j8. ## Google bench; cd; # Check out the library.; git clone https://github.com/google/benchmark.git; # Benchmark requires Google Test as a dependency. Add the source tree as a subdirectory.; git clone https://github.com/google/googletest.git benchmark/googletest. # Go to the library root directory; cd benchmark ; mkdir build_gcc; cd build_gcc ; cmake -DCMAKE_BUILD_TYPE=Release ../root && make -j8. # XGBoost; cd; git clone --recursive https://github.com/dmlc/xgboost; cd xgboost; mkdir build_gcc; cd build_gcc; cmake -DCMAKE_BUILD_TYPE=Release ../. # Setup aliases; echo ""alias bdt='cd ~/root/tmva/tmva/src/BDT'"" >> ~/.bashrc; source .bashrc. # Add the folders missing from github (add them directly in github?) ; cd; bdt ; git chec",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4351
https://github.com/root-project/root/pull/4351:3098,Deployability,install,install,3098," # to say yes when prompted. sudo apt update ; yes | sudo apt upgrade. # Install all the stuff with apt. sudo apt install clang # to use clang; sudo apt install g++-7 gcc-7 # to use gcc; sudo apt install libx11-dev build-essential cmake ; sudo apt install git dpkg-dev cmake binutils libx11-dev libxpm-dev \; libxft-dev libxext-dev; sudo apt-get install gfortran libssl-dev libpcre3-dev \; xlibmesa-glu-dev libglew1.5-dev libftgl-dev \; libmysqlclient-dev libfftw3-dev libcfitsio-dev \; graphviz-dev libavahi-compat-libdnssd-dev \; libldap2-dev python-dev libxml2-dev libkrb5-dev \; libgsl0-dev libqt4-dev; sudo apt install gdb. sudo apt install libstdc++ # then add flag -stdlib=libstdc++. wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh; (echo ''; echo 'yes'; echo ''; echo 'yes';) | bash ./Miniconda3-latest-Linux-x86_64.sh; source .bashrc; source activate base; pip install numpy sklearn xgboost matplotlib. #################################### install projects #############################3; # Get ROOT; cd; git clone git@github.com:LucaZampieri/root.git. # build with gcc; mkdir build_gcc && cd build_gcc && cmake ../root && make -j8. ## Google bench; cd; # Check out the library.; git clone https://github.com/google/benchmark.git; # Benchmark requires Google Test as a dependency. Add the source tree as a subdirectory.; git clone https://github.com/google/googletest.git benchmark/googletest. # Go to the library root directory; cd benchmark ; mkdir build_gcc; cd build_gcc ; cmake -DCMAKE_BUILD_TYPE=Release ../root && make -j8. # XGBoost; cd; git clone --recursive https://github.com/dmlc/xgboost; cd xgboost; mkdir build_gcc; cd build_gcc; cmake -DCMAKE_BUILD_TYPE=Release ../. # Setup aliases; echo ""alias bdt='cd ~/root/tmva/tmva/src/BDT'"" >> ~/.bashrc; source .bashrc. # Add the folders missing from github (add them directly in github?) ; cd; bdt ; git checkout backend/FastInference; mkdir build. # For ROOT; echo 'export ROOTSYS=""~/root/""' >> ~/.bashrc; ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4351
https://github.com/root-project/root/pull/4351:3660,Deployability,Release,Release,3660,"git dpkg-dev cmake binutils libx11-dev libxpm-dev \; libxft-dev libxext-dev; sudo apt-get install gfortran libssl-dev libpcre3-dev \; xlibmesa-glu-dev libglew1.5-dev libftgl-dev \; libmysqlclient-dev libfftw3-dev libcfitsio-dev \; graphviz-dev libavahi-compat-libdnssd-dev \; libldap2-dev python-dev libxml2-dev libkrb5-dev \; libgsl0-dev libqt4-dev; sudo apt install gdb. sudo apt install libstdc++ # then add flag -stdlib=libstdc++. wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh; (echo ''; echo 'yes'; echo ''; echo 'yes';) | bash ./Miniconda3-latest-Linux-x86_64.sh; source .bashrc; source activate base; pip install numpy sklearn xgboost matplotlib. #################################### install projects #############################3; # Get ROOT; cd; git clone git@github.com:LucaZampieri/root.git. # build with gcc; mkdir build_gcc && cd build_gcc && cmake ../root && make -j8. ## Google bench; cd; # Check out the library.; git clone https://github.com/google/benchmark.git; # Benchmark requires Google Test as a dependency. Add the source tree as a subdirectory.; git clone https://github.com/google/googletest.git benchmark/googletest. # Go to the library root directory; cd benchmark ; mkdir build_gcc; cd build_gcc ; cmake -DCMAKE_BUILD_TYPE=Release ../root && make -j8. # XGBoost; cd; git clone --recursive https://github.com/dmlc/xgboost; cd xgboost; mkdir build_gcc; cd build_gcc; cmake -DCMAKE_BUILD_TYPE=Release ../. # Setup aliases; echo ""alias bdt='cd ~/root/tmva/tmva/src/BDT'"" >> ~/.bashrc; source .bashrc. # Add the folders missing from github (add them directly in github?) ; cd; bdt ; git checkout backend/FastInference; mkdir build. # For ROOT; echo 'export ROOTSYS=""~/root/""' >> ~/.bashrc; echo 'export ROOTBUILD=""~/build_gcc/""' >> ~/.bashrc; echo 'source $ROOTBUILD/bin/thisroot.sh' >> ~/.bashrc. echo 'export XGBOOST_ROOT=""~/xgboost""' >> ~/.bashrc. echo 'export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:~/xgboost/lib/' >> ~/.bashrc. source .bashrc; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4351
https://github.com/root-project/root/pull/4351:3827,Deployability,Release,Release,3827,"git dpkg-dev cmake binutils libx11-dev libxpm-dev \; libxft-dev libxext-dev; sudo apt-get install gfortran libssl-dev libpcre3-dev \; xlibmesa-glu-dev libglew1.5-dev libftgl-dev \; libmysqlclient-dev libfftw3-dev libcfitsio-dev \; graphviz-dev libavahi-compat-libdnssd-dev \; libldap2-dev python-dev libxml2-dev libkrb5-dev \; libgsl0-dev libqt4-dev; sudo apt install gdb. sudo apt install libstdc++ # then add flag -stdlib=libstdc++. wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh; (echo ''; echo 'yes'; echo ''; echo 'yes';) | bash ./Miniconda3-latest-Linux-x86_64.sh; source .bashrc; source activate base; pip install numpy sklearn xgboost matplotlib. #################################### install projects #############################3; # Get ROOT; cd; git clone git@github.com:LucaZampieri/root.git. # build with gcc; mkdir build_gcc && cd build_gcc && cmake ../root && make -j8. ## Google bench; cd; # Check out the library.; git clone https://github.com/google/benchmark.git; # Benchmark requires Google Test as a dependency. Add the source tree as a subdirectory.; git clone https://github.com/google/googletest.git benchmark/googletest. # Go to the library root directory; cd benchmark ; mkdir build_gcc; cd build_gcc ; cmake -DCMAKE_BUILD_TYPE=Release ../root && make -j8. # XGBoost; cd; git clone --recursive https://github.com/dmlc/xgboost; cd xgboost; mkdir build_gcc; cd build_gcc; cmake -DCMAKE_BUILD_TYPE=Release ../. # Setup aliases; echo ""alias bdt='cd ~/root/tmva/tmva/src/BDT'"" >> ~/.bashrc; source .bashrc. # Add the folders missing from github (add them directly in github?) ; cd; bdt ; git checkout backend/FastInference; mkdir build. # For ROOT; echo 'export ROOTSYS=""~/root/""' >> ~/.bashrc; echo 'export ROOTBUILD=""~/build_gcc/""' >> ~/.bashrc; echo 'source $ROOTBUILD/bin/thisroot.sh' >> ~/.bashrc. echo 'export XGBOOST_ROOT=""~/xgboost""' >> ~/.bashrc. echo 'export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:~/xgboost/lib/' >> ~/.bashrc. source .bashrc; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4351
https://github.com/root-project/root/pull/4351:156,Integrability,integrat,integrate,156,"# This PR is not meant to be merged but for documentation purposes. Implementation of fast inference for Decision Trees.; @stwunsch will make another PR to integrate properly into the root system.; ## Getting started; Required additional librairies; - ROOT; - for running tests you need Google Tests; - for running benchs, you need Google Benchs and XGBoost. ### Run tests ; Update the makefile in the tests folder, then execute `make clean && make && ./testAll.exe`; At the end of this text is a setup file for a new installation of ubuntu 18.04. ### Code structure; Here below we show the structure of the repository with the files of interest.; .; ├── bench.py; ├── bench.sh; ├── build/; ├── data/; ├── experiments/; │ ├── arrayBdtPreds.cxx; │ ├── data/; │ ├── generate_data.py; │ ├── makefile; │ ├── readme.md; │ ├── run_all.sh; │ └── setup.h; ├── figures/; ├── generated_files/; ├── include/; │ ├── BranchedTree.hxx; │ ├── BranchlessTree.hxx; │ ├── CodeGeneratorsJIT.hxx; │ ├── ForestHelpers.hxx; │ ├── json.hpp; │ ├── RForestInference.hxx; │ └── TreeHelpers.hxx; ├── makefile_bench.make; ├── README.md; ├── run.sh; ├── src/; │ └── benchmark.cxx; ├── tests/; │ ├── build/; │ ├── data/; │ │ ├── events.csv; │ │ ├── model.json; │ │ ├── model.rabbit; │ │ ├── multiclass_events.csv; │ │ ├── multiclass_model.json; │ │ ├── multiclass_model.rabbit; │ │ ├── multiclass_python_groundtruths.csv; │ │ ├── multiclass_python_predictions.csv; │ │ ├── multiclass_python_scores.csv; │ │ ├── python_predictions.csv; │ │ ├── regression_events.csv; │ │ ├── regression_model.json; │ │ ├── regression_model.rabbit; │ │ ├── regression_python_groundtruths.csv; │ │ ├── regression_python_predictions.csv; │ │ ├── regression_python_scores.csv; │ ├── forestBDTest.hxx; │ ├── helpersBDTest.hxx; │ ├── makefile; │ ├── readme.md; │ ├── RegressionBDTest.hxx; │ ├── run_all.sh; │ ├── testAll.cxx; ├── train_classifiers_examples.py; └── utils.py. ### Setup script for ubuntu 18.04; It sets up a new machine, installing everythi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4351
https://github.com/root-project/root/pull/4351:3427,Integrability,depend,dependency,3427,"git dpkg-dev cmake binutils libx11-dev libxpm-dev \; libxft-dev libxext-dev; sudo apt-get install gfortran libssl-dev libpcre3-dev \; xlibmesa-glu-dev libglew1.5-dev libftgl-dev \; libmysqlclient-dev libfftw3-dev libcfitsio-dev \; graphviz-dev libavahi-compat-libdnssd-dev \; libldap2-dev python-dev libxml2-dev libkrb5-dev \; libgsl0-dev libqt4-dev; sudo apt install gdb. sudo apt install libstdc++ # then add flag -stdlib=libstdc++. wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh; (echo ''; echo 'yes'; echo ''; echo 'yes';) | bash ./Miniconda3-latest-Linux-x86_64.sh; source .bashrc; source activate base; pip install numpy sklearn xgboost matplotlib. #################################### install projects #############################3; # Get ROOT; cd; git clone git@github.com:LucaZampieri/root.git. # build with gcc; mkdir build_gcc && cd build_gcc && cmake ../root && make -j8. ## Google bench; cd; # Check out the library.; git clone https://github.com/google/benchmark.git; # Benchmark requires Google Test as a dependency. Add the source tree as a subdirectory.; git clone https://github.com/google/googletest.git benchmark/googletest. # Go to the library root directory; cd benchmark ; mkdir build_gcc; cd build_gcc ; cmake -DCMAKE_BUILD_TYPE=Release ../root && make -j8. # XGBoost; cd; git clone --recursive https://github.com/dmlc/xgboost; cd xgboost; mkdir build_gcc; cd build_gcc; cmake -DCMAKE_BUILD_TYPE=Release ../. # Setup aliases; echo ""alias bdt='cd ~/root/tmva/tmva/src/BDT'"" >> ~/.bashrc; source .bashrc. # Add the folders missing from github (add them directly in github?) ; cd; bdt ; git checkout backend/FastInference; mkdir build. # For ROOT; echo 'export ROOTSYS=""~/root/""' >> ~/.bashrc; echo 'export ROOTBUILD=""~/build_gcc/""' >> ~/.bashrc; echo 'source $ROOTBUILD/bin/thisroot.sh' >> ~/.bashrc. echo 'export XGBOOST_ROOT=""~/xgboost""' >> ~/.bashrc. echo 'export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:~/xgboost/lib/' >> ~/.bashrc. source .bashrc; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4351
https://github.com/root-project/root/pull/4351:272,Testability,test,tests,272,"# This PR is not meant to be merged but for documentation purposes. Implementation of fast inference for Decision Trees.; @stwunsch will make another PR to integrate properly into the root system.; ## Getting started; Required additional librairies; - ROOT; - for running tests you need Google Tests; - for running benchs, you need Google Benchs and XGBoost. ### Run tests ; Update the makefile in the tests folder, then execute `make clean && make && ./testAll.exe`; At the end of this text is a setup file for a new installation of ubuntu 18.04. ### Code structure; Here below we show the structure of the repository with the files of interest.; .; ├── bench.py; ├── bench.sh; ├── build/; ├── data/; ├── experiments/; │ ├── arrayBdtPreds.cxx; │ ├── data/; │ ├── generate_data.py; │ ├── makefile; │ ├── readme.md; │ ├── run_all.sh; │ └── setup.h; ├── figures/; ├── generated_files/; ├── include/; │ ├── BranchedTree.hxx; │ ├── BranchlessTree.hxx; │ ├── CodeGeneratorsJIT.hxx; │ ├── ForestHelpers.hxx; │ ├── json.hpp; │ ├── RForestInference.hxx; │ └── TreeHelpers.hxx; ├── makefile_bench.make; ├── README.md; ├── run.sh; ├── src/; │ └── benchmark.cxx; ├── tests/; │ ├── build/; │ ├── data/; │ │ ├── events.csv; │ │ ├── model.json; │ │ ├── model.rabbit; │ │ ├── multiclass_events.csv; │ │ ├── multiclass_model.json; │ │ ├── multiclass_model.rabbit; │ │ ├── multiclass_python_groundtruths.csv; │ │ ├── multiclass_python_predictions.csv; │ │ ├── multiclass_python_scores.csv; │ │ ├── python_predictions.csv; │ │ ├── regression_events.csv; │ │ ├── regression_model.json; │ │ ├── regression_model.rabbit; │ │ ├── regression_python_groundtruths.csv; │ │ ├── regression_python_predictions.csv; │ │ ├── regression_python_scores.csv; │ ├── forestBDTest.hxx; │ ├── helpersBDTest.hxx; │ ├── makefile; │ ├── readme.md; │ ├── RegressionBDTest.hxx; │ ├── run_all.sh; │ ├── testAll.cxx; ├── train_classifiers_examples.py; └── utils.py. ### Setup script for ubuntu 18.04; It sets up a new machine, installing everythi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4351
https://github.com/root-project/root/pull/4351:294,Testability,Test,Tests,294,"# This PR is not meant to be merged but for documentation purposes. Implementation of fast inference for Decision Trees.; @stwunsch will make another PR to integrate properly into the root system.; ## Getting started; Required additional librairies; - ROOT; - for running tests you need Google Tests; - for running benchs, you need Google Benchs and XGBoost. ### Run tests ; Update the makefile in the tests folder, then execute `make clean && make && ./testAll.exe`; At the end of this text is a setup file for a new installation of ubuntu 18.04. ### Code structure; Here below we show the structure of the repository with the files of interest.; .; ├── bench.py; ├── bench.sh; ├── build/; ├── data/; ├── experiments/; │ ├── arrayBdtPreds.cxx; │ ├── data/; │ ├── generate_data.py; │ ├── makefile; │ ├── readme.md; │ ├── run_all.sh; │ └── setup.h; ├── figures/; ├── generated_files/; ├── include/; │ ├── BranchedTree.hxx; │ ├── BranchlessTree.hxx; │ ├── CodeGeneratorsJIT.hxx; │ ├── ForestHelpers.hxx; │ ├── json.hpp; │ ├── RForestInference.hxx; │ └── TreeHelpers.hxx; ├── makefile_bench.make; ├── README.md; ├── run.sh; ├── src/; │ └── benchmark.cxx; ├── tests/; │ ├── build/; │ ├── data/; │ │ ├── events.csv; │ │ ├── model.json; │ │ ├── model.rabbit; │ │ ├── multiclass_events.csv; │ │ ├── multiclass_model.json; │ │ ├── multiclass_model.rabbit; │ │ ├── multiclass_python_groundtruths.csv; │ │ ├── multiclass_python_predictions.csv; │ │ ├── multiclass_python_scores.csv; │ │ ├── python_predictions.csv; │ │ ├── regression_events.csv; │ │ ├── regression_model.json; │ │ ├── regression_model.rabbit; │ │ ├── regression_python_groundtruths.csv; │ │ ├── regression_python_predictions.csv; │ │ ├── regression_python_scores.csv; │ ├── forestBDTest.hxx; │ ├── helpersBDTest.hxx; │ ├── makefile; │ ├── readme.md; │ ├── RegressionBDTest.hxx; │ ├── run_all.sh; │ ├── testAll.cxx; ├── train_classifiers_examples.py; └── utils.py. ### Setup script for ubuntu 18.04; It sets up a new machine, installing everythi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4351
https://github.com/root-project/root/pull/4351:367,Testability,test,tests,367,"# This PR is not meant to be merged but for documentation purposes. Implementation of fast inference for Decision Trees.; @stwunsch will make another PR to integrate properly into the root system.; ## Getting started; Required additional librairies; - ROOT; - for running tests you need Google Tests; - for running benchs, you need Google Benchs and XGBoost. ### Run tests ; Update the makefile in the tests folder, then execute `make clean && make && ./testAll.exe`; At the end of this text is a setup file for a new installation of ubuntu 18.04. ### Code structure; Here below we show the structure of the repository with the files of interest.; .; ├── bench.py; ├── bench.sh; ├── build/; ├── data/; ├── experiments/; │ ├── arrayBdtPreds.cxx; │ ├── data/; │ ├── generate_data.py; │ ├── makefile; │ ├── readme.md; │ ├── run_all.sh; │ └── setup.h; ├── figures/; ├── generated_files/; ├── include/; │ ├── BranchedTree.hxx; │ ├── BranchlessTree.hxx; │ ├── CodeGeneratorsJIT.hxx; │ ├── ForestHelpers.hxx; │ ├── json.hpp; │ ├── RForestInference.hxx; │ └── TreeHelpers.hxx; ├── makefile_bench.make; ├── README.md; ├── run.sh; ├── src/; │ └── benchmark.cxx; ├── tests/; │ ├── build/; │ ├── data/; │ │ ├── events.csv; │ │ ├── model.json; │ │ ├── model.rabbit; │ │ ├── multiclass_events.csv; │ │ ├── multiclass_model.json; │ │ ├── multiclass_model.rabbit; │ │ ├── multiclass_python_groundtruths.csv; │ │ ├── multiclass_python_predictions.csv; │ │ ├── multiclass_python_scores.csv; │ │ ├── python_predictions.csv; │ │ ├── regression_events.csv; │ │ ├── regression_model.json; │ │ ├── regression_model.rabbit; │ │ ├── regression_python_groundtruths.csv; │ │ ├── regression_python_predictions.csv; │ │ ├── regression_python_scores.csv; │ ├── forestBDTest.hxx; │ ├── helpersBDTest.hxx; │ ├── makefile; │ ├── readme.md; │ ├── RegressionBDTest.hxx; │ ├── run_all.sh; │ ├── testAll.cxx; ├── train_classifiers_examples.py; └── utils.py. ### Setup script for ubuntu 18.04; It sets up a new machine, installing everythi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4351
https://github.com/root-project/root/pull/4351:402,Testability,test,tests,402,"# This PR is not meant to be merged but for documentation purposes. Implementation of fast inference for Decision Trees.; @stwunsch will make another PR to integrate properly into the root system.; ## Getting started; Required additional librairies; - ROOT; - for running tests you need Google Tests; - for running benchs, you need Google Benchs and XGBoost. ### Run tests ; Update the makefile in the tests folder, then execute `make clean && make && ./testAll.exe`; At the end of this text is a setup file for a new installation of ubuntu 18.04. ### Code structure; Here below we show the structure of the repository with the files of interest.; .; ├── bench.py; ├── bench.sh; ├── build/; ├── data/; ├── experiments/; │ ├── arrayBdtPreds.cxx; │ ├── data/; │ ├── generate_data.py; │ ├── makefile; │ ├── readme.md; │ ├── run_all.sh; │ └── setup.h; ├── figures/; ├── generated_files/; ├── include/; │ ├── BranchedTree.hxx; │ ├── BranchlessTree.hxx; │ ├── CodeGeneratorsJIT.hxx; │ ├── ForestHelpers.hxx; │ ├── json.hpp; │ ├── RForestInference.hxx; │ └── TreeHelpers.hxx; ├── makefile_bench.make; ├── README.md; ├── run.sh; ├── src/; │ └── benchmark.cxx; ├── tests/; │ ├── build/; │ ├── data/; │ │ ├── events.csv; │ │ ├── model.json; │ │ ├── model.rabbit; │ │ ├── multiclass_events.csv; │ │ ├── multiclass_model.json; │ │ ├── multiclass_model.rabbit; │ │ ├── multiclass_python_groundtruths.csv; │ │ ├── multiclass_python_predictions.csv; │ │ ├── multiclass_python_scores.csv; │ │ ├── python_predictions.csv; │ │ ├── regression_events.csv; │ │ ├── regression_model.json; │ │ ├── regression_model.rabbit; │ │ ├── regression_python_groundtruths.csv; │ │ ├── regression_python_predictions.csv; │ │ ├── regression_python_scores.csv; │ ├── forestBDTest.hxx; │ ├── helpersBDTest.hxx; │ ├── makefile; │ ├── readme.md; │ ├── RegressionBDTest.hxx; │ ├── run_all.sh; │ ├── testAll.cxx; ├── train_classifiers_examples.py; └── utils.py. ### Setup script for ubuntu 18.04; It sets up a new machine, installing everythi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4351
https://github.com/root-project/root/pull/4351:454,Testability,test,testAll,454,"# This PR is not meant to be merged but for documentation purposes. Implementation of fast inference for Decision Trees.; @stwunsch will make another PR to integrate properly into the root system.; ## Getting started; Required additional librairies; - ROOT; - for running tests you need Google Tests; - for running benchs, you need Google Benchs and XGBoost. ### Run tests ; Update the makefile in the tests folder, then execute `make clean && make && ./testAll.exe`; At the end of this text is a setup file for a new installation of ubuntu 18.04. ### Code structure; Here below we show the structure of the repository with the files of interest.; .; ├── bench.py; ├── bench.sh; ├── build/; ├── data/; ├── experiments/; │ ├── arrayBdtPreds.cxx; │ ├── data/; │ ├── generate_data.py; │ ├── makefile; │ ├── readme.md; │ ├── run_all.sh; │ └── setup.h; ├── figures/; ├── generated_files/; ├── include/; │ ├── BranchedTree.hxx; │ ├── BranchlessTree.hxx; │ ├── CodeGeneratorsJIT.hxx; │ ├── ForestHelpers.hxx; │ ├── json.hpp; │ ├── RForestInference.hxx; │ └── TreeHelpers.hxx; ├── makefile_bench.make; ├── README.md; ├── run.sh; ├── src/; │ └── benchmark.cxx; ├── tests/; │ ├── build/; │ ├── data/; │ │ ├── events.csv; │ │ ├── model.json; │ │ ├── model.rabbit; │ │ ├── multiclass_events.csv; │ │ ├── multiclass_model.json; │ │ ├── multiclass_model.rabbit; │ │ ├── multiclass_python_groundtruths.csv; │ │ ├── multiclass_python_predictions.csv; │ │ ├── multiclass_python_scores.csv; │ │ ├── python_predictions.csv; │ │ ├── regression_events.csv; │ │ ├── regression_model.json; │ │ ├── regression_model.rabbit; │ │ ├── regression_python_groundtruths.csv; │ │ ├── regression_python_predictions.csv; │ │ ├── regression_python_scores.csv; │ ├── forestBDTest.hxx; │ ├── helpersBDTest.hxx; │ ├── makefile; │ ├── readme.md; │ ├── RegressionBDTest.hxx; │ ├── run_all.sh; │ ├── testAll.cxx; ├── train_classifiers_examples.py; └── utils.py. ### Setup script for ubuntu 18.04; It sets up a new machine, installing everythi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4351
https://github.com/root-project/root/pull/4351:1137,Testability,benchmark,benchmark,1137,"will make another PR to integrate properly into the root system.; ## Getting started; Required additional librairies; - ROOT; - for running tests you need Google Tests; - for running benchs, you need Google Benchs and XGBoost. ### Run tests ; Update the makefile in the tests folder, then execute `make clean && make && ./testAll.exe`; At the end of this text is a setup file for a new installation of ubuntu 18.04. ### Code structure; Here below we show the structure of the repository with the files of interest.; .; ├── bench.py; ├── bench.sh; ├── build/; ├── data/; ├── experiments/; │ ├── arrayBdtPreds.cxx; │ ├── data/; │ ├── generate_data.py; │ ├── makefile; │ ├── readme.md; │ ├── run_all.sh; │ └── setup.h; ├── figures/; ├── generated_files/; ├── include/; │ ├── BranchedTree.hxx; │ ├── BranchlessTree.hxx; │ ├── CodeGeneratorsJIT.hxx; │ ├── ForestHelpers.hxx; │ ├── json.hpp; │ ├── RForestInference.hxx; │ └── TreeHelpers.hxx; ├── makefile_bench.make; ├── README.md; ├── run.sh; ├── src/; │ └── benchmark.cxx; ├── tests/; │ ├── build/; │ ├── data/; │ │ ├── events.csv; │ │ ├── model.json; │ │ ├── model.rabbit; │ │ ├── multiclass_events.csv; │ │ ├── multiclass_model.json; │ │ ├── multiclass_model.rabbit; │ │ ├── multiclass_python_groundtruths.csv; │ │ ├── multiclass_python_predictions.csv; │ │ ├── multiclass_python_scores.csv; │ │ ├── python_predictions.csv; │ │ ├── regression_events.csv; │ │ ├── regression_model.json; │ │ ├── regression_model.rabbit; │ │ ├── regression_python_groundtruths.csv; │ │ ├── regression_python_predictions.csv; │ │ ├── regression_python_scores.csv; │ ├── forestBDTest.hxx; │ ├── helpersBDTest.hxx; │ ├── makefile; │ ├── readme.md; │ ├── RegressionBDTest.hxx; │ ├── run_all.sh; │ ├── testAll.cxx; ├── train_classifiers_examples.py; └── utils.py. ### Setup script for ubuntu 18.04; It sets up a new machine, installing everything in the home folder. Please modify for your needs.; ```bash; #!/bin/bash; cd; # can be ran with yes | bash this_file.sh # to say ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4351
https://github.com/root-project/root/pull/4351:1156,Testability,test,tests,1156,"nto the root system.; ## Getting started; Required additional librairies; - ROOT; - for running tests you need Google Tests; - for running benchs, you need Google Benchs and XGBoost. ### Run tests ; Update the makefile in the tests folder, then execute `make clean && make && ./testAll.exe`; At the end of this text is a setup file for a new installation of ubuntu 18.04. ### Code structure; Here below we show the structure of the repository with the files of interest.; .; ├── bench.py; ├── bench.sh; ├── build/; ├── data/; ├── experiments/; │ ├── arrayBdtPreds.cxx; │ ├── data/; │ ├── generate_data.py; │ ├── makefile; │ ├── readme.md; │ ├── run_all.sh; │ └── setup.h; ├── figures/; ├── generated_files/; ├── include/; │ ├── BranchedTree.hxx; │ ├── BranchlessTree.hxx; │ ├── CodeGeneratorsJIT.hxx; │ ├── ForestHelpers.hxx; │ ├── json.hpp; │ ├── RForestInference.hxx; │ └── TreeHelpers.hxx; ├── makefile_bench.make; ├── README.md; ├── run.sh; ├── src/; │ └── benchmark.cxx; ├── tests/; │ ├── build/; │ ├── data/; │ │ ├── events.csv; │ │ ├── model.json; │ │ ├── model.rabbit; │ │ ├── multiclass_events.csv; │ │ ├── multiclass_model.json; │ │ ├── multiclass_model.rabbit; │ │ ├── multiclass_python_groundtruths.csv; │ │ ├── multiclass_python_predictions.csv; │ │ ├── multiclass_python_scores.csv; │ │ ├── python_predictions.csv; │ │ ├── regression_events.csv; │ │ ├── regression_model.json; │ │ ├── regression_model.rabbit; │ │ ├── regression_python_groundtruths.csv; │ │ ├── regression_python_predictions.csv; │ │ ├── regression_python_scores.csv; │ ├── forestBDTest.hxx; │ ├── helpersBDTest.hxx; │ ├── makefile; │ ├── readme.md; │ ├── RegressionBDTest.hxx; │ ├── run_all.sh; │ ├── testAll.cxx; ├── train_classifiers_examples.py; └── utils.py. ### Setup script for ubuntu 18.04; It sets up a new machine, installing everything in the home folder. Please modify for your needs.; ```bash; #!/bin/bash; cd; # can be ran with yes | bash this_file.sh # to say yes when prompted. sudo apt update ; yes | su",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4351
https://github.com/root-project/root/pull/4351:1859,Testability,test,testAll,1859,"s/; ├── generated_files/; ├── include/; │ ├── BranchedTree.hxx; │ ├── BranchlessTree.hxx; │ ├── CodeGeneratorsJIT.hxx; │ ├── ForestHelpers.hxx; │ ├── json.hpp; │ ├── RForestInference.hxx; │ └── TreeHelpers.hxx; ├── makefile_bench.make; ├── README.md; ├── run.sh; ├── src/; │ └── benchmark.cxx; ├── tests/; │ ├── build/; │ ├── data/; │ │ ├── events.csv; │ │ ├── model.json; │ │ ├── model.rabbit; │ │ ├── multiclass_events.csv; │ │ ├── multiclass_model.json; │ │ ├── multiclass_model.rabbit; │ │ ├── multiclass_python_groundtruths.csv; │ │ ├── multiclass_python_predictions.csv; │ │ ├── multiclass_python_scores.csv; │ │ ├── python_predictions.csv; │ │ ├── regression_events.csv; │ │ ├── regression_model.json; │ │ ├── regression_model.rabbit; │ │ ├── regression_python_groundtruths.csv; │ │ ├── regression_python_predictions.csv; │ │ ├── regression_python_scores.csv; │ ├── forestBDTest.hxx; │ ├── helpersBDTest.hxx; │ ├── makefile; │ ├── readme.md; │ ├── RegressionBDTest.hxx; │ ├── run_all.sh; │ ├── testAll.cxx; ├── train_classifiers_examples.py; └── utils.py. ### Setup script for ubuntu 18.04; It sets up a new machine, installing everything in the home folder. Please modify for your needs.; ```bash; #!/bin/bash; cd; # can be ran with yes | bash this_file.sh # to say yes when prompted. sudo apt update ; yes | sudo apt upgrade. # Install all the stuff with apt. sudo apt install clang # to use clang; sudo apt install g++-7 gcc-7 # to use gcc; sudo apt install libx11-dev build-essential cmake ; sudo apt install git dpkg-dev cmake binutils libx11-dev libxpm-dev \; libxft-dev libxext-dev; sudo apt-get install gfortran libssl-dev libpcre3-dev \; xlibmesa-glu-dev libglew1.5-dev libftgl-dev \; libmysqlclient-dev libfftw3-dev libcfitsio-dev \; graphviz-dev libavahi-compat-libdnssd-dev \; libldap2-dev python-dev libxml2-dev libkrb5-dev \; libgsl0-dev libqt4-dev; sudo apt install gdb. sudo apt install libstdc++ # then add flag -stdlib=libstdc++. wget https://repo.anaconda.com/miniconda/Mini",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4351
https://github.com/root-project/root/pull/4351:3374,Testability,benchmark,benchmark,3374,"tall git dpkg-dev cmake binutils libx11-dev libxpm-dev \; libxft-dev libxext-dev; sudo apt-get install gfortran libssl-dev libpcre3-dev \; xlibmesa-glu-dev libglew1.5-dev libftgl-dev \; libmysqlclient-dev libfftw3-dev libcfitsio-dev \; graphviz-dev libavahi-compat-libdnssd-dev \; libldap2-dev python-dev libxml2-dev libkrb5-dev \; libgsl0-dev libqt4-dev; sudo apt install gdb. sudo apt install libstdc++ # then add flag -stdlib=libstdc++. wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh; (echo ''; echo 'yes'; echo ''; echo 'yes';) | bash ./Miniconda3-latest-Linux-x86_64.sh; source .bashrc; source activate base; pip install numpy sklearn xgboost matplotlib. #################################### install projects #############################3; # Get ROOT; cd; git clone git@github.com:LucaZampieri/root.git. # build with gcc; mkdir build_gcc && cd build_gcc && cmake ../root && make -j8. ## Google bench; cd; # Check out the library.; git clone https://github.com/google/benchmark.git; # Benchmark requires Google Test as a dependency. Add the source tree as a subdirectory.; git clone https://github.com/google/googletest.git benchmark/googletest. # Go to the library root directory; cd benchmark ; mkdir build_gcc; cd build_gcc ; cmake -DCMAKE_BUILD_TYPE=Release ../root && make -j8. # XGBoost; cd; git clone --recursive https://github.com/dmlc/xgboost; cd xgboost; mkdir build_gcc; cd build_gcc; cmake -DCMAKE_BUILD_TYPE=Release ../. # Setup aliases; echo ""alias bdt='cd ~/root/tmva/tmva/src/BDT'"" >> ~/.bashrc; source .bashrc. # Add the folders missing from github (add them directly in github?) ; cd; bdt ; git checkout backend/FastInference; mkdir build. # For ROOT; echo 'export ROOTSYS=""~/root/""' >> ~/.bashrc; echo 'export ROOTBUILD=""~/build_gcc/""' >> ~/.bashrc; echo 'source $ROOTBUILD/bin/thisroot.sh' >> ~/.bashrc. echo 'export XGBOOST_ROOT=""~/xgboost""' >> ~/.bashrc. echo 'export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:~/xgboost/lib/' >> ~/.bashrc. source .bashrc;",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4351
https://github.com/root-project/root/pull/4351:3391,Testability,Benchmark,Benchmark,3391,"git dpkg-dev cmake binutils libx11-dev libxpm-dev \; libxft-dev libxext-dev; sudo apt-get install gfortran libssl-dev libpcre3-dev \; xlibmesa-glu-dev libglew1.5-dev libftgl-dev \; libmysqlclient-dev libfftw3-dev libcfitsio-dev \; graphviz-dev libavahi-compat-libdnssd-dev \; libldap2-dev python-dev libxml2-dev libkrb5-dev \; libgsl0-dev libqt4-dev; sudo apt install gdb. sudo apt install libstdc++ # then add flag -stdlib=libstdc++. wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh; (echo ''; echo 'yes'; echo ''; echo 'yes';) | bash ./Miniconda3-latest-Linux-x86_64.sh; source .bashrc; source activate base; pip install numpy sklearn xgboost matplotlib. #################################### install projects #############################3; # Get ROOT; cd; git clone git@github.com:LucaZampieri/root.git. # build with gcc; mkdir build_gcc && cd build_gcc && cmake ../root && make -j8. ## Google bench; cd; # Check out the library.; git clone https://github.com/google/benchmark.git; # Benchmark requires Google Test as a dependency. Add the source tree as a subdirectory.; git clone https://github.com/google/googletest.git benchmark/googletest. # Go to the library root directory; cd benchmark ; mkdir build_gcc; cd build_gcc ; cmake -DCMAKE_BUILD_TYPE=Release ../root && make -j8. # XGBoost; cd; git clone --recursive https://github.com/dmlc/xgboost; cd xgboost; mkdir build_gcc; cd build_gcc; cmake -DCMAKE_BUILD_TYPE=Release ../. # Setup aliases; echo ""alias bdt='cd ~/root/tmva/tmva/src/BDT'"" >> ~/.bashrc; source .bashrc. # Add the folders missing from github (add them directly in github?) ; cd; bdt ; git checkout backend/FastInference; mkdir build. # For ROOT; echo 'export ROOTSYS=""~/root/""' >> ~/.bashrc; echo 'export ROOTBUILD=""~/build_gcc/""' >> ~/.bashrc; echo 'source $ROOTBUILD/bin/thisroot.sh' >> ~/.bashrc. echo 'export XGBOOST_ROOT=""~/xgboost""' >> ~/.bashrc. echo 'export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:~/xgboost/lib/' >> ~/.bashrc. source .bashrc; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4351
https://github.com/root-project/root/pull/4351:3417,Testability,Test,Test,3417,"git dpkg-dev cmake binutils libx11-dev libxpm-dev \; libxft-dev libxext-dev; sudo apt-get install gfortran libssl-dev libpcre3-dev \; xlibmesa-glu-dev libglew1.5-dev libftgl-dev \; libmysqlclient-dev libfftw3-dev libcfitsio-dev \; graphviz-dev libavahi-compat-libdnssd-dev \; libldap2-dev python-dev libxml2-dev libkrb5-dev \; libgsl0-dev libqt4-dev; sudo apt install gdb. sudo apt install libstdc++ # then add flag -stdlib=libstdc++. wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh; (echo ''; echo 'yes'; echo ''; echo 'yes';) | bash ./Miniconda3-latest-Linux-x86_64.sh; source .bashrc; source activate base; pip install numpy sklearn xgboost matplotlib. #################################### install projects #############################3; # Get ROOT; cd; git clone git@github.com:LucaZampieri/root.git. # build with gcc; mkdir build_gcc && cd build_gcc && cmake ../root && make -j8. ## Google bench; cd; # Check out the library.; git clone https://github.com/google/benchmark.git; # Benchmark requires Google Test as a dependency. Add the source tree as a subdirectory.; git clone https://github.com/google/googletest.git benchmark/googletest. # Go to the library root directory; cd benchmark ; mkdir build_gcc; cd build_gcc ; cmake -DCMAKE_BUILD_TYPE=Release ../root && make -j8. # XGBoost; cd; git clone --recursive https://github.com/dmlc/xgboost; cd xgboost; mkdir build_gcc; cd build_gcc; cmake -DCMAKE_BUILD_TYPE=Release ../. # Setup aliases; echo ""alias bdt='cd ~/root/tmva/tmva/src/BDT'"" >> ~/.bashrc; source .bashrc. # Add the folders missing from github (add them directly in github?) ; cd; bdt ; git checkout backend/FastInference; mkdir build. # For ROOT; echo 'export ROOTSYS=""~/root/""' >> ~/.bashrc; echo 'export ROOTBUILD=""~/build_gcc/""' >> ~/.bashrc; echo 'source $ROOTBUILD/bin/thisroot.sh' >> ~/.bashrc. echo 'export XGBOOST_ROOT=""~/xgboost""' >> ~/.bashrc. echo 'export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:~/xgboost/lib/' >> ~/.bashrc. source .bashrc; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4351
https://github.com/root-project/root/pull/4351:3530,Testability,benchmark,benchmark,3530,"git dpkg-dev cmake binutils libx11-dev libxpm-dev \; libxft-dev libxext-dev; sudo apt-get install gfortran libssl-dev libpcre3-dev \; xlibmesa-glu-dev libglew1.5-dev libftgl-dev \; libmysqlclient-dev libfftw3-dev libcfitsio-dev \; graphviz-dev libavahi-compat-libdnssd-dev \; libldap2-dev python-dev libxml2-dev libkrb5-dev \; libgsl0-dev libqt4-dev; sudo apt install gdb. sudo apt install libstdc++ # then add flag -stdlib=libstdc++. wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh; (echo ''; echo 'yes'; echo ''; echo 'yes';) | bash ./Miniconda3-latest-Linux-x86_64.sh; source .bashrc; source activate base; pip install numpy sklearn xgboost matplotlib. #################################### install projects #############################3; # Get ROOT; cd; git clone git@github.com:LucaZampieri/root.git. # build with gcc; mkdir build_gcc && cd build_gcc && cmake ../root && make -j8. ## Google bench; cd; # Check out the library.; git clone https://github.com/google/benchmark.git; # Benchmark requires Google Test as a dependency. Add the source tree as a subdirectory.; git clone https://github.com/google/googletest.git benchmark/googletest. # Go to the library root directory; cd benchmark ; mkdir build_gcc; cd build_gcc ; cmake -DCMAKE_BUILD_TYPE=Release ../root && make -j8. # XGBoost; cd; git clone --recursive https://github.com/dmlc/xgboost; cd xgboost; mkdir build_gcc; cd build_gcc; cmake -DCMAKE_BUILD_TYPE=Release ../. # Setup aliases; echo ""alias bdt='cd ~/root/tmva/tmva/src/BDT'"" >> ~/.bashrc; source .bashrc. # Add the folders missing from github (add them directly in github?) ; cd; bdt ; git checkout backend/FastInference; mkdir build. # For ROOT; echo 'export ROOTSYS=""~/root/""' >> ~/.bashrc; echo 'export ROOTBUILD=""~/build_gcc/""' >> ~/.bashrc; echo 'source $ROOTBUILD/bin/thisroot.sh' >> ~/.bashrc. echo 'export XGBOOST_ROOT=""~/xgboost""' >> ~/.bashrc. echo 'export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:~/xgboost/lib/' >> ~/.bashrc. source .bashrc; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4351
https://github.com/root-project/root/pull/4351:3591,Testability,benchmark,benchmark,3591,"git dpkg-dev cmake binutils libx11-dev libxpm-dev \; libxft-dev libxext-dev; sudo apt-get install gfortran libssl-dev libpcre3-dev \; xlibmesa-glu-dev libglew1.5-dev libftgl-dev \; libmysqlclient-dev libfftw3-dev libcfitsio-dev \; graphviz-dev libavahi-compat-libdnssd-dev \; libldap2-dev python-dev libxml2-dev libkrb5-dev \; libgsl0-dev libqt4-dev; sudo apt install gdb. sudo apt install libstdc++ # then add flag -stdlib=libstdc++. wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh; (echo ''; echo 'yes'; echo ''; echo 'yes';) | bash ./Miniconda3-latest-Linux-x86_64.sh; source .bashrc; source activate base; pip install numpy sklearn xgboost matplotlib. #################################### install projects #############################3; # Get ROOT; cd; git clone git@github.com:LucaZampieri/root.git. # build with gcc; mkdir build_gcc && cd build_gcc && cmake ../root && make -j8. ## Google bench; cd; # Check out the library.; git clone https://github.com/google/benchmark.git; # Benchmark requires Google Test as a dependency. Add the source tree as a subdirectory.; git clone https://github.com/google/googletest.git benchmark/googletest. # Go to the library root directory; cd benchmark ; mkdir build_gcc; cd build_gcc ; cmake -DCMAKE_BUILD_TYPE=Release ../root && make -j8. # XGBoost; cd; git clone --recursive https://github.com/dmlc/xgboost; cd xgboost; mkdir build_gcc; cd build_gcc; cmake -DCMAKE_BUILD_TYPE=Release ../. # Setup aliases; echo ""alias bdt='cd ~/root/tmva/tmva/src/BDT'"" >> ~/.bashrc; source .bashrc. # Add the folders missing from github (add them directly in github?) ; cd; bdt ; git checkout backend/FastInference; mkdir build. # For ROOT; echo 'export ROOTSYS=""~/root/""' >> ~/.bashrc; echo 'export ROOTBUILD=""~/build_gcc/""' >> ~/.bashrc; echo 'source $ROOTBUILD/bin/thisroot.sh' >> ~/.bashrc. echo 'export XGBOOST_ROOT=""~/xgboost""' >> ~/.bashrc. echo 'export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:~/xgboost/lib/' >> ~/.bashrc. source .bashrc; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4351
https://github.com/root-project/root/pull/4352:553,Security,access,access,553,"This is very first attempt to make ROOT I/O conform RDrawable classes with attributes.; Means objects which are managed with `shared_ptr` duplicated by direct pointer, which is used only for I/O (see `RDrawableAttributes::fContIO` member in RDrawingAttr.hxx file). Attributes stored in `std::unordered_map<std::string, std::unique_ptr<Value_t>>` class. `Value_t` has several sub-classes. It potentially can be replaced by `std::variant<bool,int,double,std::string>` once we had it full support for I/O (especially for JSON). Special ""Visitor"" class can access or modify attributes. ""Visitor"" should be base class for all kind of LineAttr, FillAttr, ... classes. Visitor can has list of default values which first: specify name and kind of existing fields, and provide defaults which can be applied to the object. RStyleNew class is set blocks of attributes with selector rule (like in vanila CSS). For the moment selector not really implemented - just simple type of class match. I/O same as for attributes, therefore RStyleNew can be transported to client in same way as attributes. In JSON attributes storage looks like:; ```; ""fAttr"" : {; ""_typename"" : ""ROOT::Experimental::RDrawableAttributes"",; ""fContIO"" : {; ""_typename"" : ""ROOT::Experimental::RDrawableAttributes::Record_t"",; ""user_class"" : """",; ""map"" : {; ""_typename"": ""unordered_map<string,ROOT::Experimental::RDrawableAttributes::Value_t*>"", ; ""line_width"": {; ""_typename"" : ""ROOT::Experimental::RDrawableAttributes::DoubleValue_t"",; ""v"" : 2; }; }; }; }; ```; I can easily exclude ""_typename"" already now. ; Also one can implement compressions rule for `DoubleValue_t` class - store only ""v"" data member that finally we should get:; ```; ""line_width"": 2; ```; New DrawableAttributes class can be use in `RPadLength` implementation.; It has three components: ""fUser"", ""fPixel"", ""fNormal"". These components can be created only when really specified. This solves problem of **undefined** state for user-coordinate part.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4352
https://github.com/root-project/root/pull/4352:952,Usability,simpl,simple,952,"This is very first attempt to make ROOT I/O conform RDrawable classes with attributes.; Means objects which are managed with `shared_ptr` duplicated by direct pointer, which is used only for I/O (see `RDrawableAttributes::fContIO` member in RDrawingAttr.hxx file). Attributes stored in `std::unordered_map<std::string, std::unique_ptr<Value_t>>` class. `Value_t` has several sub-classes. It potentially can be replaced by `std::variant<bool,int,double,std::string>` once we had it full support for I/O (especially for JSON). Special ""Visitor"" class can access or modify attributes. ""Visitor"" should be base class for all kind of LineAttr, FillAttr, ... classes. Visitor can has list of default values which first: specify name and kind of existing fields, and provide defaults which can be applied to the object. RStyleNew class is set blocks of attributes with selector rule (like in vanila CSS). For the moment selector not really implemented - just simple type of class match. I/O same as for attributes, therefore RStyleNew can be transported to client in same way as attributes. In JSON attributes storage looks like:; ```; ""fAttr"" : {; ""_typename"" : ""ROOT::Experimental::RDrawableAttributes"",; ""fContIO"" : {; ""_typename"" : ""ROOT::Experimental::RDrawableAttributes::Record_t"",; ""user_class"" : """",; ""map"" : {; ""_typename"": ""unordered_map<string,ROOT::Experimental::RDrawableAttributes::Value_t*>"", ; ""line_width"": {; ""_typename"" : ""ROOT::Experimental::RDrawableAttributes::DoubleValue_t"",; ""v"" : 2; }; }; }; }; ```; I can easily exclude ""_typename"" already now. ; Also one can implement compressions rule for `DoubleValue_t` class - store only ""v"" data member that finally we should get:; ```; ""line_width"": 2; ```; New DrawableAttributes class can be use in `RPadLength` implementation.; It has three components: ""fUser"", ""fPixel"", ""fNormal"". These components can be created only when really specified. This solves problem of **undefined** state for user-coordinate part.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4352
https://github.com/root-project/root/pull/4355:11,Integrability,depend,dependencies,11,"The target dependencies only ensure the ordering, which is fine for builds from scratch, but doesn't always cause the PCH to be regenerated in incremental builds. Depending only on the source; or the object file, as in commit 07d25b24, unfortunately creates race conditions on the custom command that generates the source with rootcling. Using both and adding the dictionary files as; dependency in the DEPENDS argument of the custom command that creates the PCH creates dependencies both at the target level to ensure the ordering, but also at the file level to ensure that; the PCH is regenerated when necessary. Hopefully this will avoid the race conditions...",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4355
https://github.com/root-project/root/pull/4355:163,Integrability,Depend,Depending,163,"The target dependencies only ensure the ordering, which is fine for builds from scratch, but doesn't always cause the PCH to be regenerated in incremental builds. Depending only on the source; or the object file, as in commit 07d25b24, unfortunately creates race conditions on the custom command that generates the source with rootcling. Using both and adding the dictionary files as; dependency in the DEPENDS argument of the custom command that creates the PCH creates dependencies both at the target level to ensure the ordering, but also at the file level to ensure that; the PCH is regenerated when necessary. Hopefully this will avoid the race conditions...",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4355
https://github.com/root-project/root/pull/4355:385,Integrability,depend,dependency,385,"The target dependencies only ensure the ordering, which is fine for builds from scratch, but doesn't always cause the PCH to be regenerated in incremental builds. Depending only on the source; or the object file, as in commit 07d25b24, unfortunately creates race conditions on the custom command that generates the source with rootcling. Using both and adding the dictionary files as; dependency in the DEPENDS argument of the custom command that creates the PCH creates dependencies both at the target level to ensure the ordering, but also at the file level to ensure that; the PCH is regenerated when necessary. Hopefully this will avoid the race conditions...",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4355
https://github.com/root-project/root/pull/4355:403,Integrability,DEPEND,DEPENDS,403,"The target dependencies only ensure the ordering, which is fine for builds from scratch, but doesn't always cause the PCH to be regenerated in incremental builds. Depending only on the source; or the object file, as in commit 07d25b24, unfortunately creates race conditions on the custom command that generates the source with rootcling. Using both and adding the dictionary files as; dependency in the DEPENDS argument of the custom command that creates the PCH creates dependencies both at the target level to ensure the ordering, but also at the file level to ensure that; the PCH is regenerated when necessary. Hopefully this will avoid the race conditions...",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4355
https://github.com/root-project/root/pull/4355:471,Integrability,depend,dependencies,471,"The target dependencies only ensure the ordering, which is fine for builds from scratch, but doesn't always cause the PCH to be regenerated in incremental builds. Depending only on the source; or the object file, as in commit 07d25b24, unfortunately creates race conditions on the custom command that generates the source with rootcling. Using both and adding the dictionary files as; dependency in the DEPENDS argument of the custom command that creates the PCH creates dependencies both at the target level to ensure the ordering, but also at the file level to ensure that; the PCH is regenerated when necessary. Hopefully this will avoid the race conditions...",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4355
https://github.com/root-project/root/pull/4355:258,Performance,race condition,race conditions,258,"The target dependencies only ensure the ordering, which is fine for builds from scratch, but doesn't always cause the PCH to be regenerated in incremental builds. Depending only on the source; or the object file, as in commit 07d25b24, unfortunately creates race conditions on the custom command that generates the source with rootcling. Using both and adding the dictionary files as; dependency in the DEPENDS argument of the custom command that creates the PCH creates dependencies both at the target level to ensure the ordering, but also at the file level to ensure that; the PCH is regenerated when necessary. Hopefully this will avoid the race conditions...",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4355
https://github.com/root-project/root/pull/4355:645,Performance,race condition,race conditions,645,"The target dependencies only ensure the ordering, which is fine for builds from scratch, but doesn't always cause the PCH to be regenerated in incremental builds. Depending only on the source; or the object file, as in commit 07d25b24, unfortunately creates race conditions on the custom command that generates the source with rootcling. Using both and adding the dictionary files as; dependency in the DEPENDS argument of the custom command that creates the PCH creates dependencies both at the target level to ensure the ordering, but also at the file level to ensure that; the PCH is regenerated when necessary. Hopefully this will avoid the race conditions...",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4355
https://github.com/root-project/root/pull/4355:635,Safety,avoid,avoid,635,"The target dependencies only ensure the ordering, which is fine for builds from scratch, but doesn't always cause the PCH to be regenerated in incremental builds. Depending only on the source; or the object file, as in commit 07d25b24, unfortunately creates race conditions on the custom command that generates the source with rootcling. Using both and adding the dictionary files as; dependency in the DEPENDS argument of the custom command that creates the PCH creates dependencies both at the target level to ensure the ordering, but also at the file level to ensure that; the PCH is regenerated when necessary. Hopefully this will avoid the race conditions...",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4355
https://github.com/root-project/root/pull/4356:558,Deployability,patch,patch,558,"root-project/root@72fe06a does not permit passing random options to rootcling; as improvement in encapsulation. Rootcling used to permit random flags usually; coming CXXFLAGS and it captured only -I, -D and -U. The old implementation; used to pass all flags directly to cling thus clang. This lead to allowing; the dictionaries to be compiled with incompatible to the rest of the build; flags. Some users passed their entire CXXFLAGS from the build systems and the current; rootcling implementation started to reject it breaking backward compatibility. This patch implements a sink for all unrecognized flags and issues a deprecation; message. Should address the rest of the concerns of ROOT-10303.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4356
https://github.com/root-project/root/pull/4356:635,Integrability,message,message,635,"root-project/root@72fe06a does not permit passing random options to rootcling; as improvement in encapsulation. Rootcling used to permit random flags usually; coming CXXFLAGS and it captured only -I, -D and -U. The old implementation; used to pass all flags directly to cling thus clang. This lead to allowing; the dictionaries to be compiled with incompatible to the rest of the build; flags. Some users passed their entire CXXFLAGS from the build systems and the current; rootcling implementation started to reject it breaking backward compatibility. This patch implements a sink for all unrecognized flags and issues a deprecation; message. Should address the rest of the concerns of ROOT-10303.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4356
https://github.com/root-project/root/pull/4357:6,Performance,optimiz,optimization,6,"Minor optimization found by looking at profiles a while ago... `GetSpecialProtocols()` takes the global lock, so it's best to avoid calling it too much.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4357
https://github.com/root-project/root/pull/4357:126,Safety,avoid,avoid,126,"Minor optimization found by looking at profiles a while ago... `GetSpecialProtocols()` takes the global lock, so it's best to avoid calling it too much.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4357
https://github.com/root-project/root/pull/4362:124,Availability,error,error,124,The pythonization RDataFrame.AsNumpy looks for the attribute; RDataFrameAsNumpy_ in the ROOT module and raises an attribute error if not found.; This error can not be triggered if ROOT is imported but is raised if; RDataFrame is accessed through cppyy.gbl. This PR implements a; protection for this skipping the pythonization if the pythonizer; function is not found in the ROOT module.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4362
https://github.com/root-project/root/pull/4362:150,Availability,error,error,150,The pythonization RDataFrame.AsNumpy looks for the attribute; RDataFrameAsNumpy_ in the ROOT module and raises an attribute error if not found.; This error can not be triggered if ROOT is imported but is raised if; RDataFrame is accessed through cppyy.gbl. This PR implements a; protection for this skipping the pythonization if the pythonizer; function is not found in the ROOT module.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4362
https://github.com/root-project/root/pull/4362:229,Security,access,accessed,229,The pythonization RDataFrame.AsNumpy looks for the attribute; RDataFrameAsNumpy_ in the ROOT module and raises an attribute error if not found.; This error can not be triggered if ROOT is imported but is raised if; RDataFrame is accessed through cppyy.gbl. This PR implements a; protection for this skipping the pythonization if the pythonizer; function is not found in the ROOT module.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4362
https://github.com/root-project/root/pull/4367:72,Integrability,depend,dependency,72,"When calling ROOT_EXECUTABLE from outside of ROOT (e.g. roottest), the; dependency on move_headers, which only works in the project ROOT,; must be ignored.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4367
https://github.com/root-project/root/pull/4372:178,Availability,failure,failure,178,"A previous commit dropped the use of PyROOT_PyUnicode_AsStringChecked, which in Py2 corresponds to PyString_AsString, which accepts unicode objects. This PR should fix this test failure seen in the nightlies:; http://cdash.cern.ch/testSummary.php?project=1&name=roottest-python-JupyROOT-simpleCppMagic_notebook&date=2019-09-10",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4372
https://github.com/root-project/root/pull/4372:173,Testability,test,test,173,"A previous commit dropped the use of PyROOT_PyUnicode_AsStringChecked, which in Py2 corresponds to PyString_AsString, which accepts unicode objects. This PR should fix this test failure seen in the nightlies:; http://cdash.cern.ch/testSummary.php?project=1&name=roottest-python-JupyROOT-simpleCppMagic_notebook&date=2019-09-10",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4372
https://github.com/root-project/root/pull/4372:231,Testability,test,testSummary,231,"A previous commit dropped the use of PyROOT_PyUnicode_AsStringChecked, which in Py2 corresponds to PyString_AsString, which accepts unicode objects. This PR should fix this test failure seen in the nightlies:; http://cdash.cern.ch/testSummary.php?project=1&name=roottest-python-JupyROOT-simpleCppMagic_notebook&date=2019-09-10",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4372
https://github.com/root-project/root/pull/4376:68,Availability,error,errors,68,"Convert back slashes into forward slashes. This fixes the following errors on Windows:; input_line_12(12,4): error G954FC62D: \U used with no following hex digits [C:\Users\bellenot\build\release\onepcm.vcxproj]; ""C:\Users\bellenot\libs\GSL\2.5\include"",; ^~; input_line_12(13,4): error G954FC62D: \U used with no following hex digits [C:\Users\bellenot\build\release\onepcm.vcxproj]; ""C:\Users\bellenot\libs\libxml2\2.7.8\include"",; ^~; CUSTOMBUILD : error : .\bin\rootcling: compilation failure (./allDictd5c5124b81_dictContent.h) [C:\Users\bellenot\build\release\onepcm.vcxproj]",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4376
https://github.com/root-project/root/pull/4376:109,Availability,error,error,109,"Convert back slashes into forward slashes. This fixes the following errors on Windows:; input_line_12(12,4): error G954FC62D: \U used with no following hex digits [C:\Users\bellenot\build\release\onepcm.vcxproj]; ""C:\Users\bellenot\libs\GSL\2.5\include"",; ^~; input_line_12(13,4): error G954FC62D: \U used with no following hex digits [C:\Users\bellenot\build\release\onepcm.vcxproj]; ""C:\Users\bellenot\libs\libxml2\2.7.8\include"",; ^~; CUSTOMBUILD : error : .\bin\rootcling: compilation failure (./allDictd5c5124b81_dictContent.h) [C:\Users\bellenot\build\release\onepcm.vcxproj]",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4376
https://github.com/root-project/root/pull/4376:281,Availability,error,error,281,"Convert back slashes into forward slashes. This fixes the following errors on Windows:; input_line_12(12,4): error G954FC62D: \U used with no following hex digits [C:\Users\bellenot\build\release\onepcm.vcxproj]; ""C:\Users\bellenot\libs\GSL\2.5\include"",; ^~; input_line_12(13,4): error G954FC62D: \U used with no following hex digits [C:\Users\bellenot\build\release\onepcm.vcxproj]; ""C:\Users\bellenot\libs\libxml2\2.7.8\include"",; ^~; CUSTOMBUILD : error : .\bin\rootcling: compilation failure (./allDictd5c5124b81_dictContent.h) [C:\Users\bellenot\build\release\onepcm.vcxproj]",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4376
https://github.com/root-project/root/pull/4376:452,Availability,error,error,452,"Convert back slashes into forward slashes. This fixes the following errors on Windows:; input_line_12(12,4): error G954FC62D: \U used with no following hex digits [C:\Users\bellenot\build\release\onepcm.vcxproj]; ""C:\Users\bellenot\libs\GSL\2.5\include"",; ^~; input_line_12(13,4): error G954FC62D: \U used with no following hex digits [C:\Users\bellenot\build\release\onepcm.vcxproj]; ""C:\Users\bellenot\libs\libxml2\2.7.8\include"",; ^~; CUSTOMBUILD : error : .\bin\rootcling: compilation failure (./allDictd5c5124b81_dictContent.h) [C:\Users\bellenot\build\release\onepcm.vcxproj]",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4376
https://github.com/root-project/root/pull/4376:489,Availability,failure,failure,489,"Convert back slashes into forward slashes. This fixes the following errors on Windows:; input_line_12(12,4): error G954FC62D: \U used with no following hex digits [C:\Users\bellenot\build\release\onepcm.vcxproj]; ""C:\Users\bellenot\libs\GSL\2.5\include"",; ^~; input_line_12(13,4): error G954FC62D: \U used with no following hex digits [C:\Users\bellenot\build\release\onepcm.vcxproj]; ""C:\Users\bellenot\libs\libxml2\2.7.8\include"",; ^~; CUSTOMBUILD : error : .\bin\rootcling: compilation failure (./allDictd5c5124b81_dictContent.h) [C:\Users\bellenot\build\release\onepcm.vcxproj]",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4376
https://github.com/root-project/root/pull/4376:188,Deployability,release,release,188,"Convert back slashes into forward slashes. This fixes the following errors on Windows:; input_line_12(12,4): error G954FC62D: \U used with no following hex digits [C:\Users\bellenot\build\release\onepcm.vcxproj]; ""C:\Users\bellenot\libs\GSL\2.5\include"",; ^~; input_line_12(13,4): error G954FC62D: \U used with no following hex digits [C:\Users\bellenot\build\release\onepcm.vcxproj]; ""C:\Users\bellenot\libs\libxml2\2.7.8\include"",; ^~; CUSTOMBUILD : error : .\bin\rootcling: compilation failure (./allDictd5c5124b81_dictContent.h) [C:\Users\bellenot\build\release\onepcm.vcxproj]",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4376
https://github.com/root-project/root/pull/4376:360,Deployability,release,release,360,"Convert back slashes into forward slashes. This fixes the following errors on Windows:; input_line_12(12,4): error G954FC62D: \U used with no following hex digits [C:\Users\bellenot\build\release\onepcm.vcxproj]; ""C:\Users\bellenot\libs\GSL\2.5\include"",; ^~; input_line_12(13,4): error G954FC62D: \U used with no following hex digits [C:\Users\bellenot\build\release\onepcm.vcxproj]; ""C:\Users\bellenot\libs\libxml2\2.7.8\include"",; ^~; CUSTOMBUILD : error : .\bin\rootcling: compilation failure (./allDictd5c5124b81_dictContent.h) [C:\Users\bellenot\build\release\onepcm.vcxproj]",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4376
https://github.com/root-project/root/pull/4376:558,Deployability,release,release,558,"Convert back slashes into forward slashes. This fixes the following errors on Windows:; input_line_12(12,4): error G954FC62D: \U used with no following hex digits [C:\Users\bellenot\build\release\onepcm.vcxproj]; ""C:\Users\bellenot\libs\GSL\2.5\include"",; ^~; input_line_12(13,4): error G954FC62D: \U used with no following hex digits [C:\Users\bellenot\build\release\onepcm.vcxproj]; ""C:\Users\bellenot\libs\libxml2\2.7.8\include"",; ^~; CUSTOMBUILD : error : .\bin\rootcling: compilation failure (./allDictd5c5124b81_dictContent.h) [C:\Users\bellenot\build\release\onepcm.vcxproj]",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4376
https://github.com/root-project/root/pull/4381:116,Availability,error,errors,116,"Convert the backslashes into forward slashes in the include path for rootcling on Windows. This fixes the following errors:; input_line_12(12,4): error G954FC62D: \U used with no following hex digits [C:\Users\bellenot\build\release\onepcm.vcxproj]; ""C:\Users\bellenot\libs\GSL\2.5\include"",; ^~; input_line_12(13,4): error G954FC62D: \U used with no following hex digits [C:\Users\bellenot\build\release\onepcm.vcxproj]; ""C:\Users\bellenot\libs\libxml2\2.7.8\include"",; ^~; CUSTOMBUILD : error : .\bin\rootcling: compilation failure (./allDictd5c5124b81_dictContent.h) [C:\Users\bellenot\build\release\onepcm.vcxproj]. And (when using ACLiC):; Info in <TWinNTSystem::ACLiC>: creating shared library C:/Users/bellenot/build/debug/core/dictgen/test/myextramacro_C.dll; input_line_12:7:4: error: \U used with no following hex digits; ""C:\Users\bellenot\build\debug\include"",; ^~; Error in <ACLiC>: Dictionary generation failed!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4381
https://github.com/root-project/root/pull/4381:146,Availability,error,error,146,"Convert the backslashes into forward slashes in the include path for rootcling on Windows. This fixes the following errors:; input_line_12(12,4): error G954FC62D: \U used with no following hex digits [C:\Users\bellenot\build\release\onepcm.vcxproj]; ""C:\Users\bellenot\libs\GSL\2.5\include"",; ^~; input_line_12(13,4): error G954FC62D: \U used with no following hex digits [C:\Users\bellenot\build\release\onepcm.vcxproj]; ""C:\Users\bellenot\libs\libxml2\2.7.8\include"",; ^~; CUSTOMBUILD : error : .\bin\rootcling: compilation failure (./allDictd5c5124b81_dictContent.h) [C:\Users\bellenot\build\release\onepcm.vcxproj]. And (when using ACLiC):; Info in <TWinNTSystem::ACLiC>: creating shared library C:/Users/bellenot/build/debug/core/dictgen/test/myextramacro_C.dll; input_line_12:7:4: error: \U used with no following hex digits; ""C:\Users\bellenot\build\debug\include"",; ^~; Error in <ACLiC>: Dictionary generation failed!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4381
https://github.com/root-project/root/pull/4381:318,Availability,error,error,318,"Convert the backslashes into forward slashes in the include path for rootcling on Windows. This fixes the following errors:; input_line_12(12,4): error G954FC62D: \U used with no following hex digits [C:\Users\bellenot\build\release\onepcm.vcxproj]; ""C:\Users\bellenot\libs\GSL\2.5\include"",; ^~; input_line_12(13,4): error G954FC62D: \U used with no following hex digits [C:\Users\bellenot\build\release\onepcm.vcxproj]; ""C:\Users\bellenot\libs\libxml2\2.7.8\include"",; ^~; CUSTOMBUILD : error : .\bin\rootcling: compilation failure (./allDictd5c5124b81_dictContent.h) [C:\Users\bellenot\build\release\onepcm.vcxproj]. And (when using ACLiC):; Info in <TWinNTSystem::ACLiC>: creating shared library C:/Users/bellenot/build/debug/core/dictgen/test/myextramacro_C.dll; input_line_12:7:4: error: \U used with no following hex digits; ""C:\Users\bellenot\build\debug\include"",; ^~; Error in <ACLiC>: Dictionary generation failed!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4381
https://github.com/root-project/root/pull/4381:489,Availability,error,error,489,"Convert the backslashes into forward slashes in the include path for rootcling on Windows. This fixes the following errors:; input_line_12(12,4): error G954FC62D: \U used with no following hex digits [C:\Users\bellenot\build\release\onepcm.vcxproj]; ""C:\Users\bellenot\libs\GSL\2.5\include"",; ^~; input_line_12(13,4): error G954FC62D: \U used with no following hex digits [C:\Users\bellenot\build\release\onepcm.vcxproj]; ""C:\Users\bellenot\libs\libxml2\2.7.8\include"",; ^~; CUSTOMBUILD : error : .\bin\rootcling: compilation failure (./allDictd5c5124b81_dictContent.h) [C:\Users\bellenot\build\release\onepcm.vcxproj]. And (when using ACLiC):; Info in <TWinNTSystem::ACLiC>: creating shared library C:/Users/bellenot/build/debug/core/dictgen/test/myextramacro_C.dll; input_line_12:7:4: error: \U used with no following hex digits; ""C:\Users\bellenot\build\debug\include"",; ^~; Error in <ACLiC>: Dictionary generation failed!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4381
https://github.com/root-project/root/pull/4381:526,Availability,failure,failure,526,"Convert the backslashes into forward slashes in the include path for rootcling on Windows. This fixes the following errors:; input_line_12(12,4): error G954FC62D: \U used with no following hex digits [C:\Users\bellenot\build\release\onepcm.vcxproj]; ""C:\Users\bellenot\libs\GSL\2.5\include"",; ^~; input_line_12(13,4): error G954FC62D: \U used with no following hex digits [C:\Users\bellenot\build\release\onepcm.vcxproj]; ""C:\Users\bellenot\libs\libxml2\2.7.8\include"",; ^~; CUSTOMBUILD : error : .\bin\rootcling: compilation failure (./allDictd5c5124b81_dictContent.h) [C:\Users\bellenot\build\release\onepcm.vcxproj]. And (when using ACLiC):; Info in <TWinNTSystem::ACLiC>: creating shared library C:/Users/bellenot/build/debug/core/dictgen/test/myextramacro_C.dll; input_line_12:7:4: error: \U used with no following hex digits; ""C:\Users\bellenot\build\debug\include"",; ^~; Error in <ACLiC>: Dictionary generation failed!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4381
https://github.com/root-project/root/pull/4381:787,Availability,error,error,787,"Convert the backslashes into forward slashes in the include path for rootcling on Windows. This fixes the following errors:; input_line_12(12,4): error G954FC62D: \U used with no following hex digits [C:\Users\bellenot\build\release\onepcm.vcxproj]; ""C:\Users\bellenot\libs\GSL\2.5\include"",; ^~; input_line_12(13,4): error G954FC62D: \U used with no following hex digits [C:\Users\bellenot\build\release\onepcm.vcxproj]; ""C:\Users\bellenot\libs\libxml2\2.7.8\include"",; ^~; CUSTOMBUILD : error : .\bin\rootcling: compilation failure (./allDictd5c5124b81_dictContent.h) [C:\Users\bellenot\build\release\onepcm.vcxproj]. And (when using ACLiC):; Info in <TWinNTSystem::ACLiC>: creating shared library C:/Users/bellenot/build/debug/core/dictgen/test/myextramacro_C.dll; input_line_12:7:4: error: \U used with no following hex digits; ""C:\Users\bellenot\build\debug\include"",; ^~; Error in <ACLiC>: Dictionary generation failed!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4381
https://github.com/root-project/root/pull/4381:878,Availability,Error,Error,878,"Convert the backslashes into forward slashes in the include path for rootcling on Windows. This fixes the following errors:; input_line_12(12,4): error G954FC62D: \U used with no following hex digits [C:\Users\bellenot\build\release\onepcm.vcxproj]; ""C:\Users\bellenot\libs\GSL\2.5\include"",; ^~; input_line_12(13,4): error G954FC62D: \U used with no following hex digits [C:\Users\bellenot\build\release\onepcm.vcxproj]; ""C:\Users\bellenot\libs\libxml2\2.7.8\include"",; ^~; CUSTOMBUILD : error : .\bin\rootcling: compilation failure (./allDictd5c5124b81_dictContent.h) [C:\Users\bellenot\build\release\onepcm.vcxproj]. And (when using ACLiC):; Info in <TWinNTSystem::ACLiC>: creating shared library C:/Users/bellenot/build/debug/core/dictgen/test/myextramacro_C.dll; input_line_12:7:4: error: \U used with no following hex digits; ""C:\Users\bellenot\build\debug\include"",; ^~; Error in <ACLiC>: Dictionary generation failed!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4381
https://github.com/root-project/root/pull/4381:225,Deployability,release,release,225,"Convert the backslashes into forward slashes in the include path for rootcling on Windows. This fixes the following errors:; input_line_12(12,4): error G954FC62D: \U used with no following hex digits [C:\Users\bellenot\build\release\onepcm.vcxproj]; ""C:\Users\bellenot\libs\GSL\2.5\include"",; ^~; input_line_12(13,4): error G954FC62D: \U used with no following hex digits [C:\Users\bellenot\build\release\onepcm.vcxproj]; ""C:\Users\bellenot\libs\libxml2\2.7.8\include"",; ^~; CUSTOMBUILD : error : .\bin\rootcling: compilation failure (./allDictd5c5124b81_dictContent.h) [C:\Users\bellenot\build\release\onepcm.vcxproj]. And (when using ACLiC):; Info in <TWinNTSystem::ACLiC>: creating shared library C:/Users/bellenot/build/debug/core/dictgen/test/myextramacro_C.dll; input_line_12:7:4: error: \U used with no following hex digits; ""C:\Users\bellenot\build\debug\include"",; ^~; Error in <ACLiC>: Dictionary generation failed!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4381
https://github.com/root-project/root/pull/4381:397,Deployability,release,release,397,"Convert the backslashes into forward slashes in the include path for rootcling on Windows. This fixes the following errors:; input_line_12(12,4): error G954FC62D: \U used with no following hex digits [C:\Users\bellenot\build\release\onepcm.vcxproj]; ""C:\Users\bellenot\libs\GSL\2.5\include"",; ^~; input_line_12(13,4): error G954FC62D: \U used with no following hex digits [C:\Users\bellenot\build\release\onepcm.vcxproj]; ""C:\Users\bellenot\libs\libxml2\2.7.8\include"",; ^~; CUSTOMBUILD : error : .\bin\rootcling: compilation failure (./allDictd5c5124b81_dictContent.h) [C:\Users\bellenot\build\release\onepcm.vcxproj]. And (when using ACLiC):; Info in <TWinNTSystem::ACLiC>: creating shared library C:/Users/bellenot/build/debug/core/dictgen/test/myextramacro_C.dll; input_line_12:7:4: error: \U used with no following hex digits; ""C:\Users\bellenot\build\debug\include"",; ^~; Error in <ACLiC>: Dictionary generation failed!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4381
https://github.com/root-project/root/pull/4381:595,Deployability,release,release,595,"Convert the backslashes into forward slashes in the include path for rootcling on Windows. This fixes the following errors:; input_line_12(12,4): error G954FC62D: \U used with no following hex digits [C:\Users\bellenot\build\release\onepcm.vcxproj]; ""C:\Users\bellenot\libs\GSL\2.5\include"",; ^~; input_line_12(13,4): error G954FC62D: \U used with no following hex digits [C:\Users\bellenot\build\release\onepcm.vcxproj]; ""C:\Users\bellenot\libs\libxml2\2.7.8\include"",; ^~; CUSTOMBUILD : error : .\bin\rootcling: compilation failure (./allDictd5c5124b81_dictContent.h) [C:\Users\bellenot\build\release\onepcm.vcxproj]. And (when using ACLiC):; Info in <TWinNTSystem::ACLiC>: creating shared library C:/Users/bellenot/build/debug/core/dictgen/test/myextramacro_C.dll; input_line_12:7:4: error: \U used with no following hex digits; ""C:\Users\bellenot\build\debug\include"",; ^~; Error in <ACLiC>: Dictionary generation failed!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4381
https://github.com/root-project/root/pull/4381:743,Testability,test,test,743,"Convert the backslashes into forward slashes in the include path for rootcling on Windows. This fixes the following errors:; input_line_12(12,4): error G954FC62D: \U used with no following hex digits [C:\Users\bellenot\build\release\onepcm.vcxproj]; ""C:\Users\bellenot\libs\GSL\2.5\include"",; ^~; input_line_12(13,4): error G954FC62D: \U used with no following hex digits [C:\Users\bellenot\build\release\onepcm.vcxproj]; ""C:\Users\bellenot\libs\libxml2\2.7.8\include"",; ^~; CUSTOMBUILD : error : .\bin\rootcling: compilation failure (./allDictd5c5124b81_dictContent.h) [C:\Users\bellenot\build\release\onepcm.vcxproj]. And (when using ACLiC):; Info in <TWinNTSystem::ACLiC>: creating shared library C:/Users/bellenot/build/debug/core/dictgen/test/myextramacro_C.dll; input_line_12:7:4: error: \U used with no following hex digits; ""C:\Users\bellenot\build\debug\include"",; ^~; Error in <ACLiC>: Dictionary generation failed!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4381
https://github.com/root-project/root/pull/4383:119,Integrability,wrap,wrapped,119,"RooFit contains a number of functions that cannot be used as PDFs since; they don't have automatic normalisation. When wrapped into the wrapper; PDF, functions can be used in the same way as PDFs.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4383
https://github.com/root-project/root/pull/4383:136,Integrability,wrap,wrapper,136,"RooFit contains a number of functions that cannot be used as PDFs since; they don't have automatic normalisation. When wrapped into the wrapper; PDF, functions can be used in the same way as PDFs.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4383
https://github.com/root-project/root/pull/4386:5,Deployability,update,updates,5,"This updates the following cppyy packages to the indicated versions:; - cppyy: cppyy-1.5.3; - cppyy_backend: clingwrapper-1.10.3; - CPyCppyy: CPyCppyy-1.9.3. This incorporates a fix for the issue reported here:; https://bitbucket.org/wlav/cppyy/issues/160/memoryregulator-and-the-deletion-of-python. and also this PR:; https://bitbucket.org/wlav/cppyy-backend/pull-requests/21/fix-logic-and-silence-wparentheses-warning. There are still two remaining Cppyy issues not solved yet by this update, which affect a few tests:; https://bitbucket.org/wlav/cppyy/issues/136/item-assignment-not-working-in-templated; https://bitbucket.org/wlav/cppyy/issues/145/enum-values-not-defined-as-constants",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4386
https://github.com/root-project/root/pull/4386:487,Deployability,update,update,487,"This updates the following cppyy packages to the indicated versions:; - cppyy: cppyy-1.5.3; - cppyy_backend: clingwrapper-1.10.3; - CPyCppyy: CPyCppyy-1.9.3. This incorporates a fix for the issue reported here:; https://bitbucket.org/wlav/cppyy/issues/160/memoryregulator-and-the-deletion-of-python. and also this PR:; https://bitbucket.org/wlav/cppyy-backend/pull-requests/21/fix-logic-and-silence-wparentheses-warning. There are still two remaining Cppyy issues not solved yet by this update, which affect a few tests:; https://bitbucket.org/wlav/cppyy/issues/136/item-assignment-not-working-in-templated; https://bitbucket.org/wlav/cppyy/issues/145/enum-values-not-defined-as-constants",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4386
https://github.com/root-project/root/pull/4386:381,Testability,log,logic-and-silence-wparentheses-warning,381,"This updates the following cppyy packages to the indicated versions:; - cppyy: cppyy-1.5.3; - cppyy_backend: clingwrapper-1.10.3; - CPyCppyy: CPyCppyy-1.9.3. This incorporates a fix for the issue reported here:; https://bitbucket.org/wlav/cppyy/issues/160/memoryregulator-and-the-deletion-of-python. and also this PR:; https://bitbucket.org/wlav/cppyy-backend/pull-requests/21/fix-logic-and-silence-wparentheses-warning. There are still two remaining Cppyy issues not solved yet by this update, which affect a few tests:; https://bitbucket.org/wlav/cppyy/issues/136/item-assignment-not-working-in-templated; https://bitbucket.org/wlav/cppyy/issues/145/enum-values-not-defined-as-constants",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4386
https://github.com/root-project/root/pull/4386:514,Testability,test,tests,514,"This updates the following cppyy packages to the indicated versions:; - cppyy: cppyy-1.5.3; - cppyy_backend: clingwrapper-1.10.3; - CPyCppyy: CPyCppyy-1.9.3. This incorporates a fix for the issue reported here:; https://bitbucket.org/wlav/cppyy/issues/160/memoryregulator-and-the-deletion-of-python. and also this PR:; https://bitbucket.org/wlav/cppyy-backend/pull-requests/21/fix-logic-and-silence-wparentheses-warning. There are still two remaining Cppyy issues not solved yet by this update, which affect a few tests:; https://bitbucket.org/wlav/cppyy/issues/136/item-assignment-not-working-in-templated; https://bitbucket.org/wlav/cppyy/issues/145/enum-values-not-defined-as-constants",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4386
https://github.com/root-project/root/pull/4389:1001,Deployability,Update,Update,1001," ROOT-10216. In brief, the changes are to replace lookup by simpler search to avoid nested; initialization of TClasses (leading to the outer nested initialization; to end using deleted memory). Some explanation of the reasons for and details of the actual changes. With. ```; namespace User {; class TrackerVtxBase; class BeamFlux : public User::TrackerVtxBase; class NTrackerVtx : public User::BeamFlux; }; ```. We had a crash during BuildOld for User::BeamFlux. ```; User::TBaseObject triggers replacement routines.; reaches NTrackerVtx; calls (unnecessary) TStreamerBase::InitStreaming() and BuildOld for BeamFlux; in BuildOld look at base User::TrackerVtxBase (and record pointer value in baseclass); calls Init on the TStreamerElement base; this triggers the creation of the TClass for User::TrackerVtxBase; but BuildOld kept a stale pointer to the old TClass (was baseclass variable).; ```. Solution: replace raw pointer by a TClassRef. TCompInfo::Update did a TClass::GetClass for all type that were not classes :(; Usually it is just a waste of time.; In this case, one such type is User::TContext::Time (an enum) use as part; of User::TContext .. Consequently, before the dictionary TClass for User::TContext was constructed,; another class requested the update of the emulated StreamerInfo for the (still); emulated User::TContext, this in turn provoked the (unnecessary) call to; TClass::GetClass on ‘User::TContext::Time’ which provoked the creation of; the TClass for User::TContext … one of the steps is to absorb the existing; StreamerInfo (including the one being updated) and clear them (i.e. delete; the TCompInfo array) … upon return the result of the TClass::GetClass (a nullptr); is stored in deleted memory. Solution: Don’t call TClass::GetClass on non-type. ```; User::TDatum is loaded; provokes update of a StreamerInfo with a TTrueParticle; *spurrious* InitStreaming provoke need for TTrueParticle TClass; start consuming the TTrueParticle TProtoClass; needs the TTrueVertex ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4389
https://github.com/root-project/root/pull/4389:1311,Deployability,update,update,1311," public User::BeamFlux; }; ```. We had a crash during BuildOld for User::BeamFlux. ```; User::TBaseObject triggers replacement routines.; reaches NTrackerVtx; calls (unnecessary) TStreamerBase::InitStreaming() and BuildOld for BeamFlux; in BuildOld look at base User::TrackerVtxBase (and record pointer value in baseclass); calls Init on the TStreamerElement base; this triggers the creation of the TClass for User::TrackerVtxBase; but BuildOld kept a stale pointer to the old TClass (was baseclass variable).; ```. Solution: replace raw pointer by a TClassRef. TCompInfo::Update did a TClass::GetClass for all type that were not classes :(; Usually it is just a waste of time.; In this case, one such type is User::TContext::Time (an enum) use as part; of User::TContext .. Consequently, before the dictionary TClass for User::TContext was constructed,; another class requested the update of the emulated StreamerInfo for the (still); emulated User::TContext, this in turn provoked the (unnecessary) call to; TClass::GetClass on ‘User::TContext::Time’ which provoked the creation of; the TClass for User::TContext … one of the steps is to absorb the existing; StreamerInfo (including the one being updated) and clear them (i.e. delete; the TCompInfo array) … upon return the result of the TClass::GetClass (a nullptr); is stored in deleted memory. Solution: Don’t call TClass::GetClass on non-type. ```; User::TDatum is loaded; provokes update of a StreamerInfo with a TTrueParticle; *spurrious* InitStreaming provoke need for TTrueParticle TClass; start consuming the TTrueParticle TProtoClass; needs the TTrueVertex TClass; provokes update of a StreamerInfo with a TBaseObject; *spurrious* InitStreaming provoke need for TBaseObject TClass; needs the TTrueParticle TClass; Consumes the TTrueParticle TProtoClass; return fine with a good TTrueVertex TClass; continue using the already “cleared” TTrueParticle TProtoClass; ```. Solution: significant update of TStreamerElement::Update and TStreamerB",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4389
https://github.com/root-project/root/pull/4389:1627,Deployability,update,updated,1627," public User::BeamFlux; }; ```. We had a crash during BuildOld for User::BeamFlux. ```; User::TBaseObject triggers replacement routines.; reaches NTrackerVtx; calls (unnecessary) TStreamerBase::InitStreaming() and BuildOld for BeamFlux; in BuildOld look at base User::TrackerVtxBase (and record pointer value in baseclass); calls Init on the TStreamerElement base; this triggers the creation of the TClass for User::TrackerVtxBase; but BuildOld kept a stale pointer to the old TClass (was baseclass variable).; ```. Solution: replace raw pointer by a TClassRef. TCompInfo::Update did a TClass::GetClass for all type that were not classes :(; Usually it is just a waste of time.; In this case, one such type is User::TContext::Time (an enum) use as part; of User::TContext .. Consequently, before the dictionary TClass for User::TContext was constructed,; another class requested the update of the emulated StreamerInfo for the (still); emulated User::TContext, this in turn provoked the (unnecessary) call to; TClass::GetClass on ‘User::TContext::Time’ which provoked the creation of; the TClass for User::TContext … one of the steps is to absorb the existing; StreamerInfo (including the one being updated) and clear them (i.e. delete; the TCompInfo array) … upon return the result of the TClass::GetClass (a nullptr); is stored in deleted memory. Solution: Don’t call TClass::GetClass on non-type. ```; User::TDatum is loaded; provokes update of a StreamerInfo with a TTrueParticle; *spurrious* InitStreaming provoke need for TTrueParticle TClass; start consuming the TTrueParticle TProtoClass; needs the TTrueVertex TClass; provokes update of a StreamerInfo with a TBaseObject; *spurrious* InitStreaming provoke need for TBaseObject TClass; needs the TTrueParticle TClass; Consumes the TTrueParticle TProtoClass; return fine with a good TTrueVertex TClass; continue using the already “cleared” TTrueParticle TProtoClass; ```. Solution: significant update of TStreamerElement::Update and TStreamerB",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4389
https://github.com/root-project/root/pull/4389:1866,Deployability,update,update,1866,":InitStreaming() and BuildOld for BeamFlux; in BuildOld look at base User::TrackerVtxBase (and record pointer value in baseclass); calls Init on the TStreamerElement base; this triggers the creation of the TClass for User::TrackerVtxBase; but BuildOld kept a stale pointer to the old TClass (was baseclass variable).; ```. Solution: replace raw pointer by a TClassRef. TCompInfo::Update did a TClass::GetClass for all type that were not classes :(; Usually it is just a waste of time.; In this case, one such type is User::TContext::Time (an enum) use as part; of User::TContext .. Consequently, before the dictionary TClass for User::TContext was constructed,; another class requested the update of the emulated StreamerInfo for the (still); emulated User::TContext, this in turn provoked the (unnecessary) call to; TClass::GetClass on ‘User::TContext::Time’ which provoked the creation of; the TClass for User::TContext … one of the steps is to absorb the existing; StreamerInfo (including the one being updated) and clear them (i.e. delete; the TCompInfo array) … upon return the result of the TClass::GetClass (a nullptr); is stored in deleted memory. Solution: Don’t call TClass::GetClass on non-type. ```; User::TDatum is loaded; provokes update of a StreamerInfo with a TTrueParticle; *spurrious* InitStreaming provoke need for TTrueParticle TClass; start consuming the TTrueParticle TProtoClass; needs the TTrueVertex TClass; provokes update of a StreamerInfo with a TBaseObject; *spurrious* InitStreaming provoke need for TBaseObject TClass; needs the TTrueParticle TClass; Consumes the TTrueParticle TProtoClass; return fine with a good TTrueVertex TClass; continue using the already “cleared” TTrueParticle TProtoClass; ```. Solution: significant update of TStreamerElement::Update and TStreamerBase::Update; to call TStreamerBase::InitStreamer if and only if there was a change in the base; class pointer, and to call TClass::GetClass only if there is a chance of finding; a new TClass ….",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4389
https://github.com/root-project/root/pull/4389:2064,Deployability,update,update,2064,":InitStreaming() and BuildOld for BeamFlux; in BuildOld look at base User::TrackerVtxBase (and record pointer value in baseclass); calls Init on the TStreamerElement base; this triggers the creation of the TClass for User::TrackerVtxBase; but BuildOld kept a stale pointer to the old TClass (was baseclass variable).; ```. Solution: replace raw pointer by a TClassRef. TCompInfo::Update did a TClass::GetClass for all type that were not classes :(; Usually it is just a waste of time.; In this case, one such type is User::TContext::Time (an enum) use as part; of User::TContext .. Consequently, before the dictionary TClass for User::TContext was constructed,; another class requested the update of the emulated StreamerInfo for the (still); emulated User::TContext, this in turn provoked the (unnecessary) call to; TClass::GetClass on ‘User::TContext::Time’ which provoked the creation of; the TClass for User::TContext … one of the steps is to absorb the existing; StreamerInfo (including the one being updated) and clear them (i.e. delete; the TCompInfo array) … upon return the result of the TClass::GetClass (a nullptr); is stored in deleted memory. Solution: Don’t call TClass::GetClass on non-type. ```; User::TDatum is loaded; provokes update of a StreamerInfo with a TTrueParticle; *spurrious* InitStreaming provoke need for TTrueParticle TClass; start consuming the TTrueParticle TProtoClass; needs the TTrueVertex TClass; provokes update of a StreamerInfo with a TBaseObject; *spurrious* InitStreaming provoke need for TBaseObject TClass; needs the TTrueParticle TClass; Consumes the TTrueParticle TProtoClass; return fine with a good TTrueVertex TClass; continue using the already “cleared” TTrueParticle TProtoClass; ```. Solution: significant update of TStreamerElement::Update and TStreamerBase::Update; to call TStreamerBase::InitStreamer if and only if there was a change in the base; class pointer, and to call TClass::GetClass only if there is a chance of finding; a new TClass ….",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4389
https://github.com/root-project/root/pull/4389:2379,Deployability,update,update,2379,":InitStreaming() and BuildOld for BeamFlux; in BuildOld look at base User::TrackerVtxBase (and record pointer value in baseclass); calls Init on the TStreamerElement base; this triggers the creation of the TClass for User::TrackerVtxBase; but BuildOld kept a stale pointer to the old TClass (was baseclass variable).; ```. Solution: replace raw pointer by a TClassRef. TCompInfo::Update did a TClass::GetClass for all type that were not classes :(; Usually it is just a waste of time.; In this case, one such type is User::TContext::Time (an enum) use as part; of User::TContext .. Consequently, before the dictionary TClass for User::TContext was constructed,; another class requested the update of the emulated StreamerInfo for the (still); emulated User::TContext, this in turn provoked the (unnecessary) call to; TClass::GetClass on ‘User::TContext::Time’ which provoked the creation of; the TClass for User::TContext … one of the steps is to absorb the existing; StreamerInfo (including the one being updated) and clear them (i.e. delete; the TCompInfo array) … upon return the result of the TClass::GetClass (a nullptr); is stored in deleted memory. Solution: Don’t call TClass::GetClass on non-type. ```; User::TDatum is loaded; provokes update of a StreamerInfo with a TTrueParticle; *spurrious* InitStreaming provoke need for TTrueParticle TClass; start consuming the TTrueParticle TProtoClass; needs the TTrueVertex TClass; provokes update of a StreamerInfo with a TBaseObject; *spurrious* InitStreaming provoke need for TBaseObject TClass; needs the TTrueParticle TClass; Consumes the TTrueParticle TProtoClass; return fine with a good TTrueVertex TClass; continue using the already “cleared” TTrueParticle TProtoClass; ```. Solution: significant update of TStreamerElement::Update and TStreamerBase::Update; to call TStreamerBase::InitStreamer if and only if there was a change in the base; class pointer, and to call TClass::GetClass only if there is a chance of finding; a new TClass ….",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4389
https://github.com/root-project/root/pull/4389:2407,Deployability,Update,Update,2407,":InitStreaming() and BuildOld for BeamFlux; in BuildOld look at base User::TrackerVtxBase (and record pointer value in baseclass); calls Init on the TStreamerElement base; this triggers the creation of the TClass for User::TrackerVtxBase; but BuildOld kept a stale pointer to the old TClass (was baseclass variable).; ```. Solution: replace raw pointer by a TClassRef. TCompInfo::Update did a TClass::GetClass for all type that were not classes :(; Usually it is just a waste of time.; In this case, one such type is User::TContext::Time (an enum) use as part; of User::TContext .. Consequently, before the dictionary TClass for User::TContext was constructed,; another class requested the update of the emulated StreamerInfo for the (still); emulated User::TContext, this in turn provoked the (unnecessary) call to; TClass::GetClass on ‘User::TContext::Time’ which provoked the creation of; the TClass for User::TContext … one of the steps is to absorb the existing; StreamerInfo (including the one being updated) and clear them (i.e. delete; the TCompInfo array) … upon return the result of the TClass::GetClass (a nullptr); is stored in deleted memory. Solution: Don’t call TClass::GetClass on non-type. ```; User::TDatum is loaded; provokes update of a StreamerInfo with a TTrueParticle; *spurrious* InitStreaming provoke need for TTrueParticle TClass; start consuming the TTrueParticle TProtoClass; needs the TTrueVertex TClass; provokes update of a StreamerInfo with a TBaseObject; *spurrious* InitStreaming provoke need for TBaseObject TClass; needs the TTrueParticle TClass; Consumes the TTrueParticle TProtoClass; return fine with a good TTrueVertex TClass; continue using the already “cleared” TTrueParticle TProtoClass; ```. Solution: significant update of TStreamerElement::Update and TStreamerBase::Update; to call TStreamerBase::InitStreamer if and only if there was a change in the base; class pointer, and to call TClass::GetClass only if there is a chance of finding; a new TClass ….",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4389
https://github.com/root-project/root/pull/4389:2433,Deployability,Update,Update,2433,":InitStreaming() and BuildOld for BeamFlux; in BuildOld look at base User::TrackerVtxBase (and record pointer value in baseclass); calls Init on the TStreamerElement base; this triggers the creation of the TClass for User::TrackerVtxBase; but BuildOld kept a stale pointer to the old TClass (was baseclass variable).; ```. Solution: replace raw pointer by a TClassRef. TCompInfo::Update did a TClass::GetClass for all type that were not classes :(; Usually it is just a waste of time.; In this case, one such type is User::TContext::Time (an enum) use as part; of User::TContext .. Consequently, before the dictionary TClass for User::TContext was constructed,; another class requested the update of the emulated StreamerInfo for the (still); emulated User::TContext, this in turn provoked the (unnecessary) call to; TClass::GetClass on ‘User::TContext::Time’ which provoked the creation of; the TClass for User::TContext … one of the steps is to absorb the existing; StreamerInfo (including the one being updated) and clear them (i.e. delete; the TCompInfo array) … upon return the result of the TClass::GetClass (a nullptr); is stored in deleted memory. Solution: Don’t call TClass::GetClass on non-type. ```; User::TDatum is loaded; provokes update of a StreamerInfo with a TTrueParticle; *spurrious* InitStreaming provoke need for TTrueParticle TClass; start consuming the TTrueParticle TProtoClass; needs the TTrueVertex TClass; provokes update of a StreamerInfo with a TBaseObject; *spurrious* InitStreaming provoke need for TBaseObject TClass; needs the TTrueParticle TClass; Consumes the TTrueParticle TProtoClass; return fine with a good TTrueVertex TClass; continue using the already “cleared” TTrueParticle TProtoClass; ```. Solution: significant update of TStreamerElement::Update and TStreamerBase::Update; to call TStreamerBase::InitStreamer if and only if there was a change in the base; class pointer, and to call TClass::GetClass only if there is a chance of finding; a new TClass ….",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4389
https://github.com/root-project/root/pull/4389:555,Integrability,rout,routines,555,"This should be the last crop of fixes needed by ROOT-10216. In brief, the changes are to replace lookup by simpler search to avoid nested; initialization of TClasses (leading to the outer nested initialization; to end using deleted memory). Some explanation of the reasons for and details of the actual changes. With. ```; namespace User {; class TrackerVtxBase; class BeamFlux : public User::TrackerVtxBase; class NTrackerVtx : public User::BeamFlux; }; ```. We had a crash during BuildOld for User::BeamFlux. ```; User::TBaseObject triggers replacement routines.; reaches NTrackerVtx; calls (unnecessary) TStreamerBase::InitStreaming() and BuildOld for BeamFlux; in BuildOld look at base User::TrackerVtxBase (and record pointer value in baseclass); calls Init on the TStreamerElement base; this triggers the creation of the TClass for User::TrackerVtxBase; but BuildOld kept a stale pointer to the old TClass (was baseclass variable).; ```. Solution: replace raw pointer by a TClassRef. TCompInfo::Update did a TClass::GetClass for all type that were not classes :(; Usually it is just a waste of time.; In this case, one such type is User::TContext::Time (an enum) use as part; of User::TContext .. Consequently, before the dictionary TClass for User::TContext was constructed,; another class requested the update of the emulated StreamerInfo for the (still); emulated User::TContext, this in turn provoked the (unnecessary) call to; TClass::GetClass on ‘User::TContext::Time’ which provoked the creation of; the TClass for User::TContext … one of the steps is to absorb the existing; StreamerInfo (including the one being updated) and clear them (i.e. delete; the TCompInfo array) … upon return the result of the TClass::GetClass (a nullptr); is stored in deleted memory. Solution: Don’t call TClass::GetClass on non-type. ```; User::TDatum is loaded; provokes update of a StreamerInfo with a TTrueParticle; *spurrious* InitStreaming provoke need for TTrueParticle TClass; start consuming the TTr",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4389
https://github.com/root-project/root/pull/4389:927,Modifiability,variab,variable,927,"This should be the last crop of fixes needed by ROOT-10216. In brief, the changes are to replace lookup by simpler search to avoid nested; initialization of TClasses (leading to the outer nested initialization; to end using deleted memory). Some explanation of the reasons for and details of the actual changes. With. ```; namespace User {; class TrackerVtxBase; class BeamFlux : public User::TrackerVtxBase; class NTrackerVtx : public User::BeamFlux; }; ```. We had a crash during BuildOld for User::BeamFlux. ```; User::TBaseObject triggers replacement routines.; reaches NTrackerVtx; calls (unnecessary) TStreamerBase::InitStreaming() and BuildOld for BeamFlux; in BuildOld look at base User::TrackerVtxBase (and record pointer value in baseclass); calls Init on the TStreamerElement base; this triggers the creation of the TClass for User::TrackerVtxBase; but BuildOld kept a stale pointer to the old TClass (was baseclass variable).; ```. Solution: replace raw pointer by a TClassRef. TCompInfo::Update did a TClass::GetClass for all type that were not classes :(; Usually it is just a waste of time.; In this case, one such type is User::TContext::Time (an enum) use as part; of User::TContext .. Consequently, before the dictionary TClass for User::TContext was constructed,; another class requested the update of the emulated StreamerInfo for the (still); emulated User::TContext, this in turn provoked the (unnecessary) call to; TClass::GetClass on ‘User::TContext::Time’ which provoked the creation of; the TClass for User::TContext … one of the steps is to absorb the existing; StreamerInfo (including the one being updated) and clear them (i.e. delete; the TCompInfo array) … upon return the result of the TClass::GetClass (a nullptr); is stored in deleted memory. Solution: Don’t call TClass::GetClass on non-type. ```; User::TDatum is loaded; provokes update of a StreamerInfo with a TTrueParticle; *spurrious* InitStreaming provoke need for TTrueParticle TClass; start consuming the TTr",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4389
https://github.com/root-project/root/pull/4389:1849,Performance,load,loaded,1849,":InitStreaming() and BuildOld for BeamFlux; in BuildOld look at base User::TrackerVtxBase (and record pointer value in baseclass); calls Init on the TStreamerElement base; this triggers the creation of the TClass for User::TrackerVtxBase; but BuildOld kept a stale pointer to the old TClass (was baseclass variable).; ```. Solution: replace raw pointer by a TClassRef. TCompInfo::Update did a TClass::GetClass for all type that were not classes :(; Usually it is just a waste of time.; In this case, one such type is User::TContext::Time (an enum) use as part; of User::TContext .. Consequently, before the dictionary TClass for User::TContext was constructed,; another class requested the update of the emulated StreamerInfo for the (still); emulated User::TContext, this in turn provoked the (unnecessary) call to; TClass::GetClass on ‘User::TContext::Time’ which provoked the creation of; the TClass for User::TContext … one of the steps is to absorb the existing; StreamerInfo (including the one being updated) and clear them (i.e. delete; the TCompInfo array) … upon return the result of the TClass::GetClass (a nullptr); is stored in deleted memory. Solution: Don’t call TClass::GetClass on non-type. ```; User::TDatum is loaded; provokes update of a StreamerInfo with a TTrueParticle; *spurrious* InitStreaming provoke need for TTrueParticle TClass; start consuming the TTrueParticle TProtoClass; needs the TTrueVertex TClass; provokes update of a StreamerInfo with a TBaseObject; *spurrious* InitStreaming provoke need for TBaseObject TClass; needs the TTrueParticle TClass; Consumes the TTrueParticle TProtoClass; return fine with a good TTrueVertex TClass; continue using the already “cleared” TTrueParticle TProtoClass; ```. Solution: significant update of TStreamerElement::Update and TStreamerBase::Update; to call TStreamerBase::InitStreamer if and only if there was a change in the base; class pointer, and to call TClass::GetClass only if there is a chance of finding; a new TClass ….",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4389
https://github.com/root-project/root/pull/4389:125,Safety,avoid,avoid,125,"This should be the last crop of fixes needed by ROOT-10216. In brief, the changes are to replace lookup by simpler search to avoid nested; initialization of TClasses (leading to the outer nested initialization; to end using deleted memory). Some explanation of the reasons for and details of the actual changes. With. ```; namespace User {; class TrackerVtxBase; class BeamFlux : public User::TrackerVtxBase; class NTrackerVtx : public User::BeamFlux; }; ```. We had a crash during BuildOld for User::BeamFlux. ```; User::TBaseObject triggers replacement routines.; reaches NTrackerVtx; calls (unnecessary) TStreamerBase::InitStreaming() and BuildOld for BeamFlux; in BuildOld look at base User::TrackerVtxBase (and record pointer value in baseclass); calls Init on the TStreamerElement base; this triggers the creation of the TClass for User::TrackerVtxBase; but BuildOld kept a stale pointer to the old TClass (was baseclass variable).; ```. Solution: replace raw pointer by a TClassRef. TCompInfo::Update did a TClass::GetClass for all type that were not classes :(; Usually it is just a waste of time.; In this case, one such type is User::TContext::Time (an enum) use as part; of User::TContext .. Consequently, before the dictionary TClass for User::TContext was constructed,; another class requested the update of the emulated StreamerInfo for the (still); emulated User::TContext, this in turn provoked the (unnecessary) call to; TClass::GetClass on ‘User::TContext::Time’ which provoked the creation of; the TClass for User::TContext … one of the steps is to absorb the existing; StreamerInfo (including the one being updated) and clear them (i.e. delete; the TCompInfo array) … upon return the result of the TClass::GetClass (a nullptr); is stored in deleted memory. Solution: Don’t call TClass::GetClass on non-type. ```; User::TDatum is loaded; provokes update of a StreamerInfo with a TTrueParticle; *spurrious* InitStreaming provoke need for TTrueParticle TClass; start consuming the TTr",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4389
https://github.com/root-project/root/pull/4389:107,Usability,simpl,simpler,107,"This should be the last crop of fixes needed by ROOT-10216. In brief, the changes are to replace lookup by simpler search to avoid nested; initialization of TClasses (leading to the outer nested initialization; to end using deleted memory). Some explanation of the reasons for and details of the actual changes. With. ```; namespace User {; class TrackerVtxBase; class BeamFlux : public User::TrackerVtxBase; class NTrackerVtx : public User::BeamFlux; }; ```. We had a crash during BuildOld for User::BeamFlux. ```; User::TBaseObject triggers replacement routines.; reaches NTrackerVtx; calls (unnecessary) TStreamerBase::InitStreaming() and BuildOld for BeamFlux; in BuildOld look at base User::TrackerVtxBase (and record pointer value in baseclass); calls Init on the TStreamerElement base; this triggers the creation of the TClass for User::TrackerVtxBase; but BuildOld kept a stale pointer to the old TClass (was baseclass variable).; ```. Solution: replace raw pointer by a TClassRef. TCompInfo::Update did a TClass::GetClass for all type that were not classes :(; Usually it is just a waste of time.; In this case, one such type is User::TContext::Time (an enum) use as part; of User::TContext .. Consequently, before the dictionary TClass for User::TContext was constructed,; another class requested the update of the emulated StreamerInfo for the (still); emulated User::TContext, this in turn provoked the (unnecessary) call to; TClass::GetClass on ‘User::TContext::Time’ which provoked the creation of; the TClass for User::TContext … one of the steps is to absorb the existing; StreamerInfo (including the one being updated) and clear them (i.e. delete; the TCompInfo array) … upon return the result of the TClass::GetClass (a nullptr); is stored in deleted memory. Solution: Don’t call TClass::GetClass on non-type. ```; User::TDatum is loaded; provokes update of a StreamerInfo with a TTrueParticle; *spurrious* InitStreaming provoke need for TTrueParticle TClass; start consuming the TTr",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4389
https://github.com/root-project/root/pull/4389:1640,Usability,clear,clear,1640," public User::BeamFlux; }; ```. We had a crash during BuildOld for User::BeamFlux. ```; User::TBaseObject triggers replacement routines.; reaches NTrackerVtx; calls (unnecessary) TStreamerBase::InitStreaming() and BuildOld for BeamFlux; in BuildOld look at base User::TrackerVtxBase (and record pointer value in baseclass); calls Init on the TStreamerElement base; this triggers the creation of the TClass for User::TrackerVtxBase; but BuildOld kept a stale pointer to the old TClass (was baseclass variable).; ```. Solution: replace raw pointer by a TClassRef. TCompInfo::Update did a TClass::GetClass for all type that were not classes :(; Usually it is just a waste of time.; In this case, one such type is User::TContext::Time (an enum) use as part; of User::TContext .. Consequently, before the dictionary TClass for User::TContext was constructed,; another class requested the update of the emulated StreamerInfo for the (still); emulated User::TContext, this in turn provoked the (unnecessary) call to; TClass::GetClass on ‘User::TContext::Time’ which provoked the creation of; the TClass for User::TContext … one of the steps is to absorb the existing; StreamerInfo (including the one being updated) and clear them (i.e. delete; the TCompInfo array) … upon return the result of the TClass::GetClass (a nullptr); is stored in deleted memory. Solution: Don’t call TClass::GetClass on non-type. ```; User::TDatum is loaded; provokes update of a StreamerInfo with a TTrueParticle; *spurrious* InitStreaming provoke need for TTrueParticle TClass; start consuming the TTrueParticle TProtoClass; needs the TTrueVertex TClass; provokes update of a StreamerInfo with a TBaseObject; *spurrious* InitStreaming provoke need for TBaseObject TClass; needs the TTrueParticle TClass; Consumes the TTrueParticle TProtoClass; return fine with a good TTrueVertex TClass; continue using the already “cleared” TTrueParticle TProtoClass; ```. Solution: significant update of TStreamerElement::Update and TStreamerB",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4389
https://github.com/root-project/root/pull/4389:2316,Usability,clear,cleared,2316,":InitStreaming() and BuildOld for BeamFlux; in BuildOld look at base User::TrackerVtxBase (and record pointer value in baseclass); calls Init on the TStreamerElement base; this triggers the creation of the TClass for User::TrackerVtxBase; but BuildOld kept a stale pointer to the old TClass (was baseclass variable).; ```. Solution: replace raw pointer by a TClassRef. TCompInfo::Update did a TClass::GetClass for all type that were not classes :(; Usually it is just a waste of time.; In this case, one such type is User::TContext::Time (an enum) use as part; of User::TContext .. Consequently, before the dictionary TClass for User::TContext was constructed,; another class requested the update of the emulated StreamerInfo for the (still); emulated User::TContext, this in turn provoked the (unnecessary) call to; TClass::GetClass on ‘User::TContext::Time’ which provoked the creation of; the TClass for User::TContext … one of the steps is to absorb the existing; StreamerInfo (including the one being updated) and clear them (i.e. delete; the TCompInfo array) … upon return the result of the TClass::GetClass (a nullptr); is stored in deleted memory. Solution: Don’t call TClass::GetClass on non-type. ```; User::TDatum is loaded; provokes update of a StreamerInfo with a TTrueParticle; *spurrious* InitStreaming provoke need for TTrueParticle TClass; start consuming the TTrueParticle TProtoClass; needs the TTrueVertex TClass; provokes update of a StreamerInfo with a TBaseObject; *spurrious* InitStreaming provoke need for TBaseObject TClass; needs the TTrueParticle TClass; Consumes the TTrueParticle TProtoClass; return fine with a good TTrueVertex TClass; continue using the already “cleared” TTrueParticle TProtoClass; ```. Solution: significant update of TStreamerElement::Update and TStreamerBase::Update; to call TStreamerBase::InitStreamer if and only if there was a change in the base; class pointer, and to call TClass::GetClass only if there is a chance of finding; a new TClass ….",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4389
https://github.com/root-project/root/pull/4390:1001,Deployability,Update,Update,1001," ROOT-10216. In brief, the changes are to replace lookup by simpler search to avoid nested; initialization of TClasses (leading to the outer nested initialization; to end using deleted memory). Some explanation of the reasons for and details of the actual changes. With. ```; namespace User {; class TrackerVtxBase; class BeamFlux : public User::TrackerVtxBase; class NTrackerVtx : public User::BeamFlux; }; ```. We had a crash during BuildOld for User::BeamFlux. ```; User::TBaseObject triggers replacement routines.; reaches NTrackerVtx; calls (unnecessary) TStreamerBase::InitStreaming() and BuildOld for BeamFlux; in BuildOld look at base User::TrackerVtxBase (and record pointer value in baseclass); calls Init on the TStreamerElement base; this triggers the creation of the TClass for User::TrackerVtxBase; but BuildOld kept a stale pointer to the old TClass (was baseclass variable).; ```. Solution: replace raw pointer by a TClassRef. TCompInfo::Update did a TClass::GetClass for all type that were not classes :(; Usually it is just a waste of time.; In this case, one such type is User::TContext::Time (an enum) use as part; of User::TContext .. Consequently, before the dictionary TClass for User::TContext was constructed,; another class requested the update of the emulated StreamerInfo for the (still); emulated User::TContext, this in turn provoked the (unnecessary) call to; TClass::GetClass on ‘User::TContext::Time’ which provoked the creation of; the TClass for User::TContext … one of the steps is to absorb the existing; StreamerInfo (including the one being updated) and clear them (i.e. delete; the TCompInfo array) … upon return the result of the TClass::GetClass (a nullptr); is stored in deleted memory. Solution: Don’t call TClass::GetClass on non-type. ```; User::TDatum is loaded; provokes update of a StreamerInfo with a TTrueParticle; *spurrious* InitStreaming provoke need for TTrueParticle TClass; start consuming the TTrueParticle TProtoClass; needs the TTrueVertex ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4390
https://github.com/root-project/root/pull/4390:1311,Deployability,update,update,1311," public User::BeamFlux; }; ```. We had a crash during BuildOld for User::BeamFlux. ```; User::TBaseObject triggers replacement routines.; reaches NTrackerVtx; calls (unnecessary) TStreamerBase::InitStreaming() and BuildOld for BeamFlux; in BuildOld look at base User::TrackerVtxBase (and record pointer value in baseclass); calls Init on the TStreamerElement base; this triggers the creation of the TClass for User::TrackerVtxBase; but BuildOld kept a stale pointer to the old TClass (was baseclass variable).; ```. Solution: replace raw pointer by a TClassRef. TCompInfo::Update did a TClass::GetClass for all type that were not classes :(; Usually it is just a waste of time.; In this case, one such type is User::TContext::Time (an enum) use as part; of User::TContext .. Consequently, before the dictionary TClass for User::TContext was constructed,; another class requested the update of the emulated StreamerInfo for the (still); emulated User::TContext, this in turn provoked the (unnecessary) call to; TClass::GetClass on ‘User::TContext::Time’ which provoked the creation of; the TClass for User::TContext … one of the steps is to absorb the existing; StreamerInfo (including the one being updated) and clear them (i.e. delete; the TCompInfo array) … upon return the result of the TClass::GetClass (a nullptr); is stored in deleted memory. Solution: Don’t call TClass::GetClass on non-type. ```; User::TDatum is loaded; provokes update of a StreamerInfo with a TTrueParticle; *spurrious* InitStreaming provoke need for TTrueParticle TClass; start consuming the TTrueParticle TProtoClass; needs the TTrueVertex TClass; provokes update of a StreamerInfo with a TBaseObject; *spurrious* InitStreaming provoke need for TBaseObject TClass; needs the TTrueParticle TClass; Consumes the TTrueParticle TProtoClass; return fine with a good TTrueVertex TClass; continue using the already “cleared” TTrueParticle TProtoClass; ```. Solution: significant update of TStreamerElement::Update and TStreamerB",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4390
https://github.com/root-project/root/pull/4390:1627,Deployability,update,updated,1627," public User::BeamFlux; }; ```. We had a crash during BuildOld for User::BeamFlux. ```; User::TBaseObject triggers replacement routines.; reaches NTrackerVtx; calls (unnecessary) TStreamerBase::InitStreaming() and BuildOld for BeamFlux; in BuildOld look at base User::TrackerVtxBase (and record pointer value in baseclass); calls Init on the TStreamerElement base; this triggers the creation of the TClass for User::TrackerVtxBase; but BuildOld kept a stale pointer to the old TClass (was baseclass variable).; ```. Solution: replace raw pointer by a TClassRef. TCompInfo::Update did a TClass::GetClass for all type that were not classes :(; Usually it is just a waste of time.; In this case, one such type is User::TContext::Time (an enum) use as part; of User::TContext .. Consequently, before the dictionary TClass for User::TContext was constructed,; another class requested the update of the emulated StreamerInfo for the (still); emulated User::TContext, this in turn provoked the (unnecessary) call to; TClass::GetClass on ‘User::TContext::Time’ which provoked the creation of; the TClass for User::TContext … one of the steps is to absorb the existing; StreamerInfo (including the one being updated) and clear them (i.e. delete; the TCompInfo array) … upon return the result of the TClass::GetClass (a nullptr); is stored in deleted memory. Solution: Don’t call TClass::GetClass on non-type. ```; User::TDatum is loaded; provokes update of a StreamerInfo with a TTrueParticle; *spurrious* InitStreaming provoke need for TTrueParticle TClass; start consuming the TTrueParticle TProtoClass; needs the TTrueVertex TClass; provokes update of a StreamerInfo with a TBaseObject; *spurrious* InitStreaming provoke need for TBaseObject TClass; needs the TTrueParticle TClass; Consumes the TTrueParticle TProtoClass; return fine with a good TTrueVertex TClass; continue using the already “cleared” TTrueParticle TProtoClass; ```. Solution: significant update of TStreamerElement::Update and TStreamerB",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4390
https://github.com/root-project/root/pull/4390:1866,Deployability,update,update,1866,":InitStreaming() and BuildOld for BeamFlux; in BuildOld look at base User::TrackerVtxBase (and record pointer value in baseclass); calls Init on the TStreamerElement base; this triggers the creation of the TClass for User::TrackerVtxBase; but BuildOld kept a stale pointer to the old TClass (was baseclass variable).; ```. Solution: replace raw pointer by a TClassRef. TCompInfo::Update did a TClass::GetClass for all type that were not classes :(; Usually it is just a waste of time.; In this case, one such type is User::TContext::Time (an enum) use as part; of User::TContext .. Consequently, before the dictionary TClass for User::TContext was constructed,; another class requested the update of the emulated StreamerInfo for the (still); emulated User::TContext, this in turn provoked the (unnecessary) call to; TClass::GetClass on ‘User::TContext::Time’ which provoked the creation of; the TClass for User::TContext … one of the steps is to absorb the existing; StreamerInfo (including the one being updated) and clear them (i.e. delete; the TCompInfo array) … upon return the result of the TClass::GetClass (a nullptr); is stored in deleted memory. Solution: Don’t call TClass::GetClass on non-type. ```; User::TDatum is loaded; provokes update of a StreamerInfo with a TTrueParticle; *spurrious* InitStreaming provoke need for TTrueParticle TClass; start consuming the TTrueParticle TProtoClass; needs the TTrueVertex TClass; provokes update of a StreamerInfo with a TBaseObject; *spurrious* InitStreaming provoke need for TBaseObject TClass; needs the TTrueParticle TClass; Consumes the TTrueParticle TProtoClass; return fine with a good TTrueVertex TClass; continue using the already “cleared” TTrueParticle TProtoClass; ```. Solution: significant update of TStreamerElement::Update and TStreamerBase::Update; to call TStreamerBase::InitStreamer if and only if there was a change in the base; class pointer, and to call TClass::GetClass only if there is a chance of finding; a new TClass ….",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4390
https://github.com/root-project/root/pull/4390:2064,Deployability,update,update,2064,":InitStreaming() and BuildOld for BeamFlux; in BuildOld look at base User::TrackerVtxBase (and record pointer value in baseclass); calls Init on the TStreamerElement base; this triggers the creation of the TClass for User::TrackerVtxBase; but BuildOld kept a stale pointer to the old TClass (was baseclass variable).; ```. Solution: replace raw pointer by a TClassRef. TCompInfo::Update did a TClass::GetClass for all type that were not classes :(; Usually it is just a waste of time.; In this case, one such type is User::TContext::Time (an enum) use as part; of User::TContext .. Consequently, before the dictionary TClass for User::TContext was constructed,; another class requested the update of the emulated StreamerInfo for the (still); emulated User::TContext, this in turn provoked the (unnecessary) call to; TClass::GetClass on ‘User::TContext::Time’ which provoked the creation of; the TClass for User::TContext … one of the steps is to absorb the existing; StreamerInfo (including the one being updated) and clear them (i.e. delete; the TCompInfo array) … upon return the result of the TClass::GetClass (a nullptr); is stored in deleted memory. Solution: Don’t call TClass::GetClass on non-type. ```; User::TDatum is loaded; provokes update of a StreamerInfo with a TTrueParticle; *spurrious* InitStreaming provoke need for TTrueParticle TClass; start consuming the TTrueParticle TProtoClass; needs the TTrueVertex TClass; provokes update of a StreamerInfo with a TBaseObject; *spurrious* InitStreaming provoke need for TBaseObject TClass; needs the TTrueParticle TClass; Consumes the TTrueParticle TProtoClass; return fine with a good TTrueVertex TClass; continue using the already “cleared” TTrueParticle TProtoClass; ```. Solution: significant update of TStreamerElement::Update and TStreamerBase::Update; to call TStreamerBase::InitStreamer if and only if there was a change in the base; class pointer, and to call TClass::GetClass only if there is a chance of finding; a new TClass ….",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4390
https://github.com/root-project/root/pull/4390:2379,Deployability,update,update,2379,":InitStreaming() and BuildOld for BeamFlux; in BuildOld look at base User::TrackerVtxBase (and record pointer value in baseclass); calls Init on the TStreamerElement base; this triggers the creation of the TClass for User::TrackerVtxBase; but BuildOld kept a stale pointer to the old TClass (was baseclass variable).; ```. Solution: replace raw pointer by a TClassRef. TCompInfo::Update did a TClass::GetClass for all type that were not classes :(; Usually it is just a waste of time.; In this case, one such type is User::TContext::Time (an enum) use as part; of User::TContext .. Consequently, before the dictionary TClass for User::TContext was constructed,; another class requested the update of the emulated StreamerInfo for the (still); emulated User::TContext, this in turn provoked the (unnecessary) call to; TClass::GetClass on ‘User::TContext::Time’ which provoked the creation of; the TClass for User::TContext … one of the steps is to absorb the existing; StreamerInfo (including the one being updated) and clear them (i.e. delete; the TCompInfo array) … upon return the result of the TClass::GetClass (a nullptr); is stored in deleted memory. Solution: Don’t call TClass::GetClass on non-type. ```; User::TDatum is loaded; provokes update of a StreamerInfo with a TTrueParticle; *spurrious* InitStreaming provoke need for TTrueParticle TClass; start consuming the TTrueParticle TProtoClass; needs the TTrueVertex TClass; provokes update of a StreamerInfo with a TBaseObject; *spurrious* InitStreaming provoke need for TBaseObject TClass; needs the TTrueParticle TClass; Consumes the TTrueParticle TProtoClass; return fine with a good TTrueVertex TClass; continue using the already “cleared” TTrueParticle TProtoClass; ```. Solution: significant update of TStreamerElement::Update and TStreamerBase::Update; to call TStreamerBase::InitStreamer if and only if there was a change in the base; class pointer, and to call TClass::GetClass only if there is a chance of finding; a new TClass ….",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4390
https://github.com/root-project/root/pull/4390:2407,Deployability,Update,Update,2407,":InitStreaming() and BuildOld for BeamFlux; in BuildOld look at base User::TrackerVtxBase (and record pointer value in baseclass); calls Init on the TStreamerElement base; this triggers the creation of the TClass for User::TrackerVtxBase; but BuildOld kept a stale pointer to the old TClass (was baseclass variable).; ```. Solution: replace raw pointer by a TClassRef. TCompInfo::Update did a TClass::GetClass for all type that were not classes :(; Usually it is just a waste of time.; In this case, one such type is User::TContext::Time (an enum) use as part; of User::TContext .. Consequently, before the dictionary TClass for User::TContext was constructed,; another class requested the update of the emulated StreamerInfo for the (still); emulated User::TContext, this in turn provoked the (unnecessary) call to; TClass::GetClass on ‘User::TContext::Time’ which provoked the creation of; the TClass for User::TContext … one of the steps is to absorb the existing; StreamerInfo (including the one being updated) and clear them (i.e. delete; the TCompInfo array) … upon return the result of the TClass::GetClass (a nullptr); is stored in deleted memory. Solution: Don’t call TClass::GetClass on non-type. ```; User::TDatum is loaded; provokes update of a StreamerInfo with a TTrueParticle; *spurrious* InitStreaming provoke need for TTrueParticle TClass; start consuming the TTrueParticle TProtoClass; needs the TTrueVertex TClass; provokes update of a StreamerInfo with a TBaseObject; *spurrious* InitStreaming provoke need for TBaseObject TClass; needs the TTrueParticle TClass; Consumes the TTrueParticle TProtoClass; return fine with a good TTrueVertex TClass; continue using the already “cleared” TTrueParticle TProtoClass; ```. Solution: significant update of TStreamerElement::Update and TStreamerBase::Update; to call TStreamerBase::InitStreamer if and only if there was a change in the base; class pointer, and to call TClass::GetClass only if there is a chance of finding; a new TClass ….",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4390
https://github.com/root-project/root/pull/4390:2433,Deployability,Update,Update,2433,":InitStreaming() and BuildOld for BeamFlux; in BuildOld look at base User::TrackerVtxBase (and record pointer value in baseclass); calls Init on the TStreamerElement base; this triggers the creation of the TClass for User::TrackerVtxBase; but BuildOld kept a stale pointer to the old TClass (was baseclass variable).; ```. Solution: replace raw pointer by a TClassRef. TCompInfo::Update did a TClass::GetClass for all type that were not classes :(; Usually it is just a waste of time.; In this case, one such type is User::TContext::Time (an enum) use as part; of User::TContext .. Consequently, before the dictionary TClass for User::TContext was constructed,; another class requested the update of the emulated StreamerInfo for the (still); emulated User::TContext, this in turn provoked the (unnecessary) call to; TClass::GetClass on ‘User::TContext::Time’ which provoked the creation of; the TClass for User::TContext … one of the steps is to absorb the existing; StreamerInfo (including the one being updated) and clear them (i.e. delete; the TCompInfo array) … upon return the result of the TClass::GetClass (a nullptr); is stored in deleted memory. Solution: Don’t call TClass::GetClass on non-type. ```; User::TDatum is loaded; provokes update of a StreamerInfo with a TTrueParticle; *spurrious* InitStreaming provoke need for TTrueParticle TClass; start consuming the TTrueParticle TProtoClass; needs the TTrueVertex TClass; provokes update of a StreamerInfo with a TBaseObject; *spurrious* InitStreaming provoke need for TBaseObject TClass; needs the TTrueParticle TClass; Consumes the TTrueParticle TProtoClass; return fine with a good TTrueVertex TClass; continue using the already “cleared” TTrueParticle TProtoClass; ```. Solution: significant update of TStreamerElement::Update and TStreamerBase::Update; to call TStreamerBase::InitStreamer if and only if there was a change in the base; class pointer, and to call TClass::GetClass only if there is a chance of finding; a new TClass ….",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4390
https://github.com/root-project/root/pull/4390:555,Integrability,rout,routines,555,"This should be the last crop of fixes needed by ROOT-10216. In brief, the changes are to replace lookup by simpler search to avoid nested; initialization of TClasses (leading to the outer nested initialization; to end using deleted memory). Some explanation of the reasons for and details of the actual changes. With. ```; namespace User {; class TrackerVtxBase; class BeamFlux : public User::TrackerVtxBase; class NTrackerVtx : public User::BeamFlux; }; ```. We had a crash during BuildOld for User::BeamFlux. ```; User::TBaseObject triggers replacement routines.; reaches NTrackerVtx; calls (unnecessary) TStreamerBase::InitStreaming() and BuildOld for BeamFlux; in BuildOld look at base User::TrackerVtxBase (and record pointer value in baseclass); calls Init on the TStreamerElement base; this triggers the creation of the TClass for User::TrackerVtxBase; but BuildOld kept a stale pointer to the old TClass (was baseclass variable).; ```. Solution: replace raw pointer by a TClassRef. TCompInfo::Update did a TClass::GetClass for all type that were not classes :(; Usually it is just a waste of time.; In this case, one such type is User::TContext::Time (an enum) use as part; of User::TContext .. Consequently, before the dictionary TClass for User::TContext was constructed,; another class requested the update of the emulated StreamerInfo for the (still); emulated User::TContext, this in turn provoked the (unnecessary) call to; TClass::GetClass on ‘User::TContext::Time’ which provoked the creation of; the TClass for User::TContext … one of the steps is to absorb the existing; StreamerInfo (including the one being updated) and clear them (i.e. delete; the TCompInfo array) … upon return the result of the TClass::GetClass (a nullptr); is stored in deleted memory. Solution: Don’t call TClass::GetClass on non-type. ```; User::TDatum is loaded; provokes update of a StreamerInfo with a TTrueParticle; *spurrious* InitStreaming provoke need for TTrueParticle TClass; start consuming the TTr",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4390
https://github.com/root-project/root/pull/4390:927,Modifiability,variab,variable,927,"This should be the last crop of fixes needed by ROOT-10216. In brief, the changes are to replace lookup by simpler search to avoid nested; initialization of TClasses (leading to the outer nested initialization; to end using deleted memory). Some explanation of the reasons for and details of the actual changes. With. ```; namespace User {; class TrackerVtxBase; class BeamFlux : public User::TrackerVtxBase; class NTrackerVtx : public User::BeamFlux; }; ```. We had a crash during BuildOld for User::BeamFlux. ```; User::TBaseObject triggers replacement routines.; reaches NTrackerVtx; calls (unnecessary) TStreamerBase::InitStreaming() and BuildOld for BeamFlux; in BuildOld look at base User::TrackerVtxBase (and record pointer value in baseclass); calls Init on the TStreamerElement base; this triggers the creation of the TClass for User::TrackerVtxBase; but BuildOld kept a stale pointer to the old TClass (was baseclass variable).; ```. Solution: replace raw pointer by a TClassRef. TCompInfo::Update did a TClass::GetClass for all type that were not classes :(; Usually it is just a waste of time.; In this case, one such type is User::TContext::Time (an enum) use as part; of User::TContext .. Consequently, before the dictionary TClass for User::TContext was constructed,; another class requested the update of the emulated StreamerInfo for the (still); emulated User::TContext, this in turn provoked the (unnecessary) call to; TClass::GetClass on ‘User::TContext::Time’ which provoked the creation of; the TClass for User::TContext … one of the steps is to absorb the existing; StreamerInfo (including the one being updated) and clear them (i.e. delete; the TCompInfo array) … upon return the result of the TClass::GetClass (a nullptr); is stored in deleted memory. Solution: Don’t call TClass::GetClass on non-type. ```; User::TDatum is loaded; provokes update of a StreamerInfo with a TTrueParticle; *spurrious* InitStreaming provoke need for TTrueParticle TClass; start consuming the TTr",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4390
https://github.com/root-project/root/pull/4390:1849,Performance,load,loaded,1849,":InitStreaming() and BuildOld for BeamFlux; in BuildOld look at base User::TrackerVtxBase (and record pointer value in baseclass); calls Init on the TStreamerElement base; this triggers the creation of the TClass for User::TrackerVtxBase; but BuildOld kept a stale pointer to the old TClass (was baseclass variable).; ```. Solution: replace raw pointer by a TClassRef. TCompInfo::Update did a TClass::GetClass for all type that were not classes :(; Usually it is just a waste of time.; In this case, one such type is User::TContext::Time (an enum) use as part; of User::TContext .. Consequently, before the dictionary TClass for User::TContext was constructed,; another class requested the update of the emulated StreamerInfo for the (still); emulated User::TContext, this in turn provoked the (unnecessary) call to; TClass::GetClass on ‘User::TContext::Time’ which provoked the creation of; the TClass for User::TContext … one of the steps is to absorb the existing; StreamerInfo (including the one being updated) and clear them (i.e. delete; the TCompInfo array) … upon return the result of the TClass::GetClass (a nullptr); is stored in deleted memory. Solution: Don’t call TClass::GetClass on non-type. ```; User::TDatum is loaded; provokes update of a StreamerInfo with a TTrueParticle; *spurrious* InitStreaming provoke need for TTrueParticle TClass; start consuming the TTrueParticle TProtoClass; needs the TTrueVertex TClass; provokes update of a StreamerInfo with a TBaseObject; *spurrious* InitStreaming provoke need for TBaseObject TClass; needs the TTrueParticle TClass; Consumes the TTrueParticle TProtoClass; return fine with a good TTrueVertex TClass; continue using the already “cleared” TTrueParticle TProtoClass; ```. Solution: significant update of TStreamerElement::Update and TStreamerBase::Update; to call TStreamerBase::InitStreamer if and only if there was a change in the base; class pointer, and to call TClass::GetClass only if there is a chance of finding; a new TClass ….",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4390
https://github.com/root-project/root/pull/4390:125,Safety,avoid,avoid,125,"This should be the last crop of fixes needed by ROOT-10216. In brief, the changes are to replace lookup by simpler search to avoid nested; initialization of TClasses (leading to the outer nested initialization; to end using deleted memory). Some explanation of the reasons for and details of the actual changes. With. ```; namespace User {; class TrackerVtxBase; class BeamFlux : public User::TrackerVtxBase; class NTrackerVtx : public User::BeamFlux; }; ```. We had a crash during BuildOld for User::BeamFlux. ```; User::TBaseObject triggers replacement routines.; reaches NTrackerVtx; calls (unnecessary) TStreamerBase::InitStreaming() and BuildOld for BeamFlux; in BuildOld look at base User::TrackerVtxBase (and record pointer value in baseclass); calls Init on the TStreamerElement base; this triggers the creation of the TClass for User::TrackerVtxBase; but BuildOld kept a stale pointer to the old TClass (was baseclass variable).; ```. Solution: replace raw pointer by a TClassRef. TCompInfo::Update did a TClass::GetClass for all type that were not classes :(; Usually it is just a waste of time.; In this case, one such type is User::TContext::Time (an enum) use as part; of User::TContext .. Consequently, before the dictionary TClass for User::TContext was constructed,; another class requested the update of the emulated StreamerInfo for the (still); emulated User::TContext, this in turn provoked the (unnecessary) call to; TClass::GetClass on ‘User::TContext::Time’ which provoked the creation of; the TClass for User::TContext … one of the steps is to absorb the existing; StreamerInfo (including the one being updated) and clear them (i.e. delete; the TCompInfo array) … upon return the result of the TClass::GetClass (a nullptr); is stored in deleted memory. Solution: Don’t call TClass::GetClass on non-type. ```; User::TDatum is loaded; provokes update of a StreamerInfo with a TTrueParticle; *spurrious* InitStreaming provoke need for TTrueParticle TClass; start consuming the TTr",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4390
https://github.com/root-project/root/pull/4390:107,Usability,simpl,simpler,107,"This should be the last crop of fixes needed by ROOT-10216. In brief, the changes are to replace lookup by simpler search to avoid nested; initialization of TClasses (leading to the outer nested initialization; to end using deleted memory). Some explanation of the reasons for and details of the actual changes. With. ```; namespace User {; class TrackerVtxBase; class BeamFlux : public User::TrackerVtxBase; class NTrackerVtx : public User::BeamFlux; }; ```. We had a crash during BuildOld for User::BeamFlux. ```; User::TBaseObject triggers replacement routines.; reaches NTrackerVtx; calls (unnecessary) TStreamerBase::InitStreaming() and BuildOld for BeamFlux; in BuildOld look at base User::TrackerVtxBase (and record pointer value in baseclass); calls Init on the TStreamerElement base; this triggers the creation of the TClass for User::TrackerVtxBase; but BuildOld kept a stale pointer to the old TClass (was baseclass variable).; ```. Solution: replace raw pointer by a TClassRef. TCompInfo::Update did a TClass::GetClass for all type that were not classes :(; Usually it is just a waste of time.; In this case, one such type is User::TContext::Time (an enum) use as part; of User::TContext .. Consequently, before the dictionary TClass for User::TContext was constructed,; another class requested the update of the emulated StreamerInfo for the (still); emulated User::TContext, this in turn provoked the (unnecessary) call to; TClass::GetClass on ‘User::TContext::Time’ which provoked the creation of; the TClass for User::TContext … one of the steps is to absorb the existing; StreamerInfo (including the one being updated) and clear them (i.e. delete; the TCompInfo array) … upon return the result of the TClass::GetClass (a nullptr); is stored in deleted memory. Solution: Don’t call TClass::GetClass on non-type. ```; User::TDatum is loaded; provokes update of a StreamerInfo with a TTrueParticle; *spurrious* InitStreaming provoke need for TTrueParticle TClass; start consuming the TTr",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4390
https://github.com/root-project/root/pull/4390:1640,Usability,clear,clear,1640," public User::BeamFlux; }; ```. We had a crash during BuildOld for User::BeamFlux. ```; User::TBaseObject triggers replacement routines.; reaches NTrackerVtx; calls (unnecessary) TStreamerBase::InitStreaming() and BuildOld for BeamFlux; in BuildOld look at base User::TrackerVtxBase (and record pointer value in baseclass); calls Init on the TStreamerElement base; this triggers the creation of the TClass for User::TrackerVtxBase; but BuildOld kept a stale pointer to the old TClass (was baseclass variable).; ```. Solution: replace raw pointer by a TClassRef. TCompInfo::Update did a TClass::GetClass for all type that were not classes :(; Usually it is just a waste of time.; In this case, one such type is User::TContext::Time (an enum) use as part; of User::TContext .. Consequently, before the dictionary TClass for User::TContext was constructed,; another class requested the update of the emulated StreamerInfo for the (still); emulated User::TContext, this in turn provoked the (unnecessary) call to; TClass::GetClass on ‘User::TContext::Time’ which provoked the creation of; the TClass for User::TContext … one of the steps is to absorb the existing; StreamerInfo (including the one being updated) and clear them (i.e. delete; the TCompInfo array) … upon return the result of the TClass::GetClass (a nullptr); is stored in deleted memory. Solution: Don’t call TClass::GetClass on non-type. ```; User::TDatum is loaded; provokes update of a StreamerInfo with a TTrueParticle; *spurrious* InitStreaming provoke need for TTrueParticle TClass; start consuming the TTrueParticle TProtoClass; needs the TTrueVertex TClass; provokes update of a StreamerInfo with a TBaseObject; *spurrious* InitStreaming provoke need for TBaseObject TClass; needs the TTrueParticle TClass; Consumes the TTrueParticle TProtoClass; return fine with a good TTrueVertex TClass; continue using the already “cleared” TTrueParticle TProtoClass; ```. Solution: significant update of TStreamerElement::Update and TStreamerB",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4390
https://github.com/root-project/root/pull/4390:2316,Usability,clear,cleared,2316,":InitStreaming() and BuildOld for BeamFlux; in BuildOld look at base User::TrackerVtxBase (and record pointer value in baseclass); calls Init on the TStreamerElement base; this triggers the creation of the TClass for User::TrackerVtxBase; but BuildOld kept a stale pointer to the old TClass (was baseclass variable).; ```. Solution: replace raw pointer by a TClassRef. TCompInfo::Update did a TClass::GetClass for all type that were not classes :(; Usually it is just a waste of time.; In this case, one such type is User::TContext::Time (an enum) use as part; of User::TContext .. Consequently, before the dictionary TClass for User::TContext was constructed,; another class requested the update of the emulated StreamerInfo for the (still); emulated User::TContext, this in turn provoked the (unnecessary) call to; TClass::GetClass on ‘User::TContext::Time’ which provoked the creation of; the TClass for User::TContext … one of the steps is to absorb the existing; StreamerInfo (including the one being updated) and clear them (i.e. delete; the TCompInfo array) … upon return the result of the TClass::GetClass (a nullptr); is stored in deleted memory. Solution: Don’t call TClass::GetClass on non-type. ```; User::TDatum is loaded; provokes update of a StreamerInfo with a TTrueParticle; *spurrious* InitStreaming provoke need for TTrueParticle TClass; start consuming the TTrueParticle TProtoClass; needs the TTrueVertex TClass; provokes update of a StreamerInfo with a TBaseObject; *spurrious* InitStreaming provoke need for TBaseObject TClass; needs the TTrueParticle TClass; Consumes the TTrueParticle TProtoClass; return fine with a good TTrueVertex TClass; continue using the already “cleared” TTrueParticle TProtoClass; ```. Solution: significant update of TStreamerElement::Update and TStreamerBase::Update; to call TStreamerBase::InitStreamer if and only if there was a change in the base; class pointer, and to call TClass::GetClass only if there is a chance of finding; a new TClass ….",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4390
https://github.com/root-project/root/pull/4394:144,Deployability,patch,patch,144,This allows us to use a single modulemap file across multiple libstdc++ versions and gives us a way forward to deal with deprecated files. This patch will be submitted for a review upstream. It fixes our gcc 4.8 builds where codecvt and cuchar header files do not exist.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4394
https://github.com/root-project/root/pull/4395:234,Availability,redundant,redundant,234,"ROOT has several features which interact with libraries and require implicit header inclusion. This can be triggered by reading or writing data on disk, or user actions at the prompt. Often, the headers are immutable and reparsing is redundant. C++ Modules are designed to minimize the reparsing of the same header content by providing an efficient on-disk representation of C++ Code. More information about the C++ modules technology can be found at README/README.CXXMODULES.md. This undertaking was successful due to the efforts of many people. Especially, Raphael Isemann (@Teemperor), Oksana Shadura(@oshadura) and Yuka Takahashi (@yamaguchi1024). We are grateful to Liz Sexton-Kennedy, Peter Elmer (@pelmer), Brian Bockelman(@bbockelm) and Ken Bloom for putting (wo)manpower into the project and supporting it. This work has been supported by an Intel Parallel Computing Center grant, by U.S.National Science Foundation grants PHY-1450377, ACI-1450323 and PHY-1624356, and by the U.S. Department of Energy, Office of Science. Special thanks to Axel Naumann (@Axel-Naumann) and Philippe Canal (@pcanal) for helping and supporting the technical efforts over the years. We are thankful to Shahzad Malik Muzaffar (@smuzaffar), David Lange (@davidlange6) and Mircho Rodozov (@mrodozov) from the CMSSW development team, CERN/EP-SFT and the ROOT team.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4395
https://github.com/root-project/root/pull/4395:339,Energy Efficiency,efficient,efficient,339,"ROOT has several features which interact with libraries and require implicit header inclusion. This can be triggered by reading or writing data on disk, or user actions at the prompt. Often, the headers are immutable and reparsing is redundant. C++ Modules are designed to minimize the reparsing of the same header content by providing an efficient on-disk representation of C++ Code. More information about the C++ modules technology can be found at README/README.CXXMODULES.md. This undertaking was successful due to the efforts of many people. Especially, Raphael Isemann (@Teemperor), Oksana Shadura(@oshadura) and Yuka Takahashi (@yamaguchi1024). We are grateful to Liz Sexton-Kennedy, Peter Elmer (@pelmer), Brian Bockelman(@bbockelm) and Ken Bloom for putting (wo)manpower into the project and supporting it. This work has been supported by an Intel Parallel Computing Center grant, by U.S.National Science Foundation grants PHY-1450377, ACI-1450323 and PHY-1624356, and by the U.S. Department of Energy, Office of Science. Special thanks to Axel Naumann (@Axel-Naumann) and Philippe Canal (@pcanal) for helping and supporting the technical efforts over the years. We are thankful to Shahzad Malik Muzaffar (@smuzaffar), David Lange (@davidlange6) and Mircho Rodozov (@mrodozov) from the CMSSW development team, CERN/EP-SFT and the ROOT team.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4395
https://github.com/root-project/root/pull/4395:1004,Energy Efficiency,Energy,Energy,1004,"ROOT has several features which interact with libraries and require implicit header inclusion. This can be triggered by reading or writing data on disk, or user actions at the prompt. Often, the headers are immutable and reparsing is redundant. C++ Modules are designed to minimize the reparsing of the same header content by providing an efficient on-disk representation of C++ Code. More information about the C++ modules technology can be found at README/README.CXXMODULES.md. This undertaking was successful due to the efforts of many people. Especially, Raphael Isemann (@Teemperor), Oksana Shadura(@oshadura) and Yuka Takahashi (@yamaguchi1024). We are grateful to Liz Sexton-Kennedy, Peter Elmer (@pelmer), Brian Bockelman(@bbockelm) and Ken Bloom for putting (wo)manpower into the project and supporting it. This work has been supported by an Intel Parallel Computing Center grant, by U.S.National Science Foundation grants PHY-1450377, ACI-1450323 and PHY-1624356, and by the U.S. Department of Energy, Office of Science. Special thanks to Axel Naumann (@Axel-Naumann) and Philippe Canal (@pcanal) for helping and supporting the technical efforts over the years. We are thankful to Shahzad Malik Muzaffar (@smuzaffar), David Lange (@davidlange6) and Mircho Rodozov (@mrodozov) from the CMSSW development team, CERN/EP-SFT and the ROOT team.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4395
https://github.com/root-project/root/pull/4395:234,Safety,redund,redundant,234,"ROOT has several features which interact with libraries and require implicit header inclusion. This can be triggered by reading or writing data on disk, or user actions at the prompt. Often, the headers are immutable and reparsing is redundant. C++ Modules are designed to minimize the reparsing of the same header content by providing an efficient on-disk representation of C++ Code. More information about the C++ modules technology can be found at README/README.CXXMODULES.md. This undertaking was successful due to the efforts of many people. Especially, Raphael Isemann (@Teemperor), Oksana Shadura(@oshadura) and Yuka Takahashi (@yamaguchi1024). We are grateful to Liz Sexton-Kennedy, Peter Elmer (@pelmer), Brian Bockelman(@bbockelm) and Ken Bloom for putting (wo)manpower into the project and supporting it. This work has been supported by an Intel Parallel Computing Center grant, by U.S.National Science Foundation grants PHY-1450377, ACI-1450323 and PHY-1624356, and by the U.S. Department of Energy, Office of Science. Special thanks to Axel Naumann (@Axel-Naumann) and Philippe Canal (@pcanal) for helping and supporting the technical efforts over the years. We are thankful to Shahzad Malik Muzaffar (@smuzaffar), David Lange (@davidlange6) and Mircho Rodozov (@mrodozov) from the CMSSW development team, CERN/EP-SFT and the ROOT team.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4395
https://github.com/root-project/root/pull/4401:5,Modifiability,refactor,refactored,5,"Adds refactored BDT inference engine (WIP PR #4351) and frontend classes. The current workflow looks like this:. **External training:**; ```python; x, y = ... some dataset ...; xgb = xgboost.XGBClassifier(n_estimators=100, max_depth=3); xgb.fit(x, y); # Convert to model understood by the inference engine; ROOT.TMVA.Experimental.SaveXGBoost(xgb, ""myBDT"", ""bdts.root""); ```. **Application (Python):**; ```python; bdt = ROOT.TMVA.Experimental.RBDT[](""myBDT"", ""bdts.root""); # Native numpy support; x = np.array(... some data ...); y = bdt.Compute(x); ```. **Application (C++):**; ```cpp; TMVA::Experimental::RBDT bdt(""myBDT"", ""bdts.root"");; // Single event inference; auto y = bdt.Compute({... some intializer list resolving to a std::vector ... });; // Batch inference; RTensor<float> x({ ... shape ...});; auto y2 = bdt.Compute(x);; ```. **Application (RDataFrame):**; ```cpp; TMVA::Experimental::RBDT bdt(""myBDT"", ""bdts.root"");; ROOT::RDataFrame df(...);; auto df2 = df.Define(""y"", TMVA::Experimental::Compute<N, float>(bdt), { ... N inputs ...});; ```. Comparing against XGBoost in the Python application, we outperform them currently by a factor of 4 (without jitted backend). To be improved!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4401
https://github.com/root-project/root/pull/4402:96,Availability,error,errors,96,"On i686, floating-point math is less accurate than on other systems. By enabling SSE2, rounding errors should accumulate to a lower extent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4402
https://github.com/root-project/root/pull/4406:434,Deployability,patch,patched,434,"Wim says: adding 'shell=True' makes the command run on; /bin/sh and allows you to use shell features (such as expansion and; replacement of variables). But nothing in the command seems to need that; feature, and anyway it's a risky thing to rely on, or what am I missing?. Spawning an intermediate shell makes a mess of the environment when running; under conda on Mac in the non-build environment. Running the normal way as; per the patched line above, and all seems good.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4406
https://github.com/root-project/root/pull/4406:140,Modifiability,variab,variables,140,"Wim says: adding 'shell=True' makes the command run on; /bin/sh and allows you to use shell features (such as expansion and; replacement of variables). But nothing in the command seems to need that; feature, and anyway it's a risky thing to rely on, or what am I missing?. Spawning an intermediate shell makes a mess of the environment when running; under conda on Mac in the non-build environment. Running the normal way as; per the patched line above, and all seems good.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4406
https://github.com/root-project/root/pull/4406:226,Safety,risk,risky,226,"Wim says: adding 'shell=True' makes the command run on; /bin/sh and allows you to use shell features (such as expansion and; replacement of variables). But nothing in the command seems to need that; feature, and anyway it's a risky thing to rely on, or what am I missing?. Spawning an intermediate shell makes a mess of the environment when running; under conda on Mac in the non-build environment. Running the normal way as; per the patched line above, and all seems good.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4406
https://github.com/root-project/root/pull/4407:157,Safety,avoid,avoid,157,"This PR provides the support to add input features as vector data (arrays). This is useful in case of image data (.e.g for Convolutional networks). ; The PR avoid then the creation of input TTreeFormula objects for each single array element which can be very time consume in case of large input data (e,g, > 1000). ; A new function DataLoader::AddVariableArrays has been added to provide the input array name that corresponds to the TTree branch name. Note that TMVA was providing and it continues to provide support for input array data but assuming that each single array element is a different TMVA event. The array is split and for each TTree entry, n (the size of the array) events are created in TMVA. In this particular case one needs to provides all inputs (input features, labels and weights) as array of the same size. This PR mantains this use case, but adds now the possibility to represent the array elements as different columns in the event vector.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4407
https://github.com/root-project/root/pull/4409:114,Availability,redundant,redundant,114,"ROOT::R::Label is a synonym of Rcpp::_. We should just bind to it, instead of; introducing a new variable causing redundant deserialization from the C++ module.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4409
https://github.com/root-project/root/pull/4409:97,Modifiability,variab,variable,97,"ROOT::R::Label is a synonym of Rcpp::_. We should just bind to it, instead of; introducing a new variable causing redundant deserialization from the C++ module.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4409
https://github.com/root-project/root/pull/4409:114,Safety,redund,redundant,114,"ROOT::R::Label is a synonym of Rcpp::_. We should just bind to it, instead of; introducing a new variable causing redundant deserialization from the C++ module.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4409
https://github.com/root-project/root/pull/4410:32,Availability,failure,failures,32,This appease the bots' sporadic failures about missing gRandom while we are investigating.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4410
https://github.com/root-project/root/pull/4416:397,Testability,test,test,397,"If a TClass is in fClassesToUpdate, we must run the dictionary; function to replace it (move it from kInterpreted/kEmulated/kForwardDeclared; to kHasTClassInit). Whether the classes on the list need to be processed is not related to whether; parsing on demand or module are turned on (even if those can affect the likely; hood that the list is populated or not). This fixes the problem see in the test 'pyunittests-pyroot-ttree_asmatrix':; ```; Fatal in <TClass::SetUnloaded>: The TClass for __gnu_cxx::__normal_iterator<double*,vector<double> > is being unloaded when in state 3; ```; seen in the builds with cxxruntime_module turned on.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4416
https://github.com/root-project/root/pull/4419:49,Testability,test,testRandom,49,Fix the GSLRngROOTWrapper class. Include also in testRandom the new engine based on MixMax (uses now Mixmax 17) and fix a compiler warning found in Ubuntu 18,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4419
https://github.com/root-project/root/pull/4422:86,Testability,test,test,86,Fix implementation for the case where a std::string goes over the page limit. A small test is also added to test it.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4422
https://github.com/root-project/root/pull/4422:108,Testability,test,test,108,Fix implementation for the case where a std::string goes over the page limit. A small test is also added to test it.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4422
https://github.com/root-project/root/pull/4423:32,Testability,test,test,32,This fixes ROOT-10324 and a new test for TEfficiency and TGraphAsymmErrors::Divide has been added.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4423
https://github.com/root-project/root/pull/4426:570,Modifiability,extend,extended,570,"This fixes ROOT-8396. The issues was the normalization of. ""std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >"". into vector<string> due to the inline namespace (__cxx11). Prior to this commit, it would work but only if the name for normalized twice. This because the order of operation was. 1. check if the name is std::basic_string or basic_string; 2. do more stuff; 3. remove std and std::[any-inlined-namespace-name]. now we extended 1 to also search for std::[any-inlined-namespace-name]::basic_string",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4426
https://github.com/root-project/root/pull/4427:152,Availability,error,error,152,"Disabled not-allowed methods in derived classes (TH2,TH3) by making them protected, this will avoid calling them at run time and now one gets a compile error instead of a run time error as before. ; Unfortunately one cannot prevent calling these methods when using a base class pointer (e.g. TH1 for a TH2). IN that case a run time error will be produced.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4427
https://github.com/root-project/root/pull/4427:180,Availability,error,error,180,"Disabled not-allowed methods in derived classes (TH2,TH3) by making them protected, this will avoid calling them at run time and now one gets a compile error instead of a run time error as before. ; Unfortunately one cannot prevent calling these methods when using a base class pointer (e.g. TH1 for a TH2). IN that case a run time error will be produced.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4427
https://github.com/root-project/root/pull/4427:332,Availability,error,error,332,"Disabled not-allowed methods in derived classes (TH2,TH3) by making them protected, this will avoid calling them at run time and now one gets a compile error instead of a run time error as before. ; Unfortunately one cannot prevent calling these methods when using a base class pointer (e.g. TH1 for a TH2). IN that case a run time error will be produced.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4427
https://github.com/root-project/root/pull/4427:94,Safety,avoid,avoid,94,"Disabled not-allowed methods in derived classes (TH2,TH3) by making them protected, this will avoid calling them at run time and now one gets a compile error instead of a run time error as before. ; Unfortunately one cannot prevent calling these methods when using a base class pointer (e.g. TH1 for a TH2). IN that case a run time error will be produced.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4427
https://github.com/root-project/root/pull/4430:907,Availability,failure,failures,907,In some cases such as ROOT::Experimental::Internal::TUniWeakPtr the information about if a data member is transient is kept in the template pattern (residing in Core.pcm). The template instantiation is elsewhere (in the particular case) the ROOTHistDraw.pcm. In this scenario the LinkDef request for the particular instantiation is done after Core.pcm is built leaving no chance for rootcling to transform the comment into an annotation attibute attached to the template pattern. This does not happen very often but it may occur regularly when we start writing more templated code. We should store the IO comments for the template patterns independently on if a particular template instantiation was required. This is a modules-specific issue because the PCH includes the bulk of header files altogether and this helps the current system to place this information at the required place. This should fix the failures in tutorial-hist-h1draw and cmssw CXXModules IB:; Fatal Root Error: @SUB=TProtoClass::FindDataMember; data member with index 0 is not found in class edm::value_ptr<vector<unsigned long> >.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4430
https://github.com/root-project/root/pull/4430:977,Availability,Error,Error,977,In some cases such as ROOT::Experimental::Internal::TUniWeakPtr the information about if a data member is transient is kept in the template pattern (residing in Core.pcm). The template instantiation is elsewhere (in the particular case) the ROOTHistDraw.pcm. In this scenario the LinkDef request for the particular instantiation is done after Core.pcm is built leaving no chance for rootcling to transform the comment into an annotation attibute attached to the template pattern. This does not happen very often but it may occur regularly when we start writing more templated code. We should store the IO comments for the template patterns independently on if a particular template instantiation was required. This is a modules-specific issue because the PCH includes the bulk of header files altogether and this helps the current system to place this information at the required place. This should fix the failures in tutorial-hist-h1draw and cmssw CXXModules IB:; Fatal Root Error: @SUB=TProtoClass::FindDataMember; data member with index 0 is not found in class edm::value_ptr<vector<unsigned long> >.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4430
https://github.com/root-project/root/pull/4437:434,Availability,Error,Error,434,"…te record for instantiating its definition. We model the 'inline'ness as being instantiated with the static data member in; order to track whether the declaration has become a definition yet. git-svn-id: https://llvm.org/svn/llvm-project/cfe/trunk@317147 91177308-0d34-0410-b5e6-96231b3b80d8. This patch fixes a problem in cxxmodules and c++17 of the kind:; ```; 1/2 Test #263: tutorial-dataframe-df004_cutFlowReport ......***Failed Error regular expression found in output. Regex=[: error:] 30.90 sec. Processing /home/vvassilev/workspace/sources/root/tutorials/dataframe/df004_cutFlowReport.C...; In module 'std' imported from input_line_1:1:; /usr/include/c++/7/string_view:88:41: error: static data member 'npos' already has an initializer; static constexpr size_type npos = size_type(-1);; ^; /usr/include/c++/7/string_view:319:43: note: in instantiation of static data member 'std::basic_string_view<char, std::char_traits<char> >::npos' requested here; rfind(_CharT __c, size_type __pos = npos) const noexcept;; ^; /home/vvassilev/workspace/builds/root_runtime_modules_builtin_clang_debug/include/ROOT/RDF/RInterface.hxx:468:14: note: in instantiation of function template specialization 'ROOT::RDF::RInterface<ROOT::Detail::RDF::RNodeBase, void>::SnapshotImpl<double, int>' requested here; return SnapshotImpl<ColumnTypes...>(treename, filename, columnList, options);; ^; input_line_102:2:206: note: in instantiation of function template specialization 'ROOT::RDF::RInterface<ROOT::Detail::RDF::RNodeBase, void>::Snapshot<double, int>' requested here; *reinterpret_cast<ROOT::RDF::RResultPtr<ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager>>*>(0x7fffffff9598) = reinterpret_cast<ROOT::RDF::RInterface<ROOT::Detail::RDF::RNodeBase>*>(0x7fffffff95d0)->Snapshot<__rdf1::b13_type, __rdf1::b24_type>(""myTree"", ""df004_cutFlowReport.root"", *reinterpret_cast<std::vector<std::string>*>(0x7fffffff9940),*reinterpret_cast<ROOT::RDF::RSnapshotOptions*>(0x7fffffff9a40));; ^; /usr/include/c++/7/str",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4437
https://github.com/root-project/root/pull/4437:485,Availability,error,error,485,"…te record for instantiating its definition. We model the 'inline'ness as being instantiated with the static data member in; order to track whether the declaration has become a definition yet. git-svn-id: https://llvm.org/svn/llvm-project/cfe/trunk@317147 91177308-0d34-0410-b5e6-96231b3b80d8. This patch fixes a problem in cxxmodules and c++17 of the kind:; ```; 1/2 Test #263: tutorial-dataframe-df004_cutFlowReport ......***Failed Error regular expression found in output. Regex=[: error:] 30.90 sec. Processing /home/vvassilev/workspace/sources/root/tutorials/dataframe/df004_cutFlowReport.C...; In module 'std' imported from input_line_1:1:; /usr/include/c++/7/string_view:88:41: error: static data member 'npos' already has an initializer; static constexpr size_type npos = size_type(-1);; ^; /usr/include/c++/7/string_view:319:43: note: in instantiation of static data member 'std::basic_string_view<char, std::char_traits<char> >::npos' requested here; rfind(_CharT __c, size_type __pos = npos) const noexcept;; ^; /home/vvassilev/workspace/builds/root_runtime_modules_builtin_clang_debug/include/ROOT/RDF/RInterface.hxx:468:14: note: in instantiation of function template specialization 'ROOT::RDF::RInterface<ROOT::Detail::RDF::RNodeBase, void>::SnapshotImpl<double, int>' requested here; return SnapshotImpl<ColumnTypes...>(treename, filename, columnList, options);; ^; input_line_102:2:206: note: in instantiation of function template specialization 'ROOT::RDF::RInterface<ROOT::Detail::RDF::RNodeBase, void>::Snapshot<double, int>' requested here; *reinterpret_cast<ROOT::RDF::RResultPtr<ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager>>*>(0x7fffffff9598) = reinterpret_cast<ROOT::RDF::RInterface<ROOT::Detail::RDF::RNodeBase>*>(0x7fffffff95d0)->Snapshot<__rdf1::b13_type, __rdf1::b24_type>(""myTree"", ""df004_cutFlowReport.root"", *reinterpret_cast<std::vector<std::string>*>(0x7fffffff9940),*reinterpret_cast<ROOT::RDF::RSnapshotOptions*>(0x7fffffff9a40));; ^; /usr/include/c++/7/str",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4437
https://github.com/root-project/root/pull/4437:685,Availability,error,error,685,"…te record for instantiating its definition. We model the 'inline'ness as being instantiated with the static data member in; order to track whether the declaration has become a definition yet. git-svn-id: https://llvm.org/svn/llvm-project/cfe/trunk@317147 91177308-0d34-0410-b5e6-96231b3b80d8. This patch fixes a problem in cxxmodules and c++17 of the kind:; ```; 1/2 Test #263: tutorial-dataframe-df004_cutFlowReport ......***Failed Error regular expression found in output. Regex=[: error:] 30.90 sec. Processing /home/vvassilev/workspace/sources/root/tutorials/dataframe/df004_cutFlowReport.C...; In module 'std' imported from input_line_1:1:; /usr/include/c++/7/string_view:88:41: error: static data member 'npos' already has an initializer; static constexpr size_type npos = size_type(-1);; ^; /usr/include/c++/7/string_view:319:43: note: in instantiation of static data member 'std::basic_string_view<char, std::char_traits<char> >::npos' requested here; rfind(_CharT __c, size_type __pos = npos) const noexcept;; ^; /home/vvassilev/workspace/builds/root_runtime_modules_builtin_clang_debug/include/ROOT/RDF/RInterface.hxx:468:14: note: in instantiation of function template specialization 'ROOT::RDF::RInterface<ROOT::Detail::RDF::RNodeBase, void>::SnapshotImpl<double, int>' requested here; return SnapshotImpl<ColumnTypes...>(treename, filename, columnList, options);; ^; input_line_102:2:206: note: in instantiation of function template specialization 'ROOT::RDF::RInterface<ROOT::Detail::RDF::RNodeBase, void>::Snapshot<double, int>' requested here; *reinterpret_cast<ROOT::RDF::RResultPtr<ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager>>*>(0x7fffffff9598) = reinterpret_cast<ROOT::RDF::RInterface<ROOT::Detail::RDF::RNodeBase>*>(0x7fffffff95d0)->Snapshot<__rdf1::b13_type, __rdf1::b24_type>(""myTree"", ""df004_cutFlowReport.root"", *reinterpret_cast<std::vector<std::string>*>(0x7fffffff9940),*reinterpret_cast<ROOT::RDF::RSnapshotOptions*>(0x7fffffff9a40));; ^; /usr/include/c++/7/str",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4437
https://github.com/root-project/root/pull/4437:2191,Availability,error,error,2191,"lar expression found in output. Regex=[: error:] 30.90 sec. Processing /home/vvassilev/workspace/sources/root/tutorials/dataframe/df004_cutFlowReport.C...; In module 'std' imported from input_line_1:1:; /usr/include/c++/7/string_view:88:41: error: static data member 'npos' already has an initializer; static constexpr size_type npos = size_type(-1);; ^; /usr/include/c++/7/string_view:319:43: note: in instantiation of static data member 'std::basic_string_view<char, std::char_traits<char> >::npos' requested here; rfind(_CharT __c, size_type __pos = npos) const noexcept;; ^; /home/vvassilev/workspace/builds/root_runtime_modules_builtin_clang_debug/include/ROOT/RDF/RInterface.hxx:468:14: note: in instantiation of function template specialization 'ROOT::RDF::RInterface<ROOT::Detail::RDF::RNodeBase, void>::SnapshotImpl<double, int>' requested here; return SnapshotImpl<ColumnTypes...>(treename, filename, columnList, options);; ^; input_line_102:2:206: note: in instantiation of function template specialization 'ROOT::RDF::RInterface<ROOT::Detail::RDF::RNodeBase, void>::Snapshot<double, int>' requested here; *reinterpret_cast<ROOT::RDF::RResultPtr<ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager>>*>(0x7fffffff9598) = reinterpret_cast<ROOT::RDF::RInterface<ROOT::Detail::RDF::RNodeBase>*>(0x7fffffff95d0)->Snapshot<__rdf1::b13_type, __rdf1::b24_type>(""myTree"", ""df004_cutFlowReport.root"", *reinterpret_cast<std::vector<std::string>*>(0x7fffffff9940),*reinterpret_cast<ROOT::RDF::RSnapshotOptions*>(0x7fffffff9a40));; ^; /usr/include/c++/7/string_view:88:41: note: previous initialization is here; static constexpr size_type npos = size_type(-1);; ^; terminate called after throwing an instance of 'std::runtime_error'; what(): ; An error occurred while jitting in Snapshot. The lines above might indicate the cause of the crash. CMake Error at /home/vvassilev/workspace/builds/root_runtime_modules_builtin_clang_debug/RootTestDriver.cmake:238 (message):; error code: Child aborted. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4437
https://github.com/root-project/root/pull/4437:2294,Availability,Error,Error,2294,"lar expression found in output. Regex=[: error:] 30.90 sec. Processing /home/vvassilev/workspace/sources/root/tutorials/dataframe/df004_cutFlowReport.C...; In module 'std' imported from input_line_1:1:; /usr/include/c++/7/string_view:88:41: error: static data member 'npos' already has an initializer; static constexpr size_type npos = size_type(-1);; ^; /usr/include/c++/7/string_view:319:43: note: in instantiation of static data member 'std::basic_string_view<char, std::char_traits<char> >::npos' requested here; rfind(_CharT __c, size_type __pos = npos) const noexcept;; ^; /home/vvassilev/workspace/builds/root_runtime_modules_builtin_clang_debug/include/ROOT/RDF/RInterface.hxx:468:14: note: in instantiation of function template specialization 'ROOT::RDF::RInterface<ROOT::Detail::RDF::RNodeBase, void>::SnapshotImpl<double, int>' requested here; return SnapshotImpl<ColumnTypes...>(treename, filename, columnList, options);; ^; input_line_102:2:206: note: in instantiation of function template specialization 'ROOT::RDF::RInterface<ROOT::Detail::RDF::RNodeBase, void>::Snapshot<double, int>' requested here; *reinterpret_cast<ROOT::RDF::RResultPtr<ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager>>*>(0x7fffffff9598) = reinterpret_cast<ROOT::RDF::RInterface<ROOT::Detail::RDF::RNodeBase>*>(0x7fffffff95d0)->Snapshot<__rdf1::b13_type, __rdf1::b24_type>(""myTree"", ""df004_cutFlowReport.root"", *reinterpret_cast<std::vector<std::string>*>(0x7fffffff9940),*reinterpret_cast<ROOT::RDF::RSnapshotOptions*>(0x7fffffff9a40));; ^; /usr/include/c++/7/string_view:88:41: note: previous initialization is here; static constexpr size_type npos = size_type(-1);; ^; terminate called after throwing an instance of 'std::runtime_error'; what(): ; An error occurred while jitting in Snapshot. The lines above might indicate the cause of the crash. CMake Error at /home/vvassilev/workspace/builds/root_runtime_modules_builtin_clang_debug/RootTestDriver.cmake:238 (message):; error code: Child aborted. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4437
https://github.com/root-project/root/pull/4437:2414,Availability,error,error,2414,"lar expression found in output. Regex=[: error:] 30.90 sec. Processing /home/vvassilev/workspace/sources/root/tutorials/dataframe/df004_cutFlowReport.C...; In module 'std' imported from input_line_1:1:; /usr/include/c++/7/string_view:88:41: error: static data member 'npos' already has an initializer; static constexpr size_type npos = size_type(-1);; ^; /usr/include/c++/7/string_view:319:43: note: in instantiation of static data member 'std::basic_string_view<char, std::char_traits<char> >::npos' requested here; rfind(_CharT __c, size_type __pos = npos) const noexcept;; ^; /home/vvassilev/workspace/builds/root_runtime_modules_builtin_clang_debug/include/ROOT/RDF/RInterface.hxx:468:14: note: in instantiation of function template specialization 'ROOT::RDF::RInterface<ROOT::Detail::RDF::RNodeBase, void>::SnapshotImpl<double, int>' requested here; return SnapshotImpl<ColumnTypes...>(treename, filename, columnList, options);; ^; input_line_102:2:206: note: in instantiation of function template specialization 'ROOT::RDF::RInterface<ROOT::Detail::RDF::RNodeBase, void>::Snapshot<double, int>' requested here; *reinterpret_cast<ROOT::RDF::RResultPtr<ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager>>*>(0x7fffffff9598) = reinterpret_cast<ROOT::RDF::RInterface<ROOT::Detail::RDF::RNodeBase>*>(0x7fffffff95d0)->Snapshot<__rdf1::b13_type, __rdf1::b24_type>(""myTree"", ""df004_cutFlowReport.root"", *reinterpret_cast<std::vector<std::string>*>(0x7fffffff9940),*reinterpret_cast<ROOT::RDF::RSnapshotOptions*>(0x7fffffff9a40));; ^; /usr/include/c++/7/string_view:88:41: note: previous initialization is here; static constexpr size_type npos = size_type(-1);; ^; terminate called after throwing an instance of 'std::runtime_error'; what(): ; An error occurred while jitting in Snapshot. The lines above might indicate the cause of the crash. CMake Error at /home/vvassilev/workspace/builds/root_runtime_modules_builtin_clang_debug/RootTestDriver.cmake:238 (message):; error code: Child aborted. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4437
https://github.com/root-project/root/pull/4437:299,Deployability,patch,patch,299,"…te record for instantiating its definition. We model the 'inline'ness as being instantiated with the static data member in; order to track whether the declaration has become a definition yet. git-svn-id: https://llvm.org/svn/llvm-project/cfe/trunk@317147 91177308-0d34-0410-b5e6-96231b3b80d8. This patch fixes a problem in cxxmodules and c++17 of the kind:; ```; 1/2 Test #263: tutorial-dataframe-df004_cutFlowReport ......***Failed Error regular expression found in output. Regex=[: error:] 30.90 sec. Processing /home/vvassilev/workspace/sources/root/tutorials/dataframe/df004_cutFlowReport.C...; In module 'std' imported from input_line_1:1:; /usr/include/c++/7/string_view:88:41: error: static data member 'npos' already has an initializer; static constexpr size_type npos = size_type(-1);; ^; /usr/include/c++/7/string_view:319:43: note: in instantiation of static data member 'std::basic_string_view<char, std::char_traits<char> >::npos' requested here; rfind(_CharT __c, size_type __pos = npos) const noexcept;; ^; /home/vvassilev/workspace/builds/root_runtime_modules_builtin_clang_debug/include/ROOT/RDF/RInterface.hxx:468:14: note: in instantiation of function template specialization 'ROOT::RDF::RInterface<ROOT::Detail::RDF::RNodeBase, void>::SnapshotImpl<double, int>' requested here; return SnapshotImpl<ColumnTypes...>(treename, filename, columnList, options);; ^; input_line_102:2:206: note: in instantiation of function template specialization 'ROOT::RDF::RInterface<ROOT::Detail::RDF::RNodeBase, void>::Snapshot<double, int>' requested here; *reinterpret_cast<ROOT::RDF::RResultPtr<ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager>>*>(0x7fffffff9598) = reinterpret_cast<ROOT::RDF::RInterface<ROOT::Detail::RDF::RNodeBase>*>(0x7fffffff95d0)->Snapshot<__rdf1::b13_type, __rdf1::b24_type>(""myTree"", ""df004_cutFlowReport.root"", *reinterpret_cast<std::vector<std::string>*>(0x7fffffff9940),*reinterpret_cast<ROOT::RDF::RSnapshotOptions*>(0x7fffffff9a40));; ^; /usr/include/c++/7/str",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4437
https://github.com/root-project/root/pull/4437:2403,Integrability,message,message,2403,"lar expression found in output. Regex=[: error:] 30.90 sec. Processing /home/vvassilev/workspace/sources/root/tutorials/dataframe/df004_cutFlowReport.C...; In module 'std' imported from input_line_1:1:; /usr/include/c++/7/string_view:88:41: error: static data member 'npos' already has an initializer; static constexpr size_type npos = size_type(-1);; ^; /usr/include/c++/7/string_view:319:43: note: in instantiation of static data member 'std::basic_string_view<char, std::char_traits<char> >::npos' requested here; rfind(_CharT __c, size_type __pos = npos) const noexcept;; ^; /home/vvassilev/workspace/builds/root_runtime_modules_builtin_clang_debug/include/ROOT/RDF/RInterface.hxx:468:14: note: in instantiation of function template specialization 'ROOT::RDF::RInterface<ROOT::Detail::RDF::RNodeBase, void>::SnapshotImpl<double, int>' requested here; return SnapshotImpl<ColumnTypes...>(treename, filename, columnList, options);; ^; input_line_102:2:206: note: in instantiation of function template specialization 'ROOT::RDF::RInterface<ROOT::Detail::RDF::RNodeBase, void>::Snapshot<double, int>' requested here; *reinterpret_cast<ROOT::RDF::RResultPtr<ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager>>*>(0x7fffffff9598) = reinterpret_cast<ROOT::RDF::RInterface<ROOT::Detail::RDF::RNodeBase>*>(0x7fffffff95d0)->Snapshot<__rdf1::b13_type, __rdf1::b24_type>(""myTree"", ""df004_cutFlowReport.root"", *reinterpret_cast<std::vector<std::string>*>(0x7fffffff9940),*reinterpret_cast<ROOT::RDF::RSnapshotOptions*>(0x7fffffff9a40));; ^; /usr/include/c++/7/string_view:88:41: note: previous initialization is here; static constexpr size_type npos = size_type(-1);; ^; terminate called after throwing an instance of 'std::runtime_error'; what(): ; An error occurred while jitting in Snapshot. The lines above might indicate the cause of the crash. CMake Error at /home/vvassilev/workspace/builds/root_runtime_modules_builtin_clang_debug/RootTestDriver.cmake:238 (message):; error code: Child aborted. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4437
https://github.com/root-project/root/pull/4437:2432,Safety,abort,aborted,2432,"lar expression found in output. Regex=[: error:] 30.90 sec. Processing /home/vvassilev/workspace/sources/root/tutorials/dataframe/df004_cutFlowReport.C...; In module 'std' imported from input_line_1:1:; /usr/include/c++/7/string_view:88:41: error: static data member 'npos' already has an initializer; static constexpr size_type npos = size_type(-1);; ^; /usr/include/c++/7/string_view:319:43: note: in instantiation of static data member 'std::basic_string_view<char, std::char_traits<char> >::npos' requested here; rfind(_CharT __c, size_type __pos = npos) const noexcept;; ^; /home/vvassilev/workspace/builds/root_runtime_modules_builtin_clang_debug/include/ROOT/RDF/RInterface.hxx:468:14: note: in instantiation of function template specialization 'ROOT::RDF::RInterface<ROOT::Detail::RDF::RNodeBase, void>::SnapshotImpl<double, int>' requested here; return SnapshotImpl<ColumnTypes...>(treename, filename, columnList, options);; ^; input_line_102:2:206: note: in instantiation of function template specialization 'ROOT::RDF::RInterface<ROOT::Detail::RDF::RNodeBase, void>::Snapshot<double, int>' requested here; *reinterpret_cast<ROOT::RDF::RResultPtr<ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager>>*>(0x7fffffff9598) = reinterpret_cast<ROOT::RDF::RInterface<ROOT::Detail::RDF::RNodeBase>*>(0x7fffffff95d0)->Snapshot<__rdf1::b13_type, __rdf1::b24_type>(""myTree"", ""df004_cutFlowReport.root"", *reinterpret_cast<std::vector<std::string>*>(0x7fffffff9940),*reinterpret_cast<ROOT::RDF::RSnapshotOptions*>(0x7fffffff9a40));; ^; /usr/include/c++/7/string_view:88:41: note: previous initialization is here; static constexpr size_type npos = size_type(-1);; ^; terminate called after throwing an instance of 'std::runtime_error'; what(): ; An error occurred while jitting in Snapshot. The lines above might indicate the cause of the crash. CMake Error at /home/vvassilev/workspace/builds/root_runtime_modules_builtin_clang_debug/RootTestDriver.cmake:238 (message):; error code: Child aborted. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4437
https://github.com/root-project/root/pull/4437:368,Testability,Test,Test,368,"…te record for instantiating its definition. We model the 'inline'ness as being instantiated with the static data member in; order to track whether the declaration has become a definition yet. git-svn-id: https://llvm.org/svn/llvm-project/cfe/trunk@317147 91177308-0d34-0410-b5e6-96231b3b80d8. This patch fixes a problem in cxxmodules and c++17 of the kind:; ```; 1/2 Test #263: tutorial-dataframe-df004_cutFlowReport ......***Failed Error regular expression found in output. Regex=[: error:] 30.90 sec. Processing /home/vvassilev/workspace/sources/root/tutorials/dataframe/df004_cutFlowReport.C...; In module 'std' imported from input_line_1:1:; /usr/include/c++/7/string_view:88:41: error: static data member 'npos' already has an initializer; static constexpr size_type npos = size_type(-1);; ^; /usr/include/c++/7/string_view:319:43: note: in instantiation of static data member 'std::basic_string_view<char, std::char_traits<char> >::npos' requested here; rfind(_CharT __c, size_type __pos = npos) const noexcept;; ^; /home/vvassilev/workspace/builds/root_runtime_modules_builtin_clang_debug/include/ROOT/RDF/RInterface.hxx:468:14: note: in instantiation of function template specialization 'ROOT::RDF::RInterface<ROOT::Detail::RDF::RNodeBase, void>::SnapshotImpl<double, int>' requested here; return SnapshotImpl<ColumnTypes...>(treename, filename, columnList, options);; ^; input_line_102:2:206: note: in instantiation of function template specialization 'ROOT::RDF::RInterface<ROOT::Detail::RDF::RNodeBase, void>::Snapshot<double, int>' requested here; *reinterpret_cast<ROOT::RDF::RResultPtr<ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager>>*>(0x7fffffff9598) = reinterpret_cast<ROOT::RDF::RInterface<ROOT::Detail::RDF::RNodeBase>*>(0x7fffffff95d0)->Snapshot<__rdf1::b13_type, __rdf1::b24_type>(""myTree"", ""df004_cutFlowReport.root"", *reinterpret_cast<std::vector<std::string>*>(0x7fffffff9940),*reinterpret_cast<ROOT::RDF::RSnapshotOptions*>(0x7fffffff9a40));; ^; /usr/include/c++/7/str",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4437
https://github.com/root-project/root/pull/4439:21,Availability,error,error,21,Prevent this kind of error when using ACLiC:; LINK : fatal error LNK1181: it is not possible to open input file 'VCRUNTIME140.lib',MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4439
https://github.com/root-project/root/pull/4439:59,Availability,error,error,59,Prevent this kind of error when using ACLiC:; LINK : fatal error LNK1181: it is not possible to open input file 'VCRUNTIME140.lib',MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4439
https://github.com/root-project/root/pull/4440:79,Availability,error,errors,79,I have debugged the code up till the evaluate() method and it seems ok. So the errors are maybe at the analytical integral...,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4440
https://github.com/root-project/root/pull/4442:30,Availability,failure,failures,30,"Fix intermittent nightly test failures such as:. https://epsft-jenkins.cern.ch/job/root-exp-pyroot/264/LABEL=ROOT-ubuntu18.04,SPEC=python3/testReport/junit/projectroot.bindings.pyroot_experimental.PyROOT/test/pyunittests_pyroot_pyz_ttree_setbranchaddress/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4442
https://github.com/root-project/root/pull/4442:25,Testability,test,test,25,"Fix intermittent nightly test failures such as:. https://epsft-jenkins.cern.ch/job/root-exp-pyroot/264/LABEL=ROOT-ubuntu18.04,SPEC=python3/testReport/junit/projectroot.bindings.pyroot_experimental.PyROOT/test/pyunittests_pyroot_pyz_ttree_setbranchaddress/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4442
https://github.com/root-project/root/pull/4442:139,Testability,test,testReport,139,"Fix intermittent nightly test failures such as:. https://epsft-jenkins.cern.ch/job/root-exp-pyroot/264/LABEL=ROOT-ubuntu18.04,SPEC=python3/testReport/junit/projectroot.bindings.pyroot_experimental.PyROOT/test/pyunittests_pyroot_pyz_ttree_setbranchaddress/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4442
https://github.com/root-project/root/pull/4442:204,Testability,test,test,204,"Fix intermittent nightly test failures such as:. https://epsft-jenkins.cern.ch/job/root-exp-pyroot/264/LABEL=ROOT-ubuntu18.04,SPEC=python3/testReport/junit/projectroot.bindings.pyroot_experimental.PyROOT/test/pyunittests_pyroot_pyz_ttree_setbranchaddress/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4442
https://github.com/root-project/root/pull/4446:102,Performance,cache,cached,102,"Provides an implentation for the `DefinitionShadowed()` interpreter callback, that invalidates TCling cached information about a former declaration (that has been shadowed). This PR also includes a minor fix for test 'cling/test/CodeUnloading/DeclShadowing.C'.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4446
https://github.com/root-project/root/pull/4446:212,Testability,test,test,212,"Provides an implentation for the `DefinitionShadowed()` interpreter callback, that invalidates TCling cached information about a former declaration (that has been shadowed). This PR also includes a minor fix for test 'cling/test/CodeUnloading/DeclShadowing.C'.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4446
https://github.com/root-project/root/pull/4446:224,Testability,test,test,224,"Provides an implentation for the `DefinitionShadowed()` interpreter callback, that invalidates TCling cached information about a former declaration (that has been shadowed). This PR also includes a minor fix for test 'cling/test/CodeUnloading/DeclShadowing.C'.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4446
https://github.com/root-project/root/pull/4447:559,Integrability,interface,interface,559,"DeclUnloader was trying to unload template instantiations whose point of (first) instantiation was the PCH. This caused problems with the code below. In particular, the class specialization `std::vector<int>` was instantiated in the PCH as part of `std::stack<...>`, which in turn was required by the STL <regex> header.; ```; root [0] std::vector<int> foo, bar;; root [1] std::swap(foo, bar);; root [2] .undo 1; root [3] std::swap(foo, bar);; IncrementalExecutor::executeFunction: symbol '_ZSt15__alloc_on_swapISaIiEEvRT_S2_' unresolved while linking [cling interface function]!; ```. This PR fixes the issue avoiding the unload of decls instantiated in the PCH.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4447
https://github.com/root-project/root/pull/4447:610,Safety,avoid,avoiding,610,"DeclUnloader was trying to unload template instantiations whose point of (first) instantiation was the PCH. This caused problems with the code below. In particular, the class specialization `std::vector<int>` was instantiated in the PCH as part of `std::stack<...>`, which in turn was required by the STL <regex> header.; ```; root [0] std::vector<int> foo, bar;; root [1] std::swap(foo, bar);; root [2] .undo 1; root [3] std::swap(foo, bar);; IncrementalExecutor::executeFunction: symbol '_ZSt15__alloc_on_swapISaIiEEvRT_S2_' unresolved while linking [cling interface function]!; ```. This PR fixes the issue avoiding the unload of decls instantiated in the PCH.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4447
https://github.com/root-project/root/pull/4447:405,Usability,undo,undo,405,"DeclUnloader was trying to unload template instantiations whose point of (first) instantiation was the PCH. This caused problems with the code below. In particular, the class specialization `std::vector<int>` was instantiated in the PCH as part of `std::stack<...>`, which in turn was required by the STL <regex> header.; ```; root [0] std::vector<int> foo, bar;; root [1] std::swap(foo, bar);; root [2] .undo 1; root [3] std::swap(foo, bar);; IncrementalExecutor::executeFunction: symbol '_ZSt15__alloc_on_swapISaIiEEvRT_S2_' unresolved while linking [cling interface function]!; ```. This PR fixes the issue avoiding the unload of decls instantiated in the PCH.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4447
https://github.com/root-project/root/pull/4448:0,Integrability,Depend,Depends,0,"Depends on #4401, requires rebase.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4448
https://github.com/root-project/root/pull/4451:32,Availability,failure,failures,32,This should fix the compilation failures when we build ROOT with modules; in c++17 mode. This should be solved in clang upstream.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4451
https://github.com/root-project/root/pull/4456:316,Deployability,Update,Update,316,1. Use hex string for RGB like 01FFC5; 2. Use also hex for color alpha like FF; 3. Make easier to compose result color; 4. Support plain SVG names - need to provide predefined list; 5. Reintroduce methods for HLS; 6. Provide different Setter/Getter/Clear methods; 7. Move RColor testing to correspondent library; 8. Update JSROOT code - for RColor but also recent fixes in v6,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4456
https://github.com/root-project/root/pull/4456:279,Testability,test,testing,279,1. Use hex string for RGB like 01FFC5; 2. Use also hex for color alpha like FF; 3. Make easier to compose result color; 4. Support plain SVG names - need to provide predefined list; 5. Reintroduce methods for HLS; 6. Provide different Setter/Getter/Clear methods; 7. Move RColor testing to correspondent library; 8. Update JSROOT code - for RColor but also recent fixes in v6,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4456
https://github.com/root-project/root/pull/4456:249,Usability,Clear,Clear,249,1. Use hex string for RGB like 01FFC5; 2. Use also hex for color alpha like FF; 3. Make easier to compose result color; 4. Support plain SVG names - need to provide predefined list; 5. Reintroduce methods for HLS; 6. Provide different Setter/Getter/Clear methods; 7. Move RColor testing to correspondent library; 8. Update JSROOT code - for RColor but also recent fixes in v6,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4456
https://github.com/root-project/root/pull/4457:20,Availability,error,errors,20,"This should fix the errors LNK2019: unresolved external symbol ""const ROOT::Experimental::RHistDrawable<1>::'vftable'""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4457
https://github.com/root-project/root/pull/4459:164,Availability,Recover,Recover,164,- Only rely on presence of TMCManager in multi run (PR#6 in vmc-project/vmc); - Withdraw unwanted TMCVerbose modifications to avoid changes in the tests outputs; - Recover TGeoManager::fIsOutside for transfer tracks (PR#3 in vmc-project/vmc),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4459
https://github.com/root-project/root/pull/4459:126,Safety,avoid,avoid,126,- Only rely on presence of TMCManager in multi run (PR#6 in vmc-project/vmc); - Withdraw unwanted TMCVerbose modifications to avoid changes in the tests outputs; - Recover TGeoManager::fIsOutside for transfer tracks (PR#3 in vmc-project/vmc),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4459
https://github.com/root-project/root/pull/4459:164,Safety,Recover,Recover,164,- Only rely on presence of TMCManager in multi run (PR#6 in vmc-project/vmc); - Withdraw unwanted TMCVerbose modifications to avoid changes in the tests outputs; - Recover TGeoManager::fIsOutside for transfer tracks (PR#3 in vmc-project/vmc),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4459
https://github.com/root-project/root/pull/4459:147,Testability,test,tests,147,- Only rely on presence of TMCManager in multi run (PR#6 in vmc-project/vmc); - Withdraw unwanted TMCVerbose modifications to avoid changes in the tests outputs; - Recover TGeoManager::fIsOutside for transfer tracks (PR#3 in vmc-project/vmc),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4459
https://github.com/root-project/root/pull/4465:173,Modifiability,variab,variable,173,"Originally, the changes in this branch avoided the unload/load cycle for the `.x` command, if the timestamp of a file has not changed. Due to potential problems with static variable initialization, this behavior is not finally part of this PR. Other than that, this branch includes several improvements:; - General `MetaSema.cpp` code cleanup.; - `.x` now has a list of (fallback) function names that we will try to call, in order. This makes it possible to add alternate entry points for a macro that are independent from the filename, and therefore immune to file renaming.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4465
https://github.com/root-project/root/pull/4465:58,Performance,load,load,58,"Originally, the changes in this branch avoided the unload/load cycle for the `.x` command, if the timestamp of a file has not changed. Due to potential problems with static variable initialization, this behavior is not finally part of this PR. Other than that, this branch includes several improvements:; - General `MetaSema.cpp` code cleanup.; - `.x` now has a list of (fallback) function names that we will try to call, in order. This makes it possible to add alternate entry points for a macro that are independent from the filename, and therefore immune to file renaming.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4465
https://github.com/root-project/root/pull/4465:39,Safety,avoid,avoided,39,"Originally, the changes in this branch avoided the unload/load cycle for the `.x` command, if the timestamp of a file has not changed. Due to potential problems with static variable initialization, this behavior is not finally part of this PR. Other than that, this branch includes several improvements:; - General `MetaSema.cpp` code cleanup.; - `.x` now has a list of (fallback) function names that we will try to call, in order. This makes it possible to add alternate entry points for a macro that are independent from the filename, and therefore immune to file renaming.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4465
https://github.com/root-project/root/pull/4469:550,Testability,log,logic,550,"1. Now unique drawable id will be produced when display items are created for drawables.; Each drawable has now fully custom id, which can be used later in CSS selector (on server and client sides). . 2. Fully remove RPadPainter and RHistPainter classes. These classes were introducing extra complication level around drawable classes. Now they are not necessary - correspondent RHistDrawable/RPadBase classes have methods to create appropriate RDisplayItem instances. ; `RDrawable::Display()` method fully replaces `RDrawable::Paint(RPadPainter &)` logic. 3. Fix small problems with ROOT6 classes support in RCanvas. Sync v7 context menu classes with ROOT6 TWebCanvas. Potentially TObject drawable could be moved to primitives. . 4. When RStyle applyed to RPadBase, it automatically distributed to all primitives",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4469
https://github.com/root-project/root/pull/4473:138,Usability,guid,guide,138,"Revisit the doxygen formatting for ROOT 7 graphics.; Make new groups to better reflect the structure in ""Functional part""of the Reference guide.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4473
https://github.com/root-project/root/pull/4474:31,Availability,error,error,31,"Remove the work-around for the error C2668: 'ROOT::TThreadExecutor::Map': ambiguous call to overloaded function, due to a MS compiler bug, which is now fixed in more recent versions of Visual Studio",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4474
https://github.com/root-project/root/pull/4476:340,Availability,error,error-handling,340,"Add tree inference backend using jitted evaluation of the forest. Preliminary benchmarks look promising and show a clear improvement due to the jitting (100 trees, depth 3, 100k events):. ```; XGB: 2.30692 microsec/event; BranchlessForest: 0.962279 microsec/event; BranchlessJittedForest: 0.67292 microsec/event; ```. WIP: Still needs some error-handling and doxygen markup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4476
https://github.com/root-project/root/pull/4476:78,Testability,benchmark,benchmarks,78,"Add tree inference backend using jitted evaluation of the forest. Preliminary benchmarks look promising and show a clear improvement due to the jitting (100 trees, depth 3, 100k events):. ```; XGB: 2.30692 microsec/event; BranchlessForest: 0.962279 microsec/event; BranchlessJittedForest: 0.67292 microsec/event; ```. WIP: Still needs some error-handling and doxygen markup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4476
https://github.com/root-project/root/pull/4476:115,Usability,clear,clear,115,"Add tree inference backend using jitted evaluation of the forest. Preliminary benchmarks look promising and show a clear improvement due to the jitting (100 trees, depth 3, 100k events):. ```; XGB: 2.30692 microsec/event; BranchlessForest: 0.962279 microsec/event; BranchlessJittedForest: 0.67292 microsec/event; ```. WIP: Still needs some error-handling and doxygen markup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4476
https://github.com/root-project/root/pull/4480:508,Deployability,patch,patch,508,"In clang a transient file is a header file which is stored in the pch/pcm file. If this file does not exist, clang creates a virtual file of the unzipped stored file. However, if the file exists it compares the size of the file on disk and the size of the transent file. If the two sizes are different it does not complain (as validation is off) but it triggers an assert in when constructing and outdated clang::InputFile. The implementation disallows a overridden or transient file to be out of date. This patch extends the DisableValidation abilities to span not only for timestamps but we avoid checking the file sizes if the file is on the disk. And, instead we just create a virtual file of the file that we already have. This patch should fix a relocation issue for cmssw and some of the reported LCG issues. cc: @oshadura, @davidlange6, @smuzaffar, @emanca, @zygoloid",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4480
https://github.com/root-project/root/pull/4480:733,Deployability,patch,patch,733,"In clang a transient file is a header file which is stored in the pch/pcm file. If this file does not exist, clang creates a virtual file of the unzipped stored file. However, if the file exists it compares the size of the file on disk and the size of the transent file. If the two sizes are different it does not complain (as validation is off) but it triggers an assert in when constructing and outdated clang::InputFile. The implementation disallows a overridden or transient file to be out of date. This patch extends the DisableValidation abilities to span not only for timestamps but we avoid checking the file sizes if the file is on the disk. And, instead we just create a virtual file of the file that we already have. This patch should fix a relocation issue for cmssw and some of the reported LCG issues. cc: @oshadura, @davidlange6, @smuzaffar, @emanca, @zygoloid",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4480
https://github.com/root-project/root/pull/4480:514,Modifiability,extend,extends,514,"In clang a transient file is a header file which is stored in the pch/pcm file. If this file does not exist, clang creates a virtual file of the unzipped stored file. However, if the file exists it compares the size of the file on disk and the size of the transent file. If the two sizes are different it does not complain (as validation is off) but it triggers an assert in when constructing and outdated clang::InputFile. The implementation disallows a overridden or transient file to be out of date. This patch extends the DisableValidation abilities to span not only for timestamps but we avoid checking the file sizes if the file is on the disk. And, instead we just create a virtual file of the file that we already have. This patch should fix a relocation issue for cmssw and some of the reported LCG issues. cc: @oshadura, @davidlange6, @smuzaffar, @emanca, @zygoloid",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4480
https://github.com/root-project/root/pull/4480:593,Safety,avoid,avoid,593,"In clang a transient file is a header file which is stored in the pch/pcm file. If this file does not exist, clang creates a virtual file of the unzipped stored file. However, if the file exists it compares the size of the file on disk and the size of the transent file. If the two sizes are different it does not complain (as validation is off) but it triggers an assert in when constructing and outdated clang::InputFile. The implementation disallows a overridden or transient file to be out of date. This patch extends the DisableValidation abilities to span not only for timestamps but we avoid checking the file sizes if the file is on the disk. And, instead we just create a virtual file of the file that we already have. This patch should fix a relocation issue for cmssw and some of the reported LCG issues. cc: @oshadura, @davidlange6, @smuzaffar, @emanca, @zygoloid",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4480
https://github.com/root-project/root/pull/4480:327,Security,validat,validation,327,"In clang a transient file is a header file which is stored in the pch/pcm file. If this file does not exist, clang creates a virtual file of the unzipped stored file. However, if the file exists it compares the size of the file on disk and the size of the transent file. If the two sizes are different it does not complain (as validation is off) but it triggers an assert in when constructing and outdated clang::InputFile. The implementation disallows a overridden or transient file to be out of date. This patch extends the DisableValidation abilities to span not only for timestamps but we avoid checking the file sizes if the file is on the disk. And, instead we just create a virtual file of the file that we already have. This patch should fix a relocation issue for cmssw and some of the reported LCG issues. cc: @oshadura, @davidlange6, @smuzaffar, @emanca, @zygoloid",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4480
https://github.com/root-project/root/pull/4480:365,Testability,assert,assert,365,"In clang a transient file is a header file which is stored in the pch/pcm file. If this file does not exist, clang creates a virtual file of the unzipped stored file. However, if the file exists it compares the size of the file on disk and the size of the transent file. If the two sizes are different it does not complain (as validation is off) but it triggers an assert in when constructing and outdated clang::InputFile. The implementation disallows a overridden or transient file to be out of date. This patch extends the DisableValidation abilities to span not only for timestamps but we avoid checking the file sizes if the file is on the disk. And, instead we just create a virtual file of the file that we already have. This patch should fix a relocation issue for cmssw and some of the reported LCG issues. cc: @oshadura, @davidlange6, @smuzaffar, @emanca, @zygoloid",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4480
https://github.com/root-project/root/pull/4481:484,Testability,test,test,484,"Each RDrawable can get assigned RStyle object via `weak_ptr`; At the moment when display items are created, all RStyle object are temporary locked and streamed to the client. On the client side one can use three kinds of selectors:; - by id, which can be assigned to any RDrawable ; - by class, which is again arbitrary value for each RDrawable ; - by type, which is simple text like ""box"" for RBox, ""line"" for RLine and so on; For the moment very simple CSS evaluation is supported. test and tutorials macros for RStyle are provided. Also adjust other tutorials/v7/ macros. To be done: creating RStyle from parsing text CSS files and storing RStyle as text",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4481
https://github.com/root-project/root/pull/4481:367,Usability,simpl,simple,367,"Each RDrawable can get assigned RStyle object via `weak_ptr`; At the moment when display items are created, all RStyle object are temporary locked and streamed to the client. On the client side one can use three kinds of selectors:; - by id, which can be assigned to any RDrawable ; - by class, which is again arbitrary value for each RDrawable ; - by type, which is simple text like ""box"" for RBox, ""line"" for RLine and so on; For the moment very simple CSS evaluation is supported. test and tutorials macros for RStyle are provided. Also adjust other tutorials/v7/ macros. To be done: creating RStyle from parsing text CSS files and storing RStyle as text",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4481
https://github.com/root-project/root/pull/4481:448,Usability,simpl,simple,448,"Each RDrawable can get assigned RStyle object via `weak_ptr`; At the moment when display items are created, all RStyle object are temporary locked and streamed to the client. On the client side one can use three kinds of selectors:; - by id, which can be assigned to any RDrawable ; - by class, which is again arbitrary value for each RDrawable ; - by type, which is simple text like ""box"" for RBox, ""line"" for RLine and so on; For the moment very simple CSS evaluation is supported. test and tutorials macros for RStyle are provided. Also adjust other tutorials/v7/ macros. To be done: creating RStyle from parsing text CSS files and storing RStyle as text",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4481
https://github.com/root-project/root/pull/4487:259,Availability,fault,fault,259,"This fixes ROOT-10333. Since the printValue set of functions always takes a pointer and dereferences it without any checks,; the previous implementation was attempting to valuePrint the pointee (rather than the pointer value); but this lead to a segmentation fault whenever the smart pointer was set to nullptr. Now, the valuePrinting for the smart pointers behaves the same as for regular pointer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4487
https://github.com/root-project/root/pull/4488:552,Availability,error,error,552,…argets. ROOT builds cling and then moves a set of headers under the semi-private $ROOTSYS/etc/cling. This poses an issue -- the set of proper cling dependencies seem not enough to propagate that information to rootcling for example. Instead of adding LLVMRES to rootcling (as it is the case for rootcling_stage1) add the dependency to something more fundamental such as ClingUtils. This will propagate it transitively to all parties without having to specify the sort-of internal LLVMRES target. This patch should fix the incremental builds where the error is:; error: file '/.../RuntimePrintValue.h' from the precompiled header has been overridden. cc: @Axel-Naumann,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4488
https://github.com/root-project/root/pull/4488:563,Availability,error,error,563,…argets. ROOT builds cling and then moves a set of headers under the semi-private $ROOTSYS/etc/cling. This poses an issue -- the set of proper cling dependencies seem not enough to propagate that information to rootcling for example. Instead of adding LLVMRES to rootcling (as it is the case for rootcling_stage1) add the dependency to something more fundamental such as ClingUtils. This will propagate it transitively to all parties without having to specify the sort-of internal LLVMRES target. This patch should fix the incremental builds where the error is:; error: file '/.../RuntimePrintValue.h' from the precompiled header has been overridden. cc: @Axel-Naumann,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4488
https://github.com/root-project/root/pull/4488:502,Deployability,patch,patch,502,…argets. ROOT builds cling and then moves a set of headers under the semi-private $ROOTSYS/etc/cling. This poses an issue -- the set of proper cling dependencies seem not enough to propagate that information to rootcling for example. Instead of adding LLVMRES to rootcling (as it is the case for rootcling_stage1) add the dependency to something more fundamental such as ClingUtils. This will propagate it transitively to all parties without having to specify the sort-of internal LLVMRES target. This patch should fix the incremental builds where the error is:; error: file '/.../RuntimePrintValue.h' from the precompiled header has been overridden. cc: @Axel-Naumann,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4488
https://github.com/root-project/root/pull/4488:149,Integrability,depend,dependencies,149,…argets. ROOT builds cling and then moves a set of headers under the semi-private $ROOTSYS/etc/cling. This poses an issue -- the set of proper cling dependencies seem not enough to propagate that information to rootcling for example. Instead of adding LLVMRES to rootcling (as it is the case for rootcling_stage1) add the dependency to something more fundamental such as ClingUtils. This will propagate it transitively to all parties without having to specify the sort-of internal LLVMRES target. This patch should fix the incremental builds where the error is:; error: file '/.../RuntimePrintValue.h' from the precompiled header has been overridden. cc: @Axel-Naumann,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4488
https://github.com/root-project/root/pull/4488:322,Integrability,depend,dependency,322,…argets. ROOT builds cling and then moves a set of headers under the semi-private $ROOTSYS/etc/cling. This poses an issue -- the set of proper cling dependencies seem not enough to propagate that information to rootcling for example. Instead of adding LLVMRES to rootcling (as it is the case for rootcling_stage1) add the dependency to something more fundamental such as ClingUtils. This will propagate it transitively to all parties without having to specify the sort-of internal LLVMRES target. This patch should fix the incremental builds where the error is:; error: file '/.../RuntimePrintValue.h' from the precompiled header has been overridden. cc: @Axel-Naumann,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4488
https://github.com/root-project/root/pull/4490:12,Energy Efficiency,reduce,reduce,12,This should reduce the textual duplicates in all C++ modules.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4490
https://github.com/root-project/root/pull/4493:98,Availability,error,error,98,As suggested in:. https://sft.its.cern.ch/jira/browse/ROOT-9915. we implemented a way to raise an error when a file is opened (for reading) using TFile constructor or TFile::Open().,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4493
https://github.com/root-project/root/pull/4495:420,Availability,error,error,420,"This patch is a complementary chenge to root-project/root@d2c0929e0d It will turn off the isOutOfDate checks for transient files with different size on disk. This is quite dangerous but we are supposed to control the build environment which prepares the distributable binaries. This should fix the cmssw issue:. StdDictionaries/src/DataFormatsStdDictionaries/a/DataFormatsStdDictionaries_all_def.xml; input_line_8:1:22: error: file '/usr/include/linux/falloc.h' from the precompiled header has been overridden; ^; rootcling: /build/cmsbld/jenkins/workspace/build-any-ib/w/BUILD/slc7_amd64_gcc820/lcg/root/6.17.01/root-6.17.01/interpreter/llvm/src/tools/clang/include/clang/Serialization/Module.h:72: clang::serialization::InputFile::InputFile(const clang::FileEntry*, bool, bool): Assertion `!(isOverridden && isOutOfDate) && ""an overridden cannot be out-of-date""' failed. The error tells us that `falloc.h` has different file size on the build machine and; on the distribution machine. We should probably rely on an environment variable; to turn off this diagnostic selectively and more the reponsibility if something goes; wrong to the distribution team. They should have better knowledge what is safe to; be ignored anyway. cc: @davidlange6, @oshadura, @smuzaffar",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4495
https://github.com/root-project/root/pull/4495:877,Availability,error,error,877,"This patch is a complementary chenge to root-project/root@d2c0929e0d It will turn off the isOutOfDate checks for transient files with different size on disk. This is quite dangerous but we are supposed to control the build environment which prepares the distributable binaries. This should fix the cmssw issue:. StdDictionaries/src/DataFormatsStdDictionaries/a/DataFormatsStdDictionaries_all_def.xml; input_line_8:1:22: error: file '/usr/include/linux/falloc.h' from the precompiled header has been overridden; ^; rootcling: /build/cmsbld/jenkins/workspace/build-any-ib/w/BUILD/slc7_amd64_gcc820/lcg/root/6.17.01/root-6.17.01/interpreter/llvm/src/tools/clang/include/clang/Serialization/Module.h:72: clang::serialization::InputFile::InputFile(const clang::FileEntry*, bool, bool): Assertion `!(isOverridden && isOutOfDate) && ""an overridden cannot be out-of-date""' failed. The error tells us that `falloc.h` has different file size on the build machine and; on the distribution machine. We should probably rely on an environment variable; to turn off this diagnostic selectively and more the reponsibility if something goes; wrong to the distribution team. They should have better knowledge what is safe to; be ignored anyway. cc: @davidlange6, @oshadura, @smuzaffar",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4495
https://github.com/root-project/root/pull/4495:5,Deployability,patch,patch,5,"This patch is a complementary chenge to root-project/root@d2c0929e0d It will turn off the isOutOfDate checks for transient files with different size on disk. This is quite dangerous but we are supposed to control the build environment which prepares the distributable binaries. This should fix the cmssw issue:. StdDictionaries/src/DataFormatsStdDictionaries/a/DataFormatsStdDictionaries_all_def.xml; input_line_8:1:22: error: file '/usr/include/linux/falloc.h' from the precompiled header has been overridden; ^; rootcling: /build/cmsbld/jenkins/workspace/build-any-ib/w/BUILD/slc7_amd64_gcc820/lcg/root/6.17.01/root-6.17.01/interpreter/llvm/src/tools/clang/include/clang/Serialization/Module.h:72: clang::serialization::InputFile::InputFile(const clang::FileEntry*, bool, bool): Assertion `!(isOverridden && isOutOfDate) && ""an overridden cannot be out-of-date""' failed. The error tells us that `falloc.h` has different file size on the build machine and; on the distribution machine. We should probably rely on an environment variable; to turn off this diagnostic selectively and more the reponsibility if something goes; wrong to the distribution team. They should have better knowledge what is safe to; be ignored anyway. cc: @davidlange6, @oshadura, @smuzaffar",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4495
https://github.com/root-project/root/pull/4495:1029,Modifiability,variab,variable,1029,"This patch is a complementary chenge to root-project/root@d2c0929e0d It will turn off the isOutOfDate checks for transient files with different size on disk. This is quite dangerous but we are supposed to control the build environment which prepares the distributable binaries. This should fix the cmssw issue:. StdDictionaries/src/DataFormatsStdDictionaries/a/DataFormatsStdDictionaries_all_def.xml; input_line_8:1:22: error: file '/usr/include/linux/falloc.h' from the precompiled header has been overridden; ^; rootcling: /build/cmsbld/jenkins/workspace/build-any-ib/w/BUILD/slc7_amd64_gcc820/lcg/root/6.17.01/root-6.17.01/interpreter/llvm/src/tools/clang/include/clang/Serialization/Module.h:72: clang::serialization::InputFile::InputFile(const clang::FileEntry*, bool, bool): Assertion `!(isOverridden && isOutOfDate) && ""an overridden cannot be out-of-date""' failed. The error tells us that `falloc.h` has different file size on the build machine and; on the distribution machine. We should probably rely on an environment variable; to turn off this diagnostic selectively and more the reponsibility if something goes; wrong to the distribution team. They should have better knowledge what is safe to; be ignored anyway. cc: @davidlange6, @oshadura, @smuzaffar",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4495
https://github.com/root-project/root/pull/4495:1199,Safety,safe,safe,1199,"This patch is a complementary chenge to root-project/root@d2c0929e0d It will turn off the isOutOfDate checks for transient files with different size on disk. This is quite dangerous but we are supposed to control the build environment which prepares the distributable binaries. This should fix the cmssw issue:. StdDictionaries/src/DataFormatsStdDictionaries/a/DataFormatsStdDictionaries_all_def.xml; input_line_8:1:22: error: file '/usr/include/linux/falloc.h' from the precompiled header has been overridden; ^; rootcling: /build/cmsbld/jenkins/workspace/build-any-ib/w/BUILD/slc7_amd64_gcc820/lcg/root/6.17.01/root-6.17.01/interpreter/llvm/src/tools/clang/include/clang/Serialization/Module.h:72: clang::serialization::InputFile::InputFile(const clang::FileEntry*, bool, bool): Assertion `!(isOverridden && isOutOfDate) && ""an overridden cannot be out-of-date""' failed. The error tells us that `falloc.h` has different file size on the build machine and; on the distribution machine. We should probably rely on an environment variable; to turn off this diagnostic selectively and more the reponsibility if something goes; wrong to the distribution team. They should have better knowledge what is safe to; be ignored anyway. cc: @davidlange6, @oshadura, @smuzaffar",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4495
https://github.com/root-project/root/pull/4495:781,Testability,Assert,Assertion,781,"This patch is a complementary chenge to root-project/root@d2c0929e0d It will turn off the isOutOfDate checks for transient files with different size on disk. This is quite dangerous but we are supposed to control the build environment which prepares the distributable binaries. This should fix the cmssw issue:. StdDictionaries/src/DataFormatsStdDictionaries/a/DataFormatsStdDictionaries_all_def.xml; input_line_8:1:22: error: file '/usr/include/linux/falloc.h' from the precompiled header has been overridden; ^; rootcling: /build/cmsbld/jenkins/workspace/build-any-ib/w/BUILD/slc7_amd64_gcc820/lcg/root/6.17.01/root-6.17.01/interpreter/llvm/src/tools/clang/include/clang/Serialization/Module.h:72: clang::serialization::InputFile::InputFile(const clang::FileEntry*, bool, bool): Assertion `!(isOverridden && isOutOfDate) && ""an overridden cannot be out-of-date""' failed. The error tells us that `falloc.h` has different file size on the build machine and; on the distribution machine. We should probably rely on an environment variable; to turn off this diagnostic selectively and more the reponsibility if something goes; wrong to the distribution team. They should have better knowledge what is safe to; be ignored anyway. cc: @davidlange6, @oshadura, @smuzaffar",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4495
https://github.com/root-project/root/pull/4497:72,Testability,test,tested,72,This is try to use Jupyter static location for JSROOT files.; Should be tested,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4497
https://github.com/root-project/root/pull/4498:9,Availability,error,error,9,Plus fix error with TCanvas,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4498
https://github.com/root-project/root/pull/4499:280,Deployability,update,update,280,Now both TCanvas or RCanvas can be used in RBrowser.; In both cases very similar code is used for embedding - some extension of interface was required.; On client side code is mostly identical.; For the moment TCanvas is default while RCanvas has some problem on client side with update,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4499
https://github.com/root-project/root/pull/4499:128,Integrability,interface,interface,128,Now both TCanvas or RCanvas can be used in RBrowser.; In both cases very similar code is used for embedding - some extension of interface was required.; On client side code is mostly identical.; For the moment TCanvas is default while RCanvas has some problem on client side with update,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4499
https://github.com/root-project/root/pull/4500:26,Deployability,update,update,26,Now RCanvas can correctly update/redraw ROOT6 objects - which is main test-case for RBrowser now,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4500
https://github.com/root-project/root/pull/4500:70,Testability,test,test-case,70,Now RCanvas can correctly update/redraw ROOT6 objects - which is main test-case for RBrowser now,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4500
https://github.com/root-project/root/pull/4503:113,Testability,test,tests,113,Add 'MSVCCompat' flag and set 'ThreadsafeStatics = 0' (this fixes crash when running line.cxx and text.cxx root7 tests in interpreted mode),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4503
https://github.com/root-project/root/pull/4506:30,Deployability,update,updated,30,The RooBernstein pdf is to be updated to have the correct definition over ranges of the variable.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4506
https://github.com/root-project/root/pull/4506:88,Modifiability,variab,variable,88,The RooBernstein pdf is to be updated to have the correct definition over ranges of the variable.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4506
https://github.com/root-project/root/pull/4507:731,Availability,error,error,731,"Closed the previous pull request and creating a new one after rebasing. All changes are pertaining to plotting changes within RooFit. @cburgard's comments from the previous MR ; The RooFit ""plotOn"" plotting engine is very useful to visualize RooFit objects.; However, there is currently a strict separation between ""Data-like"" objects (which can only really be drawn with points) and ""Function-like"" objects (which can only really be drawn as lines and areas).; However, in techniques like unfolding, ""data"" is often times corrected data, and hence might actually be a function-type object in RooFit.; With this PR, functionality is added to RooAbsReal::plotOn that allows to plot functions ""data-like"", with data points including error bars when using the draw option ""P"", which was previously unusable.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4507
https://github.com/root-project/root/pull/4509:30,Deployability,update,updated,30,The RooBernstein pdf is to be updated to have the correct definition over ranges of the variable.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4509
https://github.com/root-project/root/pull/4509:88,Modifiability,variab,variable,88,The RooBernstein pdf is to be updated to have the correct definition over ranges of the variable.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4509
https://github.com/root-project/root/pull/4511:110,Performance,perform,performs,110,"Introduce *Auto* property for RColor; Before drawing RCanvas, one could call `canvas->AssignAutoColors();` to performs color assignment; Later method can be invoked automatically",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4511
https://github.com/root-project/root/pull/4512:4,Availability,error,error,4,Fix error: . `/usr/local/include/module.modulemap:14:8: error: redefinition of module ROOT_Config. module ROOT_Config [system] {`,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4512
https://github.com/root-project/root/pull/4512:56,Availability,error,error,56,Fix error: . `/usr/local/include/module.modulemap:14:8: error: redefinition of module ROOT_Config. module ROOT_Config [system] {`,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4512
https://github.com/root-project/root/pull/4513:10,Safety,avoid,avoid,10,Allows to avoid several problems when browser app already running.; Used for chrome and firefox browsers,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4513
https://github.com/root-project/root/pull/4514:103,Availability,error,error,103,"When compiled in debug mode, RooFit was outlining a normally inlined; function, which created a linker error in a specific setup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4514
https://github.com/root-project/root/pull/4516:261,Deployability,patch,patch,261,The system integrity protection (SIP) on osx blocks 'dangerous' env variables when spawning a new process. The MetaProcessor command `.!` which calls the shell does not propagate (DY)LD_LIBRARY_PATH variables which prevents cling from finding the modules. This patch introduces a new env variable CLING_PREBUILT_MODULE_PATH which contains the prebuilt modules' location where cling should look for modules. Patch by Alexander Penev (@alexander-penev)!,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4516
https://github.com/root-project/root/pull/4516:407,Deployability,Patch,Patch,407,The system integrity protection (SIP) on osx blocks 'dangerous' env variables when spawning a new process. The MetaProcessor command `.!` which calls the shell does not propagate (DY)LD_LIBRARY_PATH variables which prevents cling from finding the modules. This patch introduces a new env variable CLING_PREBUILT_MODULE_PATH which contains the prebuilt modules' location where cling should look for modules. Patch by Alexander Penev (@alexander-penev)!,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4516
https://github.com/root-project/root/pull/4516:68,Modifiability,variab,variables,68,The system integrity protection (SIP) on osx blocks 'dangerous' env variables when spawning a new process. The MetaProcessor command `.!` which calls the shell does not propagate (DY)LD_LIBRARY_PATH variables which prevents cling from finding the modules. This patch introduces a new env variable CLING_PREBUILT_MODULE_PATH which contains the prebuilt modules' location where cling should look for modules. Patch by Alexander Penev (@alexander-penev)!,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4516
https://github.com/root-project/root/pull/4516:199,Modifiability,variab,variables,199,The system integrity protection (SIP) on osx blocks 'dangerous' env variables when spawning a new process. The MetaProcessor command `.!` which calls the shell does not propagate (DY)LD_LIBRARY_PATH variables which prevents cling from finding the modules. This patch introduces a new env variable CLING_PREBUILT_MODULE_PATH which contains the prebuilt modules' location where cling should look for modules. Patch by Alexander Penev (@alexander-penev)!,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4516
https://github.com/root-project/root/pull/4516:288,Modifiability,variab,variable,288,The system integrity protection (SIP) on osx blocks 'dangerous' env variables when spawning a new process. The MetaProcessor command `.!` which calls the shell does not propagate (DY)LD_LIBRARY_PATH variables which prevents cling from finding the modules. This patch introduces a new env variable CLING_PREBUILT_MODULE_PATH which contains the prebuilt modules' location where cling should look for modules. Patch by Alexander Penev (@alexander-penev)!,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4516
https://github.com/root-project/root/pull/4516:11,Security,integrity,integrity,11,The system integrity protection (SIP) on osx blocks 'dangerous' env variables when spawning a new process. The MetaProcessor command `.!` which calls the shell does not propagate (DY)LD_LIBRARY_PATH variables which prevents cling from finding the modules. This patch introduces a new env variable CLING_PREBUILT_MODULE_PATH which contains the prebuilt modules' location where cling should look for modules. Patch by Alexander Penev (@alexander-penev)!,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4516
https://github.com/root-project/root/pull/4517:38,Performance,load,load,38,"As it is now, cling is not capable to load library for outlined; functions. As long as modules not enabled by default - add; R__LOAD_LIBRARY macro to all test scripts",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4517
https://github.com/root-project/root/pull/4517:154,Testability,test,test,154,"As it is now, cling is not capable to load library for outlined; functions. As long as modules not enabled by default - add; R__LOAD_LIBRARY macro to all test scripts",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4517
https://github.com/root-project/root/pull/4519:83,Deployability,install,installed,83,This enables ROOT to run without requiring to source thisroot.sh and also run from installed public locations (via gnuinstall). Patch by Oksana Shadura and me!,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4519
https://github.com/root-project/root/pull/4519:128,Deployability,Patch,Patch,128,This enables ROOT to run without requiring to source thisroot.sh and also run from installed public locations (via gnuinstall). Patch by Oksana Shadura and me!,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4519
https://github.com/root-project/root/pull/4520:0,Availability,error,error,0,"error: std::map<std::basic_string<char>, double, std::less<std::basic_string<char> >, std::allocator<std::pair<const std::basic_string<char>, double> > >' has different definitions in different modules; first difference is defined here found end of class\n/usr/lib/gcc/aarch64-redhat-linux/4.8.5/../../../../include/c++/4.8.5/bits/stl_map.h:941:9: note: but in 'std.bits/stl_map.h' found friend declaration\n operator==(const map<_K1, _T1, _C1, _A1>&,\n ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nroot.exe: ../../../../../../../../root/interpreter/cling/lib/Interpreter/Transaction.cpp:138: void cling::Transaction::append(cling::Transaction::DelayCallInfo): Assertion getState() == kCollecting && Cannot append declarations in current state.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4520
https://github.com/root-project/root/pull/4520:660,Testability,Assert,Assertion,660,"error: std::map<std::basic_string<char>, double, std::less<std::basic_string<char> >, std::allocator<std::pair<const std::basic_string<char>, double> > >' has different definitions in different modules; first difference is defined here found end of class\n/usr/lib/gcc/aarch64-redhat-linux/4.8.5/../../../../include/c++/4.8.5/bits/stl_map.h:941:9: note: but in 'std.bits/stl_map.h' found friend declaration\n operator==(const map<_K1, _T1, _C1, _A1>&,\n ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nroot.exe: ../../../../../../../../root/interpreter/cling/lib/Interpreter/Transaction.cpp:138: void cling::Transaction::append(cling::Transaction::DelayCallInfo): Assertion getState() == kCollecting && Cannot append declarations in current state.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4520
https://github.com/root-project/root/pull/4521:628,Availability,error,error,628,"New PR after rebasing the branch. @cburgard's description of the changes:; The RooFit ""plotOn"" plotting engine is very useful to visualize RooFit objects.; However, there is currently a strict separation between ""Data-like"" objects (which can only really be drawn with points) and ""Function-like"" objects (which can only really be drawn as lines and areas).; However, in techniques like unfolding, ""data"" is often times corrected data, and hence might actually be a function-type object in RooFit.; With this PR, functionality is added to RooAbsReal::plotOn that allows to plot functions ""data-like"", with data points including error bars when using the draw option ""P"", which was previously unusable.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4521
https://github.com/root-project/root/pull/4522:12,Testability,test,test,12,Re-add tmva test directories were removed by mistake in a previous commit,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4522
https://github.com/root-project/root/pull/4523:95,Security,Access,Access,95,"Now for each attribute three methods should be used:; 1. const Getter; 2. non-const Setter; 3. Access by reference. ```; const RAttrText &GetAttrText() const { return fAttrText; }; CustomAttrs &SetAttrText(const RAttrText &txt) { fAttrText = txt; return *this; }; RAttrText &AttrText() { return fAttrText; }; ```. Such set of methods allow to clearly separate const and non-const; access. And when setter is used, chain of methods can be called. Add several new tests.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4523
https://github.com/root-project/root/pull/4523:381,Security,access,access,381,"Now for each attribute three methods should be used:; 1. const Getter; 2. non-const Setter; 3. Access by reference. ```; const RAttrText &GetAttrText() const { return fAttrText; }; CustomAttrs &SetAttrText(const RAttrText &txt) { fAttrText = txt; return *this; }; RAttrText &AttrText() { return fAttrText; }; ```. Such set of methods allow to clearly separate const and non-const; access. And when setter is used, chain of methods can be called. Add several new tests.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4523
https://github.com/root-project/root/pull/4523:462,Testability,test,tests,462,"Now for each attribute three methods should be used:; 1. const Getter; 2. non-const Setter; 3. Access by reference. ```; const RAttrText &GetAttrText() const { return fAttrText; }; CustomAttrs &SetAttrText(const RAttrText &txt) { fAttrText = txt; return *this; }; RAttrText &AttrText() { return fAttrText; }; ```. Such set of methods allow to clearly separate const and non-const; access. And when setter is used, chain of methods can be called. Add several new tests.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4523
https://github.com/root-project/root/pull/4523:343,Usability,clear,clearly,343,"Now for each attribute three methods should be used:; 1. const Getter; 2. non-const Setter; 3. Access by reference. ```; const RAttrText &GetAttrText() const { return fAttrText; }; CustomAttrs &SetAttrText(const RAttrText &txt) { fAttrText = txt; return *this; }; RAttrText &AttrText() { return fAttrText; }; ```. Such set of methods allow to clearly separate const and non-const; access. And when setter is used, chain of methods can be called. Add several new tests.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4523
https://github.com/root-project/root/pull/4524:4,Usability,clear,clear,4,Use clear =delete statements in TObjectSpy and TBufer3D classes declarations,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4524
https://github.com/root-project/root/pull/4525:32,Availability,down,down,32,Significantly speed up the tear down of hadd and its reduce memory use,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4525
https://github.com/root-project/root/pull/4525:53,Energy Efficiency,reduce,reduce,53,Significantly speed up the tear down of hadd and its reduce memory use,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4525
https://github.com/root-project/root/pull/4531:201,Performance,perform,performance,201,"This PR add a new architecture for TMVA GPU based on using the cuDNN library from NVIDIA. ; This includes the work of Joana Niermann, OpenLab summer stuident 2019. ; This accelerates significantly the performance in convolutional neural networks. ; See the figure below; [cudnnPerformanceNew.pdf](https://github.com/root-project/root/files/3716742/cudnnPerformanceNew.pdf). This PR introduces two new classes TCpuTensor whic his an extension of RTensor for using tensor operations in the CPU architecture (thanks to the work of Sitong An) and TCudaTensor for GPU operations with or without CuDNN.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4531
https://github.com/root-project/root/pull/4533:672,Availability,error,error,672,"Closed the previously opened MR as I had messed up something with the branch. @cburgard's description of the changes:; The RooFit ""plotOn"" plotting engine is very useful to visualize RooFit objects.; However, there is currently a strict separation between ""Data-like"" objects (which can only really be drawn with points) and ""Function-like"" objects (which can only really be drawn as lines and areas).; However, in techniques like unfolding, ""data"" is often times corrected data, and hence might actually be a function-type object in RooFit.; With this PR, functionality is added to RooAbsReal::plotOn that allows to plot functions ""data-like"", with data points including error bars when using the draw option ""P"", which was previously unusable.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4533
https://github.com/root-project/root/pull/4536:128,Deployability,integrat,integrator,128,"Move the fRoofit classes depending on GSL in a new library libRooFitMore. The classes are: . - AdaptiveGauss and GausKronrod 1D integrator from Roofitcore; - Legendre, non-central chi2 and SphArmonic pdf",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4536
https://github.com/root-project/root/pull/4536:95,Energy Efficiency,Adapt,AdaptiveGauss,95,"Move the fRoofit classes depending on GSL in a new library libRooFitMore. The classes are: . - AdaptiveGauss and GausKronrod 1D integrator from Roofitcore; - Legendre, non-central chi2 and SphArmonic pdf",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4536
https://github.com/root-project/root/pull/4536:25,Integrability,depend,depending,25,"Move the fRoofit classes depending on GSL in a new library libRooFitMore. The classes are: . - AdaptiveGauss and GausKronrod 1D integrator from Roofitcore; - Legendre, non-central chi2 and SphArmonic pdf",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4536
https://github.com/root-project/root/pull/4536:128,Integrability,integrat,integrator,128,"Move the fRoofit classes depending on GSL in a new library libRooFitMore. The classes are: . - AdaptiveGauss and GausKronrod 1D integrator from Roofitcore; - Legendre, non-central chi2 and SphArmonic pdf",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4536
https://github.com/root-project/root/pull/4536:95,Modifiability,Adapt,AdaptiveGauss,95,"Move the fRoofit classes depending on GSL in a new library libRooFitMore. The classes are: . - AdaptiveGauss and GausKronrod 1D integrator from Roofitcore; - Legendre, non-central chi2 and SphArmonic pdf",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4536
https://github.com/root-project/root/pull/4537:621,Deployability,patch,patch,621,"When calling rootcling we expect a set of header files and a selection file. In some cases it is more convenient to include all of them in a single header and give it to rootcling. In cases where the header files are so many and exceed the maximum characters allowed by the console the umbrella header is the only way to work it around. In cases where the umbrella header is temporary (such as in cmssw) we cannot add it as a part of the module, however, we have added its direct includes in the module definition. Then rootcling should not complain if the umbrella header file is not part of the module definition. This patch should fix the issues in cmssw when building a dictionary for DataFormats/StdDictionaries.; cc: @smuzaffar, @oshadura, @davidlange6",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4537
https://github.com/root-project/root/pull/4539:199,Availability,failure,failures,199,…ionData. git-svn-id: https://llvm.org/svn/llvm-project/cfe/trunk@313943 91177308-0d34-0410-b5e6-96231b3b80d8. This prints the definition data of the CXXRecordDecls making it easier to debug merging failures.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4539
https://github.com/root-project/root/pull/4540:917,Deployability,patch,patch,917,"C++ modules have two concepts -- a modulemap and a module file. The modulemap gives the mapping between a set of header files present in the module file. Clang has two ways to discover these artifacts -- modulemaps must be either explicitly specified or they have to be on the include paths (-I). Module files must be in the module cache path or the prebuilt module path. ROOT enforces the module files to be next to the library files. In some cases it the LD_LIBRARY_PATH is considered to extend the set of discoverables ROOT libraries. Over the years we have considered the LD_LIBRARY_PATH as the prebuilt module file locations. Relying on it leads to a number of issues. First, the osx system integrity protection filters its contents. Second, the LCG distribution mechanism can set the LD_LIBRARY_PATH to point to a complementary location of ROOT. In this case we will start loading irrelevant module files. This patch disables the LD_LIBRARY_PATH module discovery and relies on ROOT to provide its set of locations where modules should be present. Nowadays the current state of the implementation allows us to enforce this finer granularity.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4540
https://github.com/root-project/root/pull/4540:490,Modifiability,extend,extend,490,"C++ modules have two concepts -- a modulemap and a module file. The modulemap gives the mapping between a set of header files present in the module file. Clang has two ways to discover these artifacts -- modulemaps must be either explicitly specified or they have to be on the include paths (-I). Module files must be in the module cache path or the prebuilt module path. ROOT enforces the module files to be next to the library files. In some cases it the LD_LIBRARY_PATH is considered to extend the set of discoverables ROOT libraries. Over the years we have considered the LD_LIBRARY_PATH as the prebuilt module file locations. Relying on it leads to a number of issues. First, the osx system integrity protection filters its contents. Second, the LCG distribution mechanism can set the LD_LIBRARY_PATH to point to a complementary location of ROOT. In this case we will start loading irrelevant module files. This patch disables the LD_LIBRARY_PATH module discovery and relies on ROOT to provide its set of locations where modules should be present. Nowadays the current state of the implementation allows us to enforce this finer granularity.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4540
https://github.com/root-project/root/pull/4540:332,Performance,cache,cache,332,"C++ modules have two concepts -- a modulemap and a module file. The modulemap gives the mapping between a set of header files present in the module file. Clang has two ways to discover these artifacts -- modulemaps must be either explicitly specified or they have to be on the include paths (-I). Module files must be in the module cache path or the prebuilt module path. ROOT enforces the module files to be next to the library files. In some cases it the LD_LIBRARY_PATH is considered to extend the set of discoverables ROOT libraries. Over the years we have considered the LD_LIBRARY_PATH as the prebuilt module file locations. Relying on it leads to a number of issues. First, the osx system integrity protection filters its contents. Second, the LCG distribution mechanism can set the LD_LIBRARY_PATH to point to a complementary location of ROOT. In this case we will start loading irrelevant module files. This patch disables the LD_LIBRARY_PATH module discovery and relies on ROOT to provide its set of locations where modules should be present. Nowadays the current state of the implementation allows us to enforce this finer granularity.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4540
https://github.com/root-project/root/pull/4540:879,Performance,load,loading,879,"C++ modules have two concepts -- a modulemap and a module file. The modulemap gives the mapping between a set of header files present in the module file. Clang has two ways to discover these artifacts -- modulemaps must be either explicitly specified or they have to be on the include paths (-I). Module files must be in the module cache path or the prebuilt module path. ROOT enforces the module files to be next to the library files. In some cases it the LD_LIBRARY_PATH is considered to extend the set of discoverables ROOT libraries. Over the years we have considered the LD_LIBRARY_PATH as the prebuilt module file locations. Relying on it leads to a number of issues. First, the osx system integrity protection filters its contents. Second, the LCG distribution mechanism can set the LD_LIBRARY_PATH to point to a complementary location of ROOT. In this case we will start loading irrelevant module files. This patch disables the LD_LIBRARY_PATH module discovery and relies on ROOT to provide its set of locations where modules should be present. Nowadays the current state of the implementation allows us to enforce this finer granularity.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4540
https://github.com/root-project/root/pull/4540:696,Security,integrity,integrity,696,"C++ modules have two concepts -- a modulemap and a module file. The modulemap gives the mapping between a set of header files present in the module file. Clang has two ways to discover these artifacts -- modulemaps must be either explicitly specified or they have to be on the include paths (-I). Module files must be in the module cache path or the prebuilt module path. ROOT enforces the module files to be next to the library files. In some cases it the LD_LIBRARY_PATH is considered to extend the set of discoverables ROOT libraries. Over the years we have considered the LD_LIBRARY_PATH as the prebuilt module file locations. Relying on it leads to a number of issues. First, the osx system integrity protection filters its contents. Second, the LCG distribution mechanism can set the LD_LIBRARY_PATH to point to a complementary location of ROOT. In this case we will start loading irrelevant module files. This patch disables the LD_LIBRARY_PATH module discovery and relies on ROOT to provide its set of locations where modules should be present. Nowadays the current state of the implementation allows us to enforce this finer granularity.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4540
https://github.com/root-project/root/pull/4541:1301,Testability,test,tested,1301,"This PR implements a feature to combine ntuples in 2 different ways, by chaining them (combine ntuples with different clusters) or befriending them (combine ntuples with different fields). Chaining can be done in 2 ways:. 1. Create one RNTupleReader from multiple files. (`auto ntupleReader = RNTupleReader::Open(std::string_view ntupleName, std::vector<std::string> fileNames);`); 2. Combine 2 RNTupleReader into one. This can be done with move-semantics (`auto reader = RNTupleReader::ChainReader(ntupleName, std::move(reader1), std::move(reader2));`) or without (`auto reader = RNTupleReader::ChainReader(ntupleName, reader1, reader2);`). Befriending is done very similarly, but with an extra Enum class parameter:; 1. Create one RNTupleReader from multiple files. (`auto ntupleReader = RNTupleReader::Open(std::string_view ntupleName, std::vector<std::string> fileNames, ROOT::Experimental::EFileOpeningOptions::kFriend);`); 2. Combine 2 RNTupleReader into one. This can be done with move-semantics (`auto reader = RNTupleReader::ChainReader(ntupleName, std::move(reader1), std::move(reader2), ROOT::Experimental::EFileOpeningOptions::kFriend);`) or without (`auto reader = RNTupleReader::ChainReader(ntupleName, reader1, reader2, ROOT::Experimental::EFileOpeningOptions::kFriend);`). It has been tested to work for: ChainOfChainOfChains, FriendsOfFriendsOfFriends, ChainOfFriends and FriendsOfChain. All tests have been done for .root and raw-files.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4541
https://github.com/root-project/root/pull/4541:1409,Testability,test,tests,1409,"This PR implements a feature to combine ntuples in 2 different ways, by chaining them (combine ntuples with different clusters) or befriending them (combine ntuples with different fields). Chaining can be done in 2 ways:. 1. Create one RNTupleReader from multiple files. (`auto ntupleReader = RNTupleReader::Open(std::string_view ntupleName, std::vector<std::string> fileNames);`); 2. Combine 2 RNTupleReader into one. This can be done with move-semantics (`auto reader = RNTupleReader::ChainReader(ntupleName, std::move(reader1), std::move(reader2));`) or without (`auto reader = RNTupleReader::ChainReader(ntupleName, reader1, reader2);`). Befriending is done very similarly, but with an extra Enum class parameter:; 1. Create one RNTupleReader from multiple files. (`auto ntupleReader = RNTupleReader::Open(std::string_view ntupleName, std::vector<std::string> fileNames, ROOT::Experimental::EFileOpeningOptions::kFriend);`); 2. Combine 2 RNTupleReader into one. This can be done with move-semantics (`auto reader = RNTupleReader::ChainReader(ntupleName, std::move(reader1), std::move(reader2), ROOT::Experimental::EFileOpeningOptions::kFriend);`) or without (`auto reader = RNTupleReader::ChainReader(ntupleName, reader1, reader2, ROOT::Experimental::EFileOpeningOptions::kFriend);`). It has been tested to work for: ChainOfChainOfChains, FriendsOfFriendsOfFriends, ChainOfFriends and FriendsOfChain. All tests have been done for .root and raw-files.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4541
https://github.com/root-project/root/pull/4543:68,Safety,Avoid,Avoid,68,Main GUI-related classes should be collected in `core/gui` folder.; Avoid situation like TToggle class situated in `core/meta` subfolder,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4543
https://github.com/root-project/root/pull/4547:905,Deployability,patch,patch,905,"-reflex was deprecated because the flag was parsed but nothing was done after. Rootcling works in two modes. The first mode is when it is called directly. The second mode is when it was called from genreflex. Genreflex is essentially calling rootcling with the appropriate flag translation and it sets the isGenReflex variable to true. The argument translation mechanism of genreflex has a nice feature which can print the underlying rootcling invocation. This is helpful if we want to move away from reflex to rootcling. This might be reasonable to get access to the finer grained arguments and options rootcling provides. However, we should still call rootcling and set the isGenReflex to true as the variable alters the content of the dictionaries. In cmssw C++ modules IB we use rootcling instead of genreflex to have better control on the module generation provided by the rootcling option set. This patch implements a flag which can turn the rootcling invocation completely to genreflex. Using rootcling -reflex should fix the DataFormats/Provenance dictionary generation for cmssw. cc: @oshadura, @smuzaffar, @davidlange6",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4547
https://github.com/root-project/root/pull/4547:318,Modifiability,variab,variable,318,"-reflex was deprecated because the flag was parsed but nothing was done after. Rootcling works in two modes. The first mode is when it is called directly. The second mode is when it was called from genreflex. Genreflex is essentially calling rootcling with the appropriate flag translation and it sets the isGenReflex variable to true. The argument translation mechanism of genreflex has a nice feature which can print the underlying rootcling invocation. This is helpful if we want to move away from reflex to rootcling. This might be reasonable to get access to the finer grained arguments and options rootcling provides. However, we should still call rootcling and set the isGenReflex to true as the variable alters the content of the dictionaries. In cmssw C++ modules IB we use rootcling instead of genreflex to have better control on the module generation provided by the rootcling option set. This patch implements a flag which can turn the rootcling invocation completely to genreflex. Using rootcling -reflex should fix the DataFormats/Provenance dictionary generation for cmssw. cc: @oshadura, @smuzaffar, @davidlange6",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4547
https://github.com/root-project/root/pull/4547:703,Modifiability,variab,variable,703,"-reflex was deprecated because the flag was parsed but nothing was done after. Rootcling works in two modes. The first mode is when it is called directly. The second mode is when it was called from genreflex. Genreflex is essentially calling rootcling with the appropriate flag translation and it sets the isGenReflex variable to true. The argument translation mechanism of genreflex has a nice feature which can print the underlying rootcling invocation. This is helpful if we want to move away from reflex to rootcling. This might be reasonable to get access to the finer grained arguments and options rootcling provides. However, we should still call rootcling and set the isGenReflex to true as the variable alters the content of the dictionaries. In cmssw C++ modules IB we use rootcling instead of genreflex to have better control on the module generation provided by the rootcling option set. This patch implements a flag which can turn the rootcling invocation completely to genreflex. Using rootcling -reflex should fix the DataFormats/Provenance dictionary generation for cmssw. cc: @oshadura, @smuzaffar, @davidlange6",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4547
https://github.com/root-project/root/pull/4547:554,Security,access,access,554,"-reflex was deprecated because the flag was parsed but nothing was done after. Rootcling works in two modes. The first mode is when it is called directly. The second mode is when it was called from genreflex. Genreflex is essentially calling rootcling with the appropriate flag translation and it sets the isGenReflex variable to true. The argument translation mechanism of genreflex has a nice feature which can print the underlying rootcling invocation. This is helpful if we want to move away from reflex to rootcling. This might be reasonable to get access to the finer grained arguments and options rootcling provides. However, we should still call rootcling and set the isGenReflex to true as the variable alters the content of the dictionaries. In cmssw C++ modules IB we use rootcling instead of genreflex to have better control on the module generation provided by the rootcling option set. This patch implements a flag which can turn the rootcling invocation completely to genreflex. Using rootcling -reflex should fix the DataFormats/Provenance dictionary generation for cmssw. cc: @oshadura, @smuzaffar, @davidlange6",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4547
https://github.com/root-project/root/pull/4551:100,Energy Efficiency,allocate,allocated,100,"When wrong-formatted TMessage is received, length of buffer may be 0.; As result, buffer may not be allocated at all.; One should avoid that in such case memory is accessed",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4551
https://github.com/root-project/root/pull/4551:130,Safety,avoid,avoid,130,"When wrong-formatted TMessage is received, length of buffer may be 0.; As result, buffer may not be allocated at all.; One should avoid that in such case memory is accessed",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4551
https://github.com/root-project/root/pull/4551:164,Security,access,accessed,164,"When wrong-formatted TMessage is received, length of buffer may be 0.; As result, buffer may not be allocated at all.; One should avoid that in such case memory is accessed",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4551
https://github.com/root-project/root/pull/4553:217,Availability,error,errors,217,"If we use -fimplicit-module-maps this means that cling will find all files called module.modulemap on the include paths. In certain cases the same modulemap can be present in two locations causing module redefinition errors. This patch teaches cling to work with explicitly specified modulemaps in -fno-implicit-module-maps mode. It moves the generation of the overlay file closer to the CIFactory so that we can reuse the modulemap loading code before the interpreter object was set up. The patch also turns off the implicit module map discovery and explicitly specifies the ROOT-related modulemap files. The modulemap files need to be enumerated in both TCling and rootcling. Rootcling requires -fno-rtti build mode and we cannot use the utilities in TROOT (also because rootcling_stage1 is built before libCore). This requires the extraction of the `GetSysRoot`, `GetIncludeDir` and `GetEtcDir` in the `ROOT::FoundationUtils` which is can be used throughout the entire core component. This fixes ROOT-10354.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4553
https://github.com/root-project/root/pull/4553:230,Deployability,patch,patch,230,"If we use -fimplicit-module-maps this means that cling will find all files called module.modulemap on the include paths. In certain cases the same modulemap can be present in two locations causing module redefinition errors. This patch teaches cling to work with explicitly specified modulemaps in -fno-implicit-module-maps mode. It moves the generation of the overlay file closer to the CIFactory so that we can reuse the modulemap loading code before the interpreter object was set up. The patch also turns off the implicit module map discovery and explicitly specifies the ROOT-related modulemap files. The modulemap files need to be enumerated in both TCling and rootcling. Rootcling requires -fno-rtti build mode and we cannot use the utilities in TROOT (also because rootcling_stage1 is built before libCore). This requires the extraction of the `GetSysRoot`, `GetIncludeDir` and `GetEtcDir` in the `ROOT::FoundationUtils` which is can be used throughout the entire core component. This fixes ROOT-10354.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4553
https://github.com/root-project/root/pull/4553:492,Deployability,patch,patch,492,"If we use -fimplicit-module-maps this means that cling will find all files called module.modulemap on the include paths. In certain cases the same modulemap can be present in two locations causing module redefinition errors. This patch teaches cling to work with explicitly specified modulemaps in -fno-implicit-module-maps mode. It moves the generation of the overlay file closer to the CIFactory so that we can reuse the modulemap loading code before the interpreter object was set up. The patch also turns off the implicit module map discovery and explicitly specifies the ROOT-related modulemap files. The modulemap files need to be enumerated in both TCling and rootcling. Rootcling requires -fno-rtti build mode and we cannot use the utilities in TROOT (also because rootcling_stage1 is built before libCore). This requires the extraction of the `GetSysRoot`, `GetIncludeDir` and `GetEtcDir` in the `ROOT::FoundationUtils` which is can be used throughout the entire core component. This fixes ROOT-10354.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4553
https://github.com/root-project/root/pull/4553:433,Performance,load,loading,433,"If we use -fimplicit-module-maps this means that cling will find all files called module.modulemap on the include paths. In certain cases the same modulemap can be present in two locations causing module redefinition errors. This patch teaches cling to work with explicitly specified modulemaps in -fno-implicit-module-maps mode. It moves the generation of the overlay file closer to the CIFactory so that we can reuse the modulemap loading code before the interpreter object was set up. The patch also turns off the implicit module map discovery and explicitly specifies the ROOT-related modulemap files. The modulemap files need to be enumerated in both TCling and rootcling. Rootcling requires -fno-rtti build mode and we cannot use the utilities in TROOT (also because rootcling_stage1 is built before libCore). This requires the extraction of the `GetSysRoot`, `GetIncludeDir` and `GetEtcDir` in the `ROOT::FoundationUtils` which is can be used throughout the entire core component. This fixes ROOT-10354.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4553
https://github.com/root-project/root/pull/4557:619,Availability,avail,available,619,"Fixes for bug ROOT-1036 (FitResult::Scan); When fitting histograms a shared_pointer of FitData must be passed to the Fitter class, in Fitter::Fit( data,...) functions instead of a row pointer !; This fixes the shared ownership of the fitting data between the Fitter and the FitResult classes and avoid that the data are deleted when exiting TH1::Fit. ; One can then use FitResult::Scan , FitResult::Contour or FitResult::GetConfidenceIntervals.; Before the data were accidentally not deleted, when multi-thread wad not enabled, because in that case a reference for the data was kept in the global TVirtualFitter class, available only in non-mt mode/. This PR also fixes the case of bin integral fit in multithreading. The problem was caused by using the GSL integrator from Mathmore. . testFit has been improved by adding test for FitResult::Scan and tests for multi-threading fitting",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4557
https://github.com/root-project/root/pull/4557:758,Deployability,integrat,integrator,758,"Fixes for bug ROOT-1036 (FitResult::Scan); When fitting histograms a shared_pointer of FitData must be passed to the Fitter class, in Fitter::Fit( data,...) functions instead of a row pointer !; This fixes the shared ownership of the fitting data between the Fitter and the FitResult classes and avoid that the data are deleted when exiting TH1::Fit. ; One can then use FitResult::Scan , FitResult::Contour or FitResult::GetConfidenceIntervals.; Before the data were accidentally not deleted, when multi-thread wad not enabled, because in that case a reference for the data was kept in the global TVirtualFitter class, available only in non-mt mode/. This PR also fixes the case of bin integral fit in multithreading. The problem was caused by using the GSL integrator from Mathmore. . testFit has been improved by adding test for FitResult::Scan and tests for multi-threading fitting",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4557
https://github.com/root-project/root/pull/4557:758,Integrability,integrat,integrator,758,"Fixes for bug ROOT-1036 (FitResult::Scan); When fitting histograms a shared_pointer of FitData must be passed to the Fitter class, in Fitter::Fit( data,...) functions instead of a row pointer !; This fixes the shared ownership of the fitting data between the Fitter and the FitResult classes and avoid that the data are deleted when exiting TH1::Fit. ; One can then use FitResult::Scan , FitResult::Contour or FitResult::GetConfidenceIntervals.; Before the data were accidentally not deleted, when multi-thread wad not enabled, because in that case a reference for the data was kept in the global TVirtualFitter class, available only in non-mt mode/. This PR also fixes the case of bin integral fit in multithreading. The problem was caused by using the GSL integrator from Mathmore. . testFit has been improved by adding test for FitResult::Scan and tests for multi-threading fitting",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4557
https://github.com/root-project/root/pull/4557:498,Performance,multi-thread,multi-thread,498,"Fixes for bug ROOT-1036 (FitResult::Scan); When fitting histograms a shared_pointer of FitData must be passed to the Fitter class, in Fitter::Fit( data,...) functions instead of a row pointer !; This fixes the shared ownership of the fitting data between the Fitter and the FitResult classes and avoid that the data are deleted when exiting TH1::Fit. ; One can then use FitResult::Scan , FitResult::Contour or FitResult::GetConfidenceIntervals.; Before the data were accidentally not deleted, when multi-thread wad not enabled, because in that case a reference for the data was kept in the global TVirtualFitter class, available only in non-mt mode/. This PR also fixes the case of bin integral fit in multithreading. The problem was caused by using the GSL integrator from Mathmore. . testFit has been improved by adding test for FitResult::Scan and tests for multi-threading fitting",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4557
https://github.com/root-project/root/pull/4557:861,Performance,multi-thread,multi-threading,861,"Fixes for bug ROOT-1036 (FitResult::Scan); When fitting histograms a shared_pointer of FitData must be passed to the Fitter class, in Fitter::Fit( data,...) functions instead of a row pointer !; This fixes the shared ownership of the fitting data between the Fitter and the FitResult classes and avoid that the data are deleted when exiting TH1::Fit. ; One can then use FitResult::Scan , FitResult::Contour or FitResult::GetConfidenceIntervals.; Before the data were accidentally not deleted, when multi-thread wad not enabled, because in that case a reference for the data was kept in the global TVirtualFitter class, available only in non-mt mode/. This PR also fixes the case of bin integral fit in multithreading. The problem was caused by using the GSL integrator from Mathmore. . testFit has been improved by adding test for FitResult::Scan and tests for multi-threading fitting",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4557
https://github.com/root-project/root/pull/4557:296,Safety,avoid,avoid,296,"Fixes for bug ROOT-1036 (FitResult::Scan); When fitting histograms a shared_pointer of FitData must be passed to the Fitter class, in Fitter::Fit( data,...) functions instead of a row pointer !; This fixes the shared ownership of the fitting data between the Fitter and the FitResult classes and avoid that the data are deleted when exiting TH1::Fit. ; One can then use FitResult::Scan , FitResult::Contour or FitResult::GetConfidenceIntervals.; Before the data were accidentally not deleted, when multi-thread wad not enabled, because in that case a reference for the data was kept in the global TVirtualFitter class, available only in non-mt mode/. This PR also fixes the case of bin integral fit in multithreading. The problem was caused by using the GSL integrator from Mathmore. . testFit has been improved by adding test for FitResult::Scan and tests for multi-threading fitting",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4557
https://github.com/root-project/root/pull/4557:786,Testability,test,testFit,786,"Fixes for bug ROOT-1036 (FitResult::Scan); When fitting histograms a shared_pointer of FitData must be passed to the Fitter class, in Fitter::Fit( data,...) functions instead of a row pointer !; This fixes the shared ownership of the fitting data between the Fitter and the FitResult classes and avoid that the data are deleted when exiting TH1::Fit. ; One can then use FitResult::Scan , FitResult::Contour or FitResult::GetConfidenceIntervals.; Before the data were accidentally not deleted, when multi-thread wad not enabled, because in that case a reference for the data was kept in the global TVirtualFitter class, available only in non-mt mode/. This PR also fixes the case of bin integral fit in multithreading. The problem was caused by using the GSL integrator from Mathmore. . testFit has been improved by adding test for FitResult::Scan and tests for multi-threading fitting",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4557
https://github.com/root-project/root/pull/4557:822,Testability,test,test,822,"Fixes for bug ROOT-1036 (FitResult::Scan); When fitting histograms a shared_pointer of FitData must be passed to the Fitter class, in Fitter::Fit( data,...) functions instead of a row pointer !; This fixes the shared ownership of the fitting data between the Fitter and the FitResult classes and avoid that the data are deleted when exiting TH1::Fit. ; One can then use FitResult::Scan , FitResult::Contour or FitResult::GetConfidenceIntervals.; Before the data were accidentally not deleted, when multi-thread wad not enabled, because in that case a reference for the data was kept in the global TVirtualFitter class, available only in non-mt mode/. This PR also fixes the case of bin integral fit in multithreading. The problem was caused by using the GSL integrator from Mathmore. . testFit has been improved by adding test for FitResult::Scan and tests for multi-threading fitting",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4557
https://github.com/root-project/root/pull/4557:851,Testability,test,tests,851,"Fixes for bug ROOT-1036 (FitResult::Scan); When fitting histograms a shared_pointer of FitData must be passed to the Fitter class, in Fitter::Fit( data,...) functions instead of a row pointer !; This fixes the shared ownership of the fitting data between the Fitter and the FitResult classes and avoid that the data are deleted when exiting TH1::Fit. ; One can then use FitResult::Scan , FitResult::Contour or FitResult::GetConfidenceIntervals.; Before the data were accidentally not deleted, when multi-thread wad not enabled, because in that case a reference for the data was kept in the global TVirtualFitter class, available only in non-mt mode/. This PR also fixes the case of bin integral fit in multithreading. The problem was caused by using the GSL integrator from Mathmore. . testFit has been improved by adding test for FitResult::Scan and tests for multi-threading fitting",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4557
https://github.com/root-project/root/pull/4561:718,Availability,error,errors,718,"These are fixes that I had to make to build ROOT on my [Raspberry Pi](https://www.raspberrypi.org/products/raspberry-pi-3-model-b-plus/) using [GCC 8](https://gcc.gnu.org/gcc-8/). (I need to build ROOT with a hand-built GCC 8, as I need [C\+\+17](https://en.wikipedia.org/wiki/C%2B%2B17) support in the projects that I want to build on top of ROOT...). The issue at hand is one that is reasonably well documented on various forums. Like:; - https://github.com/opencv/opencv/issues/15278; - https://github.com/aws/aws-sdk-cpp/issues/1199. One has to explicitly link binaries against [libatomic](https://github.com/gcc-mirror/gcc/tree/master/libatomic) under certain conditions... If not, the following kinds of linking errors happen:. ```; [100%] Linking CXX shared library ../../lib/libRIO.so; CMakeFiles/RIO.dir/src/TFilePrefetch.cxx.o: In function `TFilePrefetch::GetBlockFromCache(char const*, int)':; TFilePrefetch.cxx:(.text+0x1424): undefined reference to `__atomic_fetch_add_8'; CMakeFiles/RIO.dir/src/TFile.cxx.o: In function `TFile::ReadBuffer(char*, int) [clone .part.82]':; TFile.cxx:(.text+0x1444): undefined reference to `__atomic_fetch_add_8'; CMakeFiles/RIO.dir/src/TFile.cxx.o: In function `TFile::ReadBuffer(char*, long long, int)':; TFile.cxx:(.text+0x3738): undefined reference to `__atomic_fetch_add_8'; CMakeFiles/RIO.dir/src/TFile.cxx.o: In function `TFile::ReadBuffers(char*, long long*, int*, int)':; TFile.cxx:(.text+0x53a4): undefined reference to `__atomic_fetch_sub_8'; CMakeFiles/RIO.dir/src/TFile.cxx.o: In function `TFile::WriteBuffer(char const*, int)':; TFile.cxx:(.text+0x5ddc): undefined reference to `__atomic_fetch_add_8'; CMakeFiles/RIO.dir/src/TFile.cxx.o: In function `TFile::GetFileBytesRead()':; TFile.cxx:(.text+0xb370): undefined reference to `__atomic_load_8'; CMakeFiles/RIO.dir/src/TFile.cxx.o: In function `TFile::GetFileBytesWritten()':; TFile.cxx:(.text+0xb390): undefined reference to `__atomic_load_8'; CMakeFiles/RIO.dir/src/TFile.cxx.o: In functio",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4561
https://github.com/root-project/root/pull/4561:2579,Availability,error,error,2579,"const*, int)':; TFile.cxx:(.text+0x5ddc): undefined reference to `__atomic_fetch_add_8'; CMakeFiles/RIO.dir/src/TFile.cxx.o: In function `TFile::GetFileBytesRead()':; TFile.cxx:(.text+0xb370): undefined reference to `__atomic_load_8'; CMakeFiles/RIO.dir/src/TFile.cxx.o: In function `TFile::GetFileBytesWritten()':; TFile.cxx:(.text+0xb390): undefined reference to `__atomic_load_8'; CMakeFiles/RIO.dir/src/TFile.cxx.o: In function `TFile::SetFileBytesRead(long long)':; TFile.cxx:(.text+0xb430): undefined reference to `__atomic_store_8'; CMakeFiles/RIO.dir/src/TFile.cxx.o: In function `TFile::SetFileBytesWritten(long long)':; TFile.cxx:(.text+0xb470): undefined reference to `__atomic_store_8'; CMakeFiles/RIO.dir/src/TFile.cxx.o: In function `TFile::GetFileCounter()':; TFile.cxx:(.text+0xb4c0): undefined reference to `__atomic_load_8'; CMakeFiles/RIO.dir/src/TFile.cxx.o: In function `TFile::IncrementFileCounter()':; TFile.cxx:(.text+0xb4f4): undefined reference to `__atomic_fetch_add_8'; collect2: error: ld returned 1 exit status; io/io/CMakeFiles/RIO.dir/build.make:599: recipe for target 'lib/libRIO.so' failed; make[3]: *** [lib/libRIO.so] Error 1; CMakeFiles/Makefile2:21040: recipe for target 'io/io/CMakeFiles/RIO.dir/all' failed; make[2]: *** [io/io/CMakeFiles/RIO.dir/all] Error 2; CMakeFiles/Makefile2:21052: recipe for target 'io/io/CMakeFiles/RIO.dir/rule' failed; make[1]: *** [io/io/CMakeFiles/RIO.dir/rule] Error 2; Makefile:5971: recipe for target 'RIO' failed; make: *** [RIO] Error 2; ```. Note that I had to add `${ROOT_ATOMIC_LIBS}` in a few more places than I would've liked. Ideally the linking against `libatomic` should've trickled down to almost all ROOT libraries from `libRIO`. I'm not sure why it didn't. :confused:. I was also wondering about possibly adding a platform / CPU check to the code, but in the end this seemed the safest. That if `libatomic` is available for the build, then the code would explicitly use it independent of what platform it is being ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4561
https://github.com/root-project/root/pull/4561:2725,Availability,Error,Error,2725,"r/src/TFile.cxx.o: In function `TFile::GetFileBytesRead()':; TFile.cxx:(.text+0xb370): undefined reference to `__atomic_load_8'; CMakeFiles/RIO.dir/src/TFile.cxx.o: In function `TFile::GetFileBytesWritten()':; TFile.cxx:(.text+0xb390): undefined reference to `__atomic_load_8'; CMakeFiles/RIO.dir/src/TFile.cxx.o: In function `TFile::SetFileBytesRead(long long)':; TFile.cxx:(.text+0xb430): undefined reference to `__atomic_store_8'; CMakeFiles/RIO.dir/src/TFile.cxx.o: In function `TFile::SetFileBytesWritten(long long)':; TFile.cxx:(.text+0xb470): undefined reference to `__atomic_store_8'; CMakeFiles/RIO.dir/src/TFile.cxx.o: In function `TFile::GetFileCounter()':; TFile.cxx:(.text+0xb4c0): undefined reference to `__atomic_load_8'; CMakeFiles/RIO.dir/src/TFile.cxx.o: In function `TFile::IncrementFileCounter()':; TFile.cxx:(.text+0xb4f4): undefined reference to `__atomic_fetch_add_8'; collect2: error: ld returned 1 exit status; io/io/CMakeFiles/RIO.dir/build.make:599: recipe for target 'lib/libRIO.so' failed; make[3]: *** [lib/libRIO.so] Error 1; CMakeFiles/Makefile2:21040: recipe for target 'io/io/CMakeFiles/RIO.dir/all' failed; make[2]: *** [io/io/CMakeFiles/RIO.dir/all] Error 2; CMakeFiles/Makefile2:21052: recipe for target 'io/io/CMakeFiles/RIO.dir/rule' failed; make[1]: *** [io/io/CMakeFiles/RIO.dir/rule] Error 2; Makefile:5971: recipe for target 'RIO' failed; make: *** [RIO] Error 2; ```. Note that I had to add `${ROOT_ATOMIC_LIBS}` in a few more places than I would've liked. Ideally the linking against `libatomic` should've trickled down to almost all ROOT libraries from `libRIO`. I'm not sure why it didn't. :confused:. I was also wondering about possibly adding a platform / CPU check to the code, but in the end this seemed the safest. That if `libatomic` is available for the build, then the code would explicitly use it independent of what platform it is being built on. Though of course I have not tried the build of this branch of mine on every possible platform...",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4561
https://github.com/root-project/root/pull/4561:2863,Availability,Error,Error,2863,"r/src/TFile.cxx.o: In function `TFile::GetFileBytesRead()':; TFile.cxx:(.text+0xb370): undefined reference to `__atomic_load_8'; CMakeFiles/RIO.dir/src/TFile.cxx.o: In function `TFile::GetFileBytesWritten()':; TFile.cxx:(.text+0xb390): undefined reference to `__atomic_load_8'; CMakeFiles/RIO.dir/src/TFile.cxx.o: In function `TFile::SetFileBytesRead(long long)':; TFile.cxx:(.text+0xb430): undefined reference to `__atomic_store_8'; CMakeFiles/RIO.dir/src/TFile.cxx.o: In function `TFile::SetFileBytesWritten(long long)':; TFile.cxx:(.text+0xb470): undefined reference to `__atomic_store_8'; CMakeFiles/RIO.dir/src/TFile.cxx.o: In function `TFile::GetFileCounter()':; TFile.cxx:(.text+0xb4c0): undefined reference to `__atomic_load_8'; CMakeFiles/RIO.dir/src/TFile.cxx.o: In function `TFile::IncrementFileCounter()':; TFile.cxx:(.text+0xb4f4): undefined reference to `__atomic_fetch_add_8'; collect2: error: ld returned 1 exit status; io/io/CMakeFiles/RIO.dir/build.make:599: recipe for target 'lib/libRIO.so' failed; make[3]: *** [lib/libRIO.so] Error 1; CMakeFiles/Makefile2:21040: recipe for target 'io/io/CMakeFiles/RIO.dir/all' failed; make[2]: *** [io/io/CMakeFiles/RIO.dir/all] Error 2; CMakeFiles/Makefile2:21052: recipe for target 'io/io/CMakeFiles/RIO.dir/rule' failed; make[1]: *** [io/io/CMakeFiles/RIO.dir/rule] Error 2; Makefile:5971: recipe for target 'RIO' failed; make: *** [RIO] Error 2; ```. Note that I had to add `${ROOT_ATOMIC_LIBS}` in a few more places than I would've liked. Ideally the linking against `libatomic` should've trickled down to almost all ROOT libraries from `libRIO`. I'm not sure why it didn't. :confused:. I was also wondering about possibly adding a platform / CPU check to the code, but in the end this seemed the safest. That if `libatomic` is available for the build, then the code would explicitly use it independent of what platform it is being built on. Though of course I have not tried the build of this branch of mine on every possible platform...",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4561
https://github.com/root-project/root/pull/4561:3003,Availability,Error,Error,3003,"r/src/TFile.cxx.o: In function `TFile::GetFileBytesRead()':; TFile.cxx:(.text+0xb370): undefined reference to `__atomic_load_8'; CMakeFiles/RIO.dir/src/TFile.cxx.o: In function `TFile::GetFileBytesWritten()':; TFile.cxx:(.text+0xb390): undefined reference to `__atomic_load_8'; CMakeFiles/RIO.dir/src/TFile.cxx.o: In function `TFile::SetFileBytesRead(long long)':; TFile.cxx:(.text+0xb430): undefined reference to `__atomic_store_8'; CMakeFiles/RIO.dir/src/TFile.cxx.o: In function `TFile::SetFileBytesWritten(long long)':; TFile.cxx:(.text+0xb470): undefined reference to `__atomic_store_8'; CMakeFiles/RIO.dir/src/TFile.cxx.o: In function `TFile::GetFileCounter()':; TFile.cxx:(.text+0xb4c0): undefined reference to `__atomic_load_8'; CMakeFiles/RIO.dir/src/TFile.cxx.o: In function `TFile::IncrementFileCounter()':; TFile.cxx:(.text+0xb4f4): undefined reference to `__atomic_fetch_add_8'; collect2: error: ld returned 1 exit status; io/io/CMakeFiles/RIO.dir/build.make:599: recipe for target 'lib/libRIO.so' failed; make[3]: *** [lib/libRIO.so] Error 1; CMakeFiles/Makefile2:21040: recipe for target 'io/io/CMakeFiles/RIO.dir/all' failed; make[2]: *** [io/io/CMakeFiles/RIO.dir/all] Error 2; CMakeFiles/Makefile2:21052: recipe for target 'io/io/CMakeFiles/RIO.dir/rule' failed; make[1]: *** [io/io/CMakeFiles/RIO.dir/rule] Error 2; Makefile:5971: recipe for target 'RIO' failed; make: *** [RIO] Error 2; ```. Note that I had to add `${ROOT_ATOMIC_LIBS}` in a few more places than I would've liked. Ideally the linking against `libatomic` should've trickled down to almost all ROOT libraries from `libRIO`. I'm not sure why it didn't. :confused:. I was also wondering about possibly adding a platform / CPU check to the code, but in the end this seemed the safest. That if `libatomic` is available for the build, then the code would explicitly use it independent of what platform it is being built on. Though of course I have not tried the build of this branch of mine on every possible platform...",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4561
https://github.com/root-project/root/pull/4561:3075,Availability,Error,Error,3075,"r/src/TFile.cxx.o: In function `TFile::GetFileBytesRead()':; TFile.cxx:(.text+0xb370): undefined reference to `__atomic_load_8'; CMakeFiles/RIO.dir/src/TFile.cxx.o: In function `TFile::GetFileBytesWritten()':; TFile.cxx:(.text+0xb390): undefined reference to `__atomic_load_8'; CMakeFiles/RIO.dir/src/TFile.cxx.o: In function `TFile::SetFileBytesRead(long long)':; TFile.cxx:(.text+0xb430): undefined reference to `__atomic_store_8'; CMakeFiles/RIO.dir/src/TFile.cxx.o: In function `TFile::SetFileBytesWritten(long long)':; TFile.cxx:(.text+0xb470): undefined reference to `__atomic_store_8'; CMakeFiles/RIO.dir/src/TFile.cxx.o: In function `TFile::GetFileCounter()':; TFile.cxx:(.text+0xb4c0): undefined reference to `__atomic_load_8'; CMakeFiles/RIO.dir/src/TFile.cxx.o: In function `TFile::IncrementFileCounter()':; TFile.cxx:(.text+0xb4f4): undefined reference to `__atomic_fetch_add_8'; collect2: error: ld returned 1 exit status; io/io/CMakeFiles/RIO.dir/build.make:599: recipe for target 'lib/libRIO.so' failed; make[3]: *** [lib/libRIO.so] Error 1; CMakeFiles/Makefile2:21040: recipe for target 'io/io/CMakeFiles/RIO.dir/all' failed; make[2]: *** [io/io/CMakeFiles/RIO.dir/all] Error 2; CMakeFiles/Makefile2:21052: recipe for target 'io/io/CMakeFiles/RIO.dir/rule' failed; make[1]: *** [io/io/CMakeFiles/RIO.dir/rule] Error 2; Makefile:5971: recipe for target 'RIO' failed; make: *** [RIO] Error 2; ```. Note that I had to add `${ROOT_ATOMIC_LIBS}` in a few more places than I would've liked. Ideally the linking against `libatomic` should've trickled down to almost all ROOT libraries from `libRIO`. I'm not sure why it didn't. :confused:. I was also wondering about possibly adding a platform / CPU check to the code, but in the end this seemed the safest. That if `libatomic` is available for the build, then the code would explicitly use it independent of what platform it is being built on. Though of course I have not tried the build of this branch of mine on every possible platform...",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4561
https://github.com/root-project/root/pull/4561:3237,Availability,down,down,3237,"r/src/TFile.cxx.o: In function `TFile::GetFileBytesRead()':; TFile.cxx:(.text+0xb370): undefined reference to `__atomic_load_8'; CMakeFiles/RIO.dir/src/TFile.cxx.o: In function `TFile::GetFileBytesWritten()':; TFile.cxx:(.text+0xb390): undefined reference to `__atomic_load_8'; CMakeFiles/RIO.dir/src/TFile.cxx.o: In function `TFile::SetFileBytesRead(long long)':; TFile.cxx:(.text+0xb430): undefined reference to `__atomic_store_8'; CMakeFiles/RIO.dir/src/TFile.cxx.o: In function `TFile::SetFileBytesWritten(long long)':; TFile.cxx:(.text+0xb470): undefined reference to `__atomic_store_8'; CMakeFiles/RIO.dir/src/TFile.cxx.o: In function `TFile::GetFileCounter()':; TFile.cxx:(.text+0xb4c0): undefined reference to `__atomic_load_8'; CMakeFiles/RIO.dir/src/TFile.cxx.o: In function `TFile::IncrementFileCounter()':; TFile.cxx:(.text+0xb4f4): undefined reference to `__atomic_fetch_add_8'; collect2: error: ld returned 1 exit status; io/io/CMakeFiles/RIO.dir/build.make:599: recipe for target 'lib/libRIO.so' failed; make[3]: *** [lib/libRIO.so] Error 1; CMakeFiles/Makefile2:21040: recipe for target 'io/io/CMakeFiles/RIO.dir/all' failed; make[2]: *** [io/io/CMakeFiles/RIO.dir/all] Error 2; CMakeFiles/Makefile2:21052: recipe for target 'io/io/CMakeFiles/RIO.dir/rule' failed; make[1]: *** [io/io/CMakeFiles/RIO.dir/rule] Error 2; Makefile:5971: recipe for target 'RIO' failed; make: *** [RIO] Error 2; ```. Note that I had to add `${ROOT_ATOMIC_LIBS}` in a few more places than I would've liked. Ideally the linking against `libatomic` should've trickled down to almost all ROOT libraries from `libRIO`. I'm not sure why it didn't. :confused:. I was also wondering about possibly adding a platform / CPU check to the code, but in the end this seemed the safest. That if `libatomic` is available for the build, then the code would explicitly use it independent of what platform it is being built on. Though of course I have not tried the build of this branch of mine on every possible platform...",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4561
https://github.com/root-project/root/pull/4561:3467,Availability,avail,available,3467,"r/src/TFile.cxx.o: In function `TFile::GetFileBytesRead()':; TFile.cxx:(.text+0xb370): undefined reference to `__atomic_load_8'; CMakeFiles/RIO.dir/src/TFile.cxx.o: In function `TFile::GetFileBytesWritten()':; TFile.cxx:(.text+0xb390): undefined reference to `__atomic_load_8'; CMakeFiles/RIO.dir/src/TFile.cxx.o: In function `TFile::SetFileBytesRead(long long)':; TFile.cxx:(.text+0xb430): undefined reference to `__atomic_store_8'; CMakeFiles/RIO.dir/src/TFile.cxx.o: In function `TFile::SetFileBytesWritten(long long)':; TFile.cxx:(.text+0xb470): undefined reference to `__atomic_store_8'; CMakeFiles/RIO.dir/src/TFile.cxx.o: In function `TFile::GetFileCounter()':; TFile.cxx:(.text+0xb4c0): undefined reference to `__atomic_load_8'; CMakeFiles/RIO.dir/src/TFile.cxx.o: In function `TFile::IncrementFileCounter()':; TFile.cxx:(.text+0xb4f4): undefined reference to `__atomic_fetch_add_8'; collect2: error: ld returned 1 exit status; io/io/CMakeFiles/RIO.dir/build.make:599: recipe for target 'lib/libRIO.so' failed; make[3]: *** [lib/libRIO.so] Error 1; CMakeFiles/Makefile2:21040: recipe for target 'io/io/CMakeFiles/RIO.dir/all' failed; make[2]: *** [io/io/CMakeFiles/RIO.dir/all] Error 2; CMakeFiles/Makefile2:21052: recipe for target 'io/io/CMakeFiles/RIO.dir/rule' failed; make[1]: *** [io/io/CMakeFiles/RIO.dir/rule] Error 2; Makefile:5971: recipe for target 'RIO' failed; make: *** [RIO] Error 2; ```. Note that I had to add `${ROOT_ATOMIC_LIBS}` in a few more places than I would've liked. Ideally the linking against `libatomic` should've trickled down to almost all ROOT libraries from `libRIO`. I'm not sure why it didn't. :confused:. I was also wondering about possibly adding a platform / CPU check to the code, but in the end this seemed the safest. That if `libatomic` is available for the build, then the code would explicitly use it independent of what platform it is being built on. Though of course I have not tried the build of this branch of mine on every possible platform...",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4561
https://github.com/root-project/root/pull/4561:3436,Safety,safe,safest,3436,"r/src/TFile.cxx.o: In function `TFile::GetFileBytesRead()':; TFile.cxx:(.text+0xb370): undefined reference to `__atomic_load_8'; CMakeFiles/RIO.dir/src/TFile.cxx.o: In function `TFile::GetFileBytesWritten()':; TFile.cxx:(.text+0xb390): undefined reference to `__atomic_load_8'; CMakeFiles/RIO.dir/src/TFile.cxx.o: In function `TFile::SetFileBytesRead(long long)':; TFile.cxx:(.text+0xb430): undefined reference to `__atomic_store_8'; CMakeFiles/RIO.dir/src/TFile.cxx.o: In function `TFile::SetFileBytesWritten(long long)':; TFile.cxx:(.text+0xb470): undefined reference to `__atomic_store_8'; CMakeFiles/RIO.dir/src/TFile.cxx.o: In function `TFile::GetFileCounter()':; TFile.cxx:(.text+0xb4c0): undefined reference to `__atomic_load_8'; CMakeFiles/RIO.dir/src/TFile.cxx.o: In function `TFile::IncrementFileCounter()':; TFile.cxx:(.text+0xb4f4): undefined reference to `__atomic_fetch_add_8'; collect2: error: ld returned 1 exit status; io/io/CMakeFiles/RIO.dir/build.make:599: recipe for target 'lib/libRIO.so' failed; make[3]: *** [lib/libRIO.so] Error 1; CMakeFiles/Makefile2:21040: recipe for target 'io/io/CMakeFiles/RIO.dir/all' failed; make[2]: *** [io/io/CMakeFiles/RIO.dir/all] Error 2; CMakeFiles/Makefile2:21052: recipe for target 'io/io/CMakeFiles/RIO.dir/rule' failed; make[1]: *** [io/io/CMakeFiles/RIO.dir/rule] Error 2; Makefile:5971: recipe for target 'RIO' failed; make: *** [RIO] Error 2; ```. Note that I had to add `${ROOT_ATOMIC_LIBS}` in a few more places than I would've liked. Ideally the linking against `libatomic` should've trickled down to almost all ROOT libraries from `libRIO`. I'm not sure why it didn't. :confused:. I was also wondering about possibly adding a platform / CPU check to the code, but in the end this seemed the safest. That if `libatomic` is available for the build, then the code would explicitly use it independent of what platform it is being built on. Though of course I have not tried the build of this branch of mine on every possible platform...",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4561
https://github.com/root-project/root/pull/4562:5,Deployability,patch,patch,5,This patch tightens the implementation of the collection of modulemap files. It still gathers all 'system' modulemaps necessary for cling to run if -fno-implicit-module-maps is specified. This patch should unbreak our osx builds.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4562
https://github.com/root-project/root/pull/4562:193,Deployability,patch,patch,193,This patch tightens the implementation of the collection of modulemap files. It still gathers all 'system' modulemaps necessary for cling to run if -fno-implicit-module-maps is specified. This patch should unbreak our osx builds.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4562
https://github.com/root-project/root/pull/4563:5,Deployability,patch,patch,5,This patch teaches cling to detect if the essential libraries have modulemaps and if necessary it adds an overlay around libc and std. This tightens the implementation and makes cling standalone easier to run in -fmodules mode.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4563
https://github.com/root-project/root/pull/4563:28,Safety,detect,detect,28,This patch teaches cling to detect if the essential libraries have modulemaps and if necessary it adds an overlay around libc and std. This tightens the implementation and makes cling standalone easier to run in -fmodules mode.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4563
https://github.com/root-project/root/pull/4564:144,Deployability,update,updates,144,LHCb requested adding the Hypatia PDF. A function for fast batch evaluations is missing. Also sneaked in a few small bugfixes and documentation updates.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4564
https://github.com/root-project/root/pull/4568:6,Availability,redundant,redundant,6,Avoid redundant read (both unzipping and unstreaming in case basket are not perfectly aligned and same size),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4568
https://github.com/root-project/root/pull/4568:0,Safety,Avoid,Avoid,0,Avoid redundant read (both unzipping and unstreaming in case basket are not perfectly aligned and same size),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4568
https://github.com/root-project/root/pull/4568:6,Safety,redund,redundant,6,Avoid redundant read (both unzipping and unstreaming in case basket are not perfectly aligned and same size),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4568
https://github.com/root-project/root/pull/4584:14,Modifiability,variab,variable,14,"The enclosing variable is not odr-used as it is a constant expr,; see https://stackoverflow.com/questions/28506342/understanding-the-example-on-lvalue-to-rvalue-conversion",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4584
https://github.com/root-project/root/pull/4589:39,Availability,error,error,39,"This fixes tonights nightlies with the error `Error in <DavixOpen>: can not open file ""https://root.cern/files/tmva101.root"" with davix: Failure (Neon): Server certificate verification failed: issuer is not trusted after 3 attempts (6)`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4589
https://github.com/root-project/root/pull/4589:46,Availability,Error,Error,46,"This fixes tonights nightlies with the error `Error in <DavixOpen>: can not open file ""https://root.cern/files/tmva101.root"" with davix: Failure (Neon): Server certificate verification failed: issuer is not trusted after 3 attempts (6)`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4589
https://github.com/root-project/root/pull/4589:137,Availability,Failure,Failure,137,"This fixes tonights nightlies with the error `Error in <DavixOpen>: can not open file ""https://root.cern/files/tmva101.root"" with davix: Failure (Neon): Server certificate verification failed: issuer is not trusted after 3 attempts (6)`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4589
https://github.com/root-project/root/pull/4589:160,Security,certificate,certificate,160,"This fixes tonights nightlies with the error `Error in <DavixOpen>: can not open file ""https://root.cern/files/tmva101.root"" with davix: Failure (Neon): Server certificate verification failed: issuer is not trusted after 3 attempts (6)`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4589
https://github.com/root-project/root/pull/4590:353,Testability,test,tests,353,The fixes in this PR correspond to the three following cppyy issues:. https://bitbucket.org/wlav/cppyy/issues/145/enum-values-not-defined-as-constants; https://bitbucket.org/wlav/cppyy/issues/136/item-assignment-not-working-in-templated; https://bitbucket.org/wlav/cppyy/issues/168/boundary-check-not-implemented-for-signed. The corresponding tutorials/tests are re-enabled.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4590
https://github.com/root-project/root/pull/4591:204,Availability,avail,available,204,"This commit revert the SplitApp into Splitter, it remove the bug of the TreeTable scrollbar appearing for no reason, and the bug of the breadcrumbs not creating the dropdown menu when not enough space is available.; I believe that this revert is useful if after CHEP users want to to try it, it will be more stable and more enjoyable.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4591
https://github.com/root-project/root/pull/4594:25,Availability,failure,failures,25,This should fix the cuda failures.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4594
https://github.com/root-project/root/pull/4595:57,Availability,failure,failures,57,"Dummy test PR to check if we can reproduce the same test failures in https://github.com/root-project/root/pull/4592 , which seem unrelated to the PR.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4595
https://github.com/root-project/root/pull/4595:6,Testability,test,test,6,"Dummy test PR to check if we can reproduce the same test failures in https://github.com/root-project/root/pull/4592 , which seem unrelated to the PR.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4595
https://github.com/root-project/root/pull/4595:52,Testability,test,test,52,"Dummy test PR to check if we can reproduce the same test failures in https://github.com/root-project/root/pull/4592 , which seem unrelated to the PR.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4595
https://github.com/root-project/root/pull/4607:223,Energy Efficiency,adapt,adapter,223,"It uses RBrowser and RBrowsable functionality to select some files or input new file SaveAs.; Provide sync and async modes. Actual ui5 coding should be implemented by @Falcort . Now RFileDialog starts its own window, later adapter will be provided to use RFileDialog inside other widgets - like RCanvas or RBrowser. Provide simple tutorial macro.; For meaningful async mode I add `RDirectory::Remove(name)` method (@Axel-Naumann)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4607
https://github.com/root-project/root/pull/4607:223,Integrability,adapter,adapter,223,"It uses RBrowser and RBrowsable functionality to select some files or input new file SaveAs.; Provide sync and async modes. Actual ui5 coding should be implemented by @Falcort . Now RFileDialog starts its own window, later adapter will be provided to use RFileDialog inside other widgets - like RCanvas or RBrowser. Provide simple tutorial macro.; For meaningful async mode I add `RDirectory::Remove(name)` method (@Axel-Naumann)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4607
https://github.com/root-project/root/pull/4607:223,Modifiability,adapt,adapter,223,"It uses RBrowser and RBrowsable functionality to select some files or input new file SaveAs.; Provide sync and async modes. Actual ui5 coding should be implemented by @Falcort . Now RFileDialog starts its own window, later adapter will be provided to use RFileDialog inside other widgets - like RCanvas or RBrowser. Provide simple tutorial macro.; For meaningful async mode I add `RDirectory::Remove(name)` method (@Axel-Naumann)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4607
https://github.com/root-project/root/pull/4607:324,Usability,simpl,simple,324,"It uses RBrowser and RBrowsable functionality to select some files or input new file SaveAs.; Provide sync and async modes. Actual ui5 coding should be implemented by @Falcort . Now RFileDialog starts its own window, later adapter will be provided to use RFileDialog inside other widgets - like RCanvas or RBrowser. Provide simple tutorial macro.; For meaningful async mode I add `RDirectory::Remove(name)` method (@Axel-Naumann)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4607
https://github.com/root-project/root/pull/4617:624,Availability,error,error,624,"- Change implementation of next event. Simplify updates. Update summary tree on scene changes. - Optimize streaming. - Detect web-socket close and warn user (red rectangle in topbar). - Standalone THREE renderer:; - ortho camera, compositing, camera reset, key and mouse handling (own copy of OrbitController needed); - picking, highlight and tooltips; - selection and multiple selection. - Don't execute user input from main toolbar while scene changes are processing. - Add virtual function LocalModelChanges to controll model changes in the proxy builder. - Major cleanup of several JS classes. - New class REveEllipsod (error ellipse). - Support changing of outline colors for selection/highlight. - Review / improve REveData classes, esp. for selection and projections. - REveSelection, allow a list of selection upward propagation modes, not just a single one. - Validate expressions for table views, also, check TROOT::ProcessLine staus. - Cleanup some TEve-stlye change propagation / update functions. - Merge REveElement GetMaster() and ForwardSelection() through fSelectionMaster member. - Use REveAuntAsList in REveDataItem to communicate selection between proxy builders and REveDataItem. - Improve selection handling for compounds and multi-Objec3D representations.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4617
https://github.com/root-project/root/pull/4617:48,Deployability,update,updates,48,"- Change implementation of next event. Simplify updates. Update summary tree on scene changes. - Optimize streaming. - Detect web-socket close and warn user (red rectangle in topbar). - Standalone THREE renderer:; - ortho camera, compositing, camera reset, key and mouse handling (own copy of OrbitController needed); - picking, highlight and tooltips; - selection and multiple selection. - Don't execute user input from main toolbar while scene changes are processing. - Add virtual function LocalModelChanges to controll model changes in the proxy builder. - Major cleanup of several JS classes. - New class REveEllipsod (error ellipse). - Support changing of outline colors for selection/highlight. - Review / improve REveData classes, esp. for selection and projections. - REveSelection, allow a list of selection upward propagation modes, not just a single one. - Validate expressions for table views, also, check TROOT::ProcessLine staus. - Cleanup some TEve-stlye change propagation / update functions. - Merge REveElement GetMaster() and ForwardSelection() through fSelectionMaster member. - Use REveAuntAsList in REveDataItem to communicate selection between proxy builders and REveDataItem. - Improve selection handling for compounds and multi-Objec3D representations.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4617
https://github.com/root-project/root/pull/4617:57,Deployability,Update,Update,57,"- Change implementation of next event. Simplify updates. Update summary tree on scene changes. - Optimize streaming. - Detect web-socket close and warn user (red rectangle in topbar). - Standalone THREE renderer:; - ortho camera, compositing, camera reset, key and mouse handling (own copy of OrbitController needed); - picking, highlight and tooltips; - selection and multiple selection. - Don't execute user input from main toolbar while scene changes are processing. - Add virtual function LocalModelChanges to controll model changes in the proxy builder. - Major cleanup of several JS classes. - New class REveEllipsod (error ellipse). - Support changing of outline colors for selection/highlight. - Review / improve REveData classes, esp. for selection and projections. - REveSelection, allow a list of selection upward propagation modes, not just a single one. - Validate expressions for table views, also, check TROOT::ProcessLine staus. - Cleanup some TEve-stlye change propagation / update functions. - Merge REveElement GetMaster() and ForwardSelection() through fSelectionMaster member. - Use REveAuntAsList in REveDataItem to communicate selection between proxy builders and REveDataItem. - Improve selection handling for compounds and multi-Objec3D representations.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4617
https://github.com/root-project/root/pull/4617:992,Deployability,update,update,992,"- Change implementation of next event. Simplify updates. Update summary tree on scene changes. - Optimize streaming. - Detect web-socket close and warn user (red rectangle in topbar). - Standalone THREE renderer:; - ortho camera, compositing, camera reset, key and mouse handling (own copy of OrbitController needed); - picking, highlight and tooltips; - selection and multiple selection. - Don't execute user input from main toolbar while scene changes are processing. - Add virtual function LocalModelChanges to controll model changes in the proxy builder. - Major cleanup of several JS classes. - New class REveEllipsod (error ellipse). - Support changing of outline colors for selection/highlight. - Review / improve REveData classes, esp. for selection and projections. - REveSelection, allow a list of selection upward propagation modes, not just a single one. - Validate expressions for table views, also, check TROOT::ProcessLine staus. - Cleanup some TEve-stlye change propagation / update functions. - Merge REveElement GetMaster() and ForwardSelection() through fSelectionMaster member. - Use REveAuntAsList in REveDataItem to communicate selection between proxy builders and REveDataItem. - Improve selection handling for compounds and multi-Objec3D representations.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4617
https://github.com/root-project/root/pull/4617:97,Performance,Optimiz,Optimize,97,"- Change implementation of next event. Simplify updates. Update summary tree on scene changes. - Optimize streaming. - Detect web-socket close and warn user (red rectangle in topbar). - Standalone THREE renderer:; - ortho camera, compositing, camera reset, key and mouse handling (own copy of OrbitController needed); - picking, highlight and tooltips; - selection and multiple selection. - Don't execute user input from main toolbar while scene changes are processing. - Add virtual function LocalModelChanges to controll model changes in the proxy builder. - Major cleanup of several JS classes. - New class REveEllipsod (error ellipse). - Support changing of outline colors for selection/highlight. - Review / improve REveData classes, esp. for selection and projections. - REveSelection, allow a list of selection upward propagation modes, not just a single one. - Validate expressions for table views, also, check TROOT::ProcessLine staus. - Cleanup some TEve-stlye change propagation / update functions. - Merge REveElement GetMaster() and ForwardSelection() through fSelectionMaster member. - Use REveAuntAsList in REveDataItem to communicate selection between proxy builders and REveDataItem. - Improve selection handling for compounds and multi-Objec3D representations.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4617
https://github.com/root-project/root/pull/4617:119,Safety,Detect,Detect,119,"- Change implementation of next event. Simplify updates. Update summary tree on scene changes. - Optimize streaming. - Detect web-socket close and warn user (red rectangle in topbar). - Standalone THREE renderer:; - ortho camera, compositing, camera reset, key and mouse handling (own copy of OrbitController needed); - picking, highlight and tooltips; - selection and multiple selection. - Don't execute user input from main toolbar while scene changes are processing. - Add virtual function LocalModelChanges to controll model changes in the proxy builder. - Major cleanup of several JS classes. - New class REveEllipsod (error ellipse). - Support changing of outline colors for selection/highlight. - Review / improve REveData classes, esp. for selection and projections. - REveSelection, allow a list of selection upward propagation modes, not just a single one. - Validate expressions for table views, also, check TROOT::ProcessLine staus. - Cleanup some TEve-stlye change propagation / update functions. - Merge REveElement GetMaster() and ForwardSelection() through fSelectionMaster member. - Use REveAuntAsList in REveDataItem to communicate selection between proxy builders and REveDataItem. - Improve selection handling for compounds and multi-Objec3D representations.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4617
https://github.com/root-project/root/pull/4617:869,Security,Validat,Validate,869,"- Change implementation of next event. Simplify updates. Update summary tree on scene changes. - Optimize streaming. - Detect web-socket close and warn user (red rectangle in topbar). - Standalone THREE renderer:; - ortho camera, compositing, camera reset, key and mouse handling (own copy of OrbitController needed); - picking, highlight and tooltips; - selection and multiple selection. - Don't execute user input from main toolbar while scene changes are processing. - Add virtual function LocalModelChanges to controll model changes in the proxy builder. - Major cleanup of several JS classes. - New class REveEllipsod (error ellipse). - Support changing of outline colors for selection/highlight. - Review / improve REveData classes, esp. for selection and projections. - REveSelection, allow a list of selection upward propagation modes, not just a single one. - Validate expressions for table views, also, check TROOT::ProcessLine staus. - Cleanup some TEve-stlye change propagation / update functions. - Merge REveElement GetMaster() and ForwardSelection() through fSelectionMaster member. - Use REveAuntAsList in REveDataItem to communicate selection between proxy builders and REveDataItem. - Improve selection handling for compounds and multi-Objec3D representations.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4617
https://github.com/root-project/root/pull/4617:39,Usability,Simpl,Simplify,39,"- Change implementation of next event. Simplify updates. Update summary tree on scene changes. - Optimize streaming. - Detect web-socket close and warn user (red rectangle in topbar). - Standalone THREE renderer:; - ortho camera, compositing, camera reset, key and mouse handling (own copy of OrbitController needed); - picking, highlight and tooltips; - selection and multiple selection. - Don't execute user input from main toolbar while scene changes are processing. - Add virtual function LocalModelChanges to controll model changes in the proxy builder. - Major cleanup of several JS classes. - New class REveEllipsod (error ellipse). - Support changing of outline colors for selection/highlight. - Review / improve REveData classes, esp. for selection and projections. - REveSelection, allow a list of selection upward propagation modes, not just a single one. - Validate expressions for table views, also, check TROOT::ProcessLine staus. - Cleanup some TEve-stlye change propagation / update functions. - Merge REveElement GetMaster() and ForwardSelection() through fSelectionMaster member. - Use REveAuntAsList in REveDataItem to communicate selection between proxy builders and REveDataItem. - Improve selection handling for compounds and multi-Objec3D representations.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4617
https://github.com/root-project/root/pull/4623:39,Testability,test,tests,39,Discovered when running PyCool/PyCoral tests. The fix is already in master of CPyCppyy (1.9.7).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4623
https://github.com/root-project/root/pull/4628:12,Modifiability,config,configure,12,* Correctly configure layout properties for the TreeTable in RBrowser and RGeometryViewer; * Do not use row._bHasChildren field which is private and may be changed/removed in future ui5 versions,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4628
https://github.com/root-project/root/pull/4630:350,Deployability,configurat,configuration,350,"Now basic openui5 config parameters can be provided via rootrc file:. * WebGui.openui5src: alternative location for openui5 like https://openui5.hana.ondemand.com/; * WebGui.openui5libs: list of pre-loaded ui5 libs like sap.m, sap.ui.layout, sap.ui.unified; * WebGui.openui5theme: openui5 theme like sap_belize (default) or sap_fiori_3. Extend light configuration in webgeom - let configure kind and intensity of the light",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4630
https://github.com/root-project/root/pull/4630:18,Modifiability,config,config,18,"Now basic openui5 config parameters can be provided via rootrc file:. * WebGui.openui5src: alternative location for openui5 like https://openui5.hana.ondemand.com/; * WebGui.openui5libs: list of pre-loaded ui5 libs like sap.m, sap.ui.layout, sap.ui.unified; * WebGui.openui5theme: openui5 theme like sap_belize (default) or sap_fiori_3. Extend light configuration in webgeom - let configure kind and intensity of the light",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4630
https://github.com/root-project/root/pull/4630:337,Modifiability,Extend,Extend,337,"Now basic openui5 config parameters can be provided via rootrc file:. * WebGui.openui5src: alternative location for openui5 like https://openui5.hana.ondemand.com/; * WebGui.openui5libs: list of pre-loaded ui5 libs like sap.m, sap.ui.layout, sap.ui.unified; * WebGui.openui5theme: openui5 theme like sap_belize (default) or sap_fiori_3. Extend light configuration in webgeom - let configure kind and intensity of the light",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4630
https://github.com/root-project/root/pull/4630:350,Modifiability,config,configuration,350,"Now basic openui5 config parameters can be provided via rootrc file:. * WebGui.openui5src: alternative location for openui5 like https://openui5.hana.ondemand.com/; * WebGui.openui5libs: list of pre-loaded ui5 libs like sap.m, sap.ui.layout, sap.ui.unified; * WebGui.openui5theme: openui5 theme like sap_belize (default) or sap_fiori_3. Extend light configuration in webgeom - let configure kind and intensity of the light",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4630
https://github.com/root-project/root/pull/4630:381,Modifiability,config,configure,381,"Now basic openui5 config parameters can be provided via rootrc file:. * WebGui.openui5src: alternative location for openui5 like https://openui5.hana.ondemand.com/; * WebGui.openui5libs: list of pre-loaded ui5 libs like sap.m, sap.ui.layout, sap.ui.unified; * WebGui.openui5theme: openui5 theme like sap_belize (default) or sap_fiori_3. Extend light configuration in webgeom - let configure kind and intensity of the light",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4630
https://github.com/root-project/root/pull/4630:199,Performance,load,loaded,199,"Now basic openui5 config parameters can be provided via rootrc file:. * WebGui.openui5src: alternative location for openui5 like https://openui5.hana.ondemand.com/; * WebGui.openui5libs: list of pre-loaded ui5 libs like sap.m, sap.ui.layout, sap.ui.unified; * WebGui.openui5theme: openui5 theme like sap_belize (default) or sap_fiori_3. Extend light configuration in webgeom - let configure kind and intensity of the light",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4630
https://github.com/root-project/root/pull/4632:7,Availability,toler,tolerance,7,Uses a tolerance based on the bin width when comparing histogram axes . This fixes ROOT-10363,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4632
https://github.com/root-project/root/pull/4634:176,Integrability,depend,dependencies,176,"This new feature allows to display the storage layout of an RNTuple and to click on its pages to display information about a page. It creates a new ntupledraw library to limit dependencies.; Syntax is similar to RNTupleReader and RNTupleWriter:; `auto reader = RNTupleReader::Open(""ntupleName"", ""fileName"");`; `auto draw = RNTupleDraw::Open(reader);`; `draw->Draw();`; or; `auto draw = RNTupleDraw(reader);`; `draw.Draw();`. An example of a displayed RNTuple is shown below, zooming into the pages is possible:; <img width=""1440"" alt=""Screenshot 2019-11-21 at 12 18 57"" src=""https://user-images.githubusercontent.com/45257539/69346926-e884a180-0c73-11ea-939a-166e36552d83.png"">",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4634
https://github.com/root-project/root/pull/4638:220,Security,Access,Access,220,One can construct relatively complex structures of elements for using them in RBrowser; Like adding different items to top-level - home directory or top file directory. Provide support of ROOT collections and TFolder. ; Access top ROOT folder (and all sub-folders); Access already opened files. Now data structures approximately that I want to see in RBrowser!,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4638
https://github.com/root-project/root/pull/4638:266,Security,Access,Access,266,One can construct relatively complex structures of elements for using them in RBrowser; Like adding different items to top-level - home directory or top file directory. Provide support of ROOT collections and TFolder. ; Access top ROOT folder (and all sub-folders); Access already opened files. Now data structures approximately that I want to see in RBrowser!,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4638
https://github.com/root-project/root/pull/4640:380,Availability,avail,available,380,…nties in weighted unbinned maximum likelihood fits (for details and a comparison of different approaches see https://arxiv.org/abs/1911.01303). This method can be used when specifying Asymptotic(true) and SumW2Error(false) as arguments to the RooAbsPdf::fitTo method. A short tutorial comparing different approaches to parameter uncertainties in the presence of event weights is available under tutorials/roofit/rf611_weightedfits.C.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4640
https://github.com/root-project/root/pull/4641:243,Availability,error,error,243,"…_PATH. The environment variable can be set like CLING_MODULEMAP_PATH=/a:./b/. In this; case ROOT will initialize with; -fmodule-map-file=/a/module.modulemap -fmodule-map-file=./b/module.modulemap. If the files do not exist ROOT will print an error. cc: @davidlange6, @oshadura",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4641
https://github.com/root-project/root/pull/4641:24,Modifiability,variab,variable,24,"…_PATH. The environment variable can be set like CLING_MODULEMAP_PATH=/a:./b/. In this; case ROOT will initialize with; -fmodule-map-file=/a/module.modulemap -fmodule-map-file=./b/module.modulemap. If the files do not exist ROOT will print an error. cc: @davidlange6, @oshadura",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4641
https://github.com/root-project/root/pull/4643:151,Deployability,update,update,151,"This change is done in order to avoid that the pythonizations modules; depend on methods defined in TPython. This commit can be descarded when we will update to CPyCppyy-1.9.7,; since TPython::CPPInstance_FromVoidPtr will become; CPyCppyy::CPPInstance_FromVoidPtr.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4643
https://github.com/root-project/root/pull/4643:71,Integrability,depend,depend,71,"This change is done in order to avoid that the pythonizations modules; depend on methods defined in TPython. This commit can be descarded when we will update to CPyCppyy-1.9.7,; since TPython::CPPInstance_FromVoidPtr will become; CPyCppyy::CPPInstance_FromVoidPtr.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4643
https://github.com/root-project/root/pull/4643:32,Safety,avoid,avoid,32,"This change is done in order to avoid that the pythonizations modules; depend on methods defined in TPython. This commit can be descarded when we will update to CPyCppyy-1.9.7,; since TPython::CPPInstance_FromVoidPtr will become; CPyCppyy::CPPInstance_FromVoidPtr.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4643
https://github.com/root-project/root/pull/4647:0,Deployability,Upgrade,Upgraded,0,"Upgraded version of PR #4279.; Changes were necessary due to incompatibility with C++ modules. Problem: due to how rootmap works, it's not possible to have multiple versions of a pair (shared library, pcm) with the same name, even in different directories. This feature lead to the impossibility of building multiple versions of libROOTPython, which used to contain, along with the pythonizations, also the TPython library. Solution: TPython and pythonizations have been split, and are built in libROOTTPython and libROOTPythonizations respectively. We only have one version of the former (the last one built) and possibility to build multiple versions for the latter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4647
https://github.com/root-project/root/pull/4648:207,Integrability,inject,injected,207,"As stated in. https://bitbucket.org/wlav/cppyy/issues/176/issue-with-python-list-created-from-vector. in Cppyy-1.5.6 when we do the following:. l = [e for e in cppyy.gbl.get_vec()]. where get_vec() is a C++ injected function that returns a C++; std::vector<std::string>, the variable 'e' that goes through the vector is; not a Python string, but a temporary object of type std::string. Being 'e' a reference to a temporary, the vector goes out of scope. The second of the two solutions suggested in the discussion is applied; where necessary.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4648
https://github.com/root-project/root/pull/4648:275,Modifiability,variab,variable,275,"As stated in. https://bitbucket.org/wlav/cppyy/issues/176/issue-with-python-list-created-from-vector. in Cppyy-1.5.6 when we do the following:. l = [e for e in cppyy.gbl.get_vec()]. where get_vec() is a C++ injected function that returns a C++; std::vector<std::string>, the variable 'e' that goes through the vector is; not a Python string, but a temporary object of type std::string. Being 'e' a reference to a temporary, the vector goes out of scope. The second of the two solutions suggested in the discussion is applied; where necessary.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4648
https://github.com/root-project/root/pull/4648:207,Security,inject,injected,207,"As stated in. https://bitbucket.org/wlav/cppyy/issues/176/issue-with-python-list-created-from-vector. in Cppyy-1.5.6 when we do the following:. l = [e for e in cppyy.gbl.get_vec()]. where get_vec() is a C++ injected function that returns a C++; std::vector<std::string>, the variable 'e' that goes through the vector is; not a Python string, but a temporary object of type std::string. Being 'e' a reference to a temporary, the vector goes out of scope. The second of the two solutions suggested in the discussion is applied; where necessary.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4648
https://github.com/root-project/root/pull/4649:74,Availability,error,error-writing-trees-with-snapshot-and-implicitmt,74,"This addresses the bug raised [in the forum](https://root-forum.cern.ch/t/error-writing-trees-with-snapshot-and-implicitmt/36965). Adds option to `TDirectoryFile` to call `mkdir` with an existing directory name without raising an error, and implements this option when creating a `Snapshot` with multithreading enabled. Also changes `CreateSnaphotRDF` to `CreateSnapshotRDF`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4649
https://github.com/root-project/root/pull/4649:230,Availability,error,error,230,"This addresses the bug raised [in the forum](https://root-forum.cern.ch/t/error-writing-trees-with-snapshot-and-implicitmt/36965). Adds option to `TDirectoryFile` to call `mkdir` with an existing directory name without raising an error, and implements this option when creating a `Snapshot` with multithreading enabled. Also changes `CreateSnaphotRDF` to `CreateSnapshotRDF`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4649
https://github.com/root-project/root/pull/4651:124,Deployability,integrat,integration,124,"It turns out that RNTuple data should better not be stored in custom directories because. 1. It is hard to get the TBrowser integration correctly; the TBrowser can only know the special status of the directory when looking at the object, looking at its key is not enough; 2. All the page keys get added to the directory's key list, which is inefficient. Instead, RNTuple will be changed to replicate the TTree approach: an ntuple is represented by a single, small `RNTuple` object, but the actual page data is stored in anonymous keys.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4651
https://github.com/root-project/root/pull/4651:124,Integrability,integrat,integration,124,"It turns out that RNTuple data should better not be stored in custom directories because. 1. It is hard to get the TBrowser integration correctly; the TBrowser can only know the special status of the directory when looking at the object, looking at its key is not enough; 2. All the page keys get added to the directory's key list, which is inefficient. Instead, RNTuple will be changed to replicate the TTree approach: an ntuple is represented by a single, small `RNTuple` object, but the actual page data is stored in anonymous keys.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4651
https://github.com/root-project/root/pull/4652:563,Availability,avail,available,563,"Jupyter may be configured to be served on different base url's, so we cannot assume that is accessible in `/`. This is the case, for example, when it's used together with JupyterHub (like SWAN), where the base url is `/user/_username_/`.; This PR fixes the way jsROOT is loaded in order to take that into account. . For that, I've removed `/static/`, which forced the absolute url to the file, and let requireJs apply its own configuration (which takes the base url into account). For Jupyterlab, I also load requireJs with the base url. In case requireJs is not available (maybe it will be possible to install Jupyterlab without Jupyter Notebooks in the future?), it falls back to a cdn to load it.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4652
https://github.com/root-project/root/pull/4652:426,Deployability,configurat,configuration,426,"Jupyter may be configured to be served on different base url's, so we cannot assume that is accessible in `/`. This is the case, for example, when it's used together with JupyterHub (like SWAN), where the base url is `/user/_username_/`.; This PR fixes the way jsROOT is loaded in order to take that into account. . For that, I've removed `/static/`, which forced the absolute url to the file, and let requireJs apply its own configuration (which takes the base url into account). For Jupyterlab, I also load requireJs with the base url. In case requireJs is not available (maybe it will be possible to install Jupyterlab without Jupyter Notebooks in the future?), it falls back to a cdn to load it.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4652
https://github.com/root-project/root/pull/4652:603,Deployability,install,install,603,"Jupyter may be configured to be served on different base url's, so we cannot assume that is accessible in `/`. This is the case, for example, when it's used together with JupyterHub (like SWAN), where the base url is `/user/_username_/`.; This PR fixes the way jsROOT is loaded in order to take that into account. . For that, I've removed `/static/`, which forced the absolute url to the file, and let requireJs apply its own configuration (which takes the base url into account). For Jupyterlab, I also load requireJs with the base url. In case requireJs is not available (maybe it will be possible to install Jupyterlab without Jupyter Notebooks in the future?), it falls back to a cdn to load it.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4652
https://github.com/root-project/root/pull/4652:15,Modifiability,config,configured,15,"Jupyter may be configured to be served on different base url's, so we cannot assume that is accessible in `/`. This is the case, for example, when it's used together with JupyterHub (like SWAN), where the base url is `/user/_username_/`.; This PR fixes the way jsROOT is loaded in order to take that into account. . For that, I've removed `/static/`, which forced the absolute url to the file, and let requireJs apply its own configuration (which takes the base url into account). For Jupyterlab, I also load requireJs with the base url. In case requireJs is not available (maybe it will be possible to install Jupyterlab without Jupyter Notebooks in the future?), it falls back to a cdn to load it.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4652
https://github.com/root-project/root/pull/4652:426,Modifiability,config,configuration,426,"Jupyter may be configured to be served on different base url's, so we cannot assume that is accessible in `/`. This is the case, for example, when it's used together with JupyterHub (like SWAN), where the base url is `/user/_username_/`.; This PR fixes the way jsROOT is loaded in order to take that into account. . For that, I've removed `/static/`, which forced the absolute url to the file, and let requireJs apply its own configuration (which takes the base url into account). For Jupyterlab, I also load requireJs with the base url. In case requireJs is not available (maybe it will be possible to install Jupyterlab without Jupyter Notebooks in the future?), it falls back to a cdn to load it.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4652
https://github.com/root-project/root/pull/4652:271,Performance,load,loaded,271,"Jupyter may be configured to be served on different base url's, so we cannot assume that is accessible in `/`. This is the case, for example, when it's used together with JupyterHub (like SWAN), where the base url is `/user/_username_/`.; This PR fixes the way jsROOT is loaded in order to take that into account. . For that, I've removed `/static/`, which forced the absolute url to the file, and let requireJs apply its own configuration (which takes the base url into account). For Jupyterlab, I also load requireJs with the base url. In case requireJs is not available (maybe it will be possible to install Jupyterlab without Jupyter Notebooks in the future?), it falls back to a cdn to load it.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4652
https://github.com/root-project/root/pull/4652:504,Performance,load,load,504,"Jupyter may be configured to be served on different base url's, so we cannot assume that is accessible in `/`. This is the case, for example, when it's used together with JupyterHub (like SWAN), where the base url is `/user/_username_/`.; This PR fixes the way jsROOT is loaded in order to take that into account. . For that, I've removed `/static/`, which forced the absolute url to the file, and let requireJs apply its own configuration (which takes the base url into account). For Jupyterlab, I also load requireJs with the base url. In case requireJs is not available (maybe it will be possible to install Jupyterlab without Jupyter Notebooks in the future?), it falls back to a cdn to load it.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4652
https://github.com/root-project/root/pull/4652:691,Performance,load,load,691,"Jupyter may be configured to be served on different base url's, so we cannot assume that is accessible in `/`. This is the case, for example, when it's used together with JupyterHub (like SWAN), where the base url is `/user/_username_/`.; This PR fixes the way jsROOT is loaded in order to take that into account. . For that, I've removed `/static/`, which forced the absolute url to the file, and let requireJs apply its own configuration (which takes the base url into account). For Jupyterlab, I also load requireJs with the base url. In case requireJs is not available (maybe it will be possible to install Jupyterlab without Jupyter Notebooks in the future?), it falls back to a cdn to load it.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4652
https://github.com/root-project/root/pull/4652:92,Security,access,accessible,92,"Jupyter may be configured to be served on different base url's, so we cannot assume that is accessible in `/`. This is the case, for example, when it's used together with JupyterHub (like SWAN), where the base url is `/user/_username_/`.; This PR fixes the way jsROOT is loaded in order to take that into account. . For that, I've removed `/static/`, which forced the absolute url to the file, and let requireJs apply its own configuration (which takes the base url into account). For Jupyterlab, I also load requireJs with the base url. In case requireJs is not available (maybe it will be possible to install Jupyterlab without Jupyter Notebooks in the future?), it falls back to a cdn to load it.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4652
https://github.com/root-project/root/pull/4656:782,Deployability,patch,patch,782,"…alizing. When we deserialize a function with noexcept(constant_expression) qualifier the; constant_expression itself might trigger deserialization. Triggering nested; deserializations is not supported in clang. Currently we just removed the assert but this shows problems when we go to; higher version of stl's (such as the one in ubuntu19) which more heavily; rely on constexpr. We segfault in cases where we do equivalent of:; ```; cling::Interpreter *interp = ((TCling*)gCling)->GetInterpreterImpl();; auto& lh = interp->getLookupHelper();; auto diag = cling::LookupHelper::WithDiagnostics;; auto S = lh.findScope(""ROOT::Internal::RDF"", diag);; lh.findAnyFunction(S, ""RDataFrameTake<float>"", diag);; lh.findAnyFunction(S, ""RDataFrameTake<std::vector<float>>"", diag);; ```. This patch delays the unsafe computation of type of the deserialized function; and thus the evaluation of the exception qualifier. This should fix the failing; pyunittests-pyroot-rdataframe-asnumpy nightly on ubuntu 19. The red pill is applying llvm-mirror/clang@5d50602a8de220e1f0bbdd136e9a7be21a1b63c0. This will happen after releasing v6.20.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4656
https://github.com/root-project/root/pull/4656:799,Safety,unsafe,unsafe,799,"…alizing. When we deserialize a function with noexcept(constant_expression) qualifier the; constant_expression itself might trigger deserialization. Triggering nested; deserializations is not supported in clang. Currently we just removed the assert but this shows problems when we go to; higher version of stl's (such as the one in ubuntu19) which more heavily; rely on constexpr. We segfault in cases where we do equivalent of:; ```; cling::Interpreter *interp = ((TCling*)gCling)->GetInterpreterImpl();; auto& lh = interp->getLookupHelper();; auto diag = cling::LookupHelper::WithDiagnostics;; auto S = lh.findScope(""ROOT::Internal::RDF"", diag);; lh.findAnyFunction(S, ""RDataFrameTake<float>"", diag);; lh.findAnyFunction(S, ""RDataFrameTake<std::vector<float>>"", diag);; ```. This patch delays the unsafe computation of type of the deserialized function; and thus the evaluation of the exception qualifier. This should fix the failing; pyunittests-pyroot-rdataframe-asnumpy nightly on ubuntu 19. The red pill is applying llvm-mirror/clang@5d50602a8de220e1f0bbdd136e9a7be21a1b63c0. This will happen after releasing v6.20.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4656
https://github.com/root-project/root/pull/4656:242,Testability,assert,assert,242,"…alizing. When we deserialize a function with noexcept(constant_expression) qualifier the; constant_expression itself might trigger deserialization. Triggering nested; deserializations is not supported in clang. Currently we just removed the assert but this shows problems when we go to; higher version of stl's (such as the one in ubuntu19) which more heavily; rely on constexpr. We segfault in cases where we do equivalent of:; ```; cling::Interpreter *interp = ((TCling*)gCling)->GetInterpreterImpl();; auto& lh = interp->getLookupHelper();; auto diag = cling::LookupHelper::WithDiagnostics;; auto S = lh.findScope(""ROOT::Internal::RDF"", diag);; lh.findAnyFunction(S, ""RDataFrameTake<float>"", diag);; lh.findAnyFunction(S, ""RDataFrameTake<std::vector<float>>"", diag);; ```. This patch delays the unsafe computation of type of the deserialized function; and thus the evaluation of the exception qualifier. This should fix the failing; pyunittests-pyroot-rdataframe-asnumpy nightly on ubuntu 19. The red pill is applying llvm-mirror/clang@5d50602a8de220e1f0bbdd136e9a7be21a1b63c0. This will happen after releasing v6.20.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4656
https://github.com/root-project/root/pull/4659:5,Deployability,patch,patch,5,This patch allows us to resolve system-specific header search directories such as the location of libc. This patch fixes experimental runtime_cxxmodules on OSX where libc is in /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/. cc: @oshadura,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4659
https://github.com/root-project/root/pull/4659:109,Deployability,patch,patch,109,This patch allows us to resolve system-specific header search directories such as the location of libc. This patch fixes experimental runtime_cxxmodules on OSX where libc is in /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/. cc: @oshadura,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4659
https://github.com/root-project/root/pull/4660:5,Deployability,patch,patch,5,"This patch should simplify the cmssw modules setup. cc: @davidlange6, @smuzaffar, @oshadura",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4660
https://github.com/root-project/root/pull/4660:18,Usability,simpl,simplify,18,"This patch should simplify the cmssw modules setup. cc: @davidlange6, @smuzaffar, @oshadura",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4660
https://github.com/root-project/root/pull/4661:328,Security,access,accessible,328,"This PR introduces a few changes to old PyROOT and new PyROOT for forward and backward compatibility reasons, respectively. Old PyROOT:; - Issue a deprecation warning when the conversion None -> null pointer happens; - Add forward compatible names for `AsCObject` (`as_cobject`) and `BindObject` (`bind_object`); - Make nullptr accessible as cppyy.nullptr; - Make pythonization functions accessible via cppyy.py ; - Issue a deprecation warning when using `buffer.SetSize`, and add `buffer.reshape` to be forward compatible; - Add a few attribute names for proxies (objects, classes, callables) that forward compatible with new PyROOT. New PyROOT; - Add `MakeNullPointer(klass)` as `bind_object(0,klass)`; - Provide `BindObject` and `AsCObject`. Related test PR:; https://github.com/root-project/roottest/pull/425",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4661
https://github.com/root-project/root/pull/4661:388,Security,access,accessible,388,"This PR introduces a few changes to old PyROOT and new PyROOT for forward and backward compatibility reasons, respectively. Old PyROOT:; - Issue a deprecation warning when the conversion None -> null pointer happens; - Add forward compatible names for `AsCObject` (`as_cobject`) and `BindObject` (`bind_object`); - Make nullptr accessible as cppyy.nullptr; - Make pythonization functions accessible via cppyy.py ; - Issue a deprecation warning when using `buffer.SetSize`, and add `buffer.reshape` to be forward compatible; - Add a few attribute names for proxies (objects, classes, callables) that forward compatible with new PyROOT. New PyROOT; - Add `MakeNullPointer(klass)` as `bind_object(0,klass)`; - Provide `BindObject` and `AsCObject`. Related test PR:; https://github.com/root-project/roottest/pull/425",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4661
https://github.com/root-project/root/pull/4661:753,Testability,test,test,753,"This PR introduces a few changes to old PyROOT and new PyROOT for forward and backward compatibility reasons, respectively. Old PyROOT:; - Issue a deprecation warning when the conversion None -> null pointer happens; - Add forward compatible names for `AsCObject` (`as_cobject`) and `BindObject` (`bind_object`); - Make nullptr accessible as cppyy.nullptr; - Make pythonization functions accessible via cppyy.py ; - Issue a deprecation warning when using `buffer.SetSize`, and add `buffer.reshape` to be forward compatible; - Add a few attribute names for proxies (objects, classes, callables) that forward compatible with new PyROOT. New PyROOT; - Add `MakeNullPointer(klass)` as `bind_object(0,klass)`; - Provide `BindObject` and `AsCObject`. Related test PR:; https://github.com/root-project/roottest/pull/425",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4661
https://github.com/root-project/root/pull/4662:321,Integrability,interface,interface,321,"Provide RFileDialog class. Can be used standalone or embed into other widgets.; Used now in RBrowser to implement SaveAs functionality for edited file. Key feature - sharing of web connection of RBrowser also for RFileDialog.; Includes changes in RWebWindow classes and in JSROOT,; but opens a lot of possibility for MDI interface developments in the future!. Now code is ready to be merged.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4662
https://github.com/root-project/root/pull/4666:107,Testability,test,tests,107,"Prevent issues seen here:; http://cdash.cern.ch/viewTest.php?onlyfailed&buildid=772393. where two JupyROOT tests that use ""%%cpp -a"" seem to step on; each other and generate the same library name.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4666
https://github.com/root-project/root/pull/4668:286,Deployability,patch,patch,286,"This is an alternative approach to solve the problem of colliding LLVM symbols, if other libraries bring in their own LLVM.; The original approach was to force other LLVM libraries to be compiled with -fvisibility=hidden or being opened with dlopen after TROOT::InitInterpreter(). This patch solves the issue on the ROOT side, which seems to me the much cleaner approach because we do not pose any limitations on 3rd party libraries. I tried it locally and it works for me. Marked as ""Work in Progress"", since this might need some more thought, in particular for other OS, and for old glibc versions that do not support RTLD_DEEPBIND.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4668
https://github.com/root-project/root/pull/4670:727,Availability,Error,Error,727,"Previously the checks that the type of the readerValue and the leaf (part of a leaflist) was susceptible to the; 'difference' between '[U]Long64_t' and '[unsigned] long long'. The previous check did not account for TDictionary::GetDictionary returning 'typedef' information. So instead rely on the numerical/enum version of the type. This addresses https://root-forum.cern.ch/t/issues-with-automatically-constructed-makeselector/37033; and https://root-forum.cern.ch/t/how-to-read-unsigned-long-using-ttreereader/21850. *Br 0 :SelectOpHitBkgInfo : deltat0/D:deltat/D:t0/D:te/D:tabs/D:PEs/D: *; * | event/l:run/l:subRun/l:chan/l:bar/l. TTreeReaderValue<ULong64_t> event = {fReader, ""SelectOpHitBkgInfo.event""};. was leading to. Error in <TTreeReaderValueBase::CreateProxy()>: Leaf of type ULong64_t cannot be read by TTreeReaderValue<unsigned long long>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4670
https://github.com/root-project/root/pull/4671:227,Availability,error,errors,227,"Based on the following patch by @wlav :; https://bitbucket.org/wlav/cppyy-backend/src/master/cling/patches/signaltrycatch.diff. Adds a new exception handler used by cppyy to provide a better debugging experience in presence of errors:; https://cppyy.readthedocs.io/en/latest/debugging.html. It also adds SIGABRT and provides support for signal handling on Windows. The original cppyy patch has been modified to make it backwards compatible, since it eliminated the use of gApplication for exception handling in Unix. In this version, if there is an exception handler (e.g. we are using PyROOT, which defines it via cppyy) we will rely on that handler to treat the exception,; otherwise we fall back to the previous behaviour which relied on gApplication. Windows-related changes to be reviewed by @bellenot.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4671
https://github.com/root-project/root/pull/4671:23,Deployability,patch,patch,23,"Based on the following patch by @wlav :; https://bitbucket.org/wlav/cppyy-backend/src/master/cling/patches/signaltrycatch.diff. Adds a new exception handler used by cppyy to provide a better debugging experience in presence of errors:; https://cppyy.readthedocs.io/en/latest/debugging.html. It also adds SIGABRT and provides support for signal handling on Windows. The original cppyy patch has been modified to make it backwards compatible, since it eliminated the use of gApplication for exception handling in Unix. In this version, if there is an exception handler (e.g. we are using PyROOT, which defines it via cppyy) we will rely on that handler to treat the exception,; otherwise we fall back to the previous behaviour which relied on gApplication. Windows-related changes to be reviewed by @bellenot.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4671
https://github.com/root-project/root/pull/4671:99,Deployability,patch,patches,99,"Based on the following patch by @wlav :; https://bitbucket.org/wlav/cppyy-backend/src/master/cling/patches/signaltrycatch.diff. Adds a new exception handler used by cppyy to provide a better debugging experience in presence of errors:; https://cppyy.readthedocs.io/en/latest/debugging.html. It also adds SIGABRT and provides support for signal handling on Windows. The original cppyy patch has been modified to make it backwards compatible, since it eliminated the use of gApplication for exception handling in Unix. In this version, if there is an exception handler (e.g. we are using PyROOT, which defines it via cppyy) we will rely on that handler to treat the exception,; otherwise we fall back to the previous behaviour which relied on gApplication. Windows-related changes to be reviewed by @bellenot.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4671
https://github.com/root-project/root/pull/4671:384,Deployability,patch,patch,384,"Based on the following patch by @wlav :; https://bitbucket.org/wlav/cppyy-backend/src/master/cling/patches/signaltrycatch.diff. Adds a new exception handler used by cppyy to provide a better debugging experience in presence of errors:; https://cppyy.readthedocs.io/en/latest/debugging.html. It also adds SIGABRT and provides support for signal handling on Windows. The original cppyy patch has been modified to make it backwards compatible, since it eliminated the use of gApplication for exception handling in Unix. In this version, if there is an exception handler (e.g. we are using PyROOT, which defines it via cppyy) we will rely on that handler to treat the exception,; otherwise we fall back to the previous behaviour which relied on gApplication. Windows-related changes to be reviewed by @bellenot.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4671
https://github.com/root-project/root/pull/4672:65,Testability,test,tests,65,"In the following platform:. olhswep22.cern.ch. the two following tests:. pyunittests-pyroot-pyz-ttree-setbranchaddress; pyunittests-pyroot-pyz-ttree-branch-attr. were failing because a string was not properly created with the ""<<""; operator. With the definition of a std::string object the problem is; solved.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4672
https://github.com/root-project/root/pull/4675:112,Availability,down,down,112,"We should follow the shutdown procedure from FrontendAction::EndSourceFile which ensures clang is properly torn down. This patch allows us to write a module file without having to explicitly call CompilerInstance::clearOutputFiles. This is part of a patch intending to lay down some infrastructure to fix the conditional build of the clang-internal module _Builtin_intrinsics.pcm in the context of cmssw. I've found an easier way to do so, however, this is of generic importance for ROOT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4675
https://github.com/root-project/root/pull/4675:273,Availability,down,down,273,"We should follow the shutdown procedure from FrontendAction::EndSourceFile which ensures clang is properly torn down. This patch allows us to write a module file without having to explicitly call CompilerInstance::clearOutputFiles. This is part of a patch intending to lay down some infrastructure to fix the conditional build of the clang-internal module _Builtin_intrinsics.pcm in the context of cmssw. I've found an easier way to do so, however, this is of generic importance for ROOT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4675
https://github.com/root-project/root/pull/4675:123,Deployability,patch,patch,123,"We should follow the shutdown procedure from FrontendAction::EndSourceFile which ensures clang is properly torn down. This patch allows us to write a module file without having to explicitly call CompilerInstance::clearOutputFiles. This is part of a patch intending to lay down some infrastructure to fix the conditional build of the clang-internal module _Builtin_intrinsics.pcm in the context of cmssw. I've found an easier way to do so, however, this is of generic importance for ROOT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4675
https://github.com/root-project/root/pull/4675:250,Deployability,patch,patch,250,"We should follow the shutdown procedure from FrontendAction::EndSourceFile which ensures clang is properly torn down. This patch allows us to write a module file without having to explicitly call CompilerInstance::clearOutputFiles. This is part of a patch intending to lay down some infrastructure to fix the conditional build of the clang-internal module _Builtin_intrinsics.pcm in the context of cmssw. I've found an easier way to do so, however, this is of generic importance for ROOT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4675
https://github.com/root-project/root/pull/4675:214,Usability,clear,clearOutputFiles,214,"We should follow the shutdown procedure from FrontendAction::EndSourceFile which ensures clang is properly torn down. This patch allows us to write a module file without having to explicitly call CompilerInstance::clearOutputFiles. This is part of a patch intending to lay down some infrastructure to fix the conditional build of the clang-internal module _Builtin_intrinsics.pcm in the context of cmssw. I've found an easier way to do so, however, this is of generic importance for ROOT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4675
https://github.com/root-project/root/pull/4676:448,Availability,error,errors,448,"It is part of the set of 'system' modules which gets created on demand when a dictionary includes intrinsics. Make this action explicit. This way we can invalidate it (from within rootcling) and rebuild it when required. This patch also fixes an issue in cmssw where _Builtin_intrinsics is generated and installed on cvmfs. If we have local ROOT which does not have this module generated, the system picks up the one from cvmfs causing out-of-date errors. cc: @davidlange6, @smuzaffar, @oshadura",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4676
https://github.com/root-project/root/pull/4676:226,Deployability,patch,patch,226,"It is part of the set of 'system' modules which gets created on demand when a dictionary includes intrinsics. Make this action explicit. This way we can invalidate it (from within rootcling) and rebuild it when required. This patch also fixes an issue in cmssw where _Builtin_intrinsics is generated and installed on cvmfs. If we have local ROOT which does not have this module generated, the system picks up the one from cvmfs causing out-of-date errors. cc: @davidlange6, @smuzaffar, @oshadura",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4676
https://github.com/root-project/root/pull/4676:304,Deployability,install,installed,304,"It is part of the set of 'system' modules which gets created on demand when a dictionary includes intrinsics. Make this action explicit. This way we can invalidate it (from within rootcling) and rebuild it when required. This patch also fixes an issue in cmssw where _Builtin_intrinsics is generated and installed on cvmfs. If we have local ROOT which does not have this module generated, the system picks up the one from cvmfs causing out-of-date errors. cc: @davidlange6, @smuzaffar, @oshadura",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4676
https://github.com/root-project/root/pull/4677:247,Security,checksum,checksums,247,"These are four bugfixes for RooFit, and an extension of schema evolution conversion rules. @pcanal, please review the following:; https://github.com/root-project/root/commit/4922063626badad3934edb5965aced6ea678c7c3. > [core] Allow hex numbers for checksums in schema rules.; > ; > When streamer infos are printed, checksums appear in hex. When rules are; > parsed, hex values were not accepted, though. This allows both hex and; > decimal checksums in conversion rules. Is this useful? If not, the checksum in one of the bugfixes has to be converted to decimal.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4677
https://github.com/root-project/root/pull/4677:314,Security,checksum,checksums,314,"These are four bugfixes for RooFit, and an extension of schema evolution conversion rules. @pcanal, please review the following:; https://github.com/root-project/root/commit/4922063626badad3934edb5965aced6ea678c7c3. > [core] Allow hex numbers for checksums in schema rules.; > ; > When streamer infos are printed, checksums appear in hex. When rules are; > parsed, hex values were not accepted, though. This allows both hex and; > decimal checksums in conversion rules. Is this useful? If not, the checksum in one of the bugfixes has to be converted to decimal.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4677
https://github.com/root-project/root/pull/4677:439,Security,checksum,checksums,439,"These are four bugfixes for RooFit, and an extension of schema evolution conversion rules. @pcanal, please review the following:; https://github.com/root-project/root/commit/4922063626badad3934edb5965aced6ea678c7c3. > [core] Allow hex numbers for checksums in schema rules.; > ; > When streamer infos are printed, checksums appear in hex. When rules are; > parsed, hex values were not accepted, though. This allows both hex and; > decimal checksums in conversion rules. Is this useful? If not, the checksum in one of the bugfixes has to be converted to decimal.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4677
https://github.com/root-project/root/pull/4677:498,Security,checksum,checksum,498,"These are four bugfixes for RooFit, and an extension of schema evolution conversion rules. @pcanal, please review the following:; https://github.com/root-project/root/commit/4922063626badad3934edb5965aced6ea678c7c3. > [core] Allow hex numbers for checksums in schema rules.; > ; > When streamer infos are printed, checksums appear in hex. When rules are; > parsed, hex values were not accepted, though. This allows both hex and; > decimal checksums in conversion rules. Is this useful? If not, the checksum in one of the bugfixes has to be converted to decimal.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4677
https://github.com/root-project/root/pull/4678:734,Availability,error,error,734,"In GCC9, operator== and operator!= are no longer member functions of STL iterators (seen in _Rb_tree_iterator). This means they cannot be obtained anymore with GetListOfMethods of the iterator class. Such change broke the iteration of STL classes from Python when using (old) cppyy alone in GCC9. The addition of the operators to the iterator class still happened when importing ROOT because; in that case gApplication is initialized to TPyROOTApplication, which is required in Utility::AddBinaryOperator to add the operators. This PR adds the necessary logic so that operator== and operator!= are also added to the iterator proxy class when using cppyy alone in GCC9. The addition is done lazily as a last attempt before throwing an error in the comparison.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4678
https://github.com/root-project/root/pull/4678:554,Testability,log,logic,554,"In GCC9, operator== and operator!= are no longer member functions of STL iterators (seen in _Rb_tree_iterator). This means they cannot be obtained anymore with GetListOfMethods of the iterator class. Such change broke the iteration of STL classes from Python when using (old) cppyy alone in GCC9. The addition of the operators to the iterator class still happened when importing ROOT because; in that case gApplication is initialized to TPyROOTApplication, which is required in Utility::AddBinaryOperator to add the operators. This PR adds the necessary logic so that operator== and operator!= are also added to the iterator proxy class when using cppyy alone in GCC9. The addition is done lazily as a last attempt before throwing an error in the comparison.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4678
https://github.com/root-project/root/pull/4681:129,Testability,test,tests,129,"Port from old PyROOT. Prevent issues seen here:; http://cdash.cern.ch/viewTest.php?onlyfailed&buildid=772393. where two JupyROOT tests that use ""%%cpp -a"" seem to step on; each other and generate the same library name. The change in behaviour also requires the corresponding; modifications to the doctests.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4681
https://github.com/root-project/root/pull/4683:300,Availability,error,error,300,"The RException class is supposed to serve as base class for all ROOT; exceptions. It contains an `RError` member with diagnostic information.; The `RResult<T>` class can be used as a return value of operations that; may fail. The `RResult<T>` object wraps either a valid value or an `RError`.; If an error state remains unchecked, the `RResult` class will throw an; exception on destruction.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4683
https://github.com/root-project/root/pull/4683:250,Integrability,wrap,wraps,250,"The RException class is supposed to serve as base class for all ROOT; exceptions. It contains an `RError` member with diagnostic information.; The `RResult<T>` class can be used as a return value of operations that; may fail. The `RResult<T>` object wraps either a valid value or an `RError`.; If an error state remains unchecked, the `RResult` class will throw an; exception on destruction.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4683
https://github.com/root-project/root/pull/4684:60,Testability,log,logical,60,"Added a function in TROOT to retrieve the correct number of logical cores, taking into account (in linux) CPU affinity and CFS bandwith control.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4684
https://github.com/root-project/root/pull/4686:124,Availability,failure,failure,124,"When PR #4279 was initially sent on Aug 25th, the search for Python was; moved to RootBuildMacros in order to avoid a build failure due ot the; search for another package and the declaration of one of the new CMake; variables.; This seem not to be a problem anymore (something changed in the; meantime?), so the search for Python can be put back to the original; place.; This could also fix the tests failing with cxx17 due to a mismatch; between Python executable and libraries.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4686
https://github.com/root-project/root/pull/4686:216,Modifiability,variab,variables,216,"When PR #4279 was initially sent on Aug 25th, the search for Python was; moved to RootBuildMacros in order to avoid a build failure due ot the; search for another package and the declaration of one of the new CMake; variables.; This seem not to be a problem anymore (something changed in the; meantime?), so the search for Python can be put back to the original; place.; This could also fix the tests failing with cxx17 due to a mismatch; between Python executable and libraries.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4686
https://github.com/root-project/root/pull/4686:110,Safety,avoid,avoid,110,"When PR #4279 was initially sent on Aug 25th, the search for Python was; moved to RootBuildMacros in order to avoid a build failure due ot the; search for another package and the declaration of one of the new CMake; variables.; This seem not to be a problem anymore (something changed in the; meantime?), so the search for Python can be put back to the original; place.; This could also fix the tests failing with cxx17 due to a mismatch; between Python executable and libraries.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4686
https://github.com/root-project/root/pull/4686:395,Testability,test,tests,395,"When PR #4279 was initially sent on Aug 25th, the search for Python was; moved to RootBuildMacros in order to avoid a build failure due ot the; search for another package and the declaration of one of the new CMake; variables.; This seem not to be a problem anymore (something changed in the; meantime?), so the search for Python can be put back to the original; place.; This could also fix the tests failing with cxx17 due to a mismatch; between Python executable and libraries.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4686
https://github.com/root-project/root/pull/4687:159,Availability,down,down,159,"Motivation: we need to make sure that, if PyROOT is used from another process that will keep on living after the Python interpreter dies, PyROOT does not shut down the ROOT interpreter via `TROOT::EndOfProcessCleanups` when running its atexit handler. In that sense, this PR adds a configuration option to tell PyROOT if the teardown needs to be soft, i.e. we do not want to shut down the ROOT interpreter. Instead, in the soft mode, we only want (and need) to clean the objects that are controlled by PyROOT via its `TMemoryRegulator`. @Axel-Naumann @pcanal just one new thing with respect to what we discussed: in the function that does the cleanup of the objects in `TMemoryRegulator`, called `RecursiveRemoveAll` in my commit, we can only delete a C++ object found in the map if the corresponding Python proxy **owns** the C++ object. Otherwise we will have a double delete (if the proxy does not own is because the deletion will happen somewhere else, so our `RecursiveRemoveAll` can't delete too).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4687
https://github.com/root-project/root/pull/4687:380,Availability,down,down,380,"Motivation: we need to make sure that, if PyROOT is used from another process that will keep on living after the Python interpreter dies, PyROOT does not shut down the ROOT interpreter via `TROOT::EndOfProcessCleanups` when running its atexit handler. In that sense, this PR adds a configuration option to tell PyROOT if the teardown needs to be soft, i.e. we do not want to shut down the ROOT interpreter. Instead, in the soft mode, we only want (and need) to clean the objects that are controlled by PyROOT via its `TMemoryRegulator`. @Axel-Naumann @pcanal just one new thing with respect to what we discussed: in the function that does the cleanup of the objects in `TMemoryRegulator`, called `RecursiveRemoveAll` in my commit, we can only delete a C++ object found in the map if the corresponding Python proxy **owns** the C++ object. Otherwise we will have a double delete (if the proxy does not own is because the deletion will happen somewhere else, so our `RecursiveRemoveAll` can't delete too).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4687
https://github.com/root-project/root/pull/4687:282,Deployability,configurat,configuration,282,"Motivation: we need to make sure that, if PyROOT is used from another process that will keep on living after the Python interpreter dies, PyROOT does not shut down the ROOT interpreter via `TROOT::EndOfProcessCleanups` when running its atexit handler. In that sense, this PR adds a configuration option to tell PyROOT if the teardown needs to be soft, i.e. we do not want to shut down the ROOT interpreter. Instead, in the soft mode, we only want (and need) to clean the objects that are controlled by PyROOT via its `TMemoryRegulator`. @Axel-Naumann @pcanal just one new thing with respect to what we discussed: in the function that does the cleanup of the objects in `TMemoryRegulator`, called `RecursiveRemoveAll` in my commit, we can only delete a C++ object found in the map if the corresponding Python proxy **owns** the C++ object. Otherwise we will have a double delete (if the proxy does not own is because the deletion will happen somewhere else, so our `RecursiveRemoveAll` can't delete too).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4687
https://github.com/root-project/root/pull/4687:282,Modifiability,config,configuration,282,"Motivation: we need to make sure that, if PyROOT is used from another process that will keep on living after the Python interpreter dies, PyROOT does not shut down the ROOT interpreter via `TROOT::EndOfProcessCleanups` when running its atexit handler. In that sense, this PR adds a configuration option to tell PyROOT if the teardown needs to be soft, i.e. we do not want to shut down the ROOT interpreter. Instead, in the soft mode, we only want (and need) to clean the objects that are controlled by PyROOT via its `TMemoryRegulator`. @Axel-Naumann @pcanal just one new thing with respect to what we discussed: in the function that does the cleanup of the objects in `TMemoryRegulator`, called `RecursiveRemoveAll` in my commit, we can only delete a C++ object found in the map if the corresponding Python proxy **owns** the C++ object. Otherwise we will have a double delete (if the proxy does not own is because the deletion will happen somewhere else, so our `RecursiveRemoveAll` can't delete too).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4687
https://github.com/root-project/root/pull/4688:322,Testability,test,tests,322,"Previously, ROOT7 histograms used different local bin coordinate conventions for GetBinIndex and GetBin(From|Center|To), as discussed in https://sft.its.cern.ch/jira/browse/ROOT-10445 . This PR brings order to that chaos, following the resolution proposed in https://sft.its.cern.ch/jira/browse/ROOT-10446 , and adds some tests which assert that the two binning conventions will remain in sync in the future. While I was looking through the RHistImpl code, investigating further binning logic inconsistencies, I also spotted a few mistakes in the (currently unused) axis growth logic of GetBinIndex. So I corrected those along the way.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4688
https://github.com/root-project/root/pull/4688:334,Testability,assert,assert,334,"Previously, ROOT7 histograms used different local bin coordinate conventions for GetBinIndex and GetBin(From|Center|To), as discussed in https://sft.its.cern.ch/jira/browse/ROOT-10445 . This PR brings order to that chaos, following the resolution proposed in https://sft.its.cern.ch/jira/browse/ROOT-10446 , and adds some tests which assert that the two binning conventions will remain in sync in the future. While I was looking through the RHistImpl code, investigating further binning logic inconsistencies, I also spotted a few mistakes in the (currently unused) axis growth logic of GetBinIndex. So I corrected those along the way.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4688
https://github.com/root-project/root/pull/4688:487,Testability,log,logic,487,"Previously, ROOT7 histograms used different local bin coordinate conventions for GetBinIndex and GetBin(From|Center|To), as discussed in https://sft.its.cern.ch/jira/browse/ROOT-10445 . This PR brings order to that chaos, following the resolution proposed in https://sft.its.cern.ch/jira/browse/ROOT-10446 , and adds some tests which assert that the two binning conventions will remain in sync in the future. While I was looking through the RHistImpl code, investigating further binning logic inconsistencies, I also spotted a few mistakes in the (currently unused) axis growth logic of GetBinIndex. So I corrected those along the way.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4688
https://github.com/root-project/root/pull/4688:578,Testability,log,logic,578,"Previously, ROOT7 histograms used different local bin coordinate conventions for GetBinIndex and GetBin(From|Center|To), as discussed in https://sft.its.cern.ch/jira/browse/ROOT-10445 . This PR brings order to that chaos, following the resolution proposed in https://sft.its.cern.ch/jira/browse/ROOT-10446 , and adds some tests which assert that the two binning conventions will remain in sync in the future. While I was looking through the RHistImpl code, investigating further binning logic inconsistencies, I also spotted a few mistakes in the (currently unused) axis growth logic of GetBinIndex. So I corrected those along the way.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4688
https://github.com/root-project/root/pull/4689:81,Performance,load,loader,81,"We had symbols exposed, which in turn meant symbols were resolved by the dynamic loader,; which in turn meant another libllvm.so could interfere with those of cling. By hiding these; symbols, all symbols are self-contained and not external symbols leak into libCling.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4689
https://github.com/root-project/root/pull/4689:15,Security,expose,exposed,15,"We had symbols exposed, which in turn meant symbols were resolved by the dynamic loader,; which in turn meant another libllvm.so could interfere with those of cling. By hiding these; symbols, all symbols are self-contained and not external symbols leak into libCling.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4689
https://github.com/root-project/root/pull/4691:244,Performance,perform,performed,244,"This PR allows to change the minimiser options when doing a second fit or when calling Hesse or Minos. . In case of Hesse the minimizer can also be changed but not in case of Minos, because the minimizer requires a a valid minimisation that is performed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4691
https://github.com/root-project/root/pull/4693:296,Availability,error,error,296,"Due to the way it works by default, sourcing a root version built with; current pyroot was failing, due to the fact that operations such as:. for pyroot_libs_dir in ${old_rootsys}/lib/python*. were performed both in experimental and current. In zsh, if a path specified with '*' is not found, an error like the; following is raised:. clean_environment:20: no matches found: zsh_build/lib/python*. and the program aborts, without sourcing anything. With these change, such loops are performed only if root is built with; pyroot experimental.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4693
https://github.com/root-project/root/pull/4693:198,Performance,perform,performed,198,"Due to the way it works by default, sourcing a root version built with; current pyroot was failing, due to the fact that operations such as:. for pyroot_libs_dir in ${old_rootsys}/lib/python*. were performed both in experimental and current. In zsh, if a path specified with '*' is not found, an error like the; following is raised:. clean_environment:20: no matches found: zsh_build/lib/python*. and the program aborts, without sourcing anything. With these change, such loops are performed only if root is built with; pyroot experimental.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4693
https://github.com/root-project/root/pull/4693:482,Performance,perform,performed,482,"Due to the way it works by default, sourcing a root version built with; current pyroot was failing, due to the fact that operations such as:. for pyroot_libs_dir in ${old_rootsys}/lib/python*. were performed both in experimental and current. In zsh, if a path specified with '*' is not found, an error like the; following is raised:. clean_environment:20: no matches found: zsh_build/lib/python*. and the program aborts, without sourcing anything. With these change, such loops are performed only if root is built with; pyroot experimental.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4693
https://github.com/root-project/root/pull/4693:413,Safety,abort,aborts,413,"Due to the way it works by default, sourcing a root version built with; current pyroot was failing, due to the fact that operations such as:. for pyroot_libs_dir in ${old_rootsys}/lib/python*. were performed both in experimental and current. In zsh, if a path specified with '*' is not found, an error like the; following is raised:. clean_environment:20: no matches found: zsh_build/lib/python*. and the program aborts, without sourcing anything. With these change, such loops are performed only if root is built with; pyroot experimental.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4693
https://github.com/root-project/root/pull/4694:185,Availability,error,error,185,"RooStats was using a global bool to switch on/off offsetting of; likelihoods. Now, this was moved into a function-local static config; struct that now also holds a flag to check if the error wall should be; presented to the minimiser.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4694
https://github.com/root-project/root/pull/4694:127,Modifiability,config,config,127,"RooStats was using a global bool to switch on/off offsetting of; likelihoods. Now, this was moved into a function-local static config; struct that now also holds a flag to check if the error wall should be; presented to the minimiser.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4694
https://github.com/root-project/root/pull/4696:140,Deployability,patch,patch,140,OSX and homebrew in particular creates many symlinks for its libraries. We should resolve to the realpath before scanning for symbols. This patch should reduce the test failues on the experimental runtime_modules support on Mac. Patch by Alexander Penev(@alexander-penev)!,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4696
https://github.com/root-project/root/pull/4696:229,Deployability,Patch,Patch,229,OSX and homebrew in particular creates many symlinks for its libraries. We should resolve to the realpath before scanning for symbols. This patch should reduce the test failues on the experimental runtime_modules support on Mac. Patch by Alexander Penev(@alexander-penev)!,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4696
https://github.com/root-project/root/pull/4696:153,Energy Efficiency,reduce,reduce,153,OSX and homebrew in particular creates many symlinks for its libraries. We should resolve to the realpath before scanning for symbols. This patch should reduce the test failues on the experimental runtime_modules support on Mac. Patch by Alexander Penev(@alexander-penev)!,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4696
https://github.com/root-project/root/pull/4696:164,Testability,test,test,164,OSX and homebrew in particular creates many symlinks for its libraries. We should resolve to the realpath before scanning for symbols. This patch should reduce the test failues on the experimental runtime_modules support on Mac. Patch by Alexander Penev(@alexander-penev)!,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4696
https://github.com/root-project/root/pull/4698:72,Availability,error,error,72,"Hello,. I'm sorry my new classed crashed root.; It seems to me that the error was due to the usauge of C-style variable length arrays that are only supported under g++ and not c++.; The changes I implemented should fix the bug. All the best,; Simon Spies",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4698
https://github.com/root-project/root/pull/4698:111,Modifiability,variab,variable,111,"Hello,. I'm sorry my new classed crashed root.; It seems to me that the error was due to the usauge of C-style variable length arrays that are only supported under g++ and not c++.; The changes I implemented should fix the bug. All the best,; Simon Spies",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4698
https://github.com/root-project/root/pull/4700:72,Modifiability,variab,variables,72,Changes are done to thisroot.sh in order to set the correct environment variables also when CMAKE_INSTALL_PYROOTDIR is specified.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4700
https://github.com/root-project/root/pull/4704:46,Availability,failure,failure,46,The header file is not needed and causes some failure on some architecture when compiling DNN GPU tests. Fix also a warning in a test,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4704
https://github.com/root-project/root/pull/4704:98,Testability,test,tests,98,The header file is not needed and causes some failure on some architecture when compiling DNN GPU tests. Fix also a warning in a test,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4704
https://github.com/root-project/root/pull/4704:129,Testability,test,test,129,The header file is not needed and causes some failure on some architecture when compiling DNN GPU tests. Fix also a warning in a test,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4704
https://github.com/root-project/root/pull/4708:84,Security,access,accessors,84,"As discussed in [ROOT-10409](https://sft.its.cern.ch/jira/browse/ROOT-10409), these accessors are very dangerous and aren't backed by a clear use case right now. Therefore, @Axel-Naumann and I think it's best to just remove them for now.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4708
https://github.com/root-project/root/pull/4708:136,Usability,clear,clear,136,"As discussed in [ROOT-10409](https://sft.its.cern.ch/jira/browse/ROOT-10409), these accessors are very dangerous and aren't backed by a clear use case right now. Therefore, @Axel-Naumann and I think it's best to just remove them for now.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4708
https://github.com/root-project/root/pull/4709:58,Availability,avail,available,58,I would prefer not to have my private mail address online available to everyone.; Please change it to my office mail address.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4709
https://github.com/root-project/root/pull/4710:73,Deployability,install,install,73,"DynamicLibraryManager only looks at LD_LIBRARY_PATH and friends, but for install / prefix; builds that might not point to the ROOT library dir. Make it explicit that the; DynamicLibraryManager is supposed to look at the directory containing ROOT libraries.; Fixes install-with-prefix builds with RPATH, that now do not need a fake LD_LIBRARY_PATH; anymore.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4710
https://github.com/root-project/root/pull/4710:264,Deployability,install,install-with-prefix,264,"DynamicLibraryManager only looks at LD_LIBRARY_PATH and friends, but for install / prefix; builds that might not point to the ROOT library dir. Make it explicit that the; DynamicLibraryManager is supposed to look at the directory containing ROOT libraries.; Fixes install-with-prefix builds with RPATH, that now do not need a fake LD_LIBRARY_PATH; anymore.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4710
https://github.com/root-project/root/pull/4713:22,Deployability,release,releases,22,Fixes Cling's nightly releases sync test.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4713
https://github.com/root-project/root/pull/4713:36,Testability,test,test,36,Fixes Cling's nightly releases sync test.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4713
https://github.com/root-project/root/pull/4717:5,Deployability,patch,patch,5,"This patch consolidates the symbol resolution facilities throughout TCling into; a new singleton class Dyld part of the cling's DynamicLibraryManager. The new dyld is responsible for:; * Symlink resolution -- it implements a memory efficient representation of; the full path to shared objects allowing search at constant time O(1). This; also fixes issues when resolving symbols from OSX where the system libraries; contain multiple levels of symlinks.; * Bloom filter optimization -- it uses a stohastic data structure which gives; a definitive answer if a symbol is not in the set. The implementation checks; the .gnu.hash section in ELF which is the GNU implementation of a bloom; filter and uses it. If the symbol is not in the bloom filter, the; implementation builds its own and uses it. The measured performance of the; bloom filter is 30% speed up for 2mb more memory. The custom bloom filter on; top of the .gnu.hash filter gives 1-2% better performance.; The advantage for the custom bloom filter is that it works on all; implementations which do not support .gnu.hash (windows and osx). It is also; customizable if we want to further reduce the false positive rates; (currently at p=2%).; * Hash table optimization -- we build a hash table which contains all symbols; for a given library. This allows us to avoid the fallback symbol iteration; if multiple symbols from the same library are requested. The hash table; optimization targets to optimize the case where the bloom filter tells us; the symbol is *maybe* in the library. Patch by Alexander Penev (@alexander-penev) and me!. Performance Report; ===. |platform|test|PCH-time|Module-time|Module-PR-time|; |:--------|:---|:---------:|:-----------:|:---------------|; |osx 10.14|roottest-python-pythonizations|22,82|26,89|20,08|; |osx 10.14| roottest-cling| 589,67|452,97|307,34|; |osx 10.14| roottest-python| 377,69|475,78|311,5|; |osx 10.14| roottest-root-hist| 60,59|90,98|49,65|; |osx 10.14| roottest-root-math| 106,18|140,41|73,96|",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4717
https://github.com/root-project/root/pull/4717:1541,Deployability,Patch,Patch,1541,"s not in the set. The implementation checks; the .gnu.hash section in ELF which is the GNU implementation of a bloom; filter and uses it. If the symbol is not in the bloom filter, the; implementation builds its own and uses it. The measured performance of the; bloom filter is 30% speed up for 2mb more memory. The custom bloom filter on; top of the .gnu.hash filter gives 1-2% better performance.; The advantage for the custom bloom filter is that it works on all; implementations which do not support .gnu.hash (windows and osx). It is also; customizable if we want to further reduce the false positive rates; (currently at p=2%).; * Hash table optimization -- we build a hash table which contains all symbols; for a given library. This allows us to avoid the fallback symbol iteration; if multiple symbols from the same library are requested. The hash table; optimization targets to optimize the case where the bloom filter tells us; the symbol is *maybe* in the library. Patch by Alexander Penev (@alexander-penev) and me!. Performance Report; ===. |platform|test|PCH-time|Module-time|Module-PR-time|; |:--------|:---|:---------:|:-----------:|:---------------|; |osx 10.14|roottest-python-pythonizations|22,82|26,89|20,08|; |osx 10.14| roottest-cling| 589,67|452,97|307,34|; |osx 10.14| roottest-python| 377,69|475,78|311,5|; |osx 10.14| roottest-root-hist| 60,59|90,98|49,65|; |osx 10.14| roottest-root-math| 106,18|140,41|73,96|; |osx 10.14| roottest-root-tree| 1287,53|1861|1149,35|; |osx 10.14| roottest-root-treeformula | 568,43|907,46|531|; |osx 10.15| root-io-stdarray| - | 126.02 | 31.42|; |osx 10.15| roottest-root-treeformula| - | 327.08 | 231.14 |. The effect of running ctest -j8:; |platform|test|PCH-time|Module-time|Module-PR-time|; |:--------|:---|:---------:|:-----------:|:---------------|; |osx 10.14|roottest-python-pythonizations|14,45|18,89|13,03|; |osx 10.14| roottest-cling| 88,96|118,94|100,1|; |osx 10.14| roottest-python| 107,57|60,93|100,88|; |osx 10.14| roottest-root-",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4717
https://github.com/root-project/root/pull/4717:232,Energy Efficiency,efficient,efficient,232,"This patch consolidates the symbol resolution facilities throughout TCling into; a new singleton class Dyld part of the cling's DynamicLibraryManager. The new dyld is responsible for:; * Symlink resolution -- it implements a memory efficient representation of; the full path to shared objects allowing search at constant time O(1). This; also fixes issues when resolving symbols from OSX where the system libraries; contain multiple levels of symlinks.; * Bloom filter optimization -- it uses a stohastic data structure which gives; a definitive answer if a symbol is not in the set. The implementation checks; the .gnu.hash section in ELF which is the GNU implementation of a bloom; filter and uses it. If the symbol is not in the bloom filter, the; implementation builds its own and uses it. The measured performance of the; bloom filter is 30% speed up for 2mb more memory. The custom bloom filter on; top of the .gnu.hash filter gives 1-2% better performance.; The advantage for the custom bloom filter is that it works on all; implementations which do not support .gnu.hash (windows and osx). It is also; customizable if we want to further reduce the false positive rates; (currently at p=2%).; * Hash table optimization -- we build a hash table which contains all symbols; for a given library. This allows us to avoid the fallback symbol iteration; if multiple symbols from the same library are requested. The hash table; optimization targets to optimize the case where the bloom filter tells us; the symbol is *maybe* in the library. Patch by Alexander Penev (@alexander-penev) and me!. Performance Report; ===. |platform|test|PCH-time|Module-time|Module-PR-time|; |:--------|:---|:---------:|:-----------:|:---------------|; |osx 10.14|roottest-python-pythonizations|22,82|26,89|20,08|; |osx 10.14| roottest-cling| 589,67|452,97|307,34|; |osx 10.14| roottest-python| 377,69|475,78|311,5|; |osx 10.14| roottest-root-hist| 60,59|90,98|49,65|; |osx 10.14| roottest-root-math| 106,18|140,41|73,96|",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4717
https://github.com/root-project/root/pull/4717:1145,Energy Efficiency,reduce,reduce,1145,"er. The new dyld is responsible for:; * Symlink resolution -- it implements a memory efficient representation of; the full path to shared objects allowing search at constant time O(1). This; also fixes issues when resolving symbols from OSX where the system libraries; contain multiple levels of symlinks.; * Bloom filter optimization -- it uses a stohastic data structure which gives; a definitive answer if a symbol is not in the set. The implementation checks; the .gnu.hash section in ELF which is the GNU implementation of a bloom; filter and uses it. If the symbol is not in the bloom filter, the; implementation builds its own and uses it. The measured performance of the; bloom filter is 30% speed up for 2mb more memory. The custom bloom filter on; top of the .gnu.hash filter gives 1-2% better performance.; The advantage for the custom bloom filter is that it works on all; implementations which do not support .gnu.hash (windows and osx). It is also; customizable if we want to further reduce the false positive rates; (currently at p=2%).; * Hash table optimization -- we build a hash table which contains all symbols; for a given library. This allows us to avoid the fallback symbol iteration; if multiple symbols from the same library are requested. The hash table; optimization targets to optimize the case where the bloom filter tells us; the symbol is *maybe* in the library. Patch by Alexander Penev (@alexander-penev) and me!. Performance Report; ===. |platform|test|PCH-time|Module-time|Module-PR-time|; |:--------|:---|:---------:|:-----------:|:---------------|; |osx 10.14|roottest-python-pythonizations|22,82|26,89|20,08|; |osx 10.14| roottest-cling| 589,67|452,97|307,34|; |osx 10.14| roottest-python| 377,69|475,78|311,5|; |osx 10.14| roottest-root-hist| 60,59|90,98|49,65|; |osx 10.14| roottest-root-math| 106,18|140,41|73,96|; |osx 10.14| roottest-root-tree| 1287,53|1861|1149,35|; |osx 10.14| roottest-root-treeformula | 568,43|907,46|531|; |osx 10.15| root-io-stdarray| ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4717
https://github.com/root-project/root/pull/4717:2908,Energy Efficiency,efficient,efficiently,2908,"ization -- we build a hash table which contains all symbols; for a given library. This allows us to avoid the fallback symbol iteration; if multiple symbols from the same library are requested. The hash table; optimization targets to optimize the case where the bloom filter tells us; the symbol is *maybe* in the library. Patch by Alexander Penev (@alexander-penev) and me!. Performance Report; ===. |platform|test|PCH-time|Module-time|Module-PR-time|; |:--------|:---|:---------:|:-----------:|:---------------|; |osx 10.14|roottest-python-pythonizations|22,82|26,89|20,08|; |osx 10.14| roottest-cling| 589,67|452,97|307,34|; |osx 10.14| roottest-python| 377,69|475,78|311,5|; |osx 10.14| roottest-root-hist| 60,59|90,98|49,65|; |osx 10.14| roottest-root-math| 106,18|140,41|73,96|; |osx 10.14| roottest-root-tree| 1287,53|1861|1149,35|; |osx 10.14| roottest-root-treeformula | 568,43|907,46|531|; |osx 10.15| root-io-stdarray| - | 126.02 | 31.42|; |osx 10.15| roottest-root-treeformula| - | 327.08 | 231.14 |. The effect of running ctest -j8:; |platform|test|PCH-time|Module-time|Module-PR-time|; |:--------|:---|:---------:|:-----------:|:---------------|; |osx 10.14|roottest-python-pythonizations|14,45|18,89|13,03|; |osx 10.14| roottest-cling| 88,96|118,94|100,1|; |osx 10.14| roottest-python| 107,57|60,93|100,88|; |osx 10.14| roottest-root-hist| 10,25|23,25|11,77|; |osx 10.14| roottest-root-math| 8,33|21,23|9,27|; |osx 10.14| roottest-root-tree| 555|840,89|510,97|; |osx 10.14| roottest-root-treeformula | 235,44|402,82|228,91|. We think in `-j8` we lose the advantage of the new PR because the PCH had the rootmaps read in memory and restarting the processes allowed the kernel efficiently reuse that memory. Whereas, the modules and this PR scans the libraries from disk and builds in-memory optimization data structures. Reading from disk seems to be the bottleneck (not verified) but if that's an issue in future we can write out the index making subsequent runs at *almost* zero cost.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4717
https://github.com/root-project/root/pull/4717:469,Performance,optimiz,optimization,469,"This patch consolidates the symbol resolution facilities throughout TCling into; a new singleton class Dyld part of the cling's DynamicLibraryManager. The new dyld is responsible for:; * Symlink resolution -- it implements a memory efficient representation of; the full path to shared objects allowing search at constant time O(1). This; also fixes issues when resolving symbols from OSX where the system libraries; contain multiple levels of symlinks.; * Bloom filter optimization -- it uses a stohastic data structure which gives; a definitive answer if a symbol is not in the set. The implementation checks; the .gnu.hash section in ELF which is the GNU implementation of a bloom; filter and uses it. If the symbol is not in the bloom filter, the; implementation builds its own and uses it. The measured performance of the; bloom filter is 30% speed up for 2mb more memory. The custom bloom filter on; top of the .gnu.hash filter gives 1-2% better performance.; The advantage for the custom bloom filter is that it works on all; implementations which do not support .gnu.hash (windows and osx). It is also; customizable if we want to further reduce the false positive rates; (currently at p=2%).; * Hash table optimization -- we build a hash table which contains all symbols; for a given library. This allows us to avoid the fallback symbol iteration; if multiple symbols from the same library are requested. The hash table; optimization targets to optimize the case where the bloom filter tells us; the symbol is *maybe* in the library. Patch by Alexander Penev (@alexander-penev) and me!. Performance Report; ===. |platform|test|PCH-time|Module-time|Module-PR-time|; |:--------|:---|:---------:|:-----------:|:---------------|; |osx 10.14|roottest-python-pythonizations|22,82|26,89|20,08|; |osx 10.14| roottest-cling| 589,67|452,97|307,34|; |osx 10.14| roottest-python| 377,69|475,78|311,5|; |osx 10.14| roottest-root-hist| 60,59|90,98|49,65|; |osx 10.14| roottest-root-math| 106,18|140,41|73,96|",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4717
https://github.com/root-project/root/pull/4717:807,Performance,perform,performance,807,"This patch consolidates the symbol resolution facilities throughout TCling into; a new singleton class Dyld part of the cling's DynamicLibraryManager. The new dyld is responsible for:; * Symlink resolution -- it implements a memory efficient representation of; the full path to shared objects allowing search at constant time O(1). This; also fixes issues when resolving symbols from OSX where the system libraries; contain multiple levels of symlinks.; * Bloom filter optimization -- it uses a stohastic data structure which gives; a definitive answer if a symbol is not in the set. The implementation checks; the .gnu.hash section in ELF which is the GNU implementation of a bloom; filter and uses it. If the symbol is not in the bloom filter, the; implementation builds its own and uses it. The measured performance of the; bloom filter is 30% speed up for 2mb more memory. The custom bloom filter on; top of the .gnu.hash filter gives 1-2% better performance.; The advantage for the custom bloom filter is that it works on all; implementations which do not support .gnu.hash (windows and osx). It is also; customizable if we want to further reduce the false positive rates; (currently at p=2%).; * Hash table optimization -- we build a hash table which contains all symbols; for a given library. This allows us to avoid the fallback symbol iteration; if multiple symbols from the same library are requested. The hash table; optimization targets to optimize the case where the bloom filter tells us; the symbol is *maybe* in the library. Patch by Alexander Penev (@alexander-penev) and me!. Performance Report; ===. |platform|test|PCH-time|Module-time|Module-PR-time|; |:--------|:---|:---------:|:-----------:|:---------------|; |osx 10.14|roottest-python-pythonizations|22,82|26,89|20,08|; |osx 10.14| roottest-cling| 589,67|452,97|307,34|; |osx 10.14| roottest-python| 377,69|475,78|311,5|; |osx 10.14| roottest-root-hist| 60,59|90,98|49,65|; |osx 10.14| roottest-root-math| 106,18|140,41|73,96|",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4717
https://github.com/root-project/root/pull/4717:951,Performance,perform,performance,951,"This patch consolidates the symbol resolution facilities throughout TCling into; a new singleton class Dyld part of the cling's DynamicLibraryManager. The new dyld is responsible for:; * Symlink resolution -- it implements a memory efficient representation of; the full path to shared objects allowing search at constant time O(1). This; also fixes issues when resolving symbols from OSX where the system libraries; contain multiple levels of symlinks.; * Bloom filter optimization -- it uses a stohastic data structure which gives; a definitive answer if a symbol is not in the set. The implementation checks; the .gnu.hash section in ELF which is the GNU implementation of a bloom; filter and uses it. If the symbol is not in the bloom filter, the; implementation builds its own and uses it. The measured performance of the; bloom filter is 30% speed up for 2mb more memory. The custom bloom filter on; top of the .gnu.hash filter gives 1-2% better performance.; The advantage for the custom bloom filter is that it works on all; implementations which do not support .gnu.hash (windows and osx). It is also; customizable if we want to further reduce the false positive rates; (currently at p=2%).; * Hash table optimization -- we build a hash table which contains all symbols; for a given library. This allows us to avoid the fallback symbol iteration; if multiple symbols from the same library are requested. The hash table; optimization targets to optimize the case where the bloom filter tells us; the symbol is *maybe* in the library. Patch by Alexander Penev (@alexander-penev) and me!. Performance Report; ===. |platform|test|PCH-time|Module-time|Module-PR-time|; |:--------|:---|:---------:|:-----------:|:---------------|; |osx 10.14|roottest-python-pythonizations|22,82|26,89|20,08|; |osx 10.14| roottest-cling| 589,67|452,97|307,34|; |osx 10.14| roottest-python| 377,69|475,78|311,5|; |osx 10.14| roottest-root-hist| 60,59|90,98|49,65|; |osx 10.14| roottest-root-math| 106,18|140,41|73,96|",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4717
https://github.com/root-project/root/pull/4717:1213,Performance,optimiz,optimization,1213,"entation of; the full path to shared objects allowing search at constant time O(1). This; also fixes issues when resolving symbols from OSX where the system libraries; contain multiple levels of symlinks.; * Bloom filter optimization -- it uses a stohastic data structure which gives; a definitive answer if a symbol is not in the set. The implementation checks; the .gnu.hash section in ELF which is the GNU implementation of a bloom; filter and uses it. If the symbol is not in the bloom filter, the; implementation builds its own and uses it. The measured performance of the; bloom filter is 30% speed up for 2mb more memory. The custom bloom filter on; top of the .gnu.hash filter gives 1-2% better performance.; The advantage for the custom bloom filter is that it works on all; implementations which do not support .gnu.hash (windows and osx). It is also; customizable if we want to further reduce the false positive rates; (currently at p=2%).; * Hash table optimization -- we build a hash table which contains all symbols; for a given library. This allows us to avoid the fallback symbol iteration; if multiple symbols from the same library are requested. The hash table; optimization targets to optimize the case where the bloom filter tells us; the symbol is *maybe* in the library. Patch by Alexander Penev (@alexander-penev) and me!. Performance Report; ===. |platform|test|PCH-time|Module-time|Module-PR-time|; |:--------|:---|:---------:|:-----------:|:---------------|; |osx 10.14|roottest-python-pythonizations|22,82|26,89|20,08|; |osx 10.14| roottest-cling| 589,67|452,97|307,34|; |osx 10.14| roottest-python| 377,69|475,78|311,5|; |osx 10.14| roottest-root-hist| 60,59|90,98|49,65|; |osx 10.14| roottest-root-math| 106,18|140,41|73,96|; |osx 10.14| roottest-root-tree| 1287,53|1861|1149,35|; |osx 10.14| roottest-root-treeformula | 568,43|907,46|531|; |osx 10.15| root-io-stdarray| - | 126.02 | 31.42|; |osx 10.15| roottest-root-treeformula| - | 327.08 | 231.14 |. The effect of runn",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4717
https://github.com/root-project/root/pull/4717:1428,Performance,optimiz,optimization,1428,"zation -- it uses a stohastic data structure which gives; a definitive answer if a symbol is not in the set. The implementation checks; the .gnu.hash section in ELF which is the GNU implementation of a bloom; filter and uses it. If the symbol is not in the bloom filter, the; implementation builds its own and uses it. The measured performance of the; bloom filter is 30% speed up for 2mb more memory. The custom bloom filter on; top of the .gnu.hash filter gives 1-2% better performance.; The advantage for the custom bloom filter is that it works on all; implementations which do not support .gnu.hash (windows and osx). It is also; customizable if we want to further reduce the false positive rates; (currently at p=2%).; * Hash table optimization -- we build a hash table which contains all symbols; for a given library. This allows us to avoid the fallback symbol iteration; if multiple symbols from the same library are requested. The hash table; optimization targets to optimize the case where the bloom filter tells us; the symbol is *maybe* in the library. Patch by Alexander Penev (@alexander-penev) and me!. Performance Report; ===. |platform|test|PCH-time|Module-time|Module-PR-time|; |:--------|:---|:---------:|:-----------:|:---------------|; |osx 10.14|roottest-python-pythonizations|22,82|26,89|20,08|; |osx 10.14| roottest-cling| 589,67|452,97|307,34|; |osx 10.14| roottest-python| 377,69|475,78|311,5|; |osx 10.14| roottest-root-hist| 60,59|90,98|49,65|; |osx 10.14| roottest-root-math| 106,18|140,41|73,96|; |osx 10.14| roottest-root-tree| 1287,53|1861|1149,35|; |osx 10.14| roottest-root-treeformula | 568,43|907,46|531|; |osx 10.15| root-io-stdarray| - | 126.02 | 31.42|; |osx 10.15| roottest-root-treeformula| - | 327.08 | 231.14 |. The effect of running ctest -j8:; |platform|test|PCH-time|Module-time|Module-PR-time|; |:--------|:---|:---------:|:-----------:|:---------------|; |osx 10.14|roottest-python-pythonizations|14,45|18,89|13,03|; |osx 10.14| roottest-cling| 88,96|1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4717
https://github.com/root-project/root/pull/4717:1452,Performance,optimiz,optimize,1452,"zation -- it uses a stohastic data structure which gives; a definitive answer if a symbol is not in the set. The implementation checks; the .gnu.hash section in ELF which is the GNU implementation of a bloom; filter and uses it. If the symbol is not in the bloom filter, the; implementation builds its own and uses it. The measured performance of the; bloom filter is 30% speed up for 2mb more memory. The custom bloom filter on; top of the .gnu.hash filter gives 1-2% better performance.; The advantage for the custom bloom filter is that it works on all; implementations which do not support .gnu.hash (windows and osx). It is also; customizable if we want to further reduce the false positive rates; (currently at p=2%).; * Hash table optimization -- we build a hash table which contains all symbols; for a given library. This allows us to avoid the fallback symbol iteration; if multiple symbols from the same library are requested. The hash table; optimization targets to optimize the case where the bloom filter tells us; the symbol is *maybe* in the library. Patch by Alexander Penev (@alexander-penev) and me!. Performance Report; ===. |platform|test|PCH-time|Module-time|Module-PR-time|; |:--------|:---|:---------:|:-----------:|:---------------|; |osx 10.14|roottest-python-pythonizations|22,82|26,89|20,08|; |osx 10.14| roottest-cling| 589,67|452,97|307,34|; |osx 10.14| roottest-python| 377,69|475,78|311,5|; |osx 10.14| roottest-root-hist| 60,59|90,98|49,65|; |osx 10.14| roottest-root-math| 106,18|140,41|73,96|; |osx 10.14| roottest-root-tree| 1287,53|1861|1149,35|; |osx 10.14| roottest-root-treeformula | 568,43|907,46|531|; |osx 10.15| root-io-stdarray| - | 126.02 | 31.42|; |osx 10.15| roottest-root-treeformula| - | 327.08 | 231.14 |. The effect of running ctest -j8:; |platform|test|PCH-time|Module-time|Module-PR-time|; |:--------|:---|:---------:|:-----------:|:---------------|; |osx 10.14|roottest-python-pythonizations|14,45|18,89|13,03|; |osx 10.14| roottest-cling| 88,96|1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4717
https://github.com/root-project/root/pull/4717:1594,Performance,Perform,Performance,1594,"ecks; the .gnu.hash section in ELF which is the GNU implementation of a bloom; filter and uses it. If the symbol is not in the bloom filter, the; implementation builds its own and uses it. The measured performance of the; bloom filter is 30% speed up for 2mb more memory. The custom bloom filter on; top of the .gnu.hash filter gives 1-2% better performance.; The advantage for the custom bloom filter is that it works on all; implementations which do not support .gnu.hash (windows and osx). It is also; customizable if we want to further reduce the false positive rates; (currently at p=2%).; * Hash table optimization -- we build a hash table which contains all symbols; for a given library. This allows us to avoid the fallback symbol iteration; if multiple symbols from the same library are requested. The hash table; optimization targets to optimize the case where the bloom filter tells us; the symbol is *maybe* in the library. Patch by Alexander Penev (@alexander-penev) and me!. Performance Report; ===. |platform|test|PCH-time|Module-time|Module-PR-time|; |:--------|:---|:---------:|:-----------:|:---------------|; |osx 10.14|roottest-python-pythonizations|22,82|26,89|20,08|; |osx 10.14| roottest-cling| 589,67|452,97|307,34|; |osx 10.14| roottest-python| 377,69|475,78|311,5|; |osx 10.14| roottest-root-hist| 60,59|90,98|49,65|; |osx 10.14| roottest-root-math| 106,18|140,41|73,96|; |osx 10.14| roottest-root-tree| 1287,53|1861|1149,35|; |osx 10.14| roottest-root-treeformula | 568,43|907,46|531|; |osx 10.15| root-io-stdarray| - | 126.02 | 31.42|; |osx 10.15| roottest-root-treeformula| - | 327.08 | 231.14 |. The effect of running ctest -j8:; |platform|test|PCH-time|Module-time|Module-PR-time|; |:--------|:---|:---------:|:-----------:|:---------------|; |osx 10.14|roottest-python-pythonizations|14,45|18,89|13,03|; |osx 10.14| roottest-cling| 88,96|118,94|100,1|; |osx 10.14| roottest-python| 107,57|60,93|100,88|; |osx 10.14| roottest-root-hist| 10,25|23,25|11,77|; |osx 10.14| r",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4717
https://github.com/root-project/root/pull/4717:3023,Performance,optimiz,optimization,3023,"ization -- we build a hash table which contains all symbols; for a given library. This allows us to avoid the fallback symbol iteration; if multiple symbols from the same library are requested. The hash table; optimization targets to optimize the case where the bloom filter tells us; the symbol is *maybe* in the library. Patch by Alexander Penev (@alexander-penev) and me!. Performance Report; ===. |platform|test|PCH-time|Module-time|Module-PR-time|; |:--------|:---|:---------:|:-----------:|:---------------|; |osx 10.14|roottest-python-pythonizations|22,82|26,89|20,08|; |osx 10.14| roottest-cling| 589,67|452,97|307,34|; |osx 10.14| roottest-python| 377,69|475,78|311,5|; |osx 10.14| roottest-root-hist| 60,59|90,98|49,65|; |osx 10.14| roottest-root-math| 106,18|140,41|73,96|; |osx 10.14| roottest-root-tree| 1287,53|1861|1149,35|; |osx 10.14| roottest-root-treeformula | 568,43|907,46|531|; |osx 10.15| root-io-stdarray| - | 126.02 | 31.42|; |osx 10.15| roottest-root-treeformula| - | 327.08 | 231.14 |. The effect of running ctest -j8:; |platform|test|PCH-time|Module-time|Module-PR-time|; |:--------|:---|:---------:|:-----------:|:---------------|; |osx 10.14|roottest-python-pythonizations|14,45|18,89|13,03|; |osx 10.14| roottest-cling| 88,96|118,94|100,1|; |osx 10.14| roottest-python| 107,57|60,93|100,88|; |osx 10.14| roottest-root-hist| 10,25|23,25|11,77|; |osx 10.14| roottest-root-math| 8,33|21,23|9,27|; |osx 10.14| roottest-root-tree| 555|840,89|510,97|; |osx 10.14| roottest-root-treeformula | 235,44|402,82|228,91|. We think in `-j8` we lose the advantage of the new PR because the PCH had the rootmaps read in memory and restarting the processes allowed the kernel efficiently reuse that memory. Whereas, the modules and this PR scans the libraries from disk and builds in-memory optimization data structures. Reading from disk seems to be the bottleneck (not verified) but if that's an issue in future we can write out the index making subsequent runs at *almost* zero cost.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4717
https://github.com/root-project/root/pull/4717:3087,Performance,bottleneck,bottleneck,3087,"ization -- we build a hash table which contains all symbols; for a given library. This allows us to avoid the fallback symbol iteration; if multiple symbols from the same library are requested. The hash table; optimization targets to optimize the case where the bloom filter tells us; the symbol is *maybe* in the library. Patch by Alexander Penev (@alexander-penev) and me!. Performance Report; ===. |platform|test|PCH-time|Module-time|Module-PR-time|; |:--------|:---|:---------:|:-----------:|:---------------|; |osx 10.14|roottest-python-pythonizations|22,82|26,89|20,08|; |osx 10.14| roottest-cling| 589,67|452,97|307,34|; |osx 10.14| roottest-python| 377,69|475,78|311,5|; |osx 10.14| roottest-root-hist| 60,59|90,98|49,65|; |osx 10.14| roottest-root-math| 106,18|140,41|73,96|; |osx 10.14| roottest-root-tree| 1287,53|1861|1149,35|; |osx 10.14| roottest-root-treeformula | 568,43|907,46|531|; |osx 10.15| root-io-stdarray| - | 126.02 | 31.42|; |osx 10.15| roottest-root-treeformula| - | 327.08 | 231.14 |. The effect of running ctest -j8:; |platform|test|PCH-time|Module-time|Module-PR-time|; |:--------|:---|:---------:|:-----------:|:---------------|; |osx 10.14|roottest-python-pythonizations|14,45|18,89|13,03|; |osx 10.14| roottest-cling| 88,96|118,94|100,1|; |osx 10.14| roottest-python| 107,57|60,93|100,88|; |osx 10.14| roottest-root-hist| 10,25|23,25|11,77|; |osx 10.14| roottest-root-math| 8,33|21,23|9,27|; |osx 10.14| roottest-root-tree| 555|840,89|510,97|; |osx 10.14| roottest-root-treeformula | 235,44|402,82|228,91|. We think in `-j8` we lose the advantage of the new PR because the PCH had the rootmaps read in memory and restarting the processes allowed the kernel efficiently reuse that memory. Whereas, the modules and this PR scans the libraries from disk and builds in-memory optimization data structures. Reading from disk seems to be the bottleneck (not verified) but if that's an issue in future we can write out the index making subsequent runs at *almost* zero cost.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4717
https://github.com/root-project/root/pull/4717:1318,Safety,avoid,avoid,1318," when resolving symbols from OSX where the system libraries; contain multiple levels of symlinks.; * Bloom filter optimization -- it uses a stohastic data structure which gives; a definitive answer if a symbol is not in the set. The implementation checks; the .gnu.hash section in ELF which is the GNU implementation of a bloom; filter and uses it. If the symbol is not in the bloom filter, the; implementation builds its own and uses it. The measured performance of the; bloom filter is 30% speed up for 2mb more memory. The custom bloom filter on; top of the .gnu.hash filter gives 1-2% better performance.; The advantage for the custom bloom filter is that it works on all; implementations which do not support .gnu.hash (windows and osx). It is also; customizable if we want to further reduce the false positive rates; (currently at p=2%).; * Hash table optimization -- we build a hash table which contains all symbols; for a given library. This allows us to avoid the fallback symbol iteration; if multiple symbols from the same library are requested. The hash table; optimization targets to optimize the case where the bloom filter tells us; the symbol is *maybe* in the library. Patch by Alexander Penev (@alexander-penev) and me!. Performance Report; ===. |platform|test|PCH-time|Module-time|Module-PR-time|; |:--------|:---|:---------:|:-----------:|:---------------|; |osx 10.14|roottest-python-pythonizations|22,82|26,89|20,08|; |osx 10.14| roottest-cling| 589,67|452,97|307,34|; |osx 10.14| roottest-python| 377,69|475,78|311,5|; |osx 10.14| roottest-root-hist| 60,59|90,98|49,65|; |osx 10.14| roottest-root-math| 106,18|140,41|73,96|; |osx 10.14| roottest-root-tree| 1287,53|1861|1149,35|; |osx 10.14| roottest-root-treeformula | 568,43|907,46|531|; |osx 10.15| root-io-stdarray| - | 126.02 | 31.42|; |osx 10.15| roottest-root-treeformula| - | 327.08 | 231.14 |. The effect of running ctest -j8:; |platform|test|PCH-time|Module-time|Module-PR-time|; |:--------|:---|:---------:|:--------",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4717
https://github.com/root-project/root/pull/4717:620,Security,hash,hash,620,"This patch consolidates the symbol resolution facilities throughout TCling into; a new singleton class Dyld part of the cling's DynamicLibraryManager. The new dyld is responsible for:; * Symlink resolution -- it implements a memory efficient representation of; the full path to shared objects allowing search at constant time O(1). This; also fixes issues when resolving symbols from OSX where the system libraries; contain multiple levels of symlinks.; * Bloom filter optimization -- it uses a stohastic data structure which gives; a definitive answer if a symbol is not in the set. The implementation checks; the .gnu.hash section in ELF which is the GNU implementation of a bloom; filter and uses it. If the symbol is not in the bloom filter, the; implementation builds its own and uses it. The measured performance of the; bloom filter is 30% speed up for 2mb more memory. The custom bloom filter on; top of the .gnu.hash filter gives 1-2% better performance.; The advantage for the custom bloom filter is that it works on all; implementations which do not support .gnu.hash (windows and osx). It is also; customizable if we want to further reduce the false positive rates; (currently at p=2%).; * Hash table optimization -- we build a hash table which contains all symbols; for a given library. This allows us to avoid the fallback symbol iteration; if multiple symbols from the same library are requested. The hash table; optimization targets to optimize the case where the bloom filter tells us; the symbol is *maybe* in the library. Patch by Alexander Penev (@alexander-penev) and me!. Performance Report; ===. |platform|test|PCH-time|Module-time|Module-PR-time|; |:--------|:---|:---------:|:-----------:|:---------------|; |osx 10.14|roottest-python-pythonizations|22,82|26,89|20,08|; |osx 10.14| roottest-cling| 589,67|452,97|307,34|; |osx 10.14| roottest-python| 377,69|475,78|311,5|; |osx 10.14| roottest-root-hist| 60,59|90,98|49,65|; |osx 10.14| roottest-root-math| 106,18|140,41|73,96|",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4717
https://github.com/root-project/root/pull/4717:921,Security,hash,hash,921,"This patch consolidates the symbol resolution facilities throughout TCling into; a new singleton class Dyld part of the cling's DynamicLibraryManager. The new dyld is responsible for:; * Symlink resolution -- it implements a memory efficient representation of; the full path to shared objects allowing search at constant time O(1). This; also fixes issues when resolving symbols from OSX where the system libraries; contain multiple levels of symlinks.; * Bloom filter optimization -- it uses a stohastic data structure which gives; a definitive answer if a symbol is not in the set. The implementation checks; the .gnu.hash section in ELF which is the GNU implementation of a bloom; filter and uses it. If the symbol is not in the bloom filter, the; implementation builds its own and uses it. The measured performance of the; bloom filter is 30% speed up for 2mb more memory. The custom bloom filter on; top of the .gnu.hash filter gives 1-2% better performance.; The advantage for the custom bloom filter is that it works on all; implementations which do not support .gnu.hash (windows and osx). It is also; customizable if we want to further reduce the false positive rates; (currently at p=2%).; * Hash table optimization -- we build a hash table which contains all symbols; for a given library. This allows us to avoid the fallback symbol iteration; if multiple symbols from the same library are requested. The hash table; optimization targets to optimize the case where the bloom filter tells us; the symbol is *maybe* in the library. Patch by Alexander Penev (@alexander-penev) and me!. Performance Report; ===. |platform|test|PCH-time|Module-time|Module-PR-time|; |:--------|:---|:---------:|:-----------:|:---------------|; |osx 10.14|roottest-python-pythonizations|22,82|26,89|20,08|; |osx 10.14| roottest-cling| 589,67|452,97|307,34|; |osx 10.14| roottest-python| 377,69|475,78|311,5|; |osx 10.14| roottest-root-hist| 60,59|90,98|49,65|; |osx 10.14| roottest-root-math| 106,18|140,41|73,96|",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4717
https://github.com/root-project/root/pull/4717:1074,Security,hash,hash,1074,"w singleton class Dyld part of the cling's DynamicLibraryManager. The new dyld is responsible for:; * Symlink resolution -- it implements a memory efficient representation of; the full path to shared objects allowing search at constant time O(1). This; also fixes issues when resolving symbols from OSX where the system libraries; contain multiple levels of symlinks.; * Bloom filter optimization -- it uses a stohastic data structure which gives; a definitive answer if a symbol is not in the set. The implementation checks; the .gnu.hash section in ELF which is the GNU implementation of a bloom; filter and uses it. If the symbol is not in the bloom filter, the; implementation builds its own and uses it. The measured performance of the; bloom filter is 30% speed up for 2mb more memory. The custom bloom filter on; top of the .gnu.hash filter gives 1-2% better performance.; The advantage for the custom bloom filter is that it works on all; implementations which do not support .gnu.hash (windows and osx). It is also; customizable if we want to further reduce the false positive rates; (currently at p=2%).; * Hash table optimization -- we build a hash table which contains all symbols; for a given library. This allows us to avoid the fallback symbol iteration; if multiple symbols from the same library are requested. The hash table; optimization targets to optimize the case where the bloom filter tells us; the symbol is *maybe* in the library. Patch by Alexander Penev (@alexander-penev) and me!. Performance Report; ===. |platform|test|PCH-time|Module-time|Module-PR-time|; |:--------|:---|:---------:|:-----------:|:---------------|; |osx 10.14|roottest-python-pythonizations|22,82|26,89|20,08|; |osx 10.14| roottest-cling| 589,67|452,97|307,34|; |osx 10.14| roottest-python| 377,69|475,78|311,5|; |osx 10.14| roottest-root-hist| 60,59|90,98|49,65|; |osx 10.14| roottest-root-math| 106,18|140,41|73,96|; |osx 10.14| roottest-root-tree| 1287,53|1861|1149,35|; |osx 10.14| roottest-root-tr",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4717
https://github.com/root-project/root/pull/4717:1202,Security,Hash,Hash,1202,"entation of; the full path to shared objects allowing search at constant time O(1). This; also fixes issues when resolving symbols from OSX where the system libraries; contain multiple levels of symlinks.; * Bloom filter optimization -- it uses a stohastic data structure which gives; a definitive answer if a symbol is not in the set. The implementation checks; the .gnu.hash section in ELF which is the GNU implementation of a bloom; filter and uses it. If the symbol is not in the bloom filter, the; implementation builds its own and uses it. The measured performance of the; bloom filter is 30% speed up for 2mb more memory. The custom bloom filter on; top of the .gnu.hash filter gives 1-2% better performance.; The advantage for the custom bloom filter is that it works on all; implementations which do not support .gnu.hash (windows and osx). It is also; customizable if we want to further reduce the false positive rates; (currently at p=2%).; * Hash table optimization -- we build a hash table which contains all symbols; for a given library. This allows us to avoid the fallback symbol iteration; if multiple symbols from the same library are requested. The hash table; optimization targets to optimize the case where the bloom filter tells us; the symbol is *maybe* in the library. Patch by Alexander Penev (@alexander-penev) and me!. Performance Report; ===. |platform|test|PCH-time|Module-time|Module-PR-time|; |:--------|:---|:---------:|:-----------:|:---------------|; |osx 10.14|roottest-python-pythonizations|22,82|26,89|20,08|; |osx 10.14| roottest-cling| 589,67|452,97|307,34|; |osx 10.14| roottest-python| 377,69|475,78|311,5|; |osx 10.14| roottest-root-hist| 60,59|90,98|49,65|; |osx 10.14| roottest-root-math| 106,18|140,41|73,96|; |osx 10.14| roottest-root-tree| 1287,53|1861|1149,35|; |osx 10.14| roottest-root-treeformula | 568,43|907,46|531|; |osx 10.15| root-io-stdarray| - | 126.02 | 31.42|; |osx 10.15| roottest-root-treeformula| - | 327.08 | 231.14 |. The effect of runn",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4717
https://github.com/root-project/root/pull/4717:1240,Security,hash,hash,1240,"entation of; the full path to shared objects allowing search at constant time O(1). This; also fixes issues when resolving symbols from OSX where the system libraries; contain multiple levels of symlinks.; * Bloom filter optimization -- it uses a stohastic data structure which gives; a definitive answer if a symbol is not in the set. The implementation checks; the .gnu.hash section in ELF which is the GNU implementation of a bloom; filter and uses it. If the symbol is not in the bloom filter, the; implementation builds its own and uses it. The measured performance of the; bloom filter is 30% speed up for 2mb more memory. The custom bloom filter on; top of the .gnu.hash filter gives 1-2% better performance.; The advantage for the custom bloom filter is that it works on all; implementations which do not support .gnu.hash (windows and osx). It is also; customizable if we want to further reduce the false positive rates; (currently at p=2%).; * Hash table optimization -- we build a hash table which contains all symbols; for a given library. This allows us to avoid the fallback symbol iteration; if multiple symbols from the same library are requested. The hash table; optimization targets to optimize the case where the bloom filter tells us; the symbol is *maybe* in the library. Patch by Alexander Penev (@alexander-penev) and me!. Performance Report; ===. |platform|test|PCH-time|Module-time|Module-PR-time|; |:--------|:---|:---------:|:-----------:|:---------------|; |osx 10.14|roottest-python-pythonizations|22,82|26,89|20,08|; |osx 10.14| roottest-cling| 589,67|452,97|307,34|; |osx 10.14| roottest-python| 377,69|475,78|311,5|; |osx 10.14| roottest-root-hist| 60,59|90,98|49,65|; |osx 10.14| roottest-root-math| 106,18|140,41|73,96|; |osx 10.14| roottest-root-tree| 1287,53|1861|1149,35|; |osx 10.14| roottest-root-treeformula | 568,43|907,46|531|; |osx 10.15| root-io-stdarray| - | 126.02 | 31.42|; |osx 10.15| roottest-root-treeformula| - | 327.08 | 231.14 |. The effect of runn",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4717
https://github.com/root-project/root/pull/4717:1416,Security,hash,hash,1416,"zation -- it uses a stohastic data structure which gives; a definitive answer if a symbol is not in the set. The implementation checks; the .gnu.hash section in ELF which is the GNU implementation of a bloom; filter and uses it. If the symbol is not in the bloom filter, the; implementation builds its own and uses it. The measured performance of the; bloom filter is 30% speed up for 2mb more memory. The custom bloom filter on; top of the .gnu.hash filter gives 1-2% better performance.; The advantage for the custom bloom filter is that it works on all; implementations which do not support .gnu.hash (windows and osx). It is also; customizable if we want to further reduce the false positive rates; (currently at p=2%).; * Hash table optimization -- we build a hash table which contains all symbols; for a given library. This allows us to avoid the fallback symbol iteration; if multiple symbols from the same library are requested. The hash table; optimization targets to optimize the case where the bloom filter tells us; the symbol is *maybe* in the library. Patch by Alexander Penev (@alexander-penev) and me!. Performance Report; ===. |platform|test|PCH-time|Module-time|Module-PR-time|; |:--------|:---|:---------:|:-----------:|:---------------|; |osx 10.14|roottest-python-pythonizations|22,82|26,89|20,08|; |osx 10.14| roottest-cling| 589,67|452,97|307,34|; |osx 10.14| roottest-python| 377,69|475,78|311,5|; |osx 10.14| roottest-root-hist| 60,59|90,98|49,65|; |osx 10.14| roottest-root-math| 106,18|140,41|73,96|; |osx 10.14| roottest-root-tree| 1287,53|1861|1149,35|; |osx 10.14| roottest-root-treeformula | 568,43|907,46|531|; |osx 10.15| root-io-stdarray| - | 126.02 | 31.42|; |osx 10.15| roottest-root-treeformula| - | 327.08 | 231.14 |. The effect of running ctest -j8:; |platform|test|PCH-time|Module-time|Module-PR-time|; |:--------|:---|:---------:|:-----------:|:---------------|; |osx 10.14|roottest-python-pythonizations|14,45|18,89|13,03|; |osx 10.14| roottest-cling| 88,96|1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4717
https://github.com/root-project/root/pull/4717:1629,Testability,test,test,1629,"oom; filter and uses it. If the symbol is not in the bloom filter, the; implementation builds its own and uses it. The measured performance of the; bloom filter is 30% speed up for 2mb more memory. The custom bloom filter on; top of the .gnu.hash filter gives 1-2% better performance.; The advantage for the custom bloom filter is that it works on all; implementations which do not support .gnu.hash (windows and osx). It is also; customizable if we want to further reduce the false positive rates; (currently at p=2%).; * Hash table optimization -- we build a hash table which contains all symbols; for a given library. This allows us to avoid the fallback symbol iteration; if multiple symbols from the same library are requested. The hash table; optimization targets to optimize the case where the bloom filter tells us; the symbol is *maybe* in the library. Patch by Alexander Penev (@alexander-penev) and me!. Performance Report; ===. |platform|test|PCH-time|Module-time|Module-PR-time|; |:--------|:---|:---------:|:-----------:|:---------------|; |osx 10.14|roottest-python-pythonizations|22,82|26,89|20,08|; |osx 10.14| roottest-cling| 589,67|452,97|307,34|; |osx 10.14| roottest-python| 377,69|475,78|311,5|; |osx 10.14| roottest-root-hist| 60,59|90,98|49,65|; |osx 10.14| roottest-root-math| 106,18|140,41|73,96|; |osx 10.14| roottest-root-tree| 1287,53|1861|1149,35|; |osx 10.14| roottest-root-treeformula | 568,43|907,46|531|; |osx 10.15| root-io-stdarray| - | 126.02 | 31.42|; |osx 10.15| roottest-root-treeformula| - | 327.08 | 231.14 |. The effect of running ctest -j8:; |platform|test|PCH-time|Module-time|Module-PR-time|; |:--------|:---|:---------:|:-----------:|:---------------|; |osx 10.14|roottest-python-pythonizations|14,45|18,89|13,03|; |osx 10.14| roottest-cling| 88,96|118,94|100,1|; |osx 10.14| roottest-python| 107,57|60,93|100,88|; |osx 10.14| roottest-root-hist| 10,25|23,25|11,77|; |osx 10.14| roottest-root-math| 8,33|21,23|9,27|; |osx 10.14| roottest-root-tree| 555|8",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4717
https://github.com/root-project/root/pull/4717:2275,Testability,test,test,2275,"ization -- we build a hash table which contains all symbols; for a given library. This allows us to avoid the fallback symbol iteration; if multiple symbols from the same library are requested. The hash table; optimization targets to optimize the case where the bloom filter tells us; the symbol is *maybe* in the library. Patch by Alexander Penev (@alexander-penev) and me!. Performance Report; ===. |platform|test|PCH-time|Module-time|Module-PR-time|; |:--------|:---|:---------:|:-----------:|:---------------|; |osx 10.14|roottest-python-pythonizations|22,82|26,89|20,08|; |osx 10.14| roottest-cling| 589,67|452,97|307,34|; |osx 10.14| roottest-python| 377,69|475,78|311,5|; |osx 10.14| roottest-root-hist| 60,59|90,98|49,65|; |osx 10.14| roottest-root-math| 106,18|140,41|73,96|; |osx 10.14| roottest-root-tree| 1287,53|1861|1149,35|; |osx 10.14| roottest-root-treeformula | 568,43|907,46|531|; |osx 10.15| root-io-stdarray| - | 126.02 | 31.42|; |osx 10.15| roottest-root-treeformula| - | 327.08 | 231.14 |. The effect of running ctest -j8:; |platform|test|PCH-time|Module-time|Module-PR-time|; |:--------|:---|:---------:|:-----------:|:---------------|; |osx 10.14|roottest-python-pythonizations|14,45|18,89|13,03|; |osx 10.14| roottest-cling| 88,96|118,94|100,1|; |osx 10.14| roottest-python| 107,57|60,93|100,88|; |osx 10.14| roottest-root-hist| 10,25|23,25|11,77|; |osx 10.14| roottest-root-math| 8,33|21,23|9,27|; |osx 10.14| roottest-root-tree| 555|840,89|510,97|; |osx 10.14| roottest-root-treeformula | 235,44|402,82|228,91|. We think in `-j8` we lose the advantage of the new PR because the PCH had the rootmaps read in memory and restarting the processes allowed the kernel efficiently reuse that memory. Whereas, the modules and this PR scans the libraries from disk and builds in-memory optimization data structures. Reading from disk seems to be the bottleneck (not verified) but if that's an issue in future we can write out the index making subsequent runs at *almost* zero cost.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4717
https://github.com/root-project/root/pull/4718:354,Availability,error,error,354,"Jira: https://sft.its.cern.ch/jira/browse/ROOT-10491. We miss the test for reading boolean branches with `RDataFrame.AsNumpy`! Added the test and start investigating when it breaks - such as reported in the Jira ticket. Following the discussion on the forum [here](https://root-forum.cern.ch/t/asnumpy-fails-with-boolean-branches/37282), we see that the error shows a missing `data` member for the `std::vector<bool>`:. ```; df.AsNumpy(); ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-10-e856f5516a02> in <module>(); ----> 1 df.AsNumpy(). /Applications/root_build/lib/ROOT.pyc in _RDataFrameAsNumpy(df, columns, exclude); 429 else:; 430 tmp = numpy.empty(len(cpp_reference), dtype=numpy.object); --> 431 for i, x in enumerate(cpp_reference):; 432 tmp[i] = x # This creates only the wrapping of the objects and does not copy.; 433 py_arrays[column] = ndarray(tmp, result_ptrs[column]). AttributeError: 'vector<bool>' object has no attribute 'data'; ```. The error seems to be triggered when iterating over `std::vector<bool>` in python. My guess is some weirdness in the given std version of macOS 10.15. @etejedor We should add a test for this at the right place not only for `AsNumpy`. Edit: Added a fix for current PyROOT by protecting the tp_iter field for `vector<bool>`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4718
https://github.com/root-project/root/pull/4718:1053,Availability,error,error,1053,"Jira: https://sft.its.cern.ch/jira/browse/ROOT-10491. We miss the test for reading boolean branches with `RDataFrame.AsNumpy`! Added the test and start investigating when it breaks - such as reported in the Jira ticket. Following the discussion on the forum [here](https://root-forum.cern.ch/t/asnumpy-fails-with-boolean-branches/37282), we see that the error shows a missing `data` member for the `std::vector<bool>`:. ```; df.AsNumpy(); ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-10-e856f5516a02> in <module>(); ----> 1 df.AsNumpy(). /Applications/root_build/lib/ROOT.pyc in _RDataFrameAsNumpy(df, columns, exclude); 429 else:; 430 tmp = numpy.empty(len(cpp_reference), dtype=numpy.object); --> 431 for i, x in enumerate(cpp_reference):; 432 tmp[i] = x # This creates only the wrapping of the objects and does not copy.; 433 py_arrays[column] = ndarray(tmp, result_ptrs[column]). AttributeError: 'vector<bool>' object has no attribute 'data'; ```. The error seems to be triggered when iterating over `std::vector<bool>` in python. My guess is some weirdness in the given std version of macOS 10.15. @etejedor We should add a test for this at the right place not only for `AsNumpy`. Edit: Added a fix for current PyROOT by protecting the tp_iter field for `vector<bool>`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4718
https://github.com/root-project/root/pull/4718:878,Integrability,wrap,wrapping,878,"Jira: https://sft.its.cern.ch/jira/browse/ROOT-10491. We miss the test for reading boolean branches with `RDataFrame.AsNumpy`! Added the test and start investigating when it breaks - such as reported in the Jira ticket. Following the discussion on the forum [here](https://root-forum.cern.ch/t/asnumpy-fails-with-boolean-branches/37282), we see that the error shows a missing `data` member for the `std::vector<bool>`:. ```; df.AsNumpy(); ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-10-e856f5516a02> in <module>(); ----> 1 df.AsNumpy(). /Applications/root_build/lib/ROOT.pyc in _RDataFrameAsNumpy(df, columns, exclude); 429 else:; 430 tmp = numpy.empty(len(cpp_reference), dtype=numpy.object); --> 431 for i, x in enumerate(cpp_reference):; 432 tmp[i] = x # This creates only the wrapping of the objects and does not copy.; 433 py_arrays[column] = ndarray(tmp, result_ptrs[column]). AttributeError: 'vector<bool>' object has no attribute 'data'; ```. The error seems to be triggered when iterating over `std::vector<bool>` in python. My guess is some weirdness in the given std version of macOS 10.15. @etejedor We should add a test for this at the right place not only for `AsNumpy`. Edit: Added a fix for current PyROOT by protecting the tp_iter field for `vector<bool>`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4718
https://github.com/root-project/root/pull/4718:66,Testability,test,test,66,"Jira: https://sft.its.cern.ch/jira/browse/ROOT-10491. We miss the test for reading boolean branches with `RDataFrame.AsNumpy`! Added the test and start investigating when it breaks - such as reported in the Jira ticket. Following the discussion on the forum [here](https://root-forum.cern.ch/t/asnumpy-fails-with-boolean-branches/37282), we see that the error shows a missing `data` member for the `std::vector<bool>`:. ```; df.AsNumpy(); ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-10-e856f5516a02> in <module>(); ----> 1 df.AsNumpy(). /Applications/root_build/lib/ROOT.pyc in _RDataFrameAsNumpy(df, columns, exclude); 429 else:; 430 tmp = numpy.empty(len(cpp_reference), dtype=numpy.object); --> 431 for i, x in enumerate(cpp_reference):; 432 tmp[i] = x # This creates only the wrapping of the objects and does not copy.; 433 py_arrays[column] = ndarray(tmp, result_ptrs[column]). AttributeError: 'vector<bool>' object has no attribute 'data'; ```. The error seems to be triggered when iterating over `std::vector<bool>` in python. My guess is some weirdness in the given std version of macOS 10.15. @etejedor We should add a test for this at the right place not only for `AsNumpy`. Edit: Added a fix for current PyROOT by protecting the tp_iter field for `vector<bool>`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4718
https://github.com/root-project/root/pull/4718:137,Testability,test,test,137,"Jira: https://sft.its.cern.ch/jira/browse/ROOT-10491. We miss the test for reading boolean branches with `RDataFrame.AsNumpy`! Added the test and start investigating when it breaks - such as reported in the Jira ticket. Following the discussion on the forum [here](https://root-forum.cern.ch/t/asnumpy-fails-with-boolean-branches/37282), we see that the error shows a missing `data` member for the `std::vector<bool>`:. ```; df.AsNumpy(); ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-10-e856f5516a02> in <module>(); ----> 1 df.AsNumpy(). /Applications/root_build/lib/ROOT.pyc in _RDataFrameAsNumpy(df, columns, exclude); 429 else:; 430 tmp = numpy.empty(len(cpp_reference), dtype=numpy.object); --> 431 for i, x in enumerate(cpp_reference):; 432 tmp[i] = x # This creates only the wrapping of the objects and does not copy.; 433 py_arrays[column] = ndarray(tmp, result_ptrs[column]). AttributeError: 'vector<bool>' object has no attribute 'data'; ```. The error seems to be triggered when iterating over `std::vector<bool>` in python. My guess is some weirdness in the given std version of macOS 10.15. @etejedor We should add a test for this at the right place not only for `AsNumpy`. Edit: Added a fix for current PyROOT by protecting the tp_iter field for `vector<bool>`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4718
https://github.com/root-project/root/pull/4718:1226,Testability,test,test,1226,"Jira: https://sft.its.cern.ch/jira/browse/ROOT-10491. We miss the test for reading boolean branches with `RDataFrame.AsNumpy`! Added the test and start investigating when it breaks - such as reported in the Jira ticket. Following the discussion on the forum [here](https://root-forum.cern.ch/t/asnumpy-fails-with-boolean-branches/37282), we see that the error shows a missing `data` member for the `std::vector<bool>`:. ```; df.AsNumpy(); ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-10-e856f5516a02> in <module>(); ----> 1 df.AsNumpy(). /Applications/root_build/lib/ROOT.pyc in _RDataFrameAsNumpy(df, columns, exclude); 429 else:; 430 tmp = numpy.empty(len(cpp_reference), dtype=numpy.object); --> 431 for i, x in enumerate(cpp_reference):; 432 tmp[i] = x # This creates only the wrapping of the objects and does not copy.; 433 py_arrays[column] = ndarray(tmp, result_ptrs[column]). AttributeError: 'vector<bool>' object has no attribute 'data'; ```. The error seems to be triggered when iterating over `std::vector<bool>` in python. My guess is some weirdness in the given std version of macOS 10.15. @etejedor We should add a test for this at the right place not only for `AsNumpy`. Edit: Added a fix for current PyROOT by protecting the tp_iter field for `vector<bool>`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4718
https://github.com/root-project/root/pull/4721:13,Deployability,patch,patch,13,"Hello,. this patch adds the possibility to specify a line width to be used when markers are drawn. Recently I stumbled upon this and searched for an already existing solution, but I could only find other people looking for something like this, so I decided to implement it. Before I start to describe the changes, let me mention the most important point first: I only tested the feature under Linux, since I have neigther a ROOT installation under Windows nor a Mac. Since the feature also changes files associated with drawing under Windows and MacOS, I consider it absolutly mandatory to test the feature under those systems before merging this pull request. Now back to the actual feature. Since an image says more than 1000 words here an image of the outcome using the implemented feature which is also part of the feature description in the class TAttMarker:; ![c](https://user-images.githubusercontent.com/5320187/71742710-ee6cc580-2e62-11ea-900d-ba546e27f474.png). **The attribute fMarkerLineWidth**; The storing of the parameter is done by the attribute fMarkerLineWidth of the TAttMarker class. I checked all daughter classes of TAttMarker for the need of changes due to this addition. Furthermore, I added a line width dropdown field to the TAttMarkerEditor which works the same way as in the TAttLineEditor. Obviosly the line width only makes sense for marker styles that consist of lines and not areas. To check whether the currently set marker style is influenced by the marker line width I added the function HasMarkerLineWidth to TAttMarker. **Marker size and draw method**; Since the calculation of the size of the marker assumed ultimatly thin lines up to now, the bounding box of the marker would have increased when setting a larger marker line width. To counter that, I decreased the marker size by the amount it would have increased due to the line width. However, note that this only works with round line caps and round line joins, since for example with miter joins the boundin",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4721
https://github.com/root-project/root/pull/4721:429,Deployability,install,installation,429,"Hello,. this patch adds the possibility to specify a line width to be used when markers are drawn. Recently I stumbled upon this and searched for an already existing solution, but I could only find other people looking for something like this, so I decided to implement it. Before I start to describe the changes, let me mention the most important point first: I only tested the feature under Linux, since I have neigther a ROOT installation under Windows nor a Mac. Since the feature also changes files associated with drawing under Windows and MacOS, I consider it absolutly mandatory to test the feature under those systems before merging this pull request. Now back to the actual feature. Since an image says more than 1000 words here an image of the outcome using the implemented feature which is also part of the feature description in the class TAttMarker:; ![c](https://user-images.githubusercontent.com/5320187/71742710-ee6cc580-2e62-11ea-900d-ba546e27f474.png). **The attribute fMarkerLineWidth**; The storing of the parameter is done by the attribute fMarkerLineWidth of the TAttMarker class. I checked all daughter classes of TAttMarker for the need of changes due to this addition. Furthermore, I added a line width dropdown field to the TAttMarkerEditor which works the same way as in the TAttLineEditor. Obviosly the line width only makes sense for marker styles that consist of lines and not areas. To check whether the currently set marker style is influenced by the marker line width I added the function HasMarkerLineWidth to TAttMarker. **Marker size and draw method**; Since the calculation of the size of the marker assumed ultimatly thin lines up to now, the bounding box of the marker would have increased when setting a larger marker line width. To counter that, I decreased the marker size by the amount it would have increased due to the line width. However, note that this only works with round line caps and round line joins, since for example with miter joins the boundin",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4721
https://github.com/root-project/root/pull/4721:2587,Integrability,depend,depending,2587,"arker style is influenced by the marker line width I added the function HasMarkerLineWidth to TAttMarker. **Marker size and draw method**; Since the calculation of the size of the marker assumed ultimatly thin lines up to now, the bounding box of the marker would have increased when setting a larger marker line width. To counter that, I decreased the marker size by the amount it would have increased due to the line width. However, note that this only works with round line caps and round line joins, since for example with miter joins the bounding box becomes infinitly large for infinitly small angles. This is also the reason why I decided to used round caps and round joins when drawing the marker lines in a TPad. However for the vector graphic export classes the line join method is set by gStyle->GetJoinLinePS(). Since there was no corresponding implementation for the line cap, I added it to TStyle. Furthermore, the line join method setting was ignored by the SVG export until now, so I decided to add it there as well. **Further changes**; Another thing I noted is that the markers 3 and 5 (and 31) were looking different depending on whether they were drawn by a class based on TVirtualPadPainter or based on TVirtualPS. Furthermore the behaviour for marker styles 9-19 were different between the implementations. (You can see the differences when you compare the canvas created by `TMarker::DisplayMarkerTypes()` with the marker style example picture in the class reference of TAttMarker.); I thought that the marker style definition used by classes based on TVirtualPadPainter seems better than the one by classes based on TVirtualPS. However, if you think that the definition of classes based on TVirtualPS is more correct, I can change this quickly but would then propose to also change definition in the TVirtualPadPainter classes since the markers should look the same everywhere. If you have any further recommendations please let me know.; Thanks and all the best,; Simon Spies",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4721
https://github.com/root-project/root/pull/4721:368,Testability,test,tested,368,"Hello,. this patch adds the possibility to specify a line width to be used when markers are drawn. Recently I stumbled upon this and searched for an already existing solution, but I could only find other people looking for something like this, so I decided to implement it. Before I start to describe the changes, let me mention the most important point first: I only tested the feature under Linux, since I have neigther a ROOT installation under Windows nor a Mac. Since the feature also changes files associated with drawing under Windows and MacOS, I consider it absolutly mandatory to test the feature under those systems before merging this pull request. Now back to the actual feature. Since an image says more than 1000 words here an image of the outcome using the implemented feature which is also part of the feature description in the class TAttMarker:; ![c](https://user-images.githubusercontent.com/5320187/71742710-ee6cc580-2e62-11ea-900d-ba546e27f474.png). **The attribute fMarkerLineWidth**; The storing of the parameter is done by the attribute fMarkerLineWidth of the TAttMarker class. I checked all daughter classes of TAttMarker for the need of changes due to this addition. Furthermore, I added a line width dropdown field to the TAttMarkerEditor which works the same way as in the TAttLineEditor. Obviosly the line width only makes sense for marker styles that consist of lines and not areas. To check whether the currently set marker style is influenced by the marker line width I added the function HasMarkerLineWidth to TAttMarker. **Marker size and draw method**; Since the calculation of the size of the marker assumed ultimatly thin lines up to now, the bounding box of the marker would have increased when setting a larger marker line width. To counter that, I decreased the marker size by the amount it would have increased due to the line width. However, note that this only works with round line caps and round line joins, since for example with miter joins the boundin",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4721
https://github.com/root-project/root/pull/4721:590,Testability,test,test,590,"Hello,. this patch adds the possibility to specify a line width to be used when markers are drawn. Recently I stumbled upon this and searched for an already existing solution, but I could only find other people looking for something like this, so I decided to implement it. Before I start to describe the changes, let me mention the most important point first: I only tested the feature under Linux, since I have neigther a ROOT installation under Windows nor a Mac. Since the feature also changes files associated with drawing under Windows and MacOS, I consider it absolutly mandatory to test the feature under those systems before merging this pull request. Now back to the actual feature. Since an image says more than 1000 words here an image of the outcome using the implemented feature which is also part of the feature description in the class TAttMarker:; ![c](https://user-images.githubusercontent.com/5320187/71742710-ee6cc580-2e62-11ea-900d-ba546e27f474.png). **The attribute fMarkerLineWidth**; The storing of the parameter is done by the attribute fMarkerLineWidth of the TAttMarker class. I checked all daughter classes of TAttMarker for the need of changes due to this addition. Furthermore, I added a line width dropdown field to the TAttMarkerEditor which works the same way as in the TAttLineEditor. Obviosly the line width only makes sense for marker styles that consist of lines and not areas. To check whether the currently set marker style is influenced by the marker line width I added the function HasMarkerLineWidth to TAttMarker. **Marker size and draw method**; Since the calculation of the size of the marker assumed ultimatly thin lines up to now, the bounding box of the marker would have increased when setting a larger marker line width. To counter that, I decreased the marker size by the amount it would have increased due to the line width. However, note that this only works with round line caps and round line joins, since for example with miter joins the boundin",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4721
https://github.com/root-project/root/pull/4722:190,Availability,avail,available,190,libNew is a custom memory allocator used in ROOT to output more information about memory pressure. It essentially overrides the new and delete operators. The functionality of libNew is only available in *rootn.exe* and libNew is statically linked to the binary. In root-project/root#4717 we discovered that dlopening libNew at random time can trigger earthquakes because it allows the dynamic linker to *sometimes* resolve new and delete to the symbols from libNew and libc++. Since libNew was not designed to be dlopened we should make it a static library to enforce this protocol more strongly.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4722
https://github.com/root-project/root/pull/4722:573,Integrability,protocol,protocol,573,libNew is a custom memory allocator used in ROOT to output more information about memory pressure. It essentially overrides the new and delete operators. The functionality of libNew is only available in *rootn.exe* and libNew is statically linked to the binary. In root-project/root#4717 we discovered that dlopening libNew at random time can trigger earthquakes because it allows the dynamic linker to *sometimes* resolve new and delete to the symbols from libNew and libc++. Since libNew was not designed to be dlopened we should make it a static library to enforce this protocol more strongly.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4722
https://github.com/root-project/root/pull/4727:25,Availability,avail,available,25,"The compiler flag is not available in clang, tested with clang9.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4727
https://github.com/root-project/root/pull/4727:45,Testability,test,tested,45,"The compiler flag is not available in clang, tested with clang9.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4727
https://github.com/root-project/root/pull/4731:41,Integrability,protocol,protocol,41,"tp_iter is used to implement an iterator protocol for Python using the; ""data"" member function of std::vector. However, the specialization; `vector<bool>` is not required to have this member function, which; breaks the iterator. Removing the tp_iter field does not break iterating; vector<bool> in Python, it falls back to the old iterator mechanism via; the get/setitem special functions.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4731
https://github.com/root-project/root/pull/4734:0,Integrability,Depend,Depending,0,"Depending from selected file extension, show only appropriate files; Preliminary windows support in RFileDialog",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4734
https://github.com/root-project/root/pull/4735:82,Integrability,message,message,82,This fixes the deprecation taken root-project/root#4716. We print the deprecation message but we still do what's intended. cc: @reikdas,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4735
https://github.com/root-project/root/pull/4737:213,Safety,safe,safe,213,"Warnings appear due to PEP 590 adding the tp_vectorcall field to some; structs which remain uninitialized in CPyCppyy. Following the conventions upstream, because the standard ensures a; zero-initialization, it's safe the leave them uninitialized such as also; done in the Python codebase itself. See discussion here:; https://bitbucket.org/wlav/cppyy/issues/186/warnings-with-python-38-due-to-vectorcall",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4737
https://github.com/root-project/root/pull/4738:393,Deployability,Patch,Patch,393,libNew is a custom memory allocator used in ROOT to output more information about memory pressure and used for interprocess communication in TMapFile. It essentially overrides the new and delete operators. We discovered that dlopening libNew at random time can trigger earthquakes because it allows the dynamic linker to sometimes resolve new and delete to the symbols from libNew and libc++. Patch by Alexander Penev (@alexander-penev) and me!,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4738
https://github.com/root-project/root/pull/4739:162,Availability,error,error,162,"Several small issues came up in the forum, and this is a collection of documentation updates, a few safety checks added to roofit and more understandable warning/error messages. Further, the class RooRealProxy (kind of a pointer with extra functionality) has been replaced by a templated class, as it always requires casting when the pointed-to object is used. Since it is internal to RooFit, this should not affect users.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4739
https://github.com/root-project/root/pull/4739:85,Deployability,update,updates,85,"Several small issues came up in the forum, and this is a collection of documentation updates, a few safety checks added to roofit and more understandable warning/error messages. Further, the class RooRealProxy (kind of a pointer with extra functionality) has been replaced by a templated class, as it always requires casting when the pointed-to object is used. Since it is internal to RooFit, this should not affect users.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4739
https://github.com/root-project/root/pull/4739:168,Integrability,message,messages,168,"Several small issues came up in the forum, and this is a collection of documentation updates, a few safety checks added to roofit and more understandable warning/error messages. Further, the class RooRealProxy (kind of a pointer with extra functionality) has been replaced by a templated class, as it always requires casting when the pointed-to object is used. Since it is internal to RooFit, this should not affect users.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4739
https://github.com/root-project/root/pull/4739:100,Safety,safe,safety,100,"Several small issues came up in the forum, and this is a collection of documentation updates, a few safety checks added to roofit and more understandable warning/error messages. Further, the class RooRealProxy (kind of a pointer with extra functionality) has been replaced by a templated class, as it always requires casting when the pointed-to object is used. Since it is internal to RooFit, this should not affect users.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4739
https://github.com/root-project/root/pull/4740:0,Usability,Simpl,Simple,0,"Simple grammar fix correcting ""to"" to ""too"" and adjusting confusing period usage.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4740
https://github.com/root-project/root/pull/4742:41,Availability,avail,available,41,"The non-modules system iterates over all available rootmap files and adds their libraries as potential dependencies to the library which ACLiC builds. The built library relies on the explicit linking to load its dependencies when it is dlopened. This is necessary because we have no other way to resolve symbols. Fortunately, the modules dynamic linker has superior symbol resolution. We can rely on it when loading a shared library. This patch fixes failing tests on OSX when runtime_cxxmodules are on.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4742
https://github.com/root-project/root/pull/4742:439,Deployability,patch,patch,439,"The non-modules system iterates over all available rootmap files and adds their libraries as potential dependencies to the library which ACLiC builds. The built library relies on the explicit linking to load its dependencies when it is dlopened. This is necessary because we have no other way to resolve symbols. Fortunately, the modules dynamic linker has superior symbol resolution. We can rely on it when loading a shared library. This patch fixes failing tests on OSX when runtime_cxxmodules are on.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4742
https://github.com/root-project/root/pull/4742:103,Integrability,depend,dependencies,103,"The non-modules system iterates over all available rootmap files and adds their libraries as potential dependencies to the library which ACLiC builds. The built library relies on the explicit linking to load its dependencies when it is dlopened. This is necessary because we have no other way to resolve symbols. Fortunately, the modules dynamic linker has superior symbol resolution. We can rely on it when loading a shared library. This patch fixes failing tests on OSX when runtime_cxxmodules are on.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4742
https://github.com/root-project/root/pull/4742:212,Integrability,depend,dependencies,212,"The non-modules system iterates over all available rootmap files and adds their libraries as potential dependencies to the library which ACLiC builds. The built library relies on the explicit linking to load its dependencies when it is dlopened. This is necessary because we have no other way to resolve symbols. Fortunately, the modules dynamic linker has superior symbol resolution. We can rely on it when loading a shared library. This patch fixes failing tests on OSX when runtime_cxxmodules are on.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4742
https://github.com/root-project/root/pull/4742:203,Performance,load,load,203,"The non-modules system iterates over all available rootmap files and adds their libraries as potential dependencies to the library which ACLiC builds. The built library relies on the explicit linking to load its dependencies when it is dlopened. This is necessary because we have no other way to resolve symbols. Fortunately, the modules dynamic linker has superior symbol resolution. We can rely on it when loading a shared library. This patch fixes failing tests on OSX when runtime_cxxmodules are on.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4742
https://github.com/root-project/root/pull/4742:408,Performance,load,loading,408,"The non-modules system iterates over all available rootmap files and adds their libraries as potential dependencies to the library which ACLiC builds. The built library relies on the explicit linking to load its dependencies when it is dlopened. This is necessary because we have no other way to resolve symbols. Fortunately, the modules dynamic linker has superior symbol resolution. We can rely on it when loading a shared library. This patch fixes failing tests on OSX when runtime_cxxmodules are on.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4742
https://github.com/root-project/root/pull/4742:459,Testability,test,tests,459,"The non-modules system iterates over all available rootmap files and adds their libraries as potential dependencies to the library which ACLiC builds. The built library relies on the explicit linking to load its dependencies when it is dlopened. This is necessary because we have no other way to resolve symbols. Fortunately, the modules dynamic linker has superior symbol resolution. We can rely on it when loading a shared library. This patch fixes failing tests on OSX when runtime_cxxmodules are on.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4742
https://github.com/root-project/root/pull/4744:91,Modifiability,config,configure,91,"1. List all windows volumes like C:, Q:,...; 2. Resolve windows links when appears; 3. Let configure file types in FileDialog (also when starts from client)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4744
https://github.com/root-project/root/pull/4747:414,Deployability,update,updates,414,"The following PR introduced some changes in the TCling shutdown; logic:; https://github.com/root-project/root/pull/4675. One of these changes affects clingwrapper.cxx in Cppyy, but the; functionality it relies on (TROOT::Initialize) is not yet in the; mini-ROOT of Cppyy, which is at the moment working with ROOT 6.18,; so we cannot push the clingwrapper change to upstream Cppyy now. For that reason, until Cppyy updates its ROOT to 6.20, we need to; keep this patch to modify our copy of Cppyy to invoke; TROOT::Initialize in the constructor of ApplicationStarter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4747
https://github.com/root-project/root/pull/4747:462,Deployability,patch,patch,462,"The following PR introduced some changes in the TCling shutdown; logic:; https://github.com/root-project/root/pull/4675. One of these changes affects clingwrapper.cxx in Cppyy, but the; functionality it relies on (TROOT::Initialize) is not yet in the; mini-ROOT of Cppyy, which is at the moment working with ROOT 6.18,; so we cannot push the clingwrapper change to upstream Cppyy now. For that reason, until Cppyy updates its ROOT to 6.20, we need to; keep this patch to modify our copy of Cppyy to invoke; TROOT::Initialize in the constructor of ApplicationStarter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4747
https://github.com/root-project/root/pull/4747:65,Testability,log,logic,65,"The following PR introduced some changes in the TCling shutdown; logic:; https://github.com/root-project/root/pull/4675. One of these changes affects clingwrapper.cxx in Cppyy, but the; functionality it relies on (TROOT::Initialize) is not yet in the; mini-ROOT of Cppyy, which is at the moment working with ROOT 6.18,; so we cannot push the clingwrapper change to upstream Cppyy now. For that reason, until Cppyy updates its ROOT to 6.20, we need to; keep this patch to modify our copy of Cppyy to invoke; TROOT::Initialize in the constructor of ApplicationStarter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4747
https://github.com/root-project/root/pull/4748:140,Deployability,install,installation,140,"As reported in:. https://sft.its.cern.ch/jira/projects/ROOT/issues/ROOT-10501?filter=allopenissues. commit 1d2e76 deletes the host's Python installation. Here two conditions are introduced to run the command:. - the flag pyroot_experimental was specified during the configuration;; - the variable CMAKE_INSTALL_PREFIX doesn't start with ""/usr"", making; the command run only if the above mentioned variable was customized.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4748
https://github.com/root-project/root/pull/4748:266,Deployability,configurat,configuration,266,"As reported in:. https://sft.its.cern.ch/jira/projects/ROOT/issues/ROOT-10501?filter=allopenissues. commit 1d2e76 deletes the host's Python installation. Here two conditions are introduced to run the command:. - the flag pyroot_experimental was specified during the configuration;; - the variable CMAKE_INSTALL_PREFIX doesn't start with ""/usr"", making; the command run only if the above mentioned variable was customized.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4748
https://github.com/root-project/root/pull/4748:266,Modifiability,config,configuration,266,"As reported in:. https://sft.its.cern.ch/jira/projects/ROOT/issues/ROOT-10501?filter=allopenissues. commit 1d2e76 deletes the host's Python installation. Here two conditions are introduced to run the command:. - the flag pyroot_experimental was specified during the configuration;; - the variable CMAKE_INSTALL_PREFIX doesn't start with ""/usr"", making; the command run only if the above mentioned variable was customized.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4748
https://github.com/root-project/root/pull/4748:288,Modifiability,variab,variable,288,"As reported in:. https://sft.its.cern.ch/jira/projects/ROOT/issues/ROOT-10501?filter=allopenissues. commit 1d2e76 deletes the host's Python installation. Here two conditions are introduced to run the command:. - the flag pyroot_experimental was specified during the configuration;; - the variable CMAKE_INSTALL_PREFIX doesn't start with ""/usr"", making; the command run only if the above mentioned variable was customized.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4748
https://github.com/root-project/root/pull/4748:397,Modifiability,variab,variable,397,"As reported in:. https://sft.its.cern.ch/jira/projects/ROOT/issues/ROOT-10501?filter=allopenissues. commit 1d2e76 deletes the host's Python installation. Here two conditions are introduced to run the command:. - the flag pyroot_experimental was specified during the configuration;; - the variable CMAKE_INSTALL_PREFIX doesn't start with ""/usr"", making; the command run only if the above mentioned variable was customized.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4748
https://github.com/root-project/root/pull/4749:114,Modifiability,plugin,plugin,114,See [this comment](https://sft.its.cern.ch/jira/browse/ROOT-10472?focusedCommentId=106666&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-106666) on JIRA for an explanation. Closes #4702.; Closes #4750.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4749
https://github.com/root-project/root/pull/4750:114,Modifiability,plugin,plugin,114,See [this comment](https://sft.its.cern.ch/jira/browse/ROOT-10472?focusedCommentId=106666&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-106666) on JIRA for an explanation. Closes #4702.; Closes #4749.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4750
https://github.com/root-project/root/pull/4751:102,Deployability,install,install,102,"Due to the default behavior of CMake. https://gitlab.kitware.com/cmake/cmake/issues/17122. when using install(DIRECTORY ... PATTERN), if there are some folders; that don't contain the given PATTERN they are also created as empty; folders. This was causing the problem already addressed in 1d2e76. As suggested in. https://stackoverflow.com/questions/55451084/cmake-files-matching-pattern-copies-empty-directories/55722518#55722518. we apply the workaround consisting in addressing the '*pcm' files with; file(GLOB ...) and then install them with install(FILES ...).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4751
https://github.com/root-project/root/pull/4751:528,Deployability,install,install,528,"Due to the default behavior of CMake. https://gitlab.kitware.com/cmake/cmake/issues/17122. when using install(DIRECTORY ... PATTERN), if there are some folders; that don't contain the given PATTERN they are also created as empty; folders. This was causing the problem already addressed in 1d2e76. As suggested in. https://stackoverflow.com/questions/55451084/cmake-files-matching-pattern-copies-empty-directories/55722518#55722518. we apply the workaround consisting in addressing the '*pcm' files with; file(GLOB ...) and then install them with install(FILES ...).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4751
https://github.com/root-project/root/pull/4751:546,Deployability,install,install,546,"Due to the default behavior of CMake. https://gitlab.kitware.com/cmake/cmake/issues/17122. when using install(DIRECTORY ... PATTERN), if there are some folders; that don't contain the given PATTERN they are also created as empty; folders. This was causing the problem already addressed in 1d2e76. As suggested in. https://stackoverflow.com/questions/55451084/cmake-files-matching-pattern-copies-empty-directories/55722518#55722518. we apply the workaround consisting in addressing the '*pcm' files with; file(GLOB ...) and then install them with install(FILES ...).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4751
https://github.com/root-project/root/pull/4752:10,Availability,error,errors,10,"Fixes the errors currently seen when building for conda. After the build `pyc` files are generated and this step fails for some of the tutorials with the following errors:; ```; compiling .pyc files...; File ""tutorials/pyroot/gui_ex.py"", line 20; print 'returning 0'; ^; SyntaxError: Missing parentheses in call to 'print'. Did you mean print('returning 0')?. File ""tutorials/pyroot/parse_CSV_file_with_TTree_ReadStream.py"", line 92; print ""Outputting %s -> %s"" % (afile, output_ROOT_file_name); ^; SyntaxError: invalid syntax. Sorry: TabError: inconsistent use of tabs and spaces in indentation (ROOTwriter.py, line 63); File ""tutorials/histfactory/makeQuickModel.py"", line 114; print ""It seems that pyROOT isn't properly configured""; ^; SyntaxError: Missing parentheses in call to 'print'. Did you mean print(""It seems that pyROOT isn't properly configured"")?. Sorry: TabError: inconsistent use of tabs and spaces in indentation (writer.py, line 123); number of files: 6175; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4752
https://github.com/root-project/root/pull/4752:164,Availability,error,errors,164,"Fixes the errors currently seen when building for conda. After the build `pyc` files are generated and this step fails for some of the tutorials with the following errors:; ```; compiling .pyc files...; File ""tutorials/pyroot/gui_ex.py"", line 20; print 'returning 0'; ^; SyntaxError: Missing parentheses in call to 'print'. Did you mean print('returning 0')?. File ""tutorials/pyroot/parse_CSV_file_with_TTree_ReadStream.py"", line 92; print ""Outputting %s -> %s"" % (afile, output_ROOT_file_name); ^; SyntaxError: invalid syntax. Sorry: TabError: inconsistent use of tabs and spaces in indentation (ROOTwriter.py, line 63); File ""tutorials/histfactory/makeQuickModel.py"", line 114; print ""It seems that pyROOT isn't properly configured""; ^; SyntaxError: Missing parentheses in call to 'print'. Did you mean print(""It seems that pyROOT isn't properly configured"")?. Sorry: TabError: inconsistent use of tabs and spaces in indentation (writer.py, line 123); number of files: 6175; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4752
https://github.com/root-project/root/pull/4752:723,Modifiability,config,configured,723,"Fixes the errors currently seen when building for conda. After the build `pyc` files are generated and this step fails for some of the tutorials with the following errors:; ```; compiling .pyc files...; File ""tutorials/pyroot/gui_ex.py"", line 20; print 'returning 0'; ^; SyntaxError: Missing parentheses in call to 'print'. Did you mean print('returning 0')?. File ""tutorials/pyroot/parse_CSV_file_with_TTree_ReadStream.py"", line 92; print ""Outputting %s -> %s"" % (afile, output_ROOT_file_name); ^; SyntaxError: invalid syntax. Sorry: TabError: inconsistent use of tabs and spaces in indentation (ROOTwriter.py, line 63); File ""tutorials/histfactory/makeQuickModel.py"", line 114; print ""It seems that pyROOT isn't properly configured""; ^; SyntaxError: Missing parentheses in call to 'print'. Did you mean print(""It seems that pyROOT isn't properly configured"")?. Sorry: TabError: inconsistent use of tabs and spaces in indentation (writer.py, line 123); number of files: 6175; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4752
https://github.com/root-project/root/pull/4752:848,Modifiability,config,configured,848,"Fixes the errors currently seen when building for conda. After the build `pyc` files are generated and this step fails for some of the tutorials with the following errors:; ```; compiling .pyc files...; File ""tutorials/pyroot/gui_ex.py"", line 20; print 'returning 0'; ^; SyntaxError: Missing parentheses in call to 'print'. Did you mean print('returning 0')?. File ""tutorials/pyroot/parse_CSV_file_with_TTree_ReadStream.py"", line 92; print ""Outputting %s -> %s"" % (afile, output_ROOT_file_name); ^; SyntaxError: invalid syntax. Sorry: TabError: inconsistent use of tabs and spaces in indentation (ROOTwriter.py, line 63); File ""tutorials/histfactory/makeQuickModel.py"", line 114; print ""It seems that pyROOT isn't properly configured""; ^; SyntaxError: Missing parentheses in call to 'print'. Did you mean print(""It seems that pyROOT isn't properly configured"")?. Sorry: TabError: inconsistent use of tabs and spaces in indentation (writer.py, line 123); number of files: 6175; ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4752
https://github.com/root-project/root/pull/4755:67,Availability,error,error-bars-drawn-in-wrong-place-if-setlogx,67,Fixes the issue raised in the [forum](https://root-forum.cern.ch/t/error-bars-drawn-in-wrong-place-if-setlogx/37507?u=mwilkins) where error bars were drawn in the wrong place if using a log scale in x.; Resolves the [JIRA task](https://sft.its.cern.ch/jira/browse/ROOT-10505).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4755
https://github.com/root-project/root/pull/4755:134,Availability,error,error,134,Fixes the issue raised in the [forum](https://root-forum.cern.ch/t/error-bars-drawn-in-wrong-place-if-setlogx/37507?u=mwilkins) where error bars were drawn in the wrong place if using a log scale in x.; Resolves the [JIRA task](https://sft.its.cern.ch/jira/browse/ROOT-10505).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4755
https://github.com/root-project/root/pull/4755:186,Testability,log,log,186,Fixes the issue raised in the [forum](https://root-forum.cern.ch/t/error-bars-drawn-in-wrong-place-if-setlogx/37507?u=mwilkins) where error bars were drawn in the wrong place if using a log scale in x.; Resolves the [JIRA task](https://sft.its.cern.ch/jira/browse/ROOT-10505).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4755
https://github.com/root-project/root/pull/4756:23,Deployability,update,updated,23,"'wmat' values were not updated when the function is called with nlmat<0, as they; should be to mimic the Geant3 behaviour. This fix should be also propagated to the patches branch. Thank you.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4756
https://github.com/root-project/root/pull/4756:165,Deployability,patch,patches,165,"'wmat' values were not updated when the function is called with nlmat<0, as they; should be to mimic the Geant3 behaviour. This fix should be also propagated to the patches branch. Thank you.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4756
https://github.com/root-project/root/pull/4757:139,Deployability,patch,patching,139,As discussed with @Axel-Naumann on mattermost: https://mattermost.web.cern.ch/root/pl/3en1hqnc9tbftqakg3s3jy4b4c. The conda build has been patching this out since it was first released. There was some issues when building with `runtime_cxxmodules` but those were fixed in #4710.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4757
https://github.com/root-project/root/pull/4757:176,Deployability,release,released,176,As discussed with @Axel-Naumann on mattermost: https://mattermost.web.cern.ch/root/pl/3en1hqnc9tbftqakg3s3jy4b4c. The conda build has been patching this out since it was first released. There was some issues when building with `runtime_cxxmodules` but those were fixed in #4710.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4757
https://github.com/root-project/root/pull/4758:33,Testability,test,tests,33,This should fix a good number of tests on osx. cc: @Axel-Naumann,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4758
https://github.com/root-project/root/pull/4759:183,Usability,simpl,simplified,183,"[RF-8932] When a RooCurve is plotted as a filled polygon, one point has; to be added at the lower left of the plot to close the polygon.; A few lines of code have been cleaned up and simplified.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4759
https://github.com/root-project/root/pull/4760:183,Usability,simpl,simplified,183,"[RF-8932] When a RooCurve is plotted as a filled polygon, one point has; to be added at the lower left of the plot to close the polygon.; A few lines of code have been cleaned up and simplified. See also here:; https://root-forum.cern.ch/t/odd-behaviour-using-drawoption-f/19104. https://root-forum.cern.ch/t/plotting-issue-with-multiple-filled-pdfs-using-addto/25746",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4760
https://github.com/root-project/root/pull/4761:787,Availability,avail,available,787,"Each module has a set of identifier tables which aid lookup. Based on this information clang decides if it needs a declaration to be deserialized. Namespace partitions and other C++ entities may have semantically the same identifier lookup tables across multiple modules. Since lookup is a heavily used operation in compilers clang tries to optimize it as much as possible. In case it sees more than 4 such lookup tables it merges them together into a single table aiming to keep the lookup algorithmic complexity of O(1). This logic approach has several assumptions:; * The progam will use only a small superset of the modules it needs;; * The program will be compiled in multiple TUs and merging of tables will not be called often;. In the interpreter context where we make all module available the merging of such tables becomes CPU intense operation at runtime which produces a lot of temporary reallocations. Moreover, we have seen a lot of profiles where the merging operation dominates (by around 18%). This patch tries to make the merging far less often. On some short benchmarks ran locally we get (70-80%) runtime improvement and ~10% reduction in memory.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4761
https://github.com/root-project/root/pull/4761:1015,Deployability,patch,patch,1015,"Each module has a set of identifier tables which aid lookup. Based on this information clang decides if it needs a declaration to be deserialized. Namespace partitions and other C++ entities may have semantically the same identifier lookup tables across multiple modules. Since lookup is a heavily used operation in compilers clang tries to optimize it as much as possible. In case it sees more than 4 such lookup tables it merges them together into a single table aiming to keep the lookup algorithmic complexity of O(1). This logic approach has several assumptions:; * The progam will use only a small superset of the modules it needs;; * The program will be compiled in multiple TUs and merging of tables will not be called often;. In the interpreter context where we make all module available the merging of such tables becomes CPU intense operation at runtime which produces a lot of temporary reallocations. Moreover, we have seen a lot of profiles where the merging operation dominates (by around 18%). This patch tries to make the merging far less often. On some short benchmarks ran locally we get (70-80%) runtime improvement and ~10% reduction in memory.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4761
https://github.com/root-project/root/pull/4761:341,Performance,optimiz,optimize,341,"Each module has a set of identifier tables which aid lookup. Based on this information clang decides if it needs a declaration to be deserialized. Namespace partitions and other C++ entities may have semantically the same identifier lookup tables across multiple modules. Since lookup is a heavily used operation in compilers clang tries to optimize it as much as possible. In case it sees more than 4 such lookup tables it merges them together into a single table aiming to keep the lookup algorithmic complexity of O(1). This logic approach has several assumptions:; * The progam will use only a small superset of the modules it needs;; * The program will be compiled in multiple TUs and merging of tables will not be called often;. In the interpreter context where we make all module available the merging of such tables becomes CPU intense operation at runtime which produces a lot of temporary reallocations. Moreover, we have seen a lot of profiles where the merging operation dominates (by around 18%). This patch tries to make the merging far less often. On some short benchmarks ran locally we get (70-80%) runtime improvement and ~10% reduction in memory.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4761
https://github.com/root-project/root/pull/4761:528,Testability,log,logic,528,"Each module has a set of identifier tables which aid lookup. Based on this information clang decides if it needs a declaration to be deserialized. Namespace partitions and other C++ entities may have semantically the same identifier lookup tables across multiple modules. Since lookup is a heavily used operation in compilers clang tries to optimize it as much as possible. In case it sees more than 4 such lookup tables it merges them together into a single table aiming to keep the lookup algorithmic complexity of O(1). This logic approach has several assumptions:; * The progam will use only a small superset of the modules it needs;; * The program will be compiled in multiple TUs and merging of tables will not be called often;. In the interpreter context where we make all module available the merging of such tables becomes CPU intense operation at runtime which produces a lot of temporary reallocations. Moreover, we have seen a lot of profiles where the merging operation dominates (by around 18%). This patch tries to make the merging far less often. On some short benchmarks ran locally we get (70-80%) runtime improvement and ~10% reduction in memory.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4761
https://github.com/root-project/root/pull/4761:1077,Testability,benchmark,benchmarks,1077,"Each module has a set of identifier tables which aid lookup. Based on this information clang decides if it needs a declaration to be deserialized. Namespace partitions and other C++ entities may have semantically the same identifier lookup tables across multiple modules. Since lookup is a heavily used operation in compilers clang tries to optimize it as much as possible. In case it sees more than 4 such lookup tables it merges them together into a single table aiming to keep the lookup algorithmic complexity of O(1). This logic approach has several assumptions:; * The progam will use only a small superset of the modules it needs;; * The program will be compiled in multiple TUs and merging of tables will not be called often;. In the interpreter context where we make all module available the merging of such tables becomes CPU intense operation at runtime which produces a lot of temporary reallocations. Moreover, we have seen a lot of profiles where the merging operation dominates (by around 18%). This patch tries to make the merging far less often. On some short benchmarks ran locally we get (70-80%) runtime improvement and ~10% reduction in memory.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4761
https://github.com/root-project/root/pull/4762:479,Deployability,patch,patch,479,"The marker styles 3, 5 and 31 were draw different depending on whether they were drawn by a class based on TVirtualX or based on TVirtualPS as it can be seen in this picture:; ![temp](https://user-images.githubusercontent.com/5320187/72254803-64142680-3605-11ea-8255-40dd13038c80.jpg); Furthermore, the marker styles 9-19 were treated differently (In TVirtualX classes they were treated like marker style 1 and in TVirtualPS classes they were treated like marker style 20). This patch changes the drawing of TVirtualPS based classes to the drawing of TVirtualX based classes like for example TGX11. The updated classes are TPDF, TPostscript, TImageDump and TSVG. Since this slightly changes the corresponding file output, some reference values for testing had to be updated.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4762
https://github.com/root-project/root/pull/4762:603,Deployability,update,updated,603,"The marker styles 3, 5 and 31 were draw different depending on whether they were drawn by a class based on TVirtualX or based on TVirtualPS as it can be seen in this picture:; ![temp](https://user-images.githubusercontent.com/5320187/72254803-64142680-3605-11ea-8255-40dd13038c80.jpg); Furthermore, the marker styles 9-19 were treated differently (In TVirtualX classes they were treated like marker style 1 and in TVirtualPS classes they were treated like marker style 20). This patch changes the drawing of TVirtualPS based classes to the drawing of TVirtualX based classes like for example TGX11. The updated classes are TPDF, TPostscript, TImageDump and TSVG. Since this slightly changes the corresponding file output, some reference values for testing had to be updated.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4762
https://github.com/root-project/root/pull/4762:766,Deployability,update,updated,766,"The marker styles 3, 5 and 31 were draw different depending on whether they were drawn by a class based on TVirtualX or based on TVirtualPS as it can be seen in this picture:; ![temp](https://user-images.githubusercontent.com/5320187/72254803-64142680-3605-11ea-8255-40dd13038c80.jpg); Furthermore, the marker styles 9-19 were treated differently (In TVirtualX classes they were treated like marker style 1 and in TVirtualPS classes they were treated like marker style 20). This patch changes the drawing of TVirtualPS based classes to the drawing of TVirtualX based classes like for example TGX11. The updated classes are TPDF, TPostscript, TImageDump and TSVG. Since this slightly changes the corresponding file output, some reference values for testing had to be updated.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4762
https://github.com/root-project/root/pull/4762:50,Integrability,depend,depending,50,"The marker styles 3, 5 and 31 were draw different depending on whether they were drawn by a class based on TVirtualX or based on TVirtualPS as it can be seen in this picture:; ![temp](https://user-images.githubusercontent.com/5320187/72254803-64142680-3605-11ea-8255-40dd13038c80.jpg); Furthermore, the marker styles 9-19 were treated differently (In TVirtualX classes they were treated like marker style 1 and in TVirtualPS classes they were treated like marker style 20). This patch changes the drawing of TVirtualPS based classes to the drawing of TVirtualX based classes like for example TGX11. The updated classes are TPDF, TPostscript, TImageDump and TSVG. Since this slightly changes the corresponding file output, some reference values for testing had to be updated.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4762
https://github.com/root-project/root/pull/4762:748,Testability,test,testing,748,"The marker styles 3, 5 and 31 were draw different depending on whether they were drawn by a class based on TVirtualX or based on TVirtualPS as it can be seen in this picture:; ![temp](https://user-images.githubusercontent.com/5320187/72254803-64142680-3605-11ea-8255-40dd13038c80.jpg); Furthermore, the marker styles 9-19 were treated differently (In TVirtualX classes they were treated like marker style 1 and in TVirtualPS classes they were treated like marker style 20). This patch changes the drawing of TVirtualPS based classes to the drawing of TVirtualX based classes like for example TGX11. The updated classes are TPDF, TPostscript, TImageDump and TSVG. Since this slightly changes the corresponding file output, some reference values for testing had to be updated.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4762
https://github.com/root-project/root/pull/4763:45,Deployability,install,installation,45,"The changes introduced in 4ce57e copy in the installation directory empty copies of all the directories found in the build directory. This was found out only recently when the MultiPython PR was merged. The solution introduced in 14366b does not work, since the globbing is performed at configuration time, when the build directory is still empty. Since commit 4ce57e was introduced only to install the ~10 pcms listed in ll. 4237-4253 of core/dictgen/src/rootcling_impl.cxx, here we find a more suitable solution to achieve this goal.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4763
https://github.com/root-project/root/pull/4763:287,Deployability,configurat,configuration,287,"The changes introduced in 4ce57e copy in the installation directory empty copies of all the directories found in the build directory. This was found out only recently when the MultiPython PR was merged. The solution introduced in 14366b does not work, since the globbing is performed at configuration time, when the build directory is still empty. Since commit 4ce57e was introduced only to install the ~10 pcms listed in ll. 4237-4253 of core/dictgen/src/rootcling_impl.cxx, here we find a more suitable solution to achieve this goal.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4763
https://github.com/root-project/root/pull/4763:391,Deployability,install,install,391,"The changes introduced in 4ce57e copy in the installation directory empty copies of all the directories found in the build directory. This was found out only recently when the MultiPython PR was merged. The solution introduced in 14366b does not work, since the globbing is performed at configuration time, when the build directory is still empty. Since commit 4ce57e was introduced only to install the ~10 pcms listed in ll. 4237-4253 of core/dictgen/src/rootcling_impl.cxx, here we find a more suitable solution to achieve this goal.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4763
https://github.com/root-project/root/pull/4763:287,Modifiability,config,configuration,287,"The changes introduced in 4ce57e copy in the installation directory empty copies of all the directories found in the build directory. This was found out only recently when the MultiPython PR was merged. The solution introduced in 14366b does not work, since the globbing is performed at configuration time, when the build directory is still empty. Since commit 4ce57e was introduced only to install the ~10 pcms listed in ll. 4237-4253 of core/dictgen/src/rootcling_impl.cxx, here we find a more suitable solution to achieve this goal.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4763
https://github.com/root-project/root/pull/4763:274,Performance,perform,performed,274,"The changes introduced in 4ce57e copy in the installation directory empty copies of all the directories found in the build directory. This was found out only recently when the MultiPython PR was merged. The solution introduced in 14366b does not work, since the globbing is performed at configuration time, when the build directory is still empty. Since commit 4ce57e was introduced only to install the ~10 pcms listed in ll. 4237-4253 of core/dictgen/src/rootcling_impl.cxx, here we find a more suitable solution to achieve this goal.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4763
https://github.com/root-project/root/pull/4767:153,Integrability,depend,depends,153,"Split monolitic RBrowser libs on following components. * **ROOTBrowsable** - core functionality for browsing of objects plus support of TObject classes, depends only on libCore and libRIO; * **ROOTObjectDrawProvider** - small factory for drawing TObject in RCanvas/TCanvas, dependency from Gpad, Gapdv7; * **ROOTTreeDrawProvider** - special support of TTree::Draw on RCanvas/TCanvas, dependency from Gpad, Gapdv7, Tree; * **ROOTHistDrawProvider** - v7 Hist drawing on RCanvas, dependency from Gapdv7, Histv7; * **ROOTBrowserv7** - RBrowser and RFileDialog, depend on RBrowsable and gpad libs, load necessary drawing/browser libs when required. That is missing is configurable factory methods to load library depending on object class.; For the moment library names are hard corded",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4767
https://github.com/root-project/root/pull/4767:274,Integrability,depend,dependency,274,"Split monolitic RBrowser libs on following components. * **ROOTBrowsable** - core functionality for browsing of objects plus support of TObject classes, depends only on libCore and libRIO; * **ROOTObjectDrawProvider** - small factory for drawing TObject in RCanvas/TCanvas, dependency from Gpad, Gapdv7; * **ROOTTreeDrawProvider** - special support of TTree::Draw on RCanvas/TCanvas, dependency from Gpad, Gapdv7, Tree; * **ROOTHistDrawProvider** - v7 Hist drawing on RCanvas, dependency from Gapdv7, Histv7; * **ROOTBrowserv7** - RBrowser and RFileDialog, depend on RBrowsable and gpad libs, load necessary drawing/browser libs when required. That is missing is configurable factory methods to load library depending on object class.; For the moment library names are hard corded",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4767
https://github.com/root-project/root/pull/4767:384,Integrability,depend,dependency,384,"Split monolitic RBrowser libs on following components. * **ROOTBrowsable** - core functionality for browsing of objects plus support of TObject classes, depends only on libCore and libRIO; * **ROOTObjectDrawProvider** - small factory for drawing TObject in RCanvas/TCanvas, dependency from Gpad, Gapdv7; * **ROOTTreeDrawProvider** - special support of TTree::Draw on RCanvas/TCanvas, dependency from Gpad, Gapdv7, Tree; * **ROOTHistDrawProvider** - v7 Hist drawing on RCanvas, dependency from Gapdv7, Histv7; * **ROOTBrowserv7** - RBrowser and RFileDialog, depend on RBrowsable and gpad libs, load necessary drawing/browser libs when required. That is missing is configurable factory methods to load library depending on object class.; For the moment library names are hard corded",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4767
https://github.com/root-project/root/pull/4767:477,Integrability,depend,dependency,477,"Split monolitic RBrowser libs on following components. * **ROOTBrowsable** - core functionality for browsing of objects plus support of TObject classes, depends only on libCore and libRIO; * **ROOTObjectDrawProvider** - small factory for drawing TObject in RCanvas/TCanvas, dependency from Gpad, Gapdv7; * **ROOTTreeDrawProvider** - special support of TTree::Draw on RCanvas/TCanvas, dependency from Gpad, Gapdv7, Tree; * **ROOTHistDrawProvider** - v7 Hist drawing on RCanvas, dependency from Gapdv7, Histv7; * **ROOTBrowserv7** - RBrowser and RFileDialog, depend on RBrowsable and gpad libs, load necessary drawing/browser libs when required. That is missing is configurable factory methods to load library depending on object class.; For the moment library names are hard corded",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4767
https://github.com/root-project/root/pull/4767:557,Integrability,depend,depend,557,"Split monolitic RBrowser libs on following components. * **ROOTBrowsable** - core functionality for browsing of objects plus support of TObject classes, depends only on libCore and libRIO; * **ROOTObjectDrawProvider** - small factory for drawing TObject in RCanvas/TCanvas, dependency from Gpad, Gapdv7; * **ROOTTreeDrawProvider** - special support of TTree::Draw on RCanvas/TCanvas, dependency from Gpad, Gapdv7, Tree; * **ROOTHistDrawProvider** - v7 Hist drawing on RCanvas, dependency from Gapdv7, Histv7; * **ROOTBrowserv7** - RBrowser and RFileDialog, depend on RBrowsable and gpad libs, load necessary drawing/browser libs when required. That is missing is configurable factory methods to load library depending on object class.; For the moment library names are hard corded",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4767
https://github.com/root-project/root/pull/4767:708,Integrability,depend,depending,708,"Split monolitic RBrowser libs on following components. * **ROOTBrowsable** - core functionality for browsing of objects plus support of TObject classes, depends only on libCore and libRIO; * **ROOTObjectDrawProvider** - small factory for drawing TObject in RCanvas/TCanvas, dependency from Gpad, Gapdv7; * **ROOTTreeDrawProvider** - special support of TTree::Draw on RCanvas/TCanvas, dependency from Gpad, Gapdv7, Tree; * **ROOTHistDrawProvider** - v7 Hist drawing on RCanvas, dependency from Gapdv7, Histv7; * **ROOTBrowserv7** - RBrowser and RFileDialog, depend on RBrowsable and gpad libs, load necessary drawing/browser libs when required. That is missing is configurable factory methods to load library depending on object class.; For the moment library names are hard corded",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4767
https://github.com/root-project/root/pull/4767:663,Modifiability,config,configurable,663,"Split monolitic RBrowser libs on following components. * **ROOTBrowsable** - core functionality for browsing of objects plus support of TObject classes, depends only on libCore and libRIO; * **ROOTObjectDrawProvider** - small factory for drawing TObject in RCanvas/TCanvas, dependency from Gpad, Gapdv7; * **ROOTTreeDrawProvider** - special support of TTree::Draw on RCanvas/TCanvas, dependency from Gpad, Gapdv7, Tree; * **ROOTHistDrawProvider** - v7 Hist drawing on RCanvas, dependency from Gapdv7, Histv7; * **ROOTBrowserv7** - RBrowser and RFileDialog, depend on RBrowsable and gpad libs, load necessary drawing/browser libs when required. That is missing is configurable factory methods to load library depending on object class.; For the moment library names are hard corded",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4767
https://github.com/root-project/root/pull/4767:593,Performance,load,load,593,"Split monolitic RBrowser libs on following components. * **ROOTBrowsable** - core functionality for browsing of objects plus support of TObject classes, depends only on libCore and libRIO; * **ROOTObjectDrawProvider** - small factory for drawing TObject in RCanvas/TCanvas, dependency from Gpad, Gapdv7; * **ROOTTreeDrawProvider** - special support of TTree::Draw on RCanvas/TCanvas, dependency from Gpad, Gapdv7, Tree; * **ROOTHistDrawProvider** - v7 Hist drawing on RCanvas, dependency from Gapdv7, Histv7; * **ROOTBrowserv7** - RBrowser and RFileDialog, depend on RBrowsable and gpad libs, load necessary drawing/browser libs when required. That is missing is configurable factory methods to load library depending on object class.; For the moment library names are hard corded",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4767
https://github.com/root-project/root/pull/4767:695,Performance,load,load,695,"Split monolitic RBrowser libs on following components. * **ROOTBrowsable** - core functionality for browsing of objects plus support of TObject classes, depends only on libCore and libRIO; * **ROOTObjectDrawProvider** - small factory for drawing TObject in RCanvas/TCanvas, dependency from Gpad, Gapdv7; * **ROOTTreeDrawProvider** - special support of TTree::Draw on RCanvas/TCanvas, dependency from Gpad, Gapdv7, Tree; * **ROOTHistDrawProvider** - v7 Hist drawing on RCanvas, dependency from Gapdv7, Histv7; * **ROOTBrowserv7** - RBrowser and RFileDialog, depend on RBrowsable and gpad libs, load necessary drawing/browser libs when required. That is missing is configurable factory methods to load library depending on object class.; For the moment library names are hard corded",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4767
https://github.com/root-project/root/pull/4772:562,Deployability,install,installation,562,"Up to now there was no way to draw open marker symbols or marker symbols consisting of lines with higher linewidths than the default 1.; I looked into several ways to implement this feature and at the end just added additional marker smbols above the current maximum of 50 with wider lines as proposed by @couet in #4721 . This example plot demonstrates the feature:; ![c2](https://user-images.githubusercontent.com/5320187/72336265-b7977a80-36c0-11ea-8d25-3e3aa0697211.png). Please note that I tested the feature as far as I could. However, I don't have a ROOT installation on Windows or a Mac, so I could not test the corresponding implementations which is why I consider further tests (and especially a build test) mandatory.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4772
https://github.com/root-project/root/pull/4772:495,Testability,test,tested,495,"Up to now there was no way to draw open marker symbols or marker symbols consisting of lines with higher linewidths than the default 1.; I looked into several ways to implement this feature and at the end just added additional marker smbols above the current maximum of 50 with wider lines as proposed by @couet in #4721 . This example plot demonstrates the feature:; ![c2](https://user-images.githubusercontent.com/5320187/72336265-b7977a80-36c0-11ea-8d25-3e3aa0697211.png). Please note that I tested the feature as far as I could. However, I don't have a ROOT installation on Windows or a Mac, so I could not test the corresponding implementations which is why I consider further tests (and especially a build test) mandatory.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4772
https://github.com/root-project/root/pull/4772:611,Testability,test,test,611,"Up to now there was no way to draw open marker symbols or marker symbols consisting of lines with higher linewidths than the default 1.; I looked into several ways to implement this feature and at the end just added additional marker smbols above the current maximum of 50 with wider lines as proposed by @couet in #4721 . This example plot demonstrates the feature:; ![c2](https://user-images.githubusercontent.com/5320187/72336265-b7977a80-36c0-11ea-8d25-3e3aa0697211.png). Please note that I tested the feature as far as I could. However, I don't have a ROOT installation on Windows or a Mac, so I could not test the corresponding implementations which is why I consider further tests (and especially a build test) mandatory.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4772
https://github.com/root-project/root/pull/4772:682,Testability,test,tests,682,"Up to now there was no way to draw open marker symbols or marker symbols consisting of lines with higher linewidths than the default 1.; I looked into several ways to implement this feature and at the end just added additional marker smbols above the current maximum of 50 with wider lines as proposed by @couet in #4721 . This example plot demonstrates the feature:; ![c2](https://user-images.githubusercontent.com/5320187/72336265-b7977a80-36c0-11ea-8d25-3e3aa0697211.png). Please note that I tested the feature as far as I could. However, I don't have a ROOT installation on Windows or a Mac, so I could not test the corresponding implementations which is why I consider further tests (and especially a build test) mandatory.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4772
https://github.com/root-project/root/pull/4772:712,Testability,test,test,712,"Up to now there was no way to draw open marker symbols or marker symbols consisting of lines with higher linewidths than the default 1.; I looked into several ways to implement this feature and at the end just added additional marker smbols above the current maximum of 50 with wider lines as proposed by @couet in #4721 . This example plot demonstrates the feature:; ![c2](https://user-images.githubusercontent.com/5320187/72336265-b7977a80-36c0-11ea-8d25-3e3aa0697211.png). Please note that I tested the feature as far as I could. However, I don't have a ROOT installation on Windows or a Mac, so I could not test the corresponding implementations which is why I consider further tests (and especially a build test) mandatory.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4772
https://github.com/root-project/root/pull/4774:793,Availability,avail,available,793,"Each module has a set of identifier tables which aid lookup. Based on this; information clang decides if it needs a declaration to be deserialized. Namespace partitions and other C++ entities may have semantically the same; identifier lookup tables across multiple modules. Since lookup is a heavily used; operation in compilers clang tries to optimize it as much as possible. In case; it sees more than 4 such lookup tables it merges them together into a single; table aiming to keep the lookup algorithmic complexity of O(1). This logic approach has several assumptions:; * The progam will use only a small superset of the modules it needs;; * The program will be compiled in multiple TUs and merging of tables will not; be called often;. In the interpreter context where we make all module available the merging of; such tables becomes CPU intense operation at runtime which produces a lot of; temporary reallocations. Moreover, we have seen a lot of profiles where the; merging operation dominates (by around 18%). This patch tries to make the merging far less often. On some short benchmarks ran; locally we get (70-80%) runtime improvement and ~10% reduction in memory.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4774
https://github.com/root-project/root/pull/4774:1024,Deployability,patch,patch,1024,"Each module has a set of identifier tables which aid lookup. Based on this; information clang decides if it needs a declaration to be deserialized. Namespace partitions and other C++ entities may have semantically the same; identifier lookup tables across multiple modules. Since lookup is a heavily used; operation in compilers clang tries to optimize it as much as possible. In case; it sees more than 4 such lookup tables it merges them together into a single; table aiming to keep the lookup algorithmic complexity of O(1). This logic approach has several assumptions:; * The progam will use only a small superset of the modules it needs;; * The program will be compiled in multiple TUs and merging of tables will not; be called often;. In the interpreter context where we make all module available the merging of; such tables becomes CPU intense operation at runtime which produces a lot of; temporary reallocations. Moreover, we have seen a lot of profiles where the; merging operation dominates (by around 18%). This patch tries to make the merging far less often. On some short benchmarks ran; locally we get (70-80%) runtime improvement and ~10% reduction in memory.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4774
https://github.com/root-project/root/pull/4774:344,Performance,optimiz,optimize,344,"Each module has a set of identifier tables which aid lookup. Based on this; information clang decides if it needs a declaration to be deserialized. Namespace partitions and other C++ entities may have semantically the same; identifier lookup tables across multiple modules. Since lookup is a heavily used; operation in compilers clang tries to optimize it as much as possible. In case; it sees more than 4 such lookup tables it merges them together into a single; table aiming to keep the lookup algorithmic complexity of O(1). This logic approach has several assumptions:; * The progam will use only a small superset of the modules it needs;; * The program will be compiled in multiple TUs and merging of tables will not; be called often;. In the interpreter context where we make all module available the merging of; such tables becomes CPU intense operation at runtime which produces a lot of; temporary reallocations. Moreover, we have seen a lot of profiles where the; merging operation dominates (by around 18%). This patch tries to make the merging far less often. On some short benchmarks ran; locally we get (70-80%) runtime improvement and ~10% reduction in memory.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4774
https://github.com/root-project/root/pull/4774:533,Testability,log,logic,533,"Each module has a set of identifier tables which aid lookup. Based on this; information clang decides if it needs a declaration to be deserialized. Namespace partitions and other C++ entities may have semantically the same; identifier lookup tables across multiple modules. Since lookup is a heavily used; operation in compilers clang tries to optimize it as much as possible. In case; it sees more than 4 such lookup tables it merges them together into a single; table aiming to keep the lookup algorithmic complexity of O(1). This logic approach has several assumptions:; * The progam will use only a small superset of the modules it needs;; * The program will be compiled in multiple TUs and merging of tables will not; be called often;. In the interpreter context where we make all module available the merging of; such tables becomes CPU intense operation at runtime which produces a lot of; temporary reallocations. Moreover, we have seen a lot of profiles where the; merging operation dominates (by around 18%). This patch tries to make the merging far less often. On some short benchmarks ran; locally we get (70-80%) runtime improvement and ~10% reduction in memory.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4774
https://github.com/root-project/root/pull/4774:1086,Testability,benchmark,benchmarks,1086,"Each module has a set of identifier tables which aid lookup. Based on this; information clang decides if it needs a declaration to be deserialized. Namespace partitions and other C++ entities may have semantically the same; identifier lookup tables across multiple modules. Since lookup is a heavily used; operation in compilers clang tries to optimize it as much as possible. In case; it sees more than 4 such lookup tables it merges them together into a single; table aiming to keep the lookup algorithmic complexity of O(1). This logic approach has several assumptions:; * The progam will use only a small superset of the modules it needs;; * The program will be compiled in multiple TUs and merging of tables will not; be called often;. In the interpreter context where we make all module available the merging of; such tables becomes CPU intense operation at runtime which produces a lot of; temporary reallocations. Moreover, we have seen a lot of profiles where the; merging operation dominates (by around 18%). This patch tries to make the merging far less often. On some short benchmarks ran; locally we get (70-80%) runtime improvement and ~10% reduction in memory.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4774
https://github.com/root-project/root/pull/4777:135,Deployability,hotfix,hotfix,135,"This PR serves the same purpose as this one: #4695 ; However, I think that older PR was never merged, because it was opened before the hotfix #4698 and therefore was not able to compile. In this PR I simply format all code that has been added for the TGraphMultiErrors class using clang-format and the format settings file provided by ROOT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4777
https://github.com/root-project/root/pull/4777:200,Usability,simpl,simply,200,"This PR serves the same purpose as this one: #4695 ; However, I think that older PR was never merged, because it was opened before the hotfix #4698 and therefore was not able to compile. In this PR I simply format all code that has been added for the TGraphMultiErrors class using clang-format and the format settings file provided by ROOT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4777
https://github.com/root-project/root/pull/4779:231,Deployability,release,release,231,…allow 'out of the box' correct source. Checking only for the existance of 'CMakeFiles' without including; ROOTSYS in the path was causing the addition of wrong paths in case of; out-of-the-box source. This also need to go in 6.20 release branch.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4779
https://github.com/root-project/root/pull/4780:61,Availability,failure,failures,61,"Hello,. the bug this PR is adressing could be seen by random failures of the test gtest-hist-hist-test-TGraphMultiErrorsTests:; - https://epsft-jenkins.cern.ch/job/root-pullrequests-build/74654/testReport/projectroot.hist.hist/test/gtest_hist_hist_test_TGraphMultiErrorsTests/; - https://epsft-jenkins.cern.ch/job/root-pullrequests-build/74449/testReport/projectroot.hist.hist/test/gtest_hist_hist_test_TGraphMultiErrorsTests/; - https://epsft-jenkins.cern.ch/job/root-pullrequests-build/73886/testReport/projectroot.hist.hist/test/gtest_hist_hist_test_TGraphMultiErrorsTests/. I have to apologize for this bug. It was caused by using an attribute to allocate an array before its value had been updated. All the best,; Simon",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4780
https://github.com/root-project/root/pull/4780:695,Deployability,update,updated,695,"Hello,. the bug this PR is adressing could be seen by random failures of the test gtest-hist-hist-test-TGraphMultiErrorsTests:; - https://epsft-jenkins.cern.ch/job/root-pullrequests-build/74654/testReport/projectroot.hist.hist/test/gtest_hist_hist_test_TGraphMultiErrorsTests/; - https://epsft-jenkins.cern.ch/job/root-pullrequests-build/74449/testReport/projectroot.hist.hist/test/gtest_hist_hist_test_TGraphMultiErrorsTests/; - https://epsft-jenkins.cern.ch/job/root-pullrequests-build/73886/testReport/projectroot.hist.hist/test/gtest_hist_hist_test_TGraphMultiErrorsTests/. I have to apologize for this bug. It was caused by using an attribute to allocate an array before its value had been updated. All the best,; Simon",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4780
https://github.com/root-project/root/pull/4780:651,Energy Efficiency,allocate,allocate,651,"Hello,. the bug this PR is adressing could be seen by random failures of the test gtest-hist-hist-test-TGraphMultiErrorsTests:; - https://epsft-jenkins.cern.ch/job/root-pullrequests-build/74654/testReport/projectroot.hist.hist/test/gtest_hist_hist_test_TGraphMultiErrorsTests/; - https://epsft-jenkins.cern.ch/job/root-pullrequests-build/74449/testReport/projectroot.hist.hist/test/gtest_hist_hist_test_TGraphMultiErrorsTests/; - https://epsft-jenkins.cern.ch/job/root-pullrequests-build/73886/testReport/projectroot.hist.hist/test/gtest_hist_hist_test_TGraphMultiErrorsTests/. I have to apologize for this bug. It was caused by using an attribute to allocate an array before its value had been updated. All the best,; Simon",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4780
https://github.com/root-project/root/pull/4780:77,Testability,test,test,77,"Hello,. the bug this PR is adressing could be seen by random failures of the test gtest-hist-hist-test-TGraphMultiErrorsTests:; - https://epsft-jenkins.cern.ch/job/root-pullrequests-build/74654/testReport/projectroot.hist.hist/test/gtest_hist_hist_test_TGraphMultiErrorsTests/; - https://epsft-jenkins.cern.ch/job/root-pullrequests-build/74449/testReport/projectroot.hist.hist/test/gtest_hist_hist_test_TGraphMultiErrorsTests/; - https://epsft-jenkins.cern.ch/job/root-pullrequests-build/73886/testReport/projectroot.hist.hist/test/gtest_hist_hist_test_TGraphMultiErrorsTests/. I have to apologize for this bug. It was caused by using an attribute to allocate an array before its value had been updated. All the best,; Simon",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4780
https://github.com/root-project/root/pull/4780:98,Testability,test,test-TGraphMultiErrorsTests,98,"Hello,. the bug this PR is adressing could be seen by random failures of the test gtest-hist-hist-test-TGraphMultiErrorsTests:; - https://epsft-jenkins.cern.ch/job/root-pullrequests-build/74654/testReport/projectroot.hist.hist/test/gtest_hist_hist_test_TGraphMultiErrorsTests/; - https://epsft-jenkins.cern.ch/job/root-pullrequests-build/74449/testReport/projectroot.hist.hist/test/gtest_hist_hist_test_TGraphMultiErrorsTests/; - https://epsft-jenkins.cern.ch/job/root-pullrequests-build/73886/testReport/projectroot.hist.hist/test/gtest_hist_hist_test_TGraphMultiErrorsTests/. I have to apologize for this bug. It was caused by using an attribute to allocate an array before its value had been updated. All the best,; Simon",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4780
https://github.com/root-project/root/pull/4780:194,Testability,test,testReport,194,"Hello,. the bug this PR is adressing could be seen by random failures of the test gtest-hist-hist-test-TGraphMultiErrorsTests:; - https://epsft-jenkins.cern.ch/job/root-pullrequests-build/74654/testReport/projectroot.hist.hist/test/gtest_hist_hist_test_TGraphMultiErrorsTests/; - https://epsft-jenkins.cern.ch/job/root-pullrequests-build/74449/testReport/projectroot.hist.hist/test/gtest_hist_hist_test_TGraphMultiErrorsTests/; - https://epsft-jenkins.cern.ch/job/root-pullrequests-build/73886/testReport/projectroot.hist.hist/test/gtest_hist_hist_test_TGraphMultiErrorsTests/. I have to apologize for this bug. It was caused by using an attribute to allocate an array before its value had been updated. All the best,; Simon",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4780
https://github.com/root-project/root/pull/4780:227,Testability,test,test,227,"Hello,. the bug this PR is adressing could be seen by random failures of the test gtest-hist-hist-test-TGraphMultiErrorsTests:; - https://epsft-jenkins.cern.ch/job/root-pullrequests-build/74654/testReport/projectroot.hist.hist/test/gtest_hist_hist_test_TGraphMultiErrorsTests/; - https://epsft-jenkins.cern.ch/job/root-pullrequests-build/74449/testReport/projectroot.hist.hist/test/gtest_hist_hist_test_TGraphMultiErrorsTests/; - https://epsft-jenkins.cern.ch/job/root-pullrequests-build/73886/testReport/projectroot.hist.hist/test/gtest_hist_hist_test_TGraphMultiErrorsTests/. I have to apologize for this bug. It was caused by using an attribute to allocate an array before its value had been updated. All the best,; Simon",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4780
https://github.com/root-project/root/pull/4780:344,Testability,test,testReport,344,"Hello,. the bug this PR is adressing could be seen by random failures of the test gtest-hist-hist-test-TGraphMultiErrorsTests:; - https://epsft-jenkins.cern.ch/job/root-pullrequests-build/74654/testReport/projectroot.hist.hist/test/gtest_hist_hist_test_TGraphMultiErrorsTests/; - https://epsft-jenkins.cern.ch/job/root-pullrequests-build/74449/testReport/projectroot.hist.hist/test/gtest_hist_hist_test_TGraphMultiErrorsTests/; - https://epsft-jenkins.cern.ch/job/root-pullrequests-build/73886/testReport/projectroot.hist.hist/test/gtest_hist_hist_test_TGraphMultiErrorsTests/. I have to apologize for this bug. It was caused by using an attribute to allocate an array before its value had been updated. All the best,; Simon",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4780
https://github.com/root-project/root/pull/4780:377,Testability,test,test,377,"Hello,. the bug this PR is adressing could be seen by random failures of the test gtest-hist-hist-test-TGraphMultiErrorsTests:; - https://epsft-jenkins.cern.ch/job/root-pullrequests-build/74654/testReport/projectroot.hist.hist/test/gtest_hist_hist_test_TGraphMultiErrorsTests/; - https://epsft-jenkins.cern.ch/job/root-pullrequests-build/74449/testReport/projectroot.hist.hist/test/gtest_hist_hist_test_TGraphMultiErrorsTests/; - https://epsft-jenkins.cern.ch/job/root-pullrequests-build/73886/testReport/projectroot.hist.hist/test/gtest_hist_hist_test_TGraphMultiErrorsTests/. I have to apologize for this bug. It was caused by using an attribute to allocate an array before its value had been updated. All the best,; Simon",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4780
https://github.com/root-project/root/pull/4780:494,Testability,test,testReport,494,"Hello,. the bug this PR is adressing could be seen by random failures of the test gtest-hist-hist-test-TGraphMultiErrorsTests:; - https://epsft-jenkins.cern.ch/job/root-pullrequests-build/74654/testReport/projectroot.hist.hist/test/gtest_hist_hist_test_TGraphMultiErrorsTests/; - https://epsft-jenkins.cern.ch/job/root-pullrequests-build/74449/testReport/projectroot.hist.hist/test/gtest_hist_hist_test_TGraphMultiErrorsTests/; - https://epsft-jenkins.cern.ch/job/root-pullrequests-build/73886/testReport/projectroot.hist.hist/test/gtest_hist_hist_test_TGraphMultiErrorsTests/. I have to apologize for this bug. It was caused by using an attribute to allocate an array before its value had been updated. All the best,; Simon",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4780
https://github.com/root-project/root/pull/4780:527,Testability,test,test,527,"Hello,. the bug this PR is adressing could be seen by random failures of the test gtest-hist-hist-test-TGraphMultiErrorsTests:; - https://epsft-jenkins.cern.ch/job/root-pullrequests-build/74654/testReport/projectroot.hist.hist/test/gtest_hist_hist_test_TGraphMultiErrorsTests/; - https://epsft-jenkins.cern.ch/job/root-pullrequests-build/74449/testReport/projectroot.hist.hist/test/gtest_hist_hist_test_TGraphMultiErrorsTests/; - https://epsft-jenkins.cern.ch/job/root-pullrequests-build/73886/testReport/projectroot.hist.hist/test/gtest_hist_hist_test_TGraphMultiErrorsTests/. I have to apologize for this bug. It was caused by using an attribute to allocate an array before its value had been updated. All the best,; Simon",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4780
https://github.com/root-project/root/pull/4782:567,Deployability,update,updated,567,"This PR handles the case in Minos when a lower function value is found. ; The iteration to find the crossing function point (in MnFunctionCross) is stopped and the new found point state with lower function value is returned. ; The Minuit2Minimizer then handles the case by re-minimizing t he function from the new point and then run again Minos from the new found minimum. In the case of TMinuit this was handles, although maybe not in the optimal case. . Fix also when a new Minimum is found that both in Minimizer and Fitter that the result with the new minimum is updated.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4782
https://github.com/root-project/root/pull/4783:11,Deployability,install,install,11,Content of install directory with this PR: ; https://gist.github.com/oshadura/7737bdcc90fed501869656808a5c514a. Next step will be to move installation of PCMs in ROOT_GENERATE_DICTIONARY().,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4783
https://github.com/root-project/root/pull/4783:138,Deployability,install,installation,138,Content of install directory with this PR: ; https://gist.github.com/oshadura/7737bdcc90fed501869656808a5c514a. Next step will be to move installation of PCMs in ROOT_GENERATE_DICTIONARY().,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4783
https://github.com/root-project/root/pull/4785:186,Availability,error,error,186,"* Use only **Browsable::Provider** class for all factory methods; * Split ROOT6 and ROOT7 drawing plugins; * Rename RBrowsable -> RBrowserData to avoid confusion; * Fix Windows compiler error, tests on Windows",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4785
https://github.com/root-project/root/pull/4785:98,Modifiability,plugin,plugins,98,"* Use only **Browsable::Provider** class for all factory methods; * Split ROOT6 and ROOT7 drawing plugins; * Rename RBrowsable -> RBrowserData to avoid confusion; * Fix Windows compiler error, tests on Windows",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4785
https://github.com/root-project/root/pull/4785:146,Safety,avoid,avoid,146,"* Use only **Browsable::Provider** class for all factory methods; * Split ROOT6 and ROOT7 drawing plugins; * Rename RBrowsable -> RBrowserData to avoid confusion; * Fix Windows compiler error, tests on Windows",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4785
https://github.com/root-project/root/pull/4785:193,Testability,test,tests,193,"* Use only **Browsable::Provider** class for all factory methods; * Split ROOT6 and ROOT7 drawing plugins; * Rename RBrowsable -> RBrowserData to avoid confusion; * Fix Windows compiler error, tests on Windows",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4785
https://github.com/root-project/root/pull/4789:65,Deployability,patch,patch,65,"The option ""G"" for RedrawAxis did not work for multigraphs. This patch fixes this and restructure this method.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4789
https://github.com/root-project/root/pull/4790:8,Availability,fault,faulty,8,"Fixed a faulty loop condition in RooAddModel that lead to a crash in; RoofitUnBinnedBenchmark.; Further, fix the definition of basis functions in RooBMixDecay, which; lead to an info message about not using a parameter in a RooFormulaVar.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4790
https://github.com/root-project/root/pull/4790:183,Integrability,message,message,183,"Fixed a faulty loop condition in RooAddModel that lead to a crash in; RoofitUnBinnedBenchmark.; Further, fix the definition of basis functions in RooBMixDecay, which; lead to an info message about not using a parameter in a RooFormulaVar.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4790
https://github.com/root-project/root/pull/4791:3,Safety,Avoid,Avoid,3,"1. Avoid usage of `static constexpr` in header files. MSVC compiler is not happy about such construct; 2. Add R__LOAD_LIBRARY to test macros (like brower.cxx) to let it run in Windows; 3. Add handling of "".lnk"" files in RBrowser",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4791
https://github.com/root-project/root/pull/4791:129,Testability,test,test,129,"1. Avoid usage of `static constexpr` in header files. MSVC compiler is not happy about such construct; 2. Add R__LOAD_LIBRARY to test macros (like brower.cxx) to let it run in Windows; 3. Add handling of "".lnk"" files in RBrowser",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4791
https://github.com/root-project/root/pull/4792:86,Deployability,install,install,86,"We are excluding directories, which are accidentaly copied via unxpected behaviour of install(DIRECTORY ..)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4792
https://github.com/root-project/root/pull/4795:29,Availability,failure,failures,29,Fixes for the following test failures:; https://github.com/root-project/root/pull/4766#issuecomment-573859694,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4795
https://github.com/root-project/root/pull/4795:24,Testability,test,test,24,Fixes for the following test failures:; https://github.com/root-project/root/pull/4766#issuecomment-573859694,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4795
https://github.com/root-project/root/pull/4805:142,Security,access,access,142,"- Add a couple of missing symbols into the export list; - Fix several test failing on Windows, mostly due to files staying open (creates file access issues on Windows); - Filter-out several unsupported tests (will add them back once the underlying issues are fixed)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4805
https://github.com/root-project/root/pull/4805:70,Testability,test,test,70,"- Add a couple of missing symbols into the export list; - Fix several test failing on Windows, mostly due to files staying open (creates file access issues on Windows); - Filter-out several unsupported tests (will add them back once the underlying issues are fixed)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4805
https://github.com/root-project/root/pull/4805:202,Testability,test,tests,202,"- Add a couple of missing symbols into the export list; - Fix several test failing on Windows, mostly due to files staying open (creates file access issues on Windows); - Filter-out several unsupported tests (will add them back once the underlying issues are fixed)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4805
https://github.com/root-project/root/pull/4806:48,Availability,Error,Error,48,This is missing from the standalone build - the Error.h file has:. https://github.com/root-project/root/blob/803df004f43cfbb7c16e455ca30f2c250cc7fd8d/math/mathcore/inc/Math/Error.h#L27. But this is not being added by the standalone CMake build. It seems that this was changed from `USE_ROOT_ERROR` missing to a check for `MATHCORE_STANDALONE` (https://github.com/root-project/root/pull/2545).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4806
https://github.com/root-project/root/pull/4806:173,Availability,Error,Error,173,This is missing from the standalone build - the Error.h file has:. https://github.com/root-project/root/blob/803df004f43cfbb7c16e455ca30f2c250cc7fd8d/math/mathcore/inc/Math/Error.h#L27. But this is not being added by the standalone CMake build. It seems that this was changed from `USE_ROOT_ERROR` missing to a check for `MATHCORE_STANDALONE` (https://github.com/root-project/root/pull/2545).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4806
https://github.com/root-project/root/pull/4810:94,Availability,redundant,redundant,94,"Give more informative member names to avoid confusion (e.g. eveId, elementId, eve_id); Remove redundant member in object3d: eveId and mstrId, which can be accessed ad eve_el.fElementId, and eve_el.fMasterId. This PR is not a design change.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4810
https://github.com/root-project/root/pull/4810:38,Safety,avoid,avoid,38,"Give more informative member names to avoid confusion (e.g. eveId, elementId, eve_id); Remove redundant member in object3d: eveId and mstrId, which can be accessed ad eve_el.fElementId, and eve_el.fMasterId. This PR is not a design change.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4810
https://github.com/root-project/root/pull/4810:94,Safety,redund,redundant,94,"Give more informative member names to avoid confusion (e.g. eveId, elementId, eve_id); Remove redundant member in object3d: eveId and mstrId, which can be accessed ad eve_el.fElementId, and eve_el.fMasterId. This PR is not a design change.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4810
https://github.com/root-project/root/pull/4810:155,Security,access,accessed,155,"Give more informative member names to avoid confusion (e.g. eveId, elementId, eve_id); Remove redundant member in object3d: eveId and mstrId, which can be accessed ad eve_el.fElementId, and eve_el.fMasterId. This PR is not a design change.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4810
https://github.com/root-project/root/pull/4812:105,Deployability,Patch,Patch,105,…a.so. This should fix the failing roottest-root-html-runMakeIndex on OSX with; -Druntime_cxxmodules=On. Patch by Alexander Penev (@alexander-penev)!,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4812
https://github.com/root-project/root/pull/4817:44,Integrability,wrap,wrapper,44,"Implemented tessellated shape in TGeo, as a wrapper shape without navigation functionality, allowing future conversions to/from Geant4 and VecGeom done by frameworks such as DD4HEP. Currently missing navigation functionality, but having ROOT/GDML persistence support and visualization.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4817
https://github.com/root-project/root/pull/4825:43,Modifiability,variab,variable,43,Old gcc issues a shadow warning if a local variable and a function have the same name.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4825
https://github.com/root-project/root/pull/4826:43,Modifiability,variab,variable,43,Old gcc issues a shadow warning if a local variable and a function have the same name.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4826
https://github.com/root-project/root/pull/4830:1320,Security,checksum,checksum,1320,"Hello,. this is a rather small, but I think very useful addition.; One application of the TMacro class is to store the code that generated a ROOT file in the file itself to be later able to reproduce the analysis.; However, in parallel computing you often execute the same macro several times and at the end merge the resulting files using the TFileMerger or a tool like hadd. Up to now the TMacro class was not mergeable and therefore merging 1000 files would create 1000 cycles of TMacro objects with the exact same content, which makes it hard to browse the ROOT file in a TBrowser for example. Of course I am aware that you cannot actually merge two different macros, but since the name of a TMacro is usually the filename of the macro stored, I cannot think of any valid case in which two TMacro objects with the same name in two files that are supposed to be merged would have different contents. Furthermore, the parameter attribute of the class is described as ""default parameters to execute this macro"" in TMacro::SetParams, so they should also not differ for two instances of the same macro. My implementation of the Merge function for the TMacro class just compares the TMacro objects that are supposed to be merged and issues warnings if there there are differences. The file contents are compared using the checksum of the TMacro object. All the best,; Simon",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4830
https://github.com/root-project/root/pull/4832:129,Availability,error,error,129,"When passing `-DPYTHON_EXECUTABLE=/my/path/to/python2` on macOS ROOT fails to configure with newer CMake versions with a bizarre error of:; ```; -- Preferring Python version 3; -- Found Python: /Users/christopherburr/miniconda3/conda-bld/root_1579698021552/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_place/bin/python2.7 (found version ""2.7.15"") found components: Interpreter Development; -- Could NOT find Python (missing: Development) (found version ""2.7.15""); -- Looking for OpenGL; -- Could NOT find OpenGL (missing: OPENGL_gl_LIBRARY OPENGL_INCLUDE_DIR); CMake Error at cmake/modules/SearchInstalledSoftware.cmake:610 (message):; OpenGL package (with GLU) not found and opengl option required; Call Stack (most recent call first):; CMakeLists.txt:167 (include); ```; Looking at the variables I see a weird mixture of python 2 and python 3:; ```; //; PYTHON_EXECUTABLE-CACHED:STRING=/Users/christopherburr/miniconda3/conda-bld/root_1579698021552/_h_env/bin/python. // Path to a program.; Python_EXECUTABLE:FILEPATH=/Users/christopherburr/miniconda3/conda-bld/root_1579698021552/_h_env/bin/python2.7. // Path to a file.; Python_INCLUDE_DIR:PATH=/usr/local/Cellar/python/3.7.6/Frameworks/Python.framework/Versions/3.7/include/python3.7m. // Path to a library.; Python_LIBRARY_DEBUG:FILEPATH=Python_LIBRARY_DEBUG-NOTFOUND. // Path to a library.; Python_LIBRARY_RELEASE:FILEPATH=/usr/local/opt/python/Frameworks/Python.framework/Versions/3.7/lib/libpython3.7m.dylib. // Path to a file.; Python_NumPy_INCLUDE_DIR:PATH=/Users/christopherburr/miniconda3/conda-bld/root_1579698021552/_h_env/lib/python2.7/site-packages/numpy/core/include; ```; This PR includes one way of fixing the issue.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4832
https://github.com/root-project/root/pull/4832:709,Availability,Error,Error,709,"When passing `-DPYTHON_EXECUTABLE=/my/path/to/python2` on macOS ROOT fails to configure with newer CMake versions with a bizarre error of:; ```; -- Preferring Python version 3; -- Found Python: /Users/christopherburr/miniconda3/conda-bld/root_1579698021552/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_place/bin/python2.7 (found version ""2.7.15"") found components: Interpreter Development; -- Could NOT find Python (missing: Development) (found version ""2.7.15""); -- Looking for OpenGL; -- Could NOT find OpenGL (missing: OPENGL_gl_LIBRARY OPENGL_INCLUDE_DIR); CMake Error at cmake/modules/SearchInstalledSoftware.cmake:610 (message):; OpenGL package (with GLU) not found and opengl option required; Call Stack (most recent call first):; CMakeLists.txt:167 (include); ```; Looking at the variables I see a weird mixture of python 2 and python 3:; ```; //; PYTHON_EXECUTABLE-CACHED:STRING=/Users/christopherburr/miniconda3/conda-bld/root_1579698021552/_h_env/bin/python. // Path to a program.; Python_EXECUTABLE:FILEPATH=/Users/christopherburr/miniconda3/conda-bld/root_1579698021552/_h_env/bin/python2.7. // Path to a file.; Python_INCLUDE_DIR:PATH=/usr/local/Cellar/python/3.7.6/Frameworks/Python.framework/Versions/3.7/include/python3.7m. // Path to a library.; Python_LIBRARY_DEBUG:FILEPATH=Python_LIBRARY_DEBUG-NOTFOUND. // Path to a library.; Python_LIBRARY_RELEASE:FILEPATH=/usr/local/opt/python/Frameworks/Python.framework/Versions/3.7/lib/libpython3.7m.dylib. // Path to a file.; Python_NumPy_INCLUDE_DIR:PATH=/Users/christopherburr/miniconda3/conda-bld/root_1579698021552/_h_env/lib/python2.7/site-packages/numpy/core/include; ```; This PR includes one way of fixing the issue.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4832
https://github.com/root-project/root/pull/4832:767,Integrability,message,message,767,"When passing `-DPYTHON_EXECUTABLE=/my/path/to/python2` on macOS ROOT fails to configure with newer CMake versions with a bizarre error of:; ```; -- Preferring Python version 3; -- Found Python: /Users/christopherburr/miniconda3/conda-bld/root_1579698021552/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_place/bin/python2.7 (found version ""2.7.15"") found components: Interpreter Development; -- Could NOT find Python (missing: Development) (found version ""2.7.15""); -- Looking for OpenGL; -- Could NOT find OpenGL (missing: OPENGL_gl_LIBRARY OPENGL_INCLUDE_DIR); CMake Error at cmake/modules/SearchInstalledSoftware.cmake:610 (message):; OpenGL package (with GLU) not found and opengl option required; Call Stack (most recent call first):; CMakeLists.txt:167 (include); ```; Looking at the variables I see a weird mixture of python 2 and python 3:; ```; //; PYTHON_EXECUTABLE-CACHED:STRING=/Users/christopherburr/miniconda3/conda-bld/root_1579698021552/_h_env/bin/python. // Path to a program.; Python_EXECUTABLE:FILEPATH=/Users/christopherburr/miniconda3/conda-bld/root_1579698021552/_h_env/bin/python2.7. // Path to a file.; Python_INCLUDE_DIR:PATH=/usr/local/Cellar/python/3.7.6/Frameworks/Python.framework/Versions/3.7/include/python3.7m. // Path to a library.; Python_LIBRARY_DEBUG:FILEPATH=Python_LIBRARY_DEBUG-NOTFOUND. // Path to a library.; Python_LIBRARY_RELEASE:FILEPATH=/usr/local/opt/python/Frameworks/Python.framework/Versions/3.7/lib/libpython3.7m.dylib. // Path to a file.; Python_NumPy_INCLUDE_DIR:PATH=/Users/christopherburr/miniconda3/conda-bld/root_1579698021552/_h_env/lib/python2.7/site-packages/numpy/core/include; ```; This PR includes one way of fixing the issue.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4832
https://github.com/root-project/root/pull/4832:78,Modifiability,config,configure,78,"When passing `-DPYTHON_EXECUTABLE=/my/path/to/python2` on macOS ROOT fails to configure with newer CMake versions with a bizarre error of:; ```; -- Preferring Python version 3; -- Found Python: /Users/christopherburr/miniconda3/conda-bld/root_1579698021552/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_place/bin/python2.7 (found version ""2.7.15"") found components: Interpreter Development; -- Could NOT find Python (missing: Development) (found version ""2.7.15""); -- Looking for OpenGL; -- Could NOT find OpenGL (missing: OPENGL_gl_LIBRARY OPENGL_INCLUDE_DIR); CMake Error at cmake/modules/SearchInstalledSoftware.cmake:610 (message):; OpenGL package (with GLU) not found and opengl option required; Call Stack (most recent call first):; CMakeLists.txt:167 (include); ```; Looking at the variables I see a weird mixture of python 2 and python 3:; ```; //; PYTHON_EXECUTABLE-CACHED:STRING=/Users/christopherburr/miniconda3/conda-bld/root_1579698021552/_h_env/bin/python. // Path to a program.; Python_EXECUTABLE:FILEPATH=/Users/christopherburr/miniconda3/conda-bld/root_1579698021552/_h_env/bin/python2.7. // Path to a file.; Python_INCLUDE_DIR:PATH=/usr/local/Cellar/python/3.7.6/Frameworks/Python.framework/Versions/3.7/include/python3.7m. // Path to a library.; Python_LIBRARY_DEBUG:FILEPATH=Python_LIBRARY_DEBUG-NOTFOUND. // Path to a library.; Python_LIBRARY_RELEASE:FILEPATH=/usr/local/opt/python/Frameworks/Python.framework/Versions/3.7/lib/libpython3.7m.dylib. // Path to a file.; Python_NumPy_INCLUDE_DIR:PATH=/Users/christopherburr/miniconda3/conda-bld/root_1579698021552/_h_env/lib/python2.7/site-packages/numpy/core/include; ```; This PR includes one way of fixing the issue.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4832
https://github.com/root-project/root/pull/4832:930,Modifiability,variab,variables,930,"When passing `-DPYTHON_EXECUTABLE=/my/path/to/python2` on macOS ROOT fails to configure with newer CMake versions with a bizarre error of:; ```; -- Preferring Python version 3; -- Found Python: /Users/christopherburr/miniconda3/conda-bld/root_1579698021552/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_place/bin/python2.7 (found version ""2.7.15"") found components: Interpreter Development; -- Could NOT find Python (missing: Development) (found version ""2.7.15""); -- Looking for OpenGL; -- Could NOT find OpenGL (missing: OPENGL_gl_LIBRARY OPENGL_INCLUDE_DIR); CMake Error at cmake/modules/SearchInstalledSoftware.cmake:610 (message):; OpenGL package (with GLU) not found and opengl option required; Call Stack (most recent call first):; CMakeLists.txt:167 (include); ```; Looking at the variables I see a weird mixture of python 2 and python 3:; ```; //; PYTHON_EXECUTABLE-CACHED:STRING=/Users/christopherburr/miniconda3/conda-bld/root_1579698021552/_h_env/bin/python. // Path to a program.; Python_EXECUTABLE:FILEPATH=/Users/christopherburr/miniconda3/conda-bld/root_1579698021552/_h_env/bin/python2.7. // Path to a file.; Python_INCLUDE_DIR:PATH=/usr/local/Cellar/python/3.7.6/Frameworks/Python.framework/Versions/3.7/include/python3.7m. // Path to a library.; Python_LIBRARY_DEBUG:FILEPATH=Python_LIBRARY_DEBUG-NOTFOUND. // Path to a library.; Python_LIBRARY_RELEASE:FILEPATH=/usr/local/opt/python/Frameworks/Python.framework/Versions/3.7/lib/libpython3.7m.dylib. // Path to a file.; Python_NumPy_INCLUDE_DIR:PATH=/Users/christopherburr/miniconda3/conda-bld/root_1579698021552/_h_env/lib/python2.7/site-packages/numpy/core/include; ```; This PR includes one way of fixing the issue.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4832
https://github.com/root-project/root/pull/4832:1016,Performance,CACHE,CACHED,1016,"When passing `-DPYTHON_EXECUTABLE=/my/path/to/python2` on macOS ROOT fails to configure with newer CMake versions with a bizarre error of:; ```; -- Preferring Python version 3; -- Found Python: /Users/christopherburr/miniconda3/conda-bld/root_1579698021552/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_place/bin/python2.7 (found version ""2.7.15"") found components: Interpreter Development; -- Could NOT find Python (missing: Development) (found version ""2.7.15""); -- Looking for OpenGL; -- Could NOT find OpenGL (missing: OPENGL_gl_LIBRARY OPENGL_INCLUDE_DIR); CMake Error at cmake/modules/SearchInstalledSoftware.cmake:610 (message):; OpenGL package (with GLU) not found and opengl option required; Call Stack (most recent call first):; CMakeLists.txt:167 (include); ```; Looking at the variables I see a weird mixture of python 2 and python 3:; ```; //; PYTHON_EXECUTABLE-CACHED:STRING=/Users/christopherburr/miniconda3/conda-bld/root_1579698021552/_h_env/bin/python. // Path to a program.; Python_EXECUTABLE:FILEPATH=/Users/christopherburr/miniconda3/conda-bld/root_1579698021552/_h_env/bin/python2.7. // Path to a file.; Python_INCLUDE_DIR:PATH=/usr/local/Cellar/python/3.7.6/Frameworks/Python.framework/Versions/3.7/include/python3.7m. // Path to a library.; Python_LIBRARY_DEBUG:FILEPATH=Python_LIBRARY_DEBUG-NOTFOUND. // Path to a library.; Python_LIBRARY_RELEASE:FILEPATH=/usr/local/opt/python/Frameworks/Python.framework/Versions/3.7/lib/libpython3.7m.dylib. // Path to a file.; Python_NumPy_INCLUDE_DIR:PATH=/Users/christopherburr/miniconda3/conda-bld/root_1579698021552/_h_env/lib/python2.7/site-packages/numpy/core/include; ```; This PR includes one way of fixing the issue.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4832
https://github.com/root-project/root/pull/4833:67,Deployability,patch,patches,67,Cherry picked from Ivana's commit f245cb4; Ivana needs this in the patches branch,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4833
https://github.com/root-project/root/pull/4835:77,Deployability,patch,patches,77,Cherry-picked from Ivana's commit f245cb4; Ivana needs this also in v6-18-00-patches,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4835
https://github.com/root-project/root/pull/4837:218,Modifiability,refactor,refactoring,218,"This avoid loading the library containing the dictionary and avoids leaving the TClass::GetClass(""HepMC::GenVertex"") meta information in an odd state. This should bring the v6.18 behavior unintentionally broken in the refactoring commit c8cce31. This should fix ROOT-10514 completely.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4837
https://github.com/root-project/root/pull/4837:11,Performance,load,loading,11,"This avoid loading the library containing the dictionary and avoids leaving the TClass::GetClass(""HepMC::GenVertex"") meta information in an odd state. This should bring the v6.18 behavior unintentionally broken in the refactoring commit c8cce31. This should fix ROOT-10514 completely.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4837
https://github.com/root-project/root/pull/4837:5,Safety,avoid,avoid,5,"This avoid loading the library containing the dictionary and avoids leaving the TClass::GetClass(""HepMC::GenVertex"") meta information in an odd state. This should bring the v6.18 behavior unintentionally broken in the refactoring commit c8cce31. This should fix ROOT-10514 completely.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4837
https://github.com/root-project/root/pull/4837:61,Safety,avoid,avoids,61,"This avoid loading the library containing the dictionary and avoids leaving the TClass::GetClass(""HepMC::GenVertex"") meta information in an odd state. This should bring the v6.18 behavior unintentionally broken in the refactoring commit c8cce31. This should fix ROOT-10514 completely.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4837
https://github.com/root-project/root/pull/4838:31,Deployability,patch,patches,31,"Backport #4806, targeting 6-20 patches.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4838
https://github.com/root-project/root/pull/4841:83,Availability,error,errors,83,Previously the handling was inconsistent resulting in mis-matches; and thus memory errors. This fixes ROOT-10526.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4841
https://github.com/root-project/root/pull/4850:39,Testability,test,tests,39,* Split dataframe_simple.cxx by moving tests for the Display action into; dataframe_display.cxx; * Add test for displaying a std::string; * Test added due to bug reported in ROOT-10527,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4850
https://github.com/root-project/root/pull/4850:103,Testability,test,test,103,* Split dataframe_simple.cxx by moving tests for the Display action into; dataframe_display.cxx; * Add test for displaying a std::string; * Test added due to bug reported in ROOT-10527,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4850
https://github.com/root-project/root/pull/4850:140,Testability,Test,Test,140,* Split dataframe_simple.cxx by moving tests for the Display action into; dataframe_display.cxx; * Add test for displaying a std::string; * Test added due to bug reported in ROOT-10527,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4850
https://github.com/root-project/root/pull/4851:79,Deployability,patch,patch,79,One have to delete result of gSystem->ExpandPathName() function.; Or as in the patch - use other signature.; Little bit simplify the code,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4851
https://github.com/root-project/root/pull/4851:120,Usability,simpl,simplify,120,One have to delete result of gSystem->ExpandPathName() function.; Or as in the patch - use other signature.; Little bit simplify the code,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4851
https://github.com/root-project/root/pull/4855:170,Deployability,install,installed,170,"Use headless Chrome browser, running from file system.; No any HTTP server required.; Following formats are supported: png, pdf, svg, jpeg, webp; Requires that chrome is installed on all test machines; Tested on Linux, Mac and Windows; Exactly same code used with TWebCanvas",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4855
https://github.com/root-project/root/pull/4855:187,Testability,test,test,187,"Use headless Chrome browser, running from file system.; No any HTTP server required.; Following formats are supported: png, pdf, svg, jpeg, webp; Requires that chrome is installed on all test machines; Tested on Linux, Mac and Windows; Exactly same code used with TWebCanvas",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4855
https://github.com/root-project/root/pull/4855:202,Testability,Test,Tested,202,"Use headless Chrome browser, running from file system.; No any HTTP server required.; Following formats are supported: png, pdf, svg, jpeg, webp; Requires that chrome is installed on all test machines; Tested on Linux, Mac and Windows; Exactly same code used with TWebCanvas",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4855
https://github.com/root-project/root/pull/4857:8,Testability,log,logic,8,"The new logic checks if we are in the IPython shell only via the; `builtins` module, thus eliminating the second condition check,; given that IPython can also be in `sys.modules` if it is imported; from the regular Python shell before importing ROOT. Also, using the builtins module in Py3 should be done via; ""import builtins"" instead of `__builtins__`, since as explained here:. https://docs.python.org/3/library/builtins.html#module-builtins. `__builtins__` can be either the `builtins` module or its `__dict__`,; and in the latter case it does not have `'__IPYTHON__'` as attribute,; which causes the condition check for IPython to fail.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4857
https://github.com/root-project/root/pull/4863:47,Deployability,release,released,47,"char* members fName, fTitle, fOption should be released in destructor",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4863
https://github.com/root-project/root/pull/4868:22,Integrability,interface,interface,22,The EnableAutoLoading interface needs to know about the internal TCling implementation to safely enable the autoloading facility in ROOT. Calling this interface cannot be user responsibility as he/she should not know the initialization details of TCling. Make this interface a nop and add a deprecation warning. This should resolve ROOT-10514 and ROOT-10528.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4868
https://github.com/root-project/root/pull/4868:151,Integrability,interface,interface,151,The EnableAutoLoading interface needs to know about the internal TCling implementation to safely enable the autoloading facility in ROOT. Calling this interface cannot be user responsibility as he/she should not know the initialization details of TCling. Make this interface a nop and add a deprecation warning. This should resolve ROOT-10514 and ROOT-10528.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4868
https://github.com/root-project/root/pull/4868:265,Integrability,interface,interface,265,The EnableAutoLoading interface needs to know about the internal TCling implementation to safely enable the autoloading facility in ROOT. Calling this interface cannot be user responsibility as he/she should not know the initialization details of TCling. Make this interface a nop and add a deprecation warning. This should resolve ROOT-10514 and ROOT-10528.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4868
https://github.com/root-project/root/pull/4868:90,Safety,safe,safely,90,The EnableAutoLoading interface needs to know about the internal TCling implementation to safely enable the autoloading facility in ROOT. Calling this interface cannot be user responsibility as he/she should not know the initialization details of TCling. Make this interface a nop and add a deprecation warning. This should resolve ROOT-10514 and ROOT-10528.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4868
https://github.com/root-project/root/pull/4871:255,Availability,down,down,255,"… with ROOT Mutex on. Compiling Interpreter.cpp allows RunFunction and friends to be actually seen during stack unwind after an; exception has been thrown, directly or indirectly, by interpreter code. This allows for the RAII objects to be; properly tear down. In particular, without this patch, EnterUserCodeRAII was not tear down and thus the callbacks were not executed.; Consequently the ""Restore the ROOT global Mutex"" callback was not executed leaving the Mutex in an invalid state. In case of ART application, in most cases, they customize the ROOT error handler to throw an exception. This; resulted (without this fix) in crash when import a GDML file with an error in it. In practice what we have is:. call to TGeo Import; which calls the interpreter for some of its functionality; which calls gdml code; which reports an error; which leads the error handler to thrown an exception.; ... some of the stack are properly unwound ... some are not (because they were not compiled with exception support on) ....; ... so the ROOT Mutex goes into an incorrect state ...; ... unwinding continues; ... unwinding reached a frame that Unlock the mutex; Mutex notices it is an incorrect state.; so it reports the Error; the Error handler throw an exception ....... and because this exception is being thrown during the unwind, it is fatal.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4871
https://github.com/root-project/root/pull/4871:327,Availability,down,down,327,"… with ROOT Mutex on. Compiling Interpreter.cpp allows RunFunction and friends to be actually seen during stack unwind after an; exception has been thrown, directly or indirectly, by interpreter code. This allows for the RAII objects to be; properly tear down. In particular, without this patch, EnterUserCodeRAII was not tear down and thus the callbacks were not executed.; Consequently the ""Restore the ROOT global Mutex"" callback was not executed leaving the Mutex in an invalid state. In case of ART application, in most cases, they customize the ROOT error handler to throw an exception. This; resulted (without this fix) in crash when import a GDML file with an error in it. In practice what we have is:. call to TGeo Import; which calls the interpreter for some of its functionality; which calls gdml code; which reports an error; which leads the error handler to thrown an exception.; ... some of the stack are properly unwound ... some are not (because they were not compiled with exception support on) ....; ... so the ROOT Mutex goes into an incorrect state ...; ... unwinding continues; ... unwinding reached a frame that Unlock the mutex; Mutex notices it is an incorrect state.; so it reports the Error; the Error handler throw an exception ....... and because this exception is being thrown during the unwind, it is fatal.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4871
https://github.com/root-project/root/pull/4871:556,Availability,error,error,556,"… with ROOT Mutex on. Compiling Interpreter.cpp allows RunFunction and friends to be actually seen during stack unwind after an; exception has been thrown, directly or indirectly, by interpreter code. This allows for the RAII objects to be; properly tear down. In particular, without this patch, EnterUserCodeRAII was not tear down and thus the callbacks were not executed.; Consequently the ""Restore the ROOT global Mutex"" callback was not executed leaving the Mutex in an invalid state. In case of ART application, in most cases, they customize the ROOT error handler to throw an exception. This; resulted (without this fix) in crash when import a GDML file with an error in it. In practice what we have is:. call to TGeo Import; which calls the interpreter for some of its functionality; which calls gdml code; which reports an error; which leads the error handler to thrown an exception.; ... some of the stack are properly unwound ... some are not (because they were not compiled with exception support on) ....; ... so the ROOT Mutex goes into an incorrect state ...; ... unwinding continues; ... unwinding reached a frame that Unlock the mutex; Mutex notices it is an incorrect state.; so it reports the Error; the Error handler throw an exception ....... and because this exception is being thrown during the unwind, it is fatal.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4871
https://github.com/root-project/root/pull/4871:668,Availability,error,error,668,"… with ROOT Mutex on. Compiling Interpreter.cpp allows RunFunction and friends to be actually seen during stack unwind after an; exception has been thrown, directly or indirectly, by interpreter code. This allows for the RAII objects to be; properly tear down. In particular, without this patch, EnterUserCodeRAII was not tear down and thus the callbacks were not executed.; Consequently the ""Restore the ROOT global Mutex"" callback was not executed leaving the Mutex in an invalid state. In case of ART application, in most cases, they customize the ROOT error handler to throw an exception. This; resulted (without this fix) in crash when import a GDML file with an error in it. In practice what we have is:. call to TGeo Import; which calls the interpreter for some of its functionality; which calls gdml code; which reports an error; which leads the error handler to thrown an exception.; ... some of the stack are properly unwound ... some are not (because they were not compiled with exception support on) ....; ... so the ROOT Mutex goes into an incorrect state ...; ... unwinding continues; ... unwinding reached a frame that Unlock the mutex; Mutex notices it is an incorrect state.; so it reports the Error; the Error handler throw an exception ....... and because this exception is being thrown during the unwind, it is fatal.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4871
https://github.com/root-project/root/pull/4871:831,Availability,error,error,831,"… with ROOT Mutex on. Compiling Interpreter.cpp allows RunFunction and friends to be actually seen during stack unwind after an; exception has been thrown, directly or indirectly, by interpreter code. This allows for the RAII objects to be; properly tear down. In particular, without this patch, EnterUserCodeRAII was not tear down and thus the callbacks were not executed.; Consequently the ""Restore the ROOT global Mutex"" callback was not executed leaving the Mutex in an invalid state. In case of ART application, in most cases, they customize the ROOT error handler to throw an exception. This; resulted (without this fix) in crash when import a GDML file with an error in it. In practice what we have is:. call to TGeo Import; which calls the interpreter for some of its functionality; which calls gdml code; which reports an error; which leads the error handler to thrown an exception.; ... some of the stack are properly unwound ... some are not (because they were not compiled with exception support on) ....; ... so the ROOT Mutex goes into an incorrect state ...; ... unwinding continues; ... unwinding reached a frame that Unlock the mutex; Mutex notices it is an incorrect state.; so it reports the Error; the Error handler throw an exception ....... and because this exception is being thrown during the unwind, it is fatal.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4871
https://github.com/root-project/root/pull/4871:854,Availability,error,error,854,"… with ROOT Mutex on. Compiling Interpreter.cpp allows RunFunction and friends to be actually seen during stack unwind after an; exception has been thrown, directly or indirectly, by interpreter code. This allows for the RAII objects to be; properly tear down. In particular, without this patch, EnterUserCodeRAII was not tear down and thus the callbacks were not executed.; Consequently the ""Restore the ROOT global Mutex"" callback was not executed leaving the Mutex in an invalid state. In case of ART application, in most cases, they customize the ROOT error handler to throw an exception. This; resulted (without this fix) in crash when import a GDML file with an error in it. In practice what we have is:. call to TGeo Import; which calls the interpreter for some of its functionality; which calls gdml code; which reports an error; which leads the error handler to thrown an exception.; ... some of the stack are properly unwound ... some are not (because they were not compiled with exception support on) ....; ... so the ROOT Mutex goes into an incorrect state ...; ... unwinding continues; ... unwinding reached a frame that Unlock the mutex; Mutex notices it is an incorrect state.; so it reports the Error; the Error handler throw an exception ....... and because this exception is being thrown during the unwind, it is fatal.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4871
https://github.com/root-project/root/pull/4871:1211,Availability,Error,Error,1211,"… with ROOT Mutex on. Compiling Interpreter.cpp allows RunFunction and friends to be actually seen during stack unwind after an; exception has been thrown, directly or indirectly, by interpreter code. This allows for the RAII objects to be; properly tear down. In particular, without this patch, EnterUserCodeRAII was not tear down and thus the callbacks were not executed.; Consequently the ""Restore the ROOT global Mutex"" callback was not executed leaving the Mutex in an invalid state. In case of ART application, in most cases, they customize the ROOT error handler to throw an exception. This; resulted (without this fix) in crash when import a GDML file with an error in it. In practice what we have is:. call to TGeo Import; which calls the interpreter for some of its functionality; which calls gdml code; which reports an error; which leads the error handler to thrown an exception.; ... some of the stack are properly unwound ... some are not (because they were not compiled with exception support on) ....; ... so the ROOT Mutex goes into an incorrect state ...; ... unwinding continues; ... unwinding reached a frame that Unlock the mutex; Mutex notices it is an incorrect state.; so it reports the Error; the Error handler throw an exception ....... and because this exception is being thrown during the unwind, it is fatal.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4871
https://github.com/root-project/root/pull/4871:1222,Availability,Error,Error,1222,"… with ROOT Mutex on. Compiling Interpreter.cpp allows RunFunction and friends to be actually seen during stack unwind after an; exception has been thrown, directly or indirectly, by interpreter code. This allows for the RAII objects to be; properly tear down. In particular, without this patch, EnterUserCodeRAII was not tear down and thus the callbacks were not executed.; Consequently the ""Restore the ROOT global Mutex"" callback was not executed leaving the Mutex in an invalid state. In case of ART application, in most cases, they customize the ROOT error handler to throw an exception. This; resulted (without this fix) in crash when import a GDML file with an error in it. In practice what we have is:. call to TGeo Import; which calls the interpreter for some of its functionality; which calls gdml code; which reports an error; which leads the error handler to thrown an exception.; ... some of the stack are properly unwound ... some are not (because they were not compiled with exception support on) ....; ... so the ROOT Mutex goes into an incorrect state ...; ... unwinding continues; ... unwinding reached a frame that Unlock the mutex; Mutex notices it is an incorrect state.; so it reports the Error; the Error handler throw an exception ....... and because this exception is being thrown during the unwind, it is fatal.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4871
https://github.com/root-project/root/pull/4871:289,Deployability,patch,patch,289,"… with ROOT Mutex on. Compiling Interpreter.cpp allows RunFunction and friends to be actually seen during stack unwind after an; exception has been thrown, directly or indirectly, by interpreter code. This allows for the RAII objects to be; properly tear down. In particular, without this patch, EnterUserCodeRAII was not tear down and thus the callbacks were not executed.; Consequently the ""Restore the ROOT global Mutex"" callback was not executed leaving the Mutex in an invalid state. In case of ART application, in most cases, they customize the ROOT error handler to throw an exception. This; resulted (without this fix) in crash when import a GDML file with an error in it. In practice what we have is:. call to TGeo Import; which calls the interpreter for some of its functionality; which calls gdml code; which reports an error; which leads the error handler to thrown an exception.; ... some of the stack are properly unwound ... some are not (because they were not compiled with exception support on) ....; ... so the ROOT Mutex goes into an incorrect state ...; ... unwinding continues; ... unwinding reached a frame that Unlock the mutex; Mutex notices it is an incorrect state.; so it reports the Error; the Error handler throw an exception ....... and because this exception is being thrown during the unwind, it is fatal.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4871
https://github.com/root-project/root/pull/4874:417,Integrability,interface,interface,417,"There are several methods in TSystem, which returns `char *` as return value, which has to be deleted. These are:; * `ExapndPathName()`; * `DirName()` (Windows only, actually a bug); * `Which()`; * `ConcatFileName()`. There are many places in ROOT which does not do it correctly, making memory leaks.; I tried to fixed all these bugs - still open PRs are #4853, #4854, #4861, #4862, #4863 . Idea to modernize TSystem interface, providing thread-safe alternatives to all mentioned methods.; Means return TString instead of `char *` or `const char *`.; Keep old methods for a while, but replace in ROOT code to new one.; Later old methods should be declared as deprecated. This PR introduces `TString TSystem::GetDirName(const char *)` as replacement of `const char * TSystem::DirName(const char *)`. Solving Windows issue, which has memory leak. Replaces all places where DirName used by GetDirName - in most cases TString used anyway as storage for return value. . Also using more C++11 in declaration of TSystem classes. If we agreed on this approach, next methods can be refactored in same way.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4874
https://github.com/root-project/root/pull/4874:1073,Modifiability,refactor,refactored,1073,"There are several methods in TSystem, which returns `char *` as return value, which has to be deleted. These are:; * `ExapndPathName()`; * `DirName()` (Windows only, actually a bug); * `Which()`; * `ConcatFileName()`. There are many places in ROOT which does not do it correctly, making memory leaks.; I tried to fixed all these bugs - still open PRs are #4853, #4854, #4861, #4862, #4863 . Idea to modernize TSystem interface, providing thread-safe alternatives to all mentioned methods.; Means return TString instead of `char *` or `const char *`.; Keep old methods for a while, but replace in ROOT code to new one.; Later old methods should be declared as deprecated. This PR introduces `TString TSystem::GetDirName(const char *)` as replacement of `const char * TSystem::DirName(const char *)`. Solving Windows issue, which has memory leak. Replaces all places where DirName used by GetDirName - in most cases TString used anyway as storage for return value. . Also using more C++11 in declaration of TSystem classes. If we agreed on this approach, next methods can be refactored in same way.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4874
https://github.com/root-project/root/pull/4874:445,Safety,safe,safe,445,"There are several methods in TSystem, which returns `char *` as return value, which has to be deleted. These are:; * `ExapndPathName()`; * `DirName()` (Windows only, actually a bug); * `Which()`; * `ConcatFileName()`. There are many places in ROOT which does not do it correctly, making memory leaks.; I tried to fixed all these bugs - still open PRs are #4853, #4854, #4861, #4862, #4863 . Idea to modernize TSystem interface, providing thread-safe alternatives to all mentioned methods.; Means return TString instead of `char *` or `const char *`.; Keep old methods for a while, but replace in ROOT code to new one.; Later old methods should be declared as deprecated. This PR introduces `TString TSystem::GetDirName(const char *)` as replacement of `const char * TSystem::DirName(const char *)`. Solving Windows issue, which has memory leak. Replaces all places where DirName used by GetDirName - in most cases TString used anyway as storage for return value. . Also using more C++11 in declaration of TSystem classes. If we agreed on this approach, next methods can be refactored in same way.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4874
https://github.com/root-project/root/pull/4875:192,Integrability,interface,interface,192,Collection of three short improvements:; - Better docs for SPlot; - Shorten run time of rf402 tutorial by removing unnecessary printouts; - [ROOT-10521] Better const-correctness in RooAbsData interface,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4875
https://github.com/root-project/root/pull/4876:70,Availability,error,error,70,We need to have class.rules during configuration time to avoid silent error during generation of dictionary: Error in <TClass::ReadRules()>: Cannot find rules,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4876
https://github.com/root-project/root/pull/4876:109,Availability,Error,Error,109,We need to have class.rules during configuration time to avoid silent error during generation of dictionary: Error in <TClass::ReadRules()>: Cannot find rules,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4876
https://github.com/root-project/root/pull/4876:35,Deployability,configurat,configuration,35,We need to have class.rules during configuration time to avoid silent error during generation of dictionary: Error in <TClass::ReadRules()>: Cannot find rules,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4876
https://github.com/root-project/root/pull/4876:35,Modifiability,config,configuration,35,We need to have class.rules during configuration time to avoid silent error during generation of dictionary: Error in <TClass::ReadRules()>: Cannot find rules,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4876
https://github.com/root-project/root/pull/4876:57,Safety,avoid,avoid,57,We need to have class.rules during configuration time to avoid silent error during generation of dictionary: Error in <TClass::ReadRules()>: Cannot find rules,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4876
https://github.com/root-project/root/pull/4877:243,Modifiability,plugin,plugin,243,"In preparation for fixing ROOT-10520, this PR moves the `RRawFile` classes out of the `Experimental` namespace into `Internal`. A follow-up pull request will modify the RDF SQLite data source such that it uses RRawFile, which in turn uses the plugin infrastructure to load the Davix libraries when necessary. Should be merged before #4878.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4877
https://github.com/root-project/root/pull/4877:268,Performance,load,load,268,"In preparation for fixing ROOT-10520, this PR moves the `RRawFile` classes out of the `Experimental` namespace into `Internal`. A follow-up pull request will modify the RDF SQLite data source such that it uses RRawFile, which in turn uses the plugin infrastructure to load the Davix libraries when necessary. Should be merged before #4878.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4877
https://github.com/root-project/root/pull/4878:58,Integrability,depend,dependency,58,This is the follow-up to #4877. It removes the hard Davix dependency from RDataFrame.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4878
https://github.com/root-project/root/pull/4879:6,Testability,test,test,6,Add a test to reproduce the issue described in [ROOT-10508](https://sft.its.cern.ch/jira/browse/ROOT-10508?jql=project%20%3D%20ROOT%20AND%20issuetype%20%3D%20Bug%20AND%20status%20%3D%20Open%20AND%20resolution%20%3D%20Unresolved%20AND%20text%20~%20%22RDataFrame%22%20ORDER%20BY%20priority%20DESC%2C%20updated%20DESC). Fixed the issue for the case if the friend chain is unnamed since then the current logic does not retrieve the name of the underlying tree correctly. See the jira ticket for the full discussion.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4879
https://github.com/root-project/root/pull/4879:400,Testability,log,logic,400,Add a test to reproduce the issue described in [ROOT-10508](https://sft.its.cern.ch/jira/browse/ROOT-10508?jql=project%20%3D%20ROOT%20AND%20issuetype%20%3D%20Bug%20AND%20status%20%3D%20Open%20AND%20resolution%20%3D%20Unresolved%20AND%20text%20~%20%22RDataFrame%22%20ORDER%20BY%20priority%20DESC%2C%20updated%20DESC). Fixed the issue for the case if the friend chain is unnamed since then the current logic does not retrieve the name of the underlying tree correctly. See the jira ticket for the full discussion.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4879
https://github.com/root-project/root/pull/4880:6,Availability,failure,failure,6,Avoid failure of v7/line.cxx tutorial in such case. Disable headless in CEF and QWebEngine plugins.; Both do not provide any functionality without X-server running,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4880
https://github.com/root-project/root/pull/4880:91,Modifiability,plugin,plugins,91,Avoid failure of v7/line.cxx tutorial in such case. Disable headless in CEF and QWebEngine plugins.; Both do not provide any functionality without X-server running,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4880
https://github.com/root-project/root/pull/4880:0,Safety,Avoid,Avoid,0,Avoid failure of v7/line.cxx tutorial in such case. Disable headless in CEF and QWebEngine plugins.; Both do not provide any functionality without X-server running,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4880
https://github.com/root-project/root/pull/4881:59,Safety,avoid,avoid,59,Wrong delete operator was used (it is @a5db401 commit); To avoid any confusion in the future - just use TString instead,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4881
https://github.com/root-project/root/pull/4882:120,Availability,failure,failure,120,"This fixes ROOT-10504. the script:; ```. namespace boost { namespace mpl {. // Commenting the next line make the assert failure go away; struct TTUBE {};. }}. ```; reproduce the problem with 'just' ROOT. The trigger is the auto-loading of a library that has a dictionary with has forward decl string .. which all starts with:; ```; static const char* fwdDeclCode = R""DICTFWDDCLS(; extern int __Cling_Autoloading_Map;; ....; ```. The order of parsing is (with many ellipsis):; ```; ""<<< cling interactive line includer >>>"" : line 9 : #include “standalone.C”; standalone.C : line 1 : #pragma GCC diagnostic push; standalone.C : line 2 : #pragma GCC diagnostic ignored ""-Wuninitialized"" // Inserted in Diag map; standalone.C : line 3 : #pragma GCC diagnostic ignored ""-Wsign-conversion"" // Inserted in Diag map; standalone.C : line 8 : struct TTUBE {} ; // triggers auto-loading and thus recursive parsing. ""<<< cling interactive line includer >>>"" : line 10 : parse dict fwd declare string; input_line_9 : line 2 : #pragma clang diagnostic ignored ""-Wkeyword-compat"" // Inserted in Diag map; input_line_9 : line 3 : #pragma clang diagnostic ignored ""-Wignored-attributes"" // Inserted in Diag map; input_line_9 : line 4 : #pragma clang diagnostic ignored ""-Wreturn-type-c-linkage"" // Inserted in Diag map. end of file. standalone.C : line 12 : #pragma GCC diagnostic pop // Inserted in Diag map; ```; The last line triggers the assert because when recording the state change, it records it as being from; ```; standalone.C : line 12; ""<<< cling interactive line includer >>>"" : line 9; ```; but when recording the last one, it notices that the last state change that happened, indirectly, for the file '<<< cling interactive line includer >>>' happened at line 10 (because of the pragma in input_line_9 which is 'recorded' as being included by line 10),; which makes that the state change for ```standalone.C:12``` happens 'ealier' than the last state change as far as the pseudo-file ""<<< cling interac",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4882
https://github.com/root-project/root/pull/4882:228,Performance,load,loading,228,"This fixes ROOT-10504. the script:; ```. namespace boost { namespace mpl {. // Commenting the next line make the assert failure go away; struct TTUBE {};. }}. ```; reproduce the problem with 'just' ROOT. The trigger is the auto-loading of a library that has a dictionary with has forward decl string .. which all starts with:; ```; static const char* fwdDeclCode = R""DICTFWDDCLS(; extern int __Cling_Autoloading_Map;; ....; ```. The order of parsing is (with many ellipsis):; ```; ""<<< cling interactive line includer >>>"" : line 9 : #include “standalone.C”; standalone.C : line 1 : #pragma GCC diagnostic push; standalone.C : line 2 : #pragma GCC diagnostic ignored ""-Wuninitialized"" // Inserted in Diag map; standalone.C : line 3 : #pragma GCC diagnostic ignored ""-Wsign-conversion"" // Inserted in Diag map; standalone.C : line 8 : struct TTUBE {} ; // triggers auto-loading and thus recursive parsing. ""<<< cling interactive line includer >>>"" : line 10 : parse dict fwd declare string; input_line_9 : line 2 : #pragma clang diagnostic ignored ""-Wkeyword-compat"" // Inserted in Diag map; input_line_9 : line 3 : #pragma clang diagnostic ignored ""-Wignored-attributes"" // Inserted in Diag map; input_line_9 : line 4 : #pragma clang diagnostic ignored ""-Wreturn-type-c-linkage"" // Inserted in Diag map. end of file. standalone.C : line 12 : #pragma GCC diagnostic pop // Inserted in Diag map; ```; The last line triggers the assert because when recording the state change, it records it as being from; ```; standalone.C : line 12; ""<<< cling interactive line includer >>>"" : line 9; ```; but when recording the last one, it notices that the last state change that happened, indirectly, for the file '<<< cling interactive line includer >>>' happened at line 10 (because of the pragma in input_line_9 which is 'recorded' as being included by line 10),; which makes that the state change for ```standalone.C:12``` happens 'ealier' than the last state change as far as the pseudo-file ""<<< cling interac",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4882
https://github.com/root-project/root/pull/4882:869,Performance,load,loading,869,"This fixes ROOT-10504. the script:; ```. namespace boost { namespace mpl {. // Commenting the next line make the assert failure go away; struct TTUBE {};. }}. ```; reproduce the problem with 'just' ROOT. The trigger is the auto-loading of a library that has a dictionary with has forward decl string .. which all starts with:; ```; static const char* fwdDeclCode = R""DICTFWDDCLS(; extern int __Cling_Autoloading_Map;; ....; ```. The order of parsing is (with many ellipsis):; ```; ""<<< cling interactive line includer >>>"" : line 9 : #include “standalone.C”; standalone.C : line 1 : #pragma GCC diagnostic push; standalone.C : line 2 : #pragma GCC diagnostic ignored ""-Wuninitialized"" // Inserted in Diag map; standalone.C : line 3 : #pragma GCC diagnostic ignored ""-Wsign-conversion"" // Inserted in Diag map; standalone.C : line 8 : struct TTUBE {} ; // triggers auto-loading and thus recursive parsing. ""<<< cling interactive line includer >>>"" : line 10 : parse dict fwd declare string; input_line_9 : line 2 : #pragma clang diagnostic ignored ""-Wkeyword-compat"" // Inserted in Diag map; input_line_9 : line 3 : #pragma clang diagnostic ignored ""-Wignored-attributes"" // Inserted in Diag map; input_line_9 : line 4 : #pragma clang diagnostic ignored ""-Wreturn-type-c-linkage"" // Inserted in Diag map. end of file. standalone.C : line 12 : #pragma GCC diagnostic pop // Inserted in Diag map; ```; The last line triggers the assert because when recording the state change, it records it as being from; ```; standalone.C : line 12; ""<<< cling interactive line includer >>>"" : line 9; ```; but when recording the last one, it notices that the last state change that happened, indirectly, for the file '<<< cling interactive line includer >>>' happened at line 10 (because of the pragma in input_line_9 which is 'recorded' as being included by line 10),; which makes that the state change for ```standalone.C:12``` happens 'ealier' than the last state change as far as the pseudo-file ""<<< cling interac",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4882
https://github.com/root-project/root/pull/4882:113,Testability,assert,assert,113,"This fixes ROOT-10504. the script:; ```. namespace boost { namespace mpl {. // Commenting the next line make the assert failure go away; struct TTUBE {};. }}. ```; reproduce the problem with 'just' ROOT. The trigger is the auto-loading of a library that has a dictionary with has forward decl string .. which all starts with:; ```; static const char* fwdDeclCode = R""DICTFWDDCLS(; extern int __Cling_Autoloading_Map;; ....; ```. The order of parsing is (with many ellipsis):; ```; ""<<< cling interactive line includer >>>"" : line 9 : #include “standalone.C”; standalone.C : line 1 : #pragma GCC diagnostic push; standalone.C : line 2 : #pragma GCC diagnostic ignored ""-Wuninitialized"" // Inserted in Diag map; standalone.C : line 3 : #pragma GCC diagnostic ignored ""-Wsign-conversion"" // Inserted in Diag map; standalone.C : line 8 : struct TTUBE {} ; // triggers auto-loading and thus recursive parsing. ""<<< cling interactive line includer >>>"" : line 10 : parse dict fwd declare string; input_line_9 : line 2 : #pragma clang diagnostic ignored ""-Wkeyword-compat"" // Inserted in Diag map; input_line_9 : line 3 : #pragma clang diagnostic ignored ""-Wignored-attributes"" // Inserted in Diag map; input_line_9 : line 4 : #pragma clang diagnostic ignored ""-Wreturn-type-c-linkage"" // Inserted in Diag map. end of file. standalone.C : line 12 : #pragma GCC diagnostic pop // Inserted in Diag map; ```; The last line triggers the assert because when recording the state change, it records it as being from; ```; standalone.C : line 12; ""<<< cling interactive line includer >>>"" : line 9; ```; but when recording the last one, it notices that the last state change that happened, indirectly, for the file '<<< cling interactive line includer >>>' happened at line 10 (because of the pragma in input_line_9 which is 'recorded' as being included by line 10),; which makes that the state change for ```standalone.C:12``` happens 'ealier' than the last state change as far as the pseudo-file ""<<< cling interac",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4882
https://github.com/root-project/root/pull/4882:1426,Testability,assert,assert,1426,"just' ROOT. The trigger is the auto-loading of a library that has a dictionary with has forward decl string .. which all starts with:; ```; static const char* fwdDeclCode = R""DICTFWDDCLS(; extern int __Cling_Autoloading_Map;; ....; ```. The order of parsing is (with many ellipsis):; ```; ""<<< cling interactive line includer >>>"" : line 9 : #include “standalone.C”; standalone.C : line 1 : #pragma GCC diagnostic push; standalone.C : line 2 : #pragma GCC diagnostic ignored ""-Wuninitialized"" // Inserted in Diag map; standalone.C : line 3 : #pragma GCC diagnostic ignored ""-Wsign-conversion"" // Inserted in Diag map; standalone.C : line 8 : struct TTUBE {} ; // triggers auto-loading and thus recursive parsing. ""<<< cling interactive line includer >>>"" : line 10 : parse dict fwd declare string; input_line_9 : line 2 : #pragma clang diagnostic ignored ""-Wkeyword-compat"" // Inserted in Diag map; input_line_9 : line 3 : #pragma clang diagnostic ignored ""-Wignored-attributes"" // Inserted in Diag map; input_line_9 : line 4 : #pragma clang diagnostic ignored ""-Wreturn-type-c-linkage"" // Inserted in Diag map. end of file. standalone.C : line 12 : #pragma GCC diagnostic pop // Inserted in Diag map; ```; The last line triggers the assert because when recording the state change, it records it as being from; ```; standalone.C : line 12; ""<<< cling interactive line includer >>>"" : line 9; ```; but when recording the last one, it notices that the last state change that happened, indirectly, for the file '<<< cling interactive line includer >>>' happened at line 10 (because of the pragma in input_line_9 which is 'recorded' as being included by line 10),; which makes that the state change for ```standalone.C:12``` happens 'ealier' than the last state change as far as the pseudo-file ""<<< cling interactive line includer >>>"" is concerned. For that pseudo-file, the last state change happened line 10 but the state change bbeing processed happens line 9 (where Standalone.C is being included).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4882
https://github.com/root-project/root/pull/4883:120,Availability,failure,failure,120,"This fixes ROOT-10504. the script:; ```. namespace boost { namespace mpl {. // Commenting the next line make the assert failure go away; struct TTUBE {};. }}. ```; reproduce the problem with 'just' ROOT. The trigger is the auto-loading of a library that has a dictionary with has forward decl string .. which all starts with:; ```; static const char* fwdDeclCode = R""DICTFWDDCLS(; extern int __Cling_Autoloading_Map;; ....; ```. The order of parsing is (with many ellipsis):; ```; ""<<< cling interactive line includer >>>"" : line 9 : #include “standalone.C”; standalone.C : line 1 : #pragma GCC diagnostic push; standalone.C : line 2 : #pragma GCC diagnostic ignored ""-Wuninitialized"" // Inserted in Diag map; standalone.C : line 3 : #pragma GCC diagnostic ignored ""-Wsign-conversion"" // Inserted in Diag map; standalone.C : line 8 : struct TTUBE {} ; // triggers auto-loading and thus recursive parsing. ""<<< cling interactive line includer >>>"" : line 10 : parse dict fwd declare string; input_line_9 : line 2 : #pragma clang diagnostic ignored ""-Wkeyword-compat"" // Inserted in Diag map; input_line_9 : line 3 : #pragma clang diagnostic ignored ""-Wignored-attributes"" // Inserted in Diag map; input_line_9 : line 4 : #pragma clang diagnostic ignored ""-Wreturn-type-c-linkage"" // Inserted in Diag map. end of file. standalone.C : line 12 : #pragma GCC diagnostic pop // Inserted in Diag map; ```; The last line triggers the assert because when recording the state change, it records it as being from; ```; standalone.C : line 12; ""<<< cling interactive line includer >>>"" : line 9; ```; but when recording the last one, it notices that the last state change that happened, indirectly, for the file '<<< cling interactive line includer >>>' happened at line 10 (because of the pragma in input_line_9 which is 'recorded' as being included by line 10),; which makes that the state change for ```standalone.C:12``` happens 'ealier' than the last state change as far as the pseudo-file ""<<< cling interac",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4883
https://github.com/root-project/root/pull/4883:228,Performance,load,loading,228,"This fixes ROOT-10504. the script:; ```. namespace boost { namespace mpl {. // Commenting the next line make the assert failure go away; struct TTUBE {};. }}. ```; reproduce the problem with 'just' ROOT. The trigger is the auto-loading of a library that has a dictionary with has forward decl string .. which all starts with:; ```; static const char* fwdDeclCode = R""DICTFWDDCLS(; extern int __Cling_Autoloading_Map;; ....; ```. The order of parsing is (with many ellipsis):; ```; ""<<< cling interactive line includer >>>"" : line 9 : #include “standalone.C”; standalone.C : line 1 : #pragma GCC diagnostic push; standalone.C : line 2 : #pragma GCC diagnostic ignored ""-Wuninitialized"" // Inserted in Diag map; standalone.C : line 3 : #pragma GCC diagnostic ignored ""-Wsign-conversion"" // Inserted in Diag map; standalone.C : line 8 : struct TTUBE {} ; // triggers auto-loading and thus recursive parsing. ""<<< cling interactive line includer >>>"" : line 10 : parse dict fwd declare string; input_line_9 : line 2 : #pragma clang diagnostic ignored ""-Wkeyword-compat"" // Inserted in Diag map; input_line_9 : line 3 : #pragma clang diagnostic ignored ""-Wignored-attributes"" // Inserted in Diag map; input_line_9 : line 4 : #pragma clang diagnostic ignored ""-Wreturn-type-c-linkage"" // Inserted in Diag map. end of file. standalone.C : line 12 : #pragma GCC diagnostic pop // Inserted in Diag map; ```; The last line triggers the assert because when recording the state change, it records it as being from; ```; standalone.C : line 12; ""<<< cling interactive line includer >>>"" : line 9; ```; but when recording the last one, it notices that the last state change that happened, indirectly, for the file '<<< cling interactive line includer >>>' happened at line 10 (because of the pragma in input_line_9 which is 'recorded' as being included by line 10),; which makes that the state change for ```standalone.C:12``` happens 'ealier' than the last state change as far as the pseudo-file ""<<< cling interac",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4883
https://github.com/root-project/root/pull/4883:869,Performance,load,loading,869,"This fixes ROOT-10504. the script:; ```. namespace boost { namespace mpl {. // Commenting the next line make the assert failure go away; struct TTUBE {};. }}. ```; reproduce the problem with 'just' ROOT. The trigger is the auto-loading of a library that has a dictionary with has forward decl string .. which all starts with:; ```; static const char* fwdDeclCode = R""DICTFWDDCLS(; extern int __Cling_Autoloading_Map;; ....; ```. The order of parsing is (with many ellipsis):; ```; ""<<< cling interactive line includer >>>"" : line 9 : #include “standalone.C”; standalone.C : line 1 : #pragma GCC diagnostic push; standalone.C : line 2 : #pragma GCC diagnostic ignored ""-Wuninitialized"" // Inserted in Diag map; standalone.C : line 3 : #pragma GCC diagnostic ignored ""-Wsign-conversion"" // Inserted in Diag map; standalone.C : line 8 : struct TTUBE {} ; // triggers auto-loading and thus recursive parsing. ""<<< cling interactive line includer >>>"" : line 10 : parse dict fwd declare string; input_line_9 : line 2 : #pragma clang diagnostic ignored ""-Wkeyword-compat"" // Inserted in Diag map; input_line_9 : line 3 : #pragma clang diagnostic ignored ""-Wignored-attributes"" // Inserted in Diag map; input_line_9 : line 4 : #pragma clang diagnostic ignored ""-Wreturn-type-c-linkage"" // Inserted in Diag map. end of file. standalone.C : line 12 : #pragma GCC diagnostic pop // Inserted in Diag map; ```; The last line triggers the assert because when recording the state change, it records it as being from; ```; standalone.C : line 12; ""<<< cling interactive line includer >>>"" : line 9; ```; but when recording the last one, it notices that the last state change that happened, indirectly, for the file '<<< cling interactive line includer >>>' happened at line 10 (because of the pragma in input_line_9 which is 'recorded' as being included by line 10),; which makes that the state change for ```standalone.C:12``` happens 'ealier' than the last state change as far as the pseudo-file ""<<< cling interac",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4883
https://github.com/root-project/root/pull/4883:113,Testability,assert,assert,113,"This fixes ROOT-10504. the script:; ```. namespace boost { namespace mpl {. // Commenting the next line make the assert failure go away; struct TTUBE {};. }}. ```; reproduce the problem with 'just' ROOT. The trigger is the auto-loading of a library that has a dictionary with has forward decl string .. which all starts with:; ```; static const char* fwdDeclCode = R""DICTFWDDCLS(; extern int __Cling_Autoloading_Map;; ....; ```. The order of parsing is (with many ellipsis):; ```; ""<<< cling interactive line includer >>>"" : line 9 : #include “standalone.C”; standalone.C : line 1 : #pragma GCC diagnostic push; standalone.C : line 2 : #pragma GCC diagnostic ignored ""-Wuninitialized"" // Inserted in Diag map; standalone.C : line 3 : #pragma GCC diagnostic ignored ""-Wsign-conversion"" // Inserted in Diag map; standalone.C : line 8 : struct TTUBE {} ; // triggers auto-loading and thus recursive parsing. ""<<< cling interactive line includer >>>"" : line 10 : parse dict fwd declare string; input_line_9 : line 2 : #pragma clang diagnostic ignored ""-Wkeyword-compat"" // Inserted in Diag map; input_line_9 : line 3 : #pragma clang diagnostic ignored ""-Wignored-attributes"" // Inserted in Diag map; input_line_9 : line 4 : #pragma clang diagnostic ignored ""-Wreturn-type-c-linkage"" // Inserted in Diag map. end of file. standalone.C : line 12 : #pragma GCC diagnostic pop // Inserted in Diag map; ```; The last line triggers the assert because when recording the state change, it records it as being from; ```; standalone.C : line 12; ""<<< cling interactive line includer >>>"" : line 9; ```; but when recording the last one, it notices that the last state change that happened, indirectly, for the file '<<< cling interactive line includer >>>' happened at line 10 (because of the pragma in input_line_9 which is 'recorded' as being included by line 10),; which makes that the state change for ```standalone.C:12``` happens 'ealier' than the last state change as far as the pseudo-file ""<<< cling interac",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4883
https://github.com/root-project/root/pull/4883:1426,Testability,assert,assert,1426,"just' ROOT. The trigger is the auto-loading of a library that has a dictionary with has forward decl string .. which all starts with:; ```; static const char* fwdDeclCode = R""DICTFWDDCLS(; extern int __Cling_Autoloading_Map;; ....; ```. The order of parsing is (with many ellipsis):; ```; ""<<< cling interactive line includer >>>"" : line 9 : #include “standalone.C”; standalone.C : line 1 : #pragma GCC diagnostic push; standalone.C : line 2 : #pragma GCC diagnostic ignored ""-Wuninitialized"" // Inserted in Diag map; standalone.C : line 3 : #pragma GCC diagnostic ignored ""-Wsign-conversion"" // Inserted in Diag map; standalone.C : line 8 : struct TTUBE {} ; // triggers auto-loading and thus recursive parsing. ""<<< cling interactive line includer >>>"" : line 10 : parse dict fwd declare string; input_line_9 : line 2 : #pragma clang diagnostic ignored ""-Wkeyword-compat"" // Inserted in Diag map; input_line_9 : line 3 : #pragma clang diagnostic ignored ""-Wignored-attributes"" // Inserted in Diag map; input_line_9 : line 4 : #pragma clang diagnostic ignored ""-Wreturn-type-c-linkage"" // Inserted in Diag map. end of file. standalone.C : line 12 : #pragma GCC diagnostic pop // Inserted in Diag map; ```; The last line triggers the assert because when recording the state change, it records it as being from; ```; standalone.C : line 12; ""<<< cling interactive line includer >>>"" : line 9; ```; but when recording the last one, it notices that the last state change that happened, indirectly, for the file '<<< cling interactive line includer >>>' happened at line 10 (because of the pragma in input_line_9 which is 'recorded' as being included by line 10),; which makes that the state change for ```standalone.C:12``` happens 'ealier' than the last state change as far as the pseudo-file ""<<< cling interactive line includer >>>"" is concerned. For that pseudo-file, the last state change happened line 10 but the state change bbeing processed happens line 9 (where Standalone.C is being included).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4883
https://github.com/root-project/root/pull/4885:247,Availability,error,errors,247,"[ROOT-10518] Due to overwriting a function-local static, range strings; for multi-range fits would be lost. The full range was fitted multiple; times. This results in exactly the same coefficients as when fitting the; full range, but in different errors, as the model is fitted repeatedly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4885
https://github.com/root-project/root/pull/4886:247,Availability,error,errors,247,"[ROOT-10518] Due to overwriting a function-local static, range strings; for multi-range fits would be lost. The full range was fitted multiple; times. This results in exactly the same coefficients as when fitting the; full range, but in different errors, as the model is fitted repeatedly. (cherry picked from commit 4f53b0fd7e01a4ba40656940359eaa5567072d75)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4886
https://github.com/root-project/root/pull/4887:42,Energy Efficiency,allocate,allocated,42,Most leaks are due to wrong management of allocated `char*` buffers via StrDup - thats how I detect them. Better to be applied after #4874,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4887
https://github.com/root-project/root/pull/4887:93,Safety,detect,detect,93,Most leaks are due to wrong management of allocated `char*` buffers via StrDup - thats how I detect them. Better to be applied after #4874,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4887
https://github.com/root-project/root/pull/4889:65,Safety,avoid,avoid,65,Replace gSystem->Which() with gSystem->FindFile() calls; Idea to avoid methods which returns `char *` value which should be deleted.; While there is already alternative - use it.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4889
https://github.com/root-project/root/pull/4892:233,Availability,down,down,233,"Compiling Interpreter.cpp allows RunFunction and friends to be actually seen during stack unwind after an; exception has been thrown, directly or indirectly, by interpreter code. This allows for the RAII objects to be; properly tear down. In particular, without this patch, EnterUserCodeRAII was not tear down and thus the callbacks were not executed.; Consequently the ""Restore the ROOT global Mutex"" callback was not executed leaving the Mutex in an invalid state. In case of ART application, in most cases, they customize the ROOT error handler to throw an exception. This; resulted (without this fix) in crash when import a GDML file with an error in it. In practice what we have is:. call to TGeo Import; which calls the interpreter for some of its functionality; which calls gdml code; which reports an error; which leads the error handler to thrown an exception.; ... some of the stack are properly unwound ... some are not (because they were not compiled with exception support on) ....; ... so the ROOT Mutex goes into an incorrect state ...; ... unwinding continues; ... unwinding reached a frame that Unlock the mutex; Mutex notices it is an incorrect state.; so it reports the Error; the Error handler throw an exception ....... and because this exception is being thrown during the unwind, it is fatal.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4892
https://github.com/root-project/root/pull/4892:305,Availability,down,down,305,"Compiling Interpreter.cpp allows RunFunction and friends to be actually seen during stack unwind after an; exception has been thrown, directly or indirectly, by interpreter code. This allows for the RAII objects to be; properly tear down. In particular, without this patch, EnterUserCodeRAII was not tear down and thus the callbacks were not executed.; Consequently the ""Restore the ROOT global Mutex"" callback was not executed leaving the Mutex in an invalid state. In case of ART application, in most cases, they customize the ROOT error handler to throw an exception. This; resulted (without this fix) in crash when import a GDML file with an error in it. In practice what we have is:. call to TGeo Import; which calls the interpreter for some of its functionality; which calls gdml code; which reports an error; which leads the error handler to thrown an exception.; ... some of the stack are properly unwound ... some are not (because they were not compiled with exception support on) ....; ... so the ROOT Mutex goes into an incorrect state ...; ... unwinding continues; ... unwinding reached a frame that Unlock the mutex; Mutex notices it is an incorrect state.; so it reports the Error; the Error handler throw an exception ....... and because this exception is being thrown during the unwind, it is fatal.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4892
https://github.com/root-project/root/pull/4892:534,Availability,error,error,534,"Compiling Interpreter.cpp allows RunFunction and friends to be actually seen during stack unwind after an; exception has been thrown, directly or indirectly, by interpreter code. This allows for the RAII objects to be; properly tear down. In particular, without this patch, EnterUserCodeRAII was not tear down and thus the callbacks were not executed.; Consequently the ""Restore the ROOT global Mutex"" callback was not executed leaving the Mutex in an invalid state. In case of ART application, in most cases, they customize the ROOT error handler to throw an exception. This; resulted (without this fix) in crash when import a GDML file with an error in it. In practice what we have is:. call to TGeo Import; which calls the interpreter for some of its functionality; which calls gdml code; which reports an error; which leads the error handler to thrown an exception.; ... some of the stack are properly unwound ... some are not (because they were not compiled with exception support on) ....; ... so the ROOT Mutex goes into an incorrect state ...; ... unwinding continues; ... unwinding reached a frame that Unlock the mutex; Mutex notices it is an incorrect state.; so it reports the Error; the Error handler throw an exception ....... and because this exception is being thrown during the unwind, it is fatal.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4892
https://github.com/root-project/root/pull/4892:646,Availability,error,error,646,"Compiling Interpreter.cpp allows RunFunction and friends to be actually seen during stack unwind after an; exception has been thrown, directly or indirectly, by interpreter code. This allows for the RAII objects to be; properly tear down. In particular, without this patch, EnterUserCodeRAII was not tear down and thus the callbacks were not executed.; Consequently the ""Restore the ROOT global Mutex"" callback was not executed leaving the Mutex in an invalid state. In case of ART application, in most cases, they customize the ROOT error handler to throw an exception. This; resulted (without this fix) in crash when import a GDML file with an error in it. In practice what we have is:. call to TGeo Import; which calls the interpreter for some of its functionality; which calls gdml code; which reports an error; which leads the error handler to thrown an exception.; ... some of the stack are properly unwound ... some are not (because they were not compiled with exception support on) ....; ... so the ROOT Mutex goes into an incorrect state ...; ... unwinding continues; ... unwinding reached a frame that Unlock the mutex; Mutex notices it is an incorrect state.; so it reports the Error; the Error handler throw an exception ....... and because this exception is being thrown during the unwind, it is fatal.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4892
https://github.com/root-project/root/pull/4892:809,Availability,error,error,809,"Compiling Interpreter.cpp allows RunFunction and friends to be actually seen during stack unwind after an; exception has been thrown, directly or indirectly, by interpreter code. This allows for the RAII objects to be; properly tear down. In particular, without this patch, EnterUserCodeRAII was not tear down and thus the callbacks were not executed.; Consequently the ""Restore the ROOT global Mutex"" callback was not executed leaving the Mutex in an invalid state. In case of ART application, in most cases, they customize the ROOT error handler to throw an exception. This; resulted (without this fix) in crash when import a GDML file with an error in it. In practice what we have is:. call to TGeo Import; which calls the interpreter for some of its functionality; which calls gdml code; which reports an error; which leads the error handler to thrown an exception.; ... some of the stack are properly unwound ... some are not (because they were not compiled with exception support on) ....; ... so the ROOT Mutex goes into an incorrect state ...; ... unwinding continues; ... unwinding reached a frame that Unlock the mutex; Mutex notices it is an incorrect state.; so it reports the Error; the Error handler throw an exception ....... and because this exception is being thrown during the unwind, it is fatal.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4892
https://github.com/root-project/root/pull/4892:832,Availability,error,error,832,"Compiling Interpreter.cpp allows RunFunction and friends to be actually seen during stack unwind after an; exception has been thrown, directly or indirectly, by interpreter code. This allows for the RAII objects to be; properly tear down. In particular, without this patch, EnterUserCodeRAII was not tear down and thus the callbacks were not executed.; Consequently the ""Restore the ROOT global Mutex"" callback was not executed leaving the Mutex in an invalid state. In case of ART application, in most cases, they customize the ROOT error handler to throw an exception. This; resulted (without this fix) in crash when import a GDML file with an error in it. In practice what we have is:. call to TGeo Import; which calls the interpreter for some of its functionality; which calls gdml code; which reports an error; which leads the error handler to thrown an exception.; ... some of the stack are properly unwound ... some are not (because they were not compiled with exception support on) ....; ... so the ROOT Mutex goes into an incorrect state ...; ... unwinding continues; ... unwinding reached a frame that Unlock the mutex; Mutex notices it is an incorrect state.; so it reports the Error; the Error handler throw an exception ....... and because this exception is being thrown during the unwind, it is fatal.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4892
https://github.com/root-project/root/pull/4892:1189,Availability,Error,Error,1189,"Compiling Interpreter.cpp allows RunFunction and friends to be actually seen during stack unwind after an; exception has been thrown, directly or indirectly, by interpreter code. This allows for the RAII objects to be; properly tear down. In particular, without this patch, EnterUserCodeRAII was not tear down and thus the callbacks were not executed.; Consequently the ""Restore the ROOT global Mutex"" callback was not executed leaving the Mutex in an invalid state. In case of ART application, in most cases, they customize the ROOT error handler to throw an exception. This; resulted (without this fix) in crash when import a GDML file with an error in it. In practice what we have is:. call to TGeo Import; which calls the interpreter for some of its functionality; which calls gdml code; which reports an error; which leads the error handler to thrown an exception.; ... some of the stack are properly unwound ... some are not (because they were not compiled with exception support on) ....; ... so the ROOT Mutex goes into an incorrect state ...; ... unwinding continues; ... unwinding reached a frame that Unlock the mutex; Mutex notices it is an incorrect state.; so it reports the Error; the Error handler throw an exception ....... and because this exception is being thrown during the unwind, it is fatal.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4892
https://github.com/root-project/root/pull/4892:1200,Availability,Error,Error,1200,"Compiling Interpreter.cpp allows RunFunction and friends to be actually seen during stack unwind after an; exception has been thrown, directly or indirectly, by interpreter code. This allows for the RAII objects to be; properly tear down. In particular, without this patch, EnterUserCodeRAII was not tear down and thus the callbacks were not executed.; Consequently the ""Restore the ROOT global Mutex"" callback was not executed leaving the Mutex in an invalid state. In case of ART application, in most cases, they customize the ROOT error handler to throw an exception. This; resulted (without this fix) in crash when import a GDML file with an error in it. In practice what we have is:. call to TGeo Import; which calls the interpreter for some of its functionality; which calls gdml code; which reports an error; which leads the error handler to thrown an exception.; ... some of the stack are properly unwound ... some are not (because they were not compiled with exception support on) ....; ... so the ROOT Mutex goes into an incorrect state ...; ... unwinding continues; ... unwinding reached a frame that Unlock the mutex; Mutex notices it is an incorrect state.; so it reports the Error; the Error handler throw an exception ....... and because this exception is being thrown during the unwind, it is fatal.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/4892
