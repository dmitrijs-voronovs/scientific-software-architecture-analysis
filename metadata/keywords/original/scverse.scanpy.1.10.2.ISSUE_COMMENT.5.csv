id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/scverse/scanpy/issues/2073#issuecomment-1058514241:517,Deployability,Update,Update,517,"> I found a workaround that does not require downloading the `.whl` file for `numpy=1.19.5`. By default, MKL is included when you install numpy with conda. It's good to do this in a new environment.; > ; > ```; > conda create -n scanpy_env; > conda activate scanpy_env; > conda install numpy=1.19; > conda install seaborn scikit-learn statsmodels numba pytables; > conda install -c conda-forge python-igraph leidenalg; > pip install scanpy; > ```; > ; > Now I can run `sc.pp.highly_variable_genes()` with no problem. Update: this workaround does not seem to work anymore, at least for scanpy 1.8.2 (you'll need to `pip install scanpy==1.8.1`). ; During `pip install scanpy`, a newer version of numpy is installed and version 1.19 is overwritten. This newer version does not have MKL, leading us back to square one. It's also not possible to `conda install numpy 1.19` as the very last step, because this leads to another error (it's related to the fact that scanpy needs to be compiled with the same version of numpy).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1058514241
https://github.com/scverse/scanpy/issues/2073#issuecomment-1058514241:619,Deployability,install,install,619,"> I found a workaround that does not require downloading the `.whl` file for `numpy=1.19.5`. By default, MKL is included when you install numpy with conda. It's good to do this in a new environment.; > ; > ```; > conda create -n scanpy_env; > conda activate scanpy_env; > conda install numpy=1.19; > conda install seaborn scikit-learn statsmodels numba pytables; > conda install -c conda-forge python-igraph leidenalg; > pip install scanpy; > ```; > ; > Now I can run `sc.pp.highly_variable_genes()` with no problem. Update: this workaround does not seem to work anymore, at least for scanpy 1.8.2 (you'll need to `pip install scanpy==1.8.1`). ; During `pip install scanpy`, a newer version of numpy is installed and version 1.19 is overwritten. This newer version does not have MKL, leading us back to square one. It's also not possible to `conda install numpy 1.19` as the very last step, because this leads to another error (it's related to the fact that scanpy needs to be compiled with the same version of numpy).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1058514241
https://github.com/scverse/scanpy/issues/2073#issuecomment-1058514241:658,Deployability,install,install,658,"> I found a workaround that does not require downloading the `.whl` file for `numpy=1.19.5`. By default, MKL is included when you install numpy with conda. It's good to do this in a new environment.; > ; > ```; > conda create -n scanpy_env; > conda activate scanpy_env; > conda install numpy=1.19; > conda install seaborn scikit-learn statsmodels numba pytables; > conda install -c conda-forge python-igraph leidenalg; > pip install scanpy; > ```; > ; > Now I can run `sc.pp.highly_variable_genes()` with no problem. Update: this workaround does not seem to work anymore, at least for scanpy 1.8.2 (you'll need to `pip install scanpy==1.8.1`). ; During `pip install scanpy`, a newer version of numpy is installed and version 1.19 is overwritten. This newer version does not have MKL, leading us back to square one. It's also not possible to `conda install numpy 1.19` as the very last step, because this leads to another error (it's related to the fact that scanpy needs to be compiled with the same version of numpy).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1058514241
https://github.com/scverse/scanpy/issues/2073#issuecomment-1058514241:703,Deployability,install,installed,703,"> I found a workaround that does not require downloading the `.whl` file for `numpy=1.19.5`. By default, MKL is included when you install numpy with conda. It's good to do this in a new environment.; > ; > ```; > conda create -n scanpy_env; > conda activate scanpy_env; > conda install numpy=1.19; > conda install seaborn scikit-learn statsmodels numba pytables; > conda install -c conda-forge python-igraph leidenalg; > pip install scanpy; > ```; > ; > Now I can run `sc.pp.highly_variable_genes()` with no problem. Update: this workaround does not seem to work anymore, at least for scanpy 1.8.2 (you'll need to `pip install scanpy==1.8.1`). ; During `pip install scanpy`, a newer version of numpy is installed and version 1.19 is overwritten. This newer version does not have MKL, leading us back to square one. It's also not possible to `conda install numpy 1.19` as the very last step, because this leads to another error (it's related to the fact that scanpy needs to be compiled with the same version of numpy).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1058514241
https://github.com/scverse/scanpy/issues/2073#issuecomment-1058514241:848,Deployability,install,install,848,"> I found a workaround that does not require downloading the `.whl` file for `numpy=1.19.5`. By default, MKL is included when you install numpy with conda. It's good to do this in a new environment.; > ; > ```; > conda create -n scanpy_env; > conda activate scanpy_env; > conda install numpy=1.19; > conda install seaborn scikit-learn statsmodels numba pytables; > conda install -c conda-forge python-igraph leidenalg; > pip install scanpy; > ```; > ; > Now I can run `sc.pp.highly_variable_genes()` with no problem. Update: this workaround does not seem to work anymore, at least for scanpy 1.8.2 (you'll need to `pip install scanpy==1.8.1`). ; During `pip install scanpy`, a newer version of numpy is installed and version 1.19 is overwritten. This newer version does not have MKL, leading us back to square one. It's also not possible to `conda install numpy 1.19` as the very last step, because this leads to another error (it's related to the fact that scanpy needs to be compiled with the same version of numpy).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1058514241
https://github.com/scverse/scanpy/issues/2073#issuecomment-1058514241:329,Usability,learn,learn,329,"> I found a workaround that does not require downloading the `.whl` file for `numpy=1.19.5`. By default, MKL is included when you install numpy with conda. It's good to do this in a new environment.; > ; > ```; > conda create -n scanpy_env; > conda activate scanpy_env; > conda install numpy=1.19; > conda install seaborn scikit-learn statsmodels numba pytables; > conda install -c conda-forge python-igraph leidenalg; > pip install scanpy; > ```; > ; > Now I can run `sc.pp.highly_variable_genes()` with no problem. Update: this workaround does not seem to work anymore, at least for scanpy 1.8.2 (you'll need to `pip install scanpy==1.8.1`). ; During `pip install scanpy`, a newer version of numpy is installed and version 1.19 is overwritten. This newer version does not have MKL, leading us back to square one. It's also not possible to `conda install numpy 1.19` as the very last step, because this leads to another error (it's related to the fact that scanpy needs to be compiled with the same version of numpy).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1058514241
https://github.com/scverse/scanpy/issues/2073#issuecomment-1153550204:170,Usability,learn,learn,170,"> I solve this question that can’t import skmisc.loess as loess by chance。the solution is: 'python3.7'+'numpy-1.20.1+mkl-cp37-cp37m-win_amd64.whl'+'scipy==1.7.3'+'scikit-learn==1.0.2'+'scikit-misc==0.1.4'+'scanpy==1.9.1'. > It is 13 Jun ,2022 ,today.I need to creat a new evn ,in which I can run the code as **sc.pp.highly_variable_genes(adata, n_top_genes=5000, flavor='seurat_v3')****. I meet the question that I can't **Import skmisc.loess as loess** ,while the code works fine in my last computer. So，there is a solution can solve this question ,now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1153550204
https://github.com/scverse/scanpy/issues/2073#issuecomment-1259069261:65,Deployability,install,install,65,I met the same problem one day ago. I run the following: ; conda install pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch ; conda install scvi-tools -c conda-forge; conda install -c conda-forge scanpy python-igraph leidenalg ; It works fine now.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1259069261
https://github.com/scverse/scanpy/issues/2073#issuecomment-1259069261:140,Deployability,install,install,140,I met the same problem one day ago. I run the following: ; conda install pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch ; conda install scvi-tools -c conda-forge; conda install -c conda-forge scanpy python-igraph leidenalg ; It works fine now.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1259069261
https://github.com/scverse/scanpy/issues/2073#issuecomment-1259069261:181,Deployability,install,install,181,I met the same problem one day ago. I run the following: ; conda install pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch ; conda install scvi-tools -c conda-forge; conda install -c conda-forge scanpy python-igraph leidenalg ; It works fine now.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1259069261
https://github.com/scverse/scanpy/issues/2073#issuecomment-1489019996:135,Deployability,install,installed,135,"Had this problem, followed the `scikit-misc` package [issue](https://github.com/has2k1/scikit-misc/issues/12) on a related problem and installed the recommended patch with ; ```; pip install -i https://test.pypi.org/simple/ ""scikit-misc==0.2.0rc1""; ```. Seems to work now for me.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1489019996
https://github.com/scverse/scanpy/issues/2073#issuecomment-1489019996:161,Deployability,patch,patch,161,"Had this problem, followed the `scikit-misc` package [issue](https://github.com/has2k1/scikit-misc/issues/12) on a related problem and installed the recommended patch with ; ```; pip install -i https://test.pypi.org/simple/ ""scikit-misc==0.2.0rc1""; ```. Seems to work now for me.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1489019996
https://github.com/scverse/scanpy/issues/2073#issuecomment-1489019996:183,Deployability,install,install,183,"Had this problem, followed the `scikit-misc` package [issue](https://github.com/has2k1/scikit-misc/issues/12) on a related problem and installed the recommended patch with ; ```; pip install -i https://test.pypi.org/simple/ ""scikit-misc==0.2.0rc1""; ```. Seems to work now for me.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1489019996
https://github.com/scverse/scanpy/issues/2073#issuecomment-1489019996:202,Testability,test,test,202,"Had this problem, followed the `scikit-misc` package [issue](https://github.com/has2k1/scikit-misc/issues/12) on a related problem and installed the recommended patch with ; ```; pip install -i https://test.pypi.org/simple/ ""scikit-misc==0.2.0rc1""; ```. Seems to work now for me.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1489019996
https://github.com/scverse/scanpy/issues/2073#issuecomment-1489019996:216,Usability,simpl,simple,216,"Had this problem, followed the `scikit-misc` package [issue](https://github.com/has2k1/scikit-misc/issues/12) on a related problem and installed the recommended patch with ; ```; pip install -i https://test.pypi.org/simple/ ""scikit-misc==0.2.0rc1""; ```. Seems to work now for me.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1489019996
https://github.com/scverse/scanpy/issues/2073#issuecomment-1518455042:74,Availability,error,error,74,"sc.pp.highly_variable_genes(adata, flavor=""seurat_v3"", n_top_genes=3000); error:Please install skmisc package via `pip install --user scikit-misc; I have the same problem as the blogger, so how should I solve it",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1518455042
https://github.com/scverse/scanpy/issues/2073#issuecomment-1518455042:87,Deployability,install,install,87,"sc.pp.highly_variable_genes(adata, flavor=""seurat_v3"", n_top_genes=3000); error:Please install skmisc package via `pip install --user scikit-misc; I have the same problem as the blogger, so how should I solve it",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1518455042
https://github.com/scverse/scanpy/issues/2073#issuecomment-1518455042:119,Deployability,install,install,119,"sc.pp.highly_variable_genes(adata, flavor=""seurat_v3"", n_top_genes=3000); error:Please install skmisc package via `pip install --user scikit-misc; I have the same problem as the blogger, so how should I solve it",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1518455042
https://github.com/scverse/scanpy/issues/2073#issuecomment-1518455078:74,Availability,error,error,74,"sc.pp.highly_variable_genes(adata, flavor=""seurat_v3"", n_top_genes=3000); error:Please install skmisc package via `pip install --user scikit-misc; I have the same problem as the blogger, so how should I solve it",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1518455078
https://github.com/scverse/scanpy/issues/2073#issuecomment-1518455078:87,Deployability,install,install,87,"sc.pp.highly_variable_genes(adata, flavor=""seurat_v3"", n_top_genes=3000); error:Please install skmisc package via `pip install --user scikit-misc; I have the same problem as the blogger, so how should I solve it",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1518455078
https://github.com/scverse/scanpy/issues/2073#issuecomment-1518455078:119,Deployability,install,install,119,"sc.pp.highly_variable_genes(adata, flavor=""seurat_v3"", n_top_genes=3000); error:Please install skmisc package via `pip install --user scikit-misc; I have the same problem as the blogger, so how should I solve it",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1518455078
https://github.com/scverse/scanpy/issues/2073#issuecomment-1738603497:133,Deployability,install,install,133,"I think maybe i found a solution to solve this problem.; Maybe this problem is caused by the version of scikit—misc，when you use pip install --user scikit-misc or pip install scikit-misc，the system will install scikit-misc==0.1.4.; so,i try to install another verion of scikit-misc,you can use install -i https://test.pypi.org/simple/ ""scikit-misc==0.2.0rc1.; In addition, this line of command needs to be used when python is greater than or equal to 3.8.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1738603497
https://github.com/scverse/scanpy/issues/2073#issuecomment-1738603497:167,Deployability,install,install,167,"I think maybe i found a solution to solve this problem.; Maybe this problem is caused by the version of scikit—misc，when you use pip install --user scikit-misc or pip install scikit-misc，the system will install scikit-misc==0.1.4.; so,i try to install another verion of scikit-misc,you can use install -i https://test.pypi.org/simple/ ""scikit-misc==0.2.0rc1.; In addition, this line of command needs to be used when python is greater than or equal to 3.8.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1738603497
https://github.com/scverse/scanpy/issues/2073#issuecomment-1738603497:203,Deployability,install,install,203,"I think maybe i found a solution to solve this problem.; Maybe this problem is caused by the version of scikit—misc，when you use pip install --user scikit-misc or pip install scikit-misc，the system will install scikit-misc==0.1.4.; so,i try to install another verion of scikit-misc,you can use install -i https://test.pypi.org/simple/ ""scikit-misc==0.2.0rc1.; In addition, this line of command needs to be used when python is greater than or equal to 3.8.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1738603497
https://github.com/scverse/scanpy/issues/2073#issuecomment-1738603497:244,Deployability,install,install,244,"I think maybe i found a solution to solve this problem.; Maybe this problem is caused by the version of scikit—misc，when you use pip install --user scikit-misc or pip install scikit-misc，the system will install scikit-misc==0.1.4.; so,i try to install another verion of scikit-misc,you can use install -i https://test.pypi.org/simple/ ""scikit-misc==0.2.0rc1.; In addition, this line of command needs to be used when python is greater than or equal to 3.8.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1738603497
https://github.com/scverse/scanpy/issues/2073#issuecomment-1738603497:294,Deployability,install,install,294,"I think maybe i found a solution to solve this problem.; Maybe this problem is caused by the version of scikit—misc，when you use pip install --user scikit-misc or pip install scikit-misc，the system will install scikit-misc==0.1.4.; so,i try to install another verion of scikit-misc,you can use install -i https://test.pypi.org/simple/ ""scikit-misc==0.2.0rc1.; In addition, this line of command needs to be used when python is greater than or equal to 3.8.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1738603497
https://github.com/scverse/scanpy/issues/2073#issuecomment-1738603497:313,Testability,test,test,313,"I think maybe i found a solution to solve this problem.; Maybe this problem is caused by the version of scikit—misc，when you use pip install --user scikit-misc or pip install scikit-misc，the system will install scikit-misc==0.1.4.; so,i try to install another verion of scikit-misc,you can use install -i https://test.pypi.org/simple/ ""scikit-misc==0.2.0rc1.; In addition, this line of command needs to be used when python is greater than or equal to 3.8.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1738603497
https://github.com/scverse/scanpy/issues/2073#issuecomment-1738603497:327,Usability,simpl,simple,327,"I think maybe i found a solution to solve this problem.; Maybe this problem is caused by the version of scikit—misc，when you use pip install --user scikit-misc or pip install scikit-misc，the system will install scikit-misc==0.1.4.; so,i try to install another verion of scikit-misc,you can use install -i https://test.pypi.org/simple/ ""scikit-misc==0.2.0rc1.; In addition, this line of command needs to be used when python is greater than or equal to 3.8.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1738603497
https://github.com/scverse/scanpy/issues/2073#issuecomment-2231704559:137,Deployability,install,installed,137,"> Had this problem, followed the `scikit-misc` package [issue](https://github.com/has2k1/scikit-misc/issues/12) on a related problem and installed the recommended patch with; > ; > ```; > pip install -i https://test.pypi.org/simple/ ""scikit-misc==0.2.0rc1""; > ```; > ; > Seems to work now for me. Thank you. It just worked for me, in July 2024.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-2231704559
https://github.com/scverse/scanpy/issues/2073#issuecomment-2231704559:163,Deployability,patch,patch,163,"> Had this problem, followed the `scikit-misc` package [issue](https://github.com/has2k1/scikit-misc/issues/12) on a related problem and installed the recommended patch with; > ; > ```; > pip install -i https://test.pypi.org/simple/ ""scikit-misc==0.2.0rc1""; > ```; > ; > Seems to work now for me. Thank you. It just worked for me, in July 2024.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-2231704559
https://github.com/scverse/scanpy/issues/2073#issuecomment-2231704559:192,Deployability,install,install,192,"> Had this problem, followed the `scikit-misc` package [issue](https://github.com/has2k1/scikit-misc/issues/12) on a related problem and installed the recommended patch with; > ; > ```; > pip install -i https://test.pypi.org/simple/ ""scikit-misc==0.2.0rc1""; > ```; > ; > Seems to work now for me. Thank you. It just worked for me, in July 2024.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-2231704559
https://github.com/scverse/scanpy/issues/2073#issuecomment-2231704559:211,Testability,test,test,211,"> Had this problem, followed the `scikit-misc` package [issue](https://github.com/has2k1/scikit-misc/issues/12) on a related problem and installed the recommended patch with; > ; > ```; > pip install -i https://test.pypi.org/simple/ ""scikit-misc==0.2.0rc1""; > ```; > ; > Seems to work now for me. Thank you. It just worked for me, in July 2024.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-2231704559
https://github.com/scverse/scanpy/issues/2073#issuecomment-2231704559:225,Usability,simpl,simple,225,"> Had this problem, followed the `scikit-misc` package [issue](https://github.com/has2k1/scikit-misc/issues/12) on a related problem and installed the recommended patch with; > ; > ```; > pip install -i https://test.pypi.org/simple/ ""scikit-misc==0.2.0rc1""; > ```; > ; > Seems to work now for me. Thank you. It just worked for me, in July 2024.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-2231704559
https://github.com/scverse/scanpy/pull/2075#issuecomment-1007917047:293,Deployability,patch,patch,293,"Don't know what this ""review"" process is , but basically it is ready. . De: ""Lukas Heumos"" ***@***.***> ; À: ""theislab/scanpy"" ***@***.***> ; Cc: ""Yves Le Feuvre"" ***@***.***>, ""Mention"" ***@***.***> ; Envoyé: Jeudi 6 Janvier 2022 20:11:35 ; Objet: Re: [theislab/scanpy] Pca loadings n points patch (PR #2075) . [ https://github.com/Yves33 | @Yves33 ] is this ready for review? . — ; Reply to this email directly, [ https://github.com/theislab/scanpy/pull/2075#issuecomment-1006847333 | view it on GitHub ] , or [ https://github.com/notifications/unsubscribe-auth/ACEYIQUT75OTZC3MUGVAT3DUUXSOPANCNFSM5JWG2IZQ | unsubscribe ] . ; Triage notifications on the go with GitHub Mobile for [ https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675 | iOS ] or [ https://play.google.com/store/apps/details?id=com.github.android&referrer=utm_campaign%3Dnotification-email%26utm_medium%3Demail%26utm_source%3Dgithub | Android ] . ; You are receiving this because you were mentioned. Message ID: ***@***.***>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2075#issuecomment-1007917047
https://github.com/scverse/scanpy/pull/2075#issuecomment-1007917047:1005,Integrability,Message,Message,1005,"Don't know what this ""review"" process is , but basically it is ready. . De: ""Lukas Heumos"" ***@***.***> ; À: ""theislab/scanpy"" ***@***.***> ; Cc: ""Yves Le Feuvre"" ***@***.***>, ""Mention"" ***@***.***> ; Envoyé: Jeudi 6 Janvier 2022 20:11:35 ; Objet: Re: [theislab/scanpy] Pca loadings n points patch (PR #2075) . [ https://github.com/Yves33 | @Yves33 ] is this ready for review? . — ; Reply to this email directly, [ https://github.com/theislab/scanpy/pull/2075#issuecomment-1006847333 | view it on GitHub ] , or [ https://github.com/notifications/unsubscribe-auth/ACEYIQUT75OTZC3MUGVAT3DUUXSOPANCNFSM5JWG2IZQ | unsubscribe ] . ; Triage notifications on the go with GitHub Mobile for [ https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675 | iOS ] or [ https://play.google.com/store/apps/details?id=com.github.android&referrer=utm_campaign%3Dnotification-email%26utm_medium%3Demail%26utm_source%3Dgithub | Android ] . ; You are receiving this because you were mentioned. Message ID: ***@***.***>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2075#issuecomment-1007917047
https://github.com/scverse/scanpy/pull/2075#issuecomment-1007917047:275,Performance,load,loadings,275,"Don't know what this ""review"" process is , but basically it is ready. . De: ""Lukas Heumos"" ***@***.***> ; À: ""theislab/scanpy"" ***@***.***> ; Cc: ""Yves Le Feuvre"" ***@***.***>, ""Mention"" ***@***.***> ; Envoyé: Jeudi 6 Janvier 2022 20:11:35 ; Objet: Re: [theislab/scanpy] Pca loadings n points patch (PR #2075) . [ https://github.com/Yves33 | @Yves33 ] is this ready for review? . — ; Reply to this email directly, [ https://github.com/theislab/scanpy/pull/2075#issuecomment-1006847333 | view it on GitHub ] , or [ https://github.com/notifications/unsubscribe-auth/ACEYIQUT75OTZC3MUGVAT3DUUXSOPANCNFSM5JWG2IZQ | unsubscribe ] . ; Triage notifications on the go with GitHub Mobile for [ https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675 | iOS ] or [ https://play.google.com/store/apps/details?id=com.github.android&referrer=utm_campaign%3Dnotification-email%26utm_medium%3Demail%26utm_source%3Dgithub | Android ] . ; You are receiving this because you were mentioned. Message ID: ***@***.***>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2075#issuecomment-1007917047
https://github.com/scverse/scanpy/pull/2075#issuecomment-1074173258:14,Deployability,Pipeline,Pipelines,14,<samp>; Azure Pipelines successfully started running 1 pipeline(s).<br>. </samp>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2075#issuecomment-1074173258
https://github.com/scverse/scanpy/pull/2075#issuecomment-1074173258:55,Deployability,pipeline,pipeline,55,<samp>; Azure Pipelines successfully started running 1 pipeline(s).<br>. </samp>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2075#issuecomment-1074173258
https://github.com/scverse/scanpy/issues/2078#issuecomment-991361911:51,Availability,error,error,51,"Thanks for the report. I can broadly reproduce the error for passing `values_to_plot`. The error I get is a little different, but I expect that's due to pandas versions. A more minimal example:. ```python; import scanpy as sc. adata = sc.datasets.pbmc3k_processed().raw.to_adata(); sc.tl.rank_genes_groups(adata, groupby=""louvain"", reference=""B cells""). # Errors with any of ['scores', 'logfoldchanges', 'pvals', 'pvals_adj','log10_pvals', 'log10_pvals_adj']; sc.pl.rank_genes_groups_dotplot(adata, values_to_plot='logfoldchanges'); ```. <details>; <summary> Traceback </summary>. ```pytb; ERROR: the given dot_color_df data frame has a different shape thanthe data frame used for the dot size. Both data frames needto have the same index and columns; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /var/folders/bd/43q20k0n6z15tdfzxvd22r7c0000gn/T/ipykernel_62013/1545772980.py in <module>; 1 while len(possible_vals) > 0:; ----> 2 sc.pl.rank_genes_groups_dotplot(adata, values_to_plot=possible_vals.pop()); 3 . ~/github/scanpy/scanpy/plotting/_tools/__init__.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, var_names, gene_symbols, min_logfoldchange, key, show, save, return_fig, **kwds); 861 tl.rank_genes_groups; 862 """"""; --> 863 return _rank_genes_groups_plot(; 864 adata,; 865 plot_type='dotplot',. ~/github/scanpy/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds); 534 from .._dotplot import dotplot; 535 ; --> 536 _pl = dotplot(; 537 adata,; 538 var_names,. ~/github/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2078#issuecomment-991361911
https://github.com/scverse/scanpy/issues/2078#issuecomment-991361911:91,Availability,error,error,91,"Thanks for the report. I can broadly reproduce the error for passing `values_to_plot`. The error I get is a little different, but I expect that's due to pandas versions. A more minimal example:. ```python; import scanpy as sc. adata = sc.datasets.pbmc3k_processed().raw.to_adata(); sc.tl.rank_genes_groups(adata, groupby=""louvain"", reference=""B cells""). # Errors with any of ['scores', 'logfoldchanges', 'pvals', 'pvals_adj','log10_pvals', 'log10_pvals_adj']; sc.pl.rank_genes_groups_dotplot(adata, values_to_plot='logfoldchanges'); ```. <details>; <summary> Traceback </summary>. ```pytb; ERROR: the given dot_color_df data frame has a different shape thanthe data frame used for the dot size. Both data frames needto have the same index and columns; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /var/folders/bd/43q20k0n6z15tdfzxvd22r7c0000gn/T/ipykernel_62013/1545772980.py in <module>; 1 while len(possible_vals) > 0:; ----> 2 sc.pl.rank_genes_groups_dotplot(adata, values_to_plot=possible_vals.pop()); 3 . ~/github/scanpy/scanpy/plotting/_tools/__init__.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, var_names, gene_symbols, min_logfoldchange, key, show, save, return_fig, **kwds); 861 tl.rank_genes_groups; 862 """"""; --> 863 return _rank_genes_groups_plot(; 864 adata,; 865 plot_type='dotplot',. ~/github/scanpy/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds); 534 from .._dotplot import dotplot; 535 ; --> 536 _pl = dotplot(; 537 adata,; 538 var_names,. ~/github/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2078#issuecomment-991361911
https://github.com/scverse/scanpy/issues/2078#issuecomment-991361911:356,Availability,Error,Errors,356,"Thanks for the report. I can broadly reproduce the error for passing `values_to_plot`. The error I get is a little different, but I expect that's due to pandas versions. A more minimal example:. ```python; import scanpy as sc. adata = sc.datasets.pbmc3k_processed().raw.to_adata(); sc.tl.rank_genes_groups(adata, groupby=""louvain"", reference=""B cells""). # Errors with any of ['scores', 'logfoldchanges', 'pvals', 'pvals_adj','log10_pvals', 'log10_pvals_adj']; sc.pl.rank_genes_groups_dotplot(adata, values_to_plot='logfoldchanges'); ```. <details>; <summary> Traceback </summary>. ```pytb; ERROR: the given dot_color_df data frame has a different shape thanthe data frame used for the dot size. Both data frames needto have the same index and columns; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /var/folders/bd/43q20k0n6z15tdfzxvd22r7c0000gn/T/ipykernel_62013/1545772980.py in <module>; 1 while len(possible_vals) > 0:; ----> 2 sc.pl.rank_genes_groups_dotplot(adata, values_to_plot=possible_vals.pop()); 3 . ~/github/scanpy/scanpy/plotting/_tools/__init__.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, var_names, gene_symbols, min_logfoldchange, key, show, save, return_fig, **kwds); 861 tl.rank_genes_groups; 862 """"""; --> 863 return _rank_genes_groups_plot(; 864 adata,; 865 plot_type='dotplot',. ~/github/scanpy/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds); 534 from .._dotplot import dotplot; 535 ; --> 536 _pl = dotplot(; 537 adata,; 538 var_names,. ~/github/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2078#issuecomment-991361911
https://github.com/scverse/scanpy/issues/2078#issuecomment-991361911:590,Availability,ERROR,ERROR,590,"Thanks for the report. I can broadly reproduce the error for passing `values_to_plot`. The error I get is a little different, but I expect that's due to pandas versions. A more minimal example:. ```python; import scanpy as sc. adata = sc.datasets.pbmc3k_processed().raw.to_adata(); sc.tl.rank_genes_groups(adata, groupby=""louvain"", reference=""B cells""). # Errors with any of ['scores', 'logfoldchanges', 'pvals', 'pvals_adj','log10_pvals', 'log10_pvals_adj']; sc.pl.rank_genes_groups_dotplot(adata, values_to_plot='logfoldchanges'); ```. <details>; <summary> Traceback </summary>. ```pytb; ERROR: the given dot_color_df data frame has a different shape thanthe data frame used for the dot size. Both data frames needto have the same index and columns; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /var/folders/bd/43q20k0n6z15tdfzxvd22r7c0000gn/T/ipykernel_62013/1545772980.py in <module>; 1 while len(possible_vals) > 0:; ----> 2 sc.pl.rank_genes_groups_dotplot(adata, values_to_plot=possible_vals.pop()); 3 . ~/github/scanpy/scanpy/plotting/_tools/__init__.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, var_names, gene_symbols, min_logfoldchange, key, show, save, return_fig, **kwds); 861 tl.rank_genes_groups; 862 """"""; --> 863 return _rank_genes_groups_plot(; 864 adata,; 865 plot_type='dotplot',. ~/github/scanpy/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds); 534 from .._dotplot import dotplot; 535 ; --> 536 _pl = dotplot(; 537 adata,; 538 var_names,. ~/github/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2078#issuecomment-991361911
https://github.com/scverse/scanpy/issues/2078#issuecomment-991361911:4321,Availability,error,error,4321,", figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, vmin, vmax, vcenter, norm, **kwds); 215 # get the same order for rows and columns in the dot_color_df; 216 # using the order from the doc_size_df; --> 217 dot_color_df = dot_color_df.loc[dot_size_df.index][dot_size_df.columns]; 218 ; 219 self.dot_color_df = dot_color_df. /usr/local/lib/python3.9/site-packages/pandas/core/indexing.py in __getitem__(self, key); 929 ; 930 maybe_callable = com.apply_if_callable(key, self.obj); --> 931 return self._getitem_axis(maybe_callable, axis=axis); 932 ; 933 def _is_scalar_access(self, key: tuple):. /usr/local/lib/python3.9/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis); 1151 raise ValueError(""Cannot index with multidimensional key""); 1152 ; -> 1153 return self._getitem_iterable(key, axis=axis); 1154 ; 1155 # nested tuple slicing. /usr/local/lib/python3.9/site-packages/pandas/core/indexing.py in _getitem_iterable(self, key, axis); 1091 ; 1092 # A collection of keys; -> 1093 keyarr, indexer = self._get_listlike_indexer(key, axis); 1094 return self.obj._reindex_with_indexers(; 1095 {axis: [keyarr, indexer]}, copy=True, allow_dups=True. /usr/local/lib/python3.9/site-packages/pandas/core/indexing.py in _get_listlike_indexer(self, key, axis); 1312 keyarr, indexer, new_indexer = ax._reindex_non_unique(keyarr); 1313 ; -> 1314 self._validate_read_indexer(keyarr, indexer, axis); 1315 ; 1316 if needs_i8_conversion(ax.dtype) or isinstance(. /usr/local/lib/python3.9/site-packages/pandas/core/indexing.py in _validate_read_indexer(self, key, indexer, axis); 1375 ; 1376 not_found = list(ensure_index(key)[missing_mask.nonzero()[0]].unique()); -> 1377 raise KeyError(f""{not_found} not in index""); 1378 ; 1379 . KeyError: ""['B cells'] not in index""; ```. </details>. For `rankby_abs` it does error, but is that a valid argument to pass to this function?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2078#issuecomment-991361911
https://github.com/scverse/scanpy/issues/2078#issuecomment-991361911:387,Testability,log,logfoldchanges,387,"Thanks for the report. I can broadly reproduce the error for passing `values_to_plot`. The error I get is a little different, but I expect that's due to pandas versions. A more minimal example:. ```python; import scanpy as sc. adata = sc.datasets.pbmc3k_processed().raw.to_adata(); sc.tl.rank_genes_groups(adata, groupby=""louvain"", reference=""B cells""). # Errors with any of ['scores', 'logfoldchanges', 'pvals', 'pvals_adj','log10_pvals', 'log10_pvals_adj']; sc.pl.rank_genes_groups_dotplot(adata, values_to_plot='logfoldchanges'); ```. <details>; <summary> Traceback </summary>. ```pytb; ERROR: the given dot_color_df data frame has a different shape thanthe data frame used for the dot size. Both data frames needto have the same index and columns; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /var/folders/bd/43q20k0n6z15tdfzxvd22r7c0000gn/T/ipykernel_62013/1545772980.py in <module>; 1 while len(possible_vals) > 0:; ----> 2 sc.pl.rank_genes_groups_dotplot(adata, values_to_plot=possible_vals.pop()); 3 . ~/github/scanpy/scanpy/plotting/_tools/__init__.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, var_names, gene_symbols, min_logfoldchange, key, show, save, return_fig, **kwds); 861 tl.rank_genes_groups; 862 """"""; --> 863 return _rank_genes_groups_plot(; 864 adata,; 865 plot_type='dotplot',. ~/github/scanpy/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds); 534 from .._dotplot import dotplot; 535 ; --> 536 _pl = dotplot(; 537 adata,; 538 var_names,. ~/github/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2078#issuecomment-991361911
https://github.com/scverse/scanpy/issues/2078#issuecomment-991361911:515,Testability,log,logfoldchanges,515,"Thanks for the report. I can broadly reproduce the error for passing `values_to_plot`. The error I get is a little different, but I expect that's due to pandas versions. A more minimal example:. ```python; import scanpy as sc. adata = sc.datasets.pbmc3k_processed().raw.to_adata(); sc.tl.rank_genes_groups(adata, groupby=""louvain"", reference=""B cells""). # Errors with any of ['scores', 'logfoldchanges', 'pvals', 'pvals_adj','log10_pvals', 'log10_pvals_adj']; sc.pl.rank_genes_groups_dotplot(adata, values_to_plot='logfoldchanges'); ```. <details>; <summary> Traceback </summary>. ```pytb; ERROR: the given dot_color_df data frame has a different shape thanthe data frame used for the dot size. Both data frames needto have the same index and columns; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /var/folders/bd/43q20k0n6z15tdfzxvd22r7c0000gn/T/ipykernel_62013/1545772980.py in <module>; 1 while len(possible_vals) > 0:; ----> 2 sc.pl.rank_genes_groups_dotplot(adata, values_to_plot=possible_vals.pop()); 3 . ~/github/scanpy/scanpy/plotting/_tools/__init__.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, var_names, gene_symbols, min_logfoldchange, key, show, save, return_fig, **kwds); 861 tl.rank_genes_groups; 862 """"""; --> 863 return _rank_genes_groups_plot(; 864 adata,; 865 plot_type='dotplot',. ~/github/scanpy/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds); 534 from .._dotplot import dotplot; 535 ; --> 536 _pl = dotplot(; 537 adata,; 538 var_names,. ~/github/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2078#issuecomment-991361911
https://github.com/scverse/scanpy/issues/2078#issuecomment-991361911:1816,Testability,log,log,1816,"> 2 sc.pl.rank_genes_groups_dotplot(adata, values_to_plot=possible_vals.pop()); 3 . ~/github/scanpy/scanpy/plotting/_tools/__init__.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, var_names, gene_symbols, min_logfoldchange, key, show, save, return_fig, **kwds); 861 tl.rank_genes_groups; 862 """"""; --> 863 return _rank_genes_groups_plot(; 864 adata,; 865 plot_type='dotplot',. ~/github/scanpy/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds); 534 from .._dotplot import dotplot; 535 ; --> 536 _pl = dotplot(; 537 adata,; 538 var_names,. ~/github/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds); 940 del kwds['color_map']; 941 ; --> 942 dp = DotPlot(; 943 adata,; 944 var_names,. ~/github/scanpy/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, vmin, vmax, vcenter, norm, **kwds); 215 # get the same order for rows and columns in the dot_color_df; 216 # using the order from the doc_size_df; --> 217 dot_color_df = dot_color_df.loc[dot_size_df.index][dot_size_df.columns]; 218 ; 219 self.dot_color_df = dot_color_df. /usr/local/lib/python3.9/site-packages/pandas/core/indexing.py in __getitem__(self, key); 929 ; 930 maybe_callable = com.apply_if_callable(key, self.obj); --> 931 return s",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2078#issuecomment-991361911
https://github.com/scverse/scanpy/issues/2078#issuecomment-991361911:2338,Testability,log,log,2338,"s, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds); 534 from .._dotplot import dotplot; 535 ; --> 536 _pl = dotplot(; 537 adata,; 538 var_names,. ~/github/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds); 940 del kwds['color_map']; 941 ; --> 942 dp = DotPlot(; 943 adata,; 944 var_names,. ~/github/scanpy/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, vmin, vmax, vcenter, norm, **kwds); 215 # get the same order for rows and columns in the dot_color_df; 216 # using the order from the doc_size_df; --> 217 dot_color_df = dot_color_df.loc[dot_size_df.index][dot_size_df.columns]; 218 ; 219 self.dot_color_df = dot_color_df. /usr/local/lib/python3.9/site-packages/pandas/core/indexing.py in __getitem__(self, key); 929 ; 930 maybe_callable = com.apply_if_callable(key, self.obj); --> 931 return self._getitem_axis(maybe_callable, axis=axis); 932 ; 933 def _is_scalar_access(self, key: tuple):. /usr/local/lib/python3.9/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis); 1151 raise ValueError(""Cannot index with multidimensional key""); 1152 ; -> 1153 return self._getitem_iterable(key, axis=axis); 1154 ; 1155 # nested tuple slicing. /usr/local/lib/python3.9/site-packages/pandas/core/indexing.py in _getitem_iterable(self, key, axis); 1091 ; 1092 # A collection of keys; -> 1093 keya",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2078#issuecomment-991361911
https://github.com/scverse/scanpy/pull/2082#issuecomment-993393067:14,Deployability,Pipeline,Pipelines,14,<samp>; Azure Pipelines successfully started running 1 pipeline(s).<br>. </samp>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2082#issuecomment-993393067
https://github.com/scverse/scanpy/pull/2082#issuecomment-993393067:55,Deployability,pipeline,pipeline,55,<samp>; Azure Pipelines successfully started running 1 pipeline(s).<br>. </samp>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2082#issuecomment-993393067
https://github.com/scverse/scanpy/issues/2085#issuecomment-1103990647:4,Deployability,update,update,4,"Any update? I have the same issue with scanpy==1.8.1. The tutorial data has different row lengths and it works, so that can't be the problem",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2085#issuecomment-1103990647
https://github.com/scverse/scanpy/issues/2085#issuecomment-1104240383:3230,Availability,error,error,3230,"dFragment-->; </body>; </html>. Both tutorial adatas after a successful ingest:; ```. (AnnData object with n_obs × n_vars = 700 × 208; obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score', 'G2M_score', 'phase', 'louvain'; var: 'n_counts', 'means', 'dispersions', 'dispersions_norm', 'highly_variable'; uns: 'bulk_labels_colors', 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups', 'umap'; obsm: 'X_pca', 'X_umap', 'rep'; varm: 'PCs'; obsp: 'distances', 'connectivities',; AnnData object with n_obs × n_vars = 2638 × 208; obs: 'n_genes', 'percent_mito', 'n_counts', 'louvain'; var: 'n_cells'; uns: 'draw_graph', 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups', 'umap'; obsm: 'X_pca', 'X_tsne', 'X_umap', 'X_draw_graph_fr'; varm: 'PCs'; obsp: 'distances', 'connectivities'); ```. Now my data, adata_ref:. <html><body>; <!--StartFragment--><div class=""lm-Widget p-Widget lm-Panel p-Panel jp-Cell-inputWrapper""><div class=""lm-Widget p-Widget jp-InputArea jp-Cell-inputArea"">.   | celltype | louvain; -- | -- | --; cell1 | hepatic stellate cells | 1; cell2 | cholangiocytes | 1; ... | ... | ... <p>8439 rows × 2 columns</p>; </div></div><!--EndFragment-->; </body>; </html>. and my adata that I wish to ingest:. <html><body>; <!--StartFragment-->.   | louvain; -- | --; cell1 | 0; cell2 | 0; ... <!--EndFragment-->; </body>; </html>. Both my adata files have the same 40 variables and pca/umaps, they look like this:. ```; (AnnData object with n_obs × n_vars = 8989 × 40; obs: 'louvain'; uns: 'pca', 'neighbors', 'umap', 'louvain', 'louvain_colors'; obsm: 'X_pca', 'X_umap'; varm: 'PCs'; obsp: 'distances', 'connectivities',; AnnData object with n_obs × n_vars = 8439 × 40; obs: 'celltype', 'louvain'; uns: 'pca', 'neighbors', 'umap', 'louvain', 'louvain_colors'; obsm: 'X_pca', 'X_umap'; varm: 'PCs'; obsp: 'distances', 'connectivities'); ```. I suspect the error stems from the Nearest Neighbours. Or maybe my number of variables (40) is too small?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2085#issuecomment-1104240383
https://github.com/scverse/scanpy/issues/2085#issuecomment-1104240383:2742,Modifiability,variab,variables,2742,"dFragment-->; </body>; </html>. Both tutorial adatas after a successful ingest:; ```. (AnnData object with n_obs × n_vars = 700 × 208; obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score', 'G2M_score', 'phase', 'louvain'; var: 'n_counts', 'means', 'dispersions', 'dispersions_norm', 'highly_variable'; uns: 'bulk_labels_colors', 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups', 'umap'; obsm: 'X_pca', 'X_umap', 'rep'; varm: 'PCs'; obsp: 'distances', 'connectivities',; AnnData object with n_obs × n_vars = 2638 × 208; obs: 'n_genes', 'percent_mito', 'n_counts', 'louvain'; var: 'n_cells'; uns: 'draw_graph', 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups', 'umap'; obsm: 'X_pca', 'X_tsne', 'X_umap', 'X_draw_graph_fr'; varm: 'PCs'; obsp: 'distances', 'connectivities'); ```. Now my data, adata_ref:. <html><body>; <!--StartFragment--><div class=""lm-Widget p-Widget lm-Panel p-Panel jp-Cell-inputWrapper""><div class=""lm-Widget p-Widget jp-InputArea jp-Cell-inputArea"">.   | celltype | louvain; -- | -- | --; cell1 | hepatic stellate cells | 1; cell2 | cholangiocytes | 1; ... | ... | ... <p>8439 rows × 2 columns</p>; </div></div><!--EndFragment-->; </body>; </html>. and my adata that I wish to ingest:. <html><body>; <!--StartFragment-->.   | louvain; -- | --; cell1 | 0; cell2 | 0; ... <!--EndFragment-->; </body>; </html>. Both my adata files have the same 40 variables and pca/umaps, they look like this:. ```; (AnnData object with n_obs × n_vars = 8989 × 40; obs: 'louvain'; uns: 'pca', 'neighbors', 'umap', 'louvain', 'louvain_colors'; obsm: 'X_pca', 'X_umap'; varm: 'PCs'; obsp: 'distances', 'connectivities',; AnnData object with n_obs × n_vars = 8439 × 40; obs: 'celltype', 'louvain'; uns: 'pca', 'neighbors', 'umap', 'louvain', 'louvain_colors'; obsm: 'X_pca', 'X_umap'; varm: 'PCs'; obsp: 'distances', 'connectivities'); ```. I suspect the error stems from the Nearest Neighbours. Or maybe my number of variables (40) is too small?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2085#issuecomment-1104240383
https://github.com/scverse/scanpy/issues/2085#issuecomment-1104240383:3293,Modifiability,variab,variables,3293,"dFragment-->; </body>; </html>. Both tutorial adatas after a successful ingest:; ```. (AnnData object with n_obs × n_vars = 700 × 208; obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score', 'G2M_score', 'phase', 'louvain'; var: 'n_counts', 'means', 'dispersions', 'dispersions_norm', 'highly_variable'; uns: 'bulk_labels_colors', 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups', 'umap'; obsm: 'X_pca', 'X_umap', 'rep'; varm: 'PCs'; obsp: 'distances', 'connectivities',; AnnData object with n_obs × n_vars = 2638 × 208; obs: 'n_genes', 'percent_mito', 'n_counts', 'louvain'; var: 'n_cells'; uns: 'draw_graph', 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups', 'umap'; obsm: 'X_pca', 'X_tsne', 'X_umap', 'X_draw_graph_fr'; varm: 'PCs'; obsp: 'distances', 'connectivities'); ```. Now my data, adata_ref:. <html><body>; <!--StartFragment--><div class=""lm-Widget p-Widget lm-Panel p-Panel jp-Cell-inputWrapper""><div class=""lm-Widget p-Widget jp-InputArea jp-Cell-inputArea"">.   | celltype | louvain; -- | -- | --; cell1 | hepatic stellate cells | 1; cell2 | cholangiocytes | 1; ... | ... | ... <p>8439 rows × 2 columns</p>; </div></div><!--EndFragment-->; </body>; </html>. and my adata that I wish to ingest:. <html><body>; <!--StartFragment-->.   | louvain; -- | --; cell1 | 0; cell2 | 0; ... <!--EndFragment-->; </body>; </html>. Both my adata files have the same 40 variables and pca/umaps, they look like this:. ```; (AnnData object with n_obs × n_vars = 8989 × 40; obs: 'louvain'; uns: 'pca', 'neighbors', 'umap', 'louvain', 'louvain_colors'; obsm: 'X_pca', 'X_umap'; varm: 'PCs'; obsp: 'distances', 'connectivities',; AnnData object with n_obs × n_vars = 8439 × 40; obs: 'celltype', 'louvain'; uns: 'pca', 'neighbors', 'umap', 'louvain', 'louvain_colors'; obsm: 'X_pca', 'X_umap'; varm: 'PCs'; obsp: 'distances', 'connectivities'); ```. I suspect the error stems from the Nearest Neighbours. Or maybe my number of variables (40) is too small?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2085#issuecomment-1104240383
https://github.com/scverse/scanpy/issues/2085#issuecomment-1104437780:26,Availability,error,error,26,"This is the origin of the error:. Some of the cells don't have neighbours at the variable adata_ref.obsp['distances'].tolil().rows:. ```; array([list([223, 280, 316, 5791]), list([3877, 5899, 7766, 7807]),; list([165, 304, 423, 713]), ..., list([]),; list([94, 865, 7077, 7666]), list([])], dtype=object); ## (the maximum 4 elements of each list comes from having run sc.pp.neighbors(adata_ref, n_neighbors = 5)) ##; ```. The above array is impossible to stack with np.stack due to the sublists having different lengths. A potential solution might be filtering out those cells without neighbours, though this is suboptimal. I have tried it and new rows remain empty. Only after repeating it a second time, it works:. ```; DEFINED_NEIGHB_NUM =5; sc.pp.pca(adata_ref); sc.pp.neighbors(adata_ref, n_neighbors = DEFINED_NEIGHB_NUM ); sc.tl.umap(adata_ref). b = np.array(list(map(len,adata_ref.obsp['distances'].tolil().rows))) == DEFINED_NEIGHB_NUM -1; adata_ref = adata_ref[b]; ```. A better solution would be correcting the Nearest Neighbour assignment so that it doesn't create empty distance lists. Did I understand this correctly?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2085#issuecomment-1104437780
https://github.com/scverse/scanpy/issues/2085#issuecomment-1104437780:81,Modifiability,variab,variable,81,"This is the origin of the error:. Some of the cells don't have neighbours at the variable adata_ref.obsp['distances'].tolil().rows:. ```; array([list([223, 280, 316, 5791]), list([3877, 5899, 7766, 7807]),; list([165, 304, 423, 713]), ..., list([]),; list([94, 865, 7077, 7666]), list([])], dtype=object); ## (the maximum 4 elements of each list comes from having run sc.pp.neighbors(adata_ref, n_neighbors = 5)) ##; ```. The above array is impossible to stack with np.stack due to the sublists having different lengths. A potential solution might be filtering out those cells without neighbours, though this is suboptimal. I have tried it and new rows remain empty. Only after repeating it a second time, it works:. ```; DEFINED_NEIGHB_NUM =5; sc.pp.pca(adata_ref); sc.pp.neighbors(adata_ref, n_neighbors = DEFINED_NEIGHB_NUM ); sc.tl.umap(adata_ref). b = np.array(list(map(len,adata_ref.obsp['distances'].tolil().rows))) == DEFINED_NEIGHB_NUM -1; adata_ref = adata_ref[b]; ```. A better solution would be correcting the Nearest Neighbour assignment so that it doesn't create empty distance lists. Did I understand this correctly?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2085#issuecomment-1104437780
https://github.com/scverse/scanpy/issues/2085#issuecomment-1110814854:48,Availability,error,error,48,"Ok, I identified the root cause of the neighbor error and reported it as a bug: . https://github.com/scverse/scanpy/issues/2244. This probably happens because you have duplicated rows or cells with almost identical gene counts",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2085#issuecomment-1110814854
https://github.com/scverse/scanpy/issues/2085#issuecomment-1382325586:5,Availability,error,error,5,"This error message was hard to debug! Indeed it is due to the behavior of `sc.pp.neighbors`. Cells are sometimes given different numbers of neighbors. Sometimes that the errant cells have a number of neighbors greater than zero (unlike as seen in #2244, where the # of neighbors of some cells was 0). My fix builds on the one above and was:; ```; b = np.array(list(map(len, adata_ref.obsp['distances'].tolil().rows))) # number of neighbors of each cell; adata_ref_subset = adata_ref[np.where(b == DEFINED_NEIGHB_NUM-1)[0]] # select only those with the right number; sc.pp.neighbors(adata_ref_subset, DEFINED_NEIGHB_NUM) # rebuild the neighbor graph; ```; ___; @ViriatoII Your comment helped me fix things – but your fix itself didn't work for me. First, when I use `adata_ref = adata_ref[b]`, with `b` defined as above, it interprets `b` not as a boolean mask but as an index, returning a single cell duplicated over and over. I'm not sure what the intended behavior is here. My solution is to use `adata_ref[np.where(b == n_neigh-1)[0]]`. However, this subselection changes the number of neighbors that other cells have. For example, for my data,. ```; b = np.array(list(map(len,adata_ref.obsp['distances'].tolil().rows))); print(""Before subselecting"", np.unique(b, return_counts = True)). adata_ref_subset = adata_ref[np.where(b == DEFINED_NEIGHB_NUM-1)[0]]; c = np.array(list(map(len,adata_ref_subset.obsp['distances'].tolil().rows))); print(""After subselecting"", np.unique(c, return_counts = True)); ```; yields; ```; Before subselecting, (array([13, 14]), array([ 28, 1161359])); After subselecting, (array([10, 11, 12, 13, 14]),; array([ 15, 1, 633, 46, 1160664]))); ```. To solve both problems I needed to rebuild the neighbor graph.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2085#issuecomment-1382325586
https://github.com/scverse/scanpy/issues/2085#issuecomment-1382325586:855,Availability,mask,mask,855,"This error message was hard to debug! Indeed it is due to the behavior of `sc.pp.neighbors`. Cells are sometimes given different numbers of neighbors. Sometimes that the errant cells have a number of neighbors greater than zero (unlike as seen in #2244, where the # of neighbors of some cells was 0). My fix builds on the one above and was:; ```; b = np.array(list(map(len, adata_ref.obsp['distances'].tolil().rows))) # number of neighbors of each cell; adata_ref_subset = adata_ref[np.where(b == DEFINED_NEIGHB_NUM-1)[0]] # select only those with the right number; sc.pp.neighbors(adata_ref_subset, DEFINED_NEIGHB_NUM) # rebuild the neighbor graph; ```; ___; @ViriatoII Your comment helped me fix things – but your fix itself didn't work for me. First, when I use `adata_ref = adata_ref[b]`, with `b` defined as above, it interprets `b` not as a boolean mask but as an index, returning a single cell duplicated over and over. I'm not sure what the intended behavior is here. My solution is to use `adata_ref[np.where(b == n_neigh-1)[0]]`. However, this subselection changes the number of neighbors that other cells have. For example, for my data,. ```; b = np.array(list(map(len,adata_ref.obsp['distances'].tolil().rows))); print(""Before subselecting"", np.unique(b, return_counts = True)). adata_ref_subset = adata_ref[np.where(b == DEFINED_NEIGHB_NUM-1)[0]]; c = np.array(list(map(len,adata_ref_subset.obsp['distances'].tolil().rows))); print(""After subselecting"", np.unique(c, return_counts = True)); ```; yields; ```; Before subselecting, (array([13, 14]), array([ 28, 1161359])); After subselecting, (array([10, 11, 12, 13, 14]),; array([ 15, 1, 633, 46, 1160664]))); ```. To solve both problems I needed to rebuild the neighbor graph.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2085#issuecomment-1382325586
https://github.com/scverse/scanpy/issues/2085#issuecomment-1382325586:11,Integrability,message,message,11,"This error message was hard to debug! Indeed it is due to the behavior of `sc.pp.neighbors`. Cells are sometimes given different numbers of neighbors. Sometimes that the errant cells have a number of neighbors greater than zero (unlike as seen in #2244, where the # of neighbors of some cells was 0). My fix builds on the one above and was:; ```; b = np.array(list(map(len, adata_ref.obsp['distances'].tolil().rows))) # number of neighbors of each cell; adata_ref_subset = adata_ref[np.where(b == DEFINED_NEIGHB_NUM-1)[0]] # select only those with the right number; sc.pp.neighbors(adata_ref_subset, DEFINED_NEIGHB_NUM) # rebuild the neighbor graph; ```; ___; @ViriatoII Your comment helped me fix things – but your fix itself didn't work for me. First, when I use `adata_ref = adata_ref[b]`, with `b` defined as above, it interprets `b` not as a boolean mask but as an index, returning a single cell duplicated over and over. I'm not sure what the intended behavior is here. My solution is to use `adata_ref[np.where(b == n_neigh-1)[0]]`. However, this subselection changes the number of neighbors that other cells have. For example, for my data,. ```; b = np.array(list(map(len,adata_ref.obsp['distances'].tolil().rows))); print(""Before subselecting"", np.unique(b, return_counts = True)). adata_ref_subset = adata_ref[np.where(b == DEFINED_NEIGHB_NUM-1)[0]]; c = np.array(list(map(len,adata_ref_subset.obsp['distances'].tolil().rows))); print(""After subselecting"", np.unique(c, return_counts = True)); ```; yields; ```; Before subselecting, (array([13, 14]), array([ 28, 1161359])); After subselecting, (array([10, 11, 12, 13, 14]),; array([ 15, 1, 633, 46, 1160664]))); ```. To solve both problems I needed to rebuild the neighbor graph.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2085#issuecomment-1382325586
https://github.com/scverse/scanpy/pull/2087#issuecomment-998071678:118,Testability,test,tests,118,"I feel like it's a bit of a weird include anyways. What would you call it?. ------------. Btw, some of the matplotlib tests are being flaky with the size of the plot generated. Not really sure what's up with it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2087#issuecomment-998071678
https://github.com/scverse/scanpy/pull/2087#issuecomment-998800841:51,Testability,test,tests,51,"maybe `hvg-seurat`?. > Btw, some of the matplotlib tests are being flaky with the size of the plot generated. Not really sure what's up with it. It’ so hard to do reproducible plots by pixel. Would be easier if there was a good declarative plot API for python that we used. I don’t know how we can improve this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2087#issuecomment-998800841
https://github.com/scverse/scanpy/pull/2087#issuecomment-998842552:128,Testability,test,tests,128,"For naming, I'd ask @adamgayoso, since he implemented it. I'm also fine with leaving it for now and merging this as is (pending tests passing). > Would be easier if there was a good declarative plot API for python . Have you seen how `seaborn` does it's tests? Not so many pixel comparison ones.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2087#issuecomment-998842552
https://github.com/scverse/scanpy/pull/2087#issuecomment-998842552:254,Testability,test,tests,254,"For naming, I'd ask @adamgayoso, since he implemented it. I'm also fine with leaving it for now and merging this as is (pending tests passing). > Would be easier if there was a good declarative plot API for python . Have you seen how `seaborn` does it's tests? Not so many pixel comparison ones.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2087#issuecomment-998842552
https://github.com/scverse/scanpy/pull/2087#issuecomment-999259300:257,Deployability,install,install,257,"> Looking through these, I saw that the skmisc isn’t named after the feature it enables. Should we add a more descriptive copy?. I don't have strong feelings. I assume most people try to run the method and then it yells at them telling them exactly what to install and how to do it. The comment is sufficient for me",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2087#issuecomment-999259300
https://github.com/scverse/scanpy/issues/2088#issuecomment-1787310117:43,Deployability,update,update,43,"OK, let’s close this in favor of #1733 and update that one with the newest information if necessary",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2088#issuecomment-1787310117
https://github.com/scverse/scanpy/pull/2089#issuecomment-997386991:1204,Testability,log,logging,1204,# [Codecov](https://codecov.io/gh/theislab/scanpy/pull/2089?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) Report; > Merging [#2089](https://codecov.io/gh/theislab/scanpy/pull/2089?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) (34640c0) into [master](https://codecov.io/gh/theislab/scanpy/commit/d805b415b732f69c639a3fec620b2bfee4ab934c?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) (d805b41) will **decrease** coverage by `0.04%`.; > The diff coverage is `63.63%`. ```diff; @@ Coverage Diff @@; ## master #2089 +/- ##; ==========================================; - Coverage 71.42% 71.38% -0.05% ; ==========================================; Files 92 92 ; Lines 11286 11283 -3 ; ==========================================; - Hits 8061 8054 -7 ; - Misses 3225 3229 +4 ; ```. | [Impacted Files](https://codecov.io/gh/theislab/scanpy/pull/2089?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) | Coverage Δ | |; |---|---|---|; | [scanpy/logging.py](https://codecov.io/gh/theislab/scanpy/pull/2089/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab#diff-c2NhbnB5L2xvZ2dpbmcucHk=) | `95.04% <63.63%> (-3.35%)` | :arrow_down: |,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2089#issuecomment-997386991
https://github.com/scverse/scanpy/pull/2089#issuecomment-998063447:308,Deployability,update,update,308,"> 2. Have the info in notebook. I think I'd be happy to recommend calling `session_info` directly for this. IIRC, we have these functions at all because a package which did a good job of displaying the imported packages and dependencies didn't really exist. . > and leave print_versions unchanged?. With the update to use `session_info`?. I'd even be fine to deprecate the `file` argument, since it's not super useful. Plus `session_info` provides this, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2089#issuecomment-998063447
https://github.com/scverse/scanpy/pull/2089#issuecomment-998063447:224,Integrability,depend,dependencies,224,"> 2. Have the info in notebook. I think I'd be happy to recommend calling `session_info` directly for this. IIRC, we have these functions at all because a package which did a good job of displaying the imported packages and dependencies didn't really exist. . > and leave print_versions unchanged?. With the update to use `session_info`?. I'd even be fine to deprecate the `file` argument, since it's not super useful. Plus `session_info` provides this, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2089#issuecomment-998063447
https://github.com/scverse/scanpy/pull/2089#issuecomment-998837030:770,Deployability,install,install,770,"> My idea was to have print_header output very little, plus an expandable region (as it’s the one called in notebooks), and to revert print_versions to just copyable text output. Could we deprecate `print_header` and instead suggest a way to call `session_info` for the equivalent?. If all we're doing is calling `session_info.show` with a couple default arguments, I'm not sure it's worth keeping here. I'd like users to call it directly because:. * Users get access to all of the session_info options without us having to mediate that; * If something doesn't work, it's not our problem. > session_info has no file argument. It has `write_req_file`, which is the same intent – right?. I assume `file` was there from a time when this wrote something that you could `pip install` from?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2089#issuecomment-998837030
https://github.com/scverse/scanpy/pull/2089#issuecomment-998837030:524,Integrability,mediat,mediate,524,"> My idea was to have print_header output very little, plus an expandable region (as it’s the one called in notebooks), and to revert print_versions to just copyable text output. Could we deprecate `print_header` and instead suggest a way to call `session_info` for the equivalent?. If all we're doing is calling `session_info.show` with a couple default arguments, I'm not sure it's worth keeping here. I'd like users to call it directly because:. * Users get access to all of the session_info options without us having to mediate that; * If something doesn't work, it's not our problem. > session_info has no file argument. It has `write_req_file`, which is the same intent – right?. I assume `file` was there from a time when this wrote something that you could `pip install` from?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2089#issuecomment-998837030
https://github.com/scverse/scanpy/pull/2089#issuecomment-998837030:461,Security,access,access,461,"> My idea was to have print_header output very little, plus an expandable region (as it’s the one called in notebooks), and to revert print_versions to just copyable text output. Could we deprecate `print_header` and instead suggest a way to call `session_info` for the equivalent?. If all we're doing is calling `session_info.show` with a couple default arguments, I'm not sure it's worth keeping here. I'd like users to call it directly because:. * Users get access to all of the session_info options without us having to mediate that; * If something doesn't work, it's not our problem. > session_info has no file argument. It has `write_req_file`, which is the same intent – right?. I assume `file` was there from a time when this wrote something that you could `pip install` from?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2089#issuecomment-998837030
https://github.com/scverse/scanpy/pull/2089#issuecomment-1068501636:14,Deployability,Pipeline,Pipelines,14,<samp>; Azure Pipelines successfully started running 1 pipeline(s).<br>. </samp>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2089#issuecomment-1068501636
https://github.com/scverse/scanpy/pull/2089#issuecomment-1068501636:55,Deployability,pipeline,pipeline,55,<samp>; Azure Pipelines successfully started running 1 pipeline(s).<br>. </samp>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2089#issuecomment-1068501636
https://github.com/scverse/scanpy/issues/2092#issuecomment-1513930164:419,Availability,error,error,419,"Yeah, it's not working . Here https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.violin.html they say; > Wraps [seaborn.violinplot()](https://seaborn.pydata.org/generated/seaborn.violinplot.html#seaborn.violinplot) for [AnnData](https://anndata.readthedocs.io/en/stable/generated/anndata.AnnData.html#anndata.AnnData). but when you add `orient='h'` or `orient='v'` to the `sc.pl.violin` run, it fails wit this error:; ```; TypeError: seaborn.categorical.violinplot() got multiple values for keyword argument 'orient'; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2092#issuecomment-1513930164
https://github.com/scverse/scanpy/issues/2092#issuecomment-1513930164:114,Integrability,Wrap,Wraps,114,"Yeah, it's not working . Here https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.violin.html they say; > Wraps [seaborn.violinplot()](https://seaborn.pydata.org/generated/seaborn.violinplot.html#seaborn.violinplot) for [AnnData](https://anndata.readthedocs.io/en/stable/generated/anndata.AnnData.html#anndata.AnnData). but when you add `orient='h'` or `orient='v'` to the `sc.pl.violin` run, it fails wit this error:; ```; TypeError: seaborn.categorical.violinplot() got multiple values for keyword argument 'orient'; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2092#issuecomment-1513930164
https://github.com/scverse/scanpy/issues/2095#issuecomment-1015376680:68,Modifiability,variab,variables,68,"It looks like the issue here is that you have a different number of variables. Here's a small example of what's happening:. ```python; import pandas as pd. a = pd.DataFrame({""bool"": [True, False]}, index=[0, 1]); b = pd.DataFrame(index=[0,1,2]). b[""bool""] = a[""bool""]; b; ```. ```; bool; 0 True; 1 False; 2 NaN; ```. So when you try to subset by `adata.var.highly_variable` you have a bunch of null values in that index, which `AnnData` does not allow (it's not super obvious what the right thing to do here is anyways). What you might want to do is:. ```python; adata = adata[:, adata.var.highly_variable & adata.var.highly_variable.notna()].copy(); ```. or. ```python; adata = adata[:, ACT_sub2.var_names[ACT_sub2.var['highly_variable']]].copy(); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2095#issuecomment-1015376680
https://github.com/scverse/scanpy/issues/2101#issuecomment-1005863077:137,Deployability,install,installed,137,"Okay, I solved the issue. In my environment, scanpy==1.7.2 does not work with umap==0.5.2. I pip uninstall scanpy and umap-learn. Next I installed umap-learn through conda which was umap==0.5.1. When installing scanpy again it works as expected. . Not sure if its worth looking further into it but pip install scanpy also installs umap==0.5.2 (which does not work at least for me). . Many thanks! ; ![umap_0 5 1](https://user-images.githubusercontent.com/20926246/148250255-5ac00a46-cbc9-4608-a893-0472e32f5fb5.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2101#issuecomment-1005863077
https://github.com/scverse/scanpy/issues/2101#issuecomment-1005863077:200,Deployability,install,installing,200,"Okay, I solved the issue. In my environment, scanpy==1.7.2 does not work with umap==0.5.2. I pip uninstall scanpy and umap-learn. Next I installed umap-learn through conda which was umap==0.5.1. When installing scanpy again it works as expected. . Not sure if its worth looking further into it but pip install scanpy also installs umap==0.5.2 (which does not work at least for me). . Many thanks! ; ![umap_0 5 1](https://user-images.githubusercontent.com/20926246/148250255-5ac00a46-cbc9-4608-a893-0472e32f5fb5.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2101#issuecomment-1005863077
https://github.com/scverse/scanpy/issues/2101#issuecomment-1005863077:302,Deployability,install,install,302,"Okay, I solved the issue. In my environment, scanpy==1.7.2 does not work with umap==0.5.2. I pip uninstall scanpy and umap-learn. Next I installed umap-learn through conda which was umap==0.5.1. When installing scanpy again it works as expected. . Not sure if its worth looking further into it but pip install scanpy also installs umap==0.5.2 (which does not work at least for me). . Many thanks! ; ![umap_0 5 1](https://user-images.githubusercontent.com/20926246/148250255-5ac00a46-cbc9-4608-a893-0472e32f5fb5.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2101#issuecomment-1005863077
https://github.com/scverse/scanpy/issues/2101#issuecomment-1005863077:322,Deployability,install,installs,322,"Okay, I solved the issue. In my environment, scanpy==1.7.2 does not work with umap==0.5.2. I pip uninstall scanpy and umap-learn. Next I installed umap-learn through conda which was umap==0.5.1. When installing scanpy again it works as expected. . Not sure if its worth looking further into it but pip install scanpy also installs umap==0.5.2 (which does not work at least for me). . Many thanks! ; ![umap_0 5 1](https://user-images.githubusercontent.com/20926246/148250255-5ac00a46-cbc9-4608-a893-0472e32f5fb5.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2101#issuecomment-1005863077
https://github.com/scverse/scanpy/issues/2101#issuecomment-1005863077:123,Usability,learn,learn,123,"Okay, I solved the issue. In my environment, scanpy==1.7.2 does not work with umap==0.5.2. I pip uninstall scanpy and umap-learn. Next I installed umap-learn through conda which was umap==0.5.1. When installing scanpy again it works as expected. . Not sure if its worth looking further into it but pip install scanpy also installs umap==0.5.2 (which does not work at least for me). . Many thanks! ; ![umap_0 5 1](https://user-images.githubusercontent.com/20926246/148250255-5ac00a46-cbc9-4608-a893-0472e32f5fb5.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2101#issuecomment-1005863077
https://github.com/scverse/scanpy/issues/2101#issuecomment-1005863077:152,Usability,learn,learn,152,"Okay, I solved the issue. In my environment, scanpy==1.7.2 does not work with umap==0.5.2. I pip uninstall scanpy and umap-learn. Next I installed umap-learn through conda which was umap==0.5.1. When installing scanpy again it works as expected. . Not sure if its worth looking further into it but pip install scanpy also installs umap==0.5.2 (which does not work at least for me). . Many thanks! ; ![umap_0 5 1](https://user-images.githubusercontent.com/20926246/148250255-5ac00a46-cbc9-4608-a893-0472e32f5fb5.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2101#issuecomment-1005863077
https://github.com/scverse/scanpy/issues/2101#issuecomment-1005944568:24,Deployability,install,install,24,"Hi,. If you solely `pip install scanpy` it will use the latest versions of both, Scanpy and umap-learn. These are certainly compatible. Scanpy 1.7.2 not being perfectly compatible with the latest umap-learn package is an artifact of us not pinning the dependencies too hard and being more on the lenient side. I'd suggest to simply use the latest versions of both packages and you should not run into any problems.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2101#issuecomment-1005944568
https://github.com/scverse/scanpy/issues/2101#issuecomment-1005944568:252,Integrability,depend,dependencies,252,"Hi,. If you solely `pip install scanpy` it will use the latest versions of both, Scanpy and umap-learn. These are certainly compatible. Scanpy 1.7.2 not being perfectly compatible with the latest umap-learn package is an artifact of us not pinning the dependencies too hard and being more on the lenient side. I'd suggest to simply use the latest versions of both packages and you should not run into any problems.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2101#issuecomment-1005944568
https://github.com/scverse/scanpy/issues/2101#issuecomment-1005944568:97,Usability,learn,learn,97,"Hi,. If you solely `pip install scanpy` it will use the latest versions of both, Scanpy and umap-learn. These are certainly compatible. Scanpy 1.7.2 not being perfectly compatible with the latest umap-learn package is an artifact of us not pinning the dependencies too hard and being more on the lenient side. I'd suggest to simply use the latest versions of both packages and you should not run into any problems.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2101#issuecomment-1005944568
https://github.com/scverse/scanpy/issues/2101#issuecomment-1005944568:201,Usability,learn,learn,201,"Hi,. If you solely `pip install scanpy` it will use the latest versions of both, Scanpy and umap-learn. These are certainly compatible. Scanpy 1.7.2 not being perfectly compatible with the latest umap-learn package is an artifact of us not pinning the dependencies too hard and being more on the lenient side. I'd suggest to simply use the latest versions of both packages and you should not run into any problems.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2101#issuecomment-1005944568
https://github.com/scverse/scanpy/issues/2101#issuecomment-1005944568:325,Usability,simpl,simply,325,"Hi,. If you solely `pip install scanpy` it will use the latest versions of both, Scanpy and umap-learn. These are certainly compatible. Scanpy 1.7.2 not being perfectly compatible with the latest umap-learn package is an artifact of us not pinning the dependencies too hard and being more on the lenient side. I'd suggest to simply use the latest versions of both packages and you should not run into any problems.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2101#issuecomment-1005944568
https://github.com/scverse/scanpy/issues/2101#issuecomment-1020766690:87,Usability,simpl,simply,87,I was having the same issue these days. Happy to find this thread.; Fixed the issue by simply using the latest version of scanpy. Thanks a lot!!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2101#issuecomment-1020766690
https://github.com/scverse/scanpy/issues/2105#issuecomment-1010871653:158,Deployability,release,releases,158,"The upper bound for python versions we support is set by `numba` and `llvm-lite`. These rely on python internals, so can take a bit to be compatible with new releases. There should be python 3.10 support in the next numba release (https://github.com/numba/numba/issues/7562), which has a candidate out now ([see details here](https://numba.discourse.group/t/numba-0-55-0-rc1/1075)). I was able to get scanpy to import by doing:. ```sh; mamba create -yn ""numba-0.55.0rc1"" ""python=3.10""; conda activate numba-0.55.0rc1; mamba install -c numba -c numba/label/numpy numba=0.55.0rc1 numpy=1.21; pip install scanpy; python -c ""import scanpy""; ```. I couldn't install `scanpy` through conda since `pytables` doesn't have a 3.10 conda build afaict. Please let me know if try this out and run into any issues!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2105#issuecomment-1010871653
https://github.com/scverse/scanpy/issues/2105#issuecomment-1010871653:222,Deployability,release,release,222,"The upper bound for python versions we support is set by `numba` and `llvm-lite`. These rely on python internals, so can take a bit to be compatible with new releases. There should be python 3.10 support in the next numba release (https://github.com/numba/numba/issues/7562), which has a candidate out now ([see details here](https://numba.discourse.group/t/numba-0-55-0-rc1/1075)). I was able to get scanpy to import by doing:. ```sh; mamba create -yn ""numba-0.55.0rc1"" ""python=3.10""; conda activate numba-0.55.0rc1; mamba install -c numba -c numba/label/numpy numba=0.55.0rc1 numpy=1.21; pip install scanpy; python -c ""import scanpy""; ```. I couldn't install `scanpy` through conda since `pytables` doesn't have a 3.10 conda build afaict. Please let me know if try this out and run into any issues!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2105#issuecomment-1010871653
https://github.com/scverse/scanpy/issues/2105#issuecomment-1010871653:524,Deployability,install,install,524,"The upper bound for python versions we support is set by `numba` and `llvm-lite`. These rely on python internals, so can take a bit to be compatible with new releases. There should be python 3.10 support in the next numba release (https://github.com/numba/numba/issues/7562), which has a candidate out now ([see details here](https://numba.discourse.group/t/numba-0-55-0-rc1/1075)). I was able to get scanpy to import by doing:. ```sh; mamba create -yn ""numba-0.55.0rc1"" ""python=3.10""; conda activate numba-0.55.0rc1; mamba install -c numba -c numba/label/numpy numba=0.55.0rc1 numpy=1.21; pip install scanpy; python -c ""import scanpy""; ```. I couldn't install `scanpy` through conda since `pytables` doesn't have a 3.10 conda build afaict. Please let me know if try this out and run into any issues!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2105#issuecomment-1010871653
https://github.com/scverse/scanpy/issues/2105#issuecomment-1010871653:594,Deployability,install,install,594,"The upper bound for python versions we support is set by `numba` and `llvm-lite`. These rely on python internals, so can take a bit to be compatible with new releases. There should be python 3.10 support in the next numba release (https://github.com/numba/numba/issues/7562), which has a candidate out now ([see details here](https://numba.discourse.group/t/numba-0-55-0-rc1/1075)). I was able to get scanpy to import by doing:. ```sh; mamba create -yn ""numba-0.55.0rc1"" ""python=3.10""; conda activate numba-0.55.0rc1; mamba install -c numba -c numba/label/numpy numba=0.55.0rc1 numpy=1.21; pip install scanpy; python -c ""import scanpy""; ```. I couldn't install `scanpy` through conda since `pytables` doesn't have a 3.10 conda build afaict. Please let me know if try this out and run into any issues!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2105#issuecomment-1010871653
https://github.com/scverse/scanpy/issues/2105#issuecomment-1010871653:653,Deployability,install,install,653,"The upper bound for python versions we support is set by `numba` and `llvm-lite`. These rely on python internals, so can take a bit to be compatible with new releases. There should be python 3.10 support in the next numba release (https://github.com/numba/numba/issues/7562), which has a candidate out now ([see details here](https://numba.discourse.group/t/numba-0-55-0-rc1/1075)). I was able to get scanpy to import by doing:. ```sh; mamba create -yn ""numba-0.55.0rc1"" ""python=3.10""; conda activate numba-0.55.0rc1; mamba install -c numba -c numba/label/numpy numba=0.55.0rc1 numpy=1.21; pip install scanpy; python -c ""import scanpy""; ```. I couldn't install `scanpy` through conda since `pytables` doesn't have a 3.10 conda build afaict. Please let me know if try this out and run into any issues!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2105#issuecomment-1010871653
https://github.com/scverse/scanpy/issues/2105#issuecomment-1010919911:282,Deployability,install,install,282,"I was able to set up a dev environment with a little work. I think it works? Ran into some other issues though. <details>; <summary> Roughly what I ran </summary>. ```sh; mamba create -yn ""numba-0.55.0rc1-pip"" -c conda-forge python=3.10 pip; conda activate numba-0.55.0rc1-pip; pip install ""numba== 0.55.0rc1-pip""; pip install flit_core setuptools_scm; cd ~/github/anndata; pip install -e "".[dev,doc,test]""; cd ~/github/scanpy; pip install -e --no-build-isolation "".[dev,doc,test]""; ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2105#issuecomment-1010919911
https://github.com/scverse/scanpy/issues/2105#issuecomment-1010919911:319,Deployability,install,install,319,"I was able to set up a dev environment with a little work. I think it works? Ran into some other issues though. <details>; <summary> Roughly what I ran </summary>. ```sh; mamba create -yn ""numba-0.55.0rc1-pip"" -c conda-forge python=3.10 pip; conda activate numba-0.55.0rc1-pip; pip install ""numba== 0.55.0rc1-pip""; pip install flit_core setuptools_scm; cd ~/github/anndata; pip install -e "".[dev,doc,test]""; cd ~/github/scanpy; pip install -e --no-build-isolation "".[dev,doc,test]""; ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2105#issuecomment-1010919911
https://github.com/scverse/scanpy/issues/2105#issuecomment-1010919911:378,Deployability,install,install,378,"I was able to set up a dev environment with a little work. I think it works? Ran into some other issues though. <details>; <summary> Roughly what I ran </summary>. ```sh; mamba create -yn ""numba-0.55.0rc1-pip"" -c conda-forge python=3.10 pip; conda activate numba-0.55.0rc1-pip; pip install ""numba== 0.55.0rc1-pip""; pip install flit_core setuptools_scm; cd ~/github/anndata; pip install -e "".[dev,doc,test]""; cd ~/github/scanpy; pip install -e --no-build-isolation "".[dev,doc,test]""; ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2105#issuecomment-1010919911
https://github.com/scverse/scanpy/issues/2105#issuecomment-1010919911:432,Deployability,install,install,432,"I was able to set up a dev environment with a little work. I think it works? Ran into some other issues though. <details>; <summary> Roughly what I ran </summary>. ```sh; mamba create -yn ""numba-0.55.0rc1-pip"" -c conda-forge python=3.10 pip; conda activate numba-0.55.0rc1-pip; pip install ""numba== 0.55.0rc1-pip""; pip install flit_core setuptools_scm; cd ~/github/anndata; pip install -e "".[dev,doc,test]""; cd ~/github/scanpy; pip install -e --no-build-isolation "".[dev,doc,test]""; ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2105#issuecomment-1010919911
https://github.com/scverse/scanpy/issues/2105#issuecomment-1010919911:400,Testability,test,test,400,"I was able to set up a dev environment with a little work. I think it works? Ran into some other issues though. <details>; <summary> Roughly what I ran </summary>. ```sh; mamba create -yn ""numba-0.55.0rc1-pip"" -c conda-forge python=3.10 pip; conda activate numba-0.55.0rc1-pip; pip install ""numba== 0.55.0rc1-pip""; pip install flit_core setuptools_scm; cd ~/github/anndata; pip install -e "".[dev,doc,test]""; cd ~/github/scanpy; pip install -e --no-build-isolation "".[dev,doc,test]""; ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2105#issuecomment-1010919911
https://github.com/scverse/scanpy/issues/2105#issuecomment-1010919911:475,Testability,test,test,475,"I was able to set up a dev environment with a little work. I think it works? Ran into some other issues though. <details>; <summary> Roughly what I ran </summary>. ```sh; mamba create -yn ""numba-0.55.0rc1-pip"" -c conda-forge python=3.10 pip; conda activate numba-0.55.0rc1-pip; pip install ""numba== 0.55.0rc1-pip""; pip install flit_core setuptools_scm; cd ~/github/anndata; pip install -e "".[dev,doc,test]""; cd ~/github/scanpy; pip install -e --no-build-isolation "".[dev,doc,test]""; ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2105#issuecomment-1010919911
https://github.com/scverse/scanpy/issues/2107#issuecomment-1016453592:633,Safety,avoid,avoid,633,"Hey Isaac - thanks for the tip, I did not know about `add_totals`! Violin plots are, in principle, exactly what I would like to have, but they are very hard to read for genes with lots of zeros or for clusters with a lot of cells. I am still worried that this doesn't make the relative numbers clear. For instance, something like 40% of CD14+ monocytes express LDHB, while maybe 80% of dendritic cells do. This looks like it might be more ""relevant"", but in reality, the number of monocytes that express the gene is three times the number of total dendritic cells. Does this make sense?. I guess that in the end the onus is on me to avoid or highlight such ambiguities in the analysis, and remain cognisant of them while looking at the data. I will keep thinking about this and post here if I have an epiphany.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2107#issuecomment-1016453592
https://github.com/scverse/scanpy/issues/2107#issuecomment-1016453592:294,Usability,clear,clear,294,"Hey Isaac - thanks for the tip, I did not know about `add_totals`! Violin plots are, in principle, exactly what I would like to have, but they are very hard to read for genes with lots of zeros or for clusters with a lot of cells. I am still worried that this doesn't make the relative numbers clear. For instance, something like 40% of CD14+ monocytes express LDHB, while maybe 80% of dendritic cells do. This looks like it might be more ""relevant"", but in reality, the number of monocytes that express the gene is three times the number of total dendritic cells. Does this make sense?. I guess that in the end the onus is on me to avoid or highlight such ambiguities in the analysis, and remain cognisant of them while looking at the data. I will keep thinking about this and post here if I have an epiphany.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2107#issuecomment-1016453592
https://github.com/scverse/scanpy/issues/2107#issuecomment-1016491736:65,Usability,clear,clear,65,"> I am still worried that this doesn't make the relative numbers clear. It sounds like you're trying to see whether absolute numbers of cells expressing a gene is similar between clusters. I don't think this is a use case I've commonly heard of. Maybe you could explain why you're interested in this?. To me, it seems more relevant to know how common a gene is expressed within a population than how many of that cell type express that gene. Proportions of cell types vary due to tissue and collection, so I'm not sure when differences in total amount is what I want to know. If you wanted, you could try to map the size of the dot to the number of cells in the cluster expressing the gene? You can find some code for doing this kind of thing here (https://github.com/theislab/scanpy/issues/1876#issuecomment-987049315), though we would like that API to be nicer.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2107#issuecomment-1016491736
https://github.com/scverse/scanpy/issues/2107#issuecomment-1017354889:1129,Performance,perform,performed,1129,"> absolute numbers of cells expressing a gene is similar between clusters as a use case. I am aware that this is a bit of a niche problem, and I am not particularly happy with domino plots as a solution either. I have no better vehicle to discuss this than opening an issue :( Hopefully this inspires the next person who deals with this problem. As to the question, maybe sticking to this example will help me explain:. I am looking at the expression of Hb9/Mnx in my whole-body dataset. I notice from the feature scatter that it seems to be somewhat expressed in clusters 0, 2, and 18. Wanting to be sure, I look at the dotplot. The dotplot tells me that there is a greater proportion of cells in cluster 18 that express it, compared to 0 and 2. The dotplot might make me believe that Hb9 is a marker for cluster 18, and if I do an in-situ hybridisation, these are the cells I would be staining. However, the truth is that the vast majority of cells that express Hb9 are actually in clusters 0 and 2, different cell types than 18. The number of cells in each cluster correlates with the number of cells in the organism, so if I performed the in-situ I would get lots of cells that I could mistakenly all identify as cluster 18. Does this make more sense?. EDIT: I am not advocating for domino plots to be part of ScanPy. I am simply trying to start a discussion, and trying to see if there was an easy fix that I missed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2107#issuecomment-1017354889
https://github.com/scverse/scanpy/issues/2107#issuecomment-1017354889:1327,Usability,simpl,simply,1327,"> absolute numbers of cells expressing a gene is similar between clusters as a use case. I am aware that this is a bit of a niche problem, and I am not particularly happy with domino plots as a solution either. I have no better vehicle to discuss this than opening an issue :( Hopefully this inspires the next person who deals with this problem. As to the question, maybe sticking to this example will help me explain:. I am looking at the expression of Hb9/Mnx in my whole-body dataset. I notice from the feature scatter that it seems to be somewhat expressed in clusters 0, 2, and 18. Wanting to be sure, I look at the dotplot. The dotplot tells me that there is a greater proportion of cells in cluster 18 that express it, compared to 0 and 2. The dotplot might make me believe that Hb9 is a marker for cluster 18, and if I do an in-situ hybridisation, these are the cells I would be staining. However, the truth is that the vast majority of cells that express Hb9 are actually in clusters 0 and 2, different cell types than 18. The number of cells in each cluster correlates with the number of cells in the organism, so if I performed the in-situ I would get lots of cells that I could mistakenly all identify as cluster 18. Does this make more sense?. EDIT: I am not advocating for domino plots to be part of ScanPy. I am simply trying to start a discussion, and trying to see if there was an easy fix that I missed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2107#issuecomment-1017354889
https://github.com/scverse/scanpy/issues/2108#issuecomment-1012619831:193,Usability,learn,learn,193,"Here is the old package information, in which I run Scanpy very well before.; Windows 10 x64 bit, 20H2. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.3 scipy==1.7.3 pandas==1.3.5 scikit-learn==1.0.1 statsmodels==0.13.1 python-igraph==0.9.8 pynndescent==0.5.5; scvelo==0.2.4 scanpy==1.8.2 anndata==0.7.8 loompy==3.0.6 numpy==1.20.3 scipy==1.7.3 matplotlib==3.5.1 sklearn==1.0.1 pandas==1.3.5; cellrank==1.5.0 scanpy==1.8.2 anndata==0.7.8 numpy==1.20.3 numba==0.54.1 scipy==1.7.3 pandas==1.3.5 pygpcca==1.0.2 scikit-learn==1.0.1 statsmodels==0.13.1 python-igraph==0.9.8 scvelo==0.2.4 pygam==0.8.0 matplotlib==3.5.1 seaborn==0.11.2",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1012619831
https://github.com/scverse/scanpy/issues/2108#issuecomment-1012619831:521,Usability,learn,learn,521,"Here is the old package information, in which I run Scanpy very well before.; Windows 10 x64 bit, 20H2. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.3 scipy==1.7.3 pandas==1.3.5 scikit-learn==1.0.1 statsmodels==0.13.1 python-igraph==0.9.8 pynndescent==0.5.5; scvelo==0.2.4 scanpy==1.8.2 anndata==0.7.8 loompy==3.0.6 numpy==1.20.3 scipy==1.7.3 matplotlib==3.5.1 sklearn==1.0.1 pandas==1.3.5; cellrank==1.5.0 scanpy==1.8.2 anndata==0.7.8 numpy==1.20.3 numba==0.54.1 scipy==1.7.3 pandas==1.3.5 pygpcca==1.0.2 scikit-learn==1.0.1 statsmodels==0.13.1 python-igraph==0.9.8 scvelo==0.2.4 pygam==0.8.0 matplotlib==3.5.1 seaborn==0.11.2",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1012619831
https://github.com/scverse/scanpy/issues/2108#issuecomment-1012719981:55,Deployability,install,install,55,"It seems to be a pytables problem. What happens if you install pytables in a fresh python 3.8 environment?; If `import tables` fails, you could also try uninstalling pytables and installing the package from conda-forge.; `conda install -c conda-forge pytables.`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1012719981
https://github.com/scverse/scanpy/issues/2108#issuecomment-1012719981:179,Deployability,install,installing,179,"It seems to be a pytables problem. What happens if you install pytables in a fresh python 3.8 environment?; If `import tables` fails, you could also try uninstalling pytables and installing the package from conda-forge.; `conda install -c conda-forge pytables.`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1012719981
https://github.com/scverse/scanpy/issues/2108#issuecomment-1012719981:228,Deployability,install,install,228,"It seems to be a pytables problem. What happens if you install pytables in a fresh python 3.8 environment?; If `import tables` fails, you could also try uninstalling pytables and installing the package from conda-forge.; `conda install -c conda-forge pytables.`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1012719981
https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841:8491,Availability,error,error,8491,"e; 7 . ~\.conda\envs\NewPy38\lib\site-packages\numba\__init__.py in <module>; 198 ; 199 _ensure_llvm(); --> 200 _ensure_critical_deps(); 201 ; 202 # we know llvmlite is working as the above tests passed, import it now as SVML. ~\.conda\envs\NewPy38\lib\site-packages\numba\__init__.py in _ensure_critical_deps(); 138 raise ImportError(""Numba needs NumPy 1.18 or greater""); 139 elif numpy_version > (1, 21):; --> 140 raise ImportError(""Numba needs NumPy 1.21 or less""); 141 ; 142 try:. ImportError: Numba needs NumPy 1.21 or less; ```; Step5: I do` !pip uninstall Numpy`, then; ```python; !pip install numpy; Requirement already satisfied: numpy in c:\users\hyjfo\.conda\envs\newpy38\lib\site-packages (1.21.5). import numpy as np; import pandas as pd; import scanpy as sc; import scanpy.external as sce; import scipy; sc.settings.verbosity = 3; sc.logging.print_header(); sc.set_figure_params(dpi=100, dpi_save=600). AttributeError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_8308/1710492625.py in <module>; 1 import numpy as np; ----> 2 import pandas as pd; 3 import scanpy as sc; 4 import scanpy.external as sce; 5 import scipy. ~\.conda\envs\NewPy38\lib\site-packages\pandas\__init__.py in <module>; 20 ; 21 # numpy compat; ---> 22 from pandas.compat import (; 23 np_version_under1p18 as _np_version_under1p18,; 24 is_numpy_dev as _is_numpy_dev,. ~\.conda\envs\NewPy38\lib\site-packages\pandas\compat\__init__.py in <module>; 12 import warnings; 13 ; ---> 14 from pandas._typing import F; 15 from pandas.compat.numpy import (; 16 is_numpy_dev,. ~\.conda\envs\NewPy38\lib\site-packages\pandas\_typing.py in <module>; 82 # array-like; 83 ; ---> 84 ArrayLike = Union[""ExtensionArray"", np.ndarray]; 85 AnyArrayLike = Union[ArrayLike, ""Index"", ""Series""]; 86 . AttributeError: module 'numpy' has no attribute 'ndarray'; ```; It looks like an endless error. What's wrong with the `!pip install scanpy[leiden]`? It installed so many incompatible packages which never happened before.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841
https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841:114,Deployability,install,install,114,"Hello @Koncopd ,; Thanks for the response!. Step 1: I created a fresh new environment (py3.8.12); ```python; !pip install scanpy[leiden]. Successfully installed anndata-0.7.8 cycler-0.11.0 fonttools-4.28.5 h5py-3.6.0 igraph-0.9.9 joblib-1.1.0 kiwisolver-1.3.2 leidenalg-0.8.8 llvmlite-0.38.0 matplotlib-3.5.1 natsort-8.0.2 networkx-2.6.3 numba-0.55.0 numexpr-2.8.1 numpy-1.21.5 pandas-1.3.5 patsy-0.5.2 pillow-9.0.0 pynndescent-0.5.5 python-igraph-0.9.9 scanpy-1.8.2 scikit-learn-1.0.2 scipy-1.7.3 seaborn-0.11.2 sinfo-0.3.4 statsmodels-0.13.1 stdlib-list-0.8.0 tables-3.7.0 texttable-1.6.4 threadpoolctl-3.0.0 tqdm-4.62.3 umap-learn-0.5.2 xlrd-1.2.0. import numpy as np; import pandas as pd; import scanpy as sc; import scanpy.external as sce; import scipy; sc.settings.verbosity = 3; sc.logging.print_header(); sc.set_figure_params(dpi=100, dpi_save=600). ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_8256/1710492625.py in <module>; 1 import numpy as np; 2 import pandas as pd; ----> 3 import scanpy as sc; 4 import scanpy.external as sce; 5 import scipy. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\__init__.py in <module>; 12 # (start with settings as several tools are using it); 13 from ._settings import settings, Verbosity; ---> 14 from . import tools as tl; 15 from . import preprocessing as pp; 16 from . import plotting as pl. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\tools\__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\tools\_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\readwrite.py in <module>; 8 import pandas as pd; 9 from ma",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841
https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841:151,Deployability,install,installed,151,"Hello @Koncopd ,; Thanks for the response!. Step 1: I created a fresh new environment (py3.8.12); ```python; !pip install scanpy[leiden]. Successfully installed anndata-0.7.8 cycler-0.11.0 fonttools-4.28.5 h5py-3.6.0 igraph-0.9.9 joblib-1.1.0 kiwisolver-1.3.2 leidenalg-0.8.8 llvmlite-0.38.0 matplotlib-3.5.1 natsort-8.0.2 networkx-2.6.3 numba-0.55.0 numexpr-2.8.1 numpy-1.21.5 pandas-1.3.5 patsy-0.5.2 pillow-9.0.0 pynndescent-0.5.5 python-igraph-0.9.9 scanpy-1.8.2 scikit-learn-1.0.2 scipy-1.7.3 seaborn-0.11.2 sinfo-0.3.4 statsmodels-0.13.1 stdlib-list-0.8.0 tables-3.7.0 texttable-1.6.4 threadpoolctl-3.0.0 tqdm-4.62.3 umap-learn-0.5.2 xlrd-1.2.0. import numpy as np; import pandas as pd; import scanpy as sc; import scanpy.external as sce; import scipy; sc.settings.verbosity = 3; sc.logging.print_header(); sc.set_figure_params(dpi=100, dpi_save=600). ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_8256/1710492625.py in <module>; 1 import numpy as np; 2 import pandas as pd; ----> 3 import scanpy as sc; 4 import scanpy.external as sce; 5 import scipy. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\__init__.py in <module>; 12 # (start with settings as several tools are using it); 13 from ._settings import settings, Verbosity; ---> 14 from . import tools as tl; 15 from . import preprocessing as pp; 16 from . import plotting as pl. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\tools\__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\tools\_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\readwrite.py in <module>; 8 import pandas as pd; 9 from ma",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841
https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841:2413,Deployability,install,install,2413,"\lib\site-packages\scanpy\tools\__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\tools\_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\readwrite.py in <module>; 8 import pandas as pd; 9 from matplotlib.image import imread; ---> 10 import tables; 11 import anndata; 12 from anndata import (. ~\.conda\envs\NewPy38\lib\site-packages\tables\__init__.py in <module>; 43 ; 44 # Necessary imports to get versions stored on the cython extension; ---> 45 from .utilsextension import get_hdf5_version as _get_hdf5_version; 46 ; 47 . ImportError: DLL load failed while importing utilsextension; ```; Step 2: Then I install tables; ```python; !pip install tables. Requirement already satisfied: tables in c:\users\hyjfo\.conda\envs\newpy38\lib\site-packages (3.7.0); Requirement already satisfied: packaging in c:\users\hyjfo\.conda\envs\newpy38\lib\site-packages (from tables) (21.3); Requirement already satisfied: numpy>=1.19.0 in c:\users\hyjfo\.conda\envs\newpy38\lib\site-packages (from tables) (1.21.5); Requirement already satisfied: numexpr>=2.6.2 in c:\users\hyjfo\.conda\envs\newpy38\lib\site-packages (from tables) (2.8.1); Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\users\hyjfo\.conda\envs\newpy38\lib\site-packages (from packaging->tables) (3.0.4). import tables. ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_8256/574719567.py in <module>; ----> 1 import tables. ~\.conda\envs\NewPy38\lib\site-packages\tables\__init__.py in <module>; 43 ; 44 # Necessary imports to get versions stored on the cython extension; ---> 45 from .utilsext",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841
https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841:2445,Deployability,install,install,2445,"\lib\site-packages\scanpy\tools\__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\tools\_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\readwrite.py in <module>; 8 import pandas as pd; 9 from matplotlib.image import imread; ---> 10 import tables; 11 import anndata; 12 from anndata import (. ~\.conda\envs\NewPy38\lib\site-packages\tables\__init__.py in <module>; 43 ; 44 # Necessary imports to get versions stored on the cython extension; ---> 45 from .utilsextension import get_hdf5_version as _get_hdf5_version; 46 ; 47 . ImportError: DLL load failed while importing utilsextension; ```; Step 2: Then I install tables; ```python; !pip install tables. Requirement already satisfied: tables in c:\users\hyjfo\.conda\envs\newpy38\lib\site-packages (3.7.0); Requirement already satisfied: packaging in c:\users\hyjfo\.conda\envs\newpy38\lib\site-packages (from tables) (21.3); Requirement already satisfied: numpy>=1.19.0 in c:\users\hyjfo\.conda\envs\newpy38\lib\site-packages (from tables) (1.21.5); Requirement already satisfied: numexpr>=2.6.2 in c:\users\hyjfo\.conda\envs\newpy38\lib\site-packages (from tables) (2.8.1); Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\users\hyjfo\.conda\envs\newpy38\lib\site-packages (from packaging->tables) (3.0.4). import tables. ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_8256/574719567.py in <module>; ----> 1 import tables. ~\.conda\envs\NewPy38\lib\site-packages\tables\__init__.py in <module>; 43 ; 44 # Necessary imports to get versions stored on the cython extension; ---> 45 from .utilsext",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841
https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841:3591,Deployability,install,install,3591,"0); Requirement already satisfied: packaging in c:\users\hyjfo\.conda\envs\newpy38\lib\site-packages (from tables) (21.3); Requirement already satisfied: numpy>=1.19.0 in c:\users\hyjfo\.conda\envs\newpy38\lib\site-packages (from tables) (1.21.5); Requirement already satisfied: numexpr>=2.6.2 in c:\users\hyjfo\.conda\envs\newpy38\lib\site-packages (from tables) (2.8.1); Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\users\hyjfo\.conda\envs\newpy38\lib\site-packages (from packaging->tables) (3.0.4). import tables. ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_8256/574719567.py in <module>; ----> 1 import tables. ~\.conda\envs\NewPy38\lib\site-packages\tables\__init__.py in <module>; 43 ; 44 # Necessary imports to get versions stored on the cython extension; ---> 45 from .utilsextension import get_hdf5_version as _get_hdf5_version; 46 ; 47 . ImportError: DLL load failed while importing utilsextension; ```; Step 3: As you recommend, I do `!pip uninstall tables` and `conda install -c conda-forge pytables`, then; ```python; import tables # pass. import numpy as np; import pandas as pd; import scanpy as sc; import scanpy.external as sce; import scipy; sc.settings.verbosity = 3; sc.logging.print_header(); sc.set_figure_params(dpi=100, dpi_save=600). ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_15024/1710492625.py in <module>; 1 import numpy as np; 2 import pandas as pd; ----> 3 import scanpy as sc; 4 import scanpy.external as sce; 5 import scipy. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\__init__.py in <module>; 4 ; 5 if not within_flit(): # see function docstring on why this is there; ----> 6 from ._utils import check_versions; 7 ; 8 check_versions(). ~\.conda\envs\NewPy38\lib\site-packages\scanpy\_utils\__init__.py in <module>; 19 from numpy import random; 20 from scipy import sparse; ---> 21 from anndata import AnnData, __version__ as anndata_version; 22 from textwrap import dedent; 23 f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841
https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841:5555,Deployability,install,install,5555,"aging import version. ~\.conda\envs\NewPy38\lib\site-packages\anndata\__init__.py in <module>; 5 if not within_flit():; 6 del within_flit; ----> 7 from ._core.anndata import AnnData, ImplicitModificationWarning; 8 from ._core.merge import concat; 9 from ._core.raw import Raw. ~\.conda\envs\NewPy38\lib\site-packages\anndata\_core\anndata.py in <module>; 15 from typing import Tuple, List # Generic; 16 ; ---> 17 import h5py; 18 from natsort import natsorted; 19 import numpy as np. ~\.conda\envs\NewPy38\lib\site-packages\h5py\__init__.py in <module>; 31 raise; 32 ; ---> 33 from . import version; 34 ; 35 if version.hdf5_version_tuple != version.hdf5_built_version_tuple:. ~\.conda\envs\NewPy38\lib\site-packages\h5py\version.py in <module>; 13 ; 14 from collections import namedtuple; ---> 15 from . import h5 as _h5; 16 import sys; 17 import numpy. h5py\h5.pyx in init h5py.h5(). ImportError: DLL load failed while importing defs; ````; Step4: I do `!pip uninstall h5py` and `conda install -c conda-forge pytables h5py`, then; ```python; import numpy as np; import pandas as pd; import scanpy as sc; import scanpy.external as sce; import scipy; sc.settings.verbosity = 3; sc.logging.print_header(); sc.set_figure_params(dpi=100, dpi_save=600). ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_14912/1710492625.py in <module>; 1 import numpy as np; 2 import pandas as pd; ----> 3 import scanpy as sc; 4 import scanpy.external as sce; 5 import scipy. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\__init__.py in <module>; 4 ; 5 if not within_flit(): # see function docstring on why this is there; ----> 6 from ._utils import check_versions; 7 ; 8 check_versions(). ~\.conda\envs\NewPy38\lib\site-packages\scanpy\_utils\__init__.py in <module>; 27 from .. import logging as logg; 28 ; ---> 29 from .compute.is_constant import is_constant; 30 ; 31 . ~\.conda\envs\NewPy38\lib\site-packages\scanpy\_utils\compute\is_constant.py in <module>; 3 ; 4 import numpy as np; ---->",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841
https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841:7215,Deployability,install,install,7215,"utils import check_versions; 7 ; 8 check_versions(). ~\.conda\envs\NewPy38\lib\site-packages\scanpy\_utils\__init__.py in <module>; 27 from .. import logging as logg; 28 ; ---> 29 from .compute.is_constant import is_constant; 30 ; 31 . ~\.conda\envs\NewPy38\lib\site-packages\scanpy\_utils\compute\is_constant.py in <module>; 3 ; 4 import numpy as np; ----> 5 from numba import njit; 6 from scipy import sparse; 7 . ~\.conda\envs\NewPy38\lib\site-packages\numba\__init__.py in <module>; 198 ; 199 _ensure_llvm(); --> 200 _ensure_critical_deps(); 201 ; 202 # we know llvmlite is working as the above tests passed, import it now as SVML. ~\.conda\envs\NewPy38\lib\site-packages\numba\__init__.py in _ensure_critical_deps(); 138 raise ImportError(""Numba needs NumPy 1.18 or greater""); 139 elif numpy_version > (1, 21):; --> 140 raise ImportError(""Numba needs NumPy 1.21 or less""); 141 ; 142 try:. ImportError: Numba needs NumPy 1.21 or less; ```; Step5: I do` !pip uninstall Numpy`, then; ```python; !pip install numpy; Requirement already satisfied: numpy in c:\users\hyjfo\.conda\envs\newpy38\lib\site-packages (1.21.5). import numpy as np; import pandas as pd; import scanpy as sc; import scanpy.external as sce; import scipy; sc.settings.verbosity = 3; sc.logging.print_header(); sc.set_figure_params(dpi=100, dpi_save=600). AttributeError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_8308/1710492625.py in <module>; 1 import numpy as np; ----> 2 import pandas as pd; 3 import scanpy as sc; 4 import scanpy.external as sce; 5 import scipy. ~\.conda\envs\NewPy38\lib\site-packages\pandas\__init__.py in <module>; 20 ; 21 # numpy compat; ---> 22 from pandas.compat import (; 23 np_version_under1p18 as _np_version_under1p18,; 24 is_numpy_dev as _is_numpy_dev,. ~\.conda\envs\NewPy38\lib\site-packages\pandas\compat\__init__.py in <module>; 12 import warnings; 13 ; ---> 14 from pandas._typing import F; 15 from pandas.compat.numpy import (; 16 is_numpy_dev,. ~\.conda\envs\NewPy38",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841
https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841:8526,Deployability,install,install,8526,"e; 7 . ~\.conda\envs\NewPy38\lib\site-packages\numba\__init__.py in <module>; 198 ; 199 _ensure_llvm(); --> 200 _ensure_critical_deps(); 201 ; 202 # we know llvmlite is working as the above tests passed, import it now as SVML. ~\.conda\envs\NewPy38\lib\site-packages\numba\__init__.py in _ensure_critical_deps(); 138 raise ImportError(""Numba needs NumPy 1.18 or greater""); 139 elif numpy_version > (1, 21):; --> 140 raise ImportError(""Numba needs NumPy 1.21 or less""); 141 ; 142 try:. ImportError: Numba needs NumPy 1.21 or less; ```; Step5: I do` !pip uninstall Numpy`, then; ```python; !pip install numpy; Requirement already satisfied: numpy in c:\users\hyjfo\.conda\envs\newpy38\lib\site-packages (1.21.5). import numpy as np; import pandas as pd; import scanpy as sc; import scanpy.external as sce; import scipy; sc.settings.verbosity = 3; sc.logging.print_header(); sc.set_figure_params(dpi=100, dpi_save=600). AttributeError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_8308/1710492625.py in <module>; 1 import numpy as np; ----> 2 import pandas as pd; 3 import scanpy as sc; 4 import scanpy.external as sce; 5 import scipy. ~\.conda\envs\NewPy38\lib\site-packages\pandas\__init__.py in <module>; 20 ; 21 # numpy compat; ---> 22 from pandas.compat import (; 23 np_version_under1p18 as _np_version_under1p18,; 24 is_numpy_dev as _is_numpy_dev,. ~\.conda\envs\NewPy38\lib\site-packages\pandas\compat\__init__.py in <module>; 12 import warnings; 13 ; ---> 14 from pandas._typing import F; 15 from pandas.compat.numpy import (; 16 is_numpy_dev,. ~\.conda\envs\NewPy38\lib\site-packages\pandas\_typing.py in <module>; 82 # array-like; 83 ; ---> 84 ArrayLike = Union[""ExtensionArray"", np.ndarray]; 85 AnyArrayLike = Union[ArrayLike, ""Index"", ""Series""]; 86 . AttributeError: module 'numpy' has no attribute 'ndarray'; ```; It looks like an endless error. What's wrong with the `!pip install scanpy[leiden]`? It installed so many incompatible packages which never happened before.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841
https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841:8554,Deployability,install,installed,8554,"e; 7 . ~\.conda\envs\NewPy38\lib\site-packages\numba\__init__.py in <module>; 198 ; 199 _ensure_llvm(); --> 200 _ensure_critical_deps(); 201 ; 202 # we know llvmlite is working as the above tests passed, import it now as SVML. ~\.conda\envs\NewPy38\lib\site-packages\numba\__init__.py in _ensure_critical_deps(); 138 raise ImportError(""Numba needs NumPy 1.18 or greater""); 139 elif numpy_version > (1, 21):; --> 140 raise ImportError(""Numba needs NumPy 1.21 or less""); 141 ; 142 try:. ImportError: Numba needs NumPy 1.21 or less; ```; Step5: I do` !pip uninstall Numpy`, then; ```python; !pip install numpy; Requirement already satisfied: numpy in c:\users\hyjfo\.conda\envs\newpy38\lib\site-packages (1.21.5). import numpy as np; import pandas as pd; import scanpy as sc; import scanpy.external as sce; import scipy; sc.settings.verbosity = 3; sc.logging.print_header(); sc.set_figure_params(dpi=100, dpi_save=600). AttributeError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_8308/1710492625.py in <module>; 1 import numpy as np; ----> 2 import pandas as pd; 3 import scanpy as sc; 4 import scanpy.external as sce; 5 import scipy. ~\.conda\envs\NewPy38\lib\site-packages\pandas\__init__.py in <module>; 20 ; 21 # numpy compat; ---> 22 from pandas.compat import (; 23 np_version_under1p18 as _np_version_under1p18,; 24 is_numpy_dev as _is_numpy_dev,. ~\.conda\envs\NewPy38\lib\site-packages\pandas\compat\__init__.py in <module>; 12 import warnings; 13 ; ---> 14 from pandas._typing import F; 15 from pandas.compat.numpy import (; 16 is_numpy_dev,. ~\.conda\envs\NewPy38\lib\site-packages\pandas\_typing.py in <module>; 82 # array-like; 83 ; ---> 84 ArrayLike = Union[""ExtensionArray"", np.ndarray]; 85 AnyArrayLike = Union[ArrayLike, ""Index"", ""Series""]; 86 . AttributeError: module 'numpy' has no attribute 'ndarray'; ```; It looks like an endless error. What's wrong with the `!pip install scanpy[leiden]`? It installed so many incompatible packages which never happened before.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841
https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841:2349,Performance,load,load,2349,"\lib\site-packages\scanpy\tools\__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\tools\_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\readwrite.py in <module>; 8 import pandas as pd; 9 from matplotlib.image import imread; ---> 10 import tables; 11 import anndata; 12 from anndata import (. ~\.conda\envs\NewPy38\lib\site-packages\tables\__init__.py in <module>; 43 ; 44 # Necessary imports to get versions stored on the cython extension; ---> 45 from .utilsextension import get_hdf5_version as _get_hdf5_version; 46 ; 47 . ImportError: DLL load failed while importing utilsextension; ```; Step 2: Then I install tables; ```python; !pip install tables. Requirement already satisfied: tables in c:\users\hyjfo\.conda\envs\newpy38\lib\site-packages (3.7.0); Requirement already satisfied: packaging in c:\users\hyjfo\.conda\envs\newpy38\lib\site-packages (from tables) (21.3); Requirement already satisfied: numpy>=1.19.0 in c:\users\hyjfo\.conda\envs\newpy38\lib\site-packages (from tables) (1.21.5); Requirement already satisfied: numexpr>=2.6.2 in c:\users\hyjfo\.conda\envs\newpy38\lib\site-packages (from tables) (2.8.1); Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\users\hyjfo\.conda\envs\newpy38\lib\site-packages (from packaging->tables) (3.0.4). import tables. ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_8256/574719567.py in <module>; ----> 1 import tables. ~\.conda\envs\NewPy38\lib\site-packages\tables\__init__.py in <module>; 43 ; 44 # Necessary imports to get versions stored on the cython extension; ---> 45 from .utilsext",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841
https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841:3476,Performance,load,load,3476,"0); Requirement already satisfied: packaging in c:\users\hyjfo\.conda\envs\newpy38\lib\site-packages (from tables) (21.3); Requirement already satisfied: numpy>=1.19.0 in c:\users\hyjfo\.conda\envs\newpy38\lib\site-packages (from tables) (1.21.5); Requirement already satisfied: numexpr>=2.6.2 in c:\users\hyjfo\.conda\envs\newpy38\lib\site-packages (from tables) (2.8.1); Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\users\hyjfo\.conda\envs\newpy38\lib\site-packages (from packaging->tables) (3.0.4). import tables. ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_8256/574719567.py in <module>; ----> 1 import tables. ~\.conda\envs\NewPy38\lib\site-packages\tables\__init__.py in <module>; 43 ; 44 # Necessary imports to get versions stored on the cython extension; ---> 45 from .utilsextension import get_hdf5_version as _get_hdf5_version; 46 ; 47 . ImportError: DLL load failed while importing utilsextension; ```; Step 3: As you recommend, I do `!pip uninstall tables` and `conda install -c conda-forge pytables`, then; ```python; import tables # pass. import numpy as np; import pandas as pd; import scanpy as sc; import scanpy.external as sce; import scipy; sc.settings.verbosity = 3; sc.logging.print_header(); sc.set_figure_params(dpi=100, dpi_save=600). ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_15024/1710492625.py in <module>; 1 import numpy as np; 2 import pandas as pd; ----> 3 import scanpy as sc; 4 import scanpy.external as sce; 5 import scipy. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\__init__.py in <module>; 4 ; 5 if not within_flit(): # see function docstring on why this is there; ----> 6 from ._utils import check_versions; 7 ; 8 check_versions(). ~\.conda\envs\NewPy38\lib\site-packages\scanpy\_utils\__init__.py in <module>; 19 from numpy import random; 20 from scipy import sparse; ---> 21 from anndata import AnnData, __version__ as anndata_version; 22 from textwrap import dedent; 23 f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841
https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841:5470,Performance,load,load,5470,"aging import version. ~\.conda\envs\NewPy38\lib\site-packages\anndata\__init__.py in <module>; 5 if not within_flit():; 6 del within_flit; ----> 7 from ._core.anndata import AnnData, ImplicitModificationWarning; 8 from ._core.merge import concat; 9 from ._core.raw import Raw. ~\.conda\envs\NewPy38\lib\site-packages\anndata\_core\anndata.py in <module>; 15 from typing import Tuple, List # Generic; 16 ; ---> 17 import h5py; 18 from natsort import natsorted; 19 import numpy as np. ~\.conda\envs\NewPy38\lib\site-packages\h5py\__init__.py in <module>; 31 raise; 32 ; ---> 33 from . import version; 34 ; 35 if version.hdf5_version_tuple != version.hdf5_built_version_tuple:. ~\.conda\envs\NewPy38\lib\site-packages\h5py\version.py in <module>; 13 ; 14 from collections import namedtuple; ---> 15 from . import h5 as _h5; 16 import sys; 17 import numpy. h5py\h5.pyx in init h5py.h5(). ImportError: DLL load failed while importing defs; ````; Step4: I do `!pip uninstall h5py` and `conda install -c conda-forge pytables h5py`, then; ```python; import numpy as np; import pandas as pd; import scanpy as sc; import scanpy.external as sce; import scipy; sc.settings.verbosity = 3; sc.logging.print_header(); sc.set_figure_params(dpi=100, dpi_save=600). ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_14912/1710492625.py in <module>; 1 import numpy as np; 2 import pandas as pd; ----> 3 import scanpy as sc; 4 import scanpy.external as sce; 5 import scipy. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\__init__.py in <module>; 4 ; 5 if not within_flit(): # see function docstring on why this is there; ----> 6 from ._utils import check_versions; 7 ; 8 check_versions(). ~\.conda\envs\NewPy38\lib\site-packages\scanpy\_utils\__init__.py in <module>; 27 from .. import logging as logg; 28 ; ---> 29 from .compute.is_constant import is_constant; 30 ; 31 . ~\.conda\envs\NewPy38\lib\site-packages\scanpy\_utils\compute\is_constant.py in <module>; 3 ; 4 import numpy as np; ---->",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841
https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841:789,Testability,log,logging,789,"Hello @Koncopd ,; Thanks for the response!. Step 1: I created a fresh new environment (py3.8.12); ```python; !pip install scanpy[leiden]. Successfully installed anndata-0.7.8 cycler-0.11.0 fonttools-4.28.5 h5py-3.6.0 igraph-0.9.9 joblib-1.1.0 kiwisolver-1.3.2 leidenalg-0.8.8 llvmlite-0.38.0 matplotlib-3.5.1 natsort-8.0.2 networkx-2.6.3 numba-0.55.0 numexpr-2.8.1 numpy-1.21.5 pandas-1.3.5 patsy-0.5.2 pillow-9.0.0 pynndescent-0.5.5 python-igraph-0.9.9 scanpy-1.8.2 scikit-learn-1.0.2 scipy-1.7.3 seaborn-0.11.2 sinfo-0.3.4 statsmodels-0.13.1 stdlib-list-0.8.0 tables-3.7.0 texttable-1.6.4 threadpoolctl-3.0.0 tqdm-4.62.3 umap-learn-0.5.2 xlrd-1.2.0. import numpy as np; import pandas as pd; import scanpy as sc; import scanpy.external as sce; import scipy; sc.settings.verbosity = 3; sc.logging.print_header(); sc.set_figure_params(dpi=100, dpi_save=600). ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_8256/1710492625.py in <module>; 1 import numpy as np; 2 import pandas as pd; ----> 3 import scanpy as sc; 4 import scanpy.external as sce; 5 import scipy. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\__init__.py in <module>; 12 # (start with settings as several tools are using it); 13 from ._settings import settings, Verbosity; ---> 14 from . import tools as tl; 15 from . import preprocessing as pp; 16 from . import plotting as pl. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\tools\__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\tools\_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\readwrite.py in <module>; 8 import pandas as pd; 9 from ma",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841
https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841:1808,Testability,log,logging,1808,"er(); sc.set_figure_params(dpi=100, dpi_save=600). ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_8256/1710492625.py in <module>; 1 import numpy as np; 2 import pandas as pd; ----> 3 import scanpy as sc; 4 import scanpy.external as sce; 5 import scipy. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\__init__.py in <module>; 12 # (start with settings as several tools are using it); 13 from ._settings import settings, Verbosity; ---> 14 from . import tools as tl; 15 from . import preprocessing as pp; 16 from . import plotting as pl. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\tools\__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\tools\_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\readwrite.py in <module>; 8 import pandas as pd; 9 from matplotlib.image import imread; ---> 10 import tables; 11 import anndata; 12 from anndata import (. ~\.conda\envs\NewPy38\lib\site-packages\tables\__init__.py in <module>; 43 ; 44 # Necessary imports to get versions stored on the cython extension; ---> 45 from .utilsextension import get_hdf5_version as _get_hdf5_version; 46 ; 47 . ImportError: DLL load failed while importing utilsextension; ```; Step 2: Then I install tables; ```python; !pip install tables. Requirement already satisfied: tables in c:\users\hyjfo\.conda\envs\newpy38\lib\site-packages (3.7.0); Requirement already satisfied: packaging in c:\users\hyjfo\.conda\envs\newpy38\lib\site-packages (from tables) (21.3); Requirement already satisfied: numpy>=1.19.0 in c:\users\hyjfo\.conda\envs\newpy38\lib\site-packages (from tables) (1.21.5); ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841
https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841:1819,Testability,log,logg,1819,"er(); sc.set_figure_params(dpi=100, dpi_save=600). ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_8256/1710492625.py in <module>; 1 import numpy as np; 2 import pandas as pd; ----> 3 import scanpy as sc; 4 import scanpy.external as sce; 5 import scipy. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\__init__.py in <module>; 12 # (start with settings as several tools are using it); 13 from ._settings import settings, Verbosity; ---> 14 from . import tools as tl; 15 from . import preprocessing as pp; 16 from . import plotting as pl. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\tools\__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\tools\_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\readwrite.py in <module>; 8 import pandas as pd; 9 from matplotlib.image import imread; ---> 10 import tables; 11 import anndata; 12 from anndata import (. ~\.conda\envs\NewPy38\lib\site-packages\tables\__init__.py in <module>; 43 ; 44 # Necessary imports to get versions stored on the cython extension; ---> 45 from .utilsextension import get_hdf5_version as _get_hdf5_version; 46 ; 47 . ImportError: DLL load failed while importing utilsextension; ```; Step 2: Then I install tables; ```python; !pip install tables. Requirement already satisfied: tables in c:\users\hyjfo\.conda\envs\newpy38\lib\site-packages (3.7.0); Requirement already satisfied: packaging in c:\users\hyjfo\.conda\envs\newpy38\lib\site-packages (from tables) (21.3); Requirement already satisfied: numpy>=1.19.0 in c:\users\hyjfo\.conda\envs\newpy38\lib\site-packages (from tables) (1.21.5); ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841
https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841:3801,Testability,log,logging,3801,"); Requirement already satisfied: numexpr>=2.6.2 in c:\users\hyjfo\.conda\envs\newpy38\lib\site-packages (from tables) (2.8.1); Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\users\hyjfo\.conda\envs\newpy38\lib\site-packages (from packaging->tables) (3.0.4). import tables. ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_8256/574719567.py in <module>; ----> 1 import tables. ~\.conda\envs\NewPy38\lib\site-packages\tables\__init__.py in <module>; 43 ; 44 # Necessary imports to get versions stored on the cython extension; ---> 45 from .utilsextension import get_hdf5_version as _get_hdf5_version; 46 ; 47 . ImportError: DLL load failed while importing utilsextension; ```; Step 3: As you recommend, I do `!pip uninstall tables` and `conda install -c conda-forge pytables`, then; ```python; import tables # pass. import numpy as np; import pandas as pd; import scanpy as sc; import scanpy.external as sce; import scipy; sc.settings.verbosity = 3; sc.logging.print_header(); sc.set_figure_params(dpi=100, dpi_save=600). ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_15024/1710492625.py in <module>; 1 import numpy as np; 2 import pandas as pd; ----> 3 import scanpy as sc; 4 import scanpy.external as sce; 5 import scipy. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\__init__.py in <module>; 4 ; 5 if not within_flit(): # see function docstring on why this is there; ----> 6 from ._utils import check_versions; 7 ; 8 check_versions(). ~\.conda\envs\NewPy38\lib\site-packages\scanpy\_utils\__init__.py in <module>; 19 from numpy import random; 20 from scipy import sparse; ---> 21 from anndata import AnnData, __version__ as anndata_version; 22 from textwrap import dedent; 23 from packaging import version. ~\.conda\envs\NewPy38\lib\site-packages\anndata\__init__.py in <module>; 5 if not within_flit():; 6 del within_flit; ----> 7 from ._core.anndata import AnnData, ImplicitModificationWarning; 8 from ._core.merge impo",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841
https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841:5748,Testability,log,logging,5748,"ImplicitModificationWarning; 8 from ._core.merge import concat; 9 from ._core.raw import Raw. ~\.conda\envs\NewPy38\lib\site-packages\anndata\_core\anndata.py in <module>; 15 from typing import Tuple, List # Generic; 16 ; ---> 17 import h5py; 18 from natsort import natsorted; 19 import numpy as np. ~\.conda\envs\NewPy38\lib\site-packages\h5py\__init__.py in <module>; 31 raise; 32 ; ---> 33 from . import version; 34 ; 35 if version.hdf5_version_tuple != version.hdf5_built_version_tuple:. ~\.conda\envs\NewPy38\lib\site-packages\h5py\version.py in <module>; 13 ; 14 from collections import namedtuple; ---> 15 from . import h5 as _h5; 16 import sys; 17 import numpy. h5py\h5.pyx in init h5py.h5(). ImportError: DLL load failed while importing defs; ````; Step4: I do `!pip uninstall h5py` and `conda install -c conda-forge pytables h5py`, then; ```python; import numpy as np; import pandas as pd; import scanpy as sc; import scanpy.external as sce; import scipy; sc.settings.verbosity = 3; sc.logging.print_header(); sc.set_figure_params(dpi=100, dpi_save=600). ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_14912/1710492625.py in <module>; 1 import numpy as np; 2 import pandas as pd; ----> 3 import scanpy as sc; 4 import scanpy.external as sce; 5 import scipy. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\__init__.py in <module>; 4 ; 5 if not within_flit(): # see function docstring on why this is there; ----> 6 from ._utils import check_versions; 7 ; 8 check_versions(). ~\.conda\envs\NewPy38\lib\site-packages\scanpy\_utils\__init__.py in <module>; 27 from .. import logging as logg; 28 ; ---> 29 from .compute.is_constant import is_constant; 30 ; 31 . ~\.conda\envs\NewPy38\lib\site-packages\scanpy\_utils\compute\is_constant.py in <module>; 3 ; 4 import numpy as np; ----> 5 from numba import njit; 6 from scipy import sparse; 7 . ~\.conda\envs\NewPy38\lib\site-packages\numba\__init__.py in <module>; 198 ; 199 _ensure_llvm(); --> 200 _ensure_critical_d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841
https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841:6363,Testability,log,logging,6363,"t h5 as _h5; 16 import sys; 17 import numpy. h5py\h5.pyx in init h5py.h5(). ImportError: DLL load failed while importing defs; ````; Step4: I do `!pip uninstall h5py` and `conda install -c conda-forge pytables h5py`, then; ```python; import numpy as np; import pandas as pd; import scanpy as sc; import scanpy.external as sce; import scipy; sc.settings.verbosity = 3; sc.logging.print_header(); sc.set_figure_params(dpi=100, dpi_save=600). ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_14912/1710492625.py in <module>; 1 import numpy as np; 2 import pandas as pd; ----> 3 import scanpy as sc; 4 import scanpy.external as sce; 5 import scipy. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\__init__.py in <module>; 4 ; 5 if not within_flit(): # see function docstring on why this is there; ----> 6 from ._utils import check_versions; 7 ; 8 check_versions(). ~\.conda\envs\NewPy38\lib\site-packages\scanpy\_utils\__init__.py in <module>; 27 from .. import logging as logg; 28 ; ---> 29 from .compute.is_constant import is_constant; 30 ; 31 . ~\.conda\envs\NewPy38\lib\site-packages\scanpy\_utils\compute\is_constant.py in <module>; 3 ; 4 import numpy as np; ----> 5 from numba import njit; 6 from scipy import sparse; 7 . ~\.conda\envs\NewPy38\lib\site-packages\numba\__init__.py in <module>; 198 ; 199 _ensure_llvm(); --> 200 _ensure_critical_deps(); 201 ; 202 # we know llvmlite is working as the above tests passed, import it now as SVML. ~\.conda\envs\NewPy38\lib\site-packages\numba\__init__.py in _ensure_critical_deps(); 138 raise ImportError(""Numba needs NumPy 1.18 or greater""); 139 elif numpy_version > (1, 21):; --> 140 raise ImportError(""Numba needs NumPy 1.21 or less""); 141 ; 142 try:. ImportError: Numba needs NumPy 1.21 or less; ```; Step5: I do` !pip uninstall Numpy`, then; ```python; !pip install numpy; Requirement already satisfied: numpy in c:\users\hyjfo\.conda\envs\newpy38\lib\site-packages (1.21.5). import numpy as np; import pandas as pd; imp",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841
https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841:6374,Testability,log,logg,6374,"t h5 as _h5; 16 import sys; 17 import numpy. h5py\h5.pyx in init h5py.h5(). ImportError: DLL load failed while importing defs; ````; Step4: I do `!pip uninstall h5py` and `conda install -c conda-forge pytables h5py`, then; ```python; import numpy as np; import pandas as pd; import scanpy as sc; import scanpy.external as sce; import scipy; sc.settings.verbosity = 3; sc.logging.print_header(); sc.set_figure_params(dpi=100, dpi_save=600). ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_14912/1710492625.py in <module>; 1 import numpy as np; 2 import pandas as pd; ----> 3 import scanpy as sc; 4 import scanpy.external as sce; 5 import scipy. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\__init__.py in <module>; 4 ; 5 if not within_flit(): # see function docstring on why this is there; ----> 6 from ._utils import check_versions; 7 ; 8 check_versions(). ~\.conda\envs\NewPy38\lib\site-packages\scanpy\_utils\__init__.py in <module>; 27 from .. import logging as logg; 28 ; ---> 29 from .compute.is_constant import is_constant; 30 ; 31 . ~\.conda\envs\NewPy38\lib\site-packages\scanpy\_utils\compute\is_constant.py in <module>; 3 ; 4 import numpy as np; ----> 5 from numba import njit; 6 from scipy import sparse; 7 . ~\.conda\envs\NewPy38\lib\site-packages\numba\__init__.py in <module>; 198 ; 199 _ensure_llvm(); --> 200 _ensure_critical_deps(); 201 ; 202 # we know llvmlite is working as the above tests passed, import it now as SVML. ~\.conda\envs\NewPy38\lib\site-packages\numba\__init__.py in _ensure_critical_deps(); 138 raise ImportError(""Numba needs NumPy 1.18 or greater""); 139 elif numpy_version > (1, 21):; --> 140 raise ImportError(""Numba needs NumPy 1.21 or less""); 141 ; 142 try:. ImportError: Numba needs NumPy 1.21 or less; ```; Step5: I do` !pip uninstall Numpy`, then; ```python; !pip install numpy; Requirement already satisfied: numpy in c:\users\hyjfo\.conda\envs\newpy38\lib\site-packages (1.21.5). import numpy as np; import pandas as pd; imp",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841
https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841:6812,Testability,test,tests,6812,"er(); sc.set_figure_params(dpi=100, dpi_save=600). ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_14912/1710492625.py in <module>; 1 import numpy as np; 2 import pandas as pd; ----> 3 import scanpy as sc; 4 import scanpy.external as sce; 5 import scipy. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\__init__.py in <module>; 4 ; 5 if not within_flit(): # see function docstring on why this is there; ----> 6 from ._utils import check_versions; 7 ; 8 check_versions(). ~\.conda\envs\NewPy38\lib\site-packages\scanpy\_utils\__init__.py in <module>; 27 from .. import logging as logg; 28 ; ---> 29 from .compute.is_constant import is_constant; 30 ; 31 . ~\.conda\envs\NewPy38\lib\site-packages\scanpy\_utils\compute\is_constant.py in <module>; 3 ; 4 import numpy as np; ----> 5 from numba import njit; 6 from scipy import sparse; 7 . ~\.conda\envs\NewPy38\lib\site-packages\numba\__init__.py in <module>; 198 ; 199 _ensure_llvm(); --> 200 _ensure_critical_deps(); 201 ; 202 # we know llvmlite is working as the above tests passed, import it now as SVML. ~\.conda\envs\NewPy38\lib\site-packages\numba\__init__.py in _ensure_critical_deps(); 138 raise ImportError(""Numba needs NumPy 1.18 or greater""); 139 elif numpy_version > (1, 21):; --> 140 raise ImportError(""Numba needs NumPy 1.21 or less""); 141 ; 142 try:. ImportError: Numba needs NumPy 1.21 or less; ```; Step5: I do` !pip uninstall Numpy`, then; ```python; !pip install numpy; Requirement already satisfied: numpy in c:\users\hyjfo\.conda\envs\newpy38\lib\site-packages (1.21.5). import numpy as np; import pandas as pd; import scanpy as sc; import scanpy.external as sce; import scipy; sc.settings.verbosity = 3; sc.logging.print_header(); sc.set_figure_params(dpi=100, dpi_save=600). AttributeError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_8308/1710492625.py in <module>; 1 import numpy as np; ----> 2 import pandas as pd; 3 import scanpy as sc; 4 import scanpy.external as sce; 5 impor",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841
https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841:7470,Testability,log,logging,7470,"\site-packages\scanpy\_utils\compute\is_constant.py in <module>; 3 ; 4 import numpy as np; ----> 5 from numba import njit; 6 from scipy import sparse; 7 . ~\.conda\envs\NewPy38\lib\site-packages\numba\__init__.py in <module>; 198 ; 199 _ensure_llvm(); --> 200 _ensure_critical_deps(); 201 ; 202 # we know llvmlite is working as the above tests passed, import it now as SVML. ~\.conda\envs\NewPy38\lib\site-packages\numba\__init__.py in _ensure_critical_deps(); 138 raise ImportError(""Numba needs NumPy 1.18 or greater""); 139 elif numpy_version > (1, 21):; --> 140 raise ImportError(""Numba needs NumPy 1.21 or less""); 141 ; 142 try:. ImportError: Numba needs NumPy 1.21 or less; ```; Step5: I do` !pip uninstall Numpy`, then; ```python; !pip install numpy; Requirement already satisfied: numpy in c:\users\hyjfo\.conda\envs\newpy38\lib\site-packages (1.21.5). import numpy as np; import pandas as pd; import scanpy as sc; import scanpy.external as sce; import scipy; sc.settings.verbosity = 3; sc.logging.print_header(); sc.set_figure_params(dpi=100, dpi_save=600). AttributeError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_8308/1710492625.py in <module>; 1 import numpy as np; ----> 2 import pandas as pd; 3 import scanpy as sc; 4 import scanpy.external as sce; 5 import scipy. ~\.conda\envs\NewPy38\lib\site-packages\pandas\__init__.py in <module>; 20 ; 21 # numpy compat; ---> 22 from pandas.compat import (; 23 np_version_under1p18 as _np_version_under1p18,; 24 is_numpy_dev as _is_numpy_dev,. ~\.conda\envs\NewPy38\lib\site-packages\pandas\compat\__init__.py in <module>; 12 import warnings; 13 ; ---> 14 from pandas._typing import F; 15 from pandas.compat.numpy import (; 16 is_numpy_dev,. ~\.conda\envs\NewPy38\lib\site-packages\pandas\_typing.py in <module>; 82 # array-like; 83 ; ---> 84 ArrayLike = Union[""ExtensionArray"", np.ndarray]; 85 AnyArrayLike = Union[ArrayLike, ""Index"", ""Series""]; 86 . AttributeError: module 'numpy' has no attribute 'ndarray'; ```; It looks",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841
https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841:474,Usability,learn,learn-,474,"Hello @Koncopd ,; Thanks for the response!. Step 1: I created a fresh new environment (py3.8.12); ```python; !pip install scanpy[leiden]. Successfully installed anndata-0.7.8 cycler-0.11.0 fonttools-4.28.5 h5py-3.6.0 igraph-0.9.9 joblib-1.1.0 kiwisolver-1.3.2 leidenalg-0.8.8 llvmlite-0.38.0 matplotlib-3.5.1 natsort-8.0.2 networkx-2.6.3 numba-0.55.0 numexpr-2.8.1 numpy-1.21.5 pandas-1.3.5 patsy-0.5.2 pillow-9.0.0 pynndescent-0.5.5 python-igraph-0.9.9 scanpy-1.8.2 scikit-learn-1.0.2 scipy-1.7.3 seaborn-0.11.2 sinfo-0.3.4 statsmodels-0.13.1 stdlib-list-0.8.0 tables-3.7.0 texttable-1.6.4 threadpoolctl-3.0.0 tqdm-4.62.3 umap-learn-0.5.2 xlrd-1.2.0. import numpy as np; import pandas as pd; import scanpy as sc; import scanpy.external as sce; import scipy; sc.settings.verbosity = 3; sc.logging.print_header(); sc.set_figure_params(dpi=100, dpi_save=600). ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_8256/1710492625.py in <module>; 1 import numpy as np; 2 import pandas as pd; ----> 3 import scanpy as sc; 4 import scanpy.external as sce; 5 import scipy. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\__init__.py in <module>; 12 # (start with settings as several tools are using it); 13 from ._settings import settings, Verbosity; ---> 14 from . import tools as tl; 15 from . import preprocessing as pp; 16 from . import plotting as pl. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\tools\__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\tools\_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\readwrite.py in <module>; 8 import pandas as pd; 9 from ma",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841
https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841:628,Usability,learn,learn-,628,"Hello @Koncopd ,; Thanks for the response!. Step 1: I created a fresh new environment (py3.8.12); ```python; !pip install scanpy[leiden]. Successfully installed anndata-0.7.8 cycler-0.11.0 fonttools-4.28.5 h5py-3.6.0 igraph-0.9.9 joblib-1.1.0 kiwisolver-1.3.2 leidenalg-0.8.8 llvmlite-0.38.0 matplotlib-3.5.1 natsort-8.0.2 networkx-2.6.3 numba-0.55.0 numexpr-2.8.1 numpy-1.21.5 pandas-1.3.5 patsy-0.5.2 pillow-9.0.0 pynndescent-0.5.5 python-igraph-0.9.9 scanpy-1.8.2 scikit-learn-1.0.2 scipy-1.7.3 seaborn-0.11.2 sinfo-0.3.4 statsmodels-0.13.1 stdlib-list-0.8.0 tables-3.7.0 texttable-1.6.4 threadpoolctl-3.0.0 tqdm-4.62.3 umap-learn-0.5.2 xlrd-1.2.0. import numpy as np; import pandas as pd; import scanpy as sc; import scanpy.external as sce; import scipy; sc.settings.verbosity = 3; sc.logging.print_header(); sc.set_figure_params(dpi=100, dpi_save=600). ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_8256/1710492625.py in <module>; 1 import numpy as np; 2 import pandas as pd; ----> 3 import scanpy as sc; 4 import scanpy.external as sce; 5 import scipy. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\__init__.py in <module>; 12 # (start with settings as several tools are using it); 13 from ._settings import settings, Verbosity; ---> 14 from . import tools as tl; 15 from . import preprocessing as pp; 16 from . import plotting as pl. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\tools\__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\tools\_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\readwrite.py in <module>; 8 import pandas as pd; 9 from ma",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841
https://github.com/scverse/scanpy/issues/2108#issuecomment-1013006816:163,Availability,error,error,163,"#2064 should do it. There seems to be some issues with recent builds of pytables. I've been having periodic trouble installing it, but had trouble reproducing the error when I tried. IIRC, the errors made me think it was some incompatibility between new versions of `pip`/ `setuptools` and old builds of `pytables` – but that wasn't on windows. @MxMstrmn has also mentioned seeing some issues with pytables installing on windows.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1013006816
https://github.com/scverse/scanpy/issues/2108#issuecomment-1013006816:193,Availability,error,errors,193,"#2064 should do it. There seems to be some issues with recent builds of pytables. I've been having periodic trouble installing it, but had trouble reproducing the error when I tried. IIRC, the errors made me think it was some incompatibility between new versions of `pip`/ `setuptools` and old builds of `pytables` – but that wasn't on windows. @MxMstrmn has also mentioned seeing some issues with pytables installing on windows.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1013006816
https://github.com/scverse/scanpy/issues/2108#issuecomment-1013006816:116,Deployability,install,installing,116,"#2064 should do it. There seems to be some issues with recent builds of pytables. I've been having periodic trouble installing it, but had trouble reproducing the error when I tried. IIRC, the errors made me think it was some incompatibility between new versions of `pip`/ `setuptools` and old builds of `pytables` – but that wasn't on windows. @MxMstrmn has also mentioned seeing some issues with pytables installing on windows.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1013006816
https://github.com/scverse/scanpy/issues/2108#issuecomment-1013006816:407,Deployability,install,installing,407,"#2064 should do it. There seems to be some issues with recent builds of pytables. I've been having periodic trouble installing it, but had trouble reproducing the error when I tried. IIRC, the errors made me think it was some incompatibility between new versions of `pip`/ `setuptools` and old builds of `pytables` – but that wasn't on windows. @MxMstrmn has also mentioned seeing some issues with pytables installing on windows.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1013006816
https://github.com/scverse/scanpy/issues/2108#issuecomment-1013450589:112,Deployability,install,install,112,"@hyjforesight no, that is a mess.; Could you try please 3 things:. 1. create fresh environment with python 3.8, install only pytables; `conda install pytables`; then run python and check; `import tables`; 2. create fresh environment with python 3.8, install only pytables from conda-forge; `conda install -c conda-forge pytables`; then run python and check; `import tables`; 3. create fresh environment with python 3.8 and install just scanpy (and nothing else); `conda install -c conda-forge scanpy`; then run python and check; `import scanpy`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1013450589
https://github.com/scverse/scanpy/issues/2108#issuecomment-1013450589:142,Deployability,install,install,142,"@hyjforesight no, that is a mess.; Could you try please 3 things:. 1. create fresh environment with python 3.8, install only pytables; `conda install pytables`; then run python and check; `import tables`; 2. create fresh environment with python 3.8, install only pytables from conda-forge; `conda install -c conda-forge pytables`; then run python and check; `import tables`; 3. create fresh environment with python 3.8 and install just scanpy (and nothing else); `conda install -c conda-forge scanpy`; then run python and check; `import scanpy`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1013450589
https://github.com/scverse/scanpy/issues/2108#issuecomment-1013450589:250,Deployability,install,install,250,"@hyjforesight no, that is a mess.; Could you try please 3 things:. 1. create fresh environment with python 3.8, install only pytables; `conda install pytables`; then run python and check; `import tables`; 2. create fresh environment with python 3.8, install only pytables from conda-forge; `conda install -c conda-forge pytables`; then run python and check; `import tables`; 3. create fresh environment with python 3.8 and install just scanpy (and nothing else); `conda install -c conda-forge scanpy`; then run python and check; `import scanpy`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1013450589
https://github.com/scverse/scanpy/issues/2108#issuecomment-1013450589:297,Deployability,install,install,297,"@hyjforesight no, that is a mess.; Could you try please 3 things:. 1. create fresh environment with python 3.8, install only pytables; `conda install pytables`; then run python and check; `import tables`; 2. create fresh environment with python 3.8, install only pytables from conda-forge; `conda install -c conda-forge pytables`; then run python and check; `import tables`; 3. create fresh environment with python 3.8 and install just scanpy (and nothing else); `conda install -c conda-forge scanpy`; then run python and check; `import scanpy`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1013450589
https://github.com/scverse/scanpy/issues/2108#issuecomment-1013450589:423,Deployability,install,install,423,"@hyjforesight no, that is a mess.; Could you try please 3 things:. 1. create fresh environment with python 3.8, install only pytables; `conda install pytables`; then run python and check; `import tables`; 2. create fresh environment with python 3.8, install only pytables from conda-forge; `conda install -c conda-forge pytables`; then run python and check; `import tables`; 3. create fresh environment with python 3.8 and install just scanpy (and nothing else); `conda install -c conda-forge scanpy`; then run python and check; `import scanpy`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1013450589
https://github.com/scverse/scanpy/issues/2108#issuecomment-1013450589:470,Deployability,install,install,470,"@hyjforesight no, that is a mess.; Could you try please 3 things:. 1. create fresh environment with python 3.8, install only pytables; `conda install pytables`; then run python and check; `import tables`; 2. create fresh environment with python 3.8, install only pytables from conda-forge; `conda install -c conda-forge pytables`; then run python and check; `import tables`; 3. create fresh environment with python 3.8 and install just scanpy (and nothing else); `conda install -c conda-forge scanpy`; then run python and check; `import scanpy`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1013450589
https://github.com/scverse/scanpy/issues/2108#issuecomment-1013511702:64,Deployability,install,install,64,"Hello @Koncopd ,; 1. New py3.8.12 environment; ```python; conda install pytables; import tables # pass; ```; 2. New py3.8.12 environment; ```python; conda install pytables; import tables # pass; ```; 3. New py3.8.12 environment; ```python; conda install -c conda-forge scanpy; import scanpy # pass; ```; I can run the Scanpy pipeline now. However, I'm wondering whether your team did some slight changes for pca, neighboring, leiden, umap functions (not big enough to introduce a new release) inside of Scanpy v1.8.2.; Because now I rerun my data and I get the UMAP like below,; ![image](https://user-images.githubusercontent.com/75048821/149594142-fcd6b1d1-7b9a-4713-9850-8b2d86a1ff61.png). but it looks like this one month ago, run by the same version of Scanpy v1.8.2 with the same coding.; ![image](https://user-images.githubusercontent.com/75048821/149593173-fc6caf3d-09e4-4b92-89ad-8cdfc1173f3c.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1013511702
https://github.com/scverse/scanpy/issues/2108#issuecomment-1013511702:155,Deployability,install,install,155,"Hello @Koncopd ,; 1. New py3.8.12 environment; ```python; conda install pytables; import tables # pass; ```; 2. New py3.8.12 environment; ```python; conda install pytables; import tables # pass; ```; 3. New py3.8.12 environment; ```python; conda install -c conda-forge scanpy; import scanpy # pass; ```; I can run the Scanpy pipeline now. However, I'm wondering whether your team did some slight changes for pca, neighboring, leiden, umap functions (not big enough to introduce a new release) inside of Scanpy v1.8.2.; Because now I rerun my data and I get the UMAP like below,; ![image](https://user-images.githubusercontent.com/75048821/149594142-fcd6b1d1-7b9a-4713-9850-8b2d86a1ff61.png). but it looks like this one month ago, run by the same version of Scanpy v1.8.2 with the same coding.; ![image](https://user-images.githubusercontent.com/75048821/149593173-fc6caf3d-09e4-4b92-89ad-8cdfc1173f3c.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1013511702
https://github.com/scverse/scanpy/issues/2108#issuecomment-1013511702:246,Deployability,install,install,246,"Hello @Koncopd ,; 1. New py3.8.12 environment; ```python; conda install pytables; import tables # pass; ```; 2. New py3.8.12 environment; ```python; conda install pytables; import tables # pass; ```; 3. New py3.8.12 environment; ```python; conda install -c conda-forge scanpy; import scanpy # pass; ```; I can run the Scanpy pipeline now. However, I'm wondering whether your team did some slight changes for pca, neighboring, leiden, umap functions (not big enough to introduce a new release) inside of Scanpy v1.8.2.; Because now I rerun my data and I get the UMAP like below,; ![image](https://user-images.githubusercontent.com/75048821/149594142-fcd6b1d1-7b9a-4713-9850-8b2d86a1ff61.png). but it looks like this one month ago, run by the same version of Scanpy v1.8.2 with the same coding.; ![image](https://user-images.githubusercontent.com/75048821/149593173-fc6caf3d-09e4-4b92-89ad-8cdfc1173f3c.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1013511702
https://github.com/scverse/scanpy/issues/2108#issuecomment-1013511702:325,Deployability,pipeline,pipeline,325,"Hello @Koncopd ,; 1. New py3.8.12 environment; ```python; conda install pytables; import tables # pass; ```; 2. New py3.8.12 environment; ```python; conda install pytables; import tables # pass; ```; 3. New py3.8.12 environment; ```python; conda install -c conda-forge scanpy; import scanpy # pass; ```; I can run the Scanpy pipeline now. However, I'm wondering whether your team did some slight changes for pca, neighboring, leiden, umap functions (not big enough to introduce a new release) inside of Scanpy v1.8.2.; Because now I rerun my data and I get the UMAP like below,; ![image](https://user-images.githubusercontent.com/75048821/149594142-fcd6b1d1-7b9a-4713-9850-8b2d86a1ff61.png). but it looks like this one month ago, run by the same version of Scanpy v1.8.2 with the same coding.; ![image](https://user-images.githubusercontent.com/75048821/149593173-fc6caf3d-09e4-4b92-89ad-8cdfc1173f3c.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1013511702
https://github.com/scverse/scanpy/issues/2108#issuecomment-1013511702:484,Deployability,release,release,484,"Hello @Koncopd ,; 1. New py3.8.12 environment; ```python; conda install pytables; import tables # pass; ```; 2. New py3.8.12 environment; ```python; conda install pytables; import tables # pass; ```; 3. New py3.8.12 environment; ```python; conda install -c conda-forge scanpy; import scanpy # pass; ```; I can run the Scanpy pipeline now. However, I'm wondering whether your team did some slight changes for pca, neighboring, leiden, umap functions (not big enough to introduce a new release) inside of Scanpy v1.8.2.; Because now I rerun my data and I get the UMAP like below,; ![image](https://user-images.githubusercontent.com/75048821/149594142-fcd6b1d1-7b9a-4713-9850-8b2d86a1ff61.png). but it looks like this one month ago, run by the same version of Scanpy v1.8.2 with the same coding.; ![image](https://user-images.githubusercontent.com/75048821/149593173-fc6caf3d-09e4-4b92-89ad-8cdfc1173f3c.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1013511702
https://github.com/scverse/scanpy/issues/2108#issuecomment-1013605391:45,Deployability,Install,Installing,45,"pytables 3.7.0 is incompatible with Windows. Installing pytables 3.6.1 solves the problem.; For the UMAP, it's quite weird. Whether I restart anaconda between installing individual packages plays the trick.; It should be done in this way.; ```python; !pip install tables==3.6.1. !pip install scanpy[leiden]; !pip install -U scvelo; !pip install tqdm; !pip install ipywidgets; !pip install cellrank. close Edge. run anaconda powershell prompt (anaconda3) as admin; conda activate HYJ_py38; conda install -y -c anaconda cytoolz; pip install pyscenic. restart anaconda3. !pip install adjustText openpyxl; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1013605391
https://github.com/scverse/scanpy/issues/2108#issuecomment-1013605391:159,Deployability,install,installing,159,"pytables 3.7.0 is incompatible with Windows. Installing pytables 3.6.1 solves the problem.; For the UMAP, it's quite weird. Whether I restart anaconda between installing individual packages plays the trick.; It should be done in this way.; ```python; !pip install tables==3.6.1. !pip install scanpy[leiden]; !pip install -U scvelo; !pip install tqdm; !pip install ipywidgets; !pip install cellrank. close Edge. run anaconda powershell prompt (anaconda3) as admin; conda activate HYJ_py38; conda install -y -c anaconda cytoolz; pip install pyscenic. restart anaconda3. !pip install adjustText openpyxl; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1013605391
https://github.com/scverse/scanpy/issues/2108#issuecomment-1013605391:256,Deployability,install,install,256,"pytables 3.7.0 is incompatible with Windows. Installing pytables 3.6.1 solves the problem.; For the UMAP, it's quite weird. Whether I restart anaconda between installing individual packages plays the trick.; It should be done in this way.; ```python; !pip install tables==3.6.1. !pip install scanpy[leiden]; !pip install -U scvelo; !pip install tqdm; !pip install ipywidgets; !pip install cellrank. close Edge. run anaconda powershell prompt (anaconda3) as admin; conda activate HYJ_py38; conda install -y -c anaconda cytoolz; pip install pyscenic. restart anaconda3. !pip install adjustText openpyxl; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1013605391
https://github.com/scverse/scanpy/issues/2108#issuecomment-1013605391:284,Deployability,install,install,284,"pytables 3.7.0 is incompatible with Windows. Installing pytables 3.6.1 solves the problem.; For the UMAP, it's quite weird. Whether I restart anaconda between installing individual packages plays the trick.; It should be done in this way.; ```python; !pip install tables==3.6.1. !pip install scanpy[leiden]; !pip install -U scvelo; !pip install tqdm; !pip install ipywidgets; !pip install cellrank. close Edge. run anaconda powershell prompt (anaconda3) as admin; conda activate HYJ_py38; conda install -y -c anaconda cytoolz; pip install pyscenic. restart anaconda3. !pip install adjustText openpyxl; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1013605391
https://github.com/scverse/scanpy/issues/2108#issuecomment-1013605391:313,Deployability,install,install,313,"pytables 3.7.0 is incompatible with Windows. Installing pytables 3.6.1 solves the problem.; For the UMAP, it's quite weird. Whether I restart anaconda between installing individual packages plays the trick.; It should be done in this way.; ```python; !pip install tables==3.6.1. !pip install scanpy[leiden]; !pip install -U scvelo; !pip install tqdm; !pip install ipywidgets; !pip install cellrank. close Edge. run anaconda powershell prompt (anaconda3) as admin; conda activate HYJ_py38; conda install -y -c anaconda cytoolz; pip install pyscenic. restart anaconda3. !pip install adjustText openpyxl; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1013605391
https://github.com/scverse/scanpy/issues/2108#issuecomment-1013605391:337,Deployability,install,install,337,"pytables 3.7.0 is incompatible with Windows. Installing pytables 3.6.1 solves the problem.; For the UMAP, it's quite weird. Whether I restart anaconda between installing individual packages plays the trick.; It should be done in this way.; ```python; !pip install tables==3.6.1. !pip install scanpy[leiden]; !pip install -U scvelo; !pip install tqdm; !pip install ipywidgets; !pip install cellrank. close Edge. run anaconda powershell prompt (anaconda3) as admin; conda activate HYJ_py38; conda install -y -c anaconda cytoolz; pip install pyscenic. restart anaconda3. !pip install adjustText openpyxl; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1013605391
https://github.com/scverse/scanpy/issues/2108#issuecomment-1013605391:356,Deployability,install,install,356,"pytables 3.7.0 is incompatible with Windows. Installing pytables 3.6.1 solves the problem.; For the UMAP, it's quite weird. Whether I restart anaconda between installing individual packages plays the trick.; It should be done in this way.; ```python; !pip install tables==3.6.1. !pip install scanpy[leiden]; !pip install -U scvelo; !pip install tqdm; !pip install ipywidgets; !pip install cellrank. close Edge. run anaconda powershell prompt (anaconda3) as admin; conda activate HYJ_py38; conda install -y -c anaconda cytoolz; pip install pyscenic. restart anaconda3. !pip install adjustText openpyxl; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1013605391
https://github.com/scverse/scanpy/issues/2108#issuecomment-1013605391:381,Deployability,install,install,381,"pytables 3.7.0 is incompatible with Windows. Installing pytables 3.6.1 solves the problem.; For the UMAP, it's quite weird. Whether I restart anaconda between installing individual packages plays the trick.; It should be done in this way.; ```python; !pip install tables==3.6.1. !pip install scanpy[leiden]; !pip install -U scvelo; !pip install tqdm; !pip install ipywidgets; !pip install cellrank. close Edge. run anaconda powershell prompt (anaconda3) as admin; conda activate HYJ_py38; conda install -y -c anaconda cytoolz; pip install pyscenic. restart anaconda3. !pip install adjustText openpyxl; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1013605391
https://github.com/scverse/scanpy/issues/2108#issuecomment-1013605391:495,Deployability,install,install,495,"pytables 3.7.0 is incompatible with Windows. Installing pytables 3.6.1 solves the problem.; For the UMAP, it's quite weird. Whether I restart anaconda between installing individual packages plays the trick.; It should be done in this way.; ```python; !pip install tables==3.6.1. !pip install scanpy[leiden]; !pip install -U scvelo; !pip install tqdm; !pip install ipywidgets; !pip install cellrank. close Edge. run anaconda powershell prompt (anaconda3) as admin; conda activate HYJ_py38; conda install -y -c anaconda cytoolz; pip install pyscenic. restart anaconda3. !pip install adjustText openpyxl; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1013605391
https://github.com/scverse/scanpy/issues/2108#issuecomment-1013605391:531,Deployability,install,install,531,"pytables 3.7.0 is incompatible with Windows. Installing pytables 3.6.1 solves the problem.; For the UMAP, it's quite weird. Whether I restart anaconda between installing individual packages plays the trick.; It should be done in this way.; ```python; !pip install tables==3.6.1. !pip install scanpy[leiden]; !pip install -U scvelo; !pip install tqdm; !pip install ipywidgets; !pip install cellrank. close Edge. run anaconda powershell prompt (anaconda3) as admin; conda activate HYJ_py38; conda install -y -c anaconda cytoolz; pip install pyscenic. restart anaconda3. !pip install adjustText openpyxl; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1013605391
https://github.com/scverse/scanpy/issues/2108#issuecomment-1013605391:573,Deployability,install,install,573,"pytables 3.7.0 is incompatible with Windows. Installing pytables 3.6.1 solves the problem.; For the UMAP, it's quite weird. Whether I restart anaconda between installing individual packages plays the trick.; It should be done in this way.; ```python; !pip install tables==3.6.1. !pip install scanpy[leiden]; !pip install -U scvelo; !pip install tqdm; !pip install ipywidgets; !pip install cellrank. close Edge. run anaconda powershell prompt (anaconda3) as admin; conda activate HYJ_py38; conda install -y -c anaconda cytoolz; pip install pyscenic. restart anaconda3. !pip install adjustText openpyxl; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1013605391
https://github.com/scverse/scanpy/issues/2108#issuecomment-1013605391:424,Energy Efficiency,power,powershell,424,"pytables 3.7.0 is incompatible with Windows. Installing pytables 3.6.1 solves the problem.; For the UMAP, it's quite weird. Whether I restart anaconda between installing individual packages plays the trick.; It should be done in this way.; ```python; !pip install tables==3.6.1. !pip install scanpy[leiden]; !pip install -U scvelo; !pip install tqdm; !pip install ipywidgets; !pip install cellrank. close Edge. run anaconda powershell prompt (anaconda3) as admin; conda activate HYJ_py38; conda install -y -c anaconda cytoolz; pip install pyscenic. restart anaconda3. !pip install adjustText openpyxl; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1013605391
https://github.com/scverse/scanpy/issues/2110#issuecomment-1013526622:79,Testability,log,logFC,79,"Hello @LuckyMD ; Thanks for the response!; Could you please also check why the logFC becomes negative and disappear for the marker genes of clusters? https://github.com/theislab/scanpy/issues/2057; Thanks!; Best,; YJ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2110#issuecomment-1013526622
https://github.com/scverse/scanpy/issues/2110#issuecomment-1103470609:78,Testability,log,logFC,78,"> Hello @LuckyMD Thanks for the response! Could you please also check why the logFC becomes negative and disappear for the marker genes of clusters? #2057 Thanks! Best, YJ. Because adata was regressed, gene expression will become negative, cannot be loged.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2110#issuecomment-1103470609
https://github.com/scverse/scanpy/issues/2110#issuecomment-1103470609:250,Testability,log,loged,250,"> Hello @LuckyMD Thanks for the response! Could you please also check why the logFC becomes negative and disappear for the marker genes of clusters? #2057 Thanks! Best, YJ. Because adata was regressed, gene expression will become negative, cannot be loged.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2110#issuecomment-1103470609
https://github.com/scverse/scanpy/issues/2110#issuecomment-1103608129:67,Testability,log,log,67,"If you have to regress out covariates, maybe you could do it after log transformation? I'm not 100% sure about this approach either though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2110#issuecomment-1103608129
https://github.com/scverse/scanpy/issues/2112#issuecomment-1015716949:1067,Usability,simpl,simplified,1067,"You would like the legend on the right to have both the short and long names, while the ""on data"" annotation would only have the short names – right?. I'm not sure I can think of a great way to do this without making the process complicated. It may be easier for you to add the text labels to the plot yourself. Here is some code for adding the labels with `""adjustText""` (which needs some parameter fiddling to look nice) #1513. ```python; def gen_mpl_labels(; adata, groupby, exclude=(), ax=None, adjust_kwargs=None, text_kwargs=None; ):; if adjust_kwargs is None:; adjust_kwargs = {""text_from_points"": False}; if text_kwargs is None:; text_kwargs = {}. medians = {}. for g, g_idx in adata.obs.groupby(groupby).indices.items():; if g in exclude:; continue; medians[g] = np.median(adata.obsm[""X_umap""][g_idx], axis=0). if ax is None:; texts = [; plt.text(x=x, y=y, s=k, **text_kwargs) for k, (x, y) in medians.items(); ]; else:; texts = [ax.text(x=x, y=y, s=k, **text_kwargs) for k, (x, y) in medians.items()]. adjust_text(texts, **adjust_kwargs); ```. which can be simplified if you're alright with just plotting on the medians. I personally think interactivity and hover-over becomes quite useful at this point, though that can be difficult to scale and share.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2112#issuecomment-1015716949
https://github.com/scverse/scanpy/issues/2112#issuecomment-1023417880:230,Usability,simpl,simply,230,"I meant apart from the long label at ""right margin"", basically adding a number to each label and display that number ""on data"". Right margin would look like this:; 1. Cell type A; 2. Cell type B; 3. Cell type C. And the UMAP will simply show 1, 2, 3 ... on the plot. If the numbers could be automatically generated when one runs `sc.pl.umap`, and added to the plot, that would be awesome. The issue is adding the text label on the plot make them overlap with each other, but the corresponding numbers would do just fine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2112#issuecomment-1023417880
https://github.com/scverse/scanpy/issues/2114#issuecomment-1016078802:2,Deployability,install,installed,2,"I installed these packages on PC1, UMAP still not consistent with others.; <html xmlns:v=""urn:schemas-microsoft-com:vml""; xmlns:o=""urn:schemas-microsoft-com:office:office""; xmlns:x=""urn:schemas-microsoft-com:office:excel""; xmlns=""http://www.w3.org/TR/REC-html40"">. <head>. <meta name=ProgId content=Excel.Sheet>; <meta name=Generator content=""Microsoft Excel 15"">; <link id=Main-File rel=Main-File; href=""file:///C:/Users/hyjfo/AppData/Local/Temp/msohtmlclip1/01/clip.htm"">; <link rel=File-List; href=""file:///C:/Users/hyjfo/AppData/Local/Temp/msohtmlclip1/01/clip_filelist.xml"">; <style>; <!--table; 	{mso-displayed-decimal-separator:""\."";; 	mso-displayed-thousand-separator:""\,"";}; @page; 	{margin:.75in .7in .75in .7in;; 	mso-header-margin:.3in;; 	mso-footer-margin:.3in;}; tr; 	{mso-height-source:auto;; 	mso-ruby-visibility:none;}; col; 	{mso-width-source:auto;; 	mso-ruby-visibility:none;}; br; 	{mso-data-placement:same-cell;}; td; 	{padding-top:1px;; 	padding-right:1px;; 	padding-left:1px;; 	mso-ignore:padding;; 	color:black;; 	font-size:11.0pt;; 	font-weight:400;; 	font-style:normal;; 	text-decoration:none;; 	font-family:等线;; 	mso-generic-font-family:auto;; 	mso-font-charset:134;; 	mso-number-format:General;; 	text-align:general;; 	vertical-align:middle;; 	border:none;; 	mso-background-source:auto;; 	mso-pattern:auto;; 	mso-protection:locked visible;; 	white-space:nowrap;; 	mso-rotate:0;}; .xl65; 	{font-size:10.0pt;; 	font-family:""Var\(--jp-code-font-family\)"", sans-serif;; 	mso-font-charset:0;; 	text-align:center;}; .xl66; 	{text-align:center;}; .xl67; 	{color:red;; 	font-size:10.0pt;; 	font-weight:700;; 	font-family:""Var\(--jp-code-font-family\)"", sans-serif;; 	mso-font-charset:0;; 	text-align:center;}; .xl68; 	{color:red;; 	font-weight:700;; 	text-align:center;}; .xl69; 	{color:red;; 	font-size:10.0pt;; 	font-weight:700;; 	font-family:""Var\(--jp-code-font-family\)"", sans-serif;; 	mso-font-charset:0;; 	text-align:center;; 	background:yellow;; 	mso-pattern:black none;}; ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2114#issuecomment-1016078802
https://github.com/scverse/scanpy/issues/2114#issuecomment-1016440947:93,Availability,down,down,93,"Do you know which step of the script the results start differing? That would help in cutting down where the issue is occurring. If not, it would be useful if you could share objects with different results from the various machines. You could use the `sc.datasets.pbmc3k` for this (if your data is private). Would you also be able to share the output of `numba -s` from each of these environments? Different CPUs can give different results from numba code due to the features available. Ping resident windows expert @Koncopd",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2114#issuecomment-1016440947
https://github.com/scverse/scanpy/issues/2114#issuecomment-1016440947:475,Availability,avail,available,475,"Do you know which step of the script the results start differing? That would help in cutting down where the issue is occurring. If not, it would be useful if you could share objects with different results from the various machines. You could use the `sc.datasets.pbmc3k` for this (if your data is private). Would you also be able to share the output of `numba -s` from each of these environments? Different CPUs can give different results from numba code due to the features available. Ping resident windows expert @Koncopd",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2114#issuecomment-1016440947
https://github.com/scverse/scanpy/issues/2114#issuecomment-1016440947:486,Availability,Ping,Ping,486,"Do you know which step of the script the results start differing? That would help in cutting down where the issue is occurring. If not, it would be useful if you could share objects with different results from the various machines. You could use the `sc.datasets.pbmc3k` for this (if your data is private). Would you also be able to share the output of `numba -s` from each of these environments? Different CPUs can give different results from numba code due to the features available. Ping resident windows expert @Koncopd",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2114#issuecomment-1016440947
https://github.com/scverse/scanpy/issues/2114#issuecomment-1016712689:345,Energy Efficiency,reduce,reduce,345,"Most of the time? There is an issue with fairly old CPUs (no AVX2, so like >5 years), but that was the last I saw. My guess is that there are more reproducibility issues on windows than linux, likely because it is tested less. I would like to confirm that it's UMAP and not the PCA though. After that could be worth checking the threading (e.g. reduce to one thread, though I thought UMAP should be as reproducible as possible w.r.t. threading by default).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2114#issuecomment-1016712689
https://github.com/scverse/scanpy/issues/2114#issuecomment-1016712689:214,Testability,test,tested,214,"Most of the time? There is an issue with fairly old CPUs (no AVX2, so like >5 years), but that was the last I saw. My guess is that there are more reproducibility issues on windows than linux, likely because it is tested less. I would like to confirm that it's UMAP and not the PCA though. After that could be worth checking the threading (e.g. reduce to one thread, though I thought UMAP should be as reproducible as possible w.r.t. threading by default).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2114#issuecomment-1016712689
https://github.com/scverse/scanpy/issues/2114#issuecomment-1020616654:53,Availability,down,download,53,"Hello @ivirshup ,; Can you upzip these files? Please download all 7 files (.zip and .z01-.z06), and use winzip, winrar, 7-zip or bandizip to unzip the Downloads.zip file. It includes three h5ad files. I also share these three h5ad files into your gmail. I use `adata.write('C:/Users/Park_Lab/Documents/PC1.h5ad', compression='gzip')` to write these files.; And use `adata = sc.read('C:/Users/Park_Lab/Documents/PC1.h5ad')` to read these files. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2114#issuecomment-1020616654
https://github.com/scverse/scanpy/issues/2114#issuecomment-1020616654:151,Availability,Down,Downloads,151,"Hello @ivirshup ,; Can you upzip these files? Please download all 7 files (.zip and .z01-.z06), and use winzip, winrar, 7-zip or bandizip to unzip the Downloads.zip file. It includes three h5ad files. I also share these three h5ad files into your gmail. I use `adata.write('C:/Users/Park_Lab/Documents/PC1.h5ad', compression='gzip')` to write these files.; And use `adata = sc.read('C:/Users/Park_Lab/Documents/PC1.h5ad')` to read these files. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2114#issuecomment-1020616654
https://github.com/scverse/scanpy/issues/2114#issuecomment-1021048765:81,Testability,assert,assert,81,"## `X`. So, the first and third result have the same values of `X`. . ```python; assert np.array_equal(pc1.X, pc3.X); ```. The second is only slightly different:. ```python; diff = pc2.X - pc1.X; diff[diff != 0]; ```. ```; array([7.450581e-09], dtype=float32); ```. This might be adjustable by setting ""regress out"" to a fixed number of jobs. ## PCA. The results of the PCA differ more significantly, but here you should just be calling scikit-learn's implementation. Could you try calling that directly and letting us know the results?. E.g. ```python; from sklearn.decomposition import PCA. pca = PCA(n_components=50, solver=""arpack"", random_state=0); result = pca.fit_transform(adata.X); ```. If this doesn't give consistent results on your machines, the issue is upstream in scikit-learn. If you need reproducibility now, I would suggest switching out the solver for the PCA and/ or using 64 bit values for `X`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2114#issuecomment-1021048765
https://github.com/scverse/scanpy/issues/2114#issuecomment-1021048765:444,Usability,learn,learn,444,"## `X`. So, the first and third result have the same values of `X`. . ```python; assert np.array_equal(pc1.X, pc3.X); ```. The second is only slightly different:. ```python; diff = pc2.X - pc1.X; diff[diff != 0]; ```. ```; array([7.450581e-09], dtype=float32); ```. This might be adjustable by setting ""regress out"" to a fixed number of jobs. ## PCA. The results of the PCA differ more significantly, but here you should just be calling scikit-learn's implementation. Could you try calling that directly and letting us know the results?. E.g. ```python; from sklearn.decomposition import PCA. pca = PCA(n_components=50, solver=""arpack"", random_state=0); result = pca.fit_transform(adata.X); ```. If this doesn't give consistent results on your machines, the issue is upstream in scikit-learn. If you need reproducibility now, I would suggest switching out the solver for the PCA and/ or using 64 bit values for `X`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2114#issuecomment-1021048765
https://github.com/scverse/scanpy/issues/2114#issuecomment-1021048765:786,Usability,learn,learn,786,"## `X`. So, the first and third result have the same values of `X`. . ```python; assert np.array_equal(pc1.X, pc3.X); ```. The second is only slightly different:. ```python; diff = pc2.X - pc1.X; diff[diff != 0]; ```. ```; array([7.450581e-09], dtype=float32); ```. This might be adjustable by setting ""regress out"" to a fixed number of jobs. ## PCA. The results of the PCA differ more significantly, but here you should just be calling scikit-learn's implementation. Could you try calling that directly and letting us know the results?. E.g. ```python; from sklearn.decomposition import PCA. pca = PCA(n_components=50, solver=""arpack"", random_state=0); result = pca.fit_transform(adata.X); ```. If this doesn't give consistent results on your machines, the issue is upstream in scikit-learn. If you need reproducibility now, I would suggest switching out the solver for the PCA and/ or using 64 bit values for `X`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2114#issuecomment-1021048765
https://github.com/scverse/scanpy/issues/2114#issuecomment-1021416791:137,Security,hash,hashlib,137,"> Where shall I call this code?. I would call it on the same exact same `X` on different machines. E.g. something like:. ```python; from hashlib import sha256; import anndata as ad; from sklearn.decomposition import PCA. adata = ad.read_h5ad(""PC1.h5ad""); print(sha256(adata.X).hexdigest()). pca = PCA(n_components=50, solver=""arpack"", random_state=0). print(sha256(pca.fit_transform(adata.X)).hexdigest()); ```. The first hash should be the same on all systems, while I would expect the second to vary if the PCA isn't reproducing. > To switch out the solver, did you mean that I should delete svd_solver='arpack' in sc.tl.pca(adata, svd_solver='arpack')?. I think you should specify a different one, like ""lob_pcg"" or ""randomized"", but you can pass this directly to `PCA(..., solver=...)` too. > To use 64bit value, shall I call this adata.X = adata.X.astype('float64') . Yes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2114#issuecomment-1021416791
https://github.com/scverse/scanpy/issues/2114#issuecomment-1021416791:422,Security,hash,hash,422,"> Where shall I call this code?. I would call it on the same exact same `X` on different machines. E.g. something like:. ```python; from hashlib import sha256; import anndata as ad; from sklearn.decomposition import PCA. adata = ad.read_h5ad(""PC1.h5ad""); print(sha256(adata.X).hexdigest()). pca = PCA(n_components=50, solver=""arpack"", random_state=0). print(sha256(pca.fit_transform(adata.X)).hexdigest()); ```. The first hash should be the same on all systems, while I would expect the second to vary if the PCA isn't reproducing. > To switch out the solver, did you mean that I should delete svd_solver='arpack' in sc.tl.pca(adata, svd_solver='arpack')?. I think you should specify a different one, like ""lob_pcg"" or ""randomized"", but you can pass this directly to `PCA(..., solver=...)` too. > To use 64bit value, shall I call this adata.X = adata.X.astype('float64') . Yes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2114#issuecomment-1021416791
https://github.com/scverse/scanpy/issues/2114#issuecomment-1021455251:28,Availability,error,errors,28,"Hello @ivirshup , I met the errors. ; ```python; from hashlib import sha256; import anndata as ad; from sklearn.decomposition import PCA. adata = ad.read_h5ad(""C:/Users/Park_Lab/Documents/PC1.h5ad""); print(sha256(adata.X).hexdigest()). pca = PCA(n_components=50, svd_solver=""arpack"", random_state=0). print(sha256(pca.fit_transform(adata.X)).hexdigest()). ValueError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_3908/912381655.py in <module>; 8 pca = PCA(n_components=50, svd_solver=""arpack"", random_state=0); 9 ; ---> 10 print(sha256(pca.fit_transform(adata.X)).hexdigest()). ValueError: ndarray is not C-contiguous; ```; change to this, same error.; ```python; from hashlib import sha256; import anndata as ad; from sklearn.decomposition import PCA. adata = ad.read_h5ad(""C:/Users/Park_Lab/Documents/PC1.h5ad""); print(sha256(adata.X).hexdigest()). pca = PCA(n_components=50, svd_solver=""arpack"", random_state=0); a=adata.X.copy(order='C'). print(sha256(pca.fit_transform(a)).hexdigest()). ValueError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_3908/1058352035.py in <module>; 8 pca = PCA(n_components=50, svd_solver=""arpack"", random_state=0); 9 a=adata.X.copy(order='C'); ---> 10 print(sha256(pca.fit_transform(a)).hexdigest()). ValueError: ndarray is not C-contiguous",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2114#issuecomment-1021455251
https://github.com/scverse/scanpy/issues/2114#issuecomment-1021455251:665,Availability,error,error,665,"Hello @ivirshup , I met the errors. ; ```python; from hashlib import sha256; import anndata as ad; from sklearn.decomposition import PCA. adata = ad.read_h5ad(""C:/Users/Park_Lab/Documents/PC1.h5ad""); print(sha256(adata.X).hexdigest()). pca = PCA(n_components=50, svd_solver=""arpack"", random_state=0). print(sha256(pca.fit_transform(adata.X)).hexdigest()). ValueError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_3908/912381655.py in <module>; 8 pca = PCA(n_components=50, svd_solver=""arpack"", random_state=0); 9 ; ---> 10 print(sha256(pca.fit_transform(adata.X)).hexdigest()). ValueError: ndarray is not C-contiguous; ```; change to this, same error.; ```python; from hashlib import sha256; import anndata as ad; from sklearn.decomposition import PCA. adata = ad.read_h5ad(""C:/Users/Park_Lab/Documents/PC1.h5ad""); print(sha256(adata.X).hexdigest()). pca = PCA(n_components=50, svd_solver=""arpack"", random_state=0); a=adata.X.copy(order='C'). print(sha256(pca.fit_transform(a)).hexdigest()). ValueError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_3908/1058352035.py in <module>; 8 pca = PCA(n_components=50, svd_solver=""arpack"", random_state=0); 9 a=adata.X.copy(order='C'); ---> 10 print(sha256(pca.fit_transform(a)).hexdigest()). ValueError: ndarray is not C-contiguous",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2114#issuecomment-1021455251
https://github.com/scverse/scanpy/issues/2114#issuecomment-1021455251:54,Security,hash,hashlib,54,"Hello @ivirshup , I met the errors. ; ```python; from hashlib import sha256; import anndata as ad; from sklearn.decomposition import PCA. adata = ad.read_h5ad(""C:/Users/Park_Lab/Documents/PC1.h5ad""); print(sha256(adata.X).hexdigest()). pca = PCA(n_components=50, svd_solver=""arpack"", random_state=0). print(sha256(pca.fit_transform(adata.X)).hexdigest()). ValueError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_3908/912381655.py in <module>; 8 pca = PCA(n_components=50, svd_solver=""arpack"", random_state=0); 9 ; ---> 10 print(sha256(pca.fit_transform(adata.X)).hexdigest()). ValueError: ndarray is not C-contiguous; ```; change to this, same error.; ```python; from hashlib import sha256; import anndata as ad; from sklearn.decomposition import PCA. adata = ad.read_h5ad(""C:/Users/Park_Lab/Documents/PC1.h5ad""); print(sha256(adata.X).hexdigest()). pca = PCA(n_components=50, svd_solver=""arpack"", random_state=0); a=adata.X.copy(order='C'). print(sha256(pca.fit_transform(a)).hexdigest()). ValueError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_3908/1058352035.py in <module>; 8 pca = PCA(n_components=50, svd_solver=""arpack"", random_state=0); 9 a=adata.X.copy(order='C'); ---> 10 print(sha256(pca.fit_transform(a)).hexdigest()). ValueError: ndarray is not C-contiguous",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2114#issuecomment-1021455251
https://github.com/scverse/scanpy/issues/2114#issuecomment-1021455251:689,Security,hash,hashlib,689,"Hello @ivirshup , I met the errors. ; ```python; from hashlib import sha256; import anndata as ad; from sklearn.decomposition import PCA. adata = ad.read_h5ad(""C:/Users/Park_Lab/Documents/PC1.h5ad""); print(sha256(adata.X).hexdigest()). pca = PCA(n_components=50, svd_solver=""arpack"", random_state=0). print(sha256(pca.fit_transform(adata.X)).hexdigest()). ValueError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_3908/912381655.py in <module>; 8 pca = PCA(n_components=50, svd_solver=""arpack"", random_state=0); 9 ; ---> 10 print(sha256(pca.fit_transform(adata.X)).hexdigest()). ValueError: ndarray is not C-contiguous; ```; change to this, same error.; ```python; from hashlib import sha256; import anndata as ad; from sklearn.decomposition import PCA. adata = ad.read_h5ad(""C:/Users/Park_Lab/Documents/PC1.h5ad""); print(sha256(adata.X).hexdigest()). pca = PCA(n_components=50, svd_solver=""arpack"", random_state=0); a=adata.X.copy(order='C'). print(sha256(pca.fit_transform(a)).hexdigest()). ValueError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_3908/1058352035.py in <module>; 8 pca = PCA(n_components=50, svd_solver=""arpack"", random_state=0); 9 a=adata.X.copy(order='C'); ---> 10 print(sha256(pca.fit_transform(a)).hexdigest()). ValueError: ndarray is not C-contiguous",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2114#issuecomment-1021455251
https://github.com/scverse/scanpy/issues/2114#issuecomment-1032179479:49,Deployability,update,update,49,"Hello @ivirshup , sorry for asking. Is there any update on this issue?; Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2114#issuecomment-1032179479
https://github.com/scverse/scanpy/issues/2117#issuecomment-1018747515:193,Security,access,accessible,193,"Thanks for the flowers (on behalf of the people who did a lot of the work, not me ^^), but it's also the developers of some of these packages, who are ensuring that their packages are directly accessible via this ecosystem. The scanpy ecosystem can only work if everyone is involved. Please feel free to contribute future tools you are working on as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2117#issuecomment-1018747515
https://github.com/scverse/scanpy/issues/2118#issuecomment-1020206162:2136,Deployability,update,updated,2136,"pbmc.uns[""rank_genes_groups""][""names""][0]). In [4]: sc.pl.stacked_violin(pbmc, var_names=genes, groupby='louvain', swap_axes=True); ```. <details>; <summary> Versions </summary>. ```; -----; scanpy 1.9.0.dev63+gb69015e9; session_info 1.0.0; -----; PIL 9.0.0; anndata 0.8.0rc1; appnope 0.1.2; asciitree NA; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; cloudpickle 2.0.0; cycler 0.10.0; cython_runtime NA; dask 2021.12.0; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.0; defusedxml 0.7.1; entrypoints 0.3; executing 0.8.2; fasteners NA; fsspec 2022.01.0; google NA; h5py 3.6.0; igraph 0.9.9; ipykernel 6.7.0; ipython_genutils 0.2.0; jedi 0.18.1; jinja2 3.0.3; joblib 1.1.0; jupyter_server 1.13.1; kiwisolver 1.3.2; leidenalg 0.8.8; llvmlite 0.38.0; markupsafe 2.0.1; matplotlib 3.5.1; matplotlib_inline NA; mpl_toolkits NA; msgpack 1.0.3; natsort 8.0.2; nbinom_ufunc NA; numba 0.55.0; numcodecs 0.9.1; numexpr 2.7.3; numpy 1.21.5; packaging 21.3; pandas 1.4.0; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.22; psutil 5.8.0; ptyprocess 0.7.0; pure_eval 0.2.1; pyarrow 6.0.1; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pyexpat NA; pygments 2.10.0; pyparsing 3.0.6; pytz 2021.3; ruamel NA; scipy 1.7.3; setuptools 60.5.0; setuptools_scm NA; sinfo 0.3.4; sitecustomize NA; six 1.16.0; sklearn 1.0.2; sparse 0.13.0; sphinxcontrib NA; stack_data 0.1.4; tables 3.7.0; tblib 1.7.0; texttable 1.6.4; threadpoolctl 3.0.0; tlz 0.11.2; toolz 0.11.2; tornado 6.1; traitlets 5.1.1; typing_extensions NA; wcwidth 0.2.5; yaml 6.0; zappy NA; zarr 2.10.3; zmq 22.3.0; -----; IPython 8.0.0; jupyter_client 7.1.0; jupyter_core 4.9.1; jupyterlab 3.2.6; notebook 6.4.7; -----; Python 3.9.9 (main, Nov 21 2021, 03:23:42) [Clang 13.0.0 (clang-1300.0.29.3)]; macOS-11.6.2-x86_64-i386-64bit; -----; Session information updated at 2022-01-24 16:14; ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2118#issuecomment-1020206162
https://github.com/scverse/scanpy/issues/2118#issuecomment-1020337090:299,Deployability,release,release,299,"Here's the commit that caused the issue: https://github.com/theislab/scanpy/commit/4cb8a61df2628f00ce7d1fff5a3b25dcbe2222ff. So the difference was switching from ColorBarBase to ColorBar, but also it looks like `ColorBarBase` only allows a single positional argument in the most recent `Matplotlib` release. Could do a conditional around matplotlib versions? Or could restrict which versions can be used?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2118#issuecomment-1020337090
https://github.com/scverse/scanpy/issues/2118#issuecomment-1020439130:27,Availability,failure,failures,27,"Oh, I had assumed the test failures were related. Any idea what's up with those?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2118#issuecomment-1020439130
https://github.com/scverse/scanpy/issues/2118#issuecomment-1020439130:22,Testability,test,test,22,"Oh, I had assumed the test failures were related. Any idea what's up with those?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2118#issuecomment-1020439130
https://github.com/scverse/scanpy/issues/2118#issuecomment-1020492061:24,Availability,failure,failures,24,"No, i see the same test failures on the PR unrelated to plotting. No, i haven't looked yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2118#issuecomment-1020492061
https://github.com/scverse/scanpy/issues/2118#issuecomment-1020492061:19,Testability,test,test,19,"No, i see the same test failures on the PR unrelated to plotting. No, i haven't looked yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2118#issuecomment-1020492061
https://github.com/scverse/scanpy/pull/2120#issuecomment-1040372589:29,Availability,failure,failures,29,"Current thinking on the test failures: #2129 was fixed upstream in pandas, so is no longer needed. This is needed, but I can't retrigger the builds because Azure is down in Europe.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2120#issuecomment-1040372589
https://github.com/scverse/scanpy/pull/2120#issuecomment-1040372589:165,Availability,down,down,165,"Current thinking on the test failures: #2129 was fixed upstream in pandas, so is no longer needed. This is needed, but I can't retrigger the builds because Azure is down in Europe.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2120#issuecomment-1040372589
https://github.com/scverse/scanpy/pull/2120#issuecomment-1040372589:24,Testability,test,test,24,"Current thinking on the test failures: #2129 was fixed upstream in pandas, so is no longer needed. This is needed, but I can't retrigger the builds because Azure is down in Europe.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2120#issuecomment-1040372589
https://github.com/scverse/scanpy/pull/2120#issuecomment-1040564918:14,Deployability,Pipeline,Pipelines,14,<samp>; Azure Pipelines successfully started running 1 pipeline(s).<br>. </samp>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2120#issuecomment-1040564918
https://github.com/scverse/scanpy/pull/2120#issuecomment-1040564918:55,Deployability,pipeline,pipeline,55,<samp>; Azure Pipelines successfully started running 1 pipeline(s).<br>. </samp>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2120#issuecomment-1040564918
https://github.com/scverse/scanpy/pull/2120#issuecomment-1054308092:14,Deployability,Pipeline,Pipelines,14,<samp>; Azure Pipelines successfully started running 1 pipeline(s).<br>. </samp>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2120#issuecomment-1054308092
https://github.com/scverse/scanpy/pull/2120#issuecomment-1054308092:55,Deployability,pipeline,pipeline,55,<samp>; Azure Pipelines successfully started running 1 pipeline(s).<br>. </samp>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2120#issuecomment-1054308092
https://github.com/scverse/scanpy/issues/2121#issuecomment-1025090712:88,Deployability,update,update,88,After my hard drive and computer crashed (which is why I respond so late) I was able to update my python env. So far it is working. Thanks a lot!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2121#issuecomment-1025090712
https://github.com/scverse/scanpy/issues/2124#issuecomment-1025527856:73,Availability,ping,pinging,73,"same here, we are having CI failing in squidpy cause we use the dataset, pinging @falexwolf",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2124#issuecomment-1025527856
https://github.com/scverse/scanpy/issues/2124#issuecomment-1025836805:12,Availability,down,download,12,How are the download speeds/ hosting for figshare? Do they mirror to different regions? I recall some painful download times from Australia. It's also probably pretty stable. Could also use `scverse.org` for permanent URIs?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2124#issuecomment-1025836805
https://github.com/scverse/scanpy/issues/2124#issuecomment-1025836805:110,Availability,down,download,110,How are the download speeds/ hosting for figshare? Do they mirror to different regions? I recall some painful download times from Australia. It's also probably pretty stable. Could also use `scverse.org` for permanent URIs?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2124#issuecomment-1025836805
https://github.com/scverse/scanpy/issues/2124#issuecomment-1025946640:55,Deployability,release,releases,55,"It's also possible to attach files as assets to github releases. That's what I do for scirpy, e.g. ; https://github.com/icbi-lab/scirpy/releases/tag/d0.1.0",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2124#issuecomment-1025946640
https://github.com/scverse/scanpy/issues/2124#issuecomment-1025946640:136,Deployability,release,releases,136,"It's also possible to attach files as assets to github releases. That's what I do for scirpy, e.g. ; https://github.com/icbi-lab/scirpy/releases/tag/d0.1.0",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2124#issuecomment-1025946640
https://github.com/scverse/scanpy/issues/2124#issuecomment-1026092545:14,Availability,down,download,14,> How are the download speeds/ hosting for figshare? Do they mirror to different regions? I recall some painful download times from Australia. It's also probably pretty stable. the datasets we have in figshar for squidpy are fast to access (europe at least) but also traffic is probably much less than pbmc3k() 😅,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2124#issuecomment-1026092545
https://github.com/scverse/scanpy/issues/2124#issuecomment-1026092545:112,Availability,down,download,112,> How are the download speeds/ hosting for figshare? Do they mirror to different regions? I recall some painful download times from Australia. It's also probably pretty stable. the datasets we have in figshar for squidpy are fast to access (europe at least) but also traffic is probably much less than pbmc3k() 😅,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2124#issuecomment-1026092545
https://github.com/scverse/scanpy/issues/2124#issuecomment-1026092545:233,Security,access,access,233,> How are the download speeds/ hosting for figshare? Do they mirror to different regions? I recall some painful download times from Australia. It's also probably pretty stable. the datasets we have in figshar for squidpy are fast to access (europe at least) but also traffic is probably much less than pbmc3k() 😅,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2124#issuecomment-1026092545
https://github.com/scverse/scanpy/issues/2125#issuecomment-1036952400:15,Availability,error,error,15,i met the same error when using sc.pl.dotplot. did you fix that?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2125#issuecomment-1036952400
https://github.com/scverse/scanpy/issues/2125#issuecomment-1042300588:44,Deployability,upgrade,upgrade,44,"Temporary fix for anyone looking in case an upgrade is not yet possible:; ```python; import scipy.spatial.distance as ssd; from contextlib import contextmanager. def squareform_force_zero_diagonal(X, *args, **kwargs):; if len(X.shape) == 2:; if isinstance(X, pd.DataFrame):; X.iloc[(np.arange(X.shape[0]), np.arange(X.shape[0]))] = 0; else:; X[(np.arange(X.shape[0]), np.arange(X.shape[0]))] = 0; return _squareform(X, *args, **kwargs). @contextmanager; def patch_squareform():; _squareform = ssd.squareform; ssd.squareform = squareform_force_zero_diagonal; try:; yield; finally:; ssd.squareform = _squareform. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); with patch_squareform():; sc.tl.dendrogram(adata, groupby='bulk_labels'); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2125#issuecomment-1042300588
https://github.com/scverse/scanpy/issues/2128#issuecomment-1027837933:308,Safety,avoid,avoid,308,"We use whatever cellranger outputs. For cellranger 3.0.0+ those files are gzip compressed. I would be fine with either of those changes. Could you make a PR?. More general note, I wouldn't want the function to look for either compressed or uncompressed. It should just be outputs from cellranger. This is to avoid scope creap – e.g. we aren't looking to support arbitrary ""cellranger-like delimited files"".",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2128#issuecomment-1027837933
https://github.com/scverse/scanpy/issues/2128#issuecomment-1027896930:69,Availability,error,error,69,"Yes, agreed. I was only talking about consistency between the raised error and docs. And yes, will open a PR.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2128#issuecomment-1027896930
https://github.com/scverse/scanpy/pull/2129#issuecomment-1039247646:46,Deployability,release,released,46,"It's possible this was fixed in pandas 1.4.1, released on Friday https://github.com/pandas-dev/pandas/issues/45640",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2129#issuecomment-1039247646
https://github.com/scverse/scanpy/issues/2131#issuecomment-1033885282:95,Availability,down,downsampling,95,So my X actually contained negative values. I removed my _scanpy.pp.scale_ step and tried this downsampling step earlier in my pipeline and its working. Thanks for taking time to help with this.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2131#issuecomment-1033885282
https://github.com/scverse/scanpy/issues/2131#issuecomment-1033885282:127,Deployability,pipeline,pipeline,127,So my X actually contained negative values. I removed my _scanpy.pp.scale_ step and tried this downsampling step earlier in my pipeline and its working. Thanks for taking time to help with this.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2131#issuecomment-1033885282
https://github.com/scverse/scanpy/issues/2132#issuecomment-1034760467:348,Deployability,release,release,348,"I'm sorry, I wasn't aware I had used so much of my private webspace for Scanpy all these years back. I migrated from some legacy infra a week ago, without trackers to links to external resources. I'll fix this current instance by fixing the URLs and make a PR to have a copy of these images in the static folder in the docs, effective for the next release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2132#issuecomment-1034760467
https://github.com/scverse/scanpy/pull/2134#issuecomment-1034839590:25,Availability,error,error,25,"```; Warning, treated as error:; /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/2134/scanpy/plotting/_anndata.py:docstring of scanpy.plotting._anndata.dendrogram:31:Exception occurred in plotting scanpy-pl-dendrogram-1; from /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/2134/docs/generated/scanpy.pl.dendrogram.rst:; Traceback (most recent call last):; File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2134/lib/python3.8/site-packages/matplotlib/sphinxext/plot_directive.py"", line 517, in _run_code; exec(code, ns); File ""<string>"", line 3, in <module>; File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/2134/scanpy/tools/_dendrogram.py"", line 139, in dendrogram; corr_condensed = distance.squareform(1 - corr_matrix); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2134/lib/python3.8/site-packages/scipy/spatial/distance.py"", line 2363, in squareform; is_valid_dm(X, throw=True, name='X'); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2134/lib/python3.8/site-packages/scipy/spatial/distance.py"", line 2444, in is_valid_dm; raise ValueError(('Distance matrix \'%s\' diagonal must '; ValueError: Distance matrix 'X' diagonal must be zero.; ```. Some dendrogram issue. The RTD build is also flaky.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2134#issuecomment-1034839590
https://github.com/scverse/scanpy/issues/2136#issuecomment-1051175372:103,Availability,error,error,103,"Thanks @ivirshup ! In addition to changing the documentation, it would probably make sense to throw an error if these two arguments are passed together.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2136#issuecomment-1051175372
https://github.com/scverse/scanpy/issues/2138#issuecomment-1040349484:171,Deployability,update,update,171,"Thanks for opening the issue. It looks like a problem with pytables, which we are removing as a dependency since it's starting to have problems like this. Are you able to update the installation of pytables? Otherwise, you could try a dev version of scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2138#issuecomment-1040349484
https://github.com/scverse/scanpy/issues/2138#issuecomment-1040349484:182,Deployability,install,installation,182,"Thanks for opening the issue. It looks like a problem with pytables, which we are removing as a dependency since it's starting to have problems like this. Are you able to update the installation of pytables? Otherwise, you could try a dev version of scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2138#issuecomment-1040349484
https://github.com/scverse/scanpy/issues/2138#issuecomment-1040349484:96,Integrability,depend,dependency,96,"Thanks for opening the issue. It looks like a problem with pytables, which we are removing as a dependency since it's starting to have problems like this. Are you able to update the installation of pytables? Otherwise, you could try a dev version of scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2138#issuecomment-1040349484
https://github.com/scverse/scanpy/issues/2138#issuecomment-1047645794:39,Deployability,install,install,39,"I meet the same problem when I want to install scanpy on my new laptop.; I run the same commands as I used to do on my old computer , but failed to import scanpy.; I've tried re-install of pytables and it still doesn't work.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2138#issuecomment-1047645794
https://github.com/scverse/scanpy/issues/2138#issuecomment-1047645794:178,Deployability,install,install,178,"I meet the same problem when I want to install scanpy on my new laptop.; I run the same commands as I used to do on my old computer , but failed to import scanpy.; I've tried re-install of pytables and it still doesn't work.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2138#issuecomment-1047645794
https://github.com/scverse/scanpy/issues/2138#issuecomment-1047851057:187,Deployability,update,update,187,"> Thanks for opening the issue.; > ; > It looks like a problem with pytables, which we are removing as a dependency since it's starting to have problems like this.; > ; > Are you able to update the installation of pytables? Otherwise, you could try a dev version of scanpy. Thank you for pointing out the issue with pytables. Tried a couple things and it works now.; I don't know how this matters. I uninstalled pytables > tried importing scanpy > doesn't work (says tables module not found, which is expected I guess). I reinstalled pytables - now it decides to work. I can't see how that makes a difference since I had the same pytables version before.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2138#issuecomment-1047851057
https://github.com/scverse/scanpy/issues/2138#issuecomment-1047851057:198,Deployability,install,installation,198,"> Thanks for opening the issue.; > ; > It looks like a problem with pytables, which we are removing as a dependency since it's starting to have problems like this.; > ; > Are you able to update the installation of pytables? Otherwise, you could try a dev version of scanpy. Thank you for pointing out the issue with pytables. Tried a couple things and it works now.; I don't know how this matters. I uninstalled pytables > tried importing scanpy > doesn't work (says tables module not found, which is expected I guess). I reinstalled pytables - now it decides to work. I can't see how that makes a difference since I had the same pytables version before.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2138#issuecomment-1047851057
https://github.com/scverse/scanpy/issues/2138#issuecomment-1047851057:105,Integrability,depend,dependency,105,"> Thanks for opening the issue.; > ; > It looks like a problem with pytables, which we are removing as a dependency since it's starting to have problems like this.; > ; > Are you able to update the installation of pytables? Otherwise, you could try a dev version of scanpy. Thank you for pointing out the issue with pytables. Tried a couple things and it works now.; I don't know how this matters. I uninstalled pytables > tried importing scanpy > doesn't work (says tables module not found, which is expected I guess). I reinstalled pytables - now it decides to work. I can't see how that makes a difference since I had the same pytables version before.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2138#issuecomment-1047851057
https://github.com/scverse/scanpy/issues/2138#issuecomment-1798995383:94,Deployability,update,updated,94,"Just came across this - is this still relevant @FionaMoon, or has this been resolved with the updated scanpy versions? :); Glad to hear it worked out in your case @molecularsensei!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2138#issuecomment-1798995383
https://github.com/scverse/scanpy/pull/2140#issuecomment-1041473484:19,Availability,error,errors,19,"Hm, looking at the errors, they don't seem to be really related to the changes in this PR, no?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2140#issuecomment-1041473484
https://github.com/scverse/scanpy/pull/2140#issuecomment-1041497012:44,Availability,error,errors,44,"Don't think so. I think these are closer to errors I was getting locally a few weeks ago, but couldn't get CI to reproduce.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2140#issuecomment-1041497012
https://github.com/scverse/scanpy/issues/2141#issuecomment-1981711229:18,Availability,error,error,18,I have this exact error!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2141#issuecomment-1981711229
https://github.com/scverse/scanpy/issues/2142#issuecomment-1046729522:229,Availability,mask,mask,229,"I would probably just pass those through with kwargs. At the moment, I'm not sure I would include this within scanpy, since it's fairly easy for users to do on their own and I'm not sure many people would want to use it. Using a mask to just scale a subset of the data could fit under a possible `mask` keyword argument.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2142#issuecomment-1046729522
https://github.com/scverse/scanpy/issues/2142#issuecomment-1046729522:297,Availability,mask,mask,297,"I would probably just pass those through with kwargs. At the moment, I'm not sure I would include this within scanpy, since it's fairly easy for users to do on their own and I'm not sure many people would want to use it. Using a mask to just scale a subset of the data could fit under a possible `mask` keyword argument.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2142#issuecomment-1046729522
https://github.com/scverse/scanpy/issues/2143#issuecomment-1049165791:62,Modifiability,variab,variable,62,"Yeah, that looks pretty weird. In your example, where did the variable `integrated_anterior` come from?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2143#issuecomment-1049165791
https://github.com/scverse/scanpy/issues/2143#issuecomment-1049184473:79,Deployability,update,updated,79,"I can reproduce from the full tutorial. The issue here is that `scanorama` has updated it's API since this tutorial was written. Now `scanorama.correct_scanpy` returns AnnData objects. @giovp, where should this tutorial live?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2143#issuecomment-1049184473
https://github.com/scverse/scanpy/issues/2143#issuecomment-1051031200:338,Usability,simpl,simply,338,@ivirshup `integrated_anterior` came from `scanorama.correct_scanpy()` like you mentioned. I'm running my jupyter notebook out of a container. I rebuilt my container with scanorama=1.7 but faced the same issue. Is it possible the problem is the preprocessed data at `https://hmgubox.helmholtz-muenchen.de/f/4ef254675e2a41f89835/?dl=1` is simply of the wrong shape once it's read by scanpy?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2143#issuecomment-1051031200
https://github.com/scverse/scanpy/issues/2143#issuecomment-1051044283:119,Deployability,release,releases,119,The problem is that `np.concatenate` is being called on an `AnnData`. You may have to go back further in the scanorama releases.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2143#issuecomment-1051044283
https://github.com/scverse/scanpy/issues/2143#issuecomment-1051048349:109,Deployability,release,release,109,"If this is the case, then why does the tutorial work with scanorama=1.7? I'll try again with an even earlier release scanorama when I have a moment though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2143#issuecomment-1051048349
https://github.com/scverse/scanpy/issues/2143#issuecomment-1053612098:29,Deployability,update,update,29,"@zappuf @ivirshup I think an update to the tutorial would be needed but don't have time right now, @zappuf did you manage to work around the issue?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2143#issuecomment-1053612098
https://github.com/scverse/scanpy/issues/2143#issuecomment-1054575633:160,Availability,error,errors,160,"@giovp I haven't been able to work around the issue. When I rebuild a container with different versions of scanorama, scanpy, numpy, scikit-learn I end up with errors. Most of the time it's this ValueError about the wrong shape. The only different error I noticed is when I tried scanorama 1.6 and there was an error about `concatenate()` not being an available function. . Whenever you find time to update the tutorial, that will be greatly appreciated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2143#issuecomment-1054575633
https://github.com/scverse/scanpy/issues/2143#issuecomment-1054575633:248,Availability,error,error,248,"@giovp I haven't been able to work around the issue. When I rebuild a container with different versions of scanorama, scanpy, numpy, scikit-learn I end up with errors. Most of the time it's this ValueError about the wrong shape. The only different error I noticed is when I tried scanorama 1.6 and there was an error about `concatenate()` not being an available function. . Whenever you find time to update the tutorial, that will be greatly appreciated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2143#issuecomment-1054575633
https://github.com/scverse/scanpy/issues/2143#issuecomment-1054575633:311,Availability,error,error,311,"@giovp I haven't been able to work around the issue. When I rebuild a container with different versions of scanorama, scanpy, numpy, scikit-learn I end up with errors. Most of the time it's this ValueError about the wrong shape. The only different error I noticed is when I tried scanorama 1.6 and there was an error about `concatenate()` not being an available function. . Whenever you find time to update the tutorial, that will be greatly appreciated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2143#issuecomment-1054575633
https://github.com/scverse/scanpy/issues/2143#issuecomment-1054575633:352,Availability,avail,available,352,"@giovp I haven't been able to work around the issue. When I rebuild a container with different versions of scanorama, scanpy, numpy, scikit-learn I end up with errors. Most of the time it's this ValueError about the wrong shape. The only different error I noticed is when I tried scanorama 1.6 and there was an error about `concatenate()` not being an available function. . Whenever you find time to update the tutorial, that will be greatly appreciated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2143#issuecomment-1054575633
https://github.com/scverse/scanpy/issues/2143#issuecomment-1054575633:400,Deployability,update,update,400,"@giovp I haven't been able to work around the issue. When I rebuild a container with different versions of scanorama, scanpy, numpy, scikit-learn I end up with errors. Most of the time it's this ValueError about the wrong shape. The only different error I noticed is when I tried scanorama 1.6 and there was an error about `concatenate()` not being an available function. . Whenever you find time to update the tutorial, that will be greatly appreciated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2143#issuecomment-1054575633
https://github.com/scverse/scanpy/issues/2143#issuecomment-1054575633:140,Usability,learn,learn,140,"@giovp I haven't been able to work around the issue. When I rebuild a container with different versions of scanorama, scanpy, numpy, scikit-learn I end up with errors. Most of the time it's this ValueError about the wrong shape. The only different error I noticed is when I tried scanorama 1.6 and there was an error about `concatenate()` not being an available function. . Whenever you find time to update the tutorial, that will be greatly appreciated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2143#issuecomment-1054575633
https://github.com/scverse/scanpy/issues/2143#issuecomment-1072774695:16,Deployability,update,updated,16,Can confirm the updated tutorial works. Thanks!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2143#issuecomment-1072774695
https://github.com/scverse/scanpy/issues/2143#issuecomment-1072908371:33,Deployability,update,updated,33,"@ivirshup I can also confirm the updated tutorial works, thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2143#issuecomment-1072908371
https://github.com/scverse/scanpy/issues/2144#issuecomment-1046710380:66,Integrability,depend,dependency,66,"Huh, that is weird. Also weird that it's including every optional dependency by default. Any chance you know if there's a way to not do that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2144#issuecomment-1046710380
https://github.com/scverse/scanpy/issues/2144#issuecomment-1055433811:51,Integrability,depend,dependencies,51,seems like the `--deps` flag can be used to select dependencies. Default is all dependencies. ```bash; $ beni --deps production pyproject.toml; channels:; - conda-forge; dependencies:; - pip:; - flit; - python>=3.7; - pip; - anndata>=0.7.4; - numpy>=1.17.0; - matplotlib-base>=3.1.2; - pandas>=0.21; - scipy>=1.4; - seaborn-split; - h5py>=2.10.0; - pytables; - tqdm; - scikit-learn>=0.22; - statsmodels>=0.10.0rc2; - patsy; - networkx>=2.3; - natsort; - joblib; - numba>=0.41.0; - umap-learn>=0.3.10; - packaging; - sinfo; name: scanpy; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2144#issuecomment-1055433811
https://github.com/scverse/scanpy/issues/2144#issuecomment-1055433811:80,Integrability,depend,dependencies,80,seems like the `--deps` flag can be used to select dependencies. Default is all dependencies. ```bash; $ beni --deps production pyproject.toml; channels:; - conda-forge; dependencies:; - pip:; - flit; - python>=3.7; - pip; - anndata>=0.7.4; - numpy>=1.17.0; - matplotlib-base>=3.1.2; - pandas>=0.21; - scipy>=1.4; - seaborn-split; - h5py>=2.10.0; - pytables; - tqdm; - scikit-learn>=0.22; - statsmodels>=0.10.0rc2; - patsy; - networkx>=2.3; - natsort; - joblib; - numba>=0.41.0; - umap-learn>=0.3.10; - packaging; - sinfo; name: scanpy; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2144#issuecomment-1055433811
https://github.com/scverse/scanpy/issues/2144#issuecomment-1055433811:170,Integrability,depend,dependencies,170,seems like the `--deps` flag can be used to select dependencies. Default is all dependencies. ```bash; $ beni --deps production pyproject.toml; channels:; - conda-forge; dependencies:; - pip:; - flit; - python>=3.7; - pip; - anndata>=0.7.4; - numpy>=1.17.0; - matplotlib-base>=3.1.2; - pandas>=0.21; - scipy>=1.4; - seaborn-split; - h5py>=2.10.0; - pytables; - tqdm; - scikit-learn>=0.22; - statsmodels>=0.10.0rc2; - patsy; - networkx>=2.3; - natsort; - joblib; - numba>=0.41.0; - umap-learn>=0.3.10; - packaging; - sinfo; name: scanpy; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2144#issuecomment-1055433811
https://github.com/scverse/scanpy/issues/2144#issuecomment-1055433811:376,Usability,learn,learn,376,seems like the `--deps` flag can be used to select dependencies. Default is all dependencies. ```bash; $ beni --deps production pyproject.toml; channels:; - conda-forge; dependencies:; - pip:; - flit; - python>=3.7; - pip; - anndata>=0.7.4; - numpy>=1.17.0; - matplotlib-base>=3.1.2; - pandas>=0.21; - scipy>=1.4; - seaborn-split; - h5py>=2.10.0; - pytables; - tqdm; - scikit-learn>=0.22; - statsmodels>=0.10.0rc2; - patsy; - networkx>=2.3; - natsort; - joblib; - numba>=0.41.0; - umap-learn>=0.3.10; - packaging; - sinfo; name: scanpy; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2144#issuecomment-1055433811
https://github.com/scverse/scanpy/issues/2144#issuecomment-1055433811:486,Usability,learn,learn,486,seems like the `--deps` flag can be used to select dependencies. Default is all dependencies. ```bash; $ beni --deps production pyproject.toml; channels:; - conda-forge; dependencies:; - pip:; - flit; - python>=3.7; - pip; - anndata>=0.7.4; - numpy>=1.17.0; - matplotlib-base>=3.1.2; - pandas>=0.21; - scipy>=1.4; - seaborn-split; - h5py>=2.10.0; - pytables; - tqdm; - scikit-learn>=0.22; - statsmodels>=0.10.0rc2; - patsy; - networkx>=2.3; - natsort; - joblib; - numba>=0.41.0; - umap-learn>=0.3.10; - packaging; - sinfo; name: scanpy; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2144#issuecomment-1055433811
https://github.com/scverse/scanpy/issues/2147#issuecomment-1049155583:201,Availability,error,errors,201,"Thanks for opening an issue!. Many of the function in scanpy do not support being applied on a backed anndata. `highly_variable_genes` hasn't had support for out of core computation implemented, so it errors. Better out of core support is something we're working for. Is it possible to load `X` into memory here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147#issuecomment-1049155583
https://github.com/scverse/scanpy/issues/2147#issuecomment-1049155583:286,Performance,load,load,286,"Thanks for opening an issue!. Many of the function in scanpy do not support being applied on a backed anndata. `highly_variable_genes` hasn't had support for out of core computation implemented, so it errors. Better out of core support is something we're working for. Is it possible to load `X` into memory here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147#issuecomment-1049155583
https://github.com/scverse/scanpy/issues/2147#issuecomment-1053044750:286,Performance,perform,performing,286,"Hello @ivirshup , Thanks for your reply. I figured that this might be an issue due to the anndata being read in backed mode. Although the file is large (7 gb in .h5ad format, and as soon as it gets read in memory, it blows up to 28 gb), but for now I have utilized a larger machine for performing my eda, and converted the sparse matrix to a dense one . Thanks for your clarification !",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147#issuecomment-1053044750
https://github.com/scverse/scanpy/issues/2148#issuecomment-1047005471:341,Energy Efficiency,adapt,adapted,341,"Hey @buesra-oezmen! I don't think this is a UMAP issue, but instead an issue of the MultiVI parameterization or the data. But as I know the data quite well in this case, I'm pretty sure it's maybe just a MultiVI model that is not sufficiently trained. Maybe try for a few more epochs? Or otherwise maybe the network architecture needs to be adapted.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2148#issuecomment-1047005471
https://github.com/scverse/scanpy/issues/2148#issuecomment-1047005471:92,Modifiability,parameteriz,parameterization,92,"Hey @buesra-oezmen! I don't think this is a UMAP issue, but instead an issue of the MultiVI parameterization or the data. But as I know the data quite well in this case, I'm pretty sure it's maybe just a MultiVI model that is not sufficiently trained. Maybe try for a few more epochs? Or otherwise maybe the network architecture needs to be adapted.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2148#issuecomment-1047005471
https://github.com/scverse/scanpy/issues/2148#issuecomment-1047005471:341,Modifiability,adapt,adapted,341,"Hey @buesra-oezmen! I don't think this is a UMAP issue, but instead an issue of the MultiVI parameterization or the data. But as I know the data quite well in this case, I'm pretty sure it's maybe just a MultiVI model that is not sufficiently trained. Maybe try for a few more epochs? Or otherwise maybe the network architecture needs to be adapted.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2148#issuecomment-1047005471
https://github.com/scverse/scanpy/issues/2149#issuecomment-1049152162:142,Availability,error,error,142,"Thanks for the report!. `scanpy.read_10x_h5` is expecting the files for the count matrices, not the UMI info. So it's throwing a non-sensical error. `read_10x_h5` is expecting files like `filtered_feature_bc_matrix.h5` or `raw_feature_bc_matrix_h5.h5`. For example:. https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_feature_bc_matrix.h5",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149#issuecomment-1049152162
https://github.com/scverse/scanpy/issues/2153#issuecomment-1910410846:348,Availability,error,error,348,"I encountered the same problem, when I created a small artificial `AnnData` with a single gene in `gene_list` for some unit test. Here is my analysis of the problem:. In this line; https://github.com/scverse/scanpy/blob/63141908601632638db8a79e8a1dfa8509cd27af/scanpy/tools/_score_genes.py#L182; `control_genes` was actually empty, hence the index error.; The reason for the empty `control_genes` genes is; https://github.com/scverse/scanpy/blob/63141908601632638db8a79e8a1dfa8509cd27af/scanpy/tools/_score_genes.py#L173; `control_genes` contained some genes before (in my artificial case only one), but they are removed here, since the genes in `control_genes` also appeared in `gene_list`. I think this is where the bug resides:; I assume `control_genes` should not contain genes from `gene_list` in the first place. Hence, this line; https://github.com/scverse/scanpy/blob/63141908601632638db8a79e8a1dfa8509cd27af/scanpy/tools/_score_genes.py#L167; would need to be changed/complemented:; An additional filter for not being a gene in `gene_list` should fix this issue, if I understand this code correctly. That being said, I suppose that this issue appears rather rarely in the realistically sized datasets. I assume, that the probability of *accidentally* picking genes from `gene_list` as `control_genes` decreases with increasing number of genes.; At least I have not encountered this exception in my experimental datasets.; Furthermore, this issue does not make the result *wrong*, as far as I understand the algorithm, because the control genes are selected randomly anyway.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2153#issuecomment-1910410846
https://github.com/scverse/scanpy/issues/2153#issuecomment-1910410846:124,Testability,test,test,124,"I encountered the same problem, when I created a small artificial `AnnData` with a single gene in `gene_list` for some unit test. Here is my analysis of the problem:. In this line; https://github.com/scverse/scanpy/blob/63141908601632638db8a79e8a1dfa8509cd27af/scanpy/tools/_score_genes.py#L182; `control_genes` was actually empty, hence the index error.; The reason for the empty `control_genes` genes is; https://github.com/scverse/scanpy/blob/63141908601632638db8a79e8a1dfa8509cd27af/scanpy/tools/_score_genes.py#L173; `control_genes` contained some genes before (in my artificial case only one), but they are removed here, since the genes in `control_genes` also appeared in `gene_list`. I think this is where the bug resides:; I assume `control_genes` should not contain genes from `gene_list` in the first place. Hence, this line; https://github.com/scverse/scanpy/blob/63141908601632638db8a79e8a1dfa8509cd27af/scanpy/tools/_score_genes.py#L167; would need to be changed/complemented:; An additional filter for not being a gene in `gene_list` should fix this issue, if I understand this code correctly. That being said, I suppose that this issue appears rather rarely in the realistically sized datasets. I assume, that the probability of *accidentally* picking genes from `gene_list` as `control_genes` decreases with increasing number of genes.; At least I have not encountered this exception in my experimental datasets.; Furthermore, this issue does not make the result *wrong*, as far as I understand the algorithm, because the control genes are selected randomly anyway.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2153#issuecomment-1910410846
https://github.com/scverse/scanpy/issues/2153#issuecomment-1956738660:5,Availability,error,error,5,"This error happened to me too when working on a small dataset and scoring a single gene with ctrl_size=1. This happens at random in the following line: https://github.com/scverse/scanpy/blob/383a61b2db0c45ba622f231f01d0e7546d99566b/scanpy/tools/_score_genes.py#L168. I was working on a small test dataset with limited features and calling the `score_genes_cell_cycle` function, where only 1 cell cycle gene is left and ctrl_size is set as follows:; https://github.com/scverse/scanpy/blob/383a61b2db0c45ba622f231f01d0e7546d99566b/scanpy/tools/_score_genes.py#L258",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2153#issuecomment-1956738660
https://github.com/scverse/scanpy/issues/2153#issuecomment-1956738660:292,Testability,test,test,292,"This error happened to me too when working on a small dataset and scoring a single gene with ctrl_size=1. This happens at random in the following line: https://github.com/scverse/scanpy/blob/383a61b2db0c45ba622f231f01d0e7546d99566b/scanpy/tools/_score_genes.py#L168. I was working on a small test dataset with limited features and calling the `score_genes_cell_cycle` function, where only 1 cell cycle gene is left and ctrl_size is set as follows:; https://github.com/scverse/scanpy/blob/383a61b2db0c45ba622f231f01d0e7546d99566b/scanpy/tools/_score_genes.py#L258",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2153#issuecomment-1956738660
https://github.com/scverse/scanpy/issues/2154#issuecomment-1050880241:53,Usability,clear,clear,53,"I'm hesitant to add another embedding method without clear benefits over existing implementations. Could you give some detail on benefits here, ideally with direct comparisons?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2154#issuecomment-1050880241
https://github.com/scverse/scanpy/issues/2154#issuecomment-1051102663:263,Performance,optimiz,optimize,263,"See [colab notebook](https://colab.research.google.com/drive/17m_3IiZApxpKUHluieWK6C7sGj2XGgTb?usp=sharing). With random initialization it's about 10x faster than UMAP on this system. The quadratic init (default) is as fast as UMAP, but there's an opportunity to optimize that code to use the GPU.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2154#issuecomment-1051102663
https://github.com/scverse/scanpy/issues/2154#issuecomment-1051103627:1197,Availability,avail,available,1197,"ry familiar with Scanpy (which seems like a fantastic library!), so please bear with me if some of the things I mention are not relevant to Scanpy. PyMDE (documentation here: https://pymde.org/) has a few benefits:; - as @adamgayoso mentioned, PyMDE supports computing embeddings on GPU. This makes it possible to compute very large embeddings quickly (often 4-10x faster than CPU).; - PyMDE is a very general embedding library. It is based on a general framework for embedding, and this framework includes many well-known methods --- such as UMAP, PCA, Laplacian embedding, multi-dimensional scaling, and more --- as special cases. This makes it easy to compare different methods using a single framework.; - PyMDE also supports creating entirely new types of embeddings, as custom instances of our framework.; - PyMDE provides ways to reason about how much an embedding distorts the original neighborhood graph. There are some comparisons to UMAP & openTSNE in the third part of our manuscript, which has been published in Foundations & Trends in Machine Learning and is available here: https://web.stanford.edu/~boyd/papers/pdf/min_dist_emb.pdf; - on CPU, UMAP and PyMDE are comparable in speed, with UMAP often having a slight edge; on GPU PyMDE can be much faster; - unlike UMAP/openTSNE, PyMDE allows users to fit constrained embeddings. Right now the supported constraints are standardization (zero mean, unit covariance; this forces embeddings to spread out, but not too much, and as a result standardized embeddings are typically similarly scaled), centering, and anchoring (pre-specifying the coordinates of a subset of the items); - PyMDE allows for more types of embeddings, in addition to UMAP-style embeddings. On the other hand, PyMDE is young software. If you do depend on it, I would recommend including it as an optional dependency, not a required one. Happy to chat more, to answer any questions, and to help with integration, if that is something you are ultimately interested in.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2154#issuecomment-1051103627
https://github.com/scverse/scanpy/issues/2154#issuecomment-1051103627:2057,Deployability,integrat,integration,2057,"ry familiar with Scanpy (which seems like a fantastic library!), so please bear with me if some of the things I mention are not relevant to Scanpy. PyMDE (documentation here: https://pymde.org/) has a few benefits:; - as @adamgayoso mentioned, PyMDE supports computing embeddings on GPU. This makes it possible to compute very large embeddings quickly (often 4-10x faster than CPU).; - PyMDE is a very general embedding library. It is based on a general framework for embedding, and this framework includes many well-known methods --- such as UMAP, PCA, Laplacian embedding, multi-dimensional scaling, and more --- as special cases. This makes it easy to compare different methods using a single framework.; - PyMDE also supports creating entirely new types of embeddings, as custom instances of our framework.; - PyMDE provides ways to reason about how much an embedding distorts the original neighborhood graph. There are some comparisons to UMAP & openTSNE in the third part of our manuscript, which has been published in Foundations & Trends in Machine Learning and is available here: https://web.stanford.edu/~boyd/papers/pdf/min_dist_emb.pdf; - on CPU, UMAP and PyMDE are comparable in speed, with UMAP often having a slight edge; on GPU PyMDE can be much faster; - unlike UMAP/openTSNE, PyMDE allows users to fit constrained embeddings. Right now the supported constraints are standardization (zero mean, unit covariance; this forces embeddings to spread out, but not too much, and as a result standardized embeddings are typically similarly scaled), centering, and anchoring (pre-specifying the coordinates of a subset of the items); - PyMDE allows for more types of embeddings, in addition to UMAP-style embeddings. On the other hand, PyMDE is young software. If you do depend on it, I would recommend including it as an optional dependency, not a required one. Happy to chat more, to answer any questions, and to help with integration, if that is something you are ultimately interested in.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2154#issuecomment-1051103627
https://github.com/scverse/scanpy/issues/2154#issuecomment-1051103627:1903,Integrability,depend,depend,1903,"ry familiar with Scanpy (which seems like a fantastic library!), so please bear with me if some of the things I mention are not relevant to Scanpy. PyMDE (documentation here: https://pymde.org/) has a few benefits:; - as @adamgayoso mentioned, PyMDE supports computing embeddings on GPU. This makes it possible to compute very large embeddings quickly (often 4-10x faster than CPU).; - PyMDE is a very general embedding library. It is based on a general framework for embedding, and this framework includes many well-known methods --- such as UMAP, PCA, Laplacian embedding, multi-dimensional scaling, and more --- as special cases. This makes it easy to compare different methods using a single framework.; - PyMDE also supports creating entirely new types of embeddings, as custom instances of our framework.; - PyMDE provides ways to reason about how much an embedding distorts the original neighborhood graph. There are some comparisons to UMAP & openTSNE in the third part of our manuscript, which has been published in Foundations & Trends in Machine Learning and is available here: https://web.stanford.edu/~boyd/papers/pdf/min_dist_emb.pdf; - on CPU, UMAP and PyMDE are comparable in speed, with UMAP often having a slight edge; on GPU PyMDE can be much faster; - unlike UMAP/openTSNE, PyMDE allows users to fit constrained embeddings. Right now the supported constraints are standardization (zero mean, unit covariance; this forces embeddings to spread out, but not too much, and as a result standardized embeddings are typically similarly scaled), centering, and anchoring (pre-specifying the coordinates of a subset of the items); - PyMDE allows for more types of embeddings, in addition to UMAP-style embeddings. On the other hand, PyMDE is young software. If you do depend on it, I would recommend including it as an optional dependency, not a required one. Happy to chat more, to answer any questions, and to help with integration, if that is something you are ultimately interested in.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2154#issuecomment-1051103627
https://github.com/scverse/scanpy/issues/2154#issuecomment-1051103627:1963,Integrability,depend,dependency,1963,"ry familiar with Scanpy (which seems like a fantastic library!), so please bear with me if some of the things I mention are not relevant to Scanpy. PyMDE (documentation here: https://pymde.org/) has a few benefits:; - as @adamgayoso mentioned, PyMDE supports computing embeddings on GPU. This makes it possible to compute very large embeddings quickly (often 4-10x faster than CPU).; - PyMDE is a very general embedding library. It is based on a general framework for embedding, and this framework includes many well-known methods --- such as UMAP, PCA, Laplacian embedding, multi-dimensional scaling, and more --- as special cases. This makes it easy to compare different methods using a single framework.; - PyMDE also supports creating entirely new types of embeddings, as custom instances of our framework.; - PyMDE provides ways to reason about how much an embedding distorts the original neighborhood graph. There are some comparisons to UMAP & openTSNE in the third part of our manuscript, which has been published in Foundations & Trends in Machine Learning and is available here: https://web.stanford.edu/~boyd/papers/pdf/min_dist_emb.pdf; - on CPU, UMAP and PyMDE are comparable in speed, with UMAP often having a slight edge; on GPU PyMDE can be much faster; - unlike UMAP/openTSNE, PyMDE allows users to fit constrained embeddings. Right now the supported constraints are standardization (zero mean, unit covariance; this forces embeddings to spread out, but not too much, and as a result standardized embeddings are typically similarly scaled), centering, and anchoring (pre-specifying the coordinates of a subset of the items); - PyMDE allows for more types of embeddings, in addition to UMAP-style embeddings. On the other hand, PyMDE is young software. If you do depend on it, I would recommend including it as an optional dependency, not a required one. Happy to chat more, to answer any questions, and to help with integration, if that is something you are ultimately interested in.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2154#issuecomment-1051103627
https://github.com/scverse/scanpy/issues/2154#issuecomment-1051103627:2057,Integrability,integrat,integration,2057,"ry familiar with Scanpy (which seems like a fantastic library!), so please bear with me if some of the things I mention are not relevant to Scanpy. PyMDE (documentation here: https://pymde.org/) has a few benefits:; - as @adamgayoso mentioned, PyMDE supports computing embeddings on GPU. This makes it possible to compute very large embeddings quickly (often 4-10x faster than CPU).; - PyMDE is a very general embedding library. It is based on a general framework for embedding, and this framework includes many well-known methods --- such as UMAP, PCA, Laplacian embedding, multi-dimensional scaling, and more --- as special cases. This makes it easy to compare different methods using a single framework.; - PyMDE also supports creating entirely new types of embeddings, as custom instances of our framework.; - PyMDE provides ways to reason about how much an embedding distorts the original neighborhood graph. There are some comparisons to UMAP & openTSNE in the third part of our manuscript, which has been published in Foundations & Trends in Machine Learning and is available here: https://web.stanford.edu/~boyd/papers/pdf/min_dist_emb.pdf; - on CPU, UMAP and PyMDE are comparable in speed, with UMAP often having a slight edge; on GPU PyMDE can be much faster; - unlike UMAP/openTSNE, PyMDE allows users to fit constrained embeddings. Right now the supported constraints are standardization (zero mean, unit covariance; this forces embeddings to spread out, but not too much, and as a result standardized embeddings are typically similarly scaled), centering, and anchoring (pre-specifying the coordinates of a subset of the items); - PyMDE allows for more types of embeddings, in addition to UMAP-style embeddings. On the other hand, PyMDE is young software. If you do depend on it, I would recommend including it as an optional dependency, not a required one. Happy to chat more, to answer any questions, and to help with integration, if that is something you are ultimately interested in.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2154#issuecomment-1051103627
https://github.com/scverse/scanpy/issues/2154#issuecomment-1051103627:1181,Usability,Learn,Learning,1181,"ry familiar with Scanpy (which seems like a fantastic library!), so please bear with me if some of the things I mention are not relevant to Scanpy. PyMDE (documentation here: https://pymde.org/) has a few benefits:; - as @adamgayoso mentioned, PyMDE supports computing embeddings on GPU. This makes it possible to compute very large embeddings quickly (often 4-10x faster than CPU).; - PyMDE is a very general embedding library. It is based on a general framework for embedding, and this framework includes many well-known methods --- such as UMAP, PCA, Laplacian embedding, multi-dimensional scaling, and more --- as special cases. This makes it easy to compare different methods using a single framework.; - PyMDE also supports creating entirely new types of embeddings, as custom instances of our framework.; - PyMDE provides ways to reason about how much an embedding distorts the original neighborhood graph. There are some comparisons to UMAP & openTSNE in the third part of our manuscript, which has been published in Foundations & Trends in Machine Learning and is available here: https://web.stanford.edu/~boyd/papers/pdf/min_dist_emb.pdf; - on CPU, UMAP and PyMDE are comparable in speed, with UMAP often having a slight edge; on GPU PyMDE can be much faster; - unlike UMAP/openTSNE, PyMDE allows users to fit constrained embeddings. Right now the supported constraints are standardization (zero mean, unit covariance; this forces embeddings to spread out, but not too much, and as a result standardized embeddings are typically similarly scaled), centering, and anchoring (pre-specifying the coordinates of a subset of the items); - PyMDE allows for more types of embeddings, in addition to UMAP-style embeddings. On the other hand, PyMDE is young software. If you do depend on it, I would recommend including it as an optional dependency, not a required one. Happy to chat more, to answer any questions, and to help with integration, if that is something you are ultimately interested in.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2154#issuecomment-1051103627
https://github.com/scverse/scanpy/issues/2154#issuecomment-1051311781:7,Deployability,update,updated,7,"I just updated the notebook linked at the top of the PR. I have a PR at pymde to improve the initialization speed using the GPU (https://github.com/cvxgrp/pymde/pull/55). Using these changes, pymde takes 20 seconds and umap takes around 200 seconds (150k cells). Most of the time of pymde I believe is from the initial pynndescent call. Therefore, if implemented well here and therefore using a precomputed neighbors graph, pymde would take no more than a few seconds for most use cases.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2154#issuecomment-1051311781
https://github.com/scverse/scanpy/issues/2154#issuecomment-1057928027:267,Availability,down,downstream,267,"@akshayka thanks for contributing to the conversation! The package does indeed look interesting. A couple questions about the tool:. Can we get a weighted graph out of the fit embedding object? For context, we use the UMAP weighted connectivity graph for a number of downstream tasks. This seems related to distortions, but maybe not quite what they are. I'm also wondering about just how early the package is. I would like to be able to take advantage of any new features, and wouldn't want an early API decision to lock us out of those.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2154#issuecomment-1057928027
https://github.com/scverse/scanpy/issues/2154#issuecomment-1062027813:118,Integrability,depend,depends,118,"> Can we get a weighted graph out of the fit embedding object? . Yes, PyMDE can do that. The longer answer is that it depends on the type of embedding problem you set up --- some are specified using weighted graphs, others are not. But most embedding problems (including all problems specified using the `preserve_neighbors` function, which is the most commonly used recipe) have associated weighted graphs. > I'm also wondering about just how early the package is. I would like to be able to take advantage of any new features, and wouldn't want an early API decision to lock us out of those. Great question. The internals will very likely change over the coming months/year. But the interface to the `MDE` class, which is the central object in PyMDE, will likely be stable.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2154#issuecomment-1062027813
https://github.com/scverse/scanpy/issues/2154#issuecomment-1062027813:685,Integrability,interface,interface,685,"> Can we get a weighted graph out of the fit embedding object? . Yes, PyMDE can do that. The longer answer is that it depends on the type of embedding problem you set up --- some are specified using weighted graphs, others are not. But most embedding problems (including all problems specified using the `preserve_neighbors` function, which is the most commonly used recipe) have associated weighted graphs. > I'm also wondering about just how early the package is. I would like to be able to take advantage of any new features, and wouldn't want an early API decision to lock us out of those. Great question. The internals will very likely change over the coming months/year. But the interface to the `MDE` class, which is the central object in PyMDE, will likely be stable.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2154#issuecomment-1062027813
https://github.com/scverse/scanpy/issues/2154#issuecomment-1062106274:236,Integrability,depend,dependency,236,"> The internals will very likely change over the coming months/year. Good to know, thanks! Any hints about what will change here? In particular, I'm wondering if there might be a `jax` implementation as I'm a bit more keen on that as a dependency. > But most embedding problems (including all problems specified using the preserve_neighbors function, which is the most commonly used recipe) have associated weighted graphs. I'd be interested in seeing how these graphs perform compared to the ones we get from UMAP. Would this be the right way to retrieve the graphs for the object, or is `distortions` not the right field?. ```python; from scipy import sparse. weights = mde.distortions().cpu().numpy(); edges = mde.edges.cpu().numpy(). graph = sparse.coo_matrix((weights, (edges[:, 0], edges[:, 1])), shape=(mde.n_items, mde.n_items)); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2154#issuecomment-1062106274
https://github.com/scverse/scanpy/issues/2154#issuecomment-1062106274:469,Performance,perform,perform,469,"> The internals will very likely change over the coming months/year. Good to know, thanks! Any hints about what will change here? In particular, I'm wondering if there might be a `jax` implementation as I'm a bit more keen on that as a dependency. > But most embedding problems (including all problems specified using the preserve_neighbors function, which is the most commonly used recipe) have associated weighted graphs. I'd be interested in seeing how these graphs perform compared to the ones we get from UMAP. Would this be the right way to retrieve the graphs for the object, or is `distortions` not the right field?. ```python; from scipy import sparse. weights = mde.distortions().cpu().numpy(); edges = mde.edges.cpu().numpy(). graph = sparse.coo_matrix((weights, (edges[:, 0], edges[:, 1])), shape=(mde.n_items, mde.n_items)); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2154#issuecomment-1062106274
https://github.com/scverse/scanpy/issues/2154#issuecomment-1062188081:199,Deployability,install,install,199,"> I'm wondering if there might be a jax implementation as I'm a bit more keen on that as a dependency. Probably for another discussion -- I like jax as much as anyone, but it's not nearly as easy to install as pytorch, especially on windows and m1 mac.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2154#issuecomment-1062188081
https://github.com/scverse/scanpy/issues/2154#issuecomment-1062188081:91,Integrability,depend,dependency,91,"> I'm wondering if there might be a jax implementation as I'm a bit more keen on that as a dependency. Probably for another discussion -- I like jax as much as anyone, but it's not nearly as easy to install as pytorch, especially on windows and m1 mac.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2154#issuecomment-1062188081
https://github.com/scverse/scanpy/issues/2154#issuecomment-1062222262:106,Integrability,depend,dependency,106,"> In particular, I'm wondering if there might be a jax implementation as I'm a bit more keen on that as a dependency. I don't have any plans to switch from PyTorch to JAX. I did evaluate JAX when I started the project, but it wasn't mature enough back then. > I'd be interested in seeing how these graphs perform compared to the ones we get from UMAP. I'm not super clear on the semantics of the graphs obtained from UMAP. They might differ somewhat from the ones obtained from PyMDE. > Would this be the right way to retrieve the graphs for the object, or is distortions not the right field?. That's not quite right. Assuming that `mde` was constructed from `preserve_neighbors`, try this:. ```python3. weights = mde.distortion_function.weights.cpu().numpy(); edges = mde.edges.cpu().numpy(); n_items = mde.n_items. graph = pymde.Graph.from_edges(edges, weights, n_items).adjacency_matrix; ```. (API docs for `Graph` here: https://pymde.org/api/index.html#pymde.Graph. In the Graph class, distances/weights are used interchangeably.). I'll just mention however that with PyMDE, the weights and edges don't fully determine the embedding. The weights are parameters to distortion functions, which convey the extent to which two items are similar or dissimilar. Roughly speaking positive weights mean items are similar and should be close together, and negative weights mean that they're dissimilar and shouldn't be close (but need not be far). More details here:https: //pymde.org/mde/index.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2154#issuecomment-1062222262
https://github.com/scverse/scanpy/issues/2154#issuecomment-1062222262:305,Performance,perform,perform,305,"> In particular, I'm wondering if there might be a jax implementation as I'm a bit more keen on that as a dependency. I don't have any plans to switch from PyTorch to JAX. I did evaluate JAX when I started the project, but it wasn't mature enough back then. > I'd be interested in seeing how these graphs perform compared to the ones we get from UMAP. I'm not super clear on the semantics of the graphs obtained from UMAP. They might differ somewhat from the ones obtained from PyMDE. > Would this be the right way to retrieve the graphs for the object, or is distortions not the right field?. That's not quite right. Assuming that `mde` was constructed from `preserve_neighbors`, try this:. ```python3. weights = mde.distortion_function.weights.cpu().numpy(); edges = mde.edges.cpu().numpy(); n_items = mde.n_items. graph = pymde.Graph.from_edges(edges, weights, n_items).adjacency_matrix; ```. (API docs for `Graph` here: https://pymde.org/api/index.html#pymde.Graph. In the Graph class, distances/weights are used interchangeably.). I'll just mention however that with PyMDE, the weights and edges don't fully determine the embedding. The weights are parameters to distortion functions, which convey the extent to which two items are similar or dissimilar. Roughly speaking positive weights mean items are similar and should be close together, and negative weights mean that they're dissimilar and shouldn't be close (but need not be far). More details here:https: //pymde.org/mde/index.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2154#issuecomment-1062222262
https://github.com/scverse/scanpy/issues/2154#issuecomment-1062222262:366,Usability,clear,clear,366,"> In particular, I'm wondering if there might be a jax implementation as I'm a bit more keen on that as a dependency. I don't have any plans to switch from PyTorch to JAX. I did evaluate JAX when I started the project, but it wasn't mature enough back then. > I'd be interested in seeing how these graphs perform compared to the ones we get from UMAP. I'm not super clear on the semantics of the graphs obtained from UMAP. They might differ somewhat from the ones obtained from PyMDE. > Would this be the right way to retrieve the graphs for the object, or is distortions not the right field?. That's not quite right. Assuming that `mde` was constructed from `preserve_neighbors`, try this:. ```python3. weights = mde.distortion_function.weights.cpu().numpy(); edges = mde.edges.cpu().numpy(); n_items = mde.n_items. graph = pymde.Graph.from_edges(edges, weights, n_items).adjacency_matrix; ```. (API docs for `Graph` here: https://pymde.org/api/index.html#pymde.Graph. In the Graph class, distances/weights are used interchangeably.). I'll just mention however that with PyMDE, the weights and edges don't fully determine the embedding. The weights are parameters to distortion functions, which convey the extent to which two items are similar or dissimilar. Roughly speaking positive weights mean items are similar and should be close together, and negative weights mean that they're dissimilar and shouldn't be close (but need not be far). More details here:https: //pymde.org/mde/index.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2154#issuecomment-1062222262
https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:110,Availability,error,error,110,"Hello,I am having the same problem. ; When I run this:; ```python; from umap import UMAP; ```; It occurs this error. ```python; TypeError Traceback (most recent call last); File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\errors.py:823, in new_error_context(fmt_, *args, **kwargs); [822](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=821) try:; --> [823](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=822) yield; [824](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=823) except NumbaError as e:. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\lowering.py:293, in BaseLower.lower_block(self, block); [291](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/lowering.py?line=290) with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,; [292](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/lowering.py?line=291) loc=self.loc, errcls_=defaulterrcls):; --> [293](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/lowering.py?line=292) self.lower_inst(inst); [294](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/lowering.py?line=293) self.post_block(block). File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\lowering.py:438, in Lower.lower_inst(self, inst); [437](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/lowering.py?line=436) ty = self.typeof(inst.target.name); --> [438](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/lowering.py?line=437) val = self.lower_assign(ty, inst); [439](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/lowering.py?line=438) argidx = None. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\l",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659
https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:248,Availability,error,errors,248,"Hello,I am having the same problem. ; When I run this:; ```python; from umap import UMAP; ```; It occurs this error. ```python; TypeError Traceback (most recent call last); File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\errors.py:823, in new_error_context(fmt_, *args, **kwargs); [822](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=821) try:; --> [823](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=822) yield; [824](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=823) except NumbaError as e:. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\lowering.py:293, in BaseLower.lower_block(self, block); [291](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/lowering.py?line=290) with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,; [292](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/lowering.py?line=291) loc=self.loc, errcls_=defaulterrcls):; --> [293](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/lowering.py?line=292) self.lower_inst(inst); [294](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/lowering.py?line=293) self.post_block(block). File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\lowering.py:438, in Lower.lower_inst(self, inst); [437](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/lowering.py?line=436) ty = self.typeof(inst.target.name); --> [438](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/lowering.py?line=437) val = self.lower_assign(ty, inst); [439](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/lowering.py?line=438) argidx = None. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\l",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659
https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:394,Availability,error,errors,394,"Hello,I am having the same problem. ; When I run this:; ```python; from umap import UMAP; ```; It occurs this error. ```python; TypeError Traceback (most recent call last); File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\errors.py:823, in new_error_context(fmt_, *args, **kwargs); [822](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=821) try:; --> [823](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=822) yield; [824](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=823) except NumbaError as e:. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\lowering.py:293, in BaseLower.lower_block(self, block); [291](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/lowering.py?line=290) with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,; [292](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/lowering.py?line=291) loc=self.loc, errcls_=defaulterrcls):; --> [293](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/lowering.py?line=292) self.lower_inst(inst); [294](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/lowering.py?line=293) self.post_block(block). File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\lowering.py:438, in Lower.lower_inst(self, inst); [437](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/lowering.py?line=436) ty = self.typeof(inst.target.name); --> [438](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/lowering.py?line=437) val = self.lower_assign(ty, inst); [439](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/lowering.py?line=438) argidx = None. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\l",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659
https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:510,Availability,error,errors,510,"Hello,I am having the same problem. ; When I run this:; ```python; from umap import UMAP; ```; It occurs this error. ```python; TypeError Traceback (most recent call last); File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\errors.py:823, in new_error_context(fmt_, *args, **kwargs); [822](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=821) try:; --> [823](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=822) yield; [824](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=823) except NumbaError as e:. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\lowering.py:293, in BaseLower.lower_block(self, block); [291](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/lowering.py?line=290) with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,; [292](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/lowering.py?line=291) loc=self.loc, errcls_=defaulterrcls):; --> [293](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/lowering.py?line=292) self.lower_inst(inst); [294](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/lowering.py?line=293) self.post_block(block). File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\lowering.py:438, in Lower.lower_inst(self, inst); [437](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/lowering.py?line=436) ty = self.typeof(inst.target.name); --> [438](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/lowering.py?line=437) val = self.lower_assign(ty, inst); [439](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/lowering.py?line=438) argidx = None. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\l",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659
https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:623,Availability,error,errors,623,"Hello,I am having the same problem. ; When I run this:; ```python; from umap import UMAP; ```; It occurs this error. ```python; TypeError Traceback (most recent call last); File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\errors.py:823, in new_error_context(fmt_, *args, **kwargs); [822](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=821) try:; --> [823](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=822) yield; [824](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=823) except NumbaError as e:. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\lowering.py:293, in BaseLower.lower_block(self, block); [291](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/lowering.py?line=290) with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,; [292](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/lowering.py?line=291) loc=self.loc, errcls_=defaulterrcls):; --> [293](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/lowering.py?line=292) self.lower_inst(inst); [294](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/lowering.py?line=293) self.post_block(block). File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\lowering.py:438, in Lower.lower_inst(self, inst); [437](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/lowering.py?line=436) ty = self.typeof(inst.target.name); --> [438](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/lowering.py?line=437) val = self.lower_assign(ty, inst); [439](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/lowering.py?line=438) argidx = None. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\l",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659
https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:14657,Availability,error,errors,14657,"es/numba/core/decorators.py?line=218) disp.compile(sig); [220](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/decorators.py?line=219) disp.disable_compile(); [221](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/decorators.py?line=220) return disp. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\dispatcher.py:965, in Dispatcher.compile(self, sig); [963](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=962) with ev.trigger_event(""numba:compile"", data=ev_details):; [964](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=963) try:; --> [965](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=964) cres = self._compiler.compile(args, return_type); [966](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=965) except errors.ForceLiteralArg as e:; [967](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=966) def folded(args, kws):. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type); [124](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=123) def compile(self, args, return_type):; --> [125](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=124) status, retval = self._compile_cached(args, return_type); [126](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=125) if status:; [127](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=126) return retval. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\dispatcher.py:139, in _FunctionCompile",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659
https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:16206,Availability,error,errors,16206,"umba/core/dispatcher.py?line=124) status, retval = self._compile_cached(args, return_type); [126](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=125) if status:; [127](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=126) return retval. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type); [136](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=135) pass; [138](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=137) try:; --> [139](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=138) retval = self._compile_core(args, return_type); [140](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=139) except errors.TypingError as e:; [141](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=140) self._failed_cache[key] = e. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type); [149](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=148) flags = self._customize_flags(flags); [151](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=150) impl = self._get_implementation(args, {}); --> [152](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=151) cres = compiler.compile_extra(self.targetdescr.typing_context,; [153](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=152) self.targetdescr.target_context,; [154](file:///d%3A/Users/xiangrong1/Miniconda3/envs",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659
https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:17829,Availability,error,error,17829,"envs/py48/lib/site-packages/numba/core/dispatcher.py?line=151) cres = compiler.compile_extra(self.targetdescr.typing_context,; [153](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=152) self.targetdescr.target_context,; [154](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=153) impl,; [155](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=154) args=args, return_type=return_type,; [156](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=155) flags=flags, locals=self.locals,; [157](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=156) pipeline_class=self.pipeline_class); [158](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=157) # Check typing error if object mode is used; [159](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=158) if cres.typing_error is not None and not flags.enable_pyobject:. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); [669](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=668) """"""Compiler entry point; [670](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=669) ; [671](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=670) Parameter; (...); [689](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=688) compiler pipeline; [690](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=689) """"""; [691](file:///d%3A/Users/xiangrong1/Min",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659
https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:21418,Availability,avail,available,21418,"y48/lib/site-packages/numba/core/compiler.py?line=495) assert self.state.func_ir is None; --> [497](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=496) return self._compile_core(). File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\compiler.py:476, in CompilerBase._compile_core(self); [474](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=473) self.state.status.fail_reason = e; [475](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=474) if is_final_pipeline:; --> [476](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=475) raise e; [477](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=476) else:; [478](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=477) raise CompilerError(""All available pipelines exhausted""). File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\compiler.py:463, in CompilerBase._compile_core(self); [461](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=460) res = None; [462](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=461) try:; --> [463](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=462) pm.run(self.state); [464](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=463) if self.state.cr is not None:; [465](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=464) break. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\compiler_machinery.py:353, in PassManager.run(self, state); [350](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659
https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:32485,Availability,error,errors,32485,"rs/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=128) value = type(); [130](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=129) try:; --> [131](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=130) self.gen.throw(type, value, traceback); [132](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=131) except StopIteration as exc:; [133](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=132) # Suppress StopIteration *unless* it's the same exception that; [134](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=133) # was passed to throw(). This prevents a StopIteration; [135](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=134) # raised inside the ""with"" statement from being suppressed.; [136](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=135) return exc is not value. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\errors.py:837, in new_error_context(fmt_, *args, **kwargs); [835](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=834) else:; [836](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=835) tb = None; --> [837](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=836) raise newerr.with_traceback(tb); [838](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=837) elif use_new_style_errors():; [839](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=838) raise e. LoweringError: Failed in nopython mode pipeline (step: native lowering); Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x00000242239BD700> (trying to write member #1). File ""D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\umap\layouts.p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659
https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:32631,Availability,error,errors,32631,"Miniconda3/envs/py48/lib/contextlib.py?line=129) try:; --> [131](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=130) self.gen.throw(type, value, traceback); [132](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=131) except StopIteration as exc:; [133](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=132) # Suppress StopIteration *unless* it's the same exception that; [134](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=133) # was passed to throw(). This prevents a StopIteration; [135](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=134) # raised inside the ""with"" statement from being suppressed.; [136](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=135) return exc is not value. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\errors.py:837, in new_error_context(fmt_, *args, **kwargs); [835](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=834) else:; [836](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=835) tb = None; --> [837](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=836) raise newerr.with_traceback(tb); [838](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=837) elif use_new_style_errors():; [839](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=838) raise e. LoweringError: Failed in nopython mode pipeline (step: native lowering); Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x00000242239BD700> (trying to write member #1). File ""D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\umap\layouts.py"", line 53:; def rdist(x, y):; <source elided>; dim = x.shape[0]; for i in range(dim):; ^. During: lowering ""$20c",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659
https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:32744,Availability,error,errors,32744,"b.py?line=130) self.gen.throw(type, value, traceback); [132](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=131) except StopIteration as exc:; [133](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=132) # Suppress StopIteration *unless* it's the same exception that; [134](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=133) # was passed to throw(). This prevents a StopIteration; [135](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=134) # raised inside the ""with"" statement from being suppressed.; [136](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=135) return exc is not value. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\errors.py:837, in new_error_context(fmt_, *args, **kwargs); [835](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=834) else:; [836](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=835) tb = None; --> [837](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=836) raise newerr.with_traceback(tb); [838](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=837) elif use_new_style_errors():; [839](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=838) raise e. LoweringError: Failed in nopython mode pipeline (step: native lowering); Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x00000242239BD700> (trying to write member #1). File ""D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\umap\layouts.py"", line 53:; def rdist(x, y):; <source elided>; dim = x.shape[0]; for i in range(dim):; ^. During: lowering ""$20call_function.7 = call $16load_global.5(dim, func=$16load_global.5, args=[Var(dim, layouts.py:52)], kws=(), vararg=None, target=Non",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659
https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:32865,Availability,error,errors,32865,"iniconda3/envs/py48/lib/contextlib.py?line=131) except StopIteration as exc:; [133](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=132) # Suppress StopIteration *unless* it's the same exception that; [134](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=133) # was passed to throw(). This prevents a StopIteration; [135](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=134) # raised inside the ""with"" statement from being suppressed.; [136](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=135) return exc is not value. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\errors.py:837, in new_error_context(fmt_, *args, **kwargs); [835](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=834) else:; [836](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=835) tb = None; --> [837](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=836) raise newerr.with_traceback(tb); [838](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=837) elif use_new_style_errors():; [839](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=838) raise e. LoweringError: Failed in nopython mode pipeline (step: native lowering); Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x00000242239BD700> (trying to write member #1). File ""D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\umap\layouts.py"", line 53:; def rdist(x, y):; <source elided>; dim = x.shape[0]; for i in range(dim):; ^. During: lowering ""$20call_function.7 = call $16load_global.5(dim, func=$16load_global.5, args=[Var(dim, layouts.py:52)], kws=(), vararg=None, target=None)"" at D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\umap\layouts.py (53); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659
https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:33004,Availability,error,errors,33004,"iniconda3/envs/py48/lib/contextlib.py?line=131) except StopIteration as exc:; [133](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=132) # Suppress StopIteration *unless* it's the same exception that; [134](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=133) # was passed to throw(). This prevents a StopIteration; [135](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=134) # raised inside the ""with"" statement from being suppressed.; [136](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=135) return exc is not value. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\errors.py:837, in new_error_context(fmt_, *args, **kwargs); [835](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=834) else:; [836](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=835) tb = None; --> [837](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=836) raise newerr.with_traceback(tb); [838](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=837) elif use_new_style_errors():; [839](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=838) raise e. LoweringError: Failed in nopython mode pipeline (step: native lowering); Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x00000242239BD700> (trying to write member #1). File ""D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\umap\layouts.py"", line 53:; def rdist(x, y):; <source elided>; dim = x.shape[0]; for i in range(dim):; ^. During: lowering ""$20call_function.7 = call $16load_global.5(dim, func=$16load_global.5, args=[Var(dim, layouts.py:52)], kws=(), vararg=None, target=None)"" at D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\umap\layouts.py (53); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659
https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:33140,Availability,error,errors,33140,"iniconda3/envs/py48/lib/contextlib.py?line=131) except StopIteration as exc:; [133](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=132) # Suppress StopIteration *unless* it's the same exception that; [134](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=133) # was passed to throw(). This prevents a StopIteration; [135](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=134) # raised inside the ""with"" statement from being suppressed.; [136](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=135) return exc is not value. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\errors.py:837, in new_error_context(fmt_, *args, **kwargs); [835](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=834) else:; [836](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=835) tb = None; --> [837](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=836) raise newerr.with_traceback(tb); [838](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=837) elif use_new_style_errors():; [839](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=838) raise e. LoweringError: Failed in nopython mode pipeline (step: native lowering); Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x00000242239BD700> (trying to write member #1). File ""D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\umap\layouts.py"", line 53:; def rdist(x, y):; <source elided>; dim = x.shape[0]; for i in range(dim):; ^. During: lowering ""$20call_function.7 = call $16load_global.5(dim, func=$16load_global.5, args=[Var(dim, layouts.py:52)], kws=(), vararg=None, target=None)"" at D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\umap\layouts.py (53); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659
https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:18717,Deployability,pipeline,pipeline,18717,"48/lib/site-packages/numba/core/dispatcher.py?line=157) # Check typing error if object mode is used; [159](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=158) if cres.typing_error is not None and not flags.enable_pyobject:. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); [669](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=668) """"""Compiler entry point; [670](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=669) ; [671](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=670) Parameter; (...); [689](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=688) compiler pipeline; [690](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=689) """"""; [691](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=690) pipeline = pipeline_class(typingctx, targetctx, library,; [692](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=691) args, return_type, flags, locals); --> [693](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=692) return pipeline.compile_extra(func). File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\compiler.py:429, in CompilerBase.compile_extra(self, func); [427](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=426) self.state.lifted = (); [428](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=427) self.state.lifted_from = None; --> [429](file:///d%3A/Users/xiangrong1/Miniconda3/envs",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659
https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:18948,Deployability,pipeline,pipeline,18948,"able_pyobject:. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); [669](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=668) """"""Compiler entry point; [670](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=669) ; [671](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=670) Parameter; (...); [689](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=688) compiler pipeline; [690](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=689) """"""; [691](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=690) pipeline = pipeline_class(typingctx, targetctx, library,; [692](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=691) args, return_type, flags, locals); --> [693](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=692) return pipeline.compile_extra(func). File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\compiler.py:429, in CompilerBase.compile_extra(self, func); [427](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=426) self.state.lifted = (); [428](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=427) self.state.lifted_from = None; --> [429](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=428) return self._compile_bytecode(). File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\compiler.py:497, in CompilerBase._compile_bytecode(self); [493](file:///d%3A/Users/xiangrong1/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659
https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:19268,Deployability,pipeline,pipeline,19268,"ong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=668) """"""Compiler entry point; [670](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=669) ; [671](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=670) Parameter; (...); [689](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=688) compiler pipeline; [690](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=689) """"""; [691](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=690) pipeline = pipeline_class(typingctx, targetctx, library,; [692](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=691) args, return_type, flags, locals); --> [693](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=692) return pipeline.compile_extra(func). File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\compiler.py:429, in CompilerBase.compile_extra(self, func); [427](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=426) self.state.lifted = (); [428](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=427) self.state.lifted_from = None; --> [429](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=428) return self._compile_bytecode(). File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\compiler.py:497, in CompilerBase._compile_bytecode(self); [493](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=492) """"""; [494](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=493) Populate and run pipeline for bytecode input; [495](file:///",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659
https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:20220,Deployability,pipeline,pipeline,20220," pipeline.compile_extra(func). File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\compiler.py:429, in CompilerBase.compile_extra(self, func); [427](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=426) self.state.lifted = (); [428](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=427) self.state.lifted_from = None; --> [429](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=428) return self._compile_bytecode(). File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\compiler.py:497, in CompilerBase._compile_bytecode(self); [493](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=492) """"""; [494](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=493) Populate and run pipeline for bytecode input; [495](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=494) """"""; [496](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=495) assert self.state.func_ir is None; --> [497](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=496) return self._compile_core(). File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\compiler.py:476, in CompilerBase._compile_core(self); [474](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=473) self.state.status.fail_reason = e; [475](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=474) if is_final_pipeline:; --> [476](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=475) raise e; [477](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659
https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:21428,Deployability,pipeline,pipelines,21428,"y48/lib/site-packages/numba/core/compiler.py?line=495) assert self.state.func_ir is None; --> [497](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=496) return self._compile_core(). File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\compiler.py:476, in CompilerBase._compile_core(self); [474](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=473) self.state.status.fail_reason = e; [475](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=474) if is_final_pipeline:; --> [476](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=475) raise e; [477](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=476) else:; [478](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=477) raise CompilerError(""All available pipelines exhausted""). File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\compiler.py:463, in CompilerBase._compile_core(self); [461](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=460) res = None; [462](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=461) try:; --> [463](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=462) pm.run(self.state); [464](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=463) if self.state.cr is not None:; [465](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=464) break. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\compiler_machinery.py:353, in PassManager.run(self, state); [350](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659
https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:22478,Deployability,pipeline,pipeline,22478,"e\compiler.py:463, in CompilerBase._compile_core(self); [461](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=460) res = None; [462](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=461) try:; --> [463](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=462) pm.run(self.state); [464](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=463) if self.state.cr is not None:; [465](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=464) break. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\compiler_machinery.py:353, in PassManager.run(self, state); [350](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler_machinery.py?line=349) msg = ""Failed in %s mode pipeline (step: %s)"" % \; [351](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler_machinery.py?line=350) (self.pipeline_name, pass_desc); [352](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler_machinery.py?line=351) patched_exception = self._patch_error(msg, e); --> [353](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler_machinery.py?line=352) raise patched_exception. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\compiler_machinery.py:341, in PassManager.run(self, state); [339](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler_machinery.py?line=338) pass_inst = _pass_registry.get(pss).pass_inst; [340](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler_machinery.py?line=339) if isinstance(pass_inst, CompilerPass):; --> [341](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659
https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:33208,Deployability,pipeline,pipeline,33208,"iniconda3/envs/py48/lib/contextlib.py?line=131) except StopIteration as exc:; [133](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=132) # Suppress StopIteration *unless* it's the same exception that; [134](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=133) # was passed to throw(). This prevents a StopIteration; [135](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=134) # raised inside the ""with"" statement from being suppressed.; [136](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=135) return exc is not value. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\errors.py:837, in new_error_context(fmt_, *args, **kwargs); [835](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=834) else:; [836](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=835) tb = None; --> [837](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=836) raise newerr.with_traceback(tb); [838](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=837) elif use_new_style_errors():; [839](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=838) raise e. LoweringError: Failed in nopython mode pipeline (step: native lowering); Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x00000242239BD700> (trying to write member #1). File ""D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\umap\layouts.py"", line 53:; def rdist(x, y):; <source elided>; dim = x.shape[0]; for i in range(dim):; ^. During: lowering ""$20call_function.7 = call $16load_global.5(dim, func=$16load_global.5, args=[Var(dim, layouts.py:52)], kws=(), vararg=None, target=None)"" at D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\umap\layouts.py (53); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659
https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:12555,Energy Efficiency,Reduce,Reduced,12555,"da3/envs/py48/lib/site-packages/umap/layouts.py?line=31) cache=True,; [33](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/umap/layouts.py?line=32) locals={; [34](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/umap/layouts.py?line=33) ""result"": numba.types.float32,; [35](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/umap/layouts.py?line=34) ""diff"": numba.types.float32,; [36](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/umap/layouts.py?line=35) ""dim"": numba.types.int32,; [37](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/umap/layouts.py?line=36) },; [38](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/umap/layouts.py?line=37) ); ---> [39](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/umap/layouts.py?line=38) def rdist(x, y):; [40](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/umap/layouts.py?line=39) """"""Reduced Euclidean distance.; [41](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/umap/layouts.py?line=40) ; [42](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/umap/layouts.py?line=41) Parameters; (...); [49](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/umap/layouts.py?line=48) The squared euclidean distance between x and y; [50](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/umap/layouts.py?line=49) """"""; [51](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/umap/layouts.py?line=50) result = 0.0. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\decorators.py:219, in _jit.<locals>.wrapper(func); [217](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/decorators.py?line=216) with typeinfer.register_dispatcher(disp):; [218](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/decorators.py?line=217) for s",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659
https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:5259,Integrability,wrap,wrapper,5259,"py?line=1129) res = impl(self.builder, argvals, self.loc); [1131](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/lowering.py?line=1130) return res. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\base.py:1201, in _wrap_impl.__call__(self, builder, args, loc); [1200](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/base.py?line=1199) def __call__(self, builder, args, loc=None):; -> [1201](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/base.py?line=1200) res = self._imp(self._context, builder, self._sig, args, loc=loc); [1202](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/base.py?line=1201) self._context.add_linking_libs(getattr(self, 'libs', ())). File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\base.py:1231, in _wrap_missing_loc.__call__.<locals>.wrapper(*args, **kwargs); [1230](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/base.py?line=1229) kwargs.pop('loc') # drop unused loc; -> [1231](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/base.py?line=1230) return fn(*args, **kwargs). File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\cpython\rangeobj.py:40, in make_range_impl.<locals>.range1_impl(context, builder, sig, args); [39](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/cpython/rangeobj.py?line=38) state.start = context.get_constant(int_type, 0); ---> [40](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/cpython/rangeobj.py?line=39) state.stop = stop; [41](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/cpython/rangeobj.py?line=40) state.step = context.get_constant(int_type, 1). File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\cgutils.py:164, in _StructProxy.__setattr__(self, field, value); [",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659
https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:13278,Integrability,wrap,wrapper,13278,"> [39](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/umap/layouts.py?line=38) def rdist(x, y):; [40](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/umap/layouts.py?line=39) """"""Reduced Euclidean distance.; [41](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/umap/layouts.py?line=40) ; [42](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/umap/layouts.py?line=41) Parameters; (...); [49](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/umap/layouts.py?line=48) The squared euclidean distance between x and y; [50](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/umap/layouts.py?line=49) """"""; [51](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/umap/layouts.py?line=50) result = 0.0. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\decorators.py:219, in _jit.<locals>.wrapper(func); [217](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/decorators.py?line=216) with typeinfer.register_dispatcher(disp):; [218](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/decorators.py?line=217) for sig in sigs:; --> [219](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/decorators.py?line=218) disp.compile(sig); [220](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/decorators.py?line=219) disp.disable_compile(); [221](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/decorators.py?line=220) return disp. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\dispatcher.py:965, in Dispatcher.compile(self, sig); [963](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=962) with ev.trigger_event(""numba:compile"", data=ev_details):; [964](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659
https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:24165,Integrability,wrap,wraps,24165,"ass_inst = _pass_registry.get(pss).pass_inst; [340](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler_machinery.py?line=339) if isinstance(pass_inst, CompilerPass):; --> [341](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler_machinery.py?line=340) self._runPass(idx, pass_inst, state); [342](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler_machinery.py?line=341) else:; [343](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler_machinery.py?line=342) raise BaseException(""Legacy pass in use""). File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs); [32](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler_lock.py?line=31) @functools.wraps(func); [33](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler_lock.py?line=32) def _acquire_compile_lock(*args, **kwargs):; [34](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler_lock.py?line=33) with self:; ---> [35](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler_lock.py?line=34) return func(*args, **kwargs). File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state); [294](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler_machinery.py?line=293) mutated |= check(pss.run_initialization, internal_state); [295](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler_machinery.py?line=294) with SimpleTimer() as pass_time:; --> [296](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler_machinery.py?line=295) mutated",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659
https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:11618,Performance,cache,cache,11618,"t import NNDescent; [48](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/umap/umap_.py?line=47) from pynndescent.distances import named_distances as pynn_named_distances. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\umap\layouts.py:39, in <module>; [25](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/umap/layouts.py?line=24) else:; [26](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/umap/layouts.py?line=25) return val; [29](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/umap/layouts.py?line=28) @numba.njit(; [30](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/umap/layouts.py?line=29) ""f4(f4[::1],f4[::1])"",; [31](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/umap/layouts.py?line=30) fastmath=True,; [32](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/umap/layouts.py?line=31) cache=True,; [33](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/umap/layouts.py?line=32) locals={; [34](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/umap/layouts.py?line=33) ""result"": numba.types.float32,; [35](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/umap/layouts.py?line=34) ""diff"": numba.types.float32,; [36](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/umap/layouts.py?line=35) ""dim"": numba.types.int32,; [37](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/umap/layouts.py?line=36) },; [38](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/umap/layouts.py?line=37) ); ---> [39](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/umap/layouts.py?line=38) def rdist(x, y):; [40](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/umap/layouts.py?line=39) """"""Reduced Euclidean distance.; [41](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/umap",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659
https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:20470,Testability,assert,assert,20470,"Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=426) self.state.lifted = (); [428](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=427) self.state.lifted_from = None; --> [429](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=428) return self._compile_bytecode(). File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\compiler.py:497, in CompilerBase._compile_bytecode(self); [493](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=492) """"""; [494](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=493) Populate and run pipeline for bytecode input; [495](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=494) """"""; [496](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=495) assert self.state.func_ir is None; --> [497](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=496) return self._compile_core(). File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\compiler.py:476, in CompilerBase._compile_core(self); [474](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=473) self.state.status.fail_reason = e; [475](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=474) if is_final_pipeline:; --> [476](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=475) raise e; [477](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=476) else:; [478](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=477) raise CompilerError(""All available pipelines exhausted""). File D:\Users\xiang",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659
https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:8685,Usability,simpl,simplefilter,8685,"cgutils.py?line=192) index=index)); [194](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/cgutils.py?line=193) self._builder.store(value, ptr). TypeError: Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x00000242239BD700> (trying to write member #1). During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last); e:\Drosophila\ST\04.yao\E8-10_b_analysis\E8-10_b_analysis\8_cellbin_clustering\cellbin_scsq.ipynb Cell 10' in <cell line: 1>(); ----> [1](vscode-notebook-cell:/e%3A/Drosophila/ST/04.yao/E8-10_b_analysis/E8-10_b_analysis/8_cellbin_clustering/cellbin_scsq.ipynb#ch0000016?line=0) from umap import UMAP. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\umap\__init__.py:2, in <module>; [1](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/umap/__init__.py?line=0) from warnings import warn, catch_warnings, simplefilter; ----> [2](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/umap/__init__.py?line=1) from .umap_ import UMAP; [4](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/umap/__init__.py?line=3) try:; [5](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/umap/__init__.py?line=4) with catch_warnings():. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\umap\umap_.py:41, in <module>; [34](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/umap/umap_.py?line=33) from umap.utils import (; [35](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/umap/umap_.py?line=34) submatrix,; [36](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/umap/umap_.py?line=35) ts,; [37](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/umap/umap_.py?line=36) csr_unique,; [38](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/umap/umap_.py?line=37) fast_knn_indices,; [39",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659
https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:25063,Usability,Simpl,SimpleTimer,25063,"core/compiler_lock.py?line=31) @functools.wraps(func); [33](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler_lock.py?line=32) def _acquire_compile_lock(*args, **kwargs):; [34](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler_lock.py?line=33) with self:; ---> [35](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler_lock.py?line=34) return func(*args, **kwargs). File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state); [294](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler_machinery.py?line=293) mutated |= check(pss.run_initialization, internal_state); [295](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler_machinery.py?line=294) with SimpleTimer() as pass_time:; --> [296](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler_machinery.py?line=295) mutated |= check(pss.run_pass, internal_state); [297](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler_machinery.py?line=296) with SimpleTimer() as finalize_time:; [298](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler_machinery.py?line=297) mutated |= check(pss.run_finalizer, internal_state). File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state); [268](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler_machinery.py?line=267) def check(func, compiler_state):; --> [269](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler_machinery.py?line=268) mangled = func(compiler_state); [270](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/sit",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659
https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:25385,Usability,Simpl,SimpleTimer,25385,"with self:; ---> [35](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler_lock.py?line=34) return func(*args, **kwargs). File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state); [294](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler_machinery.py?line=293) mutated |= check(pss.run_initialization, internal_state); [295](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler_machinery.py?line=294) with SimpleTimer() as pass_time:; --> [296](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler_machinery.py?line=295) mutated |= check(pss.run_pass, internal_state); [297](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler_machinery.py?line=296) with SimpleTimer() as finalize_time:; [298](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler_machinery.py?line=297) mutated |= check(pss.run_finalizer, internal_state). File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state); [268](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler_machinery.py?line=267) def check(func, compiler_state):; --> [269](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler_machinery.py?line=268) mangled = func(compiler_state); [270](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler_machinery.py?line=269) if mangled not in (True, False):; [271](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler_machinery.py?line=270) msg = (""CompilerPass implementations should return True/False. ""; [272](file:///d%3A/Users/xiangrong1/Miniconda3/env",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659
https://github.com/scverse/scanpy/issues/2162#issuecomment-1055535384:128,Deployability,integrat,integrating,128,Hi!. If you used a neural network approach you could use scArches to leverage transfer learning to map things across without re-integrating (only minimal additional training done there). You could also map into the embedded space using `sc.tl.ingest` for example. But there is always the danger that there is a residual batch effect that cannot be removed without de-novo integration.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162#issuecomment-1055535384
https://github.com/scverse/scanpy/issues/2162#issuecomment-1055535384:372,Deployability,integrat,integration,372,Hi!. If you used a neural network approach you could use scArches to leverage transfer learning to map things across without re-integrating (only minimal additional training done there). You could also map into the embedded space using `sc.tl.ingest` for example. But there is always the danger that there is a residual batch effect that cannot be removed without de-novo integration.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162#issuecomment-1055535384
https://github.com/scverse/scanpy/issues/2162#issuecomment-1055535384:128,Integrability,integrat,integrating,128,Hi!. If you used a neural network approach you could use scArches to leverage transfer learning to map things across without re-integrating (only minimal additional training done there). You could also map into the embedded space using `sc.tl.ingest` for example. But there is always the danger that there is a residual batch effect that cannot be removed without de-novo integration.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162#issuecomment-1055535384
https://github.com/scverse/scanpy/issues/2162#issuecomment-1055535384:372,Integrability,integrat,integration,372,Hi!. If you used a neural network approach you could use scArches to leverage transfer learning to map things across without re-integrating (only minimal additional training done there). You could also map into the embedded space using `sc.tl.ingest` for example. But there is always the danger that there is a residual batch effect that cannot be removed without de-novo integration.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162#issuecomment-1055535384
https://github.com/scverse/scanpy/issues/2162#issuecomment-1055535384:87,Usability,learn,learning,87,Hi!. If you used a neural network approach you could use scArches to leverage transfer learning to map things across without re-integrating (only minimal additional training done there). You could also map into the embedded space using `sc.tl.ingest` for example. But there is always the danger that there is a residual batch effect that cannot be removed without de-novo integration.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162#issuecomment-1055535384
https://github.com/scverse/scanpy/issues/2162#issuecomment-1059551919:83,Deployability,integrat,integrate,83,"Jumping in on this conversation to ask a related question - I'm using Scanorama to integrate some datasets and generate an aligned low-dimensional embedding. I then subset the data to only look at specific clusters and want to re-make the UMAP/t-SNE plot. Do you usually re-do the integration to generate a new low-dimensional embedding matrix with Scanorama for the subsetted data? I know you can technically subset the original low-dimensional embedding matrix, but I thought it's preferable to re-do the embedding when you have a different subset of cells to capture more of the variance between those cells (re-select HVGs, etc). Any advice would be welcome - thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162#issuecomment-1059551919
https://github.com/scverse/scanpy/issues/2162#issuecomment-1059551919:281,Deployability,integrat,integration,281,"Jumping in on this conversation to ask a related question - I'm using Scanorama to integrate some datasets and generate an aligned low-dimensional embedding. I then subset the data to only look at specific clusters and want to re-make the UMAP/t-SNE plot. Do you usually re-do the integration to generate a new low-dimensional embedding matrix with Scanorama for the subsetted data? I know you can technically subset the original low-dimensional embedding matrix, but I thought it's preferable to re-do the embedding when you have a different subset of cells to capture more of the variance between those cells (re-select HVGs, etc). Any advice would be welcome - thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162#issuecomment-1059551919
https://github.com/scverse/scanpy/issues/2162#issuecomment-1059551919:83,Integrability,integrat,integrate,83,"Jumping in on this conversation to ask a related question - I'm using Scanorama to integrate some datasets and generate an aligned low-dimensional embedding. I then subset the data to only look at specific clusters and want to re-make the UMAP/t-SNE plot. Do you usually re-do the integration to generate a new low-dimensional embedding matrix with Scanorama for the subsetted data? I know you can technically subset the original low-dimensional embedding matrix, but I thought it's preferable to re-do the embedding when you have a different subset of cells to capture more of the variance between those cells (re-select HVGs, etc). Any advice would be welcome - thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162#issuecomment-1059551919
https://github.com/scverse/scanpy/issues/2162#issuecomment-1059551919:281,Integrability,integrat,integration,281,"Jumping in on this conversation to ask a related question - I'm using Scanorama to integrate some datasets and generate an aligned low-dimensional embedding. I then subset the data to only look at specific clusters and want to re-make the UMAP/t-SNE plot. Do you usually re-do the integration to generate a new low-dimensional embedding matrix with Scanorama for the subsetted data? I know you can technically subset the original low-dimensional embedding matrix, but I thought it's preferable to re-do the embedding when you have a different subset of cells to capture more of the variance between those cells (re-select HVGs, etc). Any advice would be welcome - thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162#issuecomment-1059551919
https://github.com/scverse/scanpy/issues/2162#issuecomment-1060433444:201,Usability,learn,learning,201,"Hey @a-munoz-rojas,. I normally wouldn't redo the batch correction. That can go wrong (or better tbh)... for scanorama it could be better, but for DL-based methods you would have fewer data points for learning the difference between batch and bio effects. So unless you have a large dataset, it might generate problems for those methods. Therefore I try to stay consistent.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162#issuecomment-1060433444
https://github.com/scverse/scanpy/issues/2162#issuecomment-1061085766:349,Availability,down,downstream,349,"Hi @LuckyMD - thanks for your reply! Yeah that makes sense. I'm performing these corrections using a subset of highly variable genes, so I guess to ""make up"" for the loss of ""true"" HVGs in the new subclusters of cells I could select a higher number of HVGs to perform the original alignment? As well as maybe using a larger number of components for downstream applications from the low-dimensional embedding outputted by the original alignment. Does that make sense to you?. One more question - when performing differential gene expression analysis, what is your preferred pipeline/method when using aligned datasets? I generally do not perform the correction on the gene expression matrix when aligning, and I think doing DE with corrected matrices is not as common. So maybe other methods that use batch as a covariate would be preferable (e.g. diffxpy or others?) Would really appreciate any suggestions here!. PS. many congratulations on the benchmarking integration paper in Nature Methods - excellent work and very useful resource for the field!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162#issuecomment-1061085766
https://github.com/scverse/scanpy/issues/2162#issuecomment-1061085766:573,Deployability,pipeline,pipeline,573,"Hi @LuckyMD - thanks for your reply! Yeah that makes sense. I'm performing these corrections using a subset of highly variable genes, so I guess to ""make up"" for the loss of ""true"" HVGs in the new subclusters of cells I could select a higher number of HVGs to perform the original alignment? As well as maybe using a larger number of components for downstream applications from the low-dimensional embedding outputted by the original alignment. Does that make sense to you?. One more question - when performing differential gene expression analysis, what is your preferred pipeline/method when using aligned datasets? I generally do not perform the correction on the gene expression matrix when aligning, and I think doing DE with corrected matrices is not as common. So maybe other methods that use batch as a covariate would be preferable (e.g. diffxpy or others?) Would really appreciate any suggestions here!. PS. many congratulations on the benchmarking integration paper in Nature Methods - excellent work and very useful resource for the field!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162#issuecomment-1061085766
https://github.com/scverse/scanpy/issues/2162#issuecomment-1061085766:959,Deployability,integrat,integration,959,"Hi @LuckyMD - thanks for your reply! Yeah that makes sense. I'm performing these corrections using a subset of highly variable genes, so I guess to ""make up"" for the loss of ""true"" HVGs in the new subclusters of cells I could select a higher number of HVGs to perform the original alignment? As well as maybe using a larger number of components for downstream applications from the low-dimensional embedding outputted by the original alignment. Does that make sense to you?. One more question - when performing differential gene expression analysis, what is your preferred pipeline/method when using aligned datasets? I generally do not perform the correction on the gene expression matrix when aligning, and I think doing DE with corrected matrices is not as common. So maybe other methods that use batch as a covariate would be preferable (e.g. diffxpy or others?) Would really appreciate any suggestions here!. PS. many congratulations on the benchmarking integration paper in Nature Methods - excellent work and very useful resource for the field!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162#issuecomment-1061085766
https://github.com/scverse/scanpy/issues/2162#issuecomment-1061085766:959,Integrability,integrat,integration,959,"Hi @LuckyMD - thanks for your reply! Yeah that makes sense. I'm performing these corrections using a subset of highly variable genes, so I guess to ""make up"" for the loss of ""true"" HVGs in the new subclusters of cells I could select a higher number of HVGs to perform the original alignment? As well as maybe using a larger number of components for downstream applications from the low-dimensional embedding outputted by the original alignment. Does that make sense to you?. One more question - when performing differential gene expression analysis, what is your preferred pipeline/method when using aligned datasets? I generally do not perform the correction on the gene expression matrix when aligning, and I think doing DE with corrected matrices is not as common. So maybe other methods that use batch as a covariate would be preferable (e.g. diffxpy or others?) Would really appreciate any suggestions here!. PS. many congratulations on the benchmarking integration paper in Nature Methods - excellent work and very useful resource for the field!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162#issuecomment-1061085766
https://github.com/scverse/scanpy/issues/2162#issuecomment-1061085766:118,Modifiability,variab,variable,118,"Hi @LuckyMD - thanks for your reply! Yeah that makes sense. I'm performing these corrections using a subset of highly variable genes, so I guess to ""make up"" for the loss of ""true"" HVGs in the new subclusters of cells I could select a higher number of HVGs to perform the original alignment? As well as maybe using a larger number of components for downstream applications from the low-dimensional embedding outputted by the original alignment. Does that make sense to you?. One more question - when performing differential gene expression analysis, what is your preferred pipeline/method when using aligned datasets? I generally do not perform the correction on the gene expression matrix when aligning, and I think doing DE with corrected matrices is not as common. So maybe other methods that use batch as a covariate would be preferable (e.g. diffxpy or others?) Would really appreciate any suggestions here!. PS. many congratulations on the benchmarking integration paper in Nature Methods - excellent work and very useful resource for the field!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162#issuecomment-1061085766
https://github.com/scverse/scanpy/issues/2162#issuecomment-1061085766:64,Performance,perform,performing,64,"Hi @LuckyMD - thanks for your reply! Yeah that makes sense. I'm performing these corrections using a subset of highly variable genes, so I guess to ""make up"" for the loss of ""true"" HVGs in the new subclusters of cells I could select a higher number of HVGs to perform the original alignment? As well as maybe using a larger number of components for downstream applications from the low-dimensional embedding outputted by the original alignment. Does that make sense to you?. One more question - when performing differential gene expression analysis, what is your preferred pipeline/method when using aligned datasets? I generally do not perform the correction on the gene expression matrix when aligning, and I think doing DE with corrected matrices is not as common. So maybe other methods that use batch as a covariate would be preferable (e.g. diffxpy or others?) Would really appreciate any suggestions here!. PS. many congratulations on the benchmarking integration paper in Nature Methods - excellent work and very useful resource for the field!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162#issuecomment-1061085766
https://github.com/scverse/scanpy/issues/2162#issuecomment-1061085766:260,Performance,perform,perform,260,"Hi @LuckyMD - thanks for your reply! Yeah that makes sense. I'm performing these corrections using a subset of highly variable genes, so I guess to ""make up"" for the loss of ""true"" HVGs in the new subclusters of cells I could select a higher number of HVGs to perform the original alignment? As well as maybe using a larger number of components for downstream applications from the low-dimensional embedding outputted by the original alignment. Does that make sense to you?. One more question - when performing differential gene expression analysis, what is your preferred pipeline/method when using aligned datasets? I generally do not perform the correction on the gene expression matrix when aligning, and I think doing DE with corrected matrices is not as common. So maybe other methods that use batch as a covariate would be preferable (e.g. diffxpy or others?) Would really appreciate any suggestions here!. PS. many congratulations on the benchmarking integration paper in Nature Methods - excellent work and very useful resource for the field!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162#issuecomment-1061085766
https://github.com/scverse/scanpy/issues/2162#issuecomment-1061085766:500,Performance,perform,performing,500,"Hi @LuckyMD - thanks for your reply! Yeah that makes sense. I'm performing these corrections using a subset of highly variable genes, so I guess to ""make up"" for the loss of ""true"" HVGs in the new subclusters of cells I could select a higher number of HVGs to perform the original alignment? As well as maybe using a larger number of components for downstream applications from the low-dimensional embedding outputted by the original alignment. Does that make sense to you?. One more question - when performing differential gene expression analysis, what is your preferred pipeline/method when using aligned datasets? I generally do not perform the correction on the gene expression matrix when aligning, and I think doing DE with corrected matrices is not as common. So maybe other methods that use batch as a covariate would be preferable (e.g. diffxpy or others?) Would really appreciate any suggestions here!. PS. many congratulations on the benchmarking integration paper in Nature Methods - excellent work and very useful resource for the field!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162#issuecomment-1061085766
https://github.com/scverse/scanpy/issues/2162#issuecomment-1061085766:637,Performance,perform,perform,637,"Hi @LuckyMD - thanks for your reply! Yeah that makes sense. I'm performing these corrections using a subset of highly variable genes, so I guess to ""make up"" for the loss of ""true"" HVGs in the new subclusters of cells I could select a higher number of HVGs to perform the original alignment? As well as maybe using a larger number of components for downstream applications from the low-dimensional embedding outputted by the original alignment. Does that make sense to you?. One more question - when performing differential gene expression analysis, what is your preferred pipeline/method when using aligned datasets? I generally do not perform the correction on the gene expression matrix when aligning, and I think doing DE with corrected matrices is not as common. So maybe other methods that use batch as a covariate would be preferable (e.g. diffxpy or others?) Would really appreciate any suggestions here!. PS. many congratulations on the benchmarking integration paper in Nature Methods - excellent work and very useful resource for the field!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162#issuecomment-1061085766
https://github.com/scverse/scanpy/issues/2162#issuecomment-1061085766:946,Testability,benchmark,benchmarking,946,"Hi @LuckyMD - thanks for your reply! Yeah that makes sense. I'm performing these corrections using a subset of highly variable genes, so I guess to ""make up"" for the loss of ""true"" HVGs in the new subclusters of cells I could select a higher number of HVGs to perform the original alignment? As well as maybe using a larger number of components for downstream applications from the low-dimensional embedding outputted by the original alignment. Does that make sense to you?. One more question - when performing differential gene expression analysis, what is your preferred pipeline/method when using aligned datasets? I generally do not perform the correction on the gene expression matrix when aligning, and I think doing DE with corrected matrices is not as common. So maybe other methods that use batch as a covariate would be preferable (e.g. diffxpy or others?) Would really appreciate any suggestions here!. PS. many congratulations on the benchmarking integration paper in Nature Methods - excellent work and very useful resource for the field!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162#issuecomment-1061085766
https://github.com/scverse/scanpy/issues/2162#issuecomment-1061642536:479,Integrability,depend,depend,479,"Thanks a lot @a-munoz-rojas!. For the DE approach, I would go with the same thing you suggest. I would definitely not do DE testing on the corrected data (violation of distributional assumptions, potential overcorrection of background variation leading to false significant results). . Regarding altering the number of HVGs or latent dimensions... this is difficult to say in general. I would normally err on the higher side of the number of HVGs, but the latent dimensions will depend heavily on the complexity of the dataset i would imagine. I don't think it's possible to give a general recommendation there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162#issuecomment-1061642536
https://github.com/scverse/scanpy/issues/2162#issuecomment-1061642536:124,Testability,test,testing,124,"Thanks a lot @a-munoz-rojas!. For the DE approach, I would go with the same thing you suggest. I would definitely not do DE testing on the corrected data (violation of distributional assumptions, potential overcorrection of background variation leading to false significant results). . Regarding altering the number of HVGs or latent dimensions... this is difficult to say in general. I would normally err on the higher side of the number of HVGs, but the latent dimensions will depend heavily on the complexity of the dataset i would imagine. I don't think it's possible to give a general recommendation there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162#issuecomment-1061642536
https://github.com/scverse/scanpy/issues/2162#issuecomment-1061820029:119,Availability,robust,robust,119,"Great, thanks @LuckyMD! That makes a lot of sense. Aside from diffxpy, are there other packages you recommend for more robust DE approaches in these (or related) scenarios? Thanks again for your advice - and sorry for hijacking this conversation!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162#issuecomment-1061820029
https://github.com/scverse/scanpy/issues/2163#issuecomment-2191634706:680,Deployability,update,updated,680,"I also recently encountered this issue. I've dug into the problem a little bit and for me the cause seems to be that the sc.pp.scale function introduces the NaN values. This occurs for columns which show very little variance and are almost constant. According to the current documentation this should not be the current expected behaviour though and should only (possibly) occur in future versions: . `Variables (genes) that do not display any variation (are constant across all observations) are retained and (for zero_center==True) set to 0 during this operation. In the future, they might be set to NaNs.`. So I'm not sure if this is a bug or if the documentation has not been updated yet. . I've currently circumvented the issue by scaling in sklearn (which retains 0s instead of NaNs) and manually loading the scaled results into my adata object as this is the behaviour I would like for my dataset. In case my example dataset would be helpful let me know then I can share it with you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2163#issuecomment-2191634706
https://github.com/scverse/scanpy/issues/2163#issuecomment-2191634706:402,Modifiability,Variab,Variables,402,"I also recently encountered this issue. I've dug into the problem a little bit and for me the cause seems to be that the sc.pp.scale function introduces the NaN values. This occurs for columns which show very little variance and are almost constant. According to the current documentation this should not be the current expected behaviour though and should only (possibly) occur in future versions: . `Variables (genes) that do not display any variation (are constant across all observations) are retained and (for zero_center==True) set to 0 during this operation. In the future, they might be set to NaNs.`. So I'm not sure if this is a bug or if the documentation has not been updated yet. . I've currently circumvented the issue by scaling in sklearn (which retains 0s instead of NaNs) and manually loading the scaled results into my adata object as this is the behaviour I would like for my dataset. In case my example dataset would be helpful let me know then I can share it with you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2163#issuecomment-2191634706
https://github.com/scverse/scanpy/issues/2163#issuecomment-2191634706:803,Performance,load,loading,803,"I also recently encountered this issue. I've dug into the problem a little bit and for me the cause seems to be that the sc.pp.scale function introduces the NaN values. This occurs for columns which show very little variance and are almost constant. According to the current documentation this should not be the current expected behaviour though and should only (possibly) occur in future versions: . `Variables (genes) that do not display any variation (are constant across all observations) are retained and (for zero_center==True) set to 0 during this operation. In the future, they might be set to NaNs.`. So I'm not sure if this is a bug or if the documentation has not been updated yet. . I've currently circumvented the issue by scaling in sklearn (which retains 0s instead of NaNs) and manually loading the scaled results into my adata object as this is the behaviour I would like for my dataset. In case my example dataset would be helpful let me know then I can share it with you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2163#issuecomment-2191634706
https://github.com/scverse/scanpy/issues/2163#issuecomment-2191785768:189,Performance,perform,perform,189,"Hey, thanks for the description - yes your example dataset would be very helpful - if you could post a small code snippet here which generates this dataset and shows the specific steps you perform that would be great. If you cannot produce the dataset in a script, you could also send a link to the dataset (if its public or synthetic, making sure you're allowed to share) :). In both cases, sending a script here we can run too is a great help!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2163#issuecomment-2191785768
https://github.com/scverse/scanpy/issues/2163#issuecomment-2191814375:235,Performance,load,load,235,"Sure thing. I've dumped a couple of example entries into a numpy file and attached it below as a zip. You can replicate the behaviour with the following code. ```; import numpy; import scanpy as sc; import anndata as ad. features = np.load(""example_features.npy""). #perform scaling in sklearn; from sklearn.preprocessing import StandardScaler; scaler = StandardScaler(); scaled = scaler.fit_transform(features.copy()). print(np.isnan(scaled).sum()). #perform scaling in scanpy with the default settings; adata = ad.AnnData(features); sc.pp.scale(adata). print(np.isnan(adata.X).sum()); ```. For me this results in: . <img width=""477"" alt=""Screenshot 2024-06-26 at 16 08 41"" src=""https://github.com/scverse/scanpy/assets/15019107/806d4b70-faf2-4dce-84fc-575cd86c21f6"">. [example_features.npy.zip](https://github.com/user-attachments/files/15990483/example_features.npy.zip)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2163#issuecomment-2191814375
https://github.com/scverse/scanpy/issues/2163#issuecomment-2191814375:266,Performance,perform,perform,266,"Sure thing. I've dumped a couple of example entries into a numpy file and attached it below as a zip. You can replicate the behaviour with the following code. ```; import numpy; import scanpy as sc; import anndata as ad. features = np.load(""example_features.npy""). #perform scaling in sklearn; from sklearn.preprocessing import StandardScaler; scaler = StandardScaler(); scaled = scaler.fit_transform(features.copy()). print(np.isnan(scaled).sum()). #perform scaling in scanpy with the default settings; adata = ad.AnnData(features); sc.pp.scale(adata). print(np.isnan(adata.X).sum()); ```. For me this results in: . <img width=""477"" alt=""Screenshot 2024-06-26 at 16 08 41"" src=""https://github.com/scverse/scanpy/assets/15019107/806d4b70-faf2-4dce-84fc-575cd86c21f6"">. [example_features.npy.zip](https://github.com/user-attachments/files/15990483/example_features.npy.zip)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2163#issuecomment-2191814375
https://github.com/scverse/scanpy/issues/2163#issuecomment-2191814375:451,Performance,perform,perform,451,"Sure thing. I've dumped a couple of example entries into a numpy file and attached it below as a zip. You can replicate the behaviour with the following code. ```; import numpy; import scanpy as sc; import anndata as ad. features = np.load(""example_features.npy""). #perform scaling in sklearn; from sklearn.preprocessing import StandardScaler; scaler = StandardScaler(); scaled = scaler.fit_transform(features.copy()). print(np.isnan(scaled).sum()). #perform scaling in scanpy with the default settings; adata = ad.AnnData(features); sc.pp.scale(adata). print(np.isnan(adata.X).sum()); ```. For me this results in: . <img width=""477"" alt=""Screenshot 2024-06-26 at 16 08 41"" src=""https://github.com/scverse/scanpy/assets/15019107/806d4b70-faf2-4dce-84fc-575cd86c21f6"">. [example_features.npy.zip](https://github.com/user-attachments/files/15990483/example_features.npy.zip)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2163#issuecomment-2191814375
https://github.com/scverse/scanpy/issues/2163#issuecomment-2199782706:806,Usability,learn,learn,806,"Thanks, this is very helpful to pinpoint what is happening!. So what's going on here is that within one gene (column), all cells (rows) have the almost same float value.; This causes the variance per gene to be ~0, usually just a tiny value, in this dataset e.g. on the order of 1e-21.; Handling such tiny values, tiny offsets due to numerics can yield negative values for the variance. When doing np.sqrt() [here](https://github.com/scverse/scanpy/blob/fdfb9a1a48d480a30c23e5f14499a18a6388e418/src/scanpy/preprocessing/_scale.py#L186C5-L186C23) on such a nan, this yields this entire gene column to obtain nans. From our side, this could be addressed by considering to set such tiny negative values to 0. `sklearn` circumvents this by directly [computing the standard deviation](https://github.com/scikit-learn/scikit-learn/blob/2621573e60c295a435c62137c65ae787bf438e61/sklearn/preprocessing/_data.py#L248) from numpy, which likely has such a mechanism within it directly. However, trying to ""scale"" a feature of a constant value should be omitted in the first place very likely: as scaling involves dividing by standard deviation (which is ~0 then), the resulting numbers obtained are not actual biology, but just artifacts from a stability correction. I'd assume that in scRNAseq, this typically is a gene which is never observed (that is, 0 all the time), and as such could be filtered for in the preprocessing with e.g. `sc.pp.filter_genes(adata, min_counts=...)`, where `a` would be a number > 0. We might consider to raise a warning here though, as just introducing the nans without further comment can be quite confusing... What do you think about this @sophiamaedler?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2163#issuecomment-2199782706
https://github.com/scverse/scanpy/issues/2163#issuecomment-2199782706:819,Usability,learn,learn,819,"Thanks, this is very helpful to pinpoint what is happening!. So what's going on here is that within one gene (column), all cells (rows) have the almost same float value.; This causes the variance per gene to be ~0, usually just a tiny value, in this dataset e.g. on the order of 1e-21.; Handling such tiny values, tiny offsets due to numerics can yield negative values for the variance. When doing np.sqrt() [here](https://github.com/scverse/scanpy/blob/fdfb9a1a48d480a30c23e5f14499a18a6388e418/src/scanpy/preprocessing/_scale.py#L186C5-L186C23) on such a nan, this yields this entire gene column to obtain nans. From our side, this could be addressed by considering to set such tiny negative values to 0. `sklearn` circumvents this by directly [computing the standard deviation](https://github.com/scikit-learn/scikit-learn/blob/2621573e60c295a435c62137c65ae787bf438e61/sklearn/preprocessing/_data.py#L248) from numpy, which likely has such a mechanism within it directly. However, trying to ""scale"" a feature of a constant value should be omitted in the first place very likely: as scaling involves dividing by standard deviation (which is ~0 then), the resulting numbers obtained are not actual biology, but just artifacts from a stability correction. I'd assume that in scRNAseq, this typically is a gene which is never observed (that is, 0 all the time), and as such could be filtered for in the preprocessing with e.g. `sc.pp.filter_genes(adata, min_counts=...)`, where `a` would be a number > 0. We might consider to raise a warning here though, as just introducing the nans without further comment can be quite confusing... What do you think about this @sophiamaedler?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2163#issuecomment-2199782706
https://github.com/scverse/scanpy/issues/2164#issuecomment-1103660346:113,Modifiability,variab,variables,113,"Hello,; I have the same doubt. I think with the use of sc.pp.scale, the distribution of genes(equal to different variables) is normal distribution which mean is 0 and variance is 1. And this is an ideal data moduel for PCA. So I wanna know whether sc.pp.scale is the import step before sc.tl.pca for the reason I guess above.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2164#issuecomment-1103660346
https://github.com/scverse/scanpy/issues/2164#issuecomment-1103829861:190,Performance,optimiz,optimized,190,"Hi, thanks for your ideas and discussion. For me, I think doing scaling is necessary because if the data is not centred to 0, the plane we find based on the covariance matrix may not be the optimized one. The PCA optimization process only works for data with 0 centered I think.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2164#issuecomment-1103829861
https://github.com/scverse/scanpy/issues/2164#issuecomment-1103829861:213,Performance,optimiz,optimization,213,"Hi, thanks for your ideas and discussion. For me, I think doing scaling is necessary because if the data is not centred to 0, the plane we find based on the covariance matrix may not be the optimized one. The PCA optimization process only works for data with 0 centered I think.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2164#issuecomment-1103829861
https://github.com/scverse/scanpy/issues/2164#issuecomment-1293207815:145,Energy Efficiency,efficient,efficiently,145,"In the help documentation of sc.pp.scale, it is said ""zero_center If `False`, omit zero-centering variables, which allows to handle sparse input efficiently. ; I am still confused about zero_center. If zero_center=False, what will sc.pp.scale do ? Could you give a simple example ? For example, [1,2,3] would be [-1.22,0,1.22] after scaling, but what if zero_center=False ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2164#issuecomment-1293207815
https://github.com/scverse/scanpy/issues/2164#issuecomment-1293207815:98,Modifiability,variab,variables,98,"In the help documentation of sc.pp.scale, it is said ""zero_center If `False`, omit zero-centering variables, which allows to handle sparse input efficiently. ; I am still confused about zero_center. If zero_center=False, what will sc.pp.scale do ? Could you give a simple example ? For example, [1,2,3] would be [-1.22,0,1.22] after scaling, but what if zero_center=False ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2164#issuecomment-1293207815
https://github.com/scverse/scanpy/issues/2164#issuecomment-1293207815:265,Usability,simpl,simple,265,"In the help documentation of sc.pp.scale, it is said ""zero_center If `False`, omit zero-centering variables, which allows to handle sparse input efficiently. ; I am still confused about zero_center. If zero_center=False, what will sc.pp.scale do ? Could you give a simple example ? For example, [1,2,3] would be [-1.22,0,1.22] after scaling, but what if zero_center=False ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2164#issuecomment-1293207815
https://github.com/scverse/scanpy/issues/2164#issuecomment-1370694921:147,Energy Efficiency,efficient,efficiently,147,"> In the help documentation of sc.pp.scale, it is said ""zero_center If `False`, omit zero-centering variables, which allows to handle sparse input efficiently. I am still confused about zero_center. If zero_center=False, what will sc.pp.scale do ? Could you give a simple example ? For example, [1,2,3] would be [-1.22,0,1.22] after scaling, but what if zero_center=False ?. Just the data will be only scaled by stds, the means wouldn't be subtracted.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2164#issuecomment-1370694921
https://github.com/scverse/scanpy/issues/2164#issuecomment-1370694921:100,Modifiability,variab,variables,100,"> In the help documentation of sc.pp.scale, it is said ""zero_center If `False`, omit zero-centering variables, which allows to handle sparse input efficiently. I am still confused about zero_center. If zero_center=False, what will sc.pp.scale do ? Could you give a simple example ? For example, [1,2,3] would be [-1.22,0,1.22] after scaling, but what if zero_center=False ?. Just the data will be only scaled by stds, the means wouldn't be subtracted.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2164#issuecomment-1370694921
https://github.com/scverse/scanpy/issues/2164#issuecomment-1370694921:265,Usability,simpl,simple,265,"> In the help documentation of sc.pp.scale, it is said ""zero_center If `False`, omit zero-centering variables, which allows to handle sparse input efficiently. I am still confused about zero_center. If zero_center=False, what will sc.pp.scale do ? Could you give a simple example ? For example, [1,2,3] would be [-1.22,0,1.22] after scaling, but what if zero_center=False ?. Just the data will be only scaled by stds, the means wouldn't be subtracted.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2164#issuecomment-1370694921
https://github.com/scverse/scanpy/issues/2165#issuecomment-1058039729:5,Availability,error,error,5,"This error is certainly caused by ""scikit-learn"". I abandoned this conda environment and created a new one by `conda create -n Scanpy -c conda-forge scikit-learn`[https://scikit-learn.org/stable/install.html](url).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2165#issuecomment-1058039729
https://github.com/scverse/scanpy/issues/2165#issuecomment-1058039729:195,Deployability,install,install,195,"This error is certainly caused by ""scikit-learn"". I abandoned this conda environment and created a new one by `conda create -n Scanpy -c conda-forge scikit-learn`[https://scikit-learn.org/stable/install.html](url).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2165#issuecomment-1058039729
https://github.com/scverse/scanpy/issues/2165#issuecomment-1058039729:42,Usability,learn,learn,42,"This error is certainly caused by ""scikit-learn"". I abandoned this conda environment and created a new one by `conda create -n Scanpy -c conda-forge scikit-learn`[https://scikit-learn.org/stable/install.html](url).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2165#issuecomment-1058039729
https://github.com/scverse/scanpy/issues/2165#issuecomment-1058039729:156,Usability,learn,learn,156,"This error is certainly caused by ""scikit-learn"". I abandoned this conda environment and created a new one by `conda create -n Scanpy -c conda-forge scikit-learn`[https://scikit-learn.org/stable/install.html](url).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2165#issuecomment-1058039729
https://github.com/scverse/scanpy/issues/2165#issuecomment-1058039729:178,Usability,learn,learn,178,"This error is certainly caused by ""scikit-learn"". I abandoned this conda environment and created a new one by `conda create -n Scanpy -c conda-forge scikit-learn`[https://scikit-learn.org/stable/install.html](url).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2165#issuecomment-1058039729
https://github.com/scverse/scanpy/issues/2169#issuecomment-1062402318:512,Deployability,install,install,512,<details>; <summary>pip list</summary>. ```; anndata 0.7.8; asttokens 2.0.5; bcrypt 3.2.0; Bottleneck 1.3.2; brotlipy 0.7.0; cached-property 1.5.2; certifi 2021.10.8; cffi 1.15.0; charset-normalizer 2.0.12; chart-studio 1.1.0; click 8.0.4; cmake 3.22.2; colorama 0.4.4; conda 4.11.0; conda-package-handling 1.7.3; cryptography 36.0.1; cycler 0.11.0; Cython 0.29.20; devtools 0.8.0; dunamai 1.9.0; executing 0.8.2; fa2 0.3.5; Fabric 1.6.1; fonttools 4.29.1; get_version 3.5.4; h5py 3.6.0; idna 3.3; igraph 0.9.9; install 1.3.5; joblib 1.1.0; kiwisolver 1.3.2; legacy-api-wrap 1.2; llvmlite 0.38.0; loom 0.0.18; loompy 3.0.6; mamba 0.15.3; matplotlib 3.5.1; mkl-fft 1.3.1; mkl-random 1.2.2; mkl-service 2.4.0; MulticoreTSNE 0.1; natsort 8.1.0; networkx 2.6.3; numba 0.55.1; numexpr 2.8.1; numpy 1.21.2; numpy-groupies 0.9.14; opt-einsum 3.3.0; packaging 21.3; pandas 1.4.1; paramiko 2.9.2; patsy 0.5.2; Pillow 9.0.1; pip 21.2.4; plotly 5.6.0; pycosat 0.6.3; pycparser 2.21; PyNaCl 1.5.0; pynndescent 0.5.6; pyOpenSSL 22.0.0; pyparsing 3.0.7; PyQt5 5.12.3; PyQt5_sip 4.19.18; PyQtChart 5.12; PyQtWebEngine 5.12.1; pyro-api 0.1.2; pyro-ppl 1.8.0; pysam 0.18.0; PySocks 1.7.1; python-dateutil 2.8.2; pytz 2021.3; requests 2.27.1; retrying 1.3.3; ruamel-yaml-conda 0.15.80; scanpy 1.7.0rc1; scikit-learn 1.0.2; scipy 1.7.3; seaborn 0.11.2; setuptools 58.0.4; sinfo 0.3.4; six 1.16.0; statsmodels 0.13.2; stdlib-list 0.8.0; tables 3.7.0; tenacity 8.0.1; texttable 1.6.4; threadpoolctl 3.1.0; torch 1.10.2; tornado 6.1; tqdm 4.62.3; umap-learn 0.4.6; unicodedata2 14.0.0; urllib3 1.26.8; velocyto 0.17.17; wheel 0.37.1; xlrd 1.2.0; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169#issuecomment-1062402318
https://github.com/scverse/scanpy/issues/2169#issuecomment-1062402318:570,Integrability,wrap,wrap,570,<details>; <summary>pip list</summary>. ```; anndata 0.7.8; asttokens 2.0.5; bcrypt 3.2.0; Bottleneck 1.3.2; brotlipy 0.7.0; cached-property 1.5.2; certifi 2021.10.8; cffi 1.15.0; charset-normalizer 2.0.12; chart-studio 1.1.0; click 8.0.4; cmake 3.22.2; colorama 0.4.4; conda 4.11.0; conda-package-handling 1.7.3; cryptography 36.0.1; cycler 0.11.0; Cython 0.29.20; devtools 0.8.0; dunamai 1.9.0; executing 0.8.2; fa2 0.3.5; Fabric 1.6.1; fonttools 4.29.1; get_version 3.5.4; h5py 3.6.0; idna 3.3; igraph 0.9.9; install 1.3.5; joblib 1.1.0; kiwisolver 1.3.2; legacy-api-wrap 1.2; llvmlite 0.38.0; loom 0.0.18; loompy 3.0.6; mamba 0.15.3; matplotlib 3.5.1; mkl-fft 1.3.1; mkl-random 1.2.2; mkl-service 2.4.0; MulticoreTSNE 0.1; natsort 8.1.0; networkx 2.6.3; numba 0.55.1; numexpr 2.8.1; numpy 1.21.2; numpy-groupies 0.9.14; opt-einsum 3.3.0; packaging 21.3; pandas 1.4.1; paramiko 2.9.2; patsy 0.5.2; Pillow 9.0.1; pip 21.2.4; plotly 5.6.0; pycosat 0.6.3; pycparser 2.21; PyNaCl 1.5.0; pynndescent 0.5.6; pyOpenSSL 22.0.0; pyparsing 3.0.7; PyQt5 5.12.3; PyQt5_sip 4.19.18; PyQtChart 5.12; PyQtWebEngine 5.12.1; pyro-api 0.1.2; pyro-ppl 1.8.0; pysam 0.18.0; PySocks 1.7.1; python-dateutil 2.8.2; pytz 2021.3; requests 2.27.1; retrying 1.3.3; ruamel-yaml-conda 0.15.80; scanpy 1.7.0rc1; scikit-learn 1.0.2; scipy 1.7.3; seaborn 0.11.2; setuptools 58.0.4; sinfo 0.3.4; six 1.16.0; statsmodels 0.13.2; stdlib-list 0.8.0; tables 3.7.0; tenacity 8.0.1; texttable 1.6.4; threadpoolctl 3.1.0; torch 1.10.2; tornado 6.1; tqdm 4.62.3; umap-learn 0.4.6; unicodedata2 14.0.0; urllib3 1.26.8; velocyto 0.17.17; wheel 0.37.1; xlrd 1.2.0; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169#issuecomment-1062402318
https://github.com/scverse/scanpy/issues/2169#issuecomment-1062402318:91,Performance,Bottleneck,Bottleneck,91,<details>; <summary>pip list</summary>. ```; anndata 0.7.8; asttokens 2.0.5; bcrypt 3.2.0; Bottleneck 1.3.2; brotlipy 0.7.0; cached-property 1.5.2; certifi 2021.10.8; cffi 1.15.0; charset-normalizer 2.0.12; chart-studio 1.1.0; click 8.0.4; cmake 3.22.2; colorama 0.4.4; conda 4.11.0; conda-package-handling 1.7.3; cryptography 36.0.1; cycler 0.11.0; Cython 0.29.20; devtools 0.8.0; dunamai 1.9.0; executing 0.8.2; fa2 0.3.5; Fabric 1.6.1; fonttools 4.29.1; get_version 3.5.4; h5py 3.6.0; idna 3.3; igraph 0.9.9; install 1.3.5; joblib 1.1.0; kiwisolver 1.3.2; legacy-api-wrap 1.2; llvmlite 0.38.0; loom 0.0.18; loompy 3.0.6; mamba 0.15.3; matplotlib 3.5.1; mkl-fft 1.3.1; mkl-random 1.2.2; mkl-service 2.4.0; MulticoreTSNE 0.1; natsort 8.1.0; networkx 2.6.3; numba 0.55.1; numexpr 2.8.1; numpy 1.21.2; numpy-groupies 0.9.14; opt-einsum 3.3.0; packaging 21.3; pandas 1.4.1; paramiko 2.9.2; patsy 0.5.2; Pillow 9.0.1; pip 21.2.4; plotly 5.6.0; pycosat 0.6.3; pycparser 2.21; PyNaCl 1.5.0; pynndescent 0.5.6; pyOpenSSL 22.0.0; pyparsing 3.0.7; PyQt5 5.12.3; PyQt5_sip 4.19.18; PyQtChart 5.12; PyQtWebEngine 5.12.1; pyro-api 0.1.2; pyro-ppl 1.8.0; pysam 0.18.0; PySocks 1.7.1; python-dateutil 2.8.2; pytz 2021.3; requests 2.27.1; retrying 1.3.3; ruamel-yaml-conda 0.15.80; scanpy 1.7.0rc1; scikit-learn 1.0.2; scipy 1.7.3; seaborn 0.11.2; setuptools 58.0.4; sinfo 0.3.4; six 1.16.0; statsmodels 0.13.2; stdlib-list 0.8.0; tables 3.7.0; tenacity 8.0.1; texttable 1.6.4; threadpoolctl 3.1.0; torch 1.10.2; tornado 6.1; tqdm 4.62.3; umap-learn 0.4.6; unicodedata2 14.0.0; urllib3 1.26.8; velocyto 0.17.17; wheel 0.37.1; xlrd 1.2.0; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169#issuecomment-1062402318
https://github.com/scverse/scanpy/issues/2169#issuecomment-1062402318:125,Performance,cache,cached-property,125,<details>; <summary>pip list</summary>. ```; anndata 0.7.8; asttokens 2.0.5; bcrypt 3.2.0; Bottleneck 1.3.2; brotlipy 0.7.0; cached-property 1.5.2; certifi 2021.10.8; cffi 1.15.0; charset-normalizer 2.0.12; chart-studio 1.1.0; click 8.0.4; cmake 3.22.2; colorama 0.4.4; conda 4.11.0; conda-package-handling 1.7.3; cryptography 36.0.1; cycler 0.11.0; Cython 0.29.20; devtools 0.8.0; dunamai 1.9.0; executing 0.8.2; fa2 0.3.5; Fabric 1.6.1; fonttools 4.29.1; get_version 3.5.4; h5py 3.6.0; idna 3.3; igraph 0.9.9; install 1.3.5; joblib 1.1.0; kiwisolver 1.3.2; legacy-api-wrap 1.2; llvmlite 0.38.0; loom 0.0.18; loompy 3.0.6; mamba 0.15.3; matplotlib 3.5.1; mkl-fft 1.3.1; mkl-random 1.2.2; mkl-service 2.4.0; MulticoreTSNE 0.1; natsort 8.1.0; networkx 2.6.3; numba 0.55.1; numexpr 2.8.1; numpy 1.21.2; numpy-groupies 0.9.14; opt-einsum 3.3.0; packaging 21.3; pandas 1.4.1; paramiko 2.9.2; patsy 0.5.2; Pillow 9.0.1; pip 21.2.4; plotly 5.6.0; pycosat 0.6.3; pycparser 2.21; PyNaCl 1.5.0; pynndescent 0.5.6; pyOpenSSL 22.0.0; pyparsing 3.0.7; PyQt5 5.12.3; PyQt5_sip 4.19.18; PyQtChart 5.12; PyQtWebEngine 5.12.1; pyro-api 0.1.2; pyro-ppl 1.8.0; pysam 0.18.0; PySocks 1.7.1; python-dateutil 2.8.2; pytz 2021.3; requests 2.27.1; retrying 1.3.3; ruamel-yaml-conda 0.15.80; scanpy 1.7.0rc1; scikit-learn 1.0.2; scipy 1.7.3; seaborn 0.11.2; setuptools 58.0.4; sinfo 0.3.4; six 1.16.0; statsmodels 0.13.2; stdlib-list 0.8.0; tables 3.7.0; tenacity 8.0.1; texttable 1.6.4; threadpoolctl 3.1.0; torch 1.10.2; tornado 6.1; tqdm 4.62.3; umap-learn 0.4.6; unicodedata2 14.0.0; urllib3 1.26.8; velocyto 0.17.17; wheel 0.37.1; xlrd 1.2.0; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169#issuecomment-1062402318
https://github.com/scverse/scanpy/issues/2169#issuecomment-1062402318:1292,Usability,learn,learn,1292,<details>; <summary>pip list</summary>. ```; anndata 0.7.8; asttokens 2.0.5; bcrypt 3.2.0; Bottleneck 1.3.2; brotlipy 0.7.0; cached-property 1.5.2; certifi 2021.10.8; cffi 1.15.0; charset-normalizer 2.0.12; chart-studio 1.1.0; click 8.0.4; cmake 3.22.2; colorama 0.4.4; conda 4.11.0; conda-package-handling 1.7.3; cryptography 36.0.1; cycler 0.11.0; Cython 0.29.20; devtools 0.8.0; dunamai 1.9.0; executing 0.8.2; fa2 0.3.5; Fabric 1.6.1; fonttools 4.29.1; get_version 3.5.4; h5py 3.6.0; idna 3.3; igraph 0.9.9; install 1.3.5; joblib 1.1.0; kiwisolver 1.3.2; legacy-api-wrap 1.2; llvmlite 0.38.0; loom 0.0.18; loompy 3.0.6; mamba 0.15.3; matplotlib 3.5.1; mkl-fft 1.3.1; mkl-random 1.2.2; mkl-service 2.4.0; MulticoreTSNE 0.1; natsort 8.1.0; networkx 2.6.3; numba 0.55.1; numexpr 2.8.1; numpy 1.21.2; numpy-groupies 0.9.14; opt-einsum 3.3.0; packaging 21.3; pandas 1.4.1; paramiko 2.9.2; patsy 0.5.2; Pillow 9.0.1; pip 21.2.4; plotly 5.6.0; pycosat 0.6.3; pycparser 2.21; PyNaCl 1.5.0; pynndescent 0.5.6; pyOpenSSL 22.0.0; pyparsing 3.0.7; PyQt5 5.12.3; PyQt5_sip 4.19.18; PyQtChart 5.12; PyQtWebEngine 5.12.1; pyro-api 0.1.2; pyro-ppl 1.8.0; pysam 0.18.0; PySocks 1.7.1; python-dateutil 2.8.2; pytz 2021.3; requests 2.27.1; retrying 1.3.3; ruamel-yaml-conda 0.15.80; scanpy 1.7.0rc1; scikit-learn 1.0.2; scipy 1.7.3; seaborn 0.11.2; setuptools 58.0.4; sinfo 0.3.4; six 1.16.0; statsmodels 0.13.2; stdlib-list 0.8.0; tables 3.7.0; tenacity 8.0.1; texttable 1.6.4; threadpoolctl 3.1.0; torch 1.10.2; tornado 6.1; tqdm 4.62.3; umap-learn 0.4.6; unicodedata2 14.0.0; urllib3 1.26.8; velocyto 0.17.17; wheel 0.37.1; xlrd 1.2.0; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169#issuecomment-1062402318
https://github.com/scverse/scanpy/issues/2169#issuecomment-1062402318:1530,Usability,learn,learn,1530,<details>; <summary>pip list</summary>. ```; anndata 0.7.8; asttokens 2.0.5; bcrypt 3.2.0; Bottleneck 1.3.2; brotlipy 0.7.0; cached-property 1.5.2; certifi 2021.10.8; cffi 1.15.0; charset-normalizer 2.0.12; chart-studio 1.1.0; click 8.0.4; cmake 3.22.2; colorama 0.4.4; conda 4.11.0; conda-package-handling 1.7.3; cryptography 36.0.1; cycler 0.11.0; Cython 0.29.20; devtools 0.8.0; dunamai 1.9.0; executing 0.8.2; fa2 0.3.5; Fabric 1.6.1; fonttools 4.29.1; get_version 3.5.4; h5py 3.6.0; idna 3.3; igraph 0.9.9; install 1.3.5; joblib 1.1.0; kiwisolver 1.3.2; legacy-api-wrap 1.2; llvmlite 0.38.0; loom 0.0.18; loompy 3.0.6; mamba 0.15.3; matplotlib 3.5.1; mkl-fft 1.3.1; mkl-random 1.2.2; mkl-service 2.4.0; MulticoreTSNE 0.1; natsort 8.1.0; networkx 2.6.3; numba 0.55.1; numexpr 2.8.1; numpy 1.21.2; numpy-groupies 0.9.14; opt-einsum 3.3.0; packaging 21.3; pandas 1.4.1; paramiko 2.9.2; patsy 0.5.2; Pillow 9.0.1; pip 21.2.4; plotly 5.6.0; pycosat 0.6.3; pycparser 2.21; PyNaCl 1.5.0; pynndescent 0.5.6; pyOpenSSL 22.0.0; pyparsing 3.0.7; PyQt5 5.12.3; PyQt5_sip 4.19.18; PyQtChart 5.12; PyQtWebEngine 5.12.1; pyro-api 0.1.2; pyro-ppl 1.8.0; pysam 0.18.0; PySocks 1.7.1; python-dateutil 2.8.2; pytz 2021.3; requests 2.27.1; retrying 1.3.3; ruamel-yaml-conda 0.15.80; scanpy 1.7.0rc1; scikit-learn 1.0.2; scipy 1.7.3; seaborn 0.11.2; setuptools 58.0.4; sinfo 0.3.4; six 1.16.0; statsmodels 0.13.2; stdlib-list 0.8.0; tables 3.7.0; tenacity 8.0.1; texttable 1.6.4; threadpoolctl 3.1.0; torch 1.10.2; tornado 6.1; tqdm 4.62.3; umap-learn 0.4.6; unicodedata2 14.0.0; urllib3 1.26.8; velocyto 0.17.17; wheel 0.37.1; xlrd 1.2.0; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169#issuecomment-1062402318
https://github.com/scverse/scanpy/issues/2169#issuecomment-1064638508:28,Availability,error,error,28,"I'm also getting a separate error:; ""simplicial_set_embedding() missing 3 required positional arguments: 'densmap', 'densmap_kwds', and 'output_dens'""; When I run scanpy.tl.umap. Not sure if this is related.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169#issuecomment-1064638508
https://github.com/scverse/scanpy/pull/2170#issuecomment-1061626692:41,Modifiability,variab,variable,41,"Thanks for the PR! I've just renamed the variable to be a bit more clear. I do think this test could be a bit better (e.g. check that the structure of the object is correct), but also this is an improvement so LGTM.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2170#issuecomment-1061626692
https://github.com/scverse/scanpy/pull/2170#issuecomment-1061626692:90,Testability,test,test,90,"Thanks for the PR! I've just renamed the variable to be a bit more clear. I do think this test could be a bit better (e.g. check that the structure of the object is correct), but also this is an improvement so LGTM.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2170#issuecomment-1061626692
https://github.com/scverse/scanpy/pull/2170#issuecomment-1061626692:67,Usability,clear,clear,67,"Thanks for the PR! I've just renamed the variable to be a bit more clear. I do think this test could be a bit better (e.g. check that the structure of the object is correct), but also this is an improvement so LGTM.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2170#issuecomment-1061626692
https://github.com/scverse/scanpy/pull/2170#issuecomment-1061645321:142,Deployability,release,releases,142,I thought you had mentioned moving this to squidpy? Which is fine to me to do whenever you want. Might be good to do ahead of the next visium releases?. Not sure if another package will happen or a timeline if so.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2170#issuecomment-1061645321
https://github.com/scverse/scanpy/issues/2172#issuecomment-1063056234:129,Availability,error,error,129,"We currently distribute `scanpy` through `conda-forge`, so I would recommend using that for up to date versions. Will this still error if you've done that?. Also, it's a little unclear if your session info came from the conda environment you're running into issues with. Is this definitely the case? There shouldn't be that new of releases of scanpy or anndata available through bioconda as far as I know.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172#issuecomment-1063056234
https://github.com/scverse/scanpy/issues/2172#issuecomment-1063056234:361,Availability,avail,available,361,"We currently distribute `scanpy` through `conda-forge`, so I would recommend using that for up to date versions. Will this still error if you've done that?. Also, it's a little unclear if your session info came from the conda environment you're running into issues with. Is this definitely the case? There shouldn't be that new of releases of scanpy or anndata available through bioconda as far as I know.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172#issuecomment-1063056234
https://github.com/scverse/scanpy/issues/2172#issuecomment-1063056234:331,Deployability,release,releases,331,"We currently distribute `scanpy` through `conda-forge`, so I would recommend using that for up to date versions. Will this still error if you've done that?. Also, it's a little unclear if your session info came from the conda environment you're running into issues with. Is this definitely the case? There shouldn't be that new of releases of scanpy or anndata available through bioconda as far as I know.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172#issuecomment-1063056234
https://github.com/scverse/scanpy/issues/2172#issuecomment-1063103340:44,Deployability,install,installation,44,I used `bioconda` as it was the recommended installation method according to the Scanpy documentation site last time I checked (october 2021). My bad then. I only installed `scanpy` through `bioconda` so the version I got (and you see in the Details of the previous post) are from there. `anndata2ri` version in there is from `pip`. If I try with conda-forge channel for both scanpy and anndata2ri the issue is solved.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172#issuecomment-1063103340
https://github.com/scverse/scanpy/issues/2172#issuecomment-1063103340:163,Deployability,install,installed,163,I used `bioconda` as it was the recommended installation method according to the Scanpy documentation site last time I checked (october 2021). My bad then. I only installed `scanpy` through `bioconda` so the version I got (and you see in the Details of the previous post) are from there. `anndata2ri` version in there is from `pip`. If I try with conda-forge channel for both scanpy and anndata2ri the issue is solved.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172#issuecomment-1063103340
https://github.com/scverse/scanpy/issues/2172#issuecomment-1063294721:76,Deployability,install,install,76,Glad to see this is fixed in newer versions!. No worries about the changing install instructions.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172#issuecomment-1063294721
https://github.com/scverse/scanpy/issues/2173#issuecomment-1063418303:12,Deployability,install,install,12,How did you install scanpy? What conda command did you use?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173#issuecomment-1063418303
https://github.com/scverse/scanpy/issues/2173#issuecomment-1063426953:29,Deployability,install,install,29,I checked #1468. Tried conda install pytables. But it did not work.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173#issuecomment-1063426953
https://github.com/scverse/scanpy/issues/2173#issuecomment-1063428175:14,Deployability,install,install,14,> How did you install scanpy? What conda command did you use?. And I'd appreciate an answer here. Just want to rule out that you used bioconda.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173#issuecomment-1063428175
https://github.com/scverse/scanpy/issues/2173#issuecomment-1063703998:6,Deployability,install,install,6,conda install pytables. Collecting package metadata (current_repodata.json): ...working... done; Solving environment: ...working... done. # All requested packages already installed. But there is still ImportError.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173#issuecomment-1063703998
https://github.com/scverse/scanpy/issues/2173#issuecomment-1063703998:171,Deployability,install,installed,171,conda install pytables. Collecting package metadata (current_repodata.json): ...working... done; Solving environment: ...working... done. # All requested packages already installed. But there is still ImportError.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173#issuecomment-1063703998
https://github.com/scverse/scanpy/issues/2173#issuecomment-1063704626:5492,Availability,ERROR,ERROR,5492,"ls>=4.22.0 in c:\users\charles\anaconda3\lib\site-packages (from matplotlib>=3.1.2->scanpy) (4.25.0); Requirement already satisfied: python-dateutil>=2.7 in c:\users\charles\anaconda3\lib\site-packages (from matplotlib>=3.1.2->scanpy) (2.8.2); Requirement already satisfied: llvmlite>=0.29.0 in c:\users\charles\anaconda3\lib\site-packages (from numba>=0.41.0->scanpy) (0.29.0); Requirement already satisfied: pytz>=2017.3 in c:\users\charles\anaconda3\lib\site-packages (from pandas>=0.21->scanpy) (2021.3); Requirement already satisfied: threadpoolctl>=2.0.0 in c:\users\charles\anaconda3\lib\site-packages (from scikit-learn>=0.21.2->scanpy) (2.2.0); Collecting numba>=0.41.0; Using cached numba-0.55.1-cp37-cp37m-win_amd64.whl (2.4 MB); Requirement already satisfied: pynndescent>=0.5 in c:\users\charles\anaconda3\lib\site-packages (from umap-learn>=0.3.10->scanpy) (0.5.2); Requirement already satisfied: setuptools in c:\users\charles\anaconda3\lib\site-packages (from numba>=0.41.0->scanpy) (58.0.4); Collecting llvmlite>=0.29.0; Using cached llvmlite-0.38.0-cp37-cp37m-win_amd64.whl (23.2 MB); Requirement already satisfied: get-version>=2.0.4 in c:\users\charles\anaconda3\lib\site-packages (from legacy-api-wrap->scanpy) (2.2); Requirement already satisfied: stdlib-list in c:\users\charles\anaconda3\lib\site-packages (from sinfo->scanpy) (0.8.0); Requirement already satisfied: numexpr>=2.6.2 in c:\users\charles\anaconda3\lib\site-packages (from tables->scanpy) (2.8.1); Requirement already satisfied: colorama in c:\users\charles\anaconda3\lib\site-packages (from tqdm->scanpy) (0.4.4); Installing collected packages: llvmlite, numba, xlrd; Attempting uninstall: llvmlite; Found existing installation: llvmlite 0.29.0; Note: you may need to restart the kernel to use updated packages.; ERROR: Cannot uninstall 'llvmlite'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.; ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173#issuecomment-1063704626
https://github.com/scverse/scanpy/issues/2173#issuecomment-1063704626:20,Deployability,Install,Installed,20,<details>; <summary>Installed scanpy on jupyter notebook/ anaconda: </summary>. ```; pip install scanpy. Requirement already satisfied: scanpy in c:\users\charles\anaconda3\lib\site-packages (1.7.2); Requirement already satisfied: numba>=0.41.0 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (0.44.1); Requirement already satisfied: tables in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (3.7.0); Requirement already satisfied: anndata>=0.7.4 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (0.7.6); Requirement already satisfied: legacy-api-wrap in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (1.2); Requirement already satisfied: packaging in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (21.3); Requirement already satisfied: pandas>=0.21 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (1.3.4); Requirement already satisfied: scipy>=1.4 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (1.7.3); Requirement already satisfied: umap-learn>=0.3.10 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (0.5.1); Requirement already satisfied: h5py>=2.10.0 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (2.10.0); Requirement already satisfied: scikit-learn>=0.21.2 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (1.0.2); Requirement already satisfied: statsmodels>=0.10.0rc2 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (0.13.0); Requirement already satisfied: matplotlib>=3.1.2 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (3.5.1); Requirement already satisfied: numpy>=1.17.0 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (1.21.5); Requirement already satisfied: seaborn in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (0.11.2); Requirement already satisfied: tqdm in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (4.62.3); Requirement already satisfied: natsort in c:\users\charles\an,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173#issuecomment-1063704626
https://github.com/scverse/scanpy/issues/2173#issuecomment-1063704626:89,Deployability,install,install,89,<details>; <summary>Installed scanpy on jupyter notebook/ anaconda: </summary>. ```; pip install scanpy. Requirement already satisfied: scanpy in c:\users\charles\anaconda3\lib\site-packages (1.7.2); Requirement already satisfied: numba>=0.41.0 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (0.44.1); Requirement already satisfied: tables in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (3.7.0); Requirement already satisfied: anndata>=0.7.4 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (0.7.6); Requirement already satisfied: legacy-api-wrap in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (1.2); Requirement already satisfied: packaging in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (21.3); Requirement already satisfied: pandas>=0.21 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (1.3.4); Requirement already satisfied: scipy>=1.4 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (1.7.3); Requirement already satisfied: umap-learn>=0.3.10 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (0.5.1); Requirement already satisfied: h5py>=2.10.0 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (2.10.0); Requirement already satisfied: scikit-learn>=0.21.2 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (1.0.2); Requirement already satisfied: statsmodels>=0.10.0rc2 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (0.13.0); Requirement already satisfied: matplotlib>=3.1.2 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (3.5.1); Requirement already satisfied: numpy>=1.17.0 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (1.21.5); Requirement already satisfied: seaborn in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (0.11.2); Requirement already satisfied: tqdm in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (4.62.3); Requirement already satisfied: natsort in c:\users\charles\an,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173#issuecomment-1063704626
https://github.com/scverse/scanpy/issues/2173#issuecomment-1063704626:5293,Deployability,Install,Installing,5293,"ls>=4.22.0 in c:\users\charles\anaconda3\lib\site-packages (from matplotlib>=3.1.2->scanpy) (4.25.0); Requirement already satisfied: python-dateutil>=2.7 in c:\users\charles\anaconda3\lib\site-packages (from matplotlib>=3.1.2->scanpy) (2.8.2); Requirement already satisfied: llvmlite>=0.29.0 in c:\users\charles\anaconda3\lib\site-packages (from numba>=0.41.0->scanpy) (0.29.0); Requirement already satisfied: pytz>=2017.3 in c:\users\charles\anaconda3\lib\site-packages (from pandas>=0.21->scanpy) (2021.3); Requirement already satisfied: threadpoolctl>=2.0.0 in c:\users\charles\anaconda3\lib\site-packages (from scikit-learn>=0.21.2->scanpy) (2.2.0); Collecting numba>=0.41.0; Using cached numba-0.55.1-cp37-cp37m-win_amd64.whl (2.4 MB); Requirement already satisfied: pynndescent>=0.5 in c:\users\charles\anaconda3\lib\site-packages (from umap-learn>=0.3.10->scanpy) (0.5.2); Requirement already satisfied: setuptools in c:\users\charles\anaconda3\lib\site-packages (from numba>=0.41.0->scanpy) (58.0.4); Collecting llvmlite>=0.29.0; Using cached llvmlite-0.38.0-cp37-cp37m-win_amd64.whl (23.2 MB); Requirement already satisfied: get-version>=2.0.4 in c:\users\charles\anaconda3\lib\site-packages (from legacy-api-wrap->scanpy) (2.2); Requirement already satisfied: stdlib-list in c:\users\charles\anaconda3\lib\site-packages (from sinfo->scanpy) (0.8.0); Requirement already satisfied: numexpr>=2.6.2 in c:\users\charles\anaconda3\lib\site-packages (from tables->scanpy) (2.8.1); Requirement already satisfied: colorama in c:\users\charles\anaconda3\lib\site-packages (from tqdm->scanpy) (0.4.4); Installing collected packages: llvmlite, numba, xlrd; Attempting uninstall: llvmlite; Found existing installation: llvmlite 0.29.0; Note: you may need to restart the kernel to use updated packages.; ERROR: Cannot uninstall 'llvmlite'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.; ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173#issuecomment-1063704626
https://github.com/scverse/scanpy/issues/2173#issuecomment-1063704626:5394,Deployability,install,installation,5394,"ls>=4.22.0 in c:\users\charles\anaconda3\lib\site-packages (from matplotlib>=3.1.2->scanpy) (4.25.0); Requirement already satisfied: python-dateutil>=2.7 in c:\users\charles\anaconda3\lib\site-packages (from matplotlib>=3.1.2->scanpy) (2.8.2); Requirement already satisfied: llvmlite>=0.29.0 in c:\users\charles\anaconda3\lib\site-packages (from numba>=0.41.0->scanpy) (0.29.0); Requirement already satisfied: pytz>=2017.3 in c:\users\charles\anaconda3\lib\site-packages (from pandas>=0.21->scanpy) (2021.3); Requirement already satisfied: threadpoolctl>=2.0.0 in c:\users\charles\anaconda3\lib\site-packages (from scikit-learn>=0.21.2->scanpy) (2.2.0); Collecting numba>=0.41.0; Using cached numba-0.55.1-cp37-cp37m-win_amd64.whl (2.4 MB); Requirement already satisfied: pynndescent>=0.5 in c:\users\charles\anaconda3\lib\site-packages (from umap-learn>=0.3.10->scanpy) (0.5.2); Requirement already satisfied: setuptools in c:\users\charles\anaconda3\lib\site-packages (from numba>=0.41.0->scanpy) (58.0.4); Collecting llvmlite>=0.29.0; Using cached llvmlite-0.38.0-cp37-cp37m-win_amd64.whl (23.2 MB); Requirement already satisfied: get-version>=2.0.4 in c:\users\charles\anaconda3\lib\site-packages (from legacy-api-wrap->scanpy) (2.2); Requirement already satisfied: stdlib-list in c:\users\charles\anaconda3\lib\site-packages (from sinfo->scanpy) (0.8.0); Requirement already satisfied: numexpr>=2.6.2 in c:\users\charles\anaconda3\lib\site-packages (from tables->scanpy) (2.8.1); Requirement already satisfied: colorama in c:\users\charles\anaconda3\lib\site-packages (from tqdm->scanpy) (0.4.4); Installing collected packages: llvmlite, numba, xlrd; Attempting uninstall: llvmlite; Found existing installation: llvmlite 0.29.0; Note: you may need to restart the kernel to use updated packages.; ERROR: Cannot uninstall 'llvmlite'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.; ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173#issuecomment-1063704626
https://github.com/scverse/scanpy/issues/2173#issuecomment-1063704626:5473,Deployability,update,updated,5473,"ls>=4.22.0 in c:\users\charles\anaconda3\lib\site-packages (from matplotlib>=3.1.2->scanpy) (4.25.0); Requirement already satisfied: python-dateutil>=2.7 in c:\users\charles\anaconda3\lib\site-packages (from matplotlib>=3.1.2->scanpy) (2.8.2); Requirement already satisfied: llvmlite>=0.29.0 in c:\users\charles\anaconda3\lib\site-packages (from numba>=0.41.0->scanpy) (0.29.0); Requirement already satisfied: pytz>=2017.3 in c:\users\charles\anaconda3\lib\site-packages (from pandas>=0.21->scanpy) (2021.3); Requirement already satisfied: threadpoolctl>=2.0.0 in c:\users\charles\anaconda3\lib\site-packages (from scikit-learn>=0.21.2->scanpy) (2.2.0); Collecting numba>=0.41.0; Using cached numba-0.55.1-cp37-cp37m-win_amd64.whl (2.4 MB); Requirement already satisfied: pynndescent>=0.5 in c:\users\charles\anaconda3\lib\site-packages (from umap-learn>=0.3.10->scanpy) (0.5.2); Requirement already satisfied: setuptools in c:\users\charles\anaconda3\lib\site-packages (from numba>=0.41.0->scanpy) (58.0.4); Collecting llvmlite>=0.29.0; Using cached llvmlite-0.38.0-cp37-cp37m-win_amd64.whl (23.2 MB); Requirement already satisfied: get-version>=2.0.4 in c:\users\charles\anaconda3\lib\site-packages (from legacy-api-wrap->scanpy) (2.2); Requirement already satisfied: stdlib-list in c:\users\charles\anaconda3\lib\site-packages (from sinfo->scanpy) (0.8.0); Requirement already satisfied: numexpr>=2.6.2 in c:\users\charles\anaconda3\lib\site-packages (from tables->scanpy) (2.8.1); Requirement already satisfied: colorama in c:\users\charles\anaconda3\lib\site-packages (from tqdm->scanpy) (0.4.4); Installing collected packages: llvmlite, numba, xlrd; Attempting uninstall: llvmlite; Found existing installation: llvmlite 0.29.0; Note: you may need to restart the kernel to use updated packages.; ERROR: Cannot uninstall 'llvmlite'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.; ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173#issuecomment-1063704626
https://github.com/scverse/scanpy/issues/2173#issuecomment-1063704626:5546,Deployability,install,installed,5546,"ls>=4.22.0 in c:\users\charles\anaconda3\lib\site-packages (from matplotlib>=3.1.2->scanpy) (4.25.0); Requirement already satisfied: python-dateutil>=2.7 in c:\users\charles\anaconda3\lib\site-packages (from matplotlib>=3.1.2->scanpy) (2.8.2); Requirement already satisfied: llvmlite>=0.29.0 in c:\users\charles\anaconda3\lib\site-packages (from numba>=0.41.0->scanpy) (0.29.0); Requirement already satisfied: pytz>=2017.3 in c:\users\charles\anaconda3\lib\site-packages (from pandas>=0.21->scanpy) (2021.3); Requirement already satisfied: threadpoolctl>=2.0.0 in c:\users\charles\anaconda3\lib\site-packages (from scikit-learn>=0.21.2->scanpy) (2.2.0); Collecting numba>=0.41.0; Using cached numba-0.55.1-cp37-cp37m-win_amd64.whl (2.4 MB); Requirement already satisfied: pynndescent>=0.5 in c:\users\charles\anaconda3\lib\site-packages (from umap-learn>=0.3.10->scanpy) (0.5.2); Requirement already satisfied: setuptools in c:\users\charles\anaconda3\lib\site-packages (from numba>=0.41.0->scanpy) (58.0.4); Collecting llvmlite>=0.29.0; Using cached llvmlite-0.38.0-cp37-cp37m-win_amd64.whl (23.2 MB); Requirement already satisfied: get-version>=2.0.4 in c:\users\charles\anaconda3\lib\site-packages (from legacy-api-wrap->scanpy) (2.2); Requirement already satisfied: stdlib-list in c:\users\charles\anaconda3\lib\site-packages (from sinfo->scanpy) (0.8.0); Requirement already satisfied: numexpr>=2.6.2 in c:\users\charles\anaconda3\lib\site-packages (from tables->scanpy) (2.8.1); Requirement already satisfied: colorama in c:\users\charles\anaconda3\lib\site-packages (from tqdm->scanpy) (0.4.4); Installing collected packages: llvmlite, numba, xlrd; Attempting uninstall: llvmlite; Found existing installation: llvmlite 0.29.0; Note: you may need to restart the kernel to use updated packages.; ERROR: Cannot uninstall 'llvmlite'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.; ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173#issuecomment-1063704626
https://github.com/scverse/scanpy/issues/2173#issuecomment-1063704626:585,Integrability,wrap,wrap,585,<details>; <summary>Installed scanpy on jupyter notebook/ anaconda: </summary>. ```; pip install scanpy. Requirement already satisfied: scanpy in c:\users\charles\anaconda3\lib\site-packages (1.7.2); Requirement already satisfied: numba>=0.41.0 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (0.44.1); Requirement already satisfied: tables in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (3.7.0); Requirement already satisfied: anndata>=0.7.4 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (0.7.6); Requirement already satisfied: legacy-api-wrap in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (1.2); Requirement already satisfied: packaging in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (21.3); Requirement already satisfied: pandas>=0.21 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (1.3.4); Requirement already satisfied: scipy>=1.4 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (1.7.3); Requirement already satisfied: umap-learn>=0.3.10 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (0.5.1); Requirement already satisfied: h5py>=2.10.0 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (2.10.0); Requirement already satisfied: scikit-learn>=0.21.2 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (1.0.2); Requirement already satisfied: statsmodels>=0.10.0rc2 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (0.13.0); Requirement already satisfied: matplotlib>=3.1.2 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (3.5.1); Requirement already satisfied: numpy>=1.17.0 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (1.21.5); Requirement already satisfied: seaborn in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (0.11.2); Requirement already satisfied: tqdm in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (4.62.3); Requirement already satisfied: natsort in c:\users\charles\an,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173#issuecomment-1063704626
https://github.com/scverse/scanpy/issues/2173#issuecomment-1063704626:4909,Integrability,wrap,wrap,4909,"ls>=4.22.0 in c:\users\charles\anaconda3\lib\site-packages (from matplotlib>=3.1.2->scanpy) (4.25.0); Requirement already satisfied: python-dateutil>=2.7 in c:\users\charles\anaconda3\lib\site-packages (from matplotlib>=3.1.2->scanpy) (2.8.2); Requirement already satisfied: llvmlite>=0.29.0 in c:\users\charles\anaconda3\lib\site-packages (from numba>=0.41.0->scanpy) (0.29.0); Requirement already satisfied: pytz>=2017.3 in c:\users\charles\anaconda3\lib\site-packages (from pandas>=0.21->scanpy) (2021.3); Requirement already satisfied: threadpoolctl>=2.0.0 in c:\users\charles\anaconda3\lib\site-packages (from scikit-learn>=0.21.2->scanpy) (2.2.0); Collecting numba>=0.41.0; Using cached numba-0.55.1-cp37-cp37m-win_amd64.whl (2.4 MB); Requirement already satisfied: pynndescent>=0.5 in c:\users\charles\anaconda3\lib\site-packages (from umap-learn>=0.3.10->scanpy) (0.5.2); Requirement already satisfied: setuptools in c:\users\charles\anaconda3\lib\site-packages (from numba>=0.41.0->scanpy) (58.0.4); Collecting llvmlite>=0.29.0; Using cached llvmlite-0.38.0-cp37-cp37m-win_amd64.whl (23.2 MB); Requirement already satisfied: get-version>=2.0.4 in c:\users\charles\anaconda3\lib\site-packages (from legacy-api-wrap->scanpy) (2.2); Requirement already satisfied: stdlib-list in c:\users\charles\anaconda3\lib\site-packages (from sinfo->scanpy) (0.8.0); Requirement already satisfied: numexpr>=2.6.2 in c:\users\charles\anaconda3\lib\site-packages (from tables->scanpy) (2.8.1); Requirement already satisfied: colorama in c:\users\charles\anaconda3\lib\site-packages (from tqdm->scanpy) (0.4.4); Installing collected packages: llvmlite, numba, xlrd; Attempting uninstall: llvmlite; Found existing installation: llvmlite 0.29.0; Note: you may need to restart the kernel to use updated packages.; ERROR: Cannot uninstall 'llvmlite'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.; ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173#issuecomment-1063704626
https://github.com/scverse/scanpy/issues/2173#issuecomment-1063704626:2644,Performance,cache,cached,2644,.0 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (1.21.5); Requirement already satisfied: seaborn in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (0.11.2); Requirement already satisfied: tqdm in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (4.62.3); Requirement already satisfied: natsort in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (7.1.1); Requirement already satisfied: networkx>=2.3 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (2.6.3); Requirement already satisfied: importlib-metadata>=0.7 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (4.8.2); Requirement already satisfied: joblib in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (1.1.0); Requirement already satisfied: sinfo in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (0.3.4); Requirement already satisfied: patsy in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (0.5.2); Collecting xlrd<2.0; Using cached xlrd-1.2.0-py2.py3-none-any.whl (103 kB); Requirement already satisfied: six in c:\users\charles\anaconda3\lib\site-packages (from h5py>=2.10.0->scanpy) (1.16.0); Requirement already satisfied: typing-extensions>=3.6.4 in c:\users\charles\anaconda3\lib\site-packages (from importlib-metadata>=0.7->scanpy) (3.10.0.2); Requirement already satisfied: zipp>=0.5 in c:\users\charles\anaconda3\lib\site-packages (from importlib-metadata>=0.7->scanpy) (3.7.0); Requirement already satisfied: cycler>=0.10 in c:\users\charles\anaconda3\lib\site-packages (from matplotlib>=3.1.2->scanpy) (0.11.0); Requirement already satisfied: pyparsing>=2.2.1 in c:\users\charles\anaconda3\lib\site-packages (from matplotlib>=3.1.2->scanpy) (3.0.4); Requirement already satisfied: pillow>=6.2.0 in c:\users\charles\anaconda3\lib\site-packages (from matplotlib>=3.1.2->scanpy) (9.0.1); Requirement already satisfied: kiwisolver>=1.0.1 in c:\users\charles\anaconda3\lib\site-packages (from matplotlib>=3.1.2->scanpy) (1.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173#issuecomment-1063704626
https://github.com/scverse/scanpy/issues/2173#issuecomment-1063704626:4377,Performance,cache,cached,4377,"equirement already satisfied: pillow>=6.2.0 in c:\users\charles\anaconda3\lib\site-packages (from matplotlib>=3.1.2->scanpy) (9.0.1); Requirement already satisfied: kiwisolver>=1.0.1 in c:\users\charles\anaconda3\lib\site-packages (from matplotlib>=3.1.2->scanpy) (1.3.2); Requirement already satisfied: fonttools>=4.22.0 in c:\users\charles\anaconda3\lib\site-packages (from matplotlib>=3.1.2->scanpy) (4.25.0); Requirement already satisfied: python-dateutil>=2.7 in c:\users\charles\anaconda3\lib\site-packages (from matplotlib>=3.1.2->scanpy) (2.8.2); Requirement already satisfied: llvmlite>=0.29.0 in c:\users\charles\anaconda3\lib\site-packages (from numba>=0.41.0->scanpy) (0.29.0); Requirement already satisfied: pytz>=2017.3 in c:\users\charles\anaconda3\lib\site-packages (from pandas>=0.21->scanpy) (2021.3); Requirement already satisfied: threadpoolctl>=2.0.0 in c:\users\charles\anaconda3\lib\site-packages (from scikit-learn>=0.21.2->scanpy) (2.2.0); Collecting numba>=0.41.0; Using cached numba-0.55.1-cp37-cp37m-win_amd64.whl (2.4 MB); Requirement already satisfied: pynndescent>=0.5 in c:\users\charles\anaconda3\lib\site-packages (from umap-learn>=0.3.10->scanpy) (0.5.2); Requirement already satisfied: setuptools in c:\users\charles\anaconda3\lib\site-packages (from numba>=0.41.0->scanpy) (58.0.4); Collecting llvmlite>=0.29.0; Using cached llvmlite-0.38.0-cp37-cp37m-win_amd64.whl (23.2 MB); Requirement already satisfied: get-version>=2.0.4 in c:\users\charles\anaconda3\lib\site-packages (from legacy-api-wrap->scanpy) (2.2); Requirement already satisfied: stdlib-list in c:\users\charles\anaconda3\lib\site-packages (from sinfo->scanpy) (0.8.0); Requirement already satisfied: numexpr>=2.6.2 in c:\users\charles\anaconda3\lib\site-packages (from tables->scanpy) (2.8.1); Requirement already satisfied: colorama in c:\users\charles\anaconda3\lib\site-packages (from tqdm->scanpy) (0.4.4); Installing collected packages: llvmlite, numba, xlrd; Attempting uninstall: llvmlite; F",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173#issuecomment-1063704626
https://github.com/scverse/scanpy/issues/2173#issuecomment-1063704626:4735,Performance,cache,cached,4735,"ls>=4.22.0 in c:\users\charles\anaconda3\lib\site-packages (from matplotlib>=3.1.2->scanpy) (4.25.0); Requirement already satisfied: python-dateutil>=2.7 in c:\users\charles\anaconda3\lib\site-packages (from matplotlib>=3.1.2->scanpy) (2.8.2); Requirement already satisfied: llvmlite>=0.29.0 in c:\users\charles\anaconda3\lib\site-packages (from numba>=0.41.0->scanpy) (0.29.0); Requirement already satisfied: pytz>=2017.3 in c:\users\charles\anaconda3\lib\site-packages (from pandas>=0.21->scanpy) (2021.3); Requirement already satisfied: threadpoolctl>=2.0.0 in c:\users\charles\anaconda3\lib\site-packages (from scikit-learn>=0.21.2->scanpy) (2.2.0); Collecting numba>=0.41.0; Using cached numba-0.55.1-cp37-cp37m-win_amd64.whl (2.4 MB); Requirement already satisfied: pynndescent>=0.5 in c:\users\charles\anaconda3\lib\site-packages (from umap-learn>=0.3.10->scanpy) (0.5.2); Requirement already satisfied: setuptools in c:\users\charles\anaconda3\lib\site-packages (from numba>=0.41.0->scanpy) (58.0.4); Collecting llvmlite>=0.29.0; Using cached llvmlite-0.38.0-cp37-cp37m-win_amd64.whl (23.2 MB); Requirement already satisfied: get-version>=2.0.4 in c:\users\charles\anaconda3\lib\site-packages (from legacy-api-wrap->scanpy) (2.2); Requirement already satisfied: stdlib-list in c:\users\charles\anaconda3\lib\site-packages (from sinfo->scanpy) (0.8.0); Requirement already satisfied: numexpr>=2.6.2 in c:\users\charles\anaconda3\lib\site-packages (from tables->scanpy) (2.8.1); Requirement already satisfied: colorama in c:\users\charles\anaconda3\lib\site-packages (from tqdm->scanpy) (0.4.4); Installing collected packages: llvmlite, numba, xlrd; Attempting uninstall: llvmlite; Found existing installation: llvmlite 0.29.0; Note: you may need to restart the kernel to use updated packages.; ERROR: Cannot uninstall 'llvmlite'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.; ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173#issuecomment-1063704626
https://github.com/scverse/scanpy/issues/2173#issuecomment-1063704626:1034,Usability,learn,learn,1034,y>Installed scanpy on jupyter notebook/ anaconda: </summary>. ```; pip install scanpy. Requirement already satisfied: scanpy in c:\users\charles\anaconda3\lib\site-packages (1.7.2); Requirement already satisfied: numba>=0.41.0 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (0.44.1); Requirement already satisfied: tables in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (3.7.0); Requirement already satisfied: anndata>=0.7.4 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (0.7.6); Requirement already satisfied: legacy-api-wrap in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (1.2); Requirement already satisfied: packaging in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (21.3); Requirement already satisfied: pandas>=0.21 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (1.3.4); Requirement already satisfied: scipy>=1.4 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (1.7.3); Requirement already satisfied: umap-learn>=0.3.10 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (0.5.1); Requirement already satisfied: h5py>=2.10.0 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (2.10.0); Requirement already satisfied: scikit-learn>=0.21.2 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (1.0.2); Requirement already satisfied: statsmodels>=0.10.0rc2 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (0.13.0); Requirement already satisfied: matplotlib>=3.1.2 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (3.5.1); Requirement already satisfied: numpy>=1.17.0 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (1.21.5); Requirement already satisfied: seaborn in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (0.11.2); Requirement already satisfied: tqdm in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (4.62.3); Requirement already satisfied: natsort in c:\users\charles\anaconda3\lib\site-p,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173#issuecomment-1063704626
https://github.com/scverse/scanpy/issues/2173#issuecomment-1063704626:1273,Usability,learn,learn,1273,\charles\anaconda3\lib\site-packages (from scanpy) (0.44.1); Requirement already satisfied: tables in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (3.7.0); Requirement already satisfied: anndata>=0.7.4 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (0.7.6); Requirement already satisfied: legacy-api-wrap in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (1.2); Requirement already satisfied: packaging in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (21.3); Requirement already satisfied: pandas>=0.21 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (1.3.4); Requirement already satisfied: scipy>=1.4 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (1.7.3); Requirement already satisfied: umap-learn>=0.3.10 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (0.5.1); Requirement already satisfied: h5py>=2.10.0 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (2.10.0); Requirement already satisfied: scikit-learn>=0.21.2 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (1.0.2); Requirement already satisfied: statsmodels>=0.10.0rc2 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (0.13.0); Requirement already satisfied: matplotlib>=3.1.2 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (3.5.1); Requirement already satisfied: numpy>=1.17.0 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (1.21.5); Requirement already satisfied: seaborn in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (0.11.2); Requirement already satisfied: tqdm in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (4.62.3); Requirement already satisfied: natsort in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (7.1.1); Requirement already satisfied: networkx>=2.3 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (2.6.3); Requirement already satisfied: importlib-metadata>=0.7 in c:\users\charles\anaconda3\lib\si,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173#issuecomment-1063704626
https://github.com/scverse/scanpy/issues/2173#issuecomment-1063704626:4313,Usability,learn,learn,4313,.1 in c:\users\charles\anaconda3\lib\site-packages (from matplotlib>=3.1.2->scanpy) (3.0.4); Requirement already satisfied: pillow>=6.2.0 in c:\users\charles\anaconda3\lib\site-packages (from matplotlib>=3.1.2->scanpy) (9.0.1); Requirement already satisfied: kiwisolver>=1.0.1 in c:\users\charles\anaconda3\lib\site-packages (from matplotlib>=3.1.2->scanpy) (1.3.2); Requirement already satisfied: fonttools>=4.22.0 in c:\users\charles\anaconda3\lib\site-packages (from matplotlib>=3.1.2->scanpy) (4.25.0); Requirement already satisfied: python-dateutil>=2.7 in c:\users\charles\anaconda3\lib\site-packages (from matplotlib>=3.1.2->scanpy) (2.8.2); Requirement already satisfied: llvmlite>=0.29.0 in c:\users\charles\anaconda3\lib\site-packages (from numba>=0.41.0->scanpy) (0.29.0); Requirement already satisfied: pytz>=2017.3 in c:\users\charles\anaconda3\lib\site-packages (from pandas>=0.21->scanpy) (2021.3); Requirement already satisfied: threadpoolctl>=2.0.0 in c:\users\charles\anaconda3\lib\site-packages (from scikit-learn>=0.21.2->scanpy) (2.2.0); Collecting numba>=0.41.0; Using cached numba-0.55.1-cp37-cp37m-win_amd64.whl (2.4 MB); Requirement already satisfied: pynndescent>=0.5 in c:\users\charles\anaconda3\lib\site-packages (from umap-learn>=0.3.10->scanpy) (0.5.2); Requirement already satisfied: setuptools in c:\users\charles\anaconda3\lib\site-packages (from numba>=0.41.0->scanpy) (58.0.4); Collecting llvmlite>=0.29.0; Using cached llvmlite-0.38.0-cp37-cp37m-win_amd64.whl (23.2 MB); Requirement already satisfied: get-version>=2.0.4 in c:\users\charles\anaconda3\lib\site-packages (from legacy-api-wrap->scanpy) (2.2); Requirement already satisfied: stdlib-list in c:\users\charles\anaconda3\lib\site-packages (from sinfo->scanpy) (0.8.0); Requirement already satisfied: numexpr>=2.6.2 in c:\users\charles\anaconda3\lib\site-packages (from tables->scanpy) (2.8.1); Requirement already satisfied: colorama in c:\users\charles\anaconda3\lib\site-packages (from tqdm->scanpy) (0,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173#issuecomment-1063704626
https://github.com/scverse/scanpy/issues/2173#issuecomment-1063704626:4539,Usability,learn,learn,4539," Requirement already satisfied: kiwisolver>=1.0.1 in c:\users\charles\anaconda3\lib\site-packages (from matplotlib>=3.1.2->scanpy) (1.3.2); Requirement already satisfied: fonttools>=4.22.0 in c:\users\charles\anaconda3\lib\site-packages (from matplotlib>=3.1.2->scanpy) (4.25.0); Requirement already satisfied: python-dateutil>=2.7 in c:\users\charles\anaconda3\lib\site-packages (from matplotlib>=3.1.2->scanpy) (2.8.2); Requirement already satisfied: llvmlite>=0.29.0 in c:\users\charles\anaconda3\lib\site-packages (from numba>=0.41.0->scanpy) (0.29.0); Requirement already satisfied: pytz>=2017.3 in c:\users\charles\anaconda3\lib\site-packages (from pandas>=0.21->scanpy) (2021.3); Requirement already satisfied: threadpoolctl>=2.0.0 in c:\users\charles\anaconda3\lib\site-packages (from scikit-learn>=0.21.2->scanpy) (2.2.0); Collecting numba>=0.41.0; Using cached numba-0.55.1-cp37-cp37m-win_amd64.whl (2.4 MB); Requirement already satisfied: pynndescent>=0.5 in c:\users\charles\anaconda3\lib\site-packages (from umap-learn>=0.3.10->scanpy) (0.5.2); Requirement already satisfied: setuptools in c:\users\charles\anaconda3\lib\site-packages (from numba>=0.41.0->scanpy) (58.0.4); Collecting llvmlite>=0.29.0; Using cached llvmlite-0.38.0-cp37-cp37m-win_amd64.whl (23.2 MB); Requirement already satisfied: get-version>=2.0.4 in c:\users\charles\anaconda3\lib\site-packages (from legacy-api-wrap->scanpy) (2.2); Requirement already satisfied: stdlib-list in c:\users\charles\anaconda3\lib\site-packages (from sinfo->scanpy) (0.8.0); Requirement already satisfied: numexpr>=2.6.2 in c:\users\charles\anaconda3\lib\site-packages (from tables->scanpy) (2.8.1); Requirement already satisfied: colorama in c:\users\charles\anaconda3\lib\site-packages (from tqdm->scanpy) (0.4.4); Installing collected packages: llvmlite, numba, xlrd; Attempting uninstall: llvmlite; Found existing installation: llvmlite 0.29.0; Note: you may need to restart the kernel to use updated packages.; ERROR: Cannot uninsta",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173#issuecomment-1063704626
https://github.com/scverse/scanpy/issues/2173#issuecomment-1063709080:37,Availability,down,downgrade,37,> Did you look at #454 ?. I tried to downgrade h5py but still did not work.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173#issuecomment-1063709080
https://github.com/scverse/scanpy/issues/2173#issuecomment-1065067859:34,Deployability,install,installing,34,@charles-xu-ru you could also try installing numba from conda before installing scanpy. pytables better to install from conda-forge channel along with h5py.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173#issuecomment-1065067859
https://github.com/scverse/scanpy/issues/2173#issuecomment-1065067859:69,Deployability,install,installing,69,@charles-xu-ru you could also try installing numba from conda before installing scanpy. pytables better to install from conda-forge channel along with h5py.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173#issuecomment-1065067859
https://github.com/scverse/scanpy/issues/2173#issuecomment-1065067859:107,Deployability,install,install,107,@charles-xu-ru you could also try installing numba from conda before installing scanpy. pytables better to install from conda-forge channel along with h5py.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173#issuecomment-1065067859
https://github.com/scverse/scanpy/issues/2173#issuecomment-1073170953:1922,Performance,optimiz,optimize,1922,"ine 82, in <module>; from .base import clone; File ""C:\ProgramData\Miniconda3\lib\site-packages\sklearn\base.py"", line 17, in <module>; from .utils import _IS_32BIT; File ""C:\ProgramData\Miniconda3\lib\site-packages\sklearn\utils\__init__.py"", line 28, in <module>; from .fixes import np_version, parse_version; File ""C:\ProgramData\Miniconda3\lib\site-packages\sklearn\utils\fixes.py"", line 20, in <module>; import scipy.stats; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\stats\__init__.py"", line 441, in <module>; from .stats import *; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\stats\stats.py"", line 43, in <module>; from . import distributions; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\stats\distributions.py"", line 8, in <module>; from ._distn_infrastructure import (rv_discrete, rv_continuous, rv_frozen); File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\stats\_distn_infrastructure.py"", line 24, in <module>; from scipy import optimize; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\optimize\__init__.py"", line 400, in <module>; from .optimize import *; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\optimize\optimize.py"", line 36, in <module>; from ._numdiff import approx_derivative; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\optimize\_numdiff.py"", line 6, in <module>; from scipy.sparse.linalg import LinearOperator; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\sparse\linalg\__init__.py"", line 114, in <module>; from .eigen import *; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\sparse\linalg\eigen\__init__.py"", line 9, in <module>; from .arpack import *; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\sparse\linalg\eigen\arpack\__init__.py"", line 20, in <module>; from .arpack import *; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\sparse\linalg\eigen\arpack\arpack.py"", line 42, in <module>; from . import _arpack; ImportError: DLL load failed while importing _ar",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173#issuecomment-1073170953
https://github.com/scverse/scanpy/issues/2173#issuecomment-1073170953:1988,Performance,optimiz,optimize,1988,"ine 82, in <module>; from .base import clone; File ""C:\ProgramData\Miniconda3\lib\site-packages\sklearn\base.py"", line 17, in <module>; from .utils import _IS_32BIT; File ""C:\ProgramData\Miniconda3\lib\site-packages\sklearn\utils\__init__.py"", line 28, in <module>; from .fixes import np_version, parse_version; File ""C:\ProgramData\Miniconda3\lib\site-packages\sklearn\utils\fixes.py"", line 20, in <module>; import scipy.stats; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\stats\__init__.py"", line 441, in <module>; from .stats import *; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\stats\stats.py"", line 43, in <module>; from . import distributions; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\stats\distributions.py"", line 8, in <module>; from ._distn_infrastructure import (rv_discrete, rv_continuous, rv_frozen); File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\stats\_distn_infrastructure.py"", line 24, in <module>; from scipy import optimize; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\optimize\__init__.py"", line 400, in <module>; from .optimize import *; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\optimize\optimize.py"", line 36, in <module>; from ._numdiff import approx_derivative; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\optimize\_numdiff.py"", line 6, in <module>; from scipy.sparse.linalg import LinearOperator; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\sparse\linalg\__init__.py"", line 114, in <module>; from .eigen import *; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\sparse\linalg\eigen\__init__.py"", line 9, in <module>; from .arpack import *; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\sparse\linalg\eigen\arpack\__init__.py"", line 20, in <module>; from .arpack import *; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\sparse\linalg\eigen\arpack\arpack.py"", line 42, in <module>; from . import _arpack; ImportError: DLL load failed while importing _ar",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173#issuecomment-1073170953
https://github.com/scverse/scanpy/issues/2173#issuecomment-1073170953:2040,Performance,optimiz,optimize,2040,"ProgramData\Miniconda3\lib\site-packages\sklearn\base.py"", line 17, in <module>; from .utils import _IS_32BIT; File ""C:\ProgramData\Miniconda3\lib\site-packages\sklearn\utils\__init__.py"", line 28, in <module>; from .fixes import np_version, parse_version; File ""C:\ProgramData\Miniconda3\lib\site-packages\sklearn\utils\fixes.py"", line 20, in <module>; import scipy.stats; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\stats\__init__.py"", line 441, in <module>; from .stats import *; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\stats\stats.py"", line 43, in <module>; from . import distributions; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\stats\distributions.py"", line 8, in <module>; from ._distn_infrastructure import (rv_discrete, rv_continuous, rv_frozen); File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\stats\_distn_infrastructure.py"", line 24, in <module>; from scipy import optimize; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\optimize\__init__.py"", line 400, in <module>; from .optimize import *; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\optimize\optimize.py"", line 36, in <module>; from ._numdiff import approx_derivative; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\optimize\_numdiff.py"", line 6, in <module>; from scipy.sparse.linalg import LinearOperator; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\sparse\linalg\__init__.py"", line 114, in <module>; from .eigen import *; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\sparse\linalg\eigen\__init__.py"", line 9, in <module>; from .arpack import *; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\sparse\linalg\eigen\arpack\__init__.py"", line 20, in <module>; from .arpack import *; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\sparse\linalg\eigen\arpack\arpack.py"", line 42, in <module>; from . import _arpack; ImportError: DLL load failed while importing _arpack: The specified procedure could not be found.; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173#issuecomment-1073170953
https://github.com/scverse/scanpy/issues/2173#issuecomment-1073170953:2115,Performance,optimiz,optimize,2115,"ProgramData\Miniconda3\lib\site-packages\sklearn\base.py"", line 17, in <module>; from .utils import _IS_32BIT; File ""C:\ProgramData\Miniconda3\lib\site-packages\sklearn\utils\__init__.py"", line 28, in <module>; from .fixes import np_version, parse_version; File ""C:\ProgramData\Miniconda3\lib\site-packages\sklearn\utils\fixes.py"", line 20, in <module>; import scipy.stats; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\stats\__init__.py"", line 441, in <module>; from .stats import *; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\stats\stats.py"", line 43, in <module>; from . import distributions; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\stats\distributions.py"", line 8, in <module>; from ._distn_infrastructure import (rv_discrete, rv_continuous, rv_frozen); File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\stats\_distn_infrastructure.py"", line 24, in <module>; from scipy import optimize; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\optimize\__init__.py"", line 400, in <module>; from .optimize import *; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\optimize\optimize.py"", line 36, in <module>; from ._numdiff import approx_derivative; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\optimize\_numdiff.py"", line 6, in <module>; from scipy.sparse.linalg import LinearOperator; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\sparse\linalg\__init__.py"", line 114, in <module>; from .eigen import *; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\sparse\linalg\eigen\__init__.py"", line 9, in <module>; from .arpack import *; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\sparse\linalg\eigen\arpack\__init__.py"", line 20, in <module>; from .arpack import *; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\sparse\linalg\eigen\arpack\arpack.py"", line 42, in <module>; from . import _arpack; ImportError: DLL load failed while importing _arpack: The specified procedure could not be found.; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173#issuecomment-1073170953
https://github.com/scverse/scanpy/issues/2173#issuecomment-1073170953:2124,Performance,optimiz,optimize,2124,"ProgramData\Miniconda3\lib\site-packages\sklearn\base.py"", line 17, in <module>; from .utils import _IS_32BIT; File ""C:\ProgramData\Miniconda3\lib\site-packages\sklearn\utils\__init__.py"", line 28, in <module>; from .fixes import np_version, parse_version; File ""C:\ProgramData\Miniconda3\lib\site-packages\sklearn\utils\fixes.py"", line 20, in <module>; import scipy.stats; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\stats\__init__.py"", line 441, in <module>; from .stats import *; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\stats\stats.py"", line 43, in <module>; from . import distributions; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\stats\distributions.py"", line 8, in <module>; from ._distn_infrastructure import (rv_discrete, rv_continuous, rv_frozen); File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\stats\_distn_infrastructure.py"", line 24, in <module>; from scipy import optimize; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\optimize\__init__.py"", line 400, in <module>; from .optimize import *; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\optimize\optimize.py"", line 36, in <module>; from ._numdiff import approx_derivative; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\optimize\_numdiff.py"", line 6, in <module>; from scipy.sparse.linalg import LinearOperator; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\sparse\linalg\__init__.py"", line 114, in <module>; from .eigen import *; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\sparse\linalg\eigen\__init__.py"", line 9, in <module>; from .arpack import *; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\sparse\linalg\eigen\arpack\__init__.py"", line 20, in <module>; from .arpack import *; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\sparse\linalg\eigen\arpack\arpack.py"", line 42, in <module>; from . import _arpack; ImportError: DLL load failed while importing _arpack: The specified procedure could not be found.; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173#issuecomment-1073170953
https://github.com/scverse/scanpy/issues/2173#issuecomment-1073170953:2257,Performance,optimiz,optimize,2257,"ProgramData\Miniconda3\lib\site-packages\sklearn\base.py"", line 17, in <module>; from .utils import _IS_32BIT; File ""C:\ProgramData\Miniconda3\lib\site-packages\sklearn\utils\__init__.py"", line 28, in <module>; from .fixes import np_version, parse_version; File ""C:\ProgramData\Miniconda3\lib\site-packages\sklearn\utils\fixes.py"", line 20, in <module>; import scipy.stats; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\stats\__init__.py"", line 441, in <module>; from .stats import *; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\stats\stats.py"", line 43, in <module>; from . import distributions; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\stats\distributions.py"", line 8, in <module>; from ._distn_infrastructure import (rv_discrete, rv_continuous, rv_frozen); File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\stats\_distn_infrastructure.py"", line 24, in <module>; from scipy import optimize; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\optimize\__init__.py"", line 400, in <module>; from .optimize import *; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\optimize\optimize.py"", line 36, in <module>; from ._numdiff import approx_derivative; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\optimize\_numdiff.py"", line 6, in <module>; from scipy.sparse.linalg import LinearOperator; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\sparse\linalg\__init__.py"", line 114, in <module>; from .eigen import *; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\sparse\linalg\eigen\__init__.py"", line 9, in <module>; from .arpack import *; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\sparse\linalg\eigen\arpack\__init__.py"", line 20, in <module>; from .arpack import *; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\sparse\linalg\eigen\arpack\arpack.py"", line 42, in <module>; from . import _arpack; ImportError: DLL load failed while importing _arpack: The specified procedure could not be found.; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173#issuecomment-1073170953
https://github.com/scverse/scanpy/issues/2173#issuecomment-1073170953:2911,Performance,load,load,2911,"ProgramData\Miniconda3\lib\site-packages\sklearn\base.py"", line 17, in <module>; from .utils import _IS_32BIT; File ""C:\ProgramData\Miniconda3\lib\site-packages\sklearn\utils\__init__.py"", line 28, in <module>; from .fixes import np_version, parse_version; File ""C:\ProgramData\Miniconda3\lib\site-packages\sklearn\utils\fixes.py"", line 20, in <module>; import scipy.stats; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\stats\__init__.py"", line 441, in <module>; from .stats import *; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\stats\stats.py"", line 43, in <module>; from . import distributions; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\stats\distributions.py"", line 8, in <module>; from ._distn_infrastructure import (rv_discrete, rv_continuous, rv_frozen); File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\stats\_distn_infrastructure.py"", line 24, in <module>; from scipy import optimize; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\optimize\__init__.py"", line 400, in <module>; from .optimize import *; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\optimize\optimize.py"", line 36, in <module>; from ._numdiff import approx_derivative; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\optimize\_numdiff.py"", line 6, in <module>; from scipy.sparse.linalg import LinearOperator; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\sparse\linalg\__init__.py"", line 114, in <module>; from .eigen import *; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\sparse\linalg\eigen\__init__.py"", line 9, in <module>; from .arpack import *; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\sparse\linalg\eigen\arpack\__init__.py"", line 20, in <module>; from .arpack import *; File ""C:\ProgramData\Miniconda3\lib\site-packages\scipy\sparse\linalg\eigen\arpack\arpack.py"", line 42, in <module>; from . import _arpack; ImportError: DLL load failed while importing _arpack: The specified procedure could not be found.; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173#issuecomment-1073170953
https://github.com/scverse/scanpy/issues/2173#issuecomment-1693404137:22,Availability,error,error,22,"Hello, I get the same error when importing scanpy on 7bridges. ```pytb; ---------------------------------------------------------------------------; ImportError Traceback (most recent call last); /tmp/ipykernel_109/912249142.py in <module>; ----> 1 import scanpy as sc. /opt/conda/lib/python3.9/site-packages/scanpy/__init__.py in <module>; 14 from . import tools as tl; 15 from . import preprocessing as pp; ---> 16 from . import plotting as pl; 17 from . import datasets, logging, queries, external, get, metrics, experimental; 18 . /opt/conda/lib/python3.9/site-packages/scanpy/plotting/__init__.py in <module>; 14 from ._preprocessing import filter_genes_dispersion, highly_variable_genes; 15 ; ---> 16 from ._tools.scatterplots import (; 17 embedding,; 18 pca,. /opt/conda/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in <module>; 8 from matplotlib.colors import Normalize; 9 from matplotlib import pyplot as pl; ---> 10 from matplotlib import rcParams, colormaps; 11 from anndata import AnnData; 12 from typing import Union, Optional, List, Sequence, Iterable, Mapping, Literal. ImportError: cannot import name 'colormaps' from 'matplotlib' (/opt/conda/lib/python3.9/site-packages/matplotlib/__init__.py); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173#issuecomment-1693404137
https://github.com/scverse/scanpy/issues/2173#issuecomment-1693404137:474,Testability,log,logging,474,"Hello, I get the same error when importing scanpy on 7bridges. ```pytb; ---------------------------------------------------------------------------; ImportError Traceback (most recent call last); /tmp/ipykernel_109/912249142.py in <module>; ----> 1 import scanpy as sc. /opt/conda/lib/python3.9/site-packages/scanpy/__init__.py in <module>; 14 from . import tools as tl; 15 from . import preprocessing as pp; ---> 16 from . import plotting as pl; 17 from . import datasets, logging, queries, external, get, metrics, experimental; 18 . /opt/conda/lib/python3.9/site-packages/scanpy/plotting/__init__.py in <module>; 14 from ._preprocessing import filter_genes_dispersion, highly_variable_genes; 15 ; ---> 16 from ._tools.scatterplots import (; 17 embedding,; 18 pca,. /opt/conda/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in <module>; 8 from matplotlib.colors import Normalize; 9 from matplotlib import pyplot as pl; ---> 10 from matplotlib import rcParams, colormaps; 11 from anndata import AnnData; 12 from typing import Union, Optional, List, Sequence, Iterable, Mapping, Literal. ImportError: cannot import name 'colormaps' from 'matplotlib' (/opt/conda/lib/python3.9/site-packages/matplotlib/__init__.py); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173#issuecomment-1693404137
https://github.com/scverse/scanpy/issues/2173#issuecomment-1693549285:243,Deployability,update,update,243,"Hi @IfSumia, that’s a very different problem, see the last line:. ```pytb; ImportError: cannot import name 'colormaps' from 'matplotlib' (/opt/conda/lib/python3.9/site-packages/matplotlib/__init__.py); ```. This probably means that you should update matplotlib and try again",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173#issuecomment-1693549285
https://github.com/scverse/scanpy/pull/2174#issuecomment-1066709010:1916,Availability,error,errors,1916,"ames); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/application.py"", line 343, in build; self.builder.build_update(); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/builders/__init__.py"", line 293, in build_update; self.build(to_build,; File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/builders/__init__.py"", line 307, in build; updated_docnames = set(self.read()); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/contextlib.py"", line 120, in __exit__; next(self.gen); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings; memhandler.flushTo(logger); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/util/logging.py"", line 178, in flushTo; logger.handle(record); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/logging/__init__.py"", line 1587, in handle; self.callHandlers(record); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/logging/__init__.py"", line 1649, in callHandlers; hdlr.handle(record); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/logging/__init__.py"", line 946, in handle; rv = self.filter(record); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/logging/__init__.py"", line 807, in filter; result = f.filter(record); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/util/logging.py"", line 423, in filter; raise exc; sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/2174/scanpy/external/pp/_mnn_correct.py:docstring of scanpy.external.pp._mnn_correct.mnn_correct:76:Inline interpreted text or phrase reference start-string without end-string.; ```. Sigh, why are our jobs so flaky?....",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2174#issuecomment-1066709010
https://github.com/scverse/scanpy/pull/2174#issuecomment-1066709010:1009,Testability,log,logging,1009,"```pytb; Traceback (most recent call last):; File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/cmd/build.py"", line 280, in build_main; app.build(args.force_all, filenames); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/application.py"", line 343, in build; self.builder.build_update(); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/builders/__init__.py"", line 293, in build_update; self.build(to_build,; File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/builders/__init__.py"", line 307, in build; updated_docnames = set(self.read()); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/contextlib.py"", line 120, in __exit__; next(self.gen); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings; memhandler.flushTo(logger); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/util/logging.py"", line 178, in flushTo; logger.handle(record); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/logging/__init__.py"", line 1587, in handle; self.callHandlers(record); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/logging/__init__.py"", line 1649, in callHandlers; hdlr.handle(record); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/logging/__init__.py"", line 946, in handle; rv = self.filter(record); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/logging/__init__.py"", line 807, in filter; result = f.filter(record); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/util/logging.py"", line 423, in filter; raise exc; sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/che",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2174#issuecomment-1066709010
https://github.com/scverse/scanpy/pull/2174#issuecomment-1066709010:1072,Testability,log,logger,1072,"_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/cmd/build.py"", line 280, in build_main; app.build(args.force_all, filenames); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/application.py"", line 343, in build; self.builder.build_update(); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/builders/__init__.py"", line 293, in build_update; self.build(to_build,; File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/builders/__init__.py"", line 307, in build; updated_docnames = set(self.read()); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/contextlib.py"", line 120, in __exit__; next(self.gen); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings; memhandler.flushTo(logger); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/util/logging.py"", line 178, in flushTo; logger.handle(record); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/logging/__init__.py"", line 1587, in handle; self.callHandlers(record); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/logging/__init__.py"", line 1649, in callHandlers; hdlr.handle(record); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/logging/__init__.py"", line 946, in handle; rv = self.filter(record); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/logging/__init__.py"", line 807, in filter; result = f.filter(record); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/util/logging.py"", line 423, in filter; raise exc; sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/2174/scanpy/external/pp/_mnn_correct.py:docstring of scanpy.external.pp._mnn_correct",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2174#issuecomment-1066709010
https://github.com/scverse/scanpy/pull/2174#issuecomment-1066709010:1197,Testability,log,logging,1197,"ld_main; app.build(args.force_all, filenames); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/application.py"", line 343, in build; self.builder.build_update(); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/builders/__init__.py"", line 293, in build_update; self.build(to_build,; File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/builders/__init__.py"", line 307, in build; updated_docnames = set(self.read()); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/contextlib.py"", line 120, in __exit__; next(self.gen); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings; memhandler.flushTo(logger); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/util/logging.py"", line 178, in flushTo; logger.handle(record); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/logging/__init__.py"", line 1587, in handle; self.callHandlers(record); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/logging/__init__.py"", line 1649, in callHandlers; hdlr.handle(record); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/logging/__init__.py"", line 946, in handle; rv = self.filter(record); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/logging/__init__.py"", line 807, in filter; result = f.filter(record); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/util/logging.py"", line 423, in filter; raise exc; sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/2174/scanpy/external/pp/_mnn_correct.py:docstring of scanpy.external.pp._mnn_correct.mnn_correct:76:Inline interpreted text or phrase reference start-string without end-string.; `",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2174#issuecomment-1066709010
https://github.com/scverse/scanpy/pull/2174#issuecomment-1066709010:1232,Testability,log,logger,1232,"filenames); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/application.py"", line 343, in build; self.builder.build_update(); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/builders/__init__.py"", line 293, in build_update; self.build(to_build,; File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/builders/__init__.py"", line 307, in build; updated_docnames = set(self.read()); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/contextlib.py"", line 120, in __exit__; next(self.gen); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings; memhandler.flushTo(logger); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/util/logging.py"", line 178, in flushTo; logger.handle(record); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/logging/__init__.py"", line 1587, in handle; self.callHandlers(record); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/logging/__init__.py"", line 1649, in callHandlers; hdlr.handle(record); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/logging/__init__.py"", line 946, in handle; rv = self.filter(record); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/logging/__init__.py"", line 807, in filter; result = f.filter(record); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/util/logging.py"", line 423, in filter; raise exc; sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/2174/scanpy/external/pp/_mnn_correct.py:docstring of scanpy.external.pp._mnn_correct.mnn_correct:76:Inline interpreted text or phrase reference start-string without end-string.; ```. Sigh, why are our jobs so flaky",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2174#issuecomment-1066709010
https://github.com/scverse/scanpy/pull/2174#issuecomment-1066709010:1308,Testability,log,logging,1308,"ames); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/application.py"", line 343, in build; self.builder.build_update(); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/builders/__init__.py"", line 293, in build_update; self.build(to_build,; File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/builders/__init__.py"", line 307, in build; updated_docnames = set(self.read()); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/contextlib.py"", line 120, in __exit__; next(self.gen); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings; memhandler.flushTo(logger); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/util/logging.py"", line 178, in flushTo; logger.handle(record); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/logging/__init__.py"", line 1587, in handle; self.callHandlers(record); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/logging/__init__.py"", line 1649, in callHandlers; hdlr.handle(record); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/logging/__init__.py"", line 946, in handle; rv = self.filter(record); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/logging/__init__.py"", line 807, in filter; result = f.filter(record); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/util/logging.py"", line 423, in filter; raise exc; sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/2174/scanpy/external/pp/_mnn_correct.py:docstring of scanpy.external.pp._mnn_correct.mnn_correct:76:Inline interpreted text or phrase reference start-string without end-string.; ```. Sigh, why are our jobs so flaky?....",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2174#issuecomment-1066709010
https://github.com/scverse/scanpy/pull/2174#issuecomment-1066709010:1432,Testability,log,logging,1432,"ames); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/application.py"", line 343, in build; self.builder.build_update(); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/builders/__init__.py"", line 293, in build_update; self.build(to_build,; File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/builders/__init__.py"", line 307, in build; updated_docnames = set(self.read()); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/contextlib.py"", line 120, in __exit__; next(self.gen); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings; memhandler.flushTo(logger); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/util/logging.py"", line 178, in flushTo; logger.handle(record); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/logging/__init__.py"", line 1587, in handle; self.callHandlers(record); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/logging/__init__.py"", line 1649, in callHandlers; hdlr.handle(record); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/logging/__init__.py"", line 946, in handle; rv = self.filter(record); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/logging/__init__.py"", line 807, in filter; result = f.filter(record); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/util/logging.py"", line 423, in filter; raise exc; sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/2174/scanpy/external/pp/_mnn_correct.py:docstring of scanpy.external.pp._mnn_correct.mnn_correct:76:Inline interpreted text or phrase reference start-string without end-string.; ```. Sigh, why are our jobs so flaky?....",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2174#issuecomment-1066709010
https://github.com/scverse/scanpy/pull/2174#issuecomment-1066709010:1556,Testability,log,logging,1556,"ames); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/application.py"", line 343, in build; self.builder.build_update(); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/builders/__init__.py"", line 293, in build_update; self.build(to_build,; File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/builders/__init__.py"", line 307, in build; updated_docnames = set(self.read()); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/contextlib.py"", line 120, in __exit__; next(self.gen); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings; memhandler.flushTo(logger); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/util/logging.py"", line 178, in flushTo; logger.handle(record); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/logging/__init__.py"", line 1587, in handle; self.callHandlers(record); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/logging/__init__.py"", line 1649, in callHandlers; hdlr.handle(record); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/logging/__init__.py"", line 946, in handle; rv = self.filter(record); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/logging/__init__.py"", line 807, in filter; result = f.filter(record); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/util/logging.py"", line 423, in filter; raise exc; sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/2174/scanpy/external/pp/_mnn_correct.py:docstring of scanpy.external.pp._mnn_correct.mnn_correct:76:Inline interpreted text or phrase reference start-string without end-string.; ```. Sigh, why are our jobs so flaky?....",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2174#issuecomment-1066709010
https://github.com/scverse/scanpy/pull/2174#issuecomment-1066709010:1678,Testability,log,logging,1678,"ames); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/application.py"", line 343, in build; self.builder.build_update(); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/builders/__init__.py"", line 293, in build_update; self.build(to_build,; File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/builders/__init__.py"", line 307, in build; updated_docnames = set(self.read()); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/contextlib.py"", line 120, in __exit__; next(self.gen); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings; memhandler.flushTo(logger); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/util/logging.py"", line 178, in flushTo; logger.handle(record); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/logging/__init__.py"", line 1587, in handle; self.callHandlers(record); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/logging/__init__.py"", line 1649, in callHandlers; hdlr.handle(record); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/logging/__init__.py"", line 946, in handle; rv = self.filter(record); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/logging/__init__.py"", line 807, in filter; result = f.filter(record); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/util/logging.py"", line 423, in filter; raise exc; sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/2174/scanpy/external/pp/_mnn_correct.py:docstring of scanpy.external.pp._mnn_correct.mnn_correct:76:Inline interpreted text or phrase reference start-string without end-string.; ```. Sigh, why are our jobs so flaky?....",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2174#issuecomment-1066709010
https://github.com/scverse/scanpy/pull/2174#issuecomment-1066709010:1864,Testability,log,logging,1864,"ames); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/application.py"", line 343, in build; self.builder.build_update(); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/builders/__init__.py"", line 293, in build_update; self.build(to_build,; File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/builders/__init__.py"", line 307, in build; updated_docnames = set(self.read()); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/contextlib.py"", line 120, in __exit__; next(self.gen); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings; memhandler.flushTo(logger); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/util/logging.py"", line 178, in flushTo; logger.handle(record); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/logging/__init__.py"", line 1587, in handle; self.callHandlers(record); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/logging/__init__.py"", line 1649, in callHandlers; hdlr.handle(record); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/logging/__init__.py"", line 946, in handle; rv = self.filter(record); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/logging/__init__.py"", line 807, in filter; result = f.filter(record); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/util/logging.py"", line 423, in filter; raise exc; sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/2174/scanpy/external/pp/_mnn_correct.py:docstring of scanpy.external.pp._mnn_correct.mnn_correct:76:Inline interpreted text or phrase reference start-string without end-string.; ```. Sigh, why are our jobs so flaky?....",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2174#issuecomment-1066709010
https://github.com/scverse/scanpy/pull/2175#issuecomment-1068381662:80,Integrability,depend,dependency,80,Thanks @stkmrc!. Could you merge master into this PR? It looks like there was a dependency issue that should be fixed now.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2175#issuecomment-1068381662
https://github.com/scverse/scanpy/issues/2178#issuecomment-1068920599:105,Deployability,install,install,105,"I think I see the issue here. The bioconda distribution of scanpy is out of date and unsupported, please install it from condo-forge instead:. https://scanpy.readthedocs.io/en/latest/installation.html#anaconda",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178#issuecomment-1068920599
https://github.com/scverse/scanpy/issues/2178#issuecomment-1068920599:183,Deployability,install,installation,183,"I think I see the issue here. The bioconda distribution of scanpy is out of date and unsupported, please install it from condo-forge instead:. https://scanpy.readthedocs.io/en/latest/installation.html#anaconda",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178#issuecomment-1068920599
https://github.com/scverse/scanpy/pull/2179#issuecomment-1074431745:242,Availability,error,errors,242,"@PGmajev, I would recommend setting up pre-commit for the repo (as described in the contributing guide [here](https://scanpy.readthedocs.io/en/latest/dev/getting-set-up.html#pre-commit)). It should save you from dealing with these formatting errors.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2179#issuecomment-1074431745
https://github.com/scverse/scanpy/pull/2179#issuecomment-1074431745:97,Usability,guid,guide,97,"@PGmajev, I would recommend setting up pre-commit for the repo (as described in the contributing guide [here](https://scanpy.readthedocs.io/en/latest/dev/getting-set-up.html#pre-commit)). It should save you from dealing with these formatting errors.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2179#issuecomment-1074431745
https://github.com/scverse/scanpy/pull/2179#issuecomment-1074432061:165,Testability,test,test,165,"Hey @ivirshup,. thank you for your reply. I was not aware of that issue, but yes, this PR should solve it. I did not know where and how exactly you would prefer the test to be. So for now I put it in test_pca.py and I run a full pca on the pbmc3k data. This might of course be a bit much. Shall I provide and/or use some even smaller sample data?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2179#issuecomment-1074432061
https://github.com/scverse/scanpy/pull/2179#issuecomment-1076261309:241,Deployability,release,release,241,"No worries. . Right now I'm just thinking of whether this should be called `n_dims` now, and trying to figure out why I have the sneaking suspicion that this broke something last time I looked at it. One last thing from you, could you add a release note to `docs/release-notes/1.9.0.md`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2179#issuecomment-1076261309
https://github.com/scverse/scanpy/pull/2179#issuecomment-1076261309:263,Deployability,release,release-notes,263,"No worries. . Right now I'm just thinking of whether this should be called `n_dims` now, and trying to figure out why I have the sneaking suspicion that this broke something last time I looked at it. One last thing from you, could you add a release note to `docs/release-notes/1.9.0.md`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2179#issuecomment-1076261309
https://github.com/scverse/scanpy/pull/2179#issuecomment-1076393928:51,Deployability,release,release,51,"@ivirshup Thank you for the feedback. I will add a release note soon. I also thought about the naming of the parameter. However, if we assume that also in the future it is mostly used to subset the number of PCs in PCA arrays stored under different names, it should be fine?. I can not comment further on what these changes may break, at least ideally they should make the use of n_pcs more consistent and as expected. Would you suggest, I implement some further, more comprehensive tests?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2179#issuecomment-1076393928
https://github.com/scverse/scanpy/pull/2179#issuecomment-1076393928:483,Testability,test,tests,483,"@ivirshup Thank you for the feedback. I will add a release note soon. I also thought about the naming of the parameter. However, if we assume that also in the future it is mostly used to subset the number of PCs in PCA arrays stored under different names, it should be fine?. I can not comment further on what these changes may break, at least ideally they should make the use of n_pcs more consistent and as expected. Would you suggest, I implement some further, more comprehensive tests?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2179#issuecomment-1076393928
https://github.com/scverse/scanpy/pull/2179#issuecomment-1076393928:28,Usability,feedback,feedback,28,"@ivirshup Thank you for the feedback. I will add a release note soon. I also thought about the naming of the parameter. However, if we assume that also in the future it is mostly used to subset the number of PCs in PCA arrays stored under different names, it should be fine?. I can not comment further on what these changes may break, at least ideally they should make the use of n_pcs more consistent and as expected. Would you suggest, I implement some further, more comprehensive tests?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2179#issuecomment-1076393928
https://github.com/scverse/scanpy/pull/2179#issuecomment-1081877491:401,Availability,avail,available,401,"I think you're all good. Taking another look at the function I believe I had actually tried to completely replace the whole thing (since the logic is fairly convoluted), which ended up breaking functions that relied on the convoluted parts. I think ultimately the whole function should be replaced, ideally using `sc.get._get_obs_rep`. At that point we can rename the argument and make it more widely available.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2179#issuecomment-1081877491
https://github.com/scverse/scanpy/pull/2179#issuecomment-1081877491:141,Testability,log,logic,141,"I think you're all good. Taking another look at the function I believe I had actually tried to completely replace the whole thing (since the logic is fairly convoluted), which ended up breaking functions that relied on the convoluted parts. I think ultimately the whole function should be replaced, ideally using `sc.get._get_obs_rep`. At that point we can rename the argument and make it more widely available.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2179#issuecomment-1081877491
https://github.com/scverse/scanpy/issues/2180#issuecomment-1073786068:126,Safety,detect,detection,126,"Hi @ThomasThaewel,; In the current best-practices paper the recommendation is to use ""measured data"" as input for marker gene detection. This includes both raw, normalized, and log-normalized data formats. If you are using a count modelling approach for differential expression analysis (e.g., negative binomial, poisson), then you should use raw data (not-normalized) and include size factors in the model. For non-parametric approaches like the ones implemented in `sc.tl.rank_genes_groups()` log-normalized data is better. Hope that clarifies things.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2180#issuecomment-1073786068
https://github.com/scverse/scanpy/issues/2180#issuecomment-1073786068:177,Testability,log,log-normalized,177,"Hi @ThomasThaewel,; In the current best-practices paper the recommendation is to use ""measured data"" as input for marker gene detection. This includes both raw, normalized, and log-normalized data formats. If you are using a count modelling approach for differential expression analysis (e.g., negative binomial, poisson), then you should use raw data (not-normalized) and include size factors in the model. For non-parametric approaches like the ones implemented in `sc.tl.rank_genes_groups()` log-normalized data is better. Hope that clarifies things.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2180#issuecomment-1073786068
https://github.com/scverse/scanpy/issues/2180#issuecomment-1073786068:495,Testability,log,log-normalized,495,"Hi @ThomasThaewel,; In the current best-practices paper the recommendation is to use ""measured data"" as input for marker gene detection. This includes both raw, normalized, and log-normalized data formats. If you are using a count modelling approach for differential expression analysis (e.g., negative binomial, poisson), then you should use raw data (not-normalized) and include size factors in the model. For non-parametric approaches like the ones implemented in `sc.tl.rank_genes_groups()` log-normalized data is better. Hope that clarifies things.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2180#issuecomment-1073786068
https://github.com/scverse/scanpy/pull/2183#issuecomment-1081870894:57,Testability,test,test,57,That definitely looks wrong on our end.... Can you add a test for this?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2183#issuecomment-1081870894
https://github.com/scverse/scanpy/issues/2189#issuecomment-1077460049:116,Deployability,upgrade,upgrade,116,"> Thanks, I am running the version of `1.4.5.1`. Assuming that it is one of 1.4.1 or 1.5.1 I would suggest that you upgrade to the latest scanpy version. What you are using is quite old. If the problem still occurs we can discuss it further.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2189#issuecomment-1077460049
https://github.com/scverse/scanpy/pull/2190#issuecomment-1079689047:46,Security,validat,validate,46,Thank you!. Would it be possible to catch and validate this behavior with a test here https://github.com/theislab/scanpy/blob/master/scanpy/tests/external/test_hashsolo.py ?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2190#issuecomment-1079689047
https://github.com/scverse/scanpy/pull/2190#issuecomment-1079689047:76,Testability,test,test,76,Thank you!. Would it be possible to catch and validate this behavior with a test here https://github.com/theislab/scanpy/blob/master/scanpy/tests/external/test_hashsolo.py ?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2190#issuecomment-1079689047
https://github.com/scverse/scanpy/pull/2190#issuecomment-1079689047:140,Testability,test,tests,140,Thank you!. Would it be possible to catch and validate this behavior with a test here https://github.com/theislab/scanpy/blob/master/scanpy/tests/external/test_hashsolo.py ?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2190#issuecomment-1079689047
https://github.com/scverse/scanpy/pull/2190#issuecomment-1081869351:94,Deployability,release,release,94,"@LustigePerson, would you be able to add a quick test here? Then this could get into the next release",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2190#issuecomment-1081869351
https://github.com/scverse/scanpy/pull/2190#issuecomment-1081869351:49,Testability,test,test,49,"@LustigePerson, would you be able to add a quick test here? Then this could get into the next release",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2190#issuecomment-1081869351
https://github.com/scverse/scanpy/pull/2190#issuecomment-1082217533:34,Testability,test,testdata,34,"I just increased the noise in the testdata. With this, the assertion fails with the wrong number of noise barcodes.; The original test data was to ""clean"".",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2190#issuecomment-1082217533
https://github.com/scverse/scanpy/pull/2190#issuecomment-1082217533:59,Testability,assert,assertion,59,"I just increased the noise in the testdata. With this, the assertion fails with the wrong number of noise barcodes.; The original test data was to ""clean"".",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2190#issuecomment-1082217533
https://github.com/scverse/scanpy/pull/2190#issuecomment-1082217533:130,Testability,test,test,130,"I just increased the noise in the testdata. With this, the assertion fails with the wrong number of noise barcodes.; The original test data was to ""clean"".",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2190#issuecomment-1082217533
https://github.com/scverse/scanpy/issues/2191#issuecomment-2411290952:6,Testability,test,testing,6,"We’re testing ingest with 3.12 and soon drop support for 3.9, so this should definitely be working. I just ran the tutorial and it works fine: https://github.com/scverse/scanpy-tutorials/pull/139",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191#issuecomment-2411290952
https://github.com/scverse/scanpy/issues/2193#issuecomment-1079813917:7,Testability,log,log,7,"I have log normalised the data and have filtered out the genes. . I have : ; 1. adata.var[adata.var[""n_cells""]==np.nan] - result is 0.; 2. np.isinf(adata.X.todense()).sum() - result is 0. Data I'm using is GSE158055. Link : https://drive.google.com/file/d/1TXDJqOvFkJxbcm2u2-_bM5RBdTOqv56w/view?usp=sharing",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2193#issuecomment-1079813917
https://github.com/scverse/scanpy/issues/2193#issuecomment-1081867209:240,Availability,error,error,240,"Thanks for opening the issue. Can you provide a full traceback with any warnings?. I can replicate this when passing count data, but the issue there seems to have to do with us assuming we're getting log transformed data. I do not see this error when I pass log normalized data. E.g. this works:. ```python; import scanpy as sc; a = sc.read_h5ad(""/Users/isaac/Downloads/GSE158055_covid19.h5ad""); sc.pp.log1p(a); sc.pp.highly_variable_genes(a, n_top_genes=3000, flavor=""seurat""); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2193#issuecomment-1081867209
https://github.com/scverse/scanpy/issues/2193#issuecomment-1081867209:360,Availability,Down,Downloads,360,"Thanks for opening the issue. Can you provide a full traceback with any warnings?. I can replicate this when passing count data, but the issue there seems to have to do with us assuming we're getting log transformed data. I do not see this error when I pass log normalized data. E.g. this works:. ```python; import scanpy as sc; a = sc.read_h5ad(""/Users/isaac/Downloads/GSE158055_covid19.h5ad""); sc.pp.log1p(a); sc.pp.highly_variable_genes(a, n_top_genes=3000, flavor=""seurat""); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2193#issuecomment-1081867209
https://github.com/scverse/scanpy/issues/2193#issuecomment-1081867209:200,Testability,log,log,200,"Thanks for opening the issue. Can you provide a full traceback with any warnings?. I can replicate this when passing count data, but the issue there seems to have to do with us assuming we're getting log transformed data. I do not see this error when I pass log normalized data. E.g. this works:. ```python; import scanpy as sc; a = sc.read_h5ad(""/Users/isaac/Downloads/GSE158055_covid19.h5ad""); sc.pp.log1p(a); sc.pp.highly_variable_genes(a, n_top_genes=3000, flavor=""seurat""); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2193#issuecomment-1081867209
https://github.com/scverse/scanpy/issues/2193#issuecomment-1081867209:258,Testability,log,log,258,"Thanks for opening the issue. Can you provide a full traceback with any warnings?. I can replicate this when passing count data, but the issue there seems to have to do with us assuming we're getting log transformed data. I do not see this error when I pass log normalized data. E.g. this works:. ```python; import scanpy as sc; a = sc.read_h5ad(""/Users/isaac/Downloads/GSE158055_covid19.h5ad""); sc.pp.log1p(a); sc.pp.highly_variable_genes(a, n_top_genes=3000, flavor=""seurat""); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2193#issuecomment-1081867209
https://github.com/scverse/scanpy/issues/2194#issuecomment-1088642888:43,Modifiability,refactor,refactor,43,"I think these plots are well overdue for a refactor. It would make sense to me if the kind of marginal plots were abstracted out into their own classes. Maybe like `MarginalBar`, `MarginalDendrogram`, `MarginalLabels`. But if you have any thoughts about how you think it could be done, or want to talk it over I'd be happy to do that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2194#issuecomment-1088642888
https://github.com/scverse/scanpy/issues/2194#issuecomment-1143890664:147,Availability,avail,available,147,"I just saw on zulip that some of the functions in codaplot could be helpful here, sorry for the late reply. I'll post some more details on what is available in the package here tomorrow :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2194#issuecomment-1143890664
https://github.com/scverse/scanpy/issues/2194#issuecomment-1145123103:1886,Availability,avail,available,1886,"co.cross_plot is one high level possibility to construct complex heatmaps with the 'central data heatmap + annotation heatmaps' layout. Among other things, it can automatically cluster columns or rows based on the central data heatmap and apply the clustering to the annotation heatmaps. It can also plot dendrograms. This is an experimental function with some quirks, I did want to improve the concept soon-ish.; - co.heatmap is the base heatmap plotting function in codaplot. It provides a simple way to plot categorical heatmaps and add spacers within heatmaps. Both tasks are not trivial with matplotlib base plot functions. This would be helpful for adding categorical annotation heatmaps, even if you don't want to use co.cross_plot as it is right now.; - i have an alternative function to co.heatmap in my snippets library which is capable of creating heatmaps using rectangle or circle patches with size and color aesthetics, but i havent added it to codaplot yet. You can always create circle patch heatmaps with standard scatterplots, but this has drawbacks when you want to be able to add spacers within the plot or when you want full control of the circle patch sizes (so that they fit perfectly within the row at maximum size). From what I understand such a patch based function would be helpful, right?. I would be happy to contribute some base functionality for this issue by adding improvements to codaplot, ie provide the circle patch heatmap function and a better complex heatmap function than the currently available co.cross_plot. I do plan on maintaining codaplot for the foreseeable future and have been using it for my own projects for quite a while now. At the moment it's a relatively small library (when you subtract the experimental modules) and could be quickly refactored into a single scanpy module if something happens and I find myself unable to maintain and expand the library over the next years. . Does using codaplot for this issue sound at all interesting to you?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2194#issuecomment-1145123103
https://github.com/scverse/scanpy/issues/2194#issuecomment-1145123103:148,Deployability,patch,patches,148,"From what I can gather, one goal here is to refactor the dotplot function and give it a complex heatmap layout, with a central heatmap using circle patches with a color and size aesthetic (= the dotplot) and one or more annotation heatmaps for rows and columns, which could be categorical or quantitative each. Potentially relevant features in codaplot are. - co.cross_plot is one high level possibility to construct complex heatmaps with the 'central data heatmap + annotation heatmaps' layout. Among other things, it can automatically cluster columns or rows based on the central data heatmap and apply the clustering to the annotation heatmaps. It can also plot dendrograms. This is an experimental function with some quirks, I did want to improve the concept soon-ish.; - co.heatmap is the base heatmap plotting function in codaplot. It provides a simple way to plot categorical heatmaps and add spacers within heatmaps. Both tasks are not trivial with matplotlib base plot functions. This would be helpful for adding categorical annotation heatmaps, even if you don't want to use co.cross_plot as it is right now.; - i have an alternative function to co.heatmap in my snippets library which is capable of creating heatmaps using rectangle or circle patches with size and color aesthetics, but i havent added it to codaplot yet. You can always create circle patch heatmaps with standard scatterplots, but this has drawbacks when you want to be able to add spacers within the plot or when you want full control of the circle patch sizes (so that they fit perfectly within the row at maximum size). From what I understand such a patch based function would be helpful, right?. I would be happy to contribute some base functionality for this issue by adding improvements to codaplot, ie provide the circle patch heatmap function and a better complex heatmap function than the currently available co.cross_plot. I do plan on maintaining codaplot for the foreseeable future and have been using it for my",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2194#issuecomment-1145123103
https://github.com/scverse/scanpy/issues/2194#issuecomment-1145123103:1254,Deployability,patch,patches,1254,"ows and columns, which could be categorical or quantitative each. Potentially relevant features in codaplot are. - co.cross_plot is one high level possibility to construct complex heatmaps with the 'central data heatmap + annotation heatmaps' layout. Among other things, it can automatically cluster columns or rows based on the central data heatmap and apply the clustering to the annotation heatmaps. It can also plot dendrograms. This is an experimental function with some quirks, I did want to improve the concept soon-ish.; - co.heatmap is the base heatmap plotting function in codaplot. It provides a simple way to plot categorical heatmaps and add spacers within heatmaps. Both tasks are not trivial with matplotlib base plot functions. This would be helpful for adding categorical annotation heatmaps, even if you don't want to use co.cross_plot as it is right now.; - i have an alternative function to co.heatmap in my snippets library which is capable of creating heatmaps using rectangle or circle patches with size and color aesthetics, but i havent added it to codaplot yet. You can always create circle patch heatmaps with standard scatterplots, but this has drawbacks when you want to be able to add spacers within the plot or when you want full control of the circle patch sizes (so that they fit perfectly within the row at maximum size). From what I understand such a patch based function would be helpful, right?. I would be happy to contribute some base functionality for this issue by adding improvements to codaplot, ie provide the circle patch heatmap function and a better complex heatmap function than the currently available co.cross_plot. I do plan on maintaining codaplot for the foreseeable future and have been using it for my own projects for quite a while now. At the moment it's a relatively small library (when you subtract the experimental modules) and could be quickly refactored into a single scanpy module if something happens and I find myself unable to maintain",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2194#issuecomment-1145123103
https://github.com/scverse/scanpy/issues/2194#issuecomment-1145123103:1362,Deployability,patch,patch,1362,"co.cross_plot is one high level possibility to construct complex heatmaps with the 'central data heatmap + annotation heatmaps' layout. Among other things, it can automatically cluster columns or rows based on the central data heatmap and apply the clustering to the annotation heatmaps. It can also plot dendrograms. This is an experimental function with some quirks, I did want to improve the concept soon-ish.; - co.heatmap is the base heatmap plotting function in codaplot. It provides a simple way to plot categorical heatmaps and add spacers within heatmaps. Both tasks are not trivial with matplotlib base plot functions. This would be helpful for adding categorical annotation heatmaps, even if you don't want to use co.cross_plot as it is right now.; - i have an alternative function to co.heatmap in my snippets library which is capable of creating heatmaps using rectangle or circle patches with size and color aesthetics, but i havent added it to codaplot yet. You can always create circle patch heatmaps with standard scatterplots, but this has drawbacks when you want to be able to add spacers within the plot or when you want full control of the circle patch sizes (so that they fit perfectly within the row at maximum size). From what I understand such a patch based function would be helpful, right?. I would be happy to contribute some base functionality for this issue by adding improvements to codaplot, ie provide the circle patch heatmap function and a better complex heatmap function than the currently available co.cross_plot. I do plan on maintaining codaplot for the foreseeable future and have been using it for my own projects for quite a while now. At the moment it's a relatively small library (when you subtract the experimental modules) and could be quickly refactored into a single scanpy module if something happens and I find myself unable to maintain and expand the library over the next years. . Does using codaplot for this issue sound at all interesting to you?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2194#issuecomment-1145123103
https://github.com/scverse/scanpy/issues/2194#issuecomment-1145123103:1528,Deployability,patch,patch,1528,"co.cross_plot is one high level possibility to construct complex heatmaps with the 'central data heatmap + annotation heatmaps' layout. Among other things, it can automatically cluster columns or rows based on the central data heatmap and apply the clustering to the annotation heatmaps. It can also plot dendrograms. This is an experimental function with some quirks, I did want to improve the concept soon-ish.; - co.heatmap is the base heatmap plotting function in codaplot. It provides a simple way to plot categorical heatmaps and add spacers within heatmaps. Both tasks are not trivial with matplotlib base plot functions. This would be helpful for adding categorical annotation heatmaps, even if you don't want to use co.cross_plot as it is right now.; - i have an alternative function to co.heatmap in my snippets library which is capable of creating heatmaps using rectangle or circle patches with size and color aesthetics, but i havent added it to codaplot yet. You can always create circle patch heatmaps with standard scatterplots, but this has drawbacks when you want to be able to add spacers within the plot or when you want full control of the circle patch sizes (so that they fit perfectly within the row at maximum size). From what I understand such a patch based function would be helpful, right?. I would be happy to contribute some base functionality for this issue by adding improvements to codaplot, ie provide the circle patch heatmap function and a better complex heatmap function than the currently available co.cross_plot. I do plan on maintaining codaplot for the foreseeable future and have been using it for my own projects for quite a while now. At the moment it's a relatively small library (when you subtract the experimental modules) and could be quickly refactored into a single scanpy module if something happens and I find myself unable to maintain and expand the library over the next years. . Does using codaplot for this issue sound at all interesting to you?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2194#issuecomment-1145123103
https://github.com/scverse/scanpy/issues/2194#issuecomment-1145123103:1631,Deployability,patch,patch,1631,"co.cross_plot is one high level possibility to construct complex heatmaps with the 'central data heatmap + annotation heatmaps' layout. Among other things, it can automatically cluster columns or rows based on the central data heatmap and apply the clustering to the annotation heatmaps. It can also plot dendrograms. This is an experimental function with some quirks, I did want to improve the concept soon-ish.; - co.heatmap is the base heatmap plotting function in codaplot. It provides a simple way to plot categorical heatmaps and add spacers within heatmaps. Both tasks are not trivial with matplotlib base plot functions. This would be helpful for adding categorical annotation heatmaps, even if you don't want to use co.cross_plot as it is right now.; - i have an alternative function to co.heatmap in my snippets library which is capable of creating heatmaps using rectangle or circle patches with size and color aesthetics, but i havent added it to codaplot yet. You can always create circle patch heatmaps with standard scatterplots, but this has drawbacks when you want to be able to add spacers within the plot or when you want full control of the circle patch sizes (so that they fit perfectly within the row at maximum size). From what I understand such a patch based function would be helpful, right?. I would be happy to contribute some base functionality for this issue by adding improvements to codaplot, ie provide the circle patch heatmap function and a better complex heatmap function than the currently available co.cross_plot. I do plan on maintaining codaplot for the foreseeable future and have been using it for my own projects for quite a while now. At the moment it's a relatively small library (when you subtract the experimental modules) and could be quickly refactored into a single scanpy module if something happens and I find myself unable to maintain and expand the library over the next years. . Does using codaplot for this issue sound at all interesting to you?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2194#issuecomment-1145123103
https://github.com/scverse/scanpy/issues/2194#issuecomment-1145123103:1806,Deployability,patch,patch,1806,"co.cross_plot is one high level possibility to construct complex heatmaps with the 'central data heatmap + annotation heatmaps' layout. Among other things, it can automatically cluster columns or rows based on the central data heatmap and apply the clustering to the annotation heatmaps. It can also plot dendrograms. This is an experimental function with some quirks, I did want to improve the concept soon-ish.; - co.heatmap is the base heatmap plotting function in codaplot. It provides a simple way to plot categorical heatmaps and add spacers within heatmaps. Both tasks are not trivial with matplotlib base plot functions. This would be helpful for adding categorical annotation heatmaps, even if you don't want to use co.cross_plot as it is right now.; - i have an alternative function to co.heatmap in my snippets library which is capable of creating heatmaps using rectangle or circle patches with size and color aesthetics, but i havent added it to codaplot yet. You can always create circle patch heatmaps with standard scatterplots, but this has drawbacks when you want to be able to add spacers within the plot or when you want full control of the circle patch sizes (so that they fit perfectly within the row at maximum size). From what I understand such a patch based function would be helpful, right?. I would be happy to contribute some base functionality for this issue by adding improvements to codaplot, ie provide the circle patch heatmap function and a better complex heatmap function than the currently available co.cross_plot. I do plan on maintaining codaplot for the foreseeable future and have been using it for my own projects for quite a while now. At the moment it's a relatively small library (when you subtract the experimental modules) and could be quickly refactored into a single scanpy module if something happens and I find myself unable to maintain and expand the library over the next years. . Does using codaplot for this issue sound at all interesting to you?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2194#issuecomment-1145123103
https://github.com/scverse/scanpy/issues/2194#issuecomment-1145123103:44,Modifiability,refactor,refactor,44,"From what I can gather, one goal here is to refactor the dotplot function and give it a complex heatmap layout, with a central heatmap using circle patches with a color and size aesthetic (= the dotplot) and one or more annotation heatmaps for rows and columns, which could be categorical or quantitative each. Potentially relevant features in codaplot are. - co.cross_plot is one high level possibility to construct complex heatmaps with the 'central data heatmap + annotation heatmaps' layout. Among other things, it can automatically cluster columns or rows based on the central data heatmap and apply the clustering to the annotation heatmaps. It can also plot dendrograms. This is an experimental function with some quirks, I did want to improve the concept soon-ish.; - co.heatmap is the base heatmap plotting function in codaplot. It provides a simple way to plot categorical heatmaps and add spacers within heatmaps. Both tasks are not trivial with matplotlib base plot functions. This would be helpful for adding categorical annotation heatmaps, even if you don't want to use co.cross_plot as it is right now.; - i have an alternative function to co.heatmap in my snippets library which is capable of creating heatmaps using rectangle or circle patches with size and color aesthetics, but i havent added it to codaplot yet. You can always create circle patch heatmaps with standard scatterplots, but this has drawbacks when you want to be able to add spacers within the plot or when you want full control of the circle patch sizes (so that they fit perfectly within the row at maximum size). From what I understand such a patch based function would be helpful, right?. I would be happy to contribute some base functionality for this issue by adding improvements to codaplot, ie provide the circle patch heatmap function and a better complex heatmap function than the currently available co.cross_plot. I do plan on maintaining codaplot for the foreseeable future and have been using it for my",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2194#issuecomment-1145123103
https://github.com/scverse/scanpy/issues/2194#issuecomment-1145123103:2150,Modifiability,refactor,refactored,2150,"co.cross_plot is one high level possibility to construct complex heatmaps with the 'central data heatmap + annotation heatmaps' layout. Among other things, it can automatically cluster columns or rows based on the central data heatmap and apply the clustering to the annotation heatmaps. It can also plot dendrograms. This is an experimental function with some quirks, I did want to improve the concept soon-ish.; - co.heatmap is the base heatmap plotting function in codaplot. It provides a simple way to plot categorical heatmaps and add spacers within heatmaps. Both tasks are not trivial with matplotlib base plot functions. This would be helpful for adding categorical annotation heatmaps, even if you don't want to use co.cross_plot as it is right now.; - i have an alternative function to co.heatmap in my snippets library which is capable of creating heatmaps using rectangle or circle patches with size and color aesthetics, but i havent added it to codaplot yet. You can always create circle patch heatmaps with standard scatterplots, but this has drawbacks when you want to be able to add spacers within the plot or when you want full control of the circle patch sizes (so that they fit perfectly within the row at maximum size). From what I understand such a patch based function would be helpful, right?. I would be happy to contribute some base functionality for this issue by adding improvements to codaplot, ie provide the circle patch heatmap function and a better complex heatmap function than the currently available co.cross_plot. I do plan on maintaining codaplot for the foreseeable future and have been using it for my own projects for quite a while now. At the moment it's a relatively small library (when you subtract the experimental modules) and could be quickly refactored into a single scanpy module if something happens and I find myself unable to maintain and expand the library over the next years. . Does using codaplot for this issue sound at all interesting to you?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2194#issuecomment-1145123103
https://github.com/scverse/scanpy/issues/2194#issuecomment-1145123103:852,Usability,simpl,simple,852,"From what I can gather, one goal here is to refactor the dotplot function and give it a complex heatmap layout, with a central heatmap using circle patches with a color and size aesthetic (= the dotplot) and one or more annotation heatmaps for rows and columns, which could be categorical or quantitative each. Potentially relevant features in codaplot are. - co.cross_plot is one high level possibility to construct complex heatmaps with the 'central data heatmap + annotation heatmaps' layout. Among other things, it can automatically cluster columns or rows based on the central data heatmap and apply the clustering to the annotation heatmaps. It can also plot dendrograms. This is an experimental function with some quirks, I did want to improve the concept soon-ish.; - co.heatmap is the base heatmap plotting function in codaplot. It provides a simple way to plot categorical heatmaps and add spacers within heatmaps. Both tasks are not trivial with matplotlib base plot functions. This would be helpful for adding categorical annotation heatmaps, even if you don't want to use co.cross_plot as it is right now.; - i have an alternative function to co.heatmap in my snippets library which is capable of creating heatmaps using rectangle or circle patches with size and color aesthetics, but i havent added it to codaplot yet. You can always create circle patch heatmaps with standard scatterplots, but this has drawbacks when you want to be able to add spacers within the plot or when you want full control of the circle patch sizes (so that they fit perfectly within the row at maximum size). From what I understand such a patch based function would be helpful, right?. I would be happy to contribute some base functionality for this issue by adding improvements to codaplot, ie provide the circle patch heatmap function and a better complex heatmap function than the currently available co.cross_plot. I do plan on maintaining codaplot for the foreseeable future and have been using it for my",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2194#issuecomment-1145123103
https://github.com/scverse/scanpy/issues/2194#issuecomment-1145328823:131,Integrability,depend,dependency,131,"For me sounds interesting, especially if you add circle pathes. But I guess @ivirshup should say if this should be added as scanpy dependency potentially.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2194#issuecomment-1145328823
https://github.com/scverse/scanpy/issues/2195#issuecomment-1128687613:50,Testability,log,logreg,50,"`sc.tl.rank_genes_groups(adata, 'leiden', method='logreg',max_iter=1000)`; worked.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2195#issuecomment-1128687613
https://github.com/scverse/scanpy/pull/2201#issuecomment-1086301791:326,Availability,error,error-reference,326,# [Codecov](https://codecov.io/gh/scverse/scanpy/pull/2201?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@2c55a14`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## 1.9.x #2201 +/- ##; ========================================; Coverage ? 71.95% ; ========================================; Files ? 98 ; Lines ? 11538 ; Branches ? 0 ; ========================================; Hits ? 8302 ; Misses ? 3236 ; Partials ? 0 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2201#issuecomment-1086301791
https://github.com/scverse/scanpy/pull/2201#issuecomment-1086301791:274,Usability,learn,learn,274,# [Codecov](https://codecov.io/gh/scverse/scanpy/pull/2201?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@2c55a14`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## 1.9.x #2201 +/- ##; ========================================; Coverage ? 71.95% ; ========================================; Files ? 98 ; Lines ? 11538 ; Branches ? 0 ; ========================================; Hits ? 8302 ; Misses ? 3236 ; Partials ? 0 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2201#issuecomment-1086301791
https://github.com/scverse/scanpy/pull/2202#issuecomment-1086316533:326,Availability,error,error-reference,326,# [Codecov](https://codecov.io/gh/scverse/scanpy/pull/2202?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@2c55a14`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## 1.9.x #2202 +/- ##; ========================================; Coverage ? 71.95% ; ========================================; Files ? 98 ; Lines ? 11538 ; Branches ? 0 ; ========================================; Hits ? 8302 ; Misses ? 3236 ; Partials ? 0 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2202#issuecomment-1086316533
https://github.com/scverse/scanpy/pull/2202#issuecomment-1086316533:274,Usability,learn,learn,274,# [Codecov](https://codecov.io/gh/scverse/scanpy/pull/2202?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@2c55a14`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## 1.9.x #2202 +/- ##; ========================================; Coverage ? 71.95% ; ========================================; Files ? 98 ; Lines ? 11538 ; Branches ? 0 ; ========================================; Hits ? 8302 ; Misses ? 3236 ; Partials ? 0 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2202#issuecomment-1086316533
https://github.com/scverse/scanpy/issues/2203#issuecomment-1087572087:32,Testability,log,logging,32,Can you share the output of `sc.logging.print_versions()` in the environment that's causing you problems?. I'm unable to reproduce with recent cellranger outputs.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2203#issuecomment-1087572087
https://github.com/scverse/scanpy/issues/2203#issuecomment-1092960373:1647,Deployability,update,updated,1647,"Hey sorry for the delay: . ```; -----; anndata 0.7.5; scanpy 1.9.0; -----; PIL 8.1.2; anyio NA; attr 20.3.0; babel 2.9.0; backcall 0.2.0; brotli NA; cairo 1.20.0; certifi 2020.12.05; cffi 1.14.5; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.03.1; dateutil 2.8.1; decorator 4.4.2; fsspec 0.8.7; google NA; h5py 3.1.0; idna 2.10; igraph 0.8.3; ipykernel 5.5.0; ipython_genutils 0.2.0; jedi 0.18.0; jinja2 2.11.3; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.4.1; jupyterlab_server 2.3.0; kiwisolver 1.3.1; leidenalg 0.8.3; llvmlite 0.34.0; louvain 0.7.0; markupsafe 1.1.1; matplotlib 3.3.4; mpl_toolkits NA; natsort 7.1.1; nbclassic NA; nbformat 5.1.2; numba 0.51.2; numpy 1.20.1; packaging 20.9; pandas 1.2.3; parso 0.8.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.16; psutil 5.8.0; ptyprocess 0.7.0; pvectorc NA; pyarrow 0.16.0; pygments 2.8.0; pyparsing 2.4.7; pyrsistent NA; pytoml NA; pytz 2021.1; requests 2.25.1; ruamel NA; scipy 1.6.1; send2trash NA; session_info 1.0.0; setuptools_scm NA; six 1.15.0; sklearn 0.24.1; sniffio 1.2.0; socks 1.7.1; sphinxcontrib NA; storemagic NA; tblib 1.7.0; texttable 1.6.3; tlz 0.11.0; toolz 0.11.1; tornado 6.1; traitlets 5.0.5; typing_extensions NA; urllib3 1.26.3; wcwidth 0.2.5; yaml 5.3.1; zmq 22.0.3; -----; IPython 7.21.0; jupyter_client 6.1.11; jupyter_core 4.7.1; jupyterlab 3.0.9; notebook 6.2.0; -----; Python 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:22:27) [GCC 9.3.0]; Linux-4.15.0-112-generic-x86_64-with-glibc2.10; -----; Session information updated at 2022-04-08 14:58; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2203#issuecomment-1092960373
https://github.com/scverse/scanpy/issues/2203#issuecomment-1129213572:14,Availability,error,error,14,"I got similar error when I was trying to use .h5 file from cellbender output. I have multiome data. . ```pytb; `>>> adata = scanpy.read_10x_h5(""/sc/arion/projects/hmDNAmap/snHeroin/analysis/ARC_TD005235-354/outs/cellbender/cb_feature_bc_matrix_filtered.h5"", gex_only=False)`; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py"", line 183, in read_10x_h5; adata = _read_v3_10x_h5(filename, start=start); File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py"", line 268, in _read_v3_10x_h5; _collect_datasets(dsets, f[""matrix""]); File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py"", line 256, in _collect_datasets; dsets[k] = v[:]; File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper; File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper; File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/h5py/_hl/dataset.py"", line 738, in __getitem__; selection = sel2.select_read(fspace, args); File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/h5py/_hl/selections2.py"", line 101, in select_read; return ScalarReadSelection(fspace, args); File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/h5py/_hl/selections2.py"", line 86, in __init__; raise ValueError(""Illegal slicing argument for scalar dataspace""). > **ValueError: Illegal slicing argument for scalar dataspace**; ```. `>>> scanpy.logging.print_versions()`. anndata 0.8.0; scanpy 1.9.1. PIL 8.4.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.2; cffi 1.14.6; cloudpickle 2.0.0; colorama 0.4.4; concurrent NA; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.10.0; dateutil 2.8.2; defusedxml 0.7.1; encodings NA; fsspec 2021.08.1; genericpath NA; h5py 3.3.0; igraph 0.9.6; jinja2 2.11.3; joblib 1.1.0; kiwisolver 1.3.1; leidena",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2203#issuecomment-1129213572
https://github.com/scverse/scanpy/issues/2203#issuecomment-1129213572:2694,Deployability,update,updated,2694,"oftware/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py"", line 256, in _collect_datasets; dsets[k] = v[:]; File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper; File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper; File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/h5py/_hl/dataset.py"", line 738, in __getitem__; selection = sel2.select_read(fspace, args); File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/h5py/_hl/selections2.py"", line 101, in select_read; return ScalarReadSelection(fspace, args); File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/h5py/_hl/selections2.py"", line 86, in __init__; raise ValueError(""Illegal slicing argument for scalar dataspace""). > **ValueError: Illegal slicing argument for scalar dataspace**; ```. `>>> scanpy.logging.print_versions()`. anndata 0.8.0; scanpy 1.9.1. PIL 8.4.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.2; cffi 1.14.6; cloudpickle 2.0.0; colorama 0.4.4; concurrent NA; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.10.0; dateutil 2.8.2; defusedxml 0.7.1; encodings NA; fsspec 2021.08.1; genericpath NA; h5py 3.3.0; igraph 0.9.6; jinja2 2.11.3; joblib 1.1.0; kiwisolver 1.3.1; leidenalg 0.8.7; llvmlite 0.37.0; markupsafe 1.1.1; matplotlib 3.4.3; mkl 2.4.0; mpl_toolkits NA; natsort 7.1.1; nbinom_ufunc NA; ntpath NA; numba 0.54.1; numexpr 2.7.3; numpy 1.20.3; opcode NA; packaging 21.0; pandas 1.3.4; pkg_resources NA; posixpath NA; psutil 5.8.0; pyexpat NA; pyparsing 3.0.4; pytz 2021.3; scipy 1.7.1; scrublet NA; session_info 1.0.0; six 1.16.0; sklearn 0.24.2; sphinxcontrib NA; sre_compile NA; sre_constants NA; sre_parse NA; tblib 1.7.0; texttable 1.6.4; tlz 0.11.0; toolz 0.11.1; typing_extensions NA; wcwidth 0.2.5; yaml 6.0; zope NA. Python 3.9.7 (default, Sep 16 2021, 13:09:58) [GCC 7.5.0]; Linux-3.10.0-957.10.1.el7.x86_64-x86_64-with-glibc2.17. Session information updated at 2022-05-17 14:56",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2203#issuecomment-1129213572
https://github.com/scverse/scanpy/issues/2203#issuecomment-1129213572:900,Integrability,wrap,wrapper,900,"I got similar error when I was trying to use .h5 file from cellbender output. I have multiome data. . ```pytb; `>>> adata = scanpy.read_10x_h5(""/sc/arion/projects/hmDNAmap/snHeroin/analysis/ARC_TD005235-354/outs/cellbender/cb_feature_bc_matrix_filtered.h5"", gex_only=False)`; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py"", line 183, in read_10x_h5; adata = _read_v3_10x_h5(filename, start=start); File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py"", line 268, in _read_v3_10x_h5; _collect_datasets(dsets, f[""matrix""]); File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py"", line 256, in _collect_datasets; dsets[k] = v[:]; File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper; File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper; File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/h5py/_hl/dataset.py"", line 738, in __getitem__; selection = sel2.select_read(fspace, args); File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/h5py/_hl/selections2.py"", line 101, in select_read; return ScalarReadSelection(fspace, args); File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/h5py/_hl/selections2.py"", line 86, in __init__; raise ValueError(""Illegal slicing argument for scalar dataspace""). > **ValueError: Illegal slicing argument for scalar dataspace**; ```. `>>> scanpy.logging.print_versions()`. anndata 0.8.0; scanpy 1.9.1. PIL 8.4.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.2; cffi 1.14.6; cloudpickle 2.0.0; colorama 0.4.4; concurrent NA; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.10.0; dateutil 2.8.2; defusedxml 0.7.1; encodings NA; fsspec 2021.08.1; genericpath NA; h5py 3.3.0; igraph 0.9.6; jinja2 2.11.3; joblib 1.1.0; kiwisolver 1.3.1; leidena",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2203#issuecomment-1129213572
https://github.com/scverse/scanpy/issues/2203#issuecomment-1129213572:971,Integrability,wrap,wrapper,971,"similar error when I was trying to use .h5 file from cellbender output. I have multiome data. . ```pytb; `>>> adata = scanpy.read_10x_h5(""/sc/arion/projects/hmDNAmap/snHeroin/analysis/ARC_TD005235-354/outs/cellbender/cb_feature_bc_matrix_filtered.h5"", gex_only=False)`; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py"", line 183, in read_10x_h5; adata = _read_v3_10x_h5(filename, start=start); File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py"", line 268, in _read_v3_10x_h5; _collect_datasets(dsets, f[""matrix""]); File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py"", line 256, in _collect_datasets; dsets[k] = v[:]; File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper; File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper; File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/h5py/_hl/dataset.py"", line 738, in __getitem__; selection = sel2.select_read(fspace, args); File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/h5py/_hl/selections2.py"", line 101, in select_read; return ScalarReadSelection(fspace, args); File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/h5py/_hl/selections2.py"", line 86, in __init__; raise ValueError(""Illegal slicing argument for scalar dataspace""). > **ValueError: Illegal slicing argument for scalar dataspace**; ```. `>>> scanpy.logging.print_versions()`. anndata 0.8.0; scanpy 1.9.1. PIL 8.4.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.2; cffi 1.14.6; cloudpickle 2.0.0; colorama 0.4.4; concurrent NA; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.10.0; dateutil 2.8.2; defusedxml 0.7.1; encodings NA; fsspec 2021.08.1; genericpath NA; h5py 3.3.0; igraph 0.9.6; jinja2 2.11.3; joblib 1.1.0; kiwisolver 1.3.1; leidenalg 0.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2203#issuecomment-1129213572
https://github.com/scverse/scanpy/issues/2203#issuecomment-1129213572:1692,Performance,bottleneck,bottleneck,1692,"trix""]); File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py"", line 256, in _collect_datasets; dsets[k] = v[:]; File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper; File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper; File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/h5py/_hl/dataset.py"", line 738, in __getitem__; selection = sel2.select_read(fspace, args); File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/h5py/_hl/selections2.py"", line 101, in select_read; return ScalarReadSelection(fspace, args); File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/h5py/_hl/selections2.py"", line 86, in __init__; raise ValueError(""Illegal slicing argument for scalar dataspace""). > **ValueError: Illegal slicing argument for scalar dataspace**; ```. `>>> scanpy.logging.print_versions()`. anndata 0.8.0; scanpy 1.9.1. PIL 8.4.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.2; cffi 1.14.6; cloudpickle 2.0.0; colorama 0.4.4; concurrent NA; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.10.0; dateutil 2.8.2; defusedxml 0.7.1; encodings NA; fsspec 2021.08.1; genericpath NA; h5py 3.3.0; igraph 0.9.6; jinja2 2.11.3; joblib 1.1.0; kiwisolver 1.3.1; leidenalg 0.8.7; llvmlite 0.37.0; markupsafe 1.1.1; matplotlib 3.4.3; mkl 2.4.0; mpl_toolkits NA; natsort 7.1.1; nbinom_ufunc NA; ntpath NA; numba 0.54.1; numexpr 2.7.3; numpy 1.20.3; opcode NA; packaging 21.0; pandas 1.3.4; pkg_resources NA; posixpath NA; psutil 5.8.0; pyexpat NA; pyparsing 3.0.4; pytz 2021.3; scipy 1.7.1; scrublet NA; session_info 1.0.0; six 1.16.0; sklearn 0.24.2; sphinxcontrib NA; sre_compile NA; sre_constants NA; sre_parse NA; tblib 1.7.0; texttable 1.6.4; tlz 0.11.0; toolz 0.11.1; typing_extensions NA; wcwidth 0.2.5; yaml 6.0; zope NA. Python 3.9.7 (default, Sep 16 2021, 13:09:58) [GCC 7.5.0]; Linux-3.10.0-957.10.1.el7.x86_64-x86_64-with-glibc2.17. Session ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2203#issuecomment-1129213572
https://github.com/scverse/scanpy/issues/2203#issuecomment-1129213572:1758,Performance,concurren,concurrent,1758,"oftware/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py"", line 256, in _collect_datasets; dsets[k] = v[:]; File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper; File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper; File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/h5py/_hl/dataset.py"", line 738, in __getitem__; selection = sel2.select_read(fspace, args); File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/h5py/_hl/selections2.py"", line 101, in select_read; return ScalarReadSelection(fspace, args); File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/h5py/_hl/selections2.py"", line 86, in __init__; raise ValueError(""Illegal slicing argument for scalar dataspace""). > **ValueError: Illegal slicing argument for scalar dataspace**; ```. `>>> scanpy.logging.print_versions()`. anndata 0.8.0; scanpy 1.9.1. PIL 8.4.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.2; cffi 1.14.6; cloudpickle 2.0.0; colorama 0.4.4; concurrent NA; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.10.0; dateutil 2.8.2; defusedxml 0.7.1; encodings NA; fsspec 2021.08.1; genericpath NA; h5py 3.3.0; igraph 0.9.6; jinja2 2.11.3; joblib 1.1.0; kiwisolver 1.3.1; leidenalg 0.8.7; llvmlite 0.37.0; markupsafe 1.1.1; matplotlib 3.4.3; mkl 2.4.0; mpl_toolkits NA; natsort 7.1.1; nbinom_ufunc NA; ntpath NA; numba 0.54.1; numexpr 2.7.3; numpy 1.20.3; opcode NA; packaging 21.0; pandas 1.3.4; pkg_resources NA; posixpath NA; psutil 5.8.0; pyexpat NA; pyparsing 3.0.4; pytz 2021.3; scipy 1.7.1; scrublet NA; session_info 1.0.0; six 1.16.0; sklearn 0.24.2; sphinxcontrib NA; sre_compile NA; sre_constants NA; sre_parse NA; tblib 1.7.0; texttable 1.6.4; tlz 0.11.0; toolz 0.11.1; typing_extensions NA; wcwidth 0.2.5; yaml 6.0; zope NA. Python 3.9.7 (default, Sep 16 2021, 13:09:58) [GCC 7.5.0]; Linux-3.10.0-957.10.1.el7.x86_64-x86_64-with-glibc2.17. Session information updated at 2022-05-17 14:56",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2203#issuecomment-1129213572
https://github.com/scverse/scanpy/issues/2203#issuecomment-1129213572:1594,Testability,log,logging,1594,"/scanpy/readwrite.py"", line 268, in _read_v3_10x_h5; _collect_datasets(dsets, f[""matrix""]); File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py"", line 256, in _collect_datasets; dsets[k] = v[:]; File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper; File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper; File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/h5py/_hl/dataset.py"", line 738, in __getitem__; selection = sel2.select_read(fspace, args); File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/h5py/_hl/selections2.py"", line 101, in select_read; return ScalarReadSelection(fspace, args); File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/h5py/_hl/selections2.py"", line 86, in __init__; raise ValueError(""Illegal slicing argument for scalar dataspace""). > **ValueError: Illegal slicing argument for scalar dataspace**; ```. `>>> scanpy.logging.print_versions()`. anndata 0.8.0; scanpy 1.9.1. PIL 8.4.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.2; cffi 1.14.6; cloudpickle 2.0.0; colorama 0.4.4; concurrent NA; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.10.0; dateutil 2.8.2; defusedxml 0.7.1; encodings NA; fsspec 2021.08.1; genericpath NA; h5py 3.3.0; igraph 0.9.6; jinja2 2.11.3; joblib 1.1.0; kiwisolver 1.3.1; leidenalg 0.8.7; llvmlite 0.37.0; markupsafe 1.1.1; matplotlib 3.4.3; mkl 2.4.0; mpl_toolkits NA; natsort 7.1.1; nbinom_ufunc NA; ntpath NA; numba 0.54.1; numexpr 2.7.3; numpy 1.20.3; opcode NA; packaging 21.0; pandas 1.3.4; pkg_resources NA; posixpath NA; psutil 5.8.0; pyexpat NA; pyparsing 3.0.4; pytz 2021.3; scipy 1.7.1; scrublet NA; session_info 1.0.0; six 1.16.0; sklearn 0.24.2; sphinxcontrib NA; sre_compile NA; sre_constants NA; sre_parse NA; tblib 1.7.0; texttable 1.6.4; tlz 0.11.0; toolz 0.11.1; typing_extensions NA; wcwidth 0.2.5; yaml 6.0; zope NA. Python 3.9.7 (default, Sep 16 2021, 13:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2203#issuecomment-1129213572
https://github.com/scverse/scanpy/issues/2203#issuecomment-1136479284:21,Availability,error,error,21,"I'm getting the same error using the CellBender tutorial output. Attaching the file to make it easier to reproduce. [tiny_10x_pbmc_filtered.h5.zip](https://github.com/scverse/scanpy/files/8766499/tiny_10x_pbmc_filtered.h5.zip). `sc.logging.print_versions()`. ```; -----; anndata 0.7.8; scanpy 1.9.1; -----; PIL 9.0.1; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.0; decorator 5.1.1; defusedxml 0.7.1; doubletdetection 4.2; entrypoints 0.4; executing 0.8.3; google NA; h5py 3.6.0; hypergeom_ufunc NA; igraph 0.9.9; ipykernel 6.10.0; ipython_genutils 0.2.0; ipywidgets 7.7.0; jedi 0.18.1; joblib 1.1.0; kiwisolver 1.4.2; leidenalg 0.8.9; llvmlite 0.38.0; louvain 0.7.1; matplotlib 3.5.1; matplotlib_inline NA; mkl 2.4.0; mpl_toolkits NA; mudata 0.1.1; muon 0.1.2; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.1; numexpr 2.8.1; numpy 1.21.2; organize_metadata NA; packaging 21.3; pandas 1.4.1; parso 0.8.3; pexpect 4.8.0; phenograph 1.5.7; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.28; psutil 5.9.0; ptyprocess 0.7.0; pure_eval 0.2.2; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.8.0; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pynndescent 0.5.6; pyparsing 3.0.7; pytz 2022.1; scikits NA; scipy 1.8.0; seaborn 0.11.2; session_info 1.0.0; setuptools 62.0.0; setuptools_scm NA; six 1.16.0; sklearn 1.0.2; stack_data 0.2.0; statsmodels 0.13.2; tables 3.7.0; texttable 1.6.4; threadpoolctl 3.1.0; tornado 6.1; tqdm 4.63.1; traitlets 5.1.1; typing_extensions NA; umap 0.5.2; wcwidth 0.2.5; yaml 6.0; zipp NA; zmq 22.3.0; -----; IPython 8.2.0; jupyter_client 7.1.2; jupyter_core 4.9.2; notebook 6.4.10; -----; Python 3.9.11 (main, Mar 28 2022, 10:10:35) [GCC 7.5.0]; Linux-4.15.0-142-generic-x86_64-with-glibc2.27; -----; Session information updated at 2022-05-24 15:05; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2203#issuecomment-1136479284
https://github.com/scverse/scanpy/issues/2203#issuecomment-1136479284:1885,Deployability,update,updated,1885,"I'm getting the same error using the CellBender tutorial output. Attaching the file to make it easier to reproduce. [tiny_10x_pbmc_filtered.h5.zip](https://github.com/scverse/scanpy/files/8766499/tiny_10x_pbmc_filtered.h5.zip). `sc.logging.print_versions()`. ```; -----; anndata 0.7.8; scanpy 1.9.1; -----; PIL 9.0.1; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.0; decorator 5.1.1; defusedxml 0.7.1; doubletdetection 4.2; entrypoints 0.4; executing 0.8.3; google NA; h5py 3.6.0; hypergeom_ufunc NA; igraph 0.9.9; ipykernel 6.10.0; ipython_genutils 0.2.0; ipywidgets 7.7.0; jedi 0.18.1; joblib 1.1.0; kiwisolver 1.4.2; leidenalg 0.8.9; llvmlite 0.38.0; louvain 0.7.1; matplotlib 3.5.1; matplotlib_inline NA; mkl 2.4.0; mpl_toolkits NA; mudata 0.1.1; muon 0.1.2; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.1; numexpr 2.8.1; numpy 1.21.2; organize_metadata NA; packaging 21.3; pandas 1.4.1; parso 0.8.3; pexpect 4.8.0; phenograph 1.5.7; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.28; psutil 5.9.0; ptyprocess 0.7.0; pure_eval 0.2.2; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.8.0; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pynndescent 0.5.6; pyparsing 3.0.7; pytz 2022.1; scikits NA; scipy 1.8.0; seaborn 0.11.2; session_info 1.0.0; setuptools 62.0.0; setuptools_scm NA; six 1.16.0; sklearn 1.0.2; stack_data 0.2.0; statsmodels 0.13.2; tables 3.7.0; texttable 1.6.4; threadpoolctl 3.1.0; tornado 6.1; tqdm 4.63.1; traitlets 5.1.1; typing_extensions NA; umap 0.5.2; wcwidth 0.2.5; yaml 6.0; zipp NA; zmq 22.3.0; -----; IPython 8.2.0; jupyter_client 7.1.2; jupyter_core 4.9.2; notebook 6.4.10; -----; Python 3.9.11 (main, Mar 28 2022, 10:10:35) [GCC 7.5.0]; Linux-4.15.0-142-generic-x86_64-with-glibc2.27; -----; Session information updated at 2022-05-24 15:05; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2203#issuecomment-1136479284
https://github.com/scverse/scanpy/issues/2203#issuecomment-1136479284:232,Testability,log,logging,232,"I'm getting the same error using the CellBender tutorial output. Attaching the file to make it easier to reproduce. [tiny_10x_pbmc_filtered.h5.zip](https://github.com/scverse/scanpy/files/8766499/tiny_10x_pbmc_filtered.h5.zip). `sc.logging.print_versions()`. ```; -----; anndata 0.7.8; scanpy 1.9.1; -----; PIL 9.0.1; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.0; decorator 5.1.1; defusedxml 0.7.1; doubletdetection 4.2; entrypoints 0.4; executing 0.8.3; google NA; h5py 3.6.0; hypergeom_ufunc NA; igraph 0.9.9; ipykernel 6.10.0; ipython_genutils 0.2.0; ipywidgets 7.7.0; jedi 0.18.1; joblib 1.1.0; kiwisolver 1.4.2; leidenalg 0.8.9; llvmlite 0.38.0; louvain 0.7.1; matplotlib 3.5.1; matplotlib_inline NA; mkl 2.4.0; mpl_toolkits NA; mudata 0.1.1; muon 0.1.2; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.1; numexpr 2.8.1; numpy 1.21.2; organize_metadata NA; packaging 21.3; pandas 1.4.1; parso 0.8.3; pexpect 4.8.0; phenograph 1.5.7; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.28; psutil 5.9.0; ptyprocess 0.7.0; pure_eval 0.2.2; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.8.0; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pynndescent 0.5.6; pyparsing 3.0.7; pytz 2022.1; scikits NA; scipy 1.8.0; seaborn 0.11.2; session_info 1.0.0; setuptools 62.0.0; setuptools_scm NA; six 1.16.0; sklearn 1.0.2; stack_data 0.2.0; statsmodels 0.13.2; tables 3.7.0; texttable 1.6.4; threadpoolctl 3.1.0; tornado 6.1; tqdm 4.63.1; traitlets 5.1.1; typing_extensions NA; umap 0.5.2; wcwidth 0.2.5; yaml 6.0; zipp NA; zmq 22.3.0; -----; IPython 8.2.0; jupyter_client 7.1.2; jupyter_core 4.9.2; notebook 6.4.10; -----; Python 3.9.11 (main, Mar 28 2022, 10:10:35) [GCC 7.5.0]; Linux-4.15.0-142-generic-x86_64-with-glibc2.27; -----; Session information updated at 2022-05-24 15:05; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2203#issuecomment-1136479284
https://github.com/scverse/scanpy/pull/2204#issuecomment-1087568170:155,Modifiability,config,config,155,"Checking locally, this PR causes to docs to be fully rebuilt with no other changes. I think the issue is that `typehints_formatter` is being changed after config init, not `typehints_default`. ```; updating environment: [config changed ('typehints_formatter')] 317 added, 0 changed, 0 removed; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2204#issuecomment-1087568170
https://github.com/scverse/scanpy/pull/2204#issuecomment-1087568170:221,Modifiability,config,config,221,"Checking locally, this PR causes to docs to be fully rebuilt with no other changes. I think the issue is that `typehints_formatter` is being changed after config init, not `typehints_default`. ```; updating environment: [config changed ('typehints_formatter')] 317 added, 0 changed, 0 removed; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2204#issuecomment-1087568170
https://github.com/scverse/scanpy/pull/2204#issuecomment-1088546625:430,Performance,cache,cache,430,"Hm, you’re right! looks like a Sphinx bug, as even setting it manually doesn’t change things. Maybe pickling the function leads to it having a different object id… . The only ways to fix this:. 1. set the value to a string like `'scanpydoc.elegant_typehints:typehints_formatter'` and implement importing that object in sphinx-autodoc-typehint; 2. make it so sphinx compares function-valued settings in a way that doesn’t bust the cache.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2204#issuecomment-1088546625
https://github.com/scverse/scanpy/pull/2206#issuecomment-1088547896:77,Modifiability,config,config,77,"Check out the PR. I’m removing the GitHub actions workflow, not pre-commit’s config file. I’m talking about having two checks that do the same thing, so let’s keep the faster one:. <img width=""830"" alt=""image"" src=""https://user-images.githubusercontent.com/291575/161737449-5d10a522-9c6d-41fc-bd55-5a88518f0aee.png"">",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2206#issuecomment-1088547896
https://github.com/scverse/scanpy/issues/2208#issuecomment-1089099688:52,Deployability,install,installed,52,"> . No spesific reason, I just use the one come pre-installed. Thank you anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2208#issuecomment-1089099688
https://github.com/scverse/scanpy/issues/2208#issuecomment-1089493597:161,Deployability,install,installing,161,"Bumping matplotlib needs updating of google Colab's default matplotlib. As Colab imports matplotlib on start-up this means you have to restart the runtime after installing scanpy. For production I think it's fine, tutorials would require to restart after installing scanpy.; You can see this behavior in scverse tutorials using Colab, e.g. https://docs.scvi-tools.org/en/stable/tutorials/notebooks/api_overview.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2208#issuecomment-1089493597
https://github.com/scverse/scanpy/issues/2208#issuecomment-1089493597:255,Deployability,install,installing,255,"Bumping matplotlib needs updating of google Colab's default matplotlib. As Colab imports matplotlib on start-up this means you have to restart the runtime after installing scanpy. For production I think it's fine, tutorials would require to restart after installing scanpy.; You can see this behavior in scverse tutorials using Colab, e.g. https://docs.scvi-tools.org/en/stable/tutorials/notebooks/api_overview.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2208#issuecomment-1089493597
https://github.com/scverse/scanpy/issues/2208#issuecomment-1089886547:163,Deployability,install,installing,163,"> Bumping matplotlib needs updating of google Colab's default matplotlib. As Colab imports matplotlib on start-up this means you have to restart the runtime after installing scanpy. For production I think it's fine, tutorials would require to restart after installing scanpy. You can see this behavior in scverse tutorials using Colab, e.g. https://docs.scvi-tools.org/en/stable/tutorials/notebooks/api_overview.html. Noted!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2208#issuecomment-1089886547
https://github.com/scverse/scanpy/issues/2208#issuecomment-1089886547:257,Deployability,install,installing,257,"> Bumping matplotlib needs updating of google Colab's default matplotlib. As Colab imports matplotlib on start-up this means you have to restart the runtime after installing scanpy. For production I think it's fine, tutorials would require to restart after installing scanpy. You can see this behavior in scverse tutorials using Colab, e.g. https://docs.scvi-tools.org/en/stable/tutorials/notebooks/api_overview.html. Noted!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2208#issuecomment-1089886547
https://github.com/scverse/scanpy/issues/2208#issuecomment-1477955919:23,Availability,error,error,23,"I am getting this same error, namely when I run `sc.pl.umap(adata, color='pid')` I see `UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored` and then `adata.uns['pid_colors']` all gets set to gray, and my whole UMAP plot looks gray instead of being color by 'pid.'. I am using scanpy 1.9.1 and matplotlib 3.6.3. Can someone advise me what I need to upgrade to avoid this error, or how I can work around it with my current package versions? I see that #2212 upped the required matplotlib to 3.4, but since I'm at 3.6.3 I thought I should be okay. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2208#issuecomment-1477955919
https://github.com/scverse/scanpy/issues/2208#issuecomment-1477955919:409,Availability,error,error,409,"I am getting this same error, namely when I run `sc.pl.umap(adata, color='pid')` I see `UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored` and then `adata.uns['pid_colors']` all gets set to gray, and my whole UMAP plot looks gray instead of being color by 'pid.'. I am using scanpy 1.9.1 and matplotlib 3.6.3. Can someone advise me what I need to upgrade to avoid this error, or how I can work around it with my current package versions? I see that #2212 upped the required matplotlib to 3.4, but since I'm at 3.6.3 I thought I should be okay. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2208#issuecomment-1477955919
https://github.com/scverse/scanpy/issues/2208#issuecomment-1477955919:387,Deployability,upgrade,upgrade,387,"I am getting this same error, namely when I run `sc.pl.umap(adata, color='pid')` I see `UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored` and then `adata.uns['pid_colors']` all gets set to gray, and my whole UMAP plot looks gray instead of being color by 'pid.'. I am using scanpy 1.9.1 and matplotlib 3.6.3. Can someone advise me what I need to upgrade to avoid this error, or how I can work around it with my current package versions? I see that #2212 upped the required matplotlib to 3.4, but since I'm at 3.6.3 I thought I should be okay. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2208#issuecomment-1477955919
https://github.com/scverse/scanpy/issues/2208#issuecomment-1477955919:398,Safety,avoid,avoid,398,"I am getting this same error, namely when I run `sc.pl.umap(adata, color='pid')` I see `UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored` and then `adata.uns['pid_colors']` all gets set to gray, and my whole UMAP plot looks gray instead of being color by 'pid.'. I am using scanpy 1.9.1 and matplotlib 3.6.3. Can someone advise me what I need to upgrade to avoid this error, or how I can work around it with my current package versions? I see that #2212 upped the required matplotlib to 3.4, but since I'm at 3.6.3 I thought I should be okay. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2208#issuecomment-1477955919
https://github.com/scverse/scanpy/issues/2210#issuecomment-1088508941:37,Availability,error,error,37,Update: I was able to get rid of the error by pip installing `dask` manually in my conda environment.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2210#issuecomment-1088508941
https://github.com/scverse/scanpy/issues/2210#issuecomment-1088508941:0,Deployability,Update,Update,0,Update: I was able to get rid of the error by pip installing `dask` manually in my conda environment.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2210#issuecomment-1088508941
https://github.com/scverse/scanpy/issues/2210#issuecomment-1088508941:50,Deployability,install,installing,50,Update: I was able to get rid of the error by pip installing `dask` manually in my conda environment.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2210#issuecomment-1088508941
https://github.com/scverse/scanpy/issues/2211#issuecomment-1088611630:251,Availability,Error,Error,251,"Would be good to know if there's any nice tooling around this, as this could make fixtures and parametrized tests a bit difficult. For example, not installing `dask` makes test collection fail in the `test_normalization.py` file. <details>; <summary> Error </summary>. ```pytb; _______________________ ERROR collecting scanpy/tests/test_normalization.py ________________________; ImportError while importing test module '/Users/isaac/github/scanpy/scanpy/tests/test_normalization.py'.; Hint: make sure your test modules/packages have valid Python names.; Traceback:; ../../miniconda3/envs/scanpy-minimal/lib/python3.9/importlib/__init__.py:127: in import_module; return _bootstrap._gcd_import(name[level:], package, level); scanpy/tests/test_normalization.py:5: in <module>; import dask.array as da; E ModuleNotFoundError: No module named 'dask'; ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088611630
https://github.com/scverse/scanpy/issues/2211#issuecomment-1088611630:302,Availability,ERROR,ERROR,302,"Would be good to know if there's any nice tooling around this, as this could make fixtures and parametrized tests a bit difficult. For example, not installing `dask` makes test collection fail in the `test_normalization.py` file. <details>; <summary> Error </summary>. ```pytb; _______________________ ERROR collecting scanpy/tests/test_normalization.py ________________________; ImportError while importing test module '/Users/isaac/github/scanpy/scanpy/tests/test_normalization.py'.; Hint: make sure your test modules/packages have valid Python names.; Traceback:; ../../miniconda3/envs/scanpy-minimal/lib/python3.9/importlib/__init__.py:127: in import_module; return _bootstrap._gcd_import(name[level:], package, level); scanpy/tests/test_normalization.py:5: in <module>; import dask.array as da; E ModuleNotFoundError: No module named 'dask'; ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088611630
https://github.com/scverse/scanpy/issues/2211#issuecomment-1088611630:148,Deployability,install,installing,148,"Would be good to know if there's any nice tooling around this, as this could make fixtures and parametrized tests a bit difficult. For example, not installing `dask` makes test collection fail in the `test_normalization.py` file. <details>; <summary> Error </summary>. ```pytb; _______________________ ERROR collecting scanpy/tests/test_normalization.py ________________________; ImportError while importing test module '/Users/isaac/github/scanpy/scanpy/tests/test_normalization.py'.; Hint: make sure your test modules/packages have valid Python names.; Traceback:; ../../miniconda3/envs/scanpy-minimal/lib/python3.9/importlib/__init__.py:127: in import_module; return _bootstrap._gcd_import(name[level:], package, level); scanpy/tests/test_normalization.py:5: in <module>; import dask.array as da; E ModuleNotFoundError: No module named 'dask'; ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088611630
https://github.com/scverse/scanpy/issues/2211#issuecomment-1088611630:108,Testability,test,tests,108,"Would be good to know if there's any nice tooling around this, as this could make fixtures and parametrized tests a bit difficult. For example, not installing `dask` makes test collection fail in the `test_normalization.py` file. <details>; <summary> Error </summary>. ```pytb; _______________________ ERROR collecting scanpy/tests/test_normalization.py ________________________; ImportError while importing test module '/Users/isaac/github/scanpy/scanpy/tests/test_normalization.py'.; Hint: make sure your test modules/packages have valid Python names.; Traceback:; ../../miniconda3/envs/scanpy-minimal/lib/python3.9/importlib/__init__.py:127: in import_module; return _bootstrap._gcd_import(name[level:], package, level); scanpy/tests/test_normalization.py:5: in <module>; import dask.array as da; E ModuleNotFoundError: No module named 'dask'; ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088611630
https://github.com/scverse/scanpy/issues/2211#issuecomment-1088611630:172,Testability,test,test,172,"Would be good to know if there's any nice tooling around this, as this could make fixtures and parametrized tests a bit difficult. For example, not installing `dask` makes test collection fail in the `test_normalization.py` file. <details>; <summary> Error </summary>. ```pytb; _______________________ ERROR collecting scanpy/tests/test_normalization.py ________________________; ImportError while importing test module '/Users/isaac/github/scanpy/scanpy/tests/test_normalization.py'.; Hint: make sure your test modules/packages have valid Python names.; Traceback:; ../../miniconda3/envs/scanpy-minimal/lib/python3.9/importlib/__init__.py:127: in import_module; return _bootstrap._gcd_import(name[level:], package, level); scanpy/tests/test_normalization.py:5: in <module>; import dask.array as da; E ModuleNotFoundError: No module named 'dask'; ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088611630
https://github.com/scverse/scanpy/issues/2211#issuecomment-1088611630:326,Testability,test,tests,326,"Would be good to know if there's any nice tooling around this, as this could make fixtures and parametrized tests a bit difficult. For example, not installing `dask` makes test collection fail in the `test_normalization.py` file. <details>; <summary> Error </summary>. ```pytb; _______________________ ERROR collecting scanpy/tests/test_normalization.py ________________________; ImportError while importing test module '/Users/isaac/github/scanpy/scanpy/tests/test_normalization.py'.; Hint: make sure your test modules/packages have valid Python names.; Traceback:; ../../miniconda3/envs/scanpy-minimal/lib/python3.9/importlib/__init__.py:127: in import_module; return _bootstrap._gcd_import(name[level:], package, level); scanpy/tests/test_normalization.py:5: in <module>; import dask.array as da; E ModuleNotFoundError: No module named 'dask'; ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088611630
https://github.com/scverse/scanpy/issues/2211#issuecomment-1088611630:408,Testability,test,test,408,"Would be good to know if there's any nice tooling around this, as this could make fixtures and parametrized tests a bit difficult. For example, not installing `dask` makes test collection fail in the `test_normalization.py` file. <details>; <summary> Error </summary>. ```pytb; _______________________ ERROR collecting scanpy/tests/test_normalization.py ________________________; ImportError while importing test module '/Users/isaac/github/scanpy/scanpy/tests/test_normalization.py'.; Hint: make sure your test modules/packages have valid Python names.; Traceback:; ../../miniconda3/envs/scanpy-minimal/lib/python3.9/importlib/__init__.py:127: in import_module; return _bootstrap._gcd_import(name[level:], package, level); scanpy/tests/test_normalization.py:5: in <module>; import dask.array as da; E ModuleNotFoundError: No module named 'dask'; ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088611630
https://github.com/scverse/scanpy/issues/2211#issuecomment-1088611630:455,Testability,test,tests,455,"Would be good to know if there's any nice tooling around this, as this could make fixtures and parametrized tests a bit difficult. For example, not installing `dask` makes test collection fail in the `test_normalization.py` file. <details>; <summary> Error </summary>. ```pytb; _______________________ ERROR collecting scanpy/tests/test_normalization.py ________________________; ImportError while importing test module '/Users/isaac/github/scanpy/scanpy/tests/test_normalization.py'.; Hint: make sure your test modules/packages have valid Python names.; Traceback:; ../../miniconda3/envs/scanpy-minimal/lib/python3.9/importlib/__init__.py:127: in import_module; return _bootstrap._gcd_import(name[level:], package, level); scanpy/tests/test_normalization.py:5: in <module>; import dask.array as da; E ModuleNotFoundError: No module named 'dask'; ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088611630
https://github.com/scverse/scanpy/issues/2211#issuecomment-1088611630:507,Testability,test,test,507,"Would be good to know if there's any nice tooling around this, as this could make fixtures and parametrized tests a bit difficult. For example, not installing `dask` makes test collection fail in the `test_normalization.py` file. <details>; <summary> Error </summary>. ```pytb; _______________________ ERROR collecting scanpy/tests/test_normalization.py ________________________; ImportError while importing test module '/Users/isaac/github/scanpy/scanpy/tests/test_normalization.py'.; Hint: make sure your test modules/packages have valid Python names.; Traceback:; ../../miniconda3/envs/scanpy-minimal/lib/python3.9/importlib/__init__.py:127: in import_module; return _bootstrap._gcd_import(name[level:], package, level); scanpy/tests/test_normalization.py:5: in <module>; import dask.array as da; E ModuleNotFoundError: No module named 'dask'; ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088611630
https://github.com/scverse/scanpy/issues/2211#issuecomment-1088611630:731,Testability,test,tests,731,"Would be good to know if there's any nice tooling around this, as this could make fixtures and parametrized tests a bit difficult. For example, not installing `dask` makes test collection fail in the `test_normalization.py` file. <details>; <summary> Error </summary>. ```pytb; _______________________ ERROR collecting scanpy/tests/test_normalization.py ________________________; ImportError while importing test module '/Users/isaac/github/scanpy/scanpy/tests/test_normalization.py'.; Hint: make sure your test modules/packages have valid Python names.; Traceback:; ../../miniconda3/envs/scanpy-minimal/lib/python3.9/importlib/__init__.py:127: in import_module; return _bootstrap._gcd_import(name[level:], package, level); scanpy/tests/test_normalization.py:5: in <module>; import dask.array as da; E ModuleNotFoundError: No module named 'dask'; ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088611630
https://github.com/scverse/scanpy/issues/2211#issuecomment-1088701942:82,Deployability,update,update,82,Do you also mean minimal dependency versions? Because Rust’s cargo e.g. has `carg update -Z minimum-versions` which allows people to figure out if their minimum version bounds are truthful or lies (i.e. to be raised),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088701942
https://github.com/scverse/scanpy/issues/2211#issuecomment-1088701942:25,Integrability,depend,dependency,25,Do you also mean minimal dependency versions? Because Rust’s cargo e.g. has `carg update -Z minimum-versions` which allows people to figure out if their minimum version bounds are truthful or lies (i.e. to be raised),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088701942
https://github.com/scverse/scanpy/issues/2211#issuecomment-1088708723:108,Availability,avail,available,108,But I think it's a little different. It's probably easier to implement since we still have all dependencies available at collection time.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088708723
https://github.com/scverse/scanpy/issues/2211#issuecomment-1088708723:95,Integrability,depend,dependencies,95,But I think it's a little different. It's probably easier to implement since we still have all dependencies available at collection time.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088708723
https://github.com/scverse/scanpy/issues/2211#issuecomment-1088710180:172,Deployability,pipeline,pipelines,172,"Regarding running CI with minimal optional deps, I’d say we could change this line:. https://github.com/scverse/scanpy/blob/86e2a35c1df2b61772e5f898bfcd11abb8d9fb2c/.azure-pipelines.yml#L46. … to be parametric like `pip install .[dev,test$(test_extras))]`, and run things once with `test_extras=''` and once with `test_extras=',leiden,magic,harmony,scrublet,scanorama,skmisc'`. we’d probably have to make a lot of tests optional with `@skipif(not find_spec('thing'), ...)` though, and of course remove some things from the `test` extra",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088710180
https://github.com/scverse/scanpy/issues/2211#issuecomment-1088710180:220,Deployability,install,install,220,"Regarding running CI with minimal optional deps, I’d say we could change this line:. https://github.com/scverse/scanpy/blob/86e2a35c1df2b61772e5f898bfcd11abb8d9fb2c/.azure-pipelines.yml#L46. … to be parametric like `pip install .[dev,test$(test_extras))]`, and run things once with `test_extras=''` and once with `test_extras=',leiden,magic,harmony,scrublet,scanorama,skmisc'`. we’d probably have to make a lot of tests optional with `@skipif(not find_spec('thing'), ...)` though, and of course remove some things from the `test` extra",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088710180
https://github.com/scverse/scanpy/issues/2211#issuecomment-1088710180:234,Testability,test,test,234,"Regarding running CI with minimal optional deps, I’d say we could change this line:. https://github.com/scverse/scanpy/blob/86e2a35c1df2b61772e5f898bfcd11abb8d9fb2c/.azure-pipelines.yml#L46. … to be parametric like `pip install .[dev,test$(test_extras))]`, and run things once with `test_extras=''` and once with `test_extras=',leiden,magic,harmony,scrublet,scanorama,skmisc'`. we’d probably have to make a lot of tests optional with `@skipif(not find_spec('thing'), ...)` though, and of course remove some things from the `test` extra",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088710180
https://github.com/scverse/scanpy/issues/2211#issuecomment-1088710180:414,Testability,test,tests,414,"Regarding running CI with minimal optional deps, I’d say we could change this line:. https://github.com/scverse/scanpy/blob/86e2a35c1df2b61772e5f898bfcd11abb8d9fb2c/.azure-pipelines.yml#L46. … to be parametric like `pip install .[dev,test$(test_extras))]`, and run things once with `test_extras=''` and once with `test_extras=',leiden,magic,harmony,scrublet,scanorama,skmisc'`. we’d probably have to make a lot of tests optional with `@skipif(not find_spec('thing'), ...)` though, and of course remove some things from the `test` extra",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088710180
https://github.com/scverse/scanpy/issues/2211#issuecomment-1088710180:524,Testability,test,test,524,"Regarding running CI with minimal optional deps, I’d say we could change this line:. https://github.com/scverse/scanpy/blob/86e2a35c1df2b61772e5f898bfcd11abb8d9fb2c/.azure-pipelines.yml#L46. … to be parametric like `pip install .[dev,test$(test_extras))]`, and run things once with `test_extras=''` and once with `test_extras=',leiden,magic,harmony,scrublet,scanorama,skmisc'`. we’d probably have to make a lot of tests optional with `@skipif(not find_spec('thing'), ...)` though, and of course remove some things from the `test` extra",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088710180
https://github.com/scverse/scanpy/issues/2211#issuecomment-1088715295:39,Integrability,depend,depending,39,"One important thing: pip supports self-depending. I’ve written dep lists like. ```toml; [project]; name = 'myproj'. [project.optional-dependencies]; # myproj’s exported testing tools depend on those:; testing = ['pytest-postgresql']; # to run our package’s tests, we need:; test = ['pytest', 'myproj[testing]']; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088715295
https://github.com/scverse/scanpy/issues/2211#issuecomment-1088715295:134,Integrability,depend,dependencies,134,"One important thing: pip supports self-depending. I’ve written dep lists like. ```toml; [project]; name = 'myproj'. [project.optional-dependencies]; # myproj’s exported testing tools depend on those:; testing = ['pytest-postgresql']; # to run our package’s tests, we need:; test = ['pytest', 'myproj[testing]']; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088715295
https://github.com/scverse/scanpy/issues/2211#issuecomment-1088715295:183,Integrability,depend,depend,183,"One important thing: pip supports self-depending. I’ve written dep lists like. ```toml; [project]; name = 'myproj'. [project.optional-dependencies]; # myproj’s exported testing tools depend on those:; testing = ['pytest-postgresql']; # to run our package’s tests, we need:; test = ['pytest', 'myproj[testing]']; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088715295
https://github.com/scverse/scanpy/issues/2211#issuecomment-1088715295:169,Testability,test,testing,169,"One important thing: pip supports self-depending. I’ve written dep lists like. ```toml; [project]; name = 'myproj'. [project.optional-dependencies]; # myproj’s exported testing tools depend on those:; testing = ['pytest-postgresql']; # to run our package’s tests, we need:; test = ['pytest', 'myproj[testing]']; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088715295
https://github.com/scverse/scanpy/issues/2211#issuecomment-1088715295:201,Testability,test,testing,201,"One important thing: pip supports self-depending. I’ve written dep lists like. ```toml; [project]; name = 'myproj'. [project.optional-dependencies]; # myproj’s exported testing tools depend on those:; testing = ['pytest-postgresql']; # to run our package’s tests, we need:; test = ['pytest', 'myproj[testing]']; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088715295
https://github.com/scverse/scanpy/issues/2211#issuecomment-1088715295:257,Testability,test,tests,257,"One important thing: pip supports self-depending. I’ve written dep lists like. ```toml; [project]; name = 'myproj'. [project.optional-dependencies]; # myproj’s exported testing tools depend on those:; testing = ['pytest-postgresql']; # to run our package’s tests, we need:; test = ['pytest', 'myproj[testing]']; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088715295
https://github.com/scverse/scanpy/issues/2211#issuecomment-1088715295:274,Testability,test,test,274,"One important thing: pip supports self-depending. I’ve written dep lists like. ```toml; [project]; name = 'myproj'. [project.optional-dependencies]; # myproj’s exported testing tools depend on those:; testing = ['pytest-postgresql']; # to run our package’s tests, we need:; test = ['pytest', 'myproj[testing]']; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088715295
https://github.com/scverse/scanpy/issues/2211#issuecomment-1088715295:300,Testability,test,testing,300,"One important thing: pip supports self-depending. I’ve written dep lists like. ```toml; [project]; name = 'myproj'. [project.optional-dependencies]; # myproj’s exported testing tools depend on those:; testing = ['pytest-postgresql']; # to run our package’s tests, we need:; test = ['pytest', 'myproj[testing]']; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088715295
https://github.com/scverse/scanpy/issues/2211#issuecomment-1088721539:11,Deployability,install,install,11,"> like pip install .[dev,test$(test_extras))], and run things once with test_extras='' and once with test_extras=',leiden,magic,harmony,scrublet,scanorama,skmisc'. Yeah, I was thinking something like this. Except we could just reduce `test` to include the barebones needed to make tests run, and separately have optional dependencies. The hard part here is structuring the tests so they can run without optional dependencies being present. We'd need to establish patterns for optional dependencies in fixtures and parameterized tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088721539
https://github.com/scverse/scanpy/issues/2211#issuecomment-1088721539:227,Energy Efficiency,reduce,reduce,227,"> like pip install .[dev,test$(test_extras))], and run things once with test_extras='' and once with test_extras=',leiden,magic,harmony,scrublet,scanorama,skmisc'. Yeah, I was thinking something like this. Except we could just reduce `test` to include the barebones needed to make tests run, and separately have optional dependencies. The hard part here is structuring the tests so they can run without optional dependencies being present. We'd need to establish patterns for optional dependencies in fixtures and parameterized tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088721539
https://github.com/scverse/scanpy/issues/2211#issuecomment-1088721539:321,Integrability,depend,dependencies,321,"> like pip install .[dev,test$(test_extras))], and run things once with test_extras='' and once with test_extras=',leiden,magic,harmony,scrublet,scanorama,skmisc'. Yeah, I was thinking something like this. Except we could just reduce `test` to include the barebones needed to make tests run, and separately have optional dependencies. The hard part here is structuring the tests so they can run without optional dependencies being present. We'd need to establish patterns for optional dependencies in fixtures and parameterized tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088721539
https://github.com/scverse/scanpy/issues/2211#issuecomment-1088721539:412,Integrability,depend,dependencies,412,"> like pip install .[dev,test$(test_extras))], and run things once with test_extras='' and once with test_extras=',leiden,magic,harmony,scrublet,scanorama,skmisc'. Yeah, I was thinking something like this. Except we could just reduce `test` to include the barebones needed to make tests run, and separately have optional dependencies. The hard part here is structuring the tests so they can run without optional dependencies being present. We'd need to establish patterns for optional dependencies in fixtures and parameterized tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088721539
https://github.com/scverse/scanpy/issues/2211#issuecomment-1088721539:485,Integrability,depend,dependencies,485,"> like pip install .[dev,test$(test_extras))], and run things once with test_extras='' and once with test_extras=',leiden,magic,harmony,scrublet,scanorama,skmisc'. Yeah, I was thinking something like this. Except we could just reduce `test` to include the barebones needed to make tests run, and separately have optional dependencies. The hard part here is structuring the tests so they can run without optional dependencies being present. We'd need to establish patterns for optional dependencies in fixtures and parameterized tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088721539
https://github.com/scverse/scanpy/issues/2211#issuecomment-1088721539:514,Modifiability,parameteriz,parameterized,514,"> like pip install .[dev,test$(test_extras))], and run things once with test_extras='' and once with test_extras=',leiden,magic,harmony,scrublet,scanorama,skmisc'. Yeah, I was thinking something like this. Except we could just reduce `test` to include the barebones needed to make tests run, and separately have optional dependencies. The hard part here is structuring the tests so they can run without optional dependencies being present. We'd need to establish patterns for optional dependencies in fixtures and parameterized tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088721539
https://github.com/scverse/scanpy/issues/2211#issuecomment-1088721539:25,Testability,test,test,25,"> like pip install .[dev,test$(test_extras))], and run things once with test_extras='' and once with test_extras=',leiden,magic,harmony,scrublet,scanorama,skmisc'. Yeah, I was thinking something like this. Except we could just reduce `test` to include the barebones needed to make tests run, and separately have optional dependencies. The hard part here is structuring the tests so they can run without optional dependencies being present. We'd need to establish patterns for optional dependencies in fixtures and parameterized tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088721539
https://github.com/scverse/scanpy/issues/2211#issuecomment-1088721539:235,Testability,test,test,235,"> like pip install .[dev,test$(test_extras))], and run things once with test_extras='' and once with test_extras=',leiden,magic,harmony,scrublet,scanorama,skmisc'. Yeah, I was thinking something like this. Except we could just reduce `test` to include the barebones needed to make tests run, and separately have optional dependencies. The hard part here is structuring the tests so they can run without optional dependencies being present. We'd need to establish patterns for optional dependencies in fixtures and parameterized tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088721539
https://github.com/scverse/scanpy/issues/2211#issuecomment-1088721539:281,Testability,test,tests,281,"> like pip install .[dev,test$(test_extras))], and run things once with test_extras='' and once with test_extras=',leiden,magic,harmony,scrublet,scanorama,skmisc'. Yeah, I was thinking something like this. Except we could just reduce `test` to include the barebones needed to make tests run, and separately have optional dependencies. The hard part here is structuring the tests so they can run without optional dependencies being present. We'd need to establish patterns for optional dependencies in fixtures and parameterized tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088721539
https://github.com/scverse/scanpy/issues/2211#issuecomment-1088721539:373,Testability,test,tests,373,"> like pip install .[dev,test$(test_extras))], and run things once with test_extras='' and once with test_extras=',leiden,magic,harmony,scrublet,scanorama,skmisc'. Yeah, I was thinking something like this. Except we could just reduce `test` to include the barebones needed to make tests run, and separately have optional dependencies. The hard part here is structuring the tests so they can run without optional dependencies being present. We'd need to establish patterns for optional dependencies in fixtures and parameterized tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088721539
https://github.com/scverse/scanpy/issues/2211#issuecomment-1088721539:528,Testability,test,tests,528,"> like pip install .[dev,test$(test_extras))], and run things once with test_extras='' and once with test_extras=',leiden,magic,harmony,scrublet,scanorama,skmisc'. Yeah, I was thinking something like this. Except we could just reduce `test` to include the barebones needed to make tests run, and separately have optional dependencies. The hard part here is structuring the tests so they can run without optional dependencies being present. We'd need to establish patterns for optional dependencies in fixtures and parameterized tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088721539
https://github.com/scverse/scanpy/issues/2211#issuecomment-1088726702:54,Modifiability,rewrite,rewrite,54,"That’s the way anyway. I think first step would be to rewrite our `test` extra in terms of a) what’s needed for testing and b) what really are scanpy features being tested:. ```toml; test = [; 'pytest',; 'scanpy[dask]',; 'scanpy[zarr]',; ]; ```. then we can extra-by-extra make parts of our test suite optional.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088726702
https://github.com/scverse/scanpy/issues/2211#issuecomment-1088726702:67,Testability,test,test,67,"That’s the way anyway. I think first step would be to rewrite our `test` extra in terms of a) what’s needed for testing and b) what really are scanpy features being tested:. ```toml; test = [; 'pytest',; 'scanpy[dask]',; 'scanpy[zarr]',; ]; ```. then we can extra-by-extra make parts of our test suite optional.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088726702
https://github.com/scverse/scanpy/issues/2211#issuecomment-1088726702:112,Testability,test,testing,112,"That’s the way anyway. I think first step would be to rewrite our `test` extra in terms of a) what’s needed for testing and b) what really are scanpy features being tested:. ```toml; test = [; 'pytest',; 'scanpy[dask]',; 'scanpy[zarr]',; ]; ```. then we can extra-by-extra make parts of our test suite optional.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088726702
https://github.com/scverse/scanpy/issues/2211#issuecomment-1088726702:165,Testability,test,tested,165,"That’s the way anyway. I think first step would be to rewrite our `test` extra in terms of a) what’s needed for testing and b) what really are scanpy features being tested:. ```toml; test = [; 'pytest',; 'scanpy[dask]',; 'scanpy[zarr]',; ]; ```. then we can extra-by-extra make parts of our test suite optional.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088726702
https://github.com/scverse/scanpy/issues/2211#issuecomment-1088726702:183,Testability,test,test,183,"That’s the way anyway. I think first step would be to rewrite our `test` extra in terms of a) what’s needed for testing and b) what really are scanpy features being tested:. ```toml; test = [; 'pytest',; 'scanpy[dask]',; 'scanpy[zarr]',; ]; ```. then we can extra-by-extra make parts of our test suite optional.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088726702
https://github.com/scverse/scanpy/issues/2211#issuecomment-1088726702:291,Testability,test,test,291,"That’s the way anyway. I think first step would be to rewrite our `test` extra in terms of a) what’s needed for testing and b) what really are scanpy features being tested:. ```toml; test = [; 'pytest',; 'scanpy[dask]',; 'scanpy[zarr]',; ]; ```. then we can extra-by-extra make parts of our test suite optional.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088726702
https://github.com/scverse/scanpy/pull/2213#issuecomment-1088659791:326,Availability,error,error-reference,326,# [Codecov](https://codecov.io/gh/scverse/scanpy/pull/2213?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@3ac9169`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 9c0054f differs from pull request most recent head 02123f2. Consider uploading reports for the commit 02123f2 to get more accurate results. ```diff; @@ Coverage Diff @@; ## 1.9.x #2213 +/- ##; ========================================; Coverage ? 71.94% ; ========================================; Files ? 98 ; Lines ? 11539 ; Branches ? 0 ; ========================================; Hits ? 8302 ; Misses ? 3237 ; Partials ? 0 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2213#issuecomment-1088659791
https://github.com/scverse/scanpy/pull/2213#issuecomment-1088659791:274,Usability,learn,learn,274,# [Codecov](https://codecov.io/gh/scverse/scanpy/pull/2213?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@3ac9169`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 9c0054f differs from pull request most recent head 02123f2. Consider uploading reports for the commit 02123f2 to get more accurate results. ```diff; @@ Coverage Diff @@; ## 1.9.x #2213 +/- ##; ========================================; Coverage ? 71.94% ; ========================================; Files ? 98 ; Lines ? 11539 ; Branches ? 0 ; ========================================; Hits ? 8302 ; Misses ? 3237 ; Partials ? 0 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2213#issuecomment-1088659791
https://github.com/scverse/scanpy/pull/2220#issuecomment-1090204379:66,Availability,down,down,66,Can we customize the contents of left hand table of contents drop down?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2220#issuecomment-1090204379
https://github.com/scverse/scanpy/pull/2220#issuecomment-1090258080:63,Usability,UX,UX,63,"> > Docsearch; > ; > Gotta keep this (it's so much nicer). The UX is for sure, but if we could replace it with something that has similar UX but uses an index that’s built by the RTD build, I’d much prefer that. It’s silly that searching in PR builds or `stable` will result in getting redirected to the `latest` docs …",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2220#issuecomment-1090258080
https://github.com/scverse/scanpy/pull/2220#issuecomment-1090258080:138,Usability,UX,UX,138,"> > Docsearch; > ; > Gotta keep this (it's so much nicer). The UX is for sure, but if we could replace it with something that has similar UX but uses an index that’s built by the RTD build, I’d much prefer that. It’s silly that searching in PR builds or `stable` will result in getting redirected to the `latest` docs …",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2220#issuecomment-1090258080
https://github.com/scverse/scanpy/pull/2221#issuecomment-1088855272:326,Availability,error,error-reference,326,# [Codecov](https://codecov.io/gh/scverse/scanpy/pull/2221?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@6cc7541`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## 1.9.x #2221 +/- ##; ========================================; Coverage ? 71.94% ; ========================================; Files ? 98 ; Lines ? 11539 ; Branches ? 0 ; ========================================; Hits ? 8302 ; Misses ? 3237 ; Partials ? 0 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2221#issuecomment-1088855272
https://github.com/scverse/scanpy/pull/2221#issuecomment-1088855272:274,Usability,learn,learn,274,# [Codecov](https://codecov.io/gh/scverse/scanpy/pull/2221?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@6cc7541`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## 1.9.x #2221 +/- ##; ========================================; Coverage ? 71.94% ; ========================================; Files ? 98 ; Lines ? 11539 ; Branches ? 0 ; ========================================; Hits ? 8302 ; Misses ? 3237 ; Partials ? 0 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2221#issuecomment-1088855272
https://github.com/scverse/scanpy/issues/2225#issuecomment-1090364103:62,Integrability,depend,dependencies,62,"@flying-sheep, do you know of a large package (ideally in our dependencies) which uses the directory structure you're advocating for? I'd ideally like to have another repo to look at/ crib from for test organization strategies.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1090364103
https://github.com/scverse/scanpy/issues/2225#issuecomment-1090364103:198,Testability,test,test,198,"@flying-sheep, do you know of a large package (ideally in our dependencies) which uses the directory structure you're advocating for? I'd ideally like to have another repo to look at/ crib from for test organization strategies.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1090364103
https://github.com/scverse/scanpy/issues/2225#issuecomment-1090388986:150,Testability,test,testing,150,"Most things?. - pandas has https://github.com/pandas-dev/pandas/tree/main/pandas/_testing; - numpy has https://github.com/numpy/numpy/tree/main/numpy/testing. It also literally has `_private.py` which is awesome since I came up with that on the fly!. They both have `__init__.py` files in their `tests` directory for which I can forgive them since they probably didn’t know about `--import-mode=importlib` (or it didn’t exist) when they created their test suites. They probably ran into some problem about test files having identical names and hacked their way around it. But we can do better since we know better: `--import-mode=importlib` just fixes problems like that, no caveats.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1090388986
https://github.com/scverse/scanpy/issues/2225#issuecomment-1090388986:296,Testability,test,tests,296,"Most things?. - pandas has https://github.com/pandas-dev/pandas/tree/main/pandas/_testing; - numpy has https://github.com/numpy/numpy/tree/main/numpy/testing. It also literally has `_private.py` which is awesome since I came up with that on the fly!. They both have `__init__.py` files in their `tests` directory for which I can forgive them since they probably didn’t know about `--import-mode=importlib` (or it didn’t exist) when they created their test suites. They probably ran into some problem about test files having identical names and hacked their way around it. But we can do better since we know better: `--import-mode=importlib` just fixes problems like that, no caveats.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1090388986
https://github.com/scverse/scanpy/issues/2225#issuecomment-1090388986:451,Testability,test,test,451,"Most things?. - pandas has https://github.com/pandas-dev/pandas/tree/main/pandas/_testing; - numpy has https://github.com/numpy/numpy/tree/main/numpy/testing. It also literally has `_private.py` which is awesome since I came up with that on the fly!. They both have `__init__.py` files in their `tests` directory for which I can forgive them since they probably didn’t know about `--import-mode=importlib` (or it didn’t exist) when they created their test suites. They probably ran into some problem about test files having identical names and hacked their way around it. But we can do better since we know better: `--import-mode=importlib` just fixes problems like that, no caveats.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1090388986
https://github.com/scverse/scanpy/issues/2225#issuecomment-1090388986:506,Testability,test,test,506,"Most things?. - pandas has https://github.com/pandas-dev/pandas/tree/main/pandas/_testing; - numpy has https://github.com/numpy/numpy/tree/main/numpy/testing. It also literally has `_private.py` which is awesome since I came up with that on the fly!. They both have `__init__.py` files in their `tests` directory for which I can forgive them since they probably didn’t know about `--import-mode=importlib` (or it didn’t exist) when they created their test suites. They probably ran into some problem about test files having identical names and hacked their way around it. But we can do better since we know better: `--import-mode=importlib` just fixes problems like that, no caveats.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1090388986
https://github.com/scverse/scanpy/issues/2225#issuecomment-1090414562:26,Testability,test,tests,26,"Oh, I specifically meant `tests` not `{package}/tests`. Though looking through the pandas test it does look like there are fewer internal imports than I recall.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1090414562
https://github.com/scverse/scanpy/issues/2225#issuecomment-1090414562:48,Testability,test,tests,48,"Oh, I specifically meant `tests` not `{package}/tests`. Though looking through the pandas test it does look like there are fewer internal imports than I recall.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1090414562
https://github.com/scverse/scanpy/issues/2225#issuecomment-1090414562:90,Testability,test,test,90,"Oh, I specifically meant `tests` not `{package}/tests`. Though looking through the pandas test it does look like there are fewer internal imports than I recall.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1090414562
https://github.com/scverse/scanpy/issues/2225#issuecomment-1096435446:36,Testability,test,testing,36,"Could you point some projects who's testing layout you'd like to emulate? I'd ideally like to have something to look at for reference. I would also like something I could try out, since I recall ""acceptable test discovery arguments"" can be a bit fiddly with pytest. For modules of test utils, I think I'd go `scanpy.testing` and `scanpy.testing._marks`/ `scanpy.testing._pytest` or something like that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096435446
https://github.com/scverse/scanpy/issues/2225#issuecomment-1096435446:207,Testability,test,test,207,"Could you point some projects who's testing layout you'd like to emulate? I'd ideally like to have something to look at for reference. I would also like something I could try out, since I recall ""acceptable test discovery arguments"" can be a bit fiddly with pytest. For modules of test utils, I think I'd go `scanpy.testing` and `scanpy.testing._marks`/ `scanpy.testing._pytest` or something like that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096435446
https://github.com/scverse/scanpy/issues/2225#issuecomment-1096435446:281,Testability,test,test,281,"Could you point some projects who's testing layout you'd like to emulate? I'd ideally like to have something to look at for reference. I would also like something I could try out, since I recall ""acceptable test discovery arguments"" can be a bit fiddly with pytest. For modules of test utils, I think I'd go `scanpy.testing` and `scanpy.testing._marks`/ `scanpy.testing._pytest` or something like that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096435446
https://github.com/scverse/scanpy/issues/2225#issuecomment-1096435446:316,Testability,test,testing,316,"Could you point some projects who's testing layout you'd like to emulate? I'd ideally like to have something to look at for reference. I would also like something I could try out, since I recall ""acceptable test discovery arguments"" can be a bit fiddly with pytest. For modules of test utils, I think I'd go `scanpy.testing` and `scanpy.testing._marks`/ `scanpy.testing._pytest` or something like that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096435446
https://github.com/scverse/scanpy/issues/2225#issuecomment-1096435446:337,Testability,test,testing,337,"Could you point some projects who's testing layout you'd like to emulate? I'd ideally like to have something to look at for reference. I would also like something I could try out, since I recall ""acceptable test discovery arguments"" can be a bit fiddly with pytest. For modules of test utils, I think I'd go `scanpy.testing` and `scanpy.testing._marks`/ `scanpy.testing._pytest` or something like that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096435446
https://github.com/scverse/scanpy/issues/2225#issuecomment-1096435446:362,Testability,test,testing,362,"Could you point some projects who's testing layout you'd like to emulate? I'd ideally like to have something to look at for reference. I would also like something I could try out, since I recall ""acceptable test discovery arguments"" can be a bit fiddly with pytest. For modules of test utils, I think I'd go `scanpy.testing` and `scanpy.testing._marks`/ `scanpy.testing._pytest` or something like that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096435446
https://github.com/scverse/scanpy/issues/2225#issuecomment-1096566148:36,Testability,test,test,36,"I literally never had problems with test discovery, so idk what to look for. As said: Numpy and pandas have separated their testing utils from their tests. For the time being I want just that, no change to where the tests are. Would you accept a PR that simply moves the test utils into private submodules of `scanpy.testing` and switches the import mode to (future default, drawback-less) `importlib`?. Any change to the test layout can come later or never. I’d like to follow pytest’s recommendation (`/src/scanpy/` and `/tests/`) but this issue is orthogonal to that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096566148
https://github.com/scverse/scanpy/issues/2225#issuecomment-1096566148:124,Testability,test,testing,124,"I literally never had problems with test discovery, so idk what to look for. As said: Numpy and pandas have separated their testing utils from their tests. For the time being I want just that, no change to where the tests are. Would you accept a PR that simply moves the test utils into private submodules of `scanpy.testing` and switches the import mode to (future default, drawback-less) `importlib`?. Any change to the test layout can come later or never. I’d like to follow pytest’s recommendation (`/src/scanpy/` and `/tests/`) but this issue is orthogonal to that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096566148
https://github.com/scverse/scanpy/issues/2225#issuecomment-1096566148:149,Testability,test,tests,149,"I literally never had problems with test discovery, so idk what to look for. As said: Numpy and pandas have separated their testing utils from their tests. For the time being I want just that, no change to where the tests are. Would you accept a PR that simply moves the test utils into private submodules of `scanpy.testing` and switches the import mode to (future default, drawback-less) `importlib`?. Any change to the test layout can come later or never. I’d like to follow pytest’s recommendation (`/src/scanpy/` and `/tests/`) but this issue is orthogonal to that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096566148
https://github.com/scverse/scanpy/issues/2225#issuecomment-1096566148:216,Testability,test,tests,216,"I literally never had problems with test discovery, so idk what to look for. As said: Numpy and pandas have separated their testing utils from their tests. For the time being I want just that, no change to where the tests are. Would you accept a PR that simply moves the test utils into private submodules of `scanpy.testing` and switches the import mode to (future default, drawback-less) `importlib`?. Any change to the test layout can come later or never. I’d like to follow pytest’s recommendation (`/src/scanpy/` and `/tests/`) but this issue is orthogonal to that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096566148
https://github.com/scverse/scanpy/issues/2225#issuecomment-1096566148:271,Testability,test,test,271,"I literally never had problems with test discovery, so idk what to look for. As said: Numpy and pandas have separated their testing utils from their tests. For the time being I want just that, no change to where the tests are. Would you accept a PR that simply moves the test utils into private submodules of `scanpy.testing` and switches the import mode to (future default, drawback-less) `importlib`?. Any change to the test layout can come later or never. I’d like to follow pytest’s recommendation (`/src/scanpy/` and `/tests/`) but this issue is orthogonal to that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096566148
https://github.com/scverse/scanpy/issues/2225#issuecomment-1096566148:317,Testability,test,testing,317,"I literally never had problems with test discovery, so idk what to look for. As said: Numpy and pandas have separated their testing utils from their tests. For the time being I want just that, no change to where the tests are. Would you accept a PR that simply moves the test utils into private submodules of `scanpy.testing` and switches the import mode to (future default, drawback-less) `importlib`?. Any change to the test layout can come later or never. I’d like to follow pytest’s recommendation (`/src/scanpy/` and `/tests/`) but this issue is orthogonal to that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096566148
https://github.com/scverse/scanpy/issues/2225#issuecomment-1096566148:422,Testability,test,test,422,"I literally never had problems with test discovery, so idk what to look for. As said: Numpy and pandas have separated their testing utils from their tests. For the time being I want just that, no change to where the tests are. Would you accept a PR that simply moves the test utils into private submodules of `scanpy.testing` and switches the import mode to (future default, drawback-less) `importlib`?. Any change to the test layout can come later or never. I’d like to follow pytest’s recommendation (`/src/scanpy/` and `/tests/`) but this issue is orthogonal to that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096566148
https://github.com/scverse/scanpy/issues/2225#issuecomment-1096566148:524,Testability,test,tests,524,"I literally never had problems with test discovery, so idk what to look for. As said: Numpy and pandas have separated their testing utils from their tests. For the time being I want just that, no change to where the tests are. Would you accept a PR that simply moves the test utils into private submodules of `scanpy.testing` and switches the import mode to (future default, drawback-less) `importlib`?. Any change to the test layout can come later or never. I’d like to follow pytest’s recommendation (`/src/scanpy/` and `/tests/`) but this issue is orthogonal to that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096566148
https://github.com/scverse/scanpy/issues/2225#issuecomment-1096566148:254,Usability,simpl,simply,254,"I literally never had problems with test discovery, so idk what to look for. As said: Numpy and pandas have separated their testing utils from their tests. For the time being I want just that, no change to where the tests are. Would you accept a PR that simply moves the test utils into private submodules of `scanpy.testing` and switches the import mode to (future default, drawback-less) `importlib`?. Any change to the test layout can come later or never. I’d like to follow pytest’s recommendation (`/src/scanpy/` and `/tests/`) but this issue is orthogonal to that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096566148
https://github.com/scverse/scanpy/issues/2225#issuecomment-1096718863:888,Deployability,release,releases,888,"Can you point to a package whose test organization you would like our tests to emulate?. I find pytests docs rather hard to navigate and would really prefer to see an example of what you're advocating for. From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py). -----------. > Would you accept a PR that simply moves the test utils into private submodules of scanpy.testing. I'd lean towards it, but I fully expect issues like #685 to come up. This is why I'd like to see a working example of what you want to work towards. ------------. > switches the import mode to (future default, drawback-less) importlib?. Is it definitely the future default? It looks like they are walking that back. Current versions of pytest docs say:. > [We intend to make importlib the default in future releases, depending on feedback.](https://docs.pytest.org/en/latest/explanation/pythonpath.html#import-modes). Where it previously said:. > [We intend to make importlib the default in future releases.](https://docs.pytest.org/en/6.2.x/pythonpath.html#import-modes)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096718863
https://github.com/scverse/scanpy/issues/2225#issuecomment-1096718863:1079,Deployability,release,releases,1079,"Can you point to a package whose test organization you would like our tests to emulate?. I find pytests docs rather hard to navigate and would really prefer to see an example of what you're advocating for. From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py). -----------. > Would you accept a PR that simply moves the test utils into private submodules of scanpy.testing. I'd lean towards it, but I fully expect issues like #685 to come up. This is why I'd like to see a working example of what you want to work towards. ------------. > switches the import mode to (future default, drawback-less) importlib?. Is it definitely the future default? It looks like they are walking that back. Current versions of pytest docs say:. > [We intend to make importlib the default in future releases, depending on feedback.](https://docs.pytest.org/en/latest/explanation/pythonpath.html#import-modes). Where it previously said:. > [We intend to make importlib the default in future releases.](https://docs.pytest.org/en/6.2.x/pythonpath.html#import-modes)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096718863
https://github.com/scverse/scanpy/issues/2225#issuecomment-1096718863:898,Integrability,depend,depending,898,"Can you point to a package whose test organization you would like our tests to emulate?. I find pytests docs rather hard to navigate and would really prefer to see an example of what you're advocating for. From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py). -----------. > Would you accept a PR that simply moves the test utils into private submodules of scanpy.testing. I'd lean towards it, but I fully expect issues like #685 to come up. This is why I'd like to see a working example of what you want to work towards. ------------. > switches the import mode to (future default, drawback-less) importlib?. Is it definitely the future default? It looks like they are walking that back. Current versions of pytest docs say:. > [We intend to make importlib the default in future releases, depending on feedback.](https://docs.pytest.org/en/latest/explanation/pythonpath.html#import-modes). Where it previously said:. > [We intend to make importlib the default in future releases.](https://docs.pytest.org/en/6.2.x/pythonpath.html#import-modes)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096718863
https://github.com/scverse/scanpy/issues/2225#issuecomment-1096718863:33,Testability,test,test,33,"Can you point to a package whose test organization you would like our tests to emulate?. I find pytests docs rather hard to navigate and would really prefer to see an example of what you're advocating for. From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py). -----------. > Would you accept a PR that simply moves the test utils into private submodules of scanpy.testing. I'd lean towards it, but I fully expect issues like #685 to come up. This is why I'd like to see a working example of what you want to work towards. ------------. > switches the import mode to (future default, drawback-less) importlib?. Is it definitely the future default? It looks like they are walking that back. Current versions of pytest docs say:. > [We intend to make importlib the default in future releases, depending on feedback.](https://docs.pytest.org/en/latest/explanation/pythonpath.html#import-modes). Where it previously said:. > [We intend to make importlib the default in future releases.](https://docs.pytest.org/en/6.2.x/pythonpath.html#import-modes)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096718863
https://github.com/scverse/scanpy/issues/2225#issuecomment-1096718863:70,Testability,test,tests,70,"Can you point to a package whose test organization you would like our tests to emulate?. I find pytests docs rather hard to navigate and would really prefer to see an example of what you're advocating for. From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py). -----------. > Would you accept a PR that simply moves the test utils into private submodules of scanpy.testing. I'd lean towards it, but I fully expect issues like #685 to come up. This is why I'd like to see a working example of what you want to work towards. ------------. > switches the import mode to (future default, drawback-less) importlib?. Is it definitely the future default? It looks like they are walking that back. Current versions of pytest docs say:. > [We intend to make importlib the default in future releases, depending on feedback.](https://docs.pytest.org/en/latest/explanation/pythonpath.html#import-modes). Where it previously said:. > [We intend to make importlib the default in future releases.](https://docs.pytest.org/en/6.2.x/pythonpath.html#import-modes)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096718863
https://github.com/scverse/scanpy/issues/2225#issuecomment-1096718863:427,Testability,test,test,427,"Can you point to a package whose test organization you would like our tests to emulate?. I find pytests docs rather hard to navigate and would really prefer to see an example of what you're advocating for. From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py). -----------. > Would you accept a PR that simply moves the test utils into private submodules of scanpy.testing. I'd lean towards it, but I fully expect issues like #685 to come up. This is why I'd like to see a working example of what you want to work towards. ------------. > switches the import mode to (future default, drawback-less) importlib?. Is it definitely the future default? It looks like they are walking that back. Current versions of pytest docs say:. > [We intend to make importlib the default in future releases, depending on feedback.](https://docs.pytest.org/en/latest/explanation/pythonpath.html#import-modes). Where it previously said:. > [We intend to make importlib the default in future releases.](https://docs.pytest.org/en/6.2.x/pythonpath.html#import-modes)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096718863
https://github.com/scverse/scanpy/issues/2225#issuecomment-1096718863:472,Testability,test,testing,472,"Can you point to a package whose test organization you would like our tests to emulate?. I find pytests docs rather hard to navigate and would really prefer to see an example of what you're advocating for. From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py). -----------. > Would you accept a PR that simply moves the test utils into private submodules of scanpy.testing. I'd lean towards it, but I fully expect issues like #685 to come up. This is why I'd like to see a working example of what you want to work towards. ------------. > switches the import mode to (future default, drawback-less) importlib?. Is it definitely the future default? It looks like they are walking that back. Current versions of pytest docs say:. > [We intend to make importlib the default in future releases, depending on feedback.](https://docs.pytest.org/en/latest/explanation/pythonpath.html#import-modes). Where it previously said:. > [We intend to make importlib the default in future releases.](https://docs.pytest.org/en/6.2.x/pythonpath.html#import-modes)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096718863
https://github.com/scverse/scanpy/issues/2225#issuecomment-1096718863:410,Usability,simpl,simply,410,"Can you point to a package whose test organization you would like our tests to emulate?. I find pytests docs rather hard to navigate and would really prefer to see an example of what you're advocating for. From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py). -----------. > Would you accept a PR that simply moves the test utils into private submodules of scanpy.testing. I'd lean towards it, but I fully expect issues like #685 to come up. This is why I'd like to see a working example of what you want to work towards. ------------. > switches the import mode to (future default, drawback-less) importlib?. Is it definitely the future default? It looks like they are walking that back. Current versions of pytest docs say:. > [We intend to make importlib the default in future releases, depending on feedback.](https://docs.pytest.org/en/latest/explanation/pythonpath.html#import-modes). Where it previously said:. > [We intend to make importlib the default in future releases.](https://docs.pytest.org/en/6.2.x/pythonpath.html#import-modes)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096718863
https://github.com/scverse/scanpy/issues/2225#issuecomment-1096718863:911,Usability,feedback,feedback,911,"Can you point to a package whose test organization you would like our tests to emulate?. I find pytests docs rather hard to navigate and would really prefer to see an example of what you're advocating for. From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py). -----------. > Would you accept a PR that simply moves the test utils into private submodules of scanpy.testing. I'd lean towards it, but I fully expect issues like #685 to come up. This is why I'd like to see a working example of what you want to work towards. ------------. > switches the import mode to (future default, drawback-less) importlib?. Is it definitely the future default? It looks like they are walking that back. Current versions of pytest docs say:. > [We intend to make importlib the default in future releases, depending on feedback.](https://docs.pytest.org/en/latest/explanation/pythonpath.html#import-modes). Where it previously said:. > [We intend to make importlib the default in future releases.](https://docs.pytest.org/en/6.2.x/pythonpath.html#import-modes)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096718863
https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986:2254,Availability,down,down,2254," setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically?. Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module; 2. it collects all tests in those modules and checks which fixtures they need; 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that makes it easier to reason about how our test suite works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986
https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986:728,Modifiability,variab,variables,728,"> Can you point to a package whose test organization you would like our tests to emulate?. - pytest: https://github.com/pytest-dev/pytest/tree/main/testing; - loompy: https://github.com/linnarsson-lab/loompy/tree/master/tests. The others have their tests in the package, and just have that useless `__init__.py` in the tests directory because of either cargo culting it or becaue they know that makes setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically?. Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986
https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986:1362,Modifiability,config,configured,1362," of either cargo culting it or becaue they know that makes setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically?. Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module; 2. it collects all tests in those modules and checks which fixtures they need; 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986
https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986:1476,Modifiability,Config,Config,1476," setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically?. Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module; 2. it collects all tests in those modules and checks which fixtures they need; 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that makes it easier to reason about how our test suite works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986
https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986:1493,Modifiability,config,config,1493," setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically?. Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module; 2. it collects all tests in those modules and checks which fixtures they need; 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that makes it easier to reason about how our test suite works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986
https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986:2112,Modifiability,plugin,plugins,2112," setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically?. Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module; 2. it collects all tests in those modules and checks which fixtures they need; 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that makes it easier to reason about how our test suite works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986
https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986:35,Testability,test,test,35,"> Can you point to a package whose test organization you would like our tests to emulate?. - pytest: https://github.com/pytest-dev/pytest/tree/main/testing; - loompy: https://github.com/linnarsson-lab/loompy/tree/master/tests. The others have their tests in the package, and just have that useless `__init__.py` in the tests directory because of either cargo culting it or becaue they know that makes setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically?. Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986
https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986:72,Testability,test,tests,72,"> Can you point to a package whose test organization you would like our tests to emulate?. - pytest: https://github.com/pytest-dev/pytest/tree/main/testing; - loompy: https://github.com/linnarsson-lab/loompy/tree/master/tests. The others have their tests in the package, and just have that useless `__init__.py` in the tests directory because of either cargo culting it or becaue they know that makes setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically?. Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986
https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986:148,Testability,test,testing,148,"> Can you point to a package whose test organization you would like our tests to emulate?. - pytest: https://github.com/pytest-dev/pytest/tree/main/testing; - loompy: https://github.com/linnarsson-lab/loompy/tree/master/tests. The others have their tests in the package, and just have that useless `__init__.py` in the tests directory because of either cargo culting it or becaue they know that makes setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically?. Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986
https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986:220,Testability,test,tests,220,"> Can you point to a package whose test organization you would like our tests to emulate?. - pytest: https://github.com/pytest-dev/pytest/tree/main/testing; - loompy: https://github.com/linnarsson-lab/loompy/tree/master/tests. The others have their tests in the package, and just have that useless `__init__.py` in the tests directory because of either cargo culting it or becaue they know that makes setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically?. Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986
https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986:249,Testability,test,tests,249,"> Can you point to a package whose test organization you would like our tests to emulate?. - pytest: https://github.com/pytest-dev/pytest/tree/main/testing; - loompy: https://github.com/linnarsson-lab/loompy/tree/master/tests. The others have their tests in the package, and just have that useless `__init__.py` in the tests directory because of either cargo culting it or becaue they know that makes setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically?. Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986
https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986:319,Testability,test,tests,319,"> Can you point to a package whose test organization you would like our tests to emulate?. - pytest: https://github.com/pytest-dev/pytest/tree/main/testing; - loompy: https://github.com/linnarsson-lab/loompy/tree/master/tests. The others have their tests in the package, and just have that useless `__init__.py` in the tests directory because of either cargo culting it or becaue they know that makes setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically?. Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986
https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986:856,Testability,test,test,856,"> Can you point to a package whose test organization you would like our tests to emulate?. - pytest: https://github.com/pytest-dev/pytest/tree/main/testing; - loompy: https://github.com/linnarsson-lab/loompy/tree/master/tests. The others have their tests in the package, and just have that useless `__init__.py` in the tests directory because of either cargo culting it or becaue they know that makes setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically?. Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986
https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986:915,Testability,test,tests,915,"> Can you point to a package whose test organization you would like our tests to emulate?. - pytest: https://github.com/pytest-dev/pytest/tree/main/testing; - loompy: https://github.com/linnarsson-lab/loompy/tree/master/tests. The others have their tests in the package, and just have that useless `__init__.py` in the tests directory because of either cargo culting it or becaue they know that makes setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically?. Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986
https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986:1327,Testability,test,tests,1327," of either cargo culting it or becaue they know that makes setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically?. Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module; 2. it collects all tests in those modules and checks which fixtures they need; 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986
https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986:2021,Testability,test,test,2021," setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically?. Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module; 2. it collects all tests in those modules and checks which fixtures they need; 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that makes it easier to reason about how our test suite works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986
https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986:2138,Testability,test,test,2138," setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically?. Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module; 2. it collects all tests in those modules and checks which fixtures they need; 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that makes it easier to reason about how our test suite works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986
https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986:2170,Testability,test,tests,2170," setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically?. Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module; 2. it collects all tests in those modules and checks which fixtures they need; 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that makes it easier to reason about how our test suite works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986
https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986:2299,Testability,test,test,2299," setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically?. Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module; 2. it collects all tests in those modules and checks which fixtures they need; 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that makes it easier to reason about how our test suite works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986
https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986:2321,Testability,test,tests,2321," setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically?. Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module; 2. it collects all tests in those modules and checks which fixtures they need; 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that makes it easier to reason about how our test suite works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986
https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986:2383,Testability,test,test,2383," setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically?. Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module; 2. it collects all tests in those modules and checks which fixtures they need; 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that makes it easier to reason about how our test suite works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986
https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986:1732,Usability,clear,clear,1732," setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically?. Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module; 2. it collects all tests in those modules and checks which fixtures they need; 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that makes it easier to reason about how our test suite works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986
https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986:1993,Usability,simpl,simple,1993," setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically?. Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module; 2. it collects all tests in those modules and checks which fixtures they need; 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that makes it easier to reason about how our test suite works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986
https://github.com/scverse/scanpy/issues/2225#issuecomment-1098230922:729,Availability,down,down,729,"I'm not sure that pytest issue convinced me importlib is a good thing... A few of the recent *pytest developer* comments that caught my eye were:. > FWIW I'm convinced at this point that we should not change the import-mode to importlib anytime soon, some things just get harder to setup for out-source testing setups. > > We're interested in making our tests future-proof; >; > One way to do that is to add addopts = --importmode=prepend to your pytest.ini file. We don't intend to remove the prepend mode in the future at all. > FTR, IMO we probably should not change the default to importlib anytime soon (or ever)... . I would be up for a PR that only moved things outside of the test module. Things that would probably slow down or prevent merging would include:. * Changing the import mode; * Changing organization of tests; * Changing calling conventions for pytest. All of these things seem like they can be done in other PRs easily after test utilities are moved. Right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1098230922
https://github.com/scverse/scanpy/issues/2225#issuecomment-1098230922:303,Testability,test,testing,303,"I'm not sure that pytest issue convinced me importlib is a good thing... A few of the recent *pytest developer* comments that caught my eye were:. > FWIW I'm convinced at this point that we should not change the import-mode to importlib anytime soon, some things just get harder to setup for out-source testing setups. > > We're interested in making our tests future-proof; >; > One way to do that is to add addopts = --importmode=prepend to your pytest.ini file. We don't intend to remove the prepend mode in the future at all. > FTR, IMO we probably should not change the default to importlib anytime soon (or ever)... . I would be up for a PR that only moved things outside of the test module. Things that would probably slow down or prevent merging would include:. * Changing the import mode; * Changing organization of tests; * Changing calling conventions for pytest. All of these things seem like they can be done in other PRs easily after test utilities are moved. Right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1098230922
https://github.com/scverse/scanpy/issues/2225#issuecomment-1098230922:354,Testability,test,tests,354,"I'm not sure that pytest issue convinced me importlib is a good thing... A few of the recent *pytest developer* comments that caught my eye were:. > FWIW I'm convinced at this point that we should not change the import-mode to importlib anytime soon, some things just get harder to setup for out-source testing setups. > > We're interested in making our tests future-proof; >; > One way to do that is to add addopts = --importmode=prepend to your pytest.ini file. We don't intend to remove the prepend mode in the future at all. > FTR, IMO we probably should not change the default to importlib anytime soon (or ever)... . I would be up for a PR that only moved things outside of the test module. Things that would probably slow down or prevent merging would include:. * Changing the import mode; * Changing organization of tests; * Changing calling conventions for pytest. All of these things seem like they can be done in other PRs easily after test utilities are moved. Right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1098230922
https://github.com/scverse/scanpy/issues/2225#issuecomment-1098230922:684,Testability,test,test,684,"I'm not sure that pytest issue convinced me importlib is a good thing... A few of the recent *pytest developer* comments that caught my eye were:. > FWIW I'm convinced at this point that we should not change the import-mode to importlib anytime soon, some things just get harder to setup for out-source testing setups. > > We're interested in making our tests future-proof; >; > One way to do that is to add addopts = --importmode=prepend to your pytest.ini file. We don't intend to remove the prepend mode in the future at all. > FTR, IMO we probably should not change the default to importlib anytime soon (or ever)... . I would be up for a PR that only moved things outside of the test module. Things that would probably slow down or prevent merging would include:. * Changing the import mode; * Changing organization of tests; * Changing calling conventions for pytest. All of these things seem like they can be done in other PRs easily after test utilities are moved. Right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1098230922
https://github.com/scverse/scanpy/issues/2225#issuecomment-1098230922:824,Testability,test,tests,824,"I'm not sure that pytest issue convinced me importlib is a good thing... A few of the recent *pytest developer* comments that caught my eye were:. > FWIW I'm convinced at this point that we should not change the import-mode to importlib anytime soon, some things just get harder to setup for out-source testing setups. > > We're interested in making our tests future-proof; >; > One way to do that is to add addopts = --importmode=prepend to your pytest.ini file. We don't intend to remove the prepend mode in the future at all. > FTR, IMO we probably should not change the default to importlib anytime soon (or ever)... . I would be up for a PR that only moved things outside of the test module. Things that would probably slow down or prevent merging would include:. * Changing the import mode; * Changing organization of tests; * Changing calling conventions for pytest. All of these things seem like they can be done in other PRs easily after test utilities are moved. Right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1098230922
https://github.com/scverse/scanpy/issues/2225#issuecomment-1098230922:947,Testability,test,test,947,"I'm not sure that pytest issue convinced me importlib is a good thing... A few of the recent *pytest developer* comments that caught my eye were:. > FWIW I'm convinced at this point that we should not change the import-mode to importlib anytime soon, some things just get harder to setup for out-source testing setups. > > We're interested in making our tests future-proof; >; > One way to do that is to add addopts = --importmode=prepend to your pytest.ini file. We don't intend to remove the prepend mode in the future at all. > FTR, IMO we probably should not change the default to importlib anytime soon (or ever)... . I would be up for a PR that only moved things outside of the test module. Things that would probably slow down or prevent merging would include:. * Changing the import mode; * Changing organization of tests; * Changing calling conventions for pytest. All of these things seem like they can be done in other PRs easily after test utilities are moved. Right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1098230922
https://github.com/scverse/scanpy/pull/2226#issuecomment-1090215514:326,Availability,error,error-reference,326,# [Codecov](https://codecov.io/gh/scverse/scanpy/pull/2226?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@a08c155`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## 1.9.x #2226 +/- ##; ========================================; Coverage ? 71.82% ; ========================================; Files ? 98 ; Lines ? 11539 ; Branches ? 0 ; ========================================; Hits ? 8288 ; Misses ? 3251 ; Partials ? 0 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2226#issuecomment-1090215514
https://github.com/scverse/scanpy/pull/2226#issuecomment-1090215514:274,Usability,learn,learn,274,# [Codecov](https://codecov.io/gh/scverse/scanpy/pull/2226?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@a08c155`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## 1.9.x #2226 +/- ##; ========================================; Coverage ? 71.82% ; ========================================; Files ? 98 ; Lines ? 11539 ; Branches ? 0 ; ========================================; Hits ? 8288 ; Misses ? 3251 ; Partials ? 0 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2226#issuecomment-1090215514
https://github.com/scverse/scanpy/issues/2229#issuecomment-1256989255:95,Availability,error,error,95,"Yeah agree this is inconsistent, I'd say we should either correct the documentation + throw an error when the wrong argument is passed, or implement the matplotlib options. @ivirshup what do you think?. In [_anndata.py](https://github.com/scverse/scanpy/blob/11d0b8e992ad145eeb3f666aa4e006bd204272de/scanpy/plotting/_anndata.py#L38-L54) plotting script, VALID_LEGENDLOCS is set (not sure in which plotting functions that is eventually used), could we use something similar for the above example?; ```python; VALID_LEGENDLOCS = {; 'none',; 'right margin',; 'on data',; 'on data export',; 'best',; 'upper right',; 'upper left',; 'lower left',; 'lower right',; 'right',; 'center left',; 'center right',; 'lower center',; 'upper center',; 'center',; }; ```; Also related to issue #2322",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2229#issuecomment-1256989255
https://github.com/scverse/scanpy/pull/2231#issuecomment-1117367877:278,Testability,test,test,278,@lazappi you are now the chosen one :). Think that using the size attribute like in https://github.com/scverse/scanpy/pull/1985/files is maybe nicer and more explicit. `len()` could technically be overwritten and return anything. It's less explicit. Could you maybe add a quick test which covers this case?. Thank you very much!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231#issuecomment-1117367877
https://github.com/scverse/scanpy/pull/2231#issuecomment-1118266184:36,Testability,test,test,36,Made the `.size` change and added a test. Not entirely sure I have done the test correctly so let me know if that needs adjusting.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231#issuecomment-1118266184
https://github.com/scverse/scanpy/pull/2231#issuecomment-1118266184:76,Testability,test,test,76,Made the `.size` change and added a test. Not entirely sure I have done the test correctly so let me know if that needs adjusting.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231#issuecomment-1118266184
https://github.com/scverse/scanpy/pull/2231#issuecomment-1139755842:70,Availability,error,errors,70,"Sorry, I forgot about this. Not sure why the CI was falling. The only errors I get locally were due to problems with matching images.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231#issuecomment-1139755842
https://github.com/scverse/scanpy/pull/2231#issuecomment-1139757936:84,Availability,failure,failures,84,"@lazappi no worries! The scanpy CI has always been a little bit flaky and sometimes failures are not the faults of people submitting pull requests. If it fails again, we can dig deeper.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231#issuecomment-1139757936
https://github.com/scverse/scanpy/pull/2231#issuecomment-1139757936:105,Availability,fault,faults,105,"@lazappi no worries! The scanpy CI has always been a little bit flaky and sometimes failures are not the faults of people submitting pull requests. If it fails again, we can dig deeper.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231#issuecomment-1139757936
https://github.com/scverse/scanpy/pull/2231#issuecomment-1140780018:40,Availability,Error,Error,40,It looks like the same `AssertionError: Error: Image files did not match.` error I was getting locally from some of the spatial tests. I haven't touched this so not sure what's going on there.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231#issuecomment-1140780018
https://github.com/scverse/scanpy/pull/2231#issuecomment-1140780018:75,Availability,error,error,75,It looks like the same `AssertionError: Error: Image files did not match.` error I was getting locally from some of the spatial tests. I haven't touched this so not sure what's going on there.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231#issuecomment-1140780018
https://github.com/scverse/scanpy/pull/2231#issuecomment-1140780018:24,Testability,Assert,AssertionError,24,It looks like the same `AssertionError: Error: Image files did not match.` error I was getting locally from some of the spatial tests. I haven't touched this so not sure what's going on there.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231#issuecomment-1140780018
https://github.com/scverse/scanpy/pull/2231#issuecomment-1140780018:128,Testability,test,tests,128,It looks like the same `AssertionError: Error: Image files did not match.` error I was getting locally from some of the spatial tests. I haven't touched this so not sure what's going on there.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231#issuecomment-1140780018
https://github.com/scverse/scanpy/pull/2231#issuecomment-1158926683:67,Deployability,release,release,67,"@ivirshup this one should be good to go now, right? Do you require release notes for such small things or do you manually add those later?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231#issuecomment-1158926683
https://github.com/scverse/scanpy/pull/2231#issuecomment-1158944115:30,Deployability,release,release,30,"And yes, should get a bug fix release note.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231#issuecomment-1158944115
https://github.com/scverse/scanpy/issues/2234#issuecomment-2311895711:28,Availability,mask,mask,28,"Yes, we already have a good mask for sparse scaling. Boolean arrays are very effective for indicating where computations should be performed, as they eliminate the need for copying and reintegration. One clear example is the `tl.score_genes` function. masks there as booleans for the nanmean is a lot more efficent but less pythonic",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2234#issuecomment-2311895711
https://github.com/scverse/scanpy/issues/2234#issuecomment-2311895711:252,Availability,mask,masks,252,"Yes, we already have a good mask for sparse scaling. Boolean arrays are very effective for indicating where computations should be performed, as they eliminate the need for copying and reintegration. One clear example is the `tl.score_genes` function. masks there as booleans for the nanmean is a lot more efficent but less pythonic",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2234#issuecomment-2311895711
https://github.com/scverse/scanpy/issues/2234#issuecomment-2311895711:131,Performance,perform,performed,131,"Yes, we already have a good mask for sparse scaling. Boolean arrays are very effective for indicating where computations should be performed, as they eliminate the need for copying and reintegration. One clear example is the `tl.score_genes` function. masks there as booleans for the nanmean is a lot more efficent but less pythonic",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2234#issuecomment-2311895711
https://github.com/scverse/scanpy/issues/2234#issuecomment-2311895711:204,Usability,clear,clear,204,"Yes, we already have a good mask for sparse scaling. Boolean arrays are very effective for indicating where computations should be performed, as they eliminate the need for copying and reintegration. One clear example is the `tl.score_genes` function. masks there as booleans for the nanmean is a lot more efficent but less pythonic",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2234#issuecomment-2311895711
https://github.com/scverse/scanpy/pull/2235#issuecomment-1098162430:1289,Testability,test,testing,1289,://app.codecov.io/gh/scverse/scanpy/pull/2235?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) (fcb0a06) into [master](https://app.codecov.io/gh/scverse/scanpy/commit/06802b459648a219a10f74243efe4d6c2f912016?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) (06802b4) will **increase** coverage by `0.24%`.; > The diff coverage is `85.84%`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2235 +/- ##; ==========================================; + Coverage 71.89% 72.14% +0.24% ; ==========================================; Files 98 104 +6 ; Lines 11518 11678 +160 ; ==========================================; + Hits 8281 8425 +144 ; - Misses 3237 3253 +16 ; ```. | [Impacted Files](https://app.codecov.io/gh/scverse/scanpy/pull/2235?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/testing/\_pytest/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2235?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9fX2luaXRfXy5weQ==) | `60.86% <60.86%> (ø)` | |; | [scanpy/testing/\_pytest/marks.py](https://app.codecov.io/gh/scverse/scanpy/pull/2235?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9tYXJrcy5weQ==) | `84.61% <84.61%> (ø)` | |; | [scanpy/testing/\_helpers/data.py](https://app.codecov.io/gh/scverse/scanpy/pull/2235?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX2hlbHBlcnMvZGF0YS5weQ==) | `88.57% <88.57%> (ø)` | |; | [scanpy/plotting/\_tools/\_\_init\_\_.py](https://app.codecov.io/gh/,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235#issuecomment-1098162430
https://github.com/scverse/scanpy/pull/2235#issuecomment-1098162430:1583,Testability,test,testing,1583,m=scverse) (06802b4) will **increase** coverage by `0.24%`.; > The diff coverage is `85.84%`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2235 +/- ##; ==========================================; + Coverage 71.89% 72.14% +0.24% ; ==========================================; Files 98 104 +6 ; Lines 11518 11678 +160 ; ==========================================; + Hits 8281 8425 +144 ; - Misses 3237 3253 +16 ; ```. | [Impacted Files](https://app.codecov.io/gh/scverse/scanpy/pull/2235?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/testing/\_pytest/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2235?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9fX2luaXRfXy5weQ==) | `60.86% <60.86%> (ø)` | |; | [scanpy/testing/\_pytest/marks.py](https://app.codecov.io/gh/scverse/scanpy/pull/2235?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9tYXJrcy5weQ==) | `84.61% <84.61%> (ø)` | |; | [scanpy/testing/\_helpers/data.py](https://app.codecov.io/gh/scverse/scanpy/pull/2235?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX2hlbHBlcnMvZGF0YS5weQ==) | `88.57% <88.57%> (ø)` | |; | [scanpy/plotting/\_tools/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2235?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL190b29scy9fX2luaXRfXy5weQ==) | `76.77% <100.00%> (ø)` | |; | [scanpy/plotting/\_tools/scatterplots.py](https://app.codecov.io/gh/scverse/scanpy/pull/2235?src=pr&el=tree&utm_medium=referral&utm_source=github&,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235#issuecomment-1098162430
https://github.com/scverse/scanpy/pull/2235#issuecomment-1098162430:1866,Testability,test,testing,1866, +0.24% ; ==========================================; Files 98 104 +6 ; Lines 11518 11678 +160 ; ==========================================; + Hits 8281 8425 +144 ; - Misses 3237 3253 +16 ; ```. | [Impacted Files](https://app.codecov.io/gh/scverse/scanpy/pull/2235?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/testing/\_pytest/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2235?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9fX2luaXRfXy5weQ==) | `60.86% <60.86%> (ø)` | |; | [scanpy/testing/\_pytest/marks.py](https://app.codecov.io/gh/scverse/scanpy/pull/2235?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9tYXJrcy5weQ==) | `84.61% <84.61%> (ø)` | |; | [scanpy/testing/\_helpers/data.py](https://app.codecov.io/gh/scverse/scanpy/pull/2235?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX2hlbHBlcnMvZGF0YS5weQ==) | `88.57% <88.57%> (ø)` | |; | [scanpy/plotting/\_tools/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2235?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL190b29scy9fX2luaXRfXy5weQ==) | `76.77% <100.00%> (ø)` | |; | [scanpy/plotting/\_tools/scatterplots.py](https://app.codecov.io/gh/scverse/scanpy/pull/2235?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL190b29scy9zY2F0dGVycGxvdHMucHk=) | `87.20% <100.00%> (-1.22%)` | :arrow_down: |; | [scanpy/testing/\_helpers/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2235?src=pr&el=tree&utm,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235#issuecomment-1098162430
https://github.com/scverse/scanpy/pull/2235#issuecomment-1098162430:2761,Testability,test,testing,2761,utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9tYXJrcy5weQ==) | `84.61% <84.61%> (ø)` | |; | [scanpy/testing/\_helpers/data.py](https://app.codecov.io/gh/scverse/scanpy/pull/2235?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX2hlbHBlcnMvZGF0YS5weQ==) | `88.57% <88.57%> (ø)` | |; | [scanpy/plotting/\_tools/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2235?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL190b29scy9fX2luaXRfXy5weQ==) | `76.77% <100.00%> (ø)` | |; | [scanpy/plotting/\_tools/scatterplots.py](https://app.codecov.io/gh/scverse/scanpy/pull/2235?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL190b29scy9zY2F0dGVycGxvdHMucHk=) | `87.20% <100.00%> (-1.22%)` | :arrow_down: |; | [scanpy/testing/\_helpers/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2235?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX2hlbHBlcnMvX19pbml0X18ucHk=) | `100.00% <100.00%> (ø)` | |; | [scanpy/testing/\_pytest/fixtures/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2235?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9maXh0dXJlcy9fX2luaXRfXy5weQ==) | `91.66% <100.00%> (ø)` | |; | [scanpy/testing/\_pytest/fixtures/data.py](https://app.codecov.io/gh/scverse/scanpy/pull/2235?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9maXh0dXJlcy9kYXRhLnB5) | `100.00% <100.00%> (ø)` | |. ... and [5 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235#issuecomment-1098162430
https://github.com/scverse/scanpy/pull/2235#issuecomment-1098162430:3058,Testability,test,testing,3058,o/gh/scverse/scanpy/pull/2235?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX2hlbHBlcnMvZGF0YS5weQ==) | `88.57% <88.57%> (ø)` | |; | [scanpy/plotting/\_tools/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2235?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL190b29scy9fX2luaXRfXy5weQ==) | `76.77% <100.00%> (ø)` | |; | [scanpy/plotting/\_tools/scatterplots.py](https://app.codecov.io/gh/scverse/scanpy/pull/2235?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL190b29scy9zY2F0dGVycGxvdHMucHk=) | `87.20% <100.00%> (-1.22%)` | :arrow_down: |; | [scanpy/testing/\_helpers/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2235?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX2hlbHBlcnMvX19pbml0X18ucHk=) | `100.00% <100.00%> (ø)` | |; | [scanpy/testing/\_pytest/fixtures/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2235?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9maXh0dXJlcy9fX2luaXRfXy5weQ==) | `91.66% <100.00%> (ø)` | |; | [scanpy/testing/\_pytest/fixtures/data.py](https://app.codecov.io/gh/scverse/scanpy/pull/2235?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9maXh0dXJlcy9kYXRhLnB5) | `100.00% <100.00%> (ø)` | |. ... and [5 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2235/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235#issuecomment-1098162430
https://github.com/scverse/scanpy/pull/2235#issuecomment-1098162430:3374,Testability,test,testing,3374,o/gh/scverse/scanpy/pull/2235?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX2hlbHBlcnMvZGF0YS5weQ==) | `88.57% <88.57%> (ø)` | |; | [scanpy/plotting/\_tools/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2235?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL190b29scy9fX2luaXRfXy5weQ==) | `76.77% <100.00%> (ø)` | |; | [scanpy/plotting/\_tools/scatterplots.py](https://app.codecov.io/gh/scverse/scanpy/pull/2235?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL190b29scy9zY2F0dGVycGxvdHMucHk=) | `87.20% <100.00%> (-1.22%)` | :arrow_down: |; | [scanpy/testing/\_helpers/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2235?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX2hlbHBlcnMvX19pbml0X18ucHk=) | `100.00% <100.00%> (ø)` | |; | [scanpy/testing/\_pytest/fixtures/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2235?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9maXh0dXJlcy9fX2luaXRfXy5weQ==) | `91.66% <100.00%> (ø)` | |; | [scanpy/testing/\_pytest/fixtures/data.py](https://app.codecov.io/gh/scverse/scanpy/pull/2235?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9maXh0dXJlcy9kYXRhLnB5) | `100.00% <100.00%> (ø)` | |. ... and [5 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2235/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235#issuecomment-1098162430
https://github.com/scverse/scanpy/pull/2235#issuecomment-1099069308:19,Availability,failure,failures,19,@ivirshup The test failures are a bug exposed by the fixture refactoring. The tests were relying on `adata['uns']['pos']` being left over from a previous test run. Can you help me fix it?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235#issuecomment-1099069308
https://github.com/scverse/scanpy/pull/2235#issuecomment-1099069308:61,Modifiability,refactor,refactoring,61,@ivirshup The test failures are a bug exposed by the fixture refactoring. The tests were relying on `adata['uns']['pos']` being left over from a previous test run. Can you help me fix it?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235#issuecomment-1099069308
https://github.com/scverse/scanpy/pull/2235#issuecomment-1099069308:38,Security,expose,exposed,38,@ivirshup The test failures are a bug exposed by the fixture refactoring. The tests were relying on `adata['uns']['pos']` being left over from a previous test run. Can you help me fix it?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235#issuecomment-1099069308
https://github.com/scverse/scanpy/pull/2235#issuecomment-1099069308:14,Testability,test,test,14,@ivirshup The test failures are a bug exposed by the fixture refactoring. The tests were relying on `adata['uns']['pos']` being left over from a previous test run. Can you help me fix it?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235#issuecomment-1099069308
https://github.com/scverse/scanpy/pull/2235#issuecomment-1099069308:78,Testability,test,tests,78,@ivirshup The test failures are a bug exposed by the fixture refactoring. The tests were relying on `adata['uns']['pos']` being left over from a previous test run. Can you help me fix it?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235#issuecomment-1099069308
https://github.com/scverse/scanpy/pull/2235#issuecomment-1099069308:154,Testability,test,test,154,@ivirshup The test failures are a bug exposed by the fixture refactoring. The tests were relying on `adata['uns']['pos']` being left over from a previous test run. Can you help me fix it?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235#issuecomment-1099069308
https://github.com/scverse/scanpy/pull/2235#issuecomment-1597177367:39,Deployability,update,updates,39,"@flying-sheep, I see you're doing some updates here. Are you doing anything to narrow the scope of the PR as requested last go-around?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235#issuecomment-1597177367
https://github.com/scverse/scanpy/pull/2235#issuecomment-1597183580:225,Testability,test,test,225,I answered that back then already. - https://github.com/scverse/scanpy/pull/2235#discussion_r850302669; - https://github.com/scverse/scanpy/pull/2235#discussion_r850304636. This PR has exactly the scope necessary to separate test utils and tests. The only thing that I can think of to add to those answers is that the repeated code for all the data fixtures is necessary to make editors understand them. A more dynamic way to make all those fixtures breaks ctrl/cmd-clicking fixtures.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235#issuecomment-1597183580
https://github.com/scverse/scanpy/pull/2235#issuecomment-1597183580:240,Testability,test,tests,240,I answered that back then already. - https://github.com/scverse/scanpy/pull/2235#discussion_r850302669; - https://github.com/scverse/scanpy/pull/2235#discussion_r850304636. This PR has exactly the scope necessary to separate test utils and tests. The only thing that I can think of to add to those answers is that the repeated code for all the data fixtures is necessary to make editors understand them. A more dynamic way to make all those fixtures breaks ctrl/cmd-clicking fixtures.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235#issuecomment-1597183580
https://github.com/scverse/scanpy/pull/2235#issuecomment-1598722003:32,Testability,test,tests,32,"It’s connected because the paga tests don’t `copy` the objects and therefore run sequentially, but I can extract it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235#issuecomment-1598722003
https://github.com/scverse/scanpy/pull/2235#issuecomment-1598724173:105,Deployability,update,update,105,"Extracting it would be great. What triggered the test to fail on other branches, I'd assume a matplotlib update?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235#issuecomment-1598724173
https://github.com/scverse/scanpy/pull/2235#issuecomment-1598724173:49,Testability,test,test,49,"Extracting it would be great. What triggered the test to fail on other branches, I'd assume a matplotlib update?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235#issuecomment-1598724173
https://github.com/scverse/scanpy/pull/2235#issuecomment-1604242870:157,Deployability,update,update,157,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 e5d41d4aa58a925f0fa5cfcf580cb975167a71c9; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2235: Separate test utils from tests'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2235-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2235 on branch 1.9.x (Separate test utils from tests)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235#issuecomment-1604242870
https://github.com/scverse/scanpy/pull/2235#issuecomment-1604242870:899,Deployability,continuous,continuous,899,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 e5d41d4aa58a925f0fa5cfcf580cb975167a71c9; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2235: Separate test utils from tests'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2235-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2235 on branch 1.9.x (Separate test utils from tests)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235#issuecomment-1604242870
https://github.com/scverse/scanpy/pull/2235#issuecomment-1604242870:910,Deployability,integrat,integration,910,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 e5d41d4aa58a925f0fa5cfcf580cb975167a71c9; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2235: Separate test utils from tests'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2235-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2235 on branch 1.9.x (Separate test utils from tests)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235#issuecomment-1604242870
https://github.com/scverse/scanpy/pull/2235#issuecomment-1604242870:910,Integrability,integrat,integration,910,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 e5d41d4aa58a925f0fa5cfcf580cb975167a71c9; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2235: Separate test utils from tests'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2235-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2235 on branch 1.9.x (Separate test utils from tests)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235#issuecomment-1604242870
https://github.com/scverse/scanpy/pull/2235#issuecomment-1604242870:499,Testability,test,test,499,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 e5d41d4aa58a925f0fa5cfcf580cb975167a71c9; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2235: Separate test utils from tests'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2235-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2235 on branch 1.9.x (Separate test utils from tests)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235#issuecomment-1604242870
https://github.com/scverse/scanpy/pull/2235#issuecomment-1604242870:515,Testability,test,tests,515,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 e5d41d4aa58a925f0fa5cfcf580cb975167a71c9; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2235: Separate test utils from tests'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2235-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2235 on branch 1.9.x (Separate test utils from tests)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235#issuecomment-1604242870
https://github.com/scverse/scanpy/pull/2235#issuecomment-1604242870:738,Testability,test,test,738,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 e5d41d4aa58a925f0fa5cfcf580cb975167a71c9; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2235: Separate test utils from tests'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2235-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2235 on branch 1.9.x (Separate test utils from tests)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235#issuecomment-1604242870
https://github.com/scverse/scanpy/pull/2235#issuecomment-1604242870:754,Testability,test,tests,754,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 e5d41d4aa58a925f0fa5cfcf580cb975167a71c9; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2235: Separate test utils from tests'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2235-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2235 on branch 1.9.x (Separate test utils from tests)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235#issuecomment-1604242870
https://github.com/scverse/scanpy/pull/2235#issuecomment-1604242870:885,Testability,test,tested,885,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 e5d41d4aa58a925f0fa5cfcf580cb975167a71c9; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2235: Separate test utils from tests'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2235-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2235 on branch 1.9.x (Separate test utils from tests)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235#issuecomment-1604242870
https://github.com/scverse/scanpy/issues/2237#issuecomment-1101038489:22,Deployability,install,install,22,You should be able to install an experimental m1 native numba here:. https://numba.discourse.group/t/wheels-for-apple-silicon-m1/1282,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2237#issuecomment-1101038489
https://github.com/scverse/scanpy/issues/2239#issuecomment-1104127300:5,Availability,error,error,5,"Same error here...any ideas?. ```; -----; anndata 0.8.0; scanpy 1.8.2; sinfo 0.3.1; -----; PIL 9.0.1; PyQt5 NA; anndata 0.8.0; anndata2ri 0.0.0; atomicwrites 1.4.0; autoreload NA; backcall 0.2.0; backports NA; beta_ufunc NA; binom_ufunc NA; bs4 4.10.0; cached_property 1.5.2; cffi 1.15.0; chardet 4.0.0; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.2; dask 2022.02.0; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; dunamai 1.10.0; entrypoints 0.4; fsspec 2022.02.0; get_version 3.5.4; h5py 3.6.0; igraph 0.9.9; ipykernel 6.9.1; jedi 0.18.1; jinja2 3.0.3; joblib 1.1.0; kiwisolver 1.3.2; leidenalg 0.8.9; llvmlite 0.38.0; louvain 0.7.1; markupsafe 2.1.0; matplotlib 3.5.1; matplotlib_inline NA; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.1; numexpr 2.8.0; numpy 1.21.5; packaging 21.3; pandas 1.3.5; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.27; psutil 5.9.0; ptyprocess 0.7.0; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pyparsing 3.0.7; pytz 2021.3; pytz_deprecation_shim NA; rpy2 3.4.2; scanpy 1.8.2; scipy 1.7.3; seaborn 0.11.2; setuptools 59.8.0; sinfo 0.3.1; sip NA; six 1.16.0; sklearn 1.0.2; soupsieve 2.3.1; sphinxcontrib NA; spyder 5.2.2; spyder_kernels 2.2.1; spydercustomize NA; statsmodels 0.13.2; storemagic NA; tables 3.7.0; texttable 1.6.4; threadpoolctl 3.1.0; tlz 0.11.2; toolz 0.11.2; tornado 6.1; traitlets 5.1.1; typing_extensions NA; tzlocal NA; wcwidth 0.2.5; wurlitzer 3.0.2; yaml 6.0; zipp NA; zmq 22.3.0; -----; IPython 7.32.0; jupyter_client 7.1.2; jupyter_core 4.9.2; -----; Python 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]; Linux-5.4.0-109-generic-x86_64-with-debian-bullseye-sid; 16 logical CPU cores, x86_64; -----; Session information updated at 2022-04-20 18:16; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239#issuecomment-1104127300
https://github.com/scverse/scanpy/issues/2239#issuecomment-1104127300:1933,Deployability,update,updated,1933,"Same error here...any ideas?. ```; -----; anndata 0.8.0; scanpy 1.8.2; sinfo 0.3.1; -----; PIL 9.0.1; PyQt5 NA; anndata 0.8.0; anndata2ri 0.0.0; atomicwrites 1.4.0; autoreload NA; backcall 0.2.0; backports NA; beta_ufunc NA; binom_ufunc NA; bs4 4.10.0; cached_property 1.5.2; cffi 1.15.0; chardet 4.0.0; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.2; dask 2022.02.0; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; dunamai 1.10.0; entrypoints 0.4; fsspec 2022.02.0; get_version 3.5.4; h5py 3.6.0; igraph 0.9.9; ipykernel 6.9.1; jedi 0.18.1; jinja2 3.0.3; joblib 1.1.0; kiwisolver 1.3.2; leidenalg 0.8.9; llvmlite 0.38.0; louvain 0.7.1; markupsafe 2.1.0; matplotlib 3.5.1; matplotlib_inline NA; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.1; numexpr 2.8.0; numpy 1.21.5; packaging 21.3; pandas 1.3.5; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.27; psutil 5.9.0; ptyprocess 0.7.0; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pyparsing 3.0.7; pytz 2021.3; pytz_deprecation_shim NA; rpy2 3.4.2; scanpy 1.8.2; scipy 1.7.3; seaborn 0.11.2; setuptools 59.8.0; sinfo 0.3.1; sip NA; six 1.16.0; sklearn 1.0.2; soupsieve 2.3.1; sphinxcontrib NA; spyder 5.2.2; spyder_kernels 2.2.1; spydercustomize NA; statsmodels 0.13.2; storemagic NA; tables 3.7.0; texttable 1.6.4; threadpoolctl 3.1.0; tlz 0.11.2; toolz 0.11.2; tornado 6.1; traitlets 5.1.1; typing_extensions NA; tzlocal NA; wcwidth 0.2.5; wurlitzer 3.0.2; yaml 6.0; zipp NA; zmq 22.3.0; -----; IPython 7.32.0; jupyter_client 7.1.2; jupyter_core 4.9.2; -----; Python 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]; Linux-5.4.0-109-generic-x86_64-with-debian-bullseye-sid; 16 logical CPU cores, x86_64; -----; Session information updated at 2022-04-20 18:16; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239#issuecomment-1104127300
https://github.com/scverse/scanpy/issues/2239#issuecomment-1104127300:1879,Testability,log,logical,1879,"Same error here...any ideas?. ```; -----; anndata 0.8.0; scanpy 1.8.2; sinfo 0.3.1; -----; PIL 9.0.1; PyQt5 NA; anndata 0.8.0; anndata2ri 0.0.0; atomicwrites 1.4.0; autoreload NA; backcall 0.2.0; backports NA; beta_ufunc NA; binom_ufunc NA; bs4 4.10.0; cached_property 1.5.2; cffi 1.15.0; chardet 4.0.0; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.2; dask 2022.02.0; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; dunamai 1.10.0; entrypoints 0.4; fsspec 2022.02.0; get_version 3.5.4; h5py 3.6.0; igraph 0.9.9; ipykernel 6.9.1; jedi 0.18.1; jinja2 3.0.3; joblib 1.1.0; kiwisolver 1.3.2; leidenalg 0.8.9; llvmlite 0.38.0; louvain 0.7.1; markupsafe 2.1.0; matplotlib 3.5.1; matplotlib_inline NA; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.1; numexpr 2.8.0; numpy 1.21.5; packaging 21.3; pandas 1.3.5; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.27; psutil 5.9.0; ptyprocess 0.7.0; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pyparsing 3.0.7; pytz 2021.3; pytz_deprecation_shim NA; rpy2 3.4.2; scanpy 1.8.2; scipy 1.7.3; seaborn 0.11.2; setuptools 59.8.0; sinfo 0.3.1; sip NA; six 1.16.0; sklearn 1.0.2; soupsieve 2.3.1; sphinxcontrib NA; spyder 5.2.2; spyder_kernels 2.2.1; spydercustomize NA; statsmodels 0.13.2; storemagic NA; tables 3.7.0; texttable 1.6.4; threadpoolctl 3.1.0; tlz 0.11.2; toolz 0.11.2; tornado 6.1; traitlets 5.1.1; typing_extensions NA; tzlocal NA; wcwidth 0.2.5; wurlitzer 3.0.2; yaml 6.0; zipp NA; zmq 22.3.0; -----; IPython 7.32.0; jupyter_client 7.1.2; jupyter_core 4.9.2; -----; Python 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]; Linux-5.4.0-109-generic-x86_64-with-debian-bullseye-sid; 16 logical CPU cores, x86_64; -----; Session information updated at 2022-04-20 18:16; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239#issuecomment-1104127300
https://github.com/scverse/scanpy/issues/2239#issuecomment-1184556213:64,Availability,error,error,64,"> adata.uns['log1p'][""base""] = None. Thank you. I also had this error when calculating highly variable genes `sc.pp.highly_variable_genes(Adult,batch_key='batch')`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239#issuecomment-1184556213
https://github.com/scverse/scanpy/issues/2239#issuecomment-1184556213:94,Modifiability,variab,variable,94,"> adata.uns['log1p'][""base""] = None. Thank you. I also had this error when calculating highly variable genes `sc.pp.highly_variable_genes(Adult,batch_key='batch')`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239#issuecomment-1184556213
https://github.com/scverse/scanpy/issues/2239#issuecomment-1319791016:304,Integrability,wrap,wrapping,304,"Trying out the tutorials these days and it seems this issue still persists. ---; Here is what I got from running the tutorial `pbmc3k.ipynb`:; Before writing the `AnnData` object to a `.h5ad` file (after the PCA step; before computing the neighborhood graph); - Inside `adata.uns`:; ```; OverloadedDict, wrapping:; 	OrderedDict([('log1p', {'base': None}), ('hvg', {'flavor': 'seurat'}), ('pca', {'params': {'zero_center': True, 'use_highly_variable': True}, 'variance': array([ (not showing the numbers for simplicity here) ],; dtype=float32), 'variance_ratio': array([ (not showing the numbers for simplicity here) ],; dtype=float32)})]); With overloaded keys:; 	['neighbors'].; ```. ---; After loading the matrix from the `.h5ad` file:; - Inside `adata.uns`, the `log1p` key became an empty dictionary:; ```; OverloadedDict, wrapping:; 	{'hvg': {'flavor': 'seurat'}, 'log1p': {}, 'pca': {'params': {'use_highly_variable': True, 'zero_center': True}, 'variance': array([ (not showing the numbers for simplicity here) ],; dtype=float32), 'variance_ratio': array([ (not showing the numbers for simplicity here) ],; dtype=float32)}}; With overloaded keys:; 	['neighbors'].; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239#issuecomment-1319791016
https://github.com/scverse/scanpy/issues/2239#issuecomment-1319791016:827,Integrability,wrap,wrapping,827,"Trying out the tutorials these days and it seems this issue still persists. ---; Here is what I got from running the tutorial `pbmc3k.ipynb`:; Before writing the `AnnData` object to a `.h5ad` file (after the PCA step; before computing the neighborhood graph); - Inside `adata.uns`:; ```; OverloadedDict, wrapping:; 	OrderedDict([('log1p', {'base': None}), ('hvg', {'flavor': 'seurat'}), ('pca', {'params': {'zero_center': True, 'use_highly_variable': True}, 'variance': array([ (not showing the numbers for simplicity here) ],; dtype=float32), 'variance_ratio': array([ (not showing the numbers for simplicity here) ],; dtype=float32)})]); With overloaded keys:; 	['neighbors'].; ```. ---; After loading the matrix from the `.h5ad` file:; - Inside `adata.uns`, the `log1p` key became an empty dictionary:; ```; OverloadedDict, wrapping:; 	{'hvg': {'flavor': 'seurat'}, 'log1p': {}, 'pca': {'params': {'use_highly_variable': True, 'zero_center': True}, 'variance': array([ (not showing the numbers for simplicity here) ],; dtype=float32), 'variance_ratio': array([ (not showing the numbers for simplicity here) ],; dtype=float32)}}; With overloaded keys:; 	['neighbors'].; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239#issuecomment-1319791016
https://github.com/scverse/scanpy/issues/2239#issuecomment-1319791016:696,Performance,load,loading,696,"Trying out the tutorials these days and it seems this issue still persists. ---; Here is what I got from running the tutorial `pbmc3k.ipynb`:; Before writing the `AnnData` object to a `.h5ad` file (after the PCA step; before computing the neighborhood graph); - Inside `adata.uns`:; ```; OverloadedDict, wrapping:; 	OrderedDict([('log1p', {'base': None}), ('hvg', {'flavor': 'seurat'}), ('pca', {'params': {'zero_center': True, 'use_highly_variable': True}, 'variance': array([ (not showing the numbers for simplicity here) ],; dtype=float32), 'variance_ratio': array([ (not showing the numbers for simplicity here) ],; dtype=float32)})]); With overloaded keys:; 	['neighbors'].; ```. ---; After loading the matrix from the `.h5ad` file:; - Inside `adata.uns`, the `log1p` key became an empty dictionary:; ```; OverloadedDict, wrapping:; 	{'hvg': {'flavor': 'seurat'}, 'log1p': {}, 'pca': {'params': {'use_highly_variable': True, 'zero_center': True}, 'variance': array([ (not showing the numbers for simplicity here) ],; dtype=float32), 'variance_ratio': array([ (not showing the numbers for simplicity here) ],; dtype=float32)}}; With overloaded keys:; 	['neighbors'].; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239#issuecomment-1319791016
https://github.com/scverse/scanpy/issues/2239#issuecomment-1319791016:507,Usability,simpl,simplicity,507,"Trying out the tutorials these days and it seems this issue still persists. ---; Here is what I got from running the tutorial `pbmc3k.ipynb`:; Before writing the `AnnData` object to a `.h5ad` file (after the PCA step; before computing the neighborhood graph); - Inside `adata.uns`:; ```; OverloadedDict, wrapping:; 	OrderedDict([('log1p', {'base': None}), ('hvg', {'flavor': 'seurat'}), ('pca', {'params': {'zero_center': True, 'use_highly_variable': True}, 'variance': array([ (not showing the numbers for simplicity here) ],; dtype=float32), 'variance_ratio': array([ (not showing the numbers for simplicity here) ],; dtype=float32)})]); With overloaded keys:; 	['neighbors'].; ```. ---; After loading the matrix from the `.h5ad` file:; - Inside `adata.uns`, the `log1p` key became an empty dictionary:; ```; OverloadedDict, wrapping:; 	{'hvg': {'flavor': 'seurat'}, 'log1p': {}, 'pca': {'params': {'use_highly_variable': True, 'zero_center': True}, 'variance': array([ (not showing the numbers for simplicity here) ],; dtype=float32), 'variance_ratio': array([ (not showing the numbers for simplicity here) ],; dtype=float32)}}; With overloaded keys:; 	['neighbors'].; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239#issuecomment-1319791016
https://github.com/scverse/scanpy/issues/2239#issuecomment-1319791016:599,Usability,simpl,simplicity,599,"Trying out the tutorials these days and it seems this issue still persists. ---; Here is what I got from running the tutorial `pbmc3k.ipynb`:; Before writing the `AnnData` object to a `.h5ad` file (after the PCA step; before computing the neighborhood graph); - Inside `adata.uns`:; ```; OverloadedDict, wrapping:; 	OrderedDict([('log1p', {'base': None}), ('hvg', {'flavor': 'seurat'}), ('pca', {'params': {'zero_center': True, 'use_highly_variable': True}, 'variance': array([ (not showing the numbers for simplicity here) ],; dtype=float32), 'variance_ratio': array([ (not showing the numbers for simplicity here) ],; dtype=float32)})]); With overloaded keys:; 	['neighbors'].; ```. ---; After loading the matrix from the `.h5ad` file:; - Inside `adata.uns`, the `log1p` key became an empty dictionary:; ```; OverloadedDict, wrapping:; 	{'hvg': {'flavor': 'seurat'}, 'log1p': {}, 'pca': {'params': {'use_highly_variable': True, 'zero_center': True}, 'variance': array([ (not showing the numbers for simplicity here) ],; dtype=float32), 'variance_ratio': array([ (not showing the numbers for simplicity here) ],; dtype=float32)}}; With overloaded keys:; 	['neighbors'].; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239#issuecomment-1319791016
https://github.com/scverse/scanpy/issues/2239#issuecomment-1319791016:1001,Usability,simpl,simplicity,1001,"Trying out the tutorials these days and it seems this issue still persists. ---; Here is what I got from running the tutorial `pbmc3k.ipynb`:; Before writing the `AnnData` object to a `.h5ad` file (after the PCA step; before computing the neighborhood graph); - Inside `adata.uns`:; ```; OverloadedDict, wrapping:; 	OrderedDict([('log1p', {'base': None}), ('hvg', {'flavor': 'seurat'}), ('pca', {'params': {'zero_center': True, 'use_highly_variable': True}, 'variance': array([ (not showing the numbers for simplicity here) ],; dtype=float32), 'variance_ratio': array([ (not showing the numbers for simplicity here) ],; dtype=float32)})]); With overloaded keys:; 	['neighbors'].; ```. ---; After loading the matrix from the `.h5ad` file:; - Inside `adata.uns`, the `log1p` key became an empty dictionary:; ```; OverloadedDict, wrapping:; 	{'hvg': {'flavor': 'seurat'}, 'log1p': {}, 'pca': {'params': {'use_highly_variable': True, 'zero_center': True}, 'variance': array([ (not showing the numbers for simplicity here) ],; dtype=float32), 'variance_ratio': array([ (not showing the numbers for simplicity here) ],; dtype=float32)}}; With overloaded keys:; 	['neighbors'].; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239#issuecomment-1319791016
https://github.com/scverse/scanpy/issues/2239#issuecomment-1319791016:1093,Usability,simpl,simplicity,1093,"Trying out the tutorials these days and it seems this issue still persists. ---; Here is what I got from running the tutorial `pbmc3k.ipynb`:; Before writing the `AnnData` object to a `.h5ad` file (after the PCA step; before computing the neighborhood graph); - Inside `adata.uns`:; ```; OverloadedDict, wrapping:; 	OrderedDict([('log1p', {'base': None}), ('hvg', {'flavor': 'seurat'}), ('pca', {'params': {'zero_center': True, 'use_highly_variable': True}, 'variance': array([ (not showing the numbers for simplicity here) ],; dtype=float32), 'variance_ratio': array([ (not showing the numbers for simplicity here) ],; dtype=float32)})]); With overloaded keys:; 	['neighbors'].; ```. ---; After loading the matrix from the `.h5ad` file:; - Inside `adata.uns`, the `log1p` key became an empty dictionary:; ```; OverloadedDict, wrapping:; 	{'hvg': {'flavor': 'seurat'}, 'log1p': {}, 'pca': {'params': {'use_highly_variable': True, 'zero_center': True}, 'variance': array([ (not showing the numbers for simplicity here) ],; dtype=float32), 'variance_ratio': array([ (not showing the numbers for simplicity here) ],; dtype=float32)}}; With overloaded keys:; 	['neighbors'].; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239#issuecomment-1319791016
https://github.com/scverse/scanpy/issues/2239#issuecomment-1338287283:134,Testability,log,logfoldchange,134,"Although `adata.uns['log1p'][""base""] = None` seems work for `tl.rank_genes_groups` the results is weird in my analysis. When I check, logfoldchange, values didn't make any sense. Some of them are almost near 100. Is there any case also or maybe I'm wrong.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239#issuecomment-1338287283
https://github.com/scverse/scanpy/issues/2239#issuecomment-1414959276:60,Availability,error,error,60,"Same here. adata.uns['log1p'][""base""] = None eliminated the error, but the FC seems weird. ; I compared the FC results with Seurat FindMarker results, which used the same FC calcualtion. For most genes, Scanpy resulted in much higher FC (some gets 30 or more), which I have never seen.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239#issuecomment-1414959276
https://github.com/scverse/scanpy/issues/2239#issuecomment-1539132164:5,Availability,error,error,5,Same error here.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239#issuecomment-1539132164
https://github.com/scverse/scanpy/pull/2241#issuecomment-1104534706:327,Availability,error,error-reference,327,# [Codecov](https://codecov.io/gh/scverse/scanpy/pull/2241?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`master@cab9f78`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #2241 +/- ##; =========================================; Coverage ? 71.74% ; =========================================; Files ? 99 ; Lines ? 11560 ; Branches ? 0 ; =========================================; Hits ? 8294 ; Misses ? 3266 ; Partials ? 0 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2241#issuecomment-1104534706
https://github.com/scverse/scanpy/pull/2241#issuecomment-1104534706:275,Usability,learn,learn,275,# [Codecov](https://codecov.io/gh/scverse/scanpy/pull/2241?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`master@cab9f78`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #2241 +/- ##; =========================================; Coverage ? 71.74% ; =========================================; Files ? 99 ; Lines ? 11560 ; Branches ? 0 ; =========================================; Hits ? 8294 ; Misses ? 3266 ; Partials ? 0 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2241#issuecomment-1104534706
https://github.com/scverse/scanpy/pull/2241#issuecomment-1105162468:50,Deployability,Update,Update,50,"Hi,. thank you for your PR. Could you please:; 1. Update the body of your PR to introduce and explain what, why and if required how you are doing things.; 2. Why do you think that the volcano plot should go into external? It could go into our core plotting functions, no?; 3. Please try to hardcode as few things as possible. Also, please use the scanpy settings object for plots (e.g. the figure size)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2241#issuecomment-1105162468
https://github.com/scverse/scanpy/issues/2242#issuecomment-1256969218:47,Modifiability,variab,variable,47,"Hi Shamini,. Have you tried running the highly variable genes function on the non-log-transformed, non-normalised counts? You want to use raw counts, see the documentation:; `Expects logarithmized data, except when flavor='seurat_v3', in which count data is expected.`; The numbers in your count matrix are too large at some point in the hvg calculation, might be solved by passing it the data in the correct format!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2242#issuecomment-1256969218
https://github.com/scverse/scanpy/issues/2242#issuecomment-1256969218:82,Testability,log,log-transformed,82,"Hi Shamini,. Have you tried running the highly variable genes function on the non-log-transformed, non-normalised counts? You want to use raw counts, see the documentation:; `Expects logarithmized data, except when flavor='seurat_v3', in which count data is expected.`; The numbers in your count matrix are too large at some point in the hvg calculation, might be solved by passing it the data in the correct format!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2242#issuecomment-1256969218
https://github.com/scverse/scanpy/issues/2242#issuecomment-1256969218:183,Testability,log,logarithmized,183,"Hi Shamini,. Have you tried running the highly variable genes function on the non-log-transformed, non-normalised counts? You want to use raw counts, see the documentation:; `Expects logarithmized data, except when flavor='seurat_v3', in which count data is expected.`; The numbers in your count matrix are too large at some point in the hvg calculation, might be solved by passing it the data in the correct format!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2242#issuecomment-1256969218
https://github.com/scverse/scanpy/issues/2246#issuecomment-1112677198:138,Modifiability,refactor,refactor,138,It seems like `_read_legacy_10x_h5()` invokes ` _collect_datasets()` without taking `genome` into account? Perhaps this was lost during a refactor?; https://github.com/scverse/scanpy/blob/bd06cc3d1e0bd990f6994e54414512fa0b25fea0/scanpy/readwrite.py#L222,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246#issuecomment-1112677198
https://github.com/scverse/scanpy/issues/2246#issuecomment-1114962170:139,Testability,test,tests,139,"Yes, I think line 222 should be . ```python; _collect_datasets(dsets, f[genome]); ```. I will make a PR, and I will try to add a couple of tests to highlight this issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246#issuecomment-1114962170
https://github.com/scverse/scanpy/issues/2246#issuecomment-1196871672:179,Deployability,release,release,179,"@ivirshup or @flying-sheep or any other active maintainers, if you get a chance, could you consider the associated PR for this issue? It'd be great to have this fixed in a future release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246#issuecomment-1196871672
https://github.com/scverse/scanpy/issues/2246#issuecomment-1247444051:190,Availability,error,error-in-scanpy-,190,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error ; **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again ; **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246#issuecomment-1247444051
https://github.com/scverse/scanpy/issues/2246#issuecomment-1247444051:384,Availability,error,error,384,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error ; **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again ; **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246#issuecomment-1247444051
https://github.com/scverse/scanpy/issues/2246#issuecomment-1247444051:516,Availability,Avail,Available,516,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error ; **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again ; **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246#issuecomment-1247444051
https://github.com/scverse/scanpy/issues/2246#issuecomment-1247444051:680,Availability,avail,available,680,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error ; **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again ; **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246#issuecomment-1247444051
https://github.com/scverse/scanpy/issues/2246#issuecomment-1247444051:799,Availability,error,error,799,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error ; **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again ; **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246#issuecomment-1247444051
https://github.com/scverse/scanpy/issues/2246#issuecomment-1247444051:871,Availability,Avail,Available,871,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error ; **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again ; **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246#issuecomment-1247444051
https://github.com/scverse/scanpy/issues/2246#issuecomment-1247444051:995,Availability,error,error,995,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error ; **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again ; **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246#issuecomment-1247444051
https://github.com/scverse/scanpy/issues/2246#issuecomment-1247444051:546,Modifiability,layers,layers,546,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error ; **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again ; **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246#issuecomment-1247444051
https://github.com/scverse/scanpy/issues/2246#issuecomment-1247444051:901,Modifiability,layers,layers,901,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error ; **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again ; **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246#issuecomment-1247444051
https://github.com/scverse/scanpy/issues/2246#issuecomment-1247444051:63,Performance,load,load,63,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error ; **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again ; **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246#issuecomment-1247444051
https://github.com/scverse/scanpy/issues/2246#issuecomment-1247444051:394,Testability,test,test,394,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error ; **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again ; **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246#issuecomment-1247444051
https://github.com/scverse/scanpy/issues/2246#issuecomment-1247444051:739,Testability,test,test,739,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error ; **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again ; **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246#issuecomment-1247444051
https://github.com/scverse/scanpy/issues/2246#issuecomment-1247444051:763,Testability,test,test,763,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error ; **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again ; **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246#issuecomment-1247444051
https://github.com/scverse/scanpy/issues/2246#issuecomment-1247444051:859,Testability,test,test,859,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error ; **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again ; **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246#issuecomment-1247444051
https://github.com/scverse/scanpy/issues/2246#issuecomment-1255636170:89,Performance,load,load,89,"@karenlawwc ; For the test.h5ad that you’ve saved using adata.write, I think you want to load it with sc.read_h5ad() rather than sc.read_10x_h5(), since the saved test file will be in AnnData h5ad format",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246#issuecomment-1255636170
https://github.com/scverse/scanpy/issues/2246#issuecomment-1255636170:22,Testability,test,test,22,"@karenlawwc ; For the test.h5ad that you’ve saved using adata.write, I think you want to load it with sc.read_h5ad() rather than sc.read_10x_h5(), since the saved test file will be in AnnData h5ad format",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246#issuecomment-1255636170
https://github.com/scverse/scanpy/issues/2246#issuecomment-1255636170:163,Testability,test,test,163,"@karenlawwc ; For the test.h5ad that you’ve saved using adata.write, I think you want to load it with sc.read_h5ad() rather than sc.read_10x_h5(), since the saved test file will be in AnnData h5ad format",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246#issuecomment-1255636170
https://github.com/scverse/scanpy/issues/2247#issuecomment-1150425238:143,Testability,log,log,143,"The `tl.rank_genes_groups` function already sorts genes by their statistic score from greatest to smallest. ; If you want to sort the genes by log fold change from greatest to smallest, you can get the pandas dataframe of genes for each group and sort them using pandas function.; ```python; df = sc.get.rank_genes_groups_df(adata, group=""1""); df_sorted = df.sort_values('logfoldchanges', ascending=False); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2247#issuecomment-1150425238
https://github.com/scverse/scanpy/issues/2247#issuecomment-1150425238:372,Testability,log,logfoldchanges,372,"The `tl.rank_genes_groups` function already sorts genes by their statistic score from greatest to smallest. ; If you want to sort the genes by log fold change from greatest to smallest, you can get the pandas dataframe of genes for each group and sort them using pandas function.; ```python; df = sc.get.rank_genes_groups_df(adata, group=""1""); df_sorted = df.sort_values('logfoldchanges', ascending=False); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2247#issuecomment-1150425238
https://github.com/scverse/scanpy/pull/2248#issuecomment-1127793416:21,Performance,load,load,21,"Cool ! ; in order to load legacy h5, I had to freeze scanpy==1.8.2; now I included this fix in a scanpy fork. I hope it gets merged soon",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2248#issuecomment-1127793416
https://github.com/scverse/scanpy/issues/2250#issuecomment-1125580441:383,Availability,error,error,383,"```py; adata = sc.datasets.pbmc68k_reduced(); markers = ['C1QA', 'PSAP', 'CD79A', 'CD79B', 'CST3', 'LYZ']; categories_order=['0','1','9','8','2','5','4','7','3','6','10']; sc.pl.tracksplot(adata,markers,groupby='louvain',vmax=3,categories_order=categories_order); ```. no mattet what the ""categories_order"" is, there is no work on the order of the label.Even the categories_order is error, such as categories_order = ['a','b','c','d'], the figure can not do anything on the order of the labels",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2250#issuecomment-1125580441
https://github.com/scverse/scanpy/issues/2252#issuecomment-1249576288:261,Availability,ping,ping,261,"hi @MertDemirdizen @sophieRAIBAUD ; sorry for late reply. This type of functionality is planned to be added to squidpy (there is an issue also there discussing the same). I'd close this here since the scanpy spatial plot will be deprecated, feel free to reopen/ping me in the squidpy repo directly",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2252#issuecomment-1249576288
https://github.com/scverse/scanpy/pull/2255#issuecomment-1134725267:14,Deployability,Pipeline,Pipelines,14,<samp>; Azure Pipelines successfully started running 1 pipeline(s).<br>. </samp>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2255#issuecomment-1134725267
https://github.com/scverse/scanpy/pull/2255#issuecomment-1134725267:55,Deployability,pipeline,pipeline,55,<samp>; Azure Pipelines successfully started running 1 pipeline(s).<br>. </samp>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2255#issuecomment-1134725267
https://github.com/scverse/scanpy/pull/2255#issuecomment-1134725877:29,Deployability,release,release,29,"@Koncopd, there was a bugged release of pip. I think this should work now that there has been a bugfix",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2255#issuecomment-1134725877
https://github.com/scverse/scanpy/pull/2255#issuecomment-1143708886:38,Testability,test,test,38,@giovp Could you check why the visium test fails? I don't think it is related to this PR.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2255#issuecomment-1143708886
https://github.com/scverse/scanpy/pull/2255#issuecomment-1143800266:27,Availability,toler,tolerance,27,"ah it seems a really minor tolerance thingy, try to increase it to 16 should be fine; ```; save_and_compare_images = image_comparer(ROOT, FIGS, tol=15); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2255#issuecomment-1143800266
https://github.com/scverse/scanpy/pull/2255#issuecomment-1144683493:14,Deployability,Pipeline,Pipelines,14,<samp>; Azure Pipelines successfully started running 1 pipeline(s).<br>. </samp>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2255#issuecomment-1144683493
https://github.com/scverse/scanpy/pull/2255#issuecomment-1144683493:55,Deployability,pipeline,pipeline,55,<samp>; Azure Pipelines successfully started running 1 pipeline(s).<br>. </samp>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2255#issuecomment-1144683493
https://github.com/scverse/scanpy/issues/2256#issuecomment-1131777861:83,Availability,error,error,83,"I am also currently trying to figure out how to get around this. I am getting this error when calling `sc.pl.rank_genes_groups_violin` using a ""gene_symbols"" parameter (this function works when that parameter is omitted but the x-axis labels are not what I desire). In my case, `adata.uns[""rank_genes_groups""][""names""]` content is set to `adata.var_names` (where the index column is separate from what is being passed to the ""gene_symbols"" parameter outlined earlier). I am running anndata==0.7.8 and scanpy==1.8.2 so this issue has been around for a couple release versions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2256#issuecomment-1131777861
https://github.com/scverse/scanpy/issues/2256#issuecomment-1131777861:558,Deployability,release,release,558,"I am also currently trying to figure out how to get around this. I am getting this error when calling `sc.pl.rank_genes_groups_violin` using a ""gene_symbols"" parameter (this function works when that parameter is omitted but the x-axis labels are not what I desire). In my case, `adata.uns[""rank_genes_groups""][""names""]` content is set to `adata.var_names` (where the index column is separate from what is being passed to the ""gene_symbols"" parameter outlined earlier). I am running anndata==0.7.8 and scanpy==1.8.2 so this issue has been around for a couple release versions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2256#issuecomment-1131777861
https://github.com/scverse/scanpy/issues/2258#issuecomment-1625573706:1802,Availability,down,downstream,1802,"Since I saw this just linked to another issue (#2540), I'll post my updates and ways I got around this (since I had to re-investigate this last week for a separate script). We have not updated our Scanpy on our platform since I posted this ticket (though will soon), but I ran into another situation where the code worked on an older version of scanpy but not on a later version which was running on my machine. I just wrote a try/except block to handle this. ```python3; """"""; One of the scanpy versions introduced a bug that was recently fixed, ; where pl.rank_genes_groups works but not pl.rank_genes_groups_<plot>. ; I believe it is because adata.var.index is being stored as the ; adata.uns ""gene_symbol"" output for tl.rank_genes_groups, ; and pl.rank_genes_groups correctly looks for the adata.var.index, ; but pl.rank_genes_groups_<plot> is erroneously looking for the adata.var.gene_symbol there instead (per my supplied ""gene_symbols"" arg). Seems to work in scanpy 1.7.2 but is broke in 1.8.2; """""". ax = sc.pl.rank_genes_groups(adata, groups=[query_cluster],; gene_symbols='gene_symbol', n_genes=n_genes, save=""_comp_ranked.png""). try:; # Try 1.7.2 way first; ax = sc.pl.rank_genes_groups_violin(adata, groups=query_cluster, use_raw = False,; gene_symbols=""gene_symbol"", n_genes=n_genes, save=""_comp_violin.png""); except:; # Use gene names if that doesn't work; gene_names = adata.var.loc[adata.uns[""rank_genes_groups""]['names'][query_cluster]][""gene_symbol""][:n_genes].tolist(); ax = sc.pl.rank_genes_groups_violin(adata, groups=query_cluster, use_raw = False,; gene_symbols=""gene_symbol"", gene_names=gene_names, save=""_comp_violin.png""). ```. Earlier, I had mentioned using `use_raw=True` for the previous script I had this issue with, but ultimately removed that parameter due to some other downstream things",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2258#issuecomment-1625573706
https://github.com/scverse/scanpy/issues/2258#issuecomment-1625573706:68,Deployability,update,updates,68,"Since I saw this just linked to another issue (#2540), I'll post my updates and ways I got around this (since I had to re-investigate this last week for a separate script). We have not updated our Scanpy on our platform since I posted this ticket (though will soon), but I ran into another situation where the code worked on an older version of scanpy but not on a later version which was running on my machine. I just wrote a try/except block to handle this. ```python3; """"""; One of the scanpy versions introduced a bug that was recently fixed, ; where pl.rank_genes_groups works but not pl.rank_genes_groups_<plot>. ; I believe it is because adata.var.index is being stored as the ; adata.uns ""gene_symbol"" output for tl.rank_genes_groups, ; and pl.rank_genes_groups correctly looks for the adata.var.index, ; but pl.rank_genes_groups_<plot> is erroneously looking for the adata.var.gene_symbol there instead (per my supplied ""gene_symbols"" arg). Seems to work in scanpy 1.7.2 but is broke in 1.8.2; """""". ax = sc.pl.rank_genes_groups(adata, groups=[query_cluster],; gene_symbols='gene_symbol', n_genes=n_genes, save=""_comp_ranked.png""). try:; # Try 1.7.2 way first; ax = sc.pl.rank_genes_groups_violin(adata, groups=query_cluster, use_raw = False,; gene_symbols=""gene_symbol"", n_genes=n_genes, save=""_comp_violin.png""); except:; # Use gene names if that doesn't work; gene_names = adata.var.loc[adata.uns[""rank_genes_groups""]['names'][query_cluster]][""gene_symbol""][:n_genes].tolist(); ax = sc.pl.rank_genes_groups_violin(adata, groups=query_cluster, use_raw = False,; gene_symbols=""gene_symbol"", gene_names=gene_names, save=""_comp_violin.png""). ```. Earlier, I had mentioned using `use_raw=True` for the previous script I had this issue with, but ultimately removed that parameter due to some other downstream things",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2258#issuecomment-1625573706
https://github.com/scverse/scanpy/issues/2258#issuecomment-1625573706:185,Deployability,update,updated,185,"Since I saw this just linked to another issue (#2540), I'll post my updates and ways I got around this (since I had to re-investigate this last week for a separate script). We have not updated our Scanpy on our platform since I posted this ticket (though will soon), but I ran into another situation where the code worked on an older version of scanpy but not on a later version which was running on my machine. I just wrote a try/except block to handle this. ```python3; """"""; One of the scanpy versions introduced a bug that was recently fixed, ; where pl.rank_genes_groups works but not pl.rank_genes_groups_<plot>. ; I believe it is because adata.var.index is being stored as the ; adata.uns ""gene_symbol"" output for tl.rank_genes_groups, ; and pl.rank_genes_groups correctly looks for the adata.var.index, ; but pl.rank_genes_groups_<plot> is erroneously looking for the adata.var.gene_symbol there instead (per my supplied ""gene_symbols"" arg). Seems to work in scanpy 1.7.2 but is broke in 1.8.2; """""". ax = sc.pl.rank_genes_groups(adata, groups=[query_cluster],; gene_symbols='gene_symbol', n_genes=n_genes, save=""_comp_ranked.png""). try:; # Try 1.7.2 way first; ax = sc.pl.rank_genes_groups_violin(adata, groups=query_cluster, use_raw = False,; gene_symbols=""gene_symbol"", n_genes=n_genes, save=""_comp_violin.png""); except:; # Use gene names if that doesn't work; gene_names = adata.var.loc[adata.uns[""rank_genes_groups""]['names'][query_cluster]][""gene_symbol""][:n_genes].tolist(); ax = sc.pl.rank_genes_groups_violin(adata, groups=query_cluster, use_raw = False,; gene_symbols=""gene_symbol"", gene_names=gene_names, save=""_comp_violin.png""). ```. Earlier, I had mentioned using `use_raw=True` for the previous script I had this issue with, but ultimately removed that parameter due to some other downstream things",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2258#issuecomment-1625573706
https://github.com/scverse/scanpy/issues/2258#issuecomment-1658188074:62,Performance,cache,cache,62,"OK, reproducible with smaller test data:. ```py; adata_file = cache.mkdir(""rank_gene_groups_violin"") / ""test_adata.h5ad""; if not Path(adata_file).exists():; ssl._create_default_https_context = ssl._create_unverified_context; urllib.request.urlretrieve(; ""https://apps-01.i-med.ac.at/resources/tmp/toy_adata.h5ad"", adata_file; ); adata_full = sc.read_h5ad(adata_file); adata = ad.concat([; adata[adata.obs.cell_type == 'Naive CD4+ T cells'][:4, :4],; adata[adata.obs.cell_type == 'Naive CD8+ T cells'][:4, :4],; ], merge='unique'); adata.write(data_path / 't-cells.h5ad'); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2258#issuecomment-1658188074
https://github.com/scverse/scanpy/issues/2258#issuecomment-1658188074:30,Testability,test,test,30,"OK, reproducible with smaller test data:. ```py; adata_file = cache.mkdir(""rank_gene_groups_violin"") / ""test_adata.h5ad""; if not Path(adata_file).exists():; ssl._create_default_https_context = ssl._create_unverified_context; urllib.request.urlretrieve(; ""https://apps-01.i-med.ac.at/resources/tmp/toy_adata.h5ad"", adata_file; ); adata_full = sc.read_h5ad(adata_file); adata = ad.concat([; adata[adata.obs.cell_type == 'Naive CD4+ T cells'][:4, :4],; adata[adata.obs.cell_type == 'Naive CD8+ T cells'][:4, :4],; ], merge='unique'); adata.write(data_path / 't-cells.h5ad'); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2258#issuecomment-1658188074
https://github.com/scverse/scanpy/issues/2259#issuecomment-1133898960:24,Modifiability,extend,extended,24,"Yes, then this could be extended in scanpy. I imagine this would be very useful for reference mapping visualisations.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259#issuecomment-1133898960
https://github.com/scverse/scanpy/issues/2259#issuecomment-1133906744:153,Performance,load,loadings,153,"Indeed, but then I believe UMAP should be derived from gene space and not from PCA. Even if the variance could be decomposed on the same components, the loadings could have opposite sign and UMAP would interpret them as totally different samples",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259#issuecomment-1133906744
https://github.com/scverse/scanpy/issues/2259#issuecomment-1133920985:129,Deployability,integrat,integration,129,"The UMAP (actually neighbours in the current implementation) is already now derived from any embedding the user wants, including integration embedding, so this is not an issue in itself.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259#issuecomment-1133920985
https://github.com/scverse/scanpy/issues/2259#issuecomment-1133920985:129,Integrability,integrat,integration,129,"The UMAP (actually neighbours in the current implementation) is already now derived from any embedding the user wants, including integration embedding, so this is not an issue in itself.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259#issuecomment-1133920985
https://github.com/scverse/scanpy/issues/2259#issuecomment-1133929205:174,Deployability,integrat,integrated,174,"Yep, but still you need data passed to not only have the same dimensionality, you need dimensions to have the same meaning any time you want to project new data. If you have integrated embeddings (such ash X_pca_harmony) those will change every time you add new data. Using genes to fit a initial UMAP will ensure that you can transform new data, provided you have the same genes",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259#issuecomment-1133929205
https://github.com/scverse/scanpy/issues/2259#issuecomment-1133929205:174,Integrability,integrat,integrated,174,"Yep, but still you need data passed to not only have the same dimensionality, you need dimensions to have the same meaning any time you want to project new data. If you have integrated embeddings (such ash X_pca_harmony) those will change every time you add new data. Using genes to fit a initial UMAP will ensure that you can transform new data, provided you have the same genes",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259#issuecomment-1133929205
https://github.com/scverse/scanpy/issues/2259#issuecomment-1134250744:14,Deployability,integrat,integrated,14,"> If you have integrated embeddings (such ash X_pca_harmony) those will change every time you add new data. . This isn't always true though, e.g., if you use scArches or seurat (which also seems to use this umap transform). On the other hand, the umap transform visualization can be quite deceiving. It can be the case that it qualitatively appears to have no batch effects even when there definitely has been no integration/correction.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259#issuecomment-1134250744
https://github.com/scverse/scanpy/issues/2259#issuecomment-1134250744:413,Deployability,integrat,integration,413,"> If you have integrated embeddings (such ash X_pca_harmony) those will change every time you add new data. . This isn't always true though, e.g., if you use scArches or seurat (which also seems to use this umap transform). On the other hand, the umap transform visualization can be quite deceiving. It can be the case that it qualitatively appears to have no batch effects even when there definitely has been no integration/correction.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259#issuecomment-1134250744
https://github.com/scverse/scanpy/issues/2259#issuecomment-1134250744:14,Integrability,integrat,integrated,14,"> If you have integrated embeddings (such ash X_pca_harmony) those will change every time you add new data. . This isn't always true though, e.g., if you use scArches or seurat (which also seems to use this umap transform). On the other hand, the umap transform visualization can be quite deceiving. It can be the case that it qualitatively appears to have no batch effects even when there definitely has been no integration/correction.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259#issuecomment-1134250744
https://github.com/scverse/scanpy/issues/2259#issuecomment-1134250744:413,Integrability,integrat,integration,413,"> If you have integrated embeddings (such ash X_pca_harmony) those will change every time you add new data. . This isn't always true though, e.g., if you use scArches or seurat (which also seems to use this umap transform). On the other hand, the umap transform visualization can be quite deceiving. It can be the case that it qualitatively appears to have no batch effects even when there definitely has been no integration/correction.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259#issuecomment-1134250744
https://github.com/scverse/scanpy/issues/2259#issuecomment-1237340704:308,Availability,avail,available,308,"I think this may be already implemented in https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.ingest.html, however, this function contains extra integration and label transfer steps that are not needed for all applications. It would be great if this could be disentangled to make the umap transform available as a separate function on scanpy umaps. Also, it seems that this function does not use scanpy umap to calculate umap so changes may be needed in how scanpy umap is currently calculated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259#issuecomment-1237340704
https://github.com/scverse/scanpy/issues/2259#issuecomment-1237340704:154,Deployability,integrat,integration,154,"I think this may be already implemented in https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.ingest.html, however, this function contains extra integration and label transfer steps that are not needed for all applications. It would be great if this could be disentangled to make the umap transform available as a separate function on scanpy umaps. Also, it seems that this function does not use scanpy umap to calculate umap so changes may be needed in how scanpy umap is currently calculated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259#issuecomment-1237340704
https://github.com/scverse/scanpy/issues/2259#issuecomment-1237340704:154,Integrability,integrat,integration,154,"I think this may be already implemented in https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.ingest.html, however, this function contains extra integration and label transfer steps that are not needed for all applications. It would be great if this could be disentangled to make the umap transform available as a separate function on scanpy umaps. Also, it seems that this function does not use scanpy umap to calculate umap so changes may be needed in how scanpy umap is currently calculated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259#issuecomment-1237340704
https://github.com/scverse/scanpy/issues/2260#issuecomment-1158039454:105,Usability,learn,learn,105,"> @Zethson, do you think we should move those to scverse?. Do you mean to this page? https://scverse.org/learn/. Or generally all of them? We might require stronger filtering options then because with all tools combined we would have a lot of vignettes. Edit oh wait: I had no idea that we had this scanpy_usage repository. My answer is yes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2260#issuecomment-1158039454
https://github.com/scverse/scanpy/issues/2261#issuecomment-1153040097:39,Modifiability,layers,layers,39,"before normolization, you can do adata.layers['counts']=adata.X.copy() to add the counts of all genes to the layers.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261#issuecomment-1153040097
https://github.com/scverse/scanpy/issues/2261#issuecomment-1153040097:109,Modifiability,layers,layers,109,"before normolization, you can do adata.layers['counts']=adata.X.copy() to add the counts of all genes to the layers.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261#issuecomment-1153040097
https://github.com/scverse/scanpy/issues/2261#issuecomment-1157056525:309,Modifiability,layers,layers,309,"@ivirshup I don't think so, unless there's work towards https://github.com/scverse/anndata/issues/244. To follow the ideas in https://github.com/scverse/anndata/issues/706, seems like the steps would be:. - [ ] add an attribute `._X_layer` to store which layer `.X` references;; - [ ] use `.X` to reference `.layers[._X_layer]`;; - [ ] add `in_layer=` and `out_layer=` arguments to scanpy's `.pp` functions;; - [ ] these functions will also alter `._X_layer`. The second to last point can actually be implemented irrespective of the AnnData change as `in_layer=None` will mean taking `.X`. ; The question is, should we consider changing the defaults right away, e.g. `in_layer=""counts"", out_layer=""lognorm""`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261#issuecomment-1157056525
https://github.com/scverse/scanpy/issues/2261#issuecomment-1157056525:698,Testability,log,lognorm,698,"@ivirshup I don't think so, unless there's work towards https://github.com/scverse/anndata/issues/244. To follow the ideas in https://github.com/scverse/anndata/issues/706, seems like the steps would be:. - [ ] add an attribute `._X_layer` to store which layer `.X` references;; - [ ] use `.X` to reference `.layers[._X_layer]`;; - [ ] add `in_layer=` and `out_layer=` arguments to scanpy's `.pp` functions;; - [ ] these functions will also alter `._X_layer`. The second to last point can actually be implemented irrespective of the AnnData change as `in_layer=None` will mean taking `.X`. ; The question is, should we consider changing the defaults right away, e.g. `in_layer=""counts"", out_layer=""lognorm""`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261#issuecomment-1157056525
https://github.com/scverse/scanpy/issues/2261#issuecomment-1413237366:49,Modifiability,layers,layers,49,Related question - is it necessary to do. `adata.layers['counts']=adata.X.copy()`. or is:. `adata.layers['counts']=adata.X` sufficient?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261#issuecomment-1413237366
https://github.com/scverse/scanpy/issues/2261#issuecomment-1413237366:98,Modifiability,layers,layers,98,Related question - is it necessary to do. `adata.layers['counts']=adata.X.copy()`. or is:. `adata.layers['counts']=adata.X` sufficient?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261#issuecomment-1413237366
https://github.com/scverse/scanpy/issues/2261#issuecomment-1413733462:331,Modifiability,layers,layers,331,"@carmensandoval, there's no implicit copying so one should make a copy explicitly. . Please see the following code for more details:. ```py; import numpy as np; from anndata import AnnData; from jax import random. adata = AnnData(X=np.array(random.normal(random.PRNGKey(0), (100, 10)))). print(id(adata.X)); # => 5393766064. adata.layers[""X""] = adata.X; adata.layers[""X_copy""] = adata.X.copy(). for layer in (""X"", ""X_copy""):; print(f""{layer}: "", id(adata.layers[layer])); # => X: 5393766064; # => X_copy: 5393773552. print(adata.X[0, 0]); # => -1.5721827. adata.X[0, 0] = 0.0; for layer in (""X"", ""X_copy""):; print(f""{layer}: "", adata.layers[layer][0, 0]); # => X: 0.0; # => X_copy: -1.5721827; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261#issuecomment-1413733462
https://github.com/scverse/scanpy/issues/2261#issuecomment-1413733462:360,Modifiability,layers,layers,360,"@carmensandoval, there's no implicit copying so one should make a copy explicitly. . Please see the following code for more details:. ```py; import numpy as np; from anndata import AnnData; from jax import random. adata = AnnData(X=np.array(random.normal(random.PRNGKey(0), (100, 10)))). print(id(adata.X)); # => 5393766064. adata.layers[""X""] = adata.X; adata.layers[""X_copy""] = adata.X.copy(). for layer in (""X"", ""X_copy""):; print(f""{layer}: "", id(adata.layers[layer])); # => X: 5393766064; # => X_copy: 5393773552. print(adata.X[0, 0]); # => -1.5721827. adata.X[0, 0] = 0.0; for layer in (""X"", ""X_copy""):; print(f""{layer}: "", adata.layers[layer][0, 0]); # => X: 0.0; # => X_copy: -1.5721827; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261#issuecomment-1413733462
https://github.com/scverse/scanpy/issues/2261#issuecomment-1413733462:455,Modifiability,layers,layers,455,"@carmensandoval, there's no implicit copying so one should make a copy explicitly. . Please see the following code for more details:. ```py; import numpy as np; from anndata import AnnData; from jax import random. adata = AnnData(X=np.array(random.normal(random.PRNGKey(0), (100, 10)))). print(id(adata.X)); # => 5393766064. adata.layers[""X""] = adata.X; adata.layers[""X_copy""] = adata.X.copy(). for layer in (""X"", ""X_copy""):; print(f""{layer}: "", id(adata.layers[layer])); # => X: 5393766064; # => X_copy: 5393773552. print(adata.X[0, 0]); # => -1.5721827. adata.X[0, 0] = 0.0; for layer in (""X"", ""X_copy""):; print(f""{layer}: "", adata.layers[layer][0, 0]); # => X: 0.0; # => X_copy: -1.5721827; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261#issuecomment-1413733462
https://github.com/scverse/scanpy/issues/2261#issuecomment-1413733462:634,Modifiability,layers,layers,634,"@carmensandoval, there's no implicit copying so one should make a copy explicitly. . Please see the following code for more details:. ```py; import numpy as np; from anndata import AnnData; from jax import random. adata = AnnData(X=np.array(random.normal(random.PRNGKey(0), (100, 10)))). print(id(adata.X)); # => 5393766064. adata.layers[""X""] = adata.X; adata.layers[""X_copy""] = adata.X.copy(). for layer in (""X"", ""X_copy""):; print(f""{layer}: "", id(adata.layers[layer])); # => X: 5393766064; # => X_copy: 5393773552. print(adata.X[0, 0]); # => -1.5721827. adata.X[0, 0] = 0.0; for layer in (""X"", ""X_copy""):; print(f""{layer}: "", adata.layers[layer][0, 0]); # => X: 0.0; # => X_copy: -1.5721827; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261#issuecomment-1413733462
https://github.com/scverse/scanpy/issues/2261#issuecomment-2070663668:34,Availability,down,downstream,34,"So far as I can tell, any further downstream operations also acts on layers... so it is not useful to store raw counts there since they will just be modified with counts normalization, log normalization, etc. Storing things in layers sequentially, I just end up with a bunch of layers that all are identically fully processed rather than preserving the raw-er aspect of the counts matrix. Not sure if this is new behavior but it is super frustrating",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261#issuecomment-2070663668
https://github.com/scverse/scanpy/issues/2261#issuecomment-2070663668:69,Modifiability,layers,layers,69,"So far as I can tell, any further downstream operations also acts on layers... so it is not useful to store raw counts there since they will just be modified with counts normalization, log normalization, etc. Storing things in layers sequentially, I just end up with a bunch of layers that all are identically fully processed rather than preserving the raw-er aspect of the counts matrix. Not sure if this is new behavior but it is super frustrating",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261#issuecomment-2070663668
https://github.com/scverse/scanpy/issues/2261#issuecomment-2070663668:227,Modifiability,layers,layers,227,"So far as I can tell, any further downstream operations also acts on layers... so it is not useful to store raw counts there since they will just be modified with counts normalization, log normalization, etc. Storing things in layers sequentially, I just end up with a bunch of layers that all are identically fully processed rather than preserving the raw-er aspect of the counts matrix. Not sure if this is new behavior but it is super frustrating",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261#issuecomment-2070663668
https://github.com/scverse/scanpy/issues/2261#issuecomment-2070663668:278,Modifiability,layers,layers,278,"So far as I can tell, any further downstream operations also acts on layers... so it is not useful to store raw counts there since they will just be modified with counts normalization, log normalization, etc. Storing things in layers sequentially, I just end up with a bunch of layers that all are identically fully processed rather than preserving the raw-er aspect of the counts matrix. Not sure if this is new behavior but it is super frustrating",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261#issuecomment-2070663668
https://github.com/scverse/scanpy/issues/2261#issuecomment-2070663668:185,Testability,log,log,185,"So far as I can tell, any further downstream operations also acts on layers... so it is not useful to store raw counts there since they will just be modified with counts normalization, log normalization, etc. Storing things in layers sequentially, I just end up with a bunch of layers that all are identically fully processed rather than preserving the raw-er aspect of the counts matrix. Not sure if this is new behavior but it is super frustrating",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261#issuecomment-2070663668
https://github.com/scverse/scanpy/issues/2261#issuecomment-2071131186:229,Integrability,message,message,229,"@cdpolt, is there are specific change (""new behavior"") you're referring to?. > Storing things in layers sequentially, I just end up with a bunch of layers that all are identically fully processed . Would the code in the previous message be helpful to understand why that happens and how to fix that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261#issuecomment-2071131186
https://github.com/scverse/scanpy/issues/2261#issuecomment-2071131186:97,Modifiability,layers,layers,97,"@cdpolt, is there are specific change (""new behavior"") you're referring to?. > Storing things in layers sequentially, I just end up with a bunch of layers that all are identically fully processed . Would the code in the previous message be helpful to understand why that happens and how to fix that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261#issuecomment-2071131186
https://github.com/scverse/scanpy/issues/2261#issuecomment-2071131186:148,Modifiability,layers,layers,148,"@cdpolt, is there are specific change (""new behavior"") you're referring to?. > Storing things in layers sequentially, I just end up with a bunch of layers that all are identically fully processed . Would the code in the previous message be helpful to understand why that happens and how to fix that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261#issuecomment-2071131186
https://github.com/scverse/scanpy/issues/2265#issuecomment-1137289422:2,Deployability,install,installed,2,I installed the latest Scanpy 1.9.1 `conda install -c conda-forge scanpy python-igraph leidenalg`. And the bug was gone!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2265#issuecomment-1137289422
https://github.com/scverse/scanpy/issues/2265#issuecomment-1137289422:43,Deployability,install,install,43,I installed the latest Scanpy 1.9.1 `conda install -c conda-forge scanpy python-igraph leidenalg`. And the bug was gone!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2265#issuecomment-1137289422
https://github.com/scverse/scanpy/pull/2272#issuecomment-1807755523:288,Integrability,message,message,288,"Possible TODO:. - normalize_pearson_residuals_pca. @ivirshup I reverted the change in a6290ee9e0d1baf0e3483118aa552b6f6dcf02c0 where you changed. ```diff; -X_pca = np.zeros((X.shape[0], n_comps), X.dtype); +X_pca = np.zeros((adata_comp.shape[0], n_comps), adata.X.dtype); ```. the commit message is “Fix up pca tests”, but that change doesn’t seem to impact tests and it takes properties from several different object without reasoning.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2272#issuecomment-1807755523
https://github.com/scverse/scanpy/pull/2272#issuecomment-1807755523:311,Testability,test,tests,311,"Possible TODO:. - normalize_pearson_residuals_pca. @ivirshup I reverted the change in a6290ee9e0d1baf0e3483118aa552b6f6dcf02c0 where you changed. ```diff; -X_pca = np.zeros((X.shape[0], n_comps), X.dtype); +X_pca = np.zeros((adata_comp.shape[0], n_comps), adata.X.dtype); ```. the commit message is “Fix up pca tests”, but that change doesn’t seem to impact tests and it takes properties from several different object without reasoning.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2272#issuecomment-1807755523
https://github.com/scverse/scanpy/pull/2272#issuecomment-1807755523:358,Testability,test,tests,358,"Possible TODO:. - normalize_pearson_residuals_pca. @ivirshup I reverted the change in a6290ee9e0d1baf0e3483118aa552b6f6dcf02c0 where you changed. ```diff; -X_pca = np.zeros((X.shape[0], n_comps), X.dtype); +X_pca = np.zeros((adata_comp.shape[0], n_comps), adata.X.dtype); ```. the commit message is “Fix up pca tests”, but that change doesn’t seem to impact tests and it takes properties from several different object without reasoning.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2272#issuecomment-1807755523
https://github.com/scverse/scanpy/pull/2275#issuecomment-1156972689:326,Availability,error,error-reference,326,# [Codecov](https://codecov.io/gh/scverse/scanpy/pull/2275?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@5bcb539`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## 1.9.x #2275 +/- ##; ========================================; Coverage ? 71.82% ; ========================================; Files ? 98 ; Lines ? 11539 ; Branches ? 0 ; ========================================; Hits ? 8288 ; Misses ? 3251 ; Partials ? 0 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2275#issuecomment-1156972689
https://github.com/scverse/scanpy/pull/2275#issuecomment-1156972689:274,Usability,learn,learn,274,# [Codecov](https://codecov.io/gh/scverse/scanpy/pull/2275?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@5bcb539`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## 1.9.x #2275 +/- ##; ========================================; Coverage ? 71.82% ; ========================================; Files ? 98 ; Lines ? 11539 ; Branches ? 0 ; ========================================; Hits ? 8288 ; Misses ? 3251 ; Partials ? 0 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2275#issuecomment-1156972689
https://github.com/scverse/scanpy/pull/2277#issuecomment-1976241426:111,Deployability,hotfix,hotfix,111,"Ran into this today as a coworker wanted to stick a UMAP legend into `lower left` and couldn't. I whipped up a hotfix, which turned out to be exactly the same syntax as you've got going on here, and was on my way to mention it when I found this. Would be nice to see this integrated as the docs imply this is possible, and it seems useful to have on occasion?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2277#issuecomment-1976241426
https://github.com/scverse/scanpy/pull/2277#issuecomment-1976241426:272,Deployability,integrat,integrated,272,"Ran into this today as a coworker wanted to stick a UMAP legend into `lower left` and couldn't. I whipped up a hotfix, which turned out to be exactly the same syntax as you've got going on here, and was on my way to mention it when I found this. Would be nice to see this integrated as the docs imply this is possible, and it seems useful to have on occasion?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2277#issuecomment-1976241426
https://github.com/scverse/scanpy/pull/2277#issuecomment-1976241426:272,Integrability,integrat,integrated,272,"Ran into this today as a coworker wanted to stick a UMAP legend into `lower left` and couldn't. I whipped up a hotfix, which turned out to be exactly the same syntax as you've got going on here, and was on my way to mention it when I found this. Would be nice to see this integrated as the docs imply this is possible, and it seems useful to have on occasion?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2277#issuecomment-1976241426
https://github.com/scverse/scanpy/pull/2279#issuecomment-1157013971:326,Availability,error,error-reference,326,# [Codecov](https://codecov.io/gh/scverse/scanpy/pull/2279?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@4d0d8be`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## 1.9.x #2279 +/- ##; ========================================; Coverage ? 71.82% ; ========================================; Files ? 98 ; Lines ? 11539 ; Branches ? 0 ; ========================================; Hits ? 8288 ; Misses ? 3251 ; Partials ? 0 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2279#issuecomment-1157013971
https://github.com/scverse/scanpy/pull/2279#issuecomment-1157013971:274,Usability,learn,learn,274,# [Codecov](https://codecov.io/gh/scverse/scanpy/pull/2279?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@4d0d8be`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## 1.9.x #2279 +/- ##; ========================================; Coverage ? 71.82% ; ========================================; Files ? 98 ; Lines ? 11539 ; Branches ? 0 ; ========================================; Hits ? 8288 ; Misses ? 3251 ; Partials ? 0 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2279#issuecomment-1157013971
https://github.com/scverse/scanpy/pull/2280#issuecomment-1592923701:24,Testability,test,test,24,I think it just needs a test,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2280#issuecomment-1592923701
https://github.com/scverse/scanpy/issues/2281#issuecomment-1160313163:319,Deployability,install,installed,319,"I'm afraid it's the bioconda CI that generates them. . Switching back to bioconda has another caveat I think: The conda-forge channel is supposed to have a higher channel priority than the bioconda one. AFAIK if a more recent version of scanpy was on bioconda, it would still be the older conda-forge version that gets installed (unless the newer version is requested explicitly)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160313163
https://github.com/scverse/scanpy/issues/2281#issuecomment-1160340283:881,Availability,mainten,maintenance,881,"> it would still be the older conda-forge version that gets installed. This could be overcome by pinning the channel but I agree it could be an issue if not explicitly specified. > Also there is [no mention of singularity in the bioconda docs](https://bioconda.github.io/search.html?q=singularity). This is the Github repo used for all of the automation and is hosted by the Galaxy project:; https://github.com/BioContainers/singularity-build-bot. As others have mentioned here, it would be awesome to have the latest versions of `scanpy` on Bioconda because it is the primary channel for most Bioinformatics tools. This also allows other communities like nf-core to piggy back off their automation to make our lives easier when writing reproducible, standardised workflows. @grst did come up with a couple of workarounds like adding a mulled container with scanpy but that adds a maintenance overhead to keep things up-to-date. How much work would it be to make this happen @ivirshup and would you be willing to help?. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160340283
https://github.com/scverse/scanpy/issues/2281#issuecomment-1160340283:60,Deployability,install,installed,60,"> it would still be the older conda-forge version that gets installed. This could be overcome by pinning the channel but I agree it could be an issue if not explicitly specified. > Also there is [no mention of singularity in the bioconda docs](https://bioconda.github.io/search.html?q=singularity). This is the Github repo used for all of the automation and is hosted by the Galaxy project:; https://github.com/BioContainers/singularity-build-bot. As others have mentioned here, it would be awesome to have the latest versions of `scanpy` on Bioconda because it is the primary channel for most Bioinformatics tools. This also allows other communities like nf-core to piggy back off their automation to make our lives easier when writing reproducible, standardised workflows. @grst did come up with a couple of workarounds like adding a mulled container with scanpy but that adds a maintenance overhead to keep things up-to-date. How much work would it be to make this happen @ivirshup and would you be willing to help?. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160340283
https://github.com/scverse/scanpy/issues/2281#issuecomment-1160442532:519,Deployability,update,updates,519,"If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers) as opposed to [BioContainers/mulled](https://github.com/BioContainers/mulled). This is what I meant by adding a mulled container above and that would go some way to solving the problem because we would be able to get a Docker/Singularity Biocontainer. However, in the long term, it's always nicer if these containers come directly via recipe updates from the Bioconda community. The other alternative is that the package is eventually updated and maintained on Bioconda organically like with most other tools there but that's kinda out of our control unless we add it ourselves. Always makes sense to reach out to the tool developers first! 😎 . > I'm pretty against moving back to bioconda. Curious to know why and if it's something that can be overcome? I did see https://github.com/scverse/scanpy/issues/1169",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160442532
https://github.com/scverse/scanpy/issues/2281#issuecomment-1160442532:612,Deployability,update,updated,612,"If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers) as opposed to [BioContainers/mulled](https://github.com/BioContainers/mulled). This is what I meant by adding a mulled container above and that would go some way to solving the problem because we would be able to get a Docker/Singularity Biocontainer. However, in the long term, it's always nicer if these containers come directly via recipe updates from the Bioconda community. The other alternative is that the package is eventually updated and maintained on Bioconda organically like with most other tools there but that's kinda out of our control unless we add it ourselves. Always makes sense to reach out to the tool developers first! 😎 . > I'm pretty against moving back to bioconda. Curious to know why and if it's something that can be overcome? I did see https://github.com/scverse/scanpy/issues/1169",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160442532
https://github.com/scverse/scanpy/issues/2281#issuecomment-1160555404:1216,Availability,mainten,maintenance,1216,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome?. ### Practically. * The documentation for bioconda has been incomplete and out of date for years.; * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated.; * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*.; * All of our dependencies are on conda-forge; * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160555404
https://github.com/scverse/scanpy/issues/2281#issuecomment-1160555404:489,Deployability,release,release,489,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome?. ### Practically. * The documentation for bioconda has been incomplete and out of date for years.; * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated.; * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*.; * All of our dependencies are on conda-forge; * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160555404
https://github.com/scverse/scanpy/issues/2281#issuecomment-1160555404:512,Deployability,release,release,512,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome?. ### Practically. * The documentation for bioconda has been incomplete and out of date for years.; * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated.; * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*.; * All of our dependencies are on conda-forge; * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160555404
https://github.com/scverse/scanpy/issues/2281#issuecomment-1160555404:1385,Deployability,install,install,1385,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome?. ### Practically. * The documentation for bioconda has been incomplete and out of date for years.; * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated.; * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*.; * All of our dependencies are on conda-forge; * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160555404
https://github.com/scverse/scanpy/issues/2281#issuecomment-1160555404:213,Integrability,depend,dependencies,213,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome?. ### Practically. * The documentation for bioconda has been incomplete and out of date for years.; * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated.; * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*.; * All of our dependencies are on conda-forge; * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160555404
https://github.com/scverse/scanpy/issues/2281#issuecomment-1160555404:573,Integrability,depend,depend,573,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome?. ### Practically. * The documentation for bioconda has been incomplete and out of date for years.; * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated.; * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*.; * All of our dependencies are on conda-forge; * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160555404
https://github.com/scverse/scanpy/issues/2281#issuecomment-1160555404:690,Integrability,depend,dependents,690,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome?. ### Practically. * The documentation for bioconda has been incomplete and out of date for years.; * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated.; * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*.; * All of our dependencies are on conda-forge; * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160555404
https://github.com/scverse/scanpy/issues/2281#issuecomment-1160555404:794,Integrability,depend,dependencies,794,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome?. ### Practically. * The documentation for bioconda has been incomplete and out of date for years.; * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated.; * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*.; * All of our dependencies are on conda-forge; * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160555404
https://github.com/scverse/scanpy/issues/2281#issuecomment-1160555404:1310,Usability,clear,clear,1310,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome?. ### Practically. * The documentation for bioconda has been incomplete and out of date for years.; * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated.; * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*.; * All of our dependencies are on conda-forge; * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160555404
https://github.com/scverse/scanpy/issues/2281#issuecomment-1160565536:220,Integrability,depend,dependencies,220,"> > If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers); >; > We do make heavy use of optional dependencies, so this might be the way to go regardless. Just saw there's already a pr for this! . * BioContainers/multi-package-containers#2209",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160565536
https://github.com/scverse/scanpy/issues/2281#issuecomment-1160571955:502,Availability,down,downside,502,"At this point I'm not a big fan of moving back to bioconda either.; * anndata is not bio-specific and should go to conda-forge anyway; * it's debatable if it was a mistake to move scanpy, but moving it back causes confusion and more harm than good IMO. > Why have separate package registries for biology vs everything else?. probably because bioconda predates conda-forge? . > Just saw there's already a pr for this!; > ; > https://github.com/BioContainers/multi-package-containers/pull/2209. The only downside of this is that we need to update that file manually for every release of scanpy/anndata",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160571955
https://github.com/scverse/scanpy/issues/2281#issuecomment-1160571955:538,Deployability,update,update,538,"At this point I'm not a big fan of moving back to bioconda either.; * anndata is not bio-specific and should go to conda-forge anyway; * it's debatable if it was a mistake to move scanpy, but moving it back causes confusion and more harm than good IMO. > Why have separate package registries for biology vs everything else?. probably because bioconda predates conda-forge? . > Just saw there's already a pr for this!; > ; > https://github.com/BioContainers/multi-package-containers/pull/2209. The only downside of this is that we need to update that file manually for every release of scanpy/anndata",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160571955
https://github.com/scverse/scanpy/issues/2281#issuecomment-1160571955:574,Deployability,release,release,574,"At this point I'm not a big fan of moving back to bioconda either.; * anndata is not bio-specific and should go to conda-forge anyway; * it's debatable if it was a mistake to move scanpy, but moving it back causes confusion and more harm than good IMO. > Why have separate package registries for biology vs everything else?. probably because bioconda predates conda-forge? . > Just saw there's already a pr for this!; > ; > https://github.com/BioContainers/multi-package-containers/pull/2209. The only downside of this is that we need to update that file manually for every release of scanpy/anndata",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160571955
https://github.com/scverse/scanpy/issues/2281#issuecomment-1160598574:345,Availability,down,downside,345,> > Why have separate package registries for biology vs everything else?; >; > probably because bioconda predates conda-forge?. That would make sense! I think things like bioconda and the bioconductor registry were good things to start and have been very important. I just think some of the initial design decisions are now outdated. > The only downside of this is that we need to update that file manually for every release of scanpy/ anndata. Seems github action-able?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160598574
https://github.com/scverse/scanpy/issues/2281#issuecomment-1160598574:381,Deployability,update,update,381,> > Why have separate package registries for biology vs everything else?; >; > probably because bioconda predates conda-forge?. That would make sense! I think things like bioconda and the bioconductor registry were good things to start and have been very important. I just think some of the initial design decisions are now outdated. > The only downside of this is that we need to update that file manually for every release of scanpy/ anndata. Seems github action-able?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160598574
https://github.com/scverse/scanpy/issues/2281#issuecomment-1160598574:417,Deployability,release,release,417,> > Why have separate package registries for biology vs everything else?; >; > probably because bioconda predates conda-forge?. That would make sense! I think things like bioconda and the bioconductor registry were good things to start and have been very important. I just think some of the initial design decisions are now outdated. > The only downside of this is that we need to update that file manually for every release of scanpy/ anndata. Seems github action-able?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160598574
https://github.com/scverse/scanpy/issues/2281#issuecomment-1160759818:215,Deployability,release,release,215,"@bgruening I would be interested to hear your perspective on this, and hear any corrections. Apologies if any comments were unfair. My comments were definitely coloured by painful memories of debugging via CI for a release that just went live – which is always an emotional experience 😅. One thing I was wrong about: bioconda does have autoupdates. For whatever reason, it just looks like the scanpy recipe required a fair bit of manual intervention.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160759818
https://github.com/scverse/scanpy/issues/2281#issuecomment-1160765884:362,Integrability,Message,Message,362,"No worries, feel free to rename :) Monday, 20 June 2022, 09:11PM +02:00 from Isaac Virshup ***@***.*** :. ***@***.*** , would it be fair to retitle this something like ""Generate BioContainer images"", or should that be a separate issue?; >—; >Reply to this email directly, view it on GitHub , or unsubscribe .; >You are receiving this because you were mentioned. Message ID: @ github . com>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160765884
https://github.com/scverse/scanpy/issues/2281#issuecomment-1161394817:901,Deployability,release,release,901,"Out of experience, I don't really feel like conda-forge is much more complicated to maintain - at least didn't feel too bad for me when I added a few recipes there in the past. My concerns are mostly fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda; Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn't",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281#issuecomment-1161394817
https://github.com/scverse/scanpy/issues/2281#issuecomment-1161394817:924,Deployability,release,release,924,"Out of experience, I don't really feel like conda-forge is much more complicated to maintain - at least didn't feel too bad for me when I added a few recipes there in the past. My concerns are mostly fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda; Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn't",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281#issuecomment-1161394817
https://github.com/scverse/scanpy/issues/2281#issuecomment-1161394817:1024,Integrability,depend,depend,1024," is much more complicated to maintain - at least didn't feel too bad for me when I added a few recipes there in the past. My concerns are mostly fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda; Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn't notice that much of a difference between using 1 - 2 c",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281#issuecomment-1161394817
https://github.com/scverse/scanpy/issues/2281#issuecomment-1161394817:1142,Integrability,depend,dependents,1142," past. My concerns are mostly fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda; Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn't notice that much of a difference between using 1 - 2 channels ❓ . And thanks all for the ongoing discussion, still learning things here and also getting new perspective",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281#issuecomment-1161394817
https://github.com/scverse/scanpy/issues/2281#issuecomment-1161394817:1640,Integrability,depend,dependencies,1640,"fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda; Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn't notice that much of a difference between using 1 - 2 channels ❓ . And thanks all for the ongoing discussion, still learning things here and also getting new perspectives on the general topic here 👍🏻",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281#issuecomment-1161394817
https://github.com/scverse/scanpy/issues/2281#issuecomment-1161394817:1930,Integrability,depend,dependencies,1930,"fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda; Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn't notice that much of a difference between using 1 - 2 channels ❓ . And thanks all for the ongoing discussion, still learning things here and also getting new perspectives on the general topic here 👍🏻",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281#issuecomment-1161394817
https://github.com/scverse/scanpy/issues/2281#issuecomment-1161394817:2117,Usability,learn,learning,2117,"fueled by reading passively in the bioconda channel for years now and memorizing this rule of thumb regarding where to put recipes:. Anything bio-specific --> bioconda; Anything else --> conda-forge . If this does not hold true (anymore?), @bgruening , I believe that one could still stay with conda-forge and instead try to maintain own biocontainers (need to check with the folks there if uploading would be fine for them etc pp). . >The documentation for bioconda has been incomplete and out of date for years. It could be better, but most of the points are still valid and with some help from the community recipes are still created fine ;-) . >conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated. Bioconda-bot does the same for you ;-) . >bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on >bioconda all our dependents do too – this could make it extremely painful to do a migration to bioconda. Thats not the case: E.g. when you move `scanpy` over, the libraries that are not bio related, can stay on conda-forge. That way, resolving will work. I am really not sure if the resolving will not take other channels into account, unless there is different versions of packages on various channels, e.g. a library both on conda-forge and bioconda which would then be handled by channel priorities. >All of our dependencies are on conda-forge. Thats the case for the majority of bio tools - most rely on general purpose tools ;-) . >Fewer channels to search means easier, faster environment solving. `mamba` can help you here, at least for most of the conda recipes I have used (some have hundreds of dependencies in total, especially in multi-tool environments), I didn't notice that much of a difference between using 1 - 2 channels ❓ . And thanks all for the ongoing discussion, still learning things here and also getting new perspectives on the general topic here 👍🏻",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281#issuecomment-1161394817
https://github.com/scverse/scanpy/issues/2282#issuecomment-1160766533:17,Deployability,install,installation,17,"As noted in [the installation docs](https://scanpy.readthedocs.io/en/stable/installation.html), scanpy is not distributed via bioconda. It should be installed with `conda install -c conda-forge scanpy`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2282#issuecomment-1160766533
https://github.com/scverse/scanpy/issues/2282#issuecomment-1160766533:76,Deployability,install,installation,76,"As noted in [the installation docs](https://scanpy.readthedocs.io/en/stable/installation.html), scanpy is not distributed via bioconda. It should be installed with `conda install -c conda-forge scanpy`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2282#issuecomment-1160766533
https://github.com/scverse/scanpy/issues/2282#issuecomment-1160766533:149,Deployability,install,installed,149,"As noted in [the installation docs](https://scanpy.readthedocs.io/en/stable/installation.html), scanpy is not distributed via bioconda. It should be installed with `conda install -c conda-forge scanpy`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2282#issuecomment-1160766533
https://github.com/scverse/scanpy/issues/2282#issuecomment-1160766533:171,Deployability,install,install,171,"As noted in [the installation docs](https://scanpy.readthedocs.io/en/stable/installation.html), scanpy is not distributed via bioconda. It should be installed with `conda install -c conda-forge scanpy`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2282#issuecomment-1160766533
https://github.com/scverse/scanpy/pull/2283#issuecomment-1160889115:14,Deployability,Pipeline,Pipelines,14,<samp>; Azure Pipelines successfully started running 1 pipeline(s).<br>. </samp>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2283#issuecomment-1160889115
https://github.com/scverse/scanpy/pull/2283#issuecomment-1160889115:55,Deployability,pipeline,pipeline,55,<samp>; Azure Pipelines successfully started running 1 pipeline(s).<br>. </samp>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2283#issuecomment-1160889115
https://github.com/scverse/scanpy/issues/2286#issuecomment-1265013360:50,Availability,error,error,50,"hi,I wonder if this problem has been solved? This error also occurred recently when I used this code",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2286#issuecomment-1265013360
https://github.com/scverse/scanpy/issues/2286#issuecomment-1973497725:50,Availability,error,error,50,"hi,I wonder if this problem has been solved? This error also occurred recently when I used this code, too.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2286#issuecomment-1973497725
https://github.com/scverse/scanpy/issues/2288#issuecomment-1233188895:33,Availability,ping,ping,33,"Would love to starting November, ping me if thats still relevant",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2288#issuecomment-1233188895
https://github.com/scverse/scanpy/issues/2290#issuecomment-1257082217:701,Performance,load,loading,701,"> You can actually already do this by changing the order of your categorical, e.g.:; > ; > ```python; > adata = sc.datasets.pbmc3k_processed(); > # plot default:; > sc.pl.umap(adata, color=""louvain""); > # reorder categories alphabetically; > adata.obs.louvain = adata.obs.louvain.cat.reorder_categories(; > sorted(adata.obs.louvain.cat.categories); > ); > # plot with new category order:; > sc.pl.umap(adata, color=""louvain""); > ```; > ; > Which gives: <img alt=""Screenshot 2022-09-24 at 19 07 31"" width=""390"" src=""https://user-images.githubusercontent.com/32548783/192110283-af0d14c5-0d79-4ecd-96ff-c079f5743887.png"">. Thanks for your replay. Here, I changed the order of categorical as below:. # 0. loading data; adata = sc.datasets.pbmc3k_processed(); # 1. plot default:; sc.pl.umap(adata, color=""louvain""). # 2. show the default order of categories:; adata.obs['louvain'].cat.categories; # **Index(['CD4 T cells', 'CD14+ Monocytes', 'B cells', 'CD8 T cells', 'NK cells', 'FCGR3A+ Monocytes', 'Dendritic cells', 'Megakaryocytes'], dtype='object')**. # 3. reorder categories as customize; adata.obs['batch_3rd'].cat.reorder_categories(['CD8 T cells', 'CD4 T cells', 'B cells', 'NK cells', 'CD14+ Monocytes', 'FCGR3A+ Monocytes', 'Dendritic cells', 'Megakaryocytes'], inplace=True, ordered=True); adata.obs['batch_3rd'].cat.categories; # **Index(['CD8 T cells', 'CD4 T cells', 'B cells', 'NK cells', 'CD14+ Monocytes', 'FCGR3A+ Monocytes', 'Dendritic cells', 'Megakaryocytes'], dtype='object')**. # 4. plot with new category order:; sc.pl.umap(adata, color=""louvain"")",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2290#issuecomment-1257082217
https://github.com/scverse/scanpy/issues/2290#issuecomment-1257189686:549,Usability,guid,guidance,549,I don't think that `legend_loc` would be the correct parameter. You are not even interacting with it during the example that @LisaSikkema posted (thanks for that btw!). I see two options:; 1. Adding a general statement to the `color` argument stating that reordering the categorical column to color by can customize the legend order; 2. Adding your use-case to the example section in the pl.umap documentation. Leaning more towards the second option. What do you think? Would be great if you could attempt to submit a PR then. Happy to provide some guidance if required.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2290#issuecomment-1257189686
https://github.com/scverse/scanpy/pull/2295#issuecomment-1274299180:389,Availability,error,error,389,"Hi,. The issues I was mostly running into were that when saving the anndata; variable as a h5ad file, 'pheno_jaccard_ig' was not compatible with this; action. So, I had to either remove pheno_jaccard_ig from the anndata object; and then save it as h5ad or convert it to a sparse matrix. This also; happened with a few other functions I tried on the anndata object, and I; kept getting the error ""this function is not compatible with COO matrix; format"", always talking about pheno_jaccard_ig. Therefore, since a sparse; matrix object does not have any problems with the functions I was running; on adata, changing pheno_jaccard_ig to a sparse matrix from the start makes; sense to circumvent any of those issues I was getting before. I hope this makes sense.; Thank you,; Deena Shefter. On Wed, Jul 27, 2022 at 6:10 PM Lukas Heumos ***@***.***>; wrote:. > Hi,; >; > could you please provide more details? What issues did you run into?; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/scverse/scanpy/pull/2295#issuecomment-1197424392>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AMILUOEK7J64GU3YOR7DB53VWGXULANCNFSM534YT5ZA>; > .; > You are receiving this because you authored the thread.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2295#issuecomment-1274299180
https://github.com/scverse/scanpy/pull/2295#issuecomment-1274299180:1249,Integrability,Message,Message,1249,"Hi,. The issues I was mostly running into were that when saving the anndata; variable as a h5ad file, 'pheno_jaccard_ig' was not compatible with this; action. So, I had to either remove pheno_jaccard_ig from the anndata object; and then save it as h5ad or convert it to a sparse matrix. This also; happened with a few other functions I tried on the anndata object, and I; kept getting the error ""this function is not compatible with COO matrix; format"", always talking about pheno_jaccard_ig. Therefore, since a sparse; matrix object does not have any problems with the functions I was running; on adata, changing pheno_jaccard_ig to a sparse matrix from the start makes; sense to circumvent any of those issues I was getting before. I hope this makes sense.; Thank you,; Deena Shefter. On Wed, Jul 27, 2022 at 6:10 PM Lukas Heumos ***@***.***>; wrote:. > Hi,; >; > could you please provide more details? What issues did you run into?; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/scverse/scanpy/pull/2295#issuecomment-1197424392>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AMILUOEK7J64GU3YOR7DB53VWGXULANCNFSM534YT5ZA>; > .; > You are receiving this because you authored the thread.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2295#issuecomment-1274299180
https://github.com/scverse/scanpy/pull/2295#issuecomment-1274299180:77,Modifiability,variab,variable,77,"Hi,. The issues I was mostly running into were that when saving the anndata; variable as a h5ad file, 'pheno_jaccard_ig' was not compatible with this; action. So, I had to either remove pheno_jaccard_ig from the anndata object; and then save it as h5ad or convert it to a sparse matrix. This also; happened with a few other functions I tried on the anndata object, and I; kept getting the error ""this function is not compatible with COO matrix; format"", always talking about pheno_jaccard_ig. Therefore, since a sparse; matrix object does not have any problems with the functions I was running; on adata, changing pheno_jaccard_ig to a sparse matrix from the start makes; sense to circumvent any of those issues I was getting before. I hope this makes sense.; Thank you,; Deena Shefter. On Wed, Jul 27, 2022 at 6:10 PM Lukas Heumos ***@***.***>; wrote:. > Hi,; >; > could you please provide more details? What issues did you run into?; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/scverse/scanpy/pull/2295#issuecomment-1197424392>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AMILUOEK7J64GU3YOR7DB53VWGXULANCNFSM534YT5ZA>; > .; > You are receiving this because you authored the thread.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2295#issuecomment-1274299180
https://github.com/scverse/scanpy/pull/2296#issuecomment-1265541010:337,Deployability,release,release,337,"@giovp looking at this again, it seems you drop the mixed up columns anyway (https://github.com/scverse/squidpy/blob/fb069ded7515e8a1386224d32344a8657cbecd2e/squidpy/read/_read.py#L100) so I'd suggest having one code path with the correct column names. Please let me know if you need more clarity and help getting this over the hump for release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296#issuecomment-1265541010
https://github.com/scverse/scanpy/pull/2296#issuecomment-1272277275:395,Deployability,release,release,395,"> @giovp looking at this again, it seems you drop the mixed up columns anyway ([scverse/squidpy@`fb069de`/squidpy/read/_read.py#L100](https://github.com/scverse/squidpy/blob/fb069ded7515e8a1386224d32344a8657cbecd2e/squidpy/read/_read.py#L100)) so I'd suggest having one code path with the correct column names. Please let me know if you need more clarity and help getting this over the hump for release. Hi @stephenwilliams22 ,. we drop it from obs since we don't want to save spatial coordinates there, cause they should be only in obsm. . So the only changes between space rangers version is the name of the tissue position file correct? but the order of the columns remains the same?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296#issuecomment-1272277275
https://github.com/scverse/scanpy/pull/2296#issuecomment-1272576192:132,Deployability,release,release,132,"> @giovp, should this change happen in scanpy or squidpy?. I would make it happen in both and deprecate this function from the next release (as well as all the other spatial).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296#issuecomment-1272576192
https://github.com/scverse/scanpy/pull/2296#issuecomment-1273309536:397,Deployability,release,release,397,"> > @giovp looking at this again, it seems you drop the mixed up columns anyway ([scverse/squidpy@`fb069de`/squidpy/read/_read.py#L100](https://github.com/scverse/squidpy/blob/fb069ded7515e8a1386224d32344a8657cbecd2e/squidpy/read/_read.py#L100)) so I'd suggest having one code path with the correct column names. Please let me know if you need more clarity and help getting this over the hump for release.; > ; > Hi @stephenwilliams22 ,; > ; > we drop it from obs since we don't want to save spatial coordinates there, cause they should be only in obsm.; > ; > So the only changes between space rangers version is the name of the tissue position file correct? but the order of the columns remains the same?. Yes, this is correct.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296#issuecomment-1273309536
https://github.com/scverse/scanpy/pull/2296#issuecomment-1314154765:21,Deployability,update,update,21,@giovp do we have an update on merging this yet? Anything left on my end?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296#issuecomment-1314154765
https://github.com/scverse/scanpy/pull/2296#issuecomment-1433124648:79,Testability,test,tests,79,"@giovp, @stephenwilliams22, @Zethson. This PR seems to have broken a number of tests. I believe due to the change in `pixel_row`/ `pixel_col` order, resulting in a number of test plots now being transposed. If this was always wrong... surely usage would have caught that, so we must be correcting for this somewhere else. What's the correction here? And is it something that should be done quickly, or should I revert this PR until we can figure it out?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296#issuecomment-1433124648
https://github.com/scverse/scanpy/pull/2296#issuecomment-1433124648:174,Testability,test,test,174,"@giovp, @stephenwilliams22, @Zethson. This PR seems to have broken a number of tests. I believe due to the change in `pixel_row`/ `pixel_col` order, resulting in a number of test plots now being transposed. If this was always wrong... surely usage would have caught that, so we must be correcting for this somewhere else. What's the correction here? And is it something that should be done quickly, or should I revert this PR until we can figure it out?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296#issuecomment-1433124648
https://github.com/scverse/scanpy/issues/2297#issuecomment-1372320558:22,Availability,error,error,22,Encountering the same error. Updating h5py did not seem to help. Any advice on this?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-1372320558
https://github.com/scverse/scanpy/issues/2297#issuecomment-1434409733:39,Deployability,update,update,39,I was having the same problem. **conda update anndata** solved my problem.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-1434409733
https://github.com/scverse/scanpy/issues/2297#issuecomment-1435771153:24,Availability,error,error,24,> Encountering the same error. Updating h5py did not seem to help. Any advice on this?. This might be useful to you:; https://github.com/scverse/scanpy/issues/1351#issuecomment-1198015945,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-1435771153
https://github.com/scverse/scanpy/issues/2297#issuecomment-1447928394:137,Availability,error,error,137,@brianpenghe Hi may I consult how you resolved the problem?. The comment says upgrade anndata to 0.8.0 but mine already is 0.8.0 and the error message remains.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-1447928394
https://github.com/scverse/scanpy/issues/2297#issuecomment-1447928394:78,Deployability,upgrade,upgrade,78,@brianpenghe Hi may I consult how you resolved the problem?. The comment says upgrade anndata to 0.8.0 but mine already is 0.8.0 and the error message remains.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-1447928394
https://github.com/scverse/scanpy/issues/2297#issuecomment-1447928394:143,Integrability,message,message,143,@brianpenghe Hi may I consult how you resolved the problem?. The comment says upgrade anndata to 0.8.0 but mine already is 0.8.0 and the error message remains.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-1447928394
https://github.com/scverse/scanpy/issues/2297#issuecomment-1450229185:9,Availability,reboot,rebooted,9,"Have you rebooted the python after updating anndata? Can you paste the exact error you're seeing? Are you allowed to share the object you're having trouble loading?. OP's error is bizarre, e.g. the last part seems to be pointing to an empty line. Like the package was updated but the python was not restarted. I can't recreate the exact one he's seeing, but I've managed to get other disjoint errors along those lines by updating anndata to 0.8.0 in a second terminal while the python in question is still running.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-1450229185
https://github.com/scverse/scanpy/issues/2297#issuecomment-1450229185:77,Availability,error,error,77,"Have you rebooted the python after updating anndata? Can you paste the exact error you're seeing? Are you allowed to share the object you're having trouble loading?. OP's error is bizarre, e.g. the last part seems to be pointing to an empty line. Like the package was updated but the python was not restarted. I can't recreate the exact one he's seeing, but I've managed to get other disjoint errors along those lines by updating anndata to 0.8.0 in a second terminal while the python in question is still running.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-1450229185
https://github.com/scverse/scanpy/issues/2297#issuecomment-1450229185:171,Availability,error,error,171,"Have you rebooted the python after updating anndata? Can you paste the exact error you're seeing? Are you allowed to share the object you're having trouble loading?. OP's error is bizarre, e.g. the last part seems to be pointing to an empty line. Like the package was updated but the python was not restarted. I can't recreate the exact one he's seeing, but I've managed to get other disjoint errors along those lines by updating anndata to 0.8.0 in a second terminal while the python in question is still running.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-1450229185
https://github.com/scverse/scanpy/issues/2297#issuecomment-1450229185:393,Availability,error,errors,393,"Have you rebooted the python after updating anndata? Can you paste the exact error you're seeing? Are you allowed to share the object you're having trouble loading?. OP's error is bizarre, e.g. the last part seems to be pointing to an empty line. Like the package was updated but the python was not restarted. I can't recreate the exact one he's seeing, but I've managed to get other disjoint errors along those lines by updating anndata to 0.8.0 in a second terminal while the python in question is still running.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-1450229185
https://github.com/scverse/scanpy/issues/2297#issuecomment-1450229185:268,Deployability,update,updated,268,"Have you rebooted the python after updating anndata? Can you paste the exact error you're seeing? Are you allowed to share the object you're having trouble loading?. OP's error is bizarre, e.g. the last part seems to be pointing to an empty line. Like the package was updated but the python was not restarted. I can't recreate the exact one he's seeing, but I've managed to get other disjoint errors along those lines by updating anndata to 0.8.0 in a second terminal while the python in question is still running.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-1450229185
https://github.com/scverse/scanpy/issues/2297#issuecomment-1450229185:156,Performance,load,loading,156,"Have you rebooted the python after updating anndata? Can you paste the exact error you're seeing? Are you allowed to share the object you're having trouble loading?. OP's error is bizarre, e.g. the last part seems to be pointing to an empty line. Like the package was updated but the python was not restarted. I can't recreate the exact one he's seeing, but I've managed to get other disjoint errors along those lines by updating anndata to 0.8.0 in a second terminal while the python in question is still running.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-1450229185
https://github.com/scverse/scanpy/issues/2297#issuecomment-1451305928:165,Availability,error,error,165,"@ktpolanski I re-created a new conda env and installed scanpy so now it's working. I'm still not sure where the problem lies, though I did realize it starts jumping error after I install another package called stereopy, I'm guessing maybe that package updated something which got in conflict with normal scanpy setting.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-1451305928
https://github.com/scverse/scanpy/issues/2297#issuecomment-1451305928:45,Deployability,install,installed,45,"@ktpolanski I re-created a new conda env and installed scanpy so now it's working. I'm still not sure where the problem lies, though I did realize it starts jumping error after I install another package called stereopy, I'm guessing maybe that package updated something which got in conflict with normal scanpy setting.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-1451305928
https://github.com/scverse/scanpy/issues/2297#issuecomment-1451305928:179,Deployability,install,install,179,"@ktpolanski I re-created a new conda env and installed scanpy so now it's working. I'm still not sure where the problem lies, though I did realize it starts jumping error after I install another package called stereopy, I'm guessing maybe that package updated something which got in conflict with normal scanpy setting.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-1451305928
https://github.com/scverse/scanpy/issues/2297#issuecomment-1451305928:252,Deployability,update,updated,252,"@ktpolanski I re-created a new conda env and installed scanpy so now it's working. I'm still not sure where the problem lies, though I did realize it starts jumping error after I install another package called stereopy, I'm guessing maybe that package updated something which got in conflict with normal scanpy setting.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-1451305928
https://github.com/scverse/scanpy/issues/2297#issuecomment-1451566540:126,Availability,down,download,126,"@ktpolanski I thought I had the newest anndata version, but turns out 0.8.0 is not in Ubuntu repositiories. I had to manually download and install Python 3.8, anndata 0.8.0 and h5py, now it works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-1451566540
https://github.com/scverse/scanpy/issues/2297#issuecomment-1451566540:139,Deployability,install,install,139,"@ktpolanski I thought I had the newest anndata version, but turns out 0.8.0 is not in Ubuntu repositiories. I had to manually download and install Python 3.8, anndata 0.8.0 and h5py, now it works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-1451566540
https://github.com/scverse/scanpy/issues/2297#issuecomment-1452144253:167,Availability,error,error,167,"> @ktpolanski I re-created a new conda env and installed scanpy so now it's working. I'm still not sure where the problem lies, though I did realize it starts jumping error after I install another package called stereopy, I'm guessing maybe that package updated something which got in conflict with normal scanpy setting. https://github.com/BGIResearch/stereopy/blob/6345d2732772a58d60351e790058bd5da1301fb5/requirements.txt#L26",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-1452144253
https://github.com/scverse/scanpy/issues/2297#issuecomment-1452144253:47,Deployability,install,installed,47,"> @ktpolanski I re-created a new conda env and installed scanpy so now it's working. I'm still not sure where the problem lies, though I did realize it starts jumping error after I install another package called stereopy, I'm guessing maybe that package updated something which got in conflict with normal scanpy setting. https://github.com/BGIResearch/stereopy/blob/6345d2732772a58d60351e790058bd5da1301fb5/requirements.txt#L26",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-1452144253
https://github.com/scverse/scanpy/issues/2297#issuecomment-1452144253:181,Deployability,install,install,181,"> @ktpolanski I re-created a new conda env and installed scanpy so now it's working. I'm still not sure where the problem lies, though I did realize it starts jumping error after I install another package called stereopy, I'm guessing maybe that package updated something which got in conflict with normal scanpy setting. https://github.com/BGIResearch/stereopy/blob/6345d2732772a58d60351e790058bd5da1301fb5/requirements.txt#L26",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-1452144253
https://github.com/scverse/scanpy/issues/2297#issuecomment-1452144253:254,Deployability,update,updated,254,"> @ktpolanski I re-created a new conda env and installed scanpy so now it's working. I'm still not sure where the problem lies, though I did realize it starts jumping error after I install another package called stereopy, I'm guessing maybe that package updated something which got in conflict with normal scanpy setting. https://github.com/BGIResearch/stereopy/blob/6345d2732772a58d60351e790058bd5da1301fb5/requirements.txt#L26",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-1452144253
https://github.com/scverse/scanpy/issues/2297#issuecomment-1890353810:53,Availability,error,error,53,Seems like this is still an issue. I am getting this error below randomly. It disappears after trying sometime later with the exact code and files... scanpy==1.9.4 anndata==0.9.2 umap==0.5.3 numpy==1.23.4 scipy==1.11.2 pandas==2.1.4 scikit-learn==1.3.0 statsmodels==0.14.0 igraph==0.10.6 louvain==0.8.1 pynndescent==0.5.10. `adata=sc.read_h5ad('foo.h5ad')`; Error:; `AnnDataReadError: Above error raised while reading key '/X' of type <class 'h5py._hl.group.Group'> from /.`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-1890353810
https://github.com/scverse/scanpy/issues/2297#issuecomment-1890353810:358,Availability,Error,Error,358,Seems like this is still an issue. I am getting this error below randomly. It disappears after trying sometime later with the exact code and files... scanpy==1.9.4 anndata==0.9.2 umap==0.5.3 numpy==1.23.4 scipy==1.11.2 pandas==2.1.4 scikit-learn==1.3.0 statsmodels==0.14.0 igraph==0.10.6 louvain==0.8.1 pynndescent==0.5.10. `adata=sc.read_h5ad('foo.h5ad')`; Error:; `AnnDataReadError: Above error raised while reading key '/X' of type <class 'h5py._hl.group.Group'> from /.`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-1890353810
https://github.com/scverse/scanpy/issues/2297#issuecomment-1890353810:391,Availability,error,error,391,Seems like this is still an issue. I am getting this error below randomly. It disappears after trying sometime later with the exact code and files... scanpy==1.9.4 anndata==0.9.2 umap==0.5.3 numpy==1.23.4 scipy==1.11.2 pandas==2.1.4 scikit-learn==1.3.0 statsmodels==0.14.0 igraph==0.10.6 louvain==0.8.1 pynndescent==0.5.10. `adata=sc.read_h5ad('foo.h5ad')`; Error:; `AnnDataReadError: Above error raised while reading key '/X' of type <class 'h5py._hl.group.Group'> from /.`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-1890353810
https://github.com/scverse/scanpy/issues/2297#issuecomment-1890353810:240,Usability,learn,learn,240,Seems like this is still an issue. I am getting this error below randomly. It disappears after trying sometime later with the exact code and files... scanpy==1.9.4 anndata==0.9.2 umap==0.5.3 numpy==1.23.4 scipy==1.11.2 pandas==2.1.4 scikit-learn==1.3.0 statsmodels==0.14.0 igraph==0.10.6 louvain==0.8.1 pynndescent==0.5.10. `adata=sc.read_h5ad('foo.h5ad')`; Error:; `AnnDataReadError: Above error raised while reading key '/X' of type <class 'h5py._hl.group.Group'> from /.`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-1890353810
https://github.com/scverse/scanpy/issues/2297#issuecomment-1891204482:158,Availability,error,error,158,I'm not sure what is the cause of the problem and how to resolve it. But it I remove everything in the metadata aside from index and genecount/genenumber the error does not come up. So one solution is to save metadata to a csv and save the adata without too much metadata info.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-1891204482
https://github.com/scverse/scanpy/issues/2297#issuecomment-2162803279:39,Availability,error,error,39,"Running `0.10.3` here. I had a similar error message, originating in a **mismatch of the indices of the obs-like dataframes** of the `AnnData` object. Although it was not exactly the same (sorry i don't have it here), maybe this can be a hint. Here is how i solved the issue. ```python; ### Have a look at the indices; for key, obs_matrix in adata.obsm.items():; if hasattr(obs_matrix, ""index""):; print(key); print(obs_matrix.index); print(adata.obs_names); print(adata.obs.index). ### If there's a mismatch, you can fix by running something like:; for key, obs_matrix in adata.obsm.items():; if hasattr(obs_matrix, ""index""):; obs_matrix.index = adata.obs_names; ```. I also had a similar error message when there was a mismatch in the _name_ of the index, or if the name of the index was also the _name of a column_. Note that if there is a mismatch, the `adata.write_h5ad` function _does not_ crash. While reading the saved file with `ad.read_h5ad` _will crash_. Suggestion for developers: When the `AnnData.write_h5ad` method is called, check the homogeneity of the indices, and raise an exception if there is a mismatch. Suggestion for users: make sure all the index are the same, have the same name, and that no column has the same name.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-2162803279
https://github.com/scverse/scanpy/issues/2297#issuecomment-2162803279:689,Availability,error,error,689,"Running `0.10.3` here. I had a similar error message, originating in a **mismatch of the indices of the obs-like dataframes** of the `AnnData` object. Although it was not exactly the same (sorry i don't have it here), maybe this can be a hint. Here is how i solved the issue. ```python; ### Have a look at the indices; for key, obs_matrix in adata.obsm.items():; if hasattr(obs_matrix, ""index""):; print(key); print(obs_matrix.index); print(adata.obs_names); print(adata.obs.index). ### If there's a mismatch, you can fix by running something like:; for key, obs_matrix in adata.obsm.items():; if hasattr(obs_matrix, ""index""):; obs_matrix.index = adata.obs_names; ```. I also had a similar error message when there was a mismatch in the _name_ of the index, or if the name of the index was also the _name of a column_. Note that if there is a mismatch, the `adata.write_h5ad` function _does not_ crash. While reading the saved file with `ad.read_h5ad` _will crash_. Suggestion for developers: When the `AnnData.write_h5ad` method is called, check the homogeneity of the indices, and raise an exception if there is a mismatch. Suggestion for users: make sure all the index are the same, have the same name, and that no column has the same name.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-2162803279
https://github.com/scverse/scanpy/issues/2297#issuecomment-2162803279:45,Integrability,message,message,45,"Running `0.10.3` here. I had a similar error message, originating in a **mismatch of the indices of the obs-like dataframes** of the `AnnData` object. Although it was not exactly the same (sorry i don't have it here), maybe this can be a hint. Here is how i solved the issue. ```python; ### Have a look at the indices; for key, obs_matrix in adata.obsm.items():; if hasattr(obs_matrix, ""index""):; print(key); print(obs_matrix.index); print(adata.obs_names); print(adata.obs.index). ### If there's a mismatch, you can fix by running something like:; for key, obs_matrix in adata.obsm.items():; if hasattr(obs_matrix, ""index""):; obs_matrix.index = adata.obs_names; ```. I also had a similar error message when there was a mismatch in the _name_ of the index, or if the name of the index was also the _name of a column_. Note that if there is a mismatch, the `adata.write_h5ad` function _does not_ crash. While reading the saved file with `ad.read_h5ad` _will crash_. Suggestion for developers: When the `AnnData.write_h5ad` method is called, check the homogeneity of the indices, and raise an exception if there is a mismatch. Suggestion for users: make sure all the index are the same, have the same name, and that no column has the same name.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-2162803279
https://github.com/scverse/scanpy/issues/2297#issuecomment-2162803279:695,Integrability,message,message,695,"Running `0.10.3` here. I had a similar error message, originating in a **mismatch of the indices of the obs-like dataframes** of the `AnnData` object. Although it was not exactly the same (sorry i don't have it here), maybe this can be a hint. Here is how i solved the issue. ```python; ### Have a look at the indices; for key, obs_matrix in adata.obsm.items():; if hasattr(obs_matrix, ""index""):; print(key); print(obs_matrix.index); print(adata.obs_names); print(adata.obs.index). ### If there's a mismatch, you can fix by running something like:; for key, obs_matrix in adata.obsm.items():; if hasattr(obs_matrix, ""index""):; obs_matrix.index = adata.obs_names; ```. I also had a similar error message when there was a mismatch in the _name_ of the index, or if the name of the index was also the _name of a column_. Note that if there is a mismatch, the `adata.write_h5ad` function _does not_ crash. While reading the saved file with `ad.read_h5ad` _will crash_. Suggestion for developers: When the `AnnData.write_h5ad` method is called, check the homogeneity of the indices, and raise an exception if there is a mismatch. Suggestion for users: make sure all the index are the same, have the same name, and that no column has the same name.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-2162803279
https://github.com/scverse/scanpy/issues/2301#issuecomment-1210561561:154,Deployability,update,updated,154,"hi @yotamcons ,. thanks a lot for the feedback, we'd really appreciate if you could submit a PR fixing these parts of the documentations that needs to be updated. Happy to support if you need any help,. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2301#issuecomment-1210561561
https://github.com/scverse/scanpy/issues/2301#issuecomment-1210561561:38,Usability,feedback,feedback,38,"hi @yotamcons ,. thanks a lot for the feedback, we'd really appreciate if you could submit a PR fixing these parts of the documentations that needs to be updated. Happy to support if you need any help,. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2301#issuecomment-1210561561
https://github.com/scverse/scanpy/issues/2301#issuecomment-1233189531:262,Availability,ping,ping,262,"> hi @yotamcons ,; > ; > thanks a lot for the feedback, we'd really appreciate if you could submit a PR fixing these parts of the documentations that needs to be updated. Happy to support if you need any help,; > ; > Thank you!. Would love to starting November, ping me if thats still relevant",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2301#issuecomment-1233189531
https://github.com/scverse/scanpy/issues/2301#issuecomment-1233189531:162,Deployability,update,updated,162,"> hi @yotamcons ,; > ; > thanks a lot for the feedback, we'd really appreciate if you could submit a PR fixing these parts of the documentations that needs to be updated. Happy to support if you need any help,; > ; > Thank you!. Would love to starting November, ping me if thats still relevant",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2301#issuecomment-1233189531
https://github.com/scverse/scanpy/issues/2301#issuecomment-1233189531:46,Usability,feedback,feedback,46,"> hi @yotamcons ,; > ; > thanks a lot for the feedback, we'd really appreciate if you could submit a PR fixing these parts of the documentations that needs to be updated. Happy to support if you need any help,; > ; > Thank you!. Would love to starting November, ping me if thats still relevant",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2301#issuecomment-1233189531
https://github.com/scverse/scanpy/issues/2305#issuecomment-1210560162:73,Deployability,update,update,73,"hi @pacificoceanmist , which scanpy version are you using, and could you update to latest version ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305#issuecomment-1210560162
https://github.com/scverse/scanpy/issues/2306#issuecomment-1210554228:19,Deployability,install,install,19,hi @dm8000 did you install it with pip or conda? I would try to re installl with either of the two methods.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306#issuecomment-1210554228
https://github.com/scverse/scanpy/issues/2306#issuecomment-1210554228:67,Deployability,install,installl,67,hi @dm8000 did you install it with pip or conda? I would try to re installl with either of the two methods.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306#issuecomment-1210554228
https://github.com/scverse/scanpy/issues/2306#issuecomment-1210655230:33,Deployability,install,installation,33,Hello @giovp. I used pip for the installation,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306#issuecomment-1210655230
https://github.com/scverse/scanpy/issues/2309#issuecomment-1257066552:136,Modifiability,variab,variables,136,"the idea is you want to take advantage of the very nice macro scanpy provides to make multiple umap subplots, when you specify multiple variables to color by (`sc.pl.umap(colors=['cell_type', 'other'])`). However, for each of those subplots, you might like to place the legend in different places, e.g. on the data for the cell types, but off to the side for the other variable. Unfortunately, scanpy only allows you to specify `legend_loc` once for all the subplots.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2309#issuecomment-1257066552
https://github.com/scverse/scanpy/issues/2309#issuecomment-1257066552:369,Modifiability,variab,variable,369,"the idea is you want to take advantage of the very nice macro scanpy provides to make multiple umap subplots, when you specify multiple variables to color by (`sc.pl.umap(colors=['cell_type', 'other'])`). However, for each of those subplots, you might like to place the legend in different places, e.g. on the data for the cell types, but off to the side for the other variable. Unfortunately, scanpy only allows you to specify `legend_loc` once for all the subplots.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2309#issuecomment-1257066552
https://github.com/scverse/scanpy/issues/2310#issuecomment-1221390668:151,Deployability,upgrade,upgrade,151,"Hi, I think the problem is caused by the two different versions of anndata used. We had similar issues when using anndata 0.7 and 0.8 together. Try to upgrade the version to 0.8. Best; Florian",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310#issuecomment-1221390668
https://github.com/scverse/scanpy/issues/2311#issuecomment-1256966845:162,Modifiability,variab,variable,162,"Thanks for your comment Jason!; Don't you think the sentence before the one you quoted:; ""If None, mpl.rcParams[""axes.prop_cycle""] is used unless the categorical variable already has colors stored in adata.uns[""{var}_colors""].""; in combination with the default being ""None"" would make this clear?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2311#issuecomment-1256966845
https://github.com/scverse/scanpy/issues/2311#issuecomment-1256966845:290,Usability,clear,clear,290,"Thanks for your comment Jason!; Don't you think the sentence before the one you quoted:; ""If None, mpl.rcParams[""axes.prop_cycle""] is used unless the categorical variable already has colors stored in adata.uns[""{var}_colors""].""; in combination with the default being ""None"" would make this clear?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2311#issuecomment-1256966845
https://github.com/scverse/scanpy/issues/2311#issuecomment-1258452834:324,Usability,clear,clear,324,"Hey Lisa!; I think I can see that connection now. But I had initially interpreted the ""If provided"" to mean if I specified, but seems like it also applies to the case where `mpl.rcParams[""axes.prop_cycle""]` is provided for me.; Instead of ""If provided, values of adata.uns[""{var}_colors""] will be set."" I would find it more clear to say something like ""adata.uns[""{var}_colors""] will be set if not already stored""",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2311#issuecomment-1258452834
https://github.com/scverse/scanpy/issues/2313#issuecomment-1239413303:214,Integrability,depend,dependency,214,There is [something](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.coloring.greedy_color.html#networkx.algorithms.coloring.greedy_color) if we want to make Networkx a dependency. Igraph only seems to have graph colouring [in their c library](https://igraph.org/c/doc/igraph-Coloring.html).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2313#issuecomment-1239413303
https://github.com/scverse/scanpy/issues/2313#issuecomment-1240055609:313,Availability,down,down,313,"I think it might be enough to leave it to random chance. As it is now, `sc.pl.umap` works with 70 colors, which aren't easily distinguishable -- but neighboring clusters seem to always be distinguishable. The easiest fix to this issue would just be to support a larger color palette -- maybe even kicking the can down the road up to ~150 colors.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2313#issuecomment-1240055609
https://github.com/scverse/scanpy/issues/2313#issuecomment-1837720757:241,Security,access,access,241,"Hi @alexlenail . Re ; > I think it might be enough to leave it to random chance. As it is now, `sc.pl.umap` works with 70 colors, which aren't easily distinguishable -- but neighboring clusters seem to always be distinguishable. . How can I access the 70 colors? I have a plot with 54 clusters but they're all colored gray.; ![umap_10x_gse_leiden_bc_0001](https://github.com/scverse/scanpy/assets/32474661/dbc9781e-30a0-4262-b850-5af977a3dd24)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2313#issuecomment-1837720757
https://github.com/scverse/scanpy/issues/2314#issuecomment-1240108377:370,Integrability,interoperab,interoperable,370,"Hi! Harmony does not adjust the counts matrix at all, or even read it. Rather, it takes principal components as input, adjusts them to correct for batch, and outputs a modified set of PCs. Here is the paper that explains how it works: https://www.nature.com/articles/s41592-019-0619-0. (I wasn't involved in coming up with this method or implementing it, just making it interoperable with scanpy, for the record)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2314#issuecomment-1240108377
https://github.com/scverse/scanpy/issues/2314#issuecomment-1240114021:130,Performance,load,loadings,130,Thanks for getting back @esrice! . I think I see now -- does that mean I should multiply the `X_pca_harmony` by the _original_ PC loadings to get the imputed counts?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2314#issuecomment-1240114021
https://github.com/scverse/scanpy/issues/2314#issuecomment-1240116924:165,Availability,down,downstream,165,"No, there is no way to get any sort of correction of the counts with this method; it's just for correcting the principal components. You can use `X_pca_harmony` for downstream analyses that by default use `X_pca`, such as computing the neighbor graph.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2314#issuecomment-1240116924
https://github.com/scverse/scanpy/issues/2314#issuecomment-1240118673:37,Deployability,integrat,integration,37,"Here's a paper that compares various integration methods, with some nice figures showing which ones output corrected counts vs. corrected projections:. https://www.nature.com/articles/s41592-021-01336-8. You could use one of the methods that outputs corrected counts if you need corrected counts for some reason.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2314#issuecomment-1240118673
https://github.com/scverse/scanpy/issues/2314#issuecomment-1240118673:37,Integrability,integrat,integration,37,"Here's a paper that compares various integration methods, with some nice figures showing which ones output corrected counts vs. corrected projections:. https://www.nature.com/articles/s41592-021-01336-8. You could use one of the methods that outputs corrected counts if you need corrected counts for some reason.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2314#issuecomment-1240118673
https://github.com/scverse/scanpy/issues/2315#issuecomment-1256967526:170,Deployability,continuous,continuous,170,"Hi Quentin,. When you plot a categorical variable for the first time, scanpy stores the colors for each category in adata.uns, that's why it is modifying your adata. For continuous variables (like your adata.X), it does not do that, hence there is no warning there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2315#issuecomment-1256967526
https://github.com/scverse/scanpy/issues/2315#issuecomment-1256967526:41,Modifiability,variab,variable,41,"Hi Quentin,. When you plot a categorical variable for the first time, scanpy stores the colors for each category in adata.uns, that's why it is modifying your adata. For continuous variables (like your adata.X), it does not do that, hence there is no warning there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2315#issuecomment-1256967526
https://github.com/scverse/scanpy/issues/2315#issuecomment-1256967526:181,Modifiability,variab,variables,181,"Hi Quentin,. When you plot a categorical variable for the first time, scanpy stores the colors for each category in adata.uns, that's why it is modifying your adata. For continuous variables (like your adata.X), it does not do that, hence there is no warning there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2315#issuecomment-1256967526
https://github.com/scverse/scanpy/issues/2315#issuecomment-1257146488:63,Integrability,message,message,63,"Thanks, @LisaSikkema; I figured it out shortly after I sent my message. For now, I only have these solutions, but I don't like any of them:; - Filtering this warning. This is not very clean: I would prefer to really solve the issue. Also, it makes a copy, which is memory expensive, as I sometimes have about `10^7` observations.; - Creating a copy so that I don't use a view. Same issue about the memory.; - Plotting this UMAP on the complete anndata object so that it stores the colors, and then plotting with the view I'm creating. The problem is that, for my use case, I don't want to plot it with the entire dataset, so it makes a useless plot. I think I will go for the first solution, even though I'm not really satisfied.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2315#issuecomment-1257146488
https://github.com/scverse/scanpy/issues/2316#issuecomment-1249573153:281,Deployability,update,updated,281,"@alam-shahul I'd suggest you to look into the squidpy plotting functionalities here: https://squidpy.readthedocs.io/en/latest/examples.html#plotting and here: https://squidpy.readthedocs.io/en/latest/api/squidpy.pl.spatial_scatter.html#squidpy.pl.spatial_scatter; they cointain an updated version of the scanpy plotting spatial, which will be deprecated. I'll close this comment and please re open one if relevant in squidpy",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2316#issuecomment-1249573153
https://github.com/scverse/scanpy/issues/2317#issuecomment-1257063310:297,Testability,test,testing,297,"Hey Simon,. Thanks for your suggestions. I agree that 1 would be very useful indeed and would be worth implementing.. this is not in the making yet is it @ivirshup ?; As to point 2, this would statistically be difficult as you're comparing a group to itself, which I think should not be done when testing differences between two groups.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2317#issuecomment-1257063310
https://github.com/scverse/scanpy/issues/2318#issuecomment-1273295202:98,Deployability,update,update,98,"I just encountered the same issue, using scanpy 1.9.1 and matplotlib 3.5.3. I think it's a recent update to matbplotlib which broke something here. When I rolled back matplotlib to 3.5.2, it ran fine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318#issuecomment-1273295202
https://github.com/scverse/scanpy/issues/2318#issuecomment-1445561483:3618,Deployability,update,updated,3618,"cksSM.connect('changed', cb.update_normal); 1734 mappable.colorbar = cb. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/colorbar.py:1225, in Colorbar.__init__(self, ax, mappable, **kwargs); 1223 if isinstance(mappable, martist.Artist):; 1224 _add_disjoint_kwargs(kwargs, alpha=mappable.get_alpha()); -> 1225 ColorbarBase.__init__(self, ax, **kwargs). File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/cbook/deprecation.py:451, in _make_keyword_only.<locals>.wrapper(*args, **kwargs); 445 if len(args) > idx:; 446 warn_deprecated(; 447 since, message=""Passing the %(name)s %(obj_type)s ""; 448 ""positionally is deprecated since Matplotlib %(since)s; the ""; 449 ""parameter will become keyword-only %(removal)s."",; 450 name=name, obj_type=f""parameter of {func.__name__}()""); --> 451 return func(*args, **kwargs). TypeError: __init__() got an unexpected keyword argument 'location'; ```; I was having this problem with scanpy 1.9.1 and matplotlib 3.3.2 I just updated to 1.9.2 and confirm the issue is unchanged; ```; scanpy==1.9.2 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==0.23.2 statsmodels==0.13.2 python-igraph==0.9.9 louvain==0.7.1 pynndescent==0.5.6; -----; anndata 0.8.0; scanpy 1.9.2; -----; PIL 9.0.1; absl NA; asttokens NA; attr 21.4.0; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; brotli NA; certifi 2022.06.15; cffi 1.14.5; charset_normalizer 2.0.12; chex 0.1.5; cloudpickle 2.2.0; colorama 0.4.4; contextlib2 NA; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.0; dask 2022.11.1; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; deprecate 0.3.2; docrep 0.3.2; entrypoints 0.4; executing 0.8.3; flax 0.6.1; fsspec 2022.11.0; google NA; h5py 3.6.0; hypergeom_ufunc NA; idna 3.3; igraph 0.9.9; ipykernel 6.9.2; ipython_genutils 0.2.0; ipywidgets 7.6.5; jax 0.3.24; jaxlib 0.3.24; jedi 0.18.1; jinja2 3.0.3; joblib 1.1.0; kiwisolver 1.3.2; leidenalg 0.8.9; llvmlite 0.38.0; louvain 0.7.1; markup",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318#issuecomment-1445561483
https://github.com/scverse/scanpy/issues/2318#issuecomment-1445561483:6085,Deployability,update,updated,6085,"lib2 NA; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.0; dask 2022.11.1; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; deprecate 0.3.2; docrep 0.3.2; entrypoints 0.4; executing 0.8.3; flax 0.6.1; fsspec 2022.11.0; google NA; h5py 3.6.0; hypergeom_ufunc NA; idna 3.3; igraph 0.9.9; ipykernel 6.9.2; ipython_genutils 0.2.0; ipywidgets 7.6.5; jax 0.3.24; jaxlib 0.3.24; jedi 0.18.1; jinja2 3.0.3; joblib 1.1.0; kiwisolver 1.3.2; leidenalg 0.8.9; llvmlite 0.38.0; louvain 0.7.1; markupsafe 2.1.1; matplotlib 3.3.2; matplotlib_inline NA; ml_collections NA; mpl_toolkits NA; msgpack 1.0.4; mudata 0.2.1; multipledispatch 0.6.0; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.1; numexpr 2.8.0; numpy 1.21.5; numpyro 0.10.1; opt_einsum v3.3.0; optax 0.1.3; packaging 21.3; pandas 1.4.1; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.27; psutil 5.9.0; ptyprocess 0.7.0; pure_eval 0.2.2; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pynndescent 0.5.6; pyparsing 3.0.7; pyro 1.8.2; pytorch_lightning 1.7.7; pytz 2021.3; requests 2.27.1; rich NA; scipy 1.8.0; scrublet NA; scvi 0.19.0; seaborn 0.11.2; session_info 1.0.0; setuptools 60.9.3; setuptools_scm NA; six 1.16.0; sklearn 0.23.2; socks 1.7.1; sphinxcontrib NA; stack_data 0.2.0; statsmodels 0.13.2; tensorboard 2.10.1; texttable 1.6.4; threadpoolctl 3.1.0; tlz 0.12.0; toolz 0.12.0; torch 1.11.0; torchmetrics 0.10.2; torchvision 0.12.0; tornado 6.1; tqdm 4.63.0; traitlets 5.1.1; tree 0.1.7; typing_extensions NA; umap 0.5.2; urllib3 1.26.8; wcwidth 0.2.5; yaml 6.0; zipp NA; zmq 22.3.0; -----; IPython 8.1.1; jupyter_client 7.1.2; jupyter_core 4.9.2; notebook 6.4.9; -----; Python 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:22:27) [GCC 9.3.0]; Linux-5.4.0-139-generic-x86_64-with-glibc2.10; -----; Session information updated at 2023-02-26 19:13; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318#issuecomment-1445561483
https://github.com/scverse/scanpy/issues/2318#issuecomment-1445561483:3121,Integrability,wrap,wrapper,3121,"3 cb = cbar.colorbar_factory(cax, mappable, **cb_kw); 2345 self.sca(current_ax); 2346 self.stale = True. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/colorbar.py:1731, in colorbar_factory(cax, mappable, **kwargs); 1729 cb = ColorbarPatch(cax, mappable, **kwargs); 1730 else:; -> 1731 cb = Colorbar(cax, mappable, **kwargs); 1733 cid = mappable.callbacksSM.connect('changed', cb.update_normal); 1734 mappable.colorbar = cb. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/colorbar.py:1225, in Colorbar.__init__(self, ax, mappable, **kwargs); 1223 if isinstance(mappable, martist.Artist):; 1224 _add_disjoint_kwargs(kwargs, alpha=mappable.get_alpha()); -> 1225 ColorbarBase.__init__(self, ax, **kwargs). File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/cbook/deprecation.py:451, in _make_keyword_only.<locals>.wrapper(*args, **kwargs); 445 if len(args) > idx:; 446 warn_deprecated(; 447 since, message=""Passing the %(name)s %(obj_type)s ""; 448 ""positionally is deprecated since Matplotlib %(since)s; the ""; 449 ""parameter will become keyword-only %(removal)s."",; 450 name=name, obj_type=f""parameter of {func.__name__}()""); --> 451 return func(*args, **kwargs). TypeError: __init__() got an unexpected keyword argument 'location'; ```; I was having this problem with scanpy 1.9.1 and matplotlib 3.3.2 I just updated to 1.9.2 and confirm the issue is unchanged; ```; scanpy==1.9.2 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==0.23.2 statsmodels==0.13.2 python-igraph==0.9.9 louvain==0.7.1 pynndescent==0.5.6; -----; anndata 0.8.0; scanpy 1.9.2; -----; PIL 9.0.1; absl NA; asttokens NA; attr 21.4.0; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; brotli NA; certifi 2022.06.15; cffi 1.14.5; charset_normalizer 2.0.12; chex 0.1.5; cloudpickle 2.2.0; colorama 0.4.4; contextlib2 NA; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.0; dask 2022.11.1; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defuse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318#issuecomment-1445561483
https://github.com/scverse/scanpy/issues/2318#issuecomment-1445561483:3205,Integrability,message,message,3205,"3 cb = cbar.colorbar_factory(cax, mappable, **cb_kw); 2345 self.sca(current_ax); 2346 self.stale = True. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/colorbar.py:1731, in colorbar_factory(cax, mappable, **kwargs); 1729 cb = ColorbarPatch(cax, mappable, **kwargs); 1730 else:; -> 1731 cb = Colorbar(cax, mappable, **kwargs); 1733 cid = mappable.callbacksSM.connect('changed', cb.update_normal); 1734 mappable.colorbar = cb. File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/colorbar.py:1225, in Colorbar.__init__(self, ax, mappable, **kwargs); 1223 if isinstance(mappable, martist.Artist):; 1224 _add_disjoint_kwargs(kwargs, alpha=mappable.get_alpha()); -> 1225 ColorbarBase.__init__(self, ax, **kwargs). File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/cbook/deprecation.py:451, in _make_keyword_only.<locals>.wrapper(*args, **kwargs); 445 if len(args) > idx:; 446 warn_deprecated(; 447 since, message=""Passing the %(name)s %(obj_type)s ""; 448 ""positionally is deprecated since Matplotlib %(since)s; the ""; 449 ""parameter will become keyword-only %(removal)s."",; 450 name=name, obj_type=f""parameter of {func.__name__}()""); --> 451 return func(*args, **kwargs). TypeError: __init__() got an unexpected keyword argument 'location'; ```; I was having this problem with scanpy 1.9.1 and matplotlib 3.3.2 I just updated to 1.9.2 and confirm the issue is unchanged; ```; scanpy==1.9.2 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==0.23.2 statsmodels==0.13.2 python-igraph==0.9.9 louvain==0.7.1 pynndescent==0.5.6; -----; anndata 0.8.0; scanpy 1.9.2; -----; PIL 9.0.1; absl NA; asttokens NA; attr 21.4.0; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; brotli NA; certifi 2022.06.15; cffi 1.14.5; charset_normalizer 2.0.12; chex 0.1.5; cloudpickle 2.2.0; colorama 0.4.4; contextlib2 NA; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.0; dask 2022.11.1; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defuse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318#issuecomment-1445561483
https://github.com/scverse/scanpy/issues/2318#issuecomment-1445561483:3765,Usability,learn,learn,3765,"lorbar.py:1225, in Colorbar.__init__(self, ax, mappable, **kwargs); 1223 if isinstance(mappable, martist.Artist):; 1224 _add_disjoint_kwargs(kwargs, alpha=mappable.get_alpha()); -> 1225 ColorbarBase.__init__(self, ax, **kwargs). File ~/miniconda3/envs/scvi10j/lib/python3.8/site-packages/matplotlib/cbook/deprecation.py:451, in _make_keyword_only.<locals>.wrapper(*args, **kwargs); 445 if len(args) > idx:; 446 warn_deprecated(; 447 since, message=""Passing the %(name)s %(obj_type)s ""; 448 ""positionally is deprecated since Matplotlib %(since)s; the ""; 449 ""parameter will become keyword-only %(removal)s."",; 450 name=name, obj_type=f""parameter of {func.__name__}()""); --> 451 return func(*args, **kwargs). TypeError: __init__() got an unexpected keyword argument 'location'; ```; I was having this problem with scanpy 1.9.1 and matplotlib 3.3.2 I just updated to 1.9.2 and confirm the issue is unchanged; ```; scanpy==1.9.2 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==0.23.2 statsmodels==0.13.2 python-igraph==0.9.9 louvain==0.7.1 pynndescent==0.5.6; -----; anndata 0.8.0; scanpy 1.9.2; -----; PIL 9.0.1; absl NA; asttokens NA; attr 21.4.0; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; brotli NA; certifi 2022.06.15; cffi 1.14.5; charset_normalizer 2.0.12; chex 0.1.5; cloudpickle 2.2.0; colorama 0.4.4; contextlib2 NA; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.0; dask 2022.11.1; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; deprecate 0.3.2; docrep 0.3.2; entrypoints 0.4; executing 0.8.3; flax 0.6.1; fsspec 2022.11.0; google NA; h5py 3.6.0; hypergeom_ufunc NA; idna 3.3; igraph 0.9.9; ipykernel 6.9.2; ipython_genutils 0.2.0; ipywidgets 7.6.5; jax 0.3.24; jaxlib 0.3.24; jedi 0.18.1; jinja2 3.0.3; joblib 1.1.0; kiwisolver 1.3.2; leidenalg 0.8.9; llvmlite 0.38.0; louvain 0.7.1; markupsafe 2.1.1; matplotlib 3.3.2; matplotlib_inline NA; ml_collections NA; mpl_toolkits NA; msgpack 1.0.4; mudata 0.2.1; multipledispatch 0.6.0; nats",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318#issuecomment-1445561483
https://github.com/scverse/scanpy/issues/2330#issuecomment-1249550226:22,Availability,down,down,22,"I've been able to pin down the culprit.; Excluding this line ```adata = adata[:, adata.var.highly_variable]``` allows Leiden clustering to populate",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330#issuecomment-1249550226
https://github.com/scverse/scanpy/issues/2330#issuecomment-1249667836:815,Availability,error,error,815,"This is what I'm running; ```; bcType = 'NobatchCorr'; sc.pp.normalize_total(adata, target_sum=1e4, exclude_highly_expressed=True, key_added='Norm_Factor'); sc.pp.log1p(adata); adata.raw = adata; sc.pp.highly_variable_genes(adata, n_top_genes=4000, batch_key='batch'); #adata = adata[:, adata.var.highly_variable]; sc.pp.scale(adata, max_value=10); sc.pp.pca(adata, use_highly_variable=True, svd_solver='full', n_comps =n_pcs, random_state=10); sc.pp.neighbors(adata, n_pcs=n_pcs, use_rep='X_pca', random_state=10); sc.tl.umap(adata, random_state=10); sc.tl.leiden(adata,resolution=resolution, key_added=bcType, random_state=10); ```; The code never fails, but Leiden parameters are not present in the adata as it should. Running; ```; sc.pl.umap(adata,color=['overall'], palette=colors_list); ```; gives the above error, but if I comment out ```adata = adata[:, adata.var.highly_variable]``` it works, I'm unsure why atm.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330#issuecomment-1249667836
https://github.com/scverse/scanpy/issues/2332#issuecomment-1254363045:36,Availability,down,downgraded,36,I just had the same issue because I downgraded my matplotlib elsewhere.; So it should work if you upgrade your matplotlib.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332#issuecomment-1254363045
https://github.com/scverse/scanpy/issues/2332#issuecomment-1254363045:98,Deployability,upgrade,upgrade,98,I just had the same issue because I downgraded my matplotlib elsewhere.; So it should work if you upgrade your matplotlib.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332#issuecomment-1254363045
https://github.com/scverse/scanpy/issues/2332#issuecomment-1256252146:69,Availability,error,error,69,"It seems that you are using an online notebook. I also received this error on Colab. But when I ran the same code on the PC terminal, everything went well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332#issuecomment-1256252146
https://github.com/scverse/scanpy/issues/2332#issuecomment-1328259095:142,Deployability,upgrade,upgraded,142,"Thanks for the suggestions and sorry for the late response. Yes, I was using google colab, and a newer version of matplotlib did the trick. I upgraded to the 3.5.3 version of matplotlib, and restarted the runtime, and that did the trick, thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332#issuecomment-1328259095
https://github.com/scverse/scanpy/pull/2334#issuecomment-1291804266:19,Usability,feedback,feedback,19,Slightly unrelated feedback: I think that your API documentation is broken or incomplete: https://bento-tools.readthedocs.io/en/latest/api.html#tools. Would be great to have it complete so that people can use your tool easily.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2334#issuecomment-1291804266
https://github.com/scverse/scanpy/issues/2337#issuecomment-1261103537:120,Usability,clear,clear,120,"I just encountered this as well. It seems like it's not running UMAP at all unless I give it a `maxiter` parameter. Not clear why that is, but passing an argument there worked.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2337#issuecomment-1261103537
https://github.com/scverse/scanpy/issues/2337#issuecomment-1371840544:127,Deployability,install,installation,127,"Same! Seems like -maxiter gets set/clobbered to 1. I'm seeing it on one machine (which I have limited access too, its a galaxy installation using scanpy scripts) but not another (my local), both of which are apparently running scanpy 1.8.1. . Im wondering if there's a umap-learn version issue? In order to set the umap n_epochs(aka maxiter) default , it looks like older versions of umap-learn expected 0 (e.g. https://github.com/lmcinnes/umap/blob/0.5.0/umap/umap_.py), whereas the newer expect None. My working installation has umap-learn 0.5.2 (which seems to expect None), and I'm not sure about the one on the other server. Might be barking up the wrong tree.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2337#issuecomment-1371840544
https://github.com/scverse/scanpy/issues/2337#issuecomment-1371840544:514,Deployability,install,installation,514,"Same! Seems like -maxiter gets set/clobbered to 1. I'm seeing it on one machine (which I have limited access too, its a galaxy installation using scanpy scripts) but not another (my local), both of which are apparently running scanpy 1.8.1. . Im wondering if there's a umap-learn version issue? In order to set the umap n_epochs(aka maxiter) default , it looks like older versions of umap-learn expected 0 (e.g. https://github.com/lmcinnes/umap/blob/0.5.0/umap/umap_.py), whereas the newer expect None. My working installation has umap-learn 0.5.2 (which seems to expect None), and I'm not sure about the one on the other server. Might be barking up the wrong tree.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2337#issuecomment-1371840544
https://github.com/scverse/scanpy/issues/2337#issuecomment-1371840544:102,Security,access,access,102,"Same! Seems like -maxiter gets set/clobbered to 1. I'm seeing it on one machine (which I have limited access too, its a galaxy installation using scanpy scripts) but not another (my local), both of which are apparently running scanpy 1.8.1. . Im wondering if there's a umap-learn version issue? In order to set the umap n_epochs(aka maxiter) default , it looks like older versions of umap-learn expected 0 (e.g. https://github.com/lmcinnes/umap/blob/0.5.0/umap/umap_.py), whereas the newer expect None. My working installation has umap-learn 0.5.2 (which seems to expect None), and I'm not sure about the one on the other server. Might be barking up the wrong tree.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2337#issuecomment-1371840544
https://github.com/scverse/scanpy/issues/2337#issuecomment-1371840544:274,Usability,learn,learn,274,"Same! Seems like -maxiter gets set/clobbered to 1. I'm seeing it on one machine (which I have limited access too, its a galaxy installation using scanpy scripts) but not another (my local), both of which are apparently running scanpy 1.8.1. . Im wondering if there's a umap-learn version issue? In order to set the umap n_epochs(aka maxiter) default , it looks like older versions of umap-learn expected 0 (e.g. https://github.com/lmcinnes/umap/blob/0.5.0/umap/umap_.py), whereas the newer expect None. My working installation has umap-learn 0.5.2 (which seems to expect None), and I'm not sure about the one on the other server. Might be barking up the wrong tree.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2337#issuecomment-1371840544
https://github.com/scverse/scanpy/issues/2337#issuecomment-1371840544:389,Usability,learn,learn,389,"Same! Seems like -maxiter gets set/clobbered to 1. I'm seeing it on one machine (which I have limited access too, its a galaxy installation using scanpy scripts) but not another (my local), both of which are apparently running scanpy 1.8.1. . Im wondering if there's a umap-learn version issue? In order to set the umap n_epochs(aka maxiter) default , it looks like older versions of umap-learn expected 0 (e.g. https://github.com/lmcinnes/umap/blob/0.5.0/umap/umap_.py), whereas the newer expect None. My working installation has umap-learn 0.5.2 (which seems to expect None), and I'm not sure about the one on the other server. Might be barking up the wrong tree.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2337#issuecomment-1371840544
https://github.com/scverse/scanpy/issues/2337#issuecomment-1371840544:536,Usability,learn,learn,536,"Same! Seems like -maxiter gets set/clobbered to 1. I'm seeing it on one machine (which I have limited access too, its a galaxy installation using scanpy scripts) but not another (my local), both of which are apparently running scanpy 1.8.1. . Im wondering if there's a umap-learn version issue? In order to set the umap n_epochs(aka maxiter) default , it looks like older versions of umap-learn expected 0 (e.g. https://github.com/lmcinnes/umap/blob/0.5.0/umap/umap_.py), whereas the newer expect None. My working installation has umap-learn 0.5.2 (which seems to expect None), and I'm not sure about the one on the other server. Might be barking up the wrong tree.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2337#issuecomment-1371840544
https://github.com/scverse/scanpy/issues/2338#issuecomment-1274522724:26,Testability,log,logFoldChange,26,Any one can help?; All my logFoldChange are NAN.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2338#issuecomment-1274522724
https://github.com/scverse/scanpy/issues/2339#issuecomment-1261132252:51,Availability,Down,Downgrading,51,I also saw this with `python-igraph` version 0.10. Downgrading to `0.9.9` fixed the issue.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339#issuecomment-1261132252
https://github.com/scverse/scanpy/issues/2339#issuecomment-1261162964:290,Availability,Down,Downgrading,290,"Thanks a lot. ---Original---; From: ""James ***@***.***&gt;; Date: Thu, Sep 29, 2022 00:06 AM; To: ***@***.***&gt;;; Cc: ""Sijian ***@***.******@***.***&gt;;; Subject: Re: [scverse/scanpy] sc.tl.leiden(adata,use_weights=False) (Issue#2339). ; I also saw this with python-igraph version 0.10. Downgrading to 0.9.9 fixed the issue.; ; —; Reply to this email directly, view it on GitHub, or unsubscribe.; You are receiving this because you authored the thread.Message ID: ***@***.***&gt;",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339#issuecomment-1261162964
https://github.com/scverse/scanpy/issues/2339#issuecomment-1261162964:455,Integrability,Message,Message,455,"Thanks a lot. ---Original---; From: ""James ***@***.***&gt;; Date: Thu, Sep 29, 2022 00:06 AM; To: ***@***.***&gt;;; Cc: ""Sijian ***@***.******@***.***&gt;;; Subject: Re: [scverse/scanpy] sc.tl.leiden(adata,use_weights=False) (Issue#2339). ; I also saw this with python-igraph version 0.10. Downgrading to 0.9.9 fixed the issue.; ; —; Reply to this email directly, view it on GitHub, or unsubscribe.; You are receiving this because you authored the thread.Message ID: ***@***.***&gt;",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339#issuecomment-1261162964
https://github.com/scverse/scanpy/issues/2339#issuecomment-1261170036:94,Availability,failure,failure,94,"Thanks for your help. It works fine now! I have tried several times this day, but end up with failure. It works fine now following your method!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339#issuecomment-1261170036
https://github.com/scverse/scanpy/issues/2339#issuecomment-1262134575:5,Availability,error,error,5,"Same error occurred when using the default leiden with weights as well; downgrading python-igraph to 0.9.11 fixed the issue.; leidenalg is dependent on python-igraph (0.10.0 for my conda) and igraph (0.9.10), and I suppose the version discrepancy caused the problem. Or you can replace tl.leiden with leiden algorithm in python-igraph:. adjacency = sc._utils._choose_graph(adata, obsp=None, neighbors_key=None); g = sc._utils.get_igraph_from_adjacency(adjacency); clustering = g.community_leiden(objective_function='modularity', weights='weight', resolution_parameter=0.5); adata.obs['leiden_igraph_weight'] = pd.Series(clustering.membership, dtype='category', index=adata.obs.index). sc.pl.umap(adata, color='leiden_igraph_weight')",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339#issuecomment-1262134575
https://github.com/scverse/scanpy/issues/2339#issuecomment-1262134575:72,Availability,down,downgrading,72,"Same error occurred when using the default leiden with weights as well; downgrading python-igraph to 0.9.11 fixed the issue.; leidenalg is dependent on python-igraph (0.10.0 for my conda) and igraph (0.9.10), and I suppose the version discrepancy caused the problem. Or you can replace tl.leiden with leiden algorithm in python-igraph:. adjacency = sc._utils._choose_graph(adata, obsp=None, neighbors_key=None); g = sc._utils.get_igraph_from_adjacency(adjacency); clustering = g.community_leiden(objective_function='modularity', weights='weight', resolution_parameter=0.5); adata.obs['leiden_igraph_weight'] = pd.Series(clustering.membership, dtype='category', index=adata.obs.index). sc.pl.umap(adata, color='leiden_igraph_weight')",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339#issuecomment-1262134575
https://github.com/scverse/scanpy/issues/2339#issuecomment-1262134575:139,Integrability,depend,dependent,139,"Same error occurred when using the default leiden with weights as well; downgrading python-igraph to 0.9.11 fixed the issue.; leidenalg is dependent on python-igraph (0.10.0 for my conda) and igraph (0.9.10), and I suppose the version discrepancy caused the problem. Or you can replace tl.leiden with leiden algorithm in python-igraph:. adjacency = sc._utils._choose_graph(adata, obsp=None, neighbors_key=None); g = sc._utils.get_igraph_from_adjacency(adjacency); clustering = g.community_leiden(objective_function='modularity', weights='weight', resolution_parameter=0.5); adata.obs['leiden_igraph_weight'] = pd.Series(clustering.membership, dtype='category', index=adata.obs.index). sc.pl.umap(adata, color='leiden_igraph_weight')",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339#issuecomment-1262134575
https://github.com/scverse/scanpy/issues/2339#issuecomment-1646862855:82,Deployability,update,update,82,"the newest versions of leidenalg and igraph should be compatible with each other. update both, e.g. `pip install -U leidenalg igraph`. `python-igraph` is no longer necessary, you can remove it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339#issuecomment-1646862855
https://github.com/scverse/scanpy/issues/2339#issuecomment-1646862855:105,Deployability,install,install,105,"the newest versions of leidenalg and igraph should be compatible with each other. update both, e.g. `pip install -U leidenalg igraph`. `python-igraph` is no longer necessary, you can remove it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339#issuecomment-1646862855
https://github.com/scverse/scanpy/issues/2339#issuecomment-1647473441:84,Deployability,update,update,84,"> the newest versions of leidenalg and igraph should be compatible with each other. update both, e.g. `pip install -U leidenalg igraph`; > ; > `python-igraph` is no longer necessary, you can remove it. Thanks for your help!that‘s works！！！",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339#issuecomment-1647473441
https://github.com/scverse/scanpy/issues/2339#issuecomment-1647473441:107,Deployability,install,install,107,"> the newest versions of leidenalg and igraph should be compatible with each other. update both, e.g. `pip install -U leidenalg igraph`; > ; > `python-igraph` is no longer necessary, you can remove it. Thanks for your help!that‘s works！！！",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339#issuecomment-1647473441
https://github.com/scverse/scanpy/issues/2341#issuecomment-1265542125:67,Availability,error,error,67,I installed leidenalg through conda today and encountered the same error.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341#issuecomment-1265542125
https://github.com/scverse/scanpy/issues/2341#issuecomment-1265542125:2,Deployability,install,installed,2,I installed leidenalg through conda today and encountered the same error.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341#issuecomment-1265542125
https://github.com/scverse/scanpy/issues/2341#issuecomment-1271333881:53,Availability,down,downgrade,53,"This is identical with #2339. The simplest way is to downgrade `python-igraph` to `0.9.9`, https://github.com/scverse/scanpy/issues/2339#issuecomment-1261132252",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341#issuecomment-1271333881
https://github.com/scverse/scanpy/issues/2341#issuecomment-1271333881:34,Usability,simpl,simplest,34,"This is identical with #2339. The simplest way is to downgrade `python-igraph` to `0.9.9`, https://github.com/scverse/scanpy/issues/2339#issuecomment-1261132252",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341#issuecomment-1271333881
https://github.com/scverse/scanpy/issues/2341#issuecomment-1641870947:850,Deployability,update,updated,850,"Also running into this now with pertpy. . ```; -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 10.0.0; cffi 1.15.1; colorama 0.4.6; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; defusedxml 0.7.1; h5py 3.9.0; igraph 0.9.7; joblib 1.3.1; kiwisolver 1.4.4; leidenalg 0.10.0; llvmlite 0.40.1; matplotlib 3.7.2; mpl_toolkits NA; mpmath 1.3.0; natsort 8.4.0; numba 0.57.1; numpy 1.24.4; nvfuser NA; opt_einsum v3.3.0; packaging 23.1; pandas 2.0.3; psutil 5.9.5; pyarrow 12.0.1; pyparsing 3.0.9; pytz 2023.3; scipy 1.11.1; session_info 1.0.0; six 1.16.0; sklearn 1.3.0; sphinxcontrib NA; sympy 1.12; texttable 1.6.7; threadpoolctl 3.2.0; torch 2.0.1+cu117; tqdm 4.65.0; typing_extensions NA; wcwidth 0.2.6; yaml 6.0.1; -----; Python 3.10.9 (main, Jan 11 2023, 15:21:40) [GCC 11.2.0]; Linux-6.4.3-arch1-2-x86_64-with-glibc2.37; -----; Session information updated at 2023-07-19 12:57; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341#issuecomment-1641870947
https://github.com/scverse/scanpy/issues/2341#issuecomment-1641903565:149,Deployability,update,update,149,> @Zethson See my comment above. You have a version mismatch between igraph and leidenalg. Use the latest of both. I know. The issue is that `poetry update` defaults to this combination in my environment for pertpy. I'll probably have to set minimum requirements. Thanks nevertheless!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341#issuecomment-1641903565
https://github.com/scverse/scanpy/issues/2341#issuecomment-1645373691:47,Deployability,install,install,47,"@Zethson added a fix for this to #2566. if you install `scanpy[leiden]`, it’ll make sure the correct versions are installed",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341#issuecomment-1645373691
https://github.com/scverse/scanpy/issues/2341#issuecomment-1645373691:114,Deployability,install,installed,114,"@Zethson added a fix for this to #2566. if you install `scanpy[leiden]`, it’ll make sure the correct versions are installed",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341#issuecomment-1645373691
https://github.com/scverse/scanpy/issues/2343#issuecomment-1290776224:23,Availability,avail,available,23,"Reopen if more info is available, please.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343#issuecomment-1290776224
https://github.com/scverse/scanpy/pull/2344#issuecomment-1267397231:40,Testability,test,tests,40,"I added a scalar dataset to the `scanpy/tests/_data/10x_data/1.2.0/multiple_genomes.h5` file in the last commit. Diff between the h5ls of old vs new files:. ```diff; @@ -6,6 +6,7 @@; /another_genome/genes Dataset {343/4681}; /another_genome/indices Dataset {12/8192}; /another_genome/indptr Dataset {13/8192}; +/another_genome/scalar_dataset Dataset {SCALAR}; /another_genome/shape Dataset {2/16384}; /hg19_chr21 Group; /hg19_chr21/barcodes Dataset {12/3640}; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2344#issuecomment-1267397231
https://github.com/scverse/scanpy/pull/2348#issuecomment-1273857794:326,Availability,error,error-reference,326,# [Codecov](https://codecov.io/gh/scverse/scanpy/pull/2348?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@6b5f786`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 6fb5f26 differs from pull request most recent head fb557a1. Consider uploading reports for the commit fb557a1 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2348 +/- ##; ========================================; Coverage ? 71.77% ; ========================================; Files ? 97 ; Lines ? 11519 ; Branches ? 0 ; ========================================; Hits ? 8268 ; Misses ? 3251 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2348#issuecomment-1273857794
https://github.com/scverse/scanpy/pull/2348#issuecomment-1273857794:274,Usability,learn,learn,274,# [Codecov](https://codecov.io/gh/scverse/scanpy/pull/2348?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@6b5f786`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 6fb5f26 differs from pull request most recent head fb557a1. Consider uploading reports for the commit fb557a1 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2348 +/- ##; ========================================; Coverage ? 71.77% ; ========================================; Files ? 97 ; Lines ? 11519 ; Branches ? 0 ; ========================================; Hits ? 8268 ; Misses ? 3251 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2348#issuecomment-1273857794
https://github.com/scverse/scanpy/pull/2350#issuecomment-1274792439:326,Availability,error,error-reference,326,# [Codecov](https://codecov.io/gh/scverse/scanpy/pull/2350?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@cf6d820`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2350 +/- ##; ========================================; Coverage ? 71.77% ; ========================================; Files ? 97 ; Lines ? 11519 ; Branches ? 0 ; ========================================; Hits ? 8268 ; Misses ? 3251 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2350#issuecomment-1274792439
https://github.com/scverse/scanpy/pull/2350#issuecomment-1274792439:274,Usability,learn,learn,274,# [Codecov](https://codecov.io/gh/scverse/scanpy/pull/2350?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@cf6d820`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2350 +/- ##; ========================================; Coverage ? 71.77% ; ========================================; Files ? 97 ; Lines ? 11519 ; Branches ? 0 ; ========================================; Hits ? 8268 ; Misses ? 3251 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2350#issuecomment-1274792439
https://github.com/scverse/scanpy/issues/2351#issuecomment-1275594865:4,Availability,error,error,4,The error happened because the ingest cannot use neighbors generated from harmony.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2351#issuecomment-1275594865
https://github.com/scverse/scanpy/issues/2352#issuecomment-1370858567:38,Deployability,install,install,38,Is this issue still relevant? Did you install scikit-misc?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352#issuecomment-1370858567
https://github.com/scverse/scanpy/issues/2352#issuecomment-2090072902:11,Deployability,install,install,11,Doing `pip install --user scikit-misc` as the last line says should solve this issue - I hope it worked out!; Will close this as no more followups seen here.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352#issuecomment-2090072902
https://github.com/scverse/scanpy/pull/2355#issuecomment-1376280885:844,Deployability,integrat,integration,844,"> Hi,; > ; > all things that are not transcriptomics should ideally live in our sister packages such as https://github.com/scverse/muon . If you remove all things related to ATAC-seq in this PR we could consider it, but honestly I think that this might better live outside of scanpy external and much rather in the [scverse ecosystem](https://scverse.org/packages/#ecosystem). Hi,; Thank you for your reply. I could remove the ATAC in the PR, actually, this commit [7f74d8c](https://github.com/scverse/scanpy/pull/2355/commits/7f74d8c47005dd630f691ab5926095f0ff277ce8) is the version without ATAC. Please let me know if this does not work, I will commit another PR.; I think scalex is very suitable to be included in pp.external since it was developed based-on scanpy system, which could provide more choices for scanpy users to do single-cell integration.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355#issuecomment-1376280885
https://github.com/scverse/scanpy/pull/2355#issuecomment-1376280885:844,Integrability,integrat,integration,844,"> Hi,; > ; > all things that are not transcriptomics should ideally live in our sister packages such as https://github.com/scverse/muon . If you remove all things related to ATAC-seq in this PR we could consider it, but honestly I think that this might better live outside of scanpy external and much rather in the [scverse ecosystem](https://scverse.org/packages/#ecosystem). Hi,; Thank you for your reply. I could remove the ATAC in the PR, actually, this commit [7f74d8c](https://github.com/scverse/scanpy/pull/2355/commits/7f74d8c47005dd630f691ab5926095f0ff277ce8) is the version without ATAC. Please let me know if this does not work, I will commit another PR.; I think scalex is very suitable to be included in pp.external since it was developed based-on scanpy system, which could provide more choices for scanpy users to do single-cell integration.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355#issuecomment-1376280885
https://github.com/scverse/scanpy/pull/2355#issuecomment-1431674978:116,Deployability,update,updated,116,"So we're really not accepting any packages into scanpy.external anymore and will deprecate external soon. We've now updated our documentation to reflect this. However, we'd be very happy to welcome your package in the scverse ecosystem -> https://scverse.org/packages/#ecosystem. I'm sorry that you put in all this work but then get denied by us like this :(",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355#issuecomment-1431674978
https://github.com/scverse/scanpy/issues/2358#issuecomment-1372935932:133,Availability,down,downloaded,133,"hi, it is actually just one line code. here it is:; ad['leiden'] = rapids_scanpy_funcs.leiden(ad). rapids_scanpy_funcs.leiden can be downloaded from the link",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2358#issuecomment-1372935932
https://github.com/scverse/scanpy/issues/2359#issuecomment-1291786208:97,Availability,error,error,97,"Honestly a bit lost elsewise. Think that what is shown above is only a Numba warning, but not an error. Not sure what kills the kernel... Anybody else has an idea @scverse/scanpy ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359#issuecomment-1291786208
https://github.com/scverse/scanpy/issues/2359#issuecomment-1291812216:95,Integrability,depend,dependency,95,"@Brycealong could you also try this in a new isolated environment, please? There might be some dependency that's interfering. Would be glad to know which one, but it's tricky...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359#issuecomment-1291812216
https://github.com/scverse/scanpy/issues/2359#issuecomment-1298073650:97,Integrability,depend,dependency,97,"> @Brycealong could you also try this in a new isolated environment, please? There might be some dependency that's interfering. Would be glad to know which one, but it's tricky... Ofc. I can run the code on google colab and i'm stick to that. I think there's something interferring the process in my own computer...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359#issuecomment-1298073650
https://github.com/scverse/scanpy/issues/2359#issuecomment-1345470076:151,Deployability,install,installation,151,"Has anyone found a solution for this? I run into segfault with the same message when trying to run `sc.pp.calculate_qc_metrics` on my M2. Latest clean installation. I have the core dump as well, but I don't know how to get useful information from there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359#issuecomment-1345470076
https://github.com/scverse/scanpy/issues/2359#issuecomment-1345470076:72,Integrability,message,message,72,"Has anyone found a solution for this? I run into segfault with the same message when trying to run `sc.pp.calculate_qc_metrics` on my M2. Latest clean installation. I have the core dump as well, but I don't know how to get useful information from there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359#issuecomment-1345470076
https://github.com/scverse/scanpy/issues/2359#issuecomment-1518690218:11,Deployability,install,installed,11,"I recently installed the [miniforge3](https://github.com/conda-forge/miniforge) distribution on my Apple with M1 and both `sc.pp.neighbors` and `sc.pp.calculate_qc_metrics` work nice and quiet. Not sure if that helps with the issue here, but might be worth a try. ; My versions:; ```; -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.5.0; anndata2ri 1.2.dev11; appnope 0.1.3; asttokens NA; backcall 0.2.0; backports NA; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; colorama 0.4.6; comm 0.1.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; defusedxml 0.7.1; executing 1.2.0; h5py 3.8.0; hypergeom_ufunc NA; igraph 0.10.4; importlib_resources NA; ipykernel 6.22.0; ipython_genutils 0.2.0; ipywidgets 8.0.6; jedi 0.18.2; jinja2 3.1.2; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.39.1; markupsafe 2.1.2; matplotlib 3.7.1; mpl_toolkits NA; natsort 8.3.1; nbinom_ufunc NA; ncf_ufunc NA; numba 0.56.4; numpy 1.22.0; packaging 23.1; pandas 1.2.5; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.2.0; prompt_toolkit 3.0.38; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.15.1; pyparsing 3.0.9; pytz 2023.3; pytz_deprecation_shim NA; rpy2 3.5.11; scipy 1.9.1; scrublet NA; seaborn 0.12.2; session_info 1.0.0; six 1.16.0; sklearn 1.2.2; stack_data 0.6.2; statsmodels 0.13.5; texttable 1.6.7; threadpoolctl 3.1.0; tornado 6.3; traitlets 5.9.0; typing_extensions NA; tzlocal NA; wcwidth 0.2.6; yaml 6.0; zipp NA; zmq 25.0.2; -----; IPython 8.12.0; jupyter_client 8.2.0; jupyter_core 5.3.0; notebook 6.5.4; -----; Python 3.8.16 | packaged by conda-forge | (default, Feb 1 2023, 16:01:13) [Clang 14.0.6 ]; macOS-13.2.1-arm64-arm-64bit; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359#issuecomment-1518690218
https://github.com/scverse/scanpy/issues/2359#issuecomment-1551035497:231,Testability,log,logs,231,"It happened many times on centos os I am using and I have been pulling at my hair. Finally what solved my issue is reinstalling traitlets to 5.9.0, which is apparently critical to operations in jupyter notebook. Reading the output logs of the crashed sessions really helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359#issuecomment-1551035497
https://github.com/scverse/scanpy/issues/2359#issuecomment-1909651108:56,Integrability,depend,dependency,56,"OK, issues like this are almost always either memory or dependency problems: Something’s miscompiled or compiled for the wrong architecture (e.g. a newer CPU than you have) or simply buggy. We have no native code in Scanpy, so we don’t cause segfaults. If there’s anything we can mitigate, we will, if someone demonstrates a reproducible problem with up-to-date dependencies",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359#issuecomment-1909651108
https://github.com/scverse/scanpy/issues/2359#issuecomment-1909651108:362,Integrability,depend,dependencies,362,"OK, issues like this are almost always either memory or dependency problems: Something’s miscompiled or compiled for the wrong architecture (e.g. a newer CPU than you have) or simply buggy. We have no native code in Scanpy, so we don’t cause segfaults. If there’s anything we can mitigate, we will, if someone demonstrates a reproducible problem with up-to-date dependencies",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359#issuecomment-1909651108
https://github.com/scverse/scanpy/issues/2359#issuecomment-1909651108:176,Usability,simpl,simply,176,"OK, issues like this are almost always either memory or dependency problems: Something’s miscompiled or compiled for the wrong architecture (e.g. a newer CPU than you have) or simply buggy. We have no native code in Scanpy, so we don’t cause segfaults. If there’s anything we can mitigate, we will, if someone demonstrates a reproducible problem with up-to-date dependencies",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359#issuecomment-1909651108
https://github.com/scverse/scanpy/issues/2361#issuecomment-1289062735:124,Availability,error,error,124,"I always got a kernel restart when run:. `sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40)`. Also my memory is enough. This error comes from pbmc3k.ipynb file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361#issuecomment-1289062735
https://github.com/scverse/scanpy/issues/2361#issuecomment-1313450128:242,Availability,fault,fault,242,"I have a similar problem. And this does not seam to be related to any python package version as I have 4 data sets loaded from CellRanger h5 files.; With two of these files the neighbors function works and with two it fails with likely a seg fault as a cpp_abort_hook process takes over. This is REALLY annoying as I also get this problem with a random number of different single cell data sets. I assume there is some issue with a dataset that results in a cpp error.; I do not want to debug that as cpp errors are a pain. Can you guess what the problem might be?; The cpp breaks after the multiprocessor step. The Python process has used my 10 processors to the max for some time, but then fallen back to 100%. So it seams it might be after collecting whatever has been produced in the first multiprocessor step.; Can you tell me what that could be so I can implement a test into my scripts? It also probably would be a good idea if you could implement that test into your package. I'll check the two other links, too. If I do not come back here assume both links were not helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361#issuecomment-1313450128
https://github.com/scverse/scanpy/issues/2361#issuecomment-1313450128:462,Availability,error,error,462,"I have a similar problem. And this does not seam to be related to any python package version as I have 4 data sets loaded from CellRanger h5 files.; With two of these files the neighbors function works and with two it fails with likely a seg fault as a cpp_abort_hook process takes over. This is REALLY annoying as I also get this problem with a random number of different single cell data sets. I assume there is some issue with a dataset that results in a cpp error.; I do not want to debug that as cpp errors are a pain. Can you guess what the problem might be?; The cpp breaks after the multiprocessor step. The Python process has used my 10 processors to the max for some time, but then fallen back to 100%. So it seams it might be after collecting whatever has been produced in the first multiprocessor step.; Can you tell me what that could be so I can implement a test into my scripts? It also probably would be a good idea if you could implement that test into your package. I'll check the two other links, too. If I do not come back here assume both links were not helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361#issuecomment-1313450128
https://github.com/scverse/scanpy/issues/2361#issuecomment-1313450128:505,Availability,error,errors,505,"I have a similar problem. And this does not seam to be related to any python package version as I have 4 data sets loaded from CellRanger h5 files.; With two of these files the neighbors function works and with two it fails with likely a seg fault as a cpp_abort_hook process takes over. This is REALLY annoying as I also get this problem with a random number of different single cell data sets. I assume there is some issue with a dataset that results in a cpp error.; I do not want to debug that as cpp errors are a pain. Can you guess what the problem might be?; The cpp breaks after the multiprocessor step. The Python process has used my 10 processors to the max for some time, but then fallen back to 100%. So it seams it might be after collecting whatever has been produced in the first multiprocessor step.; Can you tell me what that could be so I can implement a test into my scripts? It also probably would be a good idea if you could implement that test into your package. I'll check the two other links, too. If I do not come back here assume both links were not helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361#issuecomment-1313450128
https://github.com/scverse/scanpy/issues/2361#issuecomment-1313450128:115,Performance,load,loaded,115,"I have a similar problem. And this does not seam to be related to any python package version as I have 4 data sets loaded from CellRanger h5 files.; With two of these files the neighbors function works and with two it fails with likely a seg fault as a cpp_abort_hook process takes over. This is REALLY annoying as I also get this problem with a random number of different single cell data sets. I assume there is some issue with a dataset that results in a cpp error.; I do not want to debug that as cpp errors are a pain. Can you guess what the problem might be?; The cpp breaks after the multiprocessor step. The Python process has used my 10 processors to the max for some time, but then fallen back to 100%. So it seams it might be after collecting whatever has been produced in the first multiprocessor step.; Can you tell me what that could be so I can implement a test into my scripts? It also probably would be a good idea if you could implement that test into your package. I'll check the two other links, too. If I do not come back here assume both links were not helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361#issuecomment-1313450128
https://github.com/scverse/scanpy/issues/2361#issuecomment-1313450128:872,Testability,test,test,872,"I have a similar problem. And this does not seam to be related to any python package version as I have 4 data sets loaded from CellRanger h5 files.; With two of these files the neighbors function works and with two it fails with likely a seg fault as a cpp_abort_hook process takes over. This is REALLY annoying as I also get this problem with a random number of different single cell data sets. I assume there is some issue with a dataset that results in a cpp error.; I do not want to debug that as cpp errors are a pain. Can you guess what the problem might be?; The cpp breaks after the multiprocessor step. The Python process has used my 10 processors to the max for some time, but then fallen back to 100%. So it seams it might be after collecting whatever has been produced in the first multiprocessor step.; Can you tell me what that could be so I can implement a test into my scripts? It also probably would be a good idea if you could implement that test into your package. I'll check the two other links, too. If I do not come back here assume both links were not helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361#issuecomment-1313450128
https://github.com/scverse/scanpy/issues/2361#issuecomment-1313450128:960,Testability,test,test,960,"I have a similar problem. And this does not seam to be related to any python package version as I have 4 data sets loaded from CellRanger h5 files.; With two of these files the neighbors function works and with two it fails with likely a seg fault as a cpp_abort_hook process takes over. This is REALLY annoying as I also get this problem with a random number of different single cell data sets. I assume there is some issue with a dataset that results in a cpp error.; I do not want to debug that as cpp errors are a pain. Can you guess what the problem might be?; The cpp breaks after the multiprocessor step. The Python process has used my 10 processors to the max for some time, but then fallen back to 100%. So it seams it might be after collecting whatever has been produced in the first multiprocessor step.; Can you tell me what that could be so I can implement a test into my scripts? It also probably would be a good idea if you could implement that test into your package. I'll check the two other links, too. If I do not come back here assume both links were not helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361#issuecomment-1313450128
https://github.com/scverse/scanpy/issues/2361#issuecomment-1313461261:367,Availability,fault,fault,367,"As expected the two other links here were of no use.; I also replictaed the problem in Python (not Jupyter) and get this unhepful message:. scanpy.pp.neighbors(adatas[1]); WARNING: You\u2019re trying to run this on 19151 dimensions of `.X`, if you really want this, set `use_rep='X'`.; Falling back to preprocessing with `sc.pp.pca` and default params.; Segmentation fault (core dumped). I know cpp is like this. But I can not even find the core.dump anywhere. Please help!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361#issuecomment-1313461261
https://github.com/scverse/scanpy/issues/2361#issuecomment-1313461261:130,Integrability,message,message,130,"As expected the two other links here were of no use.; I also replictaed the problem in Python (not Jupyter) and get this unhepful message:. scanpy.pp.neighbors(adatas[1]); WARNING: You\u2019re trying to run this on 19151 dimensions of `.X`, if you really want this, set `use_rep='X'`.; Falling back to preprocessing with `sc.pp.pca` and default params.; Segmentation fault (core dumped). I know cpp is like this. But I can not even find the core.dump anywhere. Please help!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361#issuecomment-1313461261
https://github.com/scverse/scanpy/issues/2361#issuecomment-1426965264:173,Availability,fault,fault,173,I'm having the same issue using pp.neighbors for a slightly different clustering purpose. It seems to handle ~200k data points just fine but above ~300k gives `Segmentation fault (core dumped)` no matter how much memory I allocate to the job. ; The quick fix with threads above did not work for me.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361#issuecomment-1426965264
https://github.com/scverse/scanpy/issues/2361#issuecomment-1426965264:222,Energy Efficiency,allocate,allocate,222,I'm having the same issue using pp.neighbors for a slightly different clustering purpose. It seems to handle ~200k data points just fine but above ~300k gives `Segmentation fault (core dumped)` no matter how much memory I allocate to the job. ; The quick fix with threads above did not work for me.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361#issuecomment-1426965264
https://github.com/scverse/scanpy/issues/2361#issuecomment-1909658183:566,Availability,error,error,566,"OK, as I wrote here: https://github.com/scverse/scanpy/issues/2359#issuecomment-1909651108. > We have no native code in Scanpy, so we don’t cause segfaults. If there’s anything we can mitigate, we will, if someone demonstrates a reproducible problem with up-to-date dependencies. Reinstalling your environment often helps. If not, please give us a way to completely reproduce this just from copyable code, i.e. . 1. a lockfile (environment.yaml or requirements.txt) containing the exact versions of everything in your environment; 2. a block of code that throws the error when run in that environment (code should download the data necessary to reproduce the issue). Then we can help",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361#issuecomment-1909658183
https://github.com/scverse/scanpy/issues/2361#issuecomment-1909658183:614,Availability,down,download,614,"OK, as I wrote here: https://github.com/scverse/scanpy/issues/2359#issuecomment-1909651108. > We have no native code in Scanpy, so we don’t cause segfaults. If there’s anything we can mitigate, we will, if someone demonstrates a reproducible problem with up-to-date dependencies. Reinstalling your environment often helps. If not, please give us a way to completely reproduce this just from copyable code, i.e. . 1. a lockfile (environment.yaml or requirements.txt) containing the exact versions of everything in your environment; 2. a block of code that throws the error when run in that environment (code should download the data necessary to reproduce the issue). Then we can help",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361#issuecomment-1909658183
https://github.com/scverse/scanpy/issues/2361#issuecomment-1909658183:266,Integrability,depend,dependencies,266,"OK, as I wrote here: https://github.com/scverse/scanpy/issues/2359#issuecomment-1909651108. > We have no native code in Scanpy, so we don’t cause segfaults. If there’s anything we can mitigate, we will, if someone demonstrates a reproducible problem with up-to-date dependencies. Reinstalling your environment often helps. If not, please give us a way to completely reproduce this just from copyable code, i.e. . 1. a lockfile (environment.yaml or requirements.txt) containing the exact versions of everything in your environment; 2. a block of code that throws the error when run in that environment (code should download the data necessary to reproduce the issue). Then we can help",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361#issuecomment-1909658183
https://github.com/scverse/scanpy/issues/2361#issuecomment-1913368683:34,Availability,error,error,34,"Below is code that reproduces the error. What I've already tried is 1) updating all the packages 2) reverting to the versions I had prior and 3) creating a new virtual environment and reinstalling everything. None of them worked. . ```; # import libraries; import numpy as np; import pandas as pd; import scanpy as sc; import scvelo as scv; # download data; adata = scv.datasets.pancreas(); # preprocess ; sc.pp.filter_cells(adata, min_counts=200); sc.pp.filter_genes(adata, min_cells=10); adata.raw = adata; sc.pp.highly_variable_genes(; adata, ; n_top_genes=3000, ; flavor='seurat_v3', ; subset=True; ); sc.tl.pca(adata); # find neighbors -- this is the bit that errors; sc.pp.neighbors(; adata, ; n_neighbors=20,; n_pcs=30, ; metric='cosine', ; random_state=312; ); ```. The error is below: . ```; OMP: info #276: omp_set_nested_routine is deprecated, please use omp_set_max_active_levels instead. ; ```; The output of `pip freeze` detailing all of my package versions is attached. My Python version is 3.11.6, and I'm using a 2020 Intel MacBook Pro running Sonoma v14.3. ; [requirements.txt](https://github.com/scverse/scanpy/files/14074316/requirements.txt)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361#issuecomment-1913368683
https://github.com/scverse/scanpy/issues/2361#issuecomment-1913368683:343,Availability,down,download,343,"Below is code that reproduces the error. What I've already tried is 1) updating all the packages 2) reverting to the versions I had prior and 3) creating a new virtual environment and reinstalling everything. None of them worked. . ```; # import libraries; import numpy as np; import pandas as pd; import scanpy as sc; import scvelo as scv; # download data; adata = scv.datasets.pancreas(); # preprocess ; sc.pp.filter_cells(adata, min_counts=200); sc.pp.filter_genes(adata, min_cells=10); adata.raw = adata; sc.pp.highly_variable_genes(; adata, ; n_top_genes=3000, ; flavor='seurat_v3', ; subset=True; ); sc.tl.pca(adata); # find neighbors -- this is the bit that errors; sc.pp.neighbors(; adata, ; n_neighbors=20,; n_pcs=30, ; metric='cosine', ; random_state=312; ); ```. The error is below: . ```; OMP: info #276: omp_set_nested_routine is deprecated, please use omp_set_max_active_levels instead. ; ```; The output of `pip freeze` detailing all of my package versions is attached. My Python version is 3.11.6, and I'm using a 2020 Intel MacBook Pro running Sonoma v14.3. ; [requirements.txt](https://github.com/scverse/scanpy/files/14074316/requirements.txt)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361#issuecomment-1913368683
https://github.com/scverse/scanpy/issues/2361#issuecomment-1913368683:665,Availability,error,errors,665,"Below is code that reproduces the error. What I've already tried is 1) updating all the packages 2) reverting to the versions I had prior and 3) creating a new virtual environment and reinstalling everything. None of them worked. . ```; # import libraries; import numpy as np; import pandas as pd; import scanpy as sc; import scvelo as scv; # download data; adata = scv.datasets.pancreas(); # preprocess ; sc.pp.filter_cells(adata, min_counts=200); sc.pp.filter_genes(adata, min_cells=10); adata.raw = adata; sc.pp.highly_variable_genes(; adata, ; n_top_genes=3000, ; flavor='seurat_v3', ; subset=True; ); sc.tl.pca(adata); # find neighbors -- this is the bit that errors; sc.pp.neighbors(; adata, ; n_neighbors=20,; n_pcs=30, ; metric='cosine', ; random_state=312; ); ```. The error is below: . ```; OMP: info #276: omp_set_nested_routine is deprecated, please use omp_set_max_active_levels instead. ; ```; The output of `pip freeze` detailing all of my package versions is attached. My Python version is 3.11.6, and I'm using a 2020 Intel MacBook Pro running Sonoma v14.3. ; [requirements.txt](https://github.com/scverse/scanpy/files/14074316/requirements.txt)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361#issuecomment-1913368683
https://github.com/scverse/scanpy/issues/2361#issuecomment-1913368683:778,Availability,error,error,778,"Below is code that reproduces the error. What I've already tried is 1) updating all the packages 2) reverting to the versions I had prior and 3) creating a new virtual environment and reinstalling everything. None of them worked. . ```; # import libraries; import numpy as np; import pandas as pd; import scanpy as sc; import scvelo as scv; # download data; adata = scv.datasets.pancreas(); # preprocess ; sc.pp.filter_cells(adata, min_counts=200); sc.pp.filter_genes(adata, min_cells=10); adata.raw = adata; sc.pp.highly_variable_genes(; adata, ; n_top_genes=3000, ; flavor='seurat_v3', ; subset=True; ); sc.tl.pca(adata); # find neighbors -- this is the bit that errors; sc.pp.neighbors(; adata, ; n_neighbors=20,; n_pcs=30, ; metric='cosine', ; random_state=312; ); ```. The error is below: . ```; OMP: info #276: omp_set_nested_routine is deprecated, please use omp_set_max_active_levels instead. ; ```; The output of `pip freeze` detailing all of my package versions is attached. My Python version is 3.11.6, and I'm using a 2020 Intel MacBook Pro running Sonoma v14.3. ; [requirements.txt](https://github.com/scverse/scanpy/files/14074316/requirements.txt)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361#issuecomment-1913368683
https://github.com/scverse/scanpy/issues/2361#issuecomment-1944940981:48,Availability,error,error,48,Any update on this ? I'm still getting the same error even with the development version.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361#issuecomment-1944940981
https://github.com/scverse/scanpy/issues/2361#issuecomment-1944940981:4,Deployability,update,update,4,Any update on this ? I'm still getting the same error even with the development version.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361#issuecomment-1944940981
https://github.com/scverse/scanpy/issues/2369#issuecomment-1327933295:110,Deployability,install,installation,110,Same here. I would like to run Scanpy on the latest Python version. Does anyone have an ETA or a way to force installation (at our own risk of course)?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1327933295
https://github.com/scverse/scanpy/issues/2369#issuecomment-1327933295:135,Safety,risk,risk,135,Same here. I would like to run Scanpy on the latest Python version. Does anyone have an ETA or a way to force installation (at our own risk of course)?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1327933295
https://github.com/scverse/scanpy/issues/2369#issuecomment-1331976462:233,Deployability,install,install,233,"What do you mean? Scanpy’s metadata only specifies a lower Python version bound:. https://github.com/scverse/scanpy/blob/d7e13025b931ad4afd03b4344ef5ff4a46f78b2b/pyproject.toml#L13. Which of the following is it?. - Does it refuse to install because some dependency is not Python 3.11 compatible?; - Does it crash when run there?; - Something else?. I assume it’s just that numba is incompatible still (which will always be a recurring problem as long as we depend on it), but please let me know. With installation issues, you can always run `pip -vv install scanpy` to get much more output that could be helpful. Please [use code blocks](https://docs.github.com/en/get-started/writing-on-github/working-with-advanced-formatting/creating-and-highlighting-code-blocks) when including it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1331976462
https://github.com/scverse/scanpy/issues/2369#issuecomment-1331976462:501,Deployability,install,installation,501,"What do you mean? Scanpy’s metadata only specifies a lower Python version bound:. https://github.com/scverse/scanpy/blob/d7e13025b931ad4afd03b4344ef5ff4a46f78b2b/pyproject.toml#L13. Which of the following is it?. - Does it refuse to install because some dependency is not Python 3.11 compatible?; - Does it crash when run there?; - Something else?. I assume it’s just that numba is incompatible still (which will always be a recurring problem as long as we depend on it), but please let me know. With installation issues, you can always run `pip -vv install scanpy` to get much more output that could be helpful. Please [use code blocks](https://docs.github.com/en/get-started/writing-on-github/working-with-advanced-formatting/creating-and-highlighting-code-blocks) when including it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1331976462
https://github.com/scverse/scanpy/issues/2369#issuecomment-1331976462:550,Deployability,install,install,550,"What do you mean? Scanpy’s metadata only specifies a lower Python version bound:. https://github.com/scverse/scanpy/blob/d7e13025b931ad4afd03b4344ef5ff4a46f78b2b/pyproject.toml#L13. Which of the following is it?. - Does it refuse to install because some dependency is not Python 3.11 compatible?; - Does it crash when run there?; - Something else?. I assume it’s just that numba is incompatible still (which will always be a recurring problem as long as we depend on it), but please let me know. With installation issues, you can always run `pip -vv install scanpy` to get much more output that could be helpful. Please [use code blocks](https://docs.github.com/en/get-started/writing-on-github/working-with-advanced-formatting/creating-and-highlighting-code-blocks) when including it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1331976462
https://github.com/scverse/scanpy/issues/2369#issuecomment-1331976462:254,Integrability,depend,dependency,254,"What do you mean? Scanpy’s metadata only specifies a lower Python version bound:. https://github.com/scverse/scanpy/blob/d7e13025b931ad4afd03b4344ef5ff4a46f78b2b/pyproject.toml#L13. Which of the following is it?. - Does it refuse to install because some dependency is not Python 3.11 compatible?; - Does it crash when run there?; - Something else?. I assume it’s just that numba is incompatible still (which will always be a recurring problem as long as we depend on it), but please let me know. With installation issues, you can always run `pip -vv install scanpy` to get much more output that could be helpful. Please [use code blocks](https://docs.github.com/en/get-started/writing-on-github/working-with-advanced-formatting/creating-and-highlighting-code-blocks) when including it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1331976462
https://github.com/scverse/scanpy/issues/2369#issuecomment-1331976462:457,Integrability,depend,depend,457,"What do you mean? Scanpy’s metadata only specifies a lower Python version bound:. https://github.com/scverse/scanpy/blob/d7e13025b931ad4afd03b4344ef5ff4a46f78b2b/pyproject.toml#L13. Which of the following is it?. - Does it refuse to install because some dependency is not Python 3.11 compatible?; - Does it crash when run there?; - Something else?. I assume it’s just that numba is incompatible still (which will always be a recurring problem as long as we depend on it), but please let me know. With installation issues, you can always run `pip -vv install scanpy` to get much more output that could be helpful. Please [use code blocks](https://docs.github.com/en/get-started/writing-on-github/working-with-advanced-formatting/creating-and-highlighting-code-blocks) when including it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1331976462
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:188,Availability,error,error,188,"The problem is that it does not install at all. ; When I run; ```; conda create -n test; conda activate test; conda install python=3.11; conda install -c conda-forge scanpy; ```; I get an error output for the last line, which is:; ```; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0; - feature:|@/osx-64::__osx==10.16=0; - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16; ```. Repeating this with python=3.10 does not give an error.; Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```; Collecting numba>=0.41.0; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod; Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache; Current age based on date: 1302943; Ignoring unknown cache-control directive: immutable; Freshness lifetime from max-age: 365000000; The response is ""fresh"", returning cached response; 365000000 > 1302943; Using cached numba-0.56.4.tar.gz (2.4 MB); Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'; Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:489,Availability,Avail,Available,489,"The problem is that it does not install at all. ; When I run; ```; conda create -n test; conda activate test; conda install python=3.11; conda install -c conda-forge scanpy; ```; I get an error output for the last line, which is:; ```; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0; - feature:|@/osx-64::__osx==10.16=0; - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16; ```. Repeating this with python=3.10 does not give an error.; Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```; Collecting numba>=0.41.0; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod; Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache; Current age based on date: 1302943; Ignoring unknown cache-control directive: immutable; Freshness lifetime from max-age: 365000000; The response is ""fresh"", returning cached response; 365000000 > 1302943; Using cached numba-0.56.4.tar.gz (2.4 MB); Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'; Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:819,Availability,error,error,819,"The problem is that it does not install at all. ; When I run; ```; conda create -n test; conda activate test; conda install python=3.11; conda install -c conda-forge scanpy; ```; I get an error output for the last line, which is:; ```; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0; - feature:|@/osx-64::__osx==10.16=0; - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16; ```. Repeating this with python=3.10 does not give an error.; Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```; Collecting numba>=0.41.0; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod; Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache; Current age based on date: 1302943; Ignoring unknown cache-control directive: immutable; Freshness lifetime from max-age: 365000000; The response is ""fresh"", returning cached response; 365000000 > 1302943; Using cached numba-0.56.4.tar.gz (2.4 MB); Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'; Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:907,Availability,error,error,907,"The problem is that it does not install at all. ; When I run; ```; conda create -n test; conda activate test; conda install python=3.11; conda install -c conda-forge scanpy; ```; I get an error output for the last line, which is:; ```; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0; - feature:|@/osx-64::__osx==10.16=0; - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16; ```. Repeating this with python=3.10 does not give an error.; Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```; Collecting numba>=0.41.0; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod; Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache; Current age based on date: 1302943; Ignoring unknown cache-control directive: immutable; Freshness lifetime from max-age: 365000000; The response is ""fresh"", returning cached response; 365000000 > 1302943; Using cached numba-0.56.4.tar.gz (2.4 MB); Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'; Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:2686,Availability,error,error,2686,"-build-tracker-740xp5sy'; Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q; Running command python setup.py egg_info; Traceback (most recent call last):; File ""<string>"", line 2, in <module>; File ""<pip-setuptools-caller>"", line 34, in <module>; File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>; _guard_py_ver(); File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver; raise RuntimeError(msg.format(cur_py, min_py, max_py)); RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported.; error: subprocess-exited-with-error; ; × python setup.py egg_info did not run successfully.; │ exit code: 1; ╰─> See above for output.; ; note: This error originates from a subprocess, and is likely not a problem with pip.; full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '; exec(compile('""'""''""'""''""'""'; # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py; #; # - It imports setuptools before invoking setup.py, to enable projects that directly; # import from `distutils.core` to work with newer packaging standards.; # - It provides a clear error message when setuptools is not installed.; # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so; # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:; # manifest_maker: standard file '""'""'-c'""'""' not found"".; # - It generates a shim setup.py, for handling setup.cfg-only projects.; import os, sys, tokenize; ; try:; import setuptools; except ImportError as error:; pr",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:2716,Availability,error,error,2716,"-build-tracker-740xp5sy'; Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q; Running command python setup.py egg_info; Traceback (most recent call last):; File ""<string>"", line 2, in <module>; File ""<pip-setuptools-caller>"", line 34, in <module>; File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>; _guard_py_ver(); File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver; raise RuntimeError(msg.format(cur_py, min_py, max_py)); RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported.; error: subprocess-exited-with-error; ; × python setup.py egg_info did not run successfully.; │ exit code: 1; ╰─> See above for output.; ; note: This error originates from a subprocess, and is likely not a problem with pip.; full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '; exec(compile('""'""''""'""''""'""'; # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py; #; # - It imports setuptools before invoking setup.py, to enable projects that directly; # import from `distutils.core` to work with newer packaging standards.; # - It provides a clear error message when setuptools is not installed.; # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so; # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:; # manifest_maker: standard file '""'""'-c'""'""' not found"".; # - It generates a shim setup.py, for handling setup.cfg-only projects.; import os, sys, tokenize; ; try:; import setuptools; except ImportError as error:; pr",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:2835,Availability,error,error,2835,"6f16ee1b89979/setup.py) egg_info for package numba; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q; Running command python setup.py egg_info; Traceback (most recent call last):; File ""<string>"", line 2, in <module>; File ""<pip-setuptools-caller>"", line 34, in <module>; File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>; _guard_py_ver(); File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver; raise RuntimeError(msg.format(cur_py, min_py, max_py)); RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported.; error: subprocess-exited-with-error; ; × python setup.py egg_info did not run successfully.; │ exit code: 1; ╰─> See above for output.; ; note: This error originates from a subprocess, and is likely not a problem with pip.; full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '; exec(compile('""'""''""'""''""'""'; # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py; #; # - It imports setuptools before invoking setup.py, to enable projects that directly; # import from `distutils.core` to work with newer packaging standards.; # - It provides a clear error message when setuptools is not installed.; # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so; # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:; # manifest_maker: standard file '""'""'-c'""'""' not found"".; # - It generates a shim setup.py, for handling setup.cfg-only projects.; import os, sys, tokenize; ; try:; import setuptools; except ImportError as error:; print(; ""ERROR: Can not execute `setup.py` since setuptools is not available in ""; ""the build environment."",; file=sys.stderr,; ); sys.exit(1); ; __file__",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:3275,Availability,error,error,3275,"mba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>; _guard_py_ver(); File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver; raise RuntimeError(msg.format(cur_py, min_py, max_py)); RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported.; error: subprocess-exited-with-error; ; × python setup.py egg_info did not run successfully.; │ exit code: 1; ╰─> See above for output.; ; note: This error originates from a subprocess, and is likely not a problem with pip.; full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '; exec(compile('""'""''""'""''""'""'; # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py; #; # - It imports setuptools before invoking setup.py, to enable projects that directly; # import from `distutils.core` to work with newer packaging standards.; # - It provides a clear error message when setuptools is not installed.; # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so; # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:; # manifest_maker: standard file '""'""'-c'""'""' not found"".; # - It generates a shim setup.py, for handling setup.cfg-only projects.; import os, sys, tokenize; ; try:; import setuptools; except ImportError as error:; print(; ""ERROR: Can not execute `setup.py` since setuptools is not available in ""; ""the build environment."",; file=sys.stderr,; ); sys.exit(1); ; __file__ = %r; sys.argv[0] = __file__; ; if os.path.exists(__file__):; filename = __file__; with tokenize.open(__file__) as f:; setup_py_code = f.read(); else:; filename = ""<auto-generated setuptools caller>""; setup_py_code = ""from setuptools import setup; setup()""; ; exec(compile(setup_py_code, filename, ""exec"")); '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:3702,Availability,error,error,3702,"rror: subprocess-exited-with-error; ; × python setup.py egg_info did not run successfully.; │ exit code: 1; ╰─> See above for output.; ; note: This error originates from a subprocess, and is likely not a problem with pip.; full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '; exec(compile('""'""''""'""''""'""'; # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py; #; # - It imports setuptools before invoking setup.py, to enable projects that directly; # import from `distutils.core` to work with newer packaging standards.; # - It provides a clear error message when setuptools is not installed.; # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so; # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:; # manifest_maker: standard file '""'""'-c'""'""' not found"".; # - It generates a shim setup.py, for handling setup.cfg-only projects.; import os, sys, tokenize; ; try:; import setuptools; except ImportError as error:; print(; ""ERROR: Can not execute `setup.py` since setuptools is not available in ""; ""the build environment."",; file=sys.stderr,; ); sys.exit(1); ; __file__ = %r; sys.argv[0] = __file__; ; if os.path.exists(__file__):; filename = __file__; with tokenize.open(__file__) as f:; setup_py_code = f.read(); else:; filename = ""<auto-generated setuptools caller>""; setup_py_code = ""from setuptools import setup; setup()""; ; exec(compile(setup_py_code, filename, ""exec"")); '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q; cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/; Preparing metadata (setup.py) ... error; error: metadata-generation-failed. × Encountered e",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:3719,Availability,ERROR,ERROR,3719,"rror: subprocess-exited-with-error; ; × python setup.py egg_info did not run successfully.; │ exit code: 1; ╰─> See above for output.; ; note: This error originates from a subprocess, and is likely not a problem with pip.; full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '; exec(compile('""'""''""'""''""'""'; # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py; #; # - It imports setuptools before invoking setup.py, to enable projects that directly; # import from `distutils.core` to work with newer packaging standards.; # - It provides a clear error message when setuptools is not installed.; # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so; # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:; # manifest_maker: standard file '""'""'-c'""'""' not found"".; # - It generates a shim setup.py, for handling setup.cfg-only projects.; import os, sys, tokenize; ; try:; import setuptools; except ImportError as error:; print(; ""ERROR: Can not execute `setup.py` since setuptools is not available in ""; ""the build environment."",; file=sys.stderr,; ); sys.exit(1); ; __file__ = %r; sys.argv[0] = __file__; ; if os.path.exists(__file__):; filename = __file__; with tokenize.open(__file__) as f:; setup_py_code = f.read(); else:; filename = ""<auto-generated setuptools caller>""; setup_py_code = ""from setuptools import setup; setup()""; ; exec(compile(setup_py_code, filename, ""exec"")); '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q; cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/; Preparing metadata (setup.py) ... error; error: metadata-generation-failed. × Encountered e",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:3777,Availability,avail,available,3777,"xit code: 1; ╰─> See above for output.; ; note: This error originates from a subprocess, and is likely not a problem with pip.; full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '; exec(compile('""'""''""'""''""'""'; # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py; #; # - It imports setuptools before invoking setup.py, to enable projects that directly; # import from `distutils.core` to work with newer packaging standards.; # - It provides a clear error message when setuptools is not installed.; # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so; # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:; # manifest_maker: standard file '""'""'-c'""'""' not found"".; # - It generates a shim setup.py, for handling setup.cfg-only projects.; import os, sys, tokenize; ; try:; import setuptools; except ImportError as error:; print(; ""ERROR: Can not execute `setup.py` since setuptools is not available in ""; ""the build environment."",; file=sys.stderr,; ); sys.exit(1); ; __file__ = %r; sys.argv[0] = __file__; ; if os.path.exists(__file__):; filename = __file__; with tokenize.open(__file__) as f:; setup_py_code = f.read(); else:; filename = ""<auto-generated setuptools caller>""; setup_py_code = ""from setuptools import setup; setup()""; ; exec(compile(setup_py_code, filename, ""exec"")); '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q; cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/; Preparing metadata (setup.py) ... error; error: metadata-generation-failed. × Encountered error while generating package metadata.; ╰─> See above for output. note: This is an issue with t",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:4630,Availability,error,error,4630,"e; ; try:; import setuptools; except ImportError as error:; print(; ""ERROR: Can not execute `setup.py` since setuptools is not available in ""; ""the build environment."",; file=sys.stderr,; ); sys.exit(1); ; __file__ = %r; sys.argv[0] = __file__; ; if os.path.exists(__file__):; filename = __file__; with tokenize.open(__file__) as f:; setup_py_code = f.read(); else:; filename = ""<auto-generated setuptools caller>""; setup_py_code = ""from setuptools import setup; setup()""; ; exec(compile(setup_py_code, filename, ""exec"")); '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q; cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/; Preparing metadata (setup.py) ... error; error: metadata-generation-failed. × Encountered error while generating package metadata.; ╰─> See above for output. note: This is an issue with the package mentioned above, not pip.; hint: See above for details.; Exception information:; Traceback (most recent call last):; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata; call_subprocess(; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess; raise error; pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper; status = run_func(*args); ^^^^^^^^^^^^^^^; File ""/Users/dang/opt/minic",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:4637,Availability,error,error,4637,"e; ; try:; import setuptools; except ImportError as error:; print(; ""ERROR: Can not execute `setup.py` since setuptools is not available in ""; ""the build environment."",; file=sys.stderr,; ); sys.exit(1); ; __file__ = %r; sys.argv[0] = __file__; ; if os.path.exists(__file__):; filename = __file__; with tokenize.open(__file__) as f:; setup_py_code = f.read(); else:; filename = ""<auto-generated setuptools caller>""; setup_py_code = ""from setuptools import setup; setup()""; ; exec(compile(setup_py_code, filename, ""exec"")); '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q; cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/; Preparing metadata (setup.py) ... error; error: metadata-generation-failed. × Encountered error while generating package metadata.; ╰─> See above for output. note: This is an issue with the package mentioned above, not pip.; hint: See above for details.; Exception information:; Traceback (most recent call last):; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata; call_subprocess(; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess; raise error; pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper; status = run_func(*args); ^^^^^^^^^^^^^^^; File ""/Users/dang/opt/minic",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:4686,Availability,error,error,4686," as error:; print(; ""ERROR: Can not execute `setup.py` since setuptools is not available in ""; ""the build environment."",; file=sys.stderr,; ); sys.exit(1); ; __file__ = %r; sys.argv[0] = __file__; ; if os.path.exists(__file__):; filename = __file__; with tokenize.open(__file__) as f:; setup_py_code = f.read(); else:; filename = ""<auto-generated setuptools caller>""; setup_py_code = ""from setuptools import setup; setup()""; ; exec(compile(setup_py_code, filename, ""exec"")); '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q; cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/; Preparing metadata (setup.py) ... error; error: metadata-generation-failed. × Encountered error while generating package metadata.; ╰─> See above for output. note: This is an issue with the package mentioned above, not pip.; hint: See above for details.; Exception information:; Traceback (most recent call last):; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata; call_subprocess(; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess; raise error; pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper; status = run_func(*args); ^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:5230,Availability,error,error,5230,"rs/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q; cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/; Preparing metadata (setup.py) ... error; error: metadata-generation-failed. × Encountered error while generating package metadata.; ╰─> See above for output. note: This is an issue with the package mentioned above, not pip.; hint: See above for details.; Exception information:; Traceback (most recent call last):; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata; call_subprocess(; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess; raise error; pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper; status = run_func(*args); ^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper; return func(self, options, args); ^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/commands/install.py"", line 400, in run; requirement_set = resolver.resolve(; ^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py"", line 92, in resolve; result = self._result = resolver.resolve(; ^^^^^^^^^^^^^^^^^; File ""/Users",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:10564,Availability,error,error,10564,"e_linked_requirement(self._ireq, parallel_builds=True); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement; return self._prepare_linked_requirement(req, parallel_builds); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 577, in _prepare_linked_requirement; dist = _get_prepared_distribution(; ^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 69, in _get_prepared_distribution; abstract_dist.prepare_distribution_metadata(; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/distributions/sdist.py"", line 61, in prepare_distribution_metadata; self.req.prepare_metadata(); File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/req/req_install.py"", line 541, in prepare_metadata; self.metadata_directory = generate_metadata_legacy(; ^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 71, in generate_metadata; raise MetadataGenerationFailed(package_details=details) from error; pip._internal.exceptions.MetadataGenerationFailed: metadata generation failed; Remote version of pip: 22.3.1; Local version of pip: 22.3.1; Was pip installed by pip? False; Removed numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) from build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'; Removed build tracker: '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:32,Deployability,install,install,32,"The problem is that it does not install at all. ; When I run; ```; conda create -n test; conda activate test; conda install python=3.11; conda install -c conda-forge scanpy; ```; I get an error output for the last line, which is:; ```; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0; - feature:|@/osx-64::__osx==10.16=0; - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16; ```. Repeating this with python=3.10 does not give an error.; Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```; Collecting numba>=0.41.0; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod; Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache; Current age based on date: 1302943; Ignoring unknown cache-control directive: immutable; Freshness lifetime from max-age: 365000000; The response is ""fresh"", returning cached response; 365000000 > 1302943; Using cached numba-0.56.4.tar.gz (2.4 MB); Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'; Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:116,Deployability,install,install,116,"The problem is that it does not install at all. ; When I run; ```; conda create -n test; conda activate test; conda install python=3.11; conda install -c conda-forge scanpy; ```; I get an error output for the last line, which is:; ```; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0; - feature:|@/osx-64::__osx==10.16=0; - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16; ```. Repeating this with python=3.10 does not give an error.; Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```; Collecting numba>=0.41.0; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod; Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache; Current age based on date: 1302943; Ignoring unknown cache-control directive: immutable; Freshness lifetime from max-age: 365000000; The response is ""fresh"", returning cached response; 365000000 > 1302943; Using cached numba-0.56.4.tar.gz (2.4 MB); Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'; Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:143,Deployability,install,install,143,"The problem is that it does not install at all. ; When I run; ```; conda create -n test; conda activate test; conda install python=3.11; conda install -c conda-forge scanpy; ```; I get an error output for the last line, which is:; ```; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0; - feature:|@/osx-64::__osx==10.16=0; - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16; ```. Repeating this with python=3.10 does not give an error.; Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```; Collecting numba>=0.41.0; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod; Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache; Current age based on date: 1302943; Ignoring unknown cache-control directive: immutable; Freshness lifetime from max-age: 365000000; The response is ""fresh"", returning cached response; 365000000 > 1302943; Using cached numba-0.56.4.tar.gz (2.4 MB); Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'; Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:736,Deployability,install,installed,736,"The problem is that it does not install at all. ; When I run; ```; conda create -n test; conda activate test; conda install python=3.11; conda install -c conda-forge scanpy; ```; I get an error output for the last line, which is:; ```; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0; - feature:|@/osx-64::__osx==10.16=0; - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16; ```. Repeating this with python=3.10 does not give an error.; Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```; Collecting numba>=0.41.0; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod; Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache; Current age based on date: 1302943; Ignoring unknown cache-control directive: immutable; Freshness lifetime from max-age: 365000000; The response is ""fresh"", returning cached response; 365000000 > 1302943; Using cached numba-0.56.4.tar.gz (2.4 MB); Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'; Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:856,Deployability,install,install,856,"The problem is that it does not install at all. ; When I run; ```; conda create -n test; conda activate test; conda install python=3.11; conda install -c conda-forge scanpy; ```; I get an error output for the last line, which is:; ```; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0; - feature:|@/osx-64::__osx==10.16=0; - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16; ```. Repeating this with python=3.10 does not give an error.; Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```; Collecting numba>=0.41.0; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod; Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache; Current age based on date: 1302943; Ignoring unknown cache-control directive: immutable; Freshness lifetime from max-age: 365000000; The response is ""fresh"", returning cached response; 365000000 > 1302943; Using cached numba-0.56.4.tar.gz (2.4 MB); Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'; Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:1822,Deployability,install,install-,1822," error.; Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```; Collecting numba>=0.41.0; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod; Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache; Current age based on date: 1302943; Ignoring unknown cache-control directive: immutable; Freshness lifetime from max-age: 365000000; The response is ""fresh"", returning cached response; 365000000 > 1302943; Using cached numba-0.56.4.tar.gz (2.4 MB); Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'; Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q; Running command python setup.py egg_info; Traceback (most recent call last):; File ""<string>"", line 2, in <module>; File ""<pip-setuptools-caller>"", line 34, in <module>; File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>; _guard_py_ver(); File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver; raise RuntimeError(msg.format(cur_py, min_py, max_py)); RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported.; error: subprocess-exited-with-error; ; × python setup.py egg_info did not run successfully.; │ exit code: 1; ╰─> See above for outpu",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:2266,Deployability,install,install-,2266,"6.4.tar.gz"" in the cache; Current age based on date: 1302943; Ignoring unknown cache-control directive: immutable; Freshness lifetime from max-age: 365000000; The response is ""fresh"", returning cached response; 365000000 > 1302943; Using cached numba-0.56.4.tar.gz (2.4 MB); Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'; Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q; Running command python setup.py egg_info; Traceback (most recent call last):; File ""<string>"", line 2, in <module>; File ""<pip-setuptools-caller>"", line 34, in <module>; File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>; _guard_py_ver(); File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver; raise RuntimeError(msg.format(cur_py, min_py, max_py)); RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported.; error: subprocess-exited-with-error; ; × python setup.py egg_info did not run successfully.; │ exit code: 1; ╰─> See above for output.; ; note: This error originates from a subprocess, and is likely not a problem with pip.; full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '; exec(compile('""'""''""'""''""'""'; # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py; #; # - It imports setuptools before invoking setup.py, to enable projects that directly; # import from ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:2439,Deployability,install,install-,2439,"> 1302943; Using cached numba-0.56.4.tar.gz (2.4 MB); Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'; Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q; Running command python setup.py egg_info; Traceback (most recent call last):; File ""<string>"", line 2, in <module>; File ""<pip-setuptools-caller>"", line 34, in <module>; File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>; _guard_py_ver(); File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver; raise RuntimeError(msg.format(cur_py, min_py, max_py)); RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported.; error: subprocess-exited-with-error; ; × python setup.py egg_info did not run successfully.; │ exit code: 1; ╰─> See above for output.; ; note: This error originates from a subprocess, and is likely not a problem with pip.; full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '; exec(compile('""'""''""'""''""'""'; # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py; #; # - It imports setuptools before invoking setup.py, to enable projects that directly; # import from `distutils.core` to work with newer packaging standards.; # - It provides a clear error message when setuptools is not installed.; # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so; # setu",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:2610,Deployability,install,install,2610,"4f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'; Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q; Running command python setup.py egg_info; Traceback (most recent call last):; File ""<string>"", line 2, in <module>; File ""<pip-setuptools-caller>"", line 34, in <module>; File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>; _guard_py_ver(); File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver; raise RuntimeError(msg.format(cur_py, min_py, max_py)); RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported.; error: subprocess-exited-with-error; ; × python setup.py egg_info did not run successfully.; │ exit code: 1; ╰─> See above for output.; ; note: This error originates from a subprocess, and is likely not a problem with pip.; full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '; exec(compile('""'""''""'""''""'""'; # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py; #; # - It imports setuptools before invoking setup.py, to enable projects that directly; # import from `distutils.core` to work with newer packaging standards.; # - It provides a clear error message when setuptools is not installed.; # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so; # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:; # manifest_maker: standard file '""'""'-c'""'""' not found"".; # - It generates a shim setup.py, for handl",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:3312,Deployability,install,installed,3312,"mba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>; _guard_py_ver(); File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver; raise RuntimeError(msg.format(cur_py, min_py, max_py)); RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported.; error: subprocess-exited-with-error; ; × python setup.py egg_info did not run successfully.; │ exit code: 1; ╰─> See above for output.; ; note: This error originates from a subprocess, and is likely not a problem with pip.; full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '; exec(compile('""'""''""'""''""'""'; # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py; #; # - It imports setuptools before invoking setup.py, to enable projects that directly; # import from `distutils.core` to work with newer packaging standards.; # - It provides a clear error message when setuptools is not installed.; # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so; # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:; # manifest_maker: standard file '""'""'-c'""'""' not found"".; # - It generates a shim setup.py, for handling setup.cfg-only projects.; import os, sys, tokenize; ; try:; import setuptools; except ImportError as error:; print(; ""ERROR: Can not execute `setup.py` since setuptools is not available in ""; ""the build environment."",; file=sys.stderr,; ); sys.exit(1); ; __file__ = %r; sys.argv[0] = __file__; ; if os.path.exists(__file__):; filename = __file__; with tokenize.open(__file__) as f:; setup_py_code = f.read(); else:; filename = ""<auto-generated setuptools caller>""; setup_py_code = ""from setuptools import setup; setup()""; ; exec(compile(setup_py_code, filename, ""exec"")); '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:4258,Deployability,install,install-,4258,"ts that directly; # import from `distutils.core` to work with newer packaging standards.; # - It provides a clear error message when setuptools is not installed.; # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so; # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:; # manifest_maker: standard file '""'""'-c'""'""' not found"".; # - It generates a shim setup.py, for handling setup.cfg-only projects.; import os, sys, tokenize; ; try:; import setuptools; except ImportError as error:; print(; ""ERROR: Can not execute `setup.py` since setuptools is not available in ""; ""the build environment."",; file=sys.stderr,; ); sys.exit(1); ; __file__ = %r; sys.argv[0] = __file__; ; if os.path.exists(__file__):; filename = __file__; with tokenize.open(__file__) as f:; setup_py_code = f.read(); else:; filename = ""<auto-generated setuptools caller>""; setup_py_code = ""from setuptools import setup; setup()""; ; exec(compile(setup_py_code, filename, ""exec"")); '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q; cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/; Preparing metadata (setup.py) ... error; error: metadata-generation-failed. × Encountered error while generating package metadata.; ╰─> See above for output. note: This is an issue with the package mentioned above, not pip.; hint: See above for details.; Exception information:; Traceback (most recent call last):; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata; call_subprocess(; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:4538,Deployability,install,install-,4538," the following warning:; # manifest_maker: standard file '""'""'-c'""'""' not found"".; # - It generates a shim setup.py, for handling setup.cfg-only projects.; import os, sys, tokenize; ; try:; import setuptools; except ImportError as error:; print(; ""ERROR: Can not execute `setup.py` since setuptools is not available in ""; ""the build environment."",; file=sys.stderr,; ); sys.exit(1); ; __file__ = %r; sys.argv[0] = __file__; ; if os.path.exists(__file__):; filename = __file__; with tokenize.open(__file__) as f:; setup_py_code = f.read(); else:; filename = ""<auto-generated setuptools caller>""; setup_py_code = ""from setuptools import setup; setup()""; ; exec(compile(setup_py_code, filename, ""exec"")); '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q; cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/; Preparing metadata (setup.py) ... error; error: metadata-generation-failed. × Encountered error while generating package metadata.; ╰─> See above for output. note: This is an issue with the package mentioned above, not pip.; hint: See above for details.; Exception information:; Traceback (most recent call last):; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata; call_subprocess(; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess; raise error; pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):; File ""/Users/dang/opt/miniconda3/e",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:5262,Deployability,Install,InstallationSubprocessError,5262,"51d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q; cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/; Preparing metadata (setup.py) ... error; error: metadata-generation-failed. × Encountered error while generating package metadata.; ╰─> See above for output. note: This is an issue with the package mentioned above, not pip.; hint: See above for details.; Exception information:; Traceback (most recent call last):; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata; call_subprocess(; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess; raise error; pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper; status = run_func(*args); ^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper; return func(self, options, args); ^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/commands/install.py"", line 400, in run; requirement_set = resolver.resolve(; ^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py"", line 92, in resolve; result = self._result = resolver.resolve(; ^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_ve",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:5910,Deployability,install,install,5910,"ent call last):; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata; call_subprocess(; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess; raise error; pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper; status = run_func(*args); ^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper; return func(self, options, args); ^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/commands/install.py"", line 400, in run; requirement_set = resolver.resolve(; ^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py"", line 92, in resolve; result = self._result = resolver.resolve(; ^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 481, in resolve; state = resolution.resolve(requirements, max_rounds=max_rounds); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 373, in resolve; failure_causes = self._attempt_to_pin_criterion(name); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 213, in _attempt_to_pin_criterion; criteria = self._get_updated_criteria(candidate); ^^^^^^^^^",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:10719,Deployability,install,installed,10719,"e_linked_requirement(self._ireq, parallel_builds=True); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement; return self._prepare_linked_requirement(req, parallel_builds); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 577, in _prepare_linked_requirement; dist = _get_prepared_distribution(; ^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 69, in _get_prepared_distribution; abstract_dist.prepare_distribution_metadata(; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/distributions/sdist.py"", line 61, in prepare_distribution_metadata; self.req.prepare_metadata(); File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/req/req_install.py"", line 541, in prepare_metadata; self.metadata_directory = generate_metadata_legacy(; ^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 71, in generate_metadata; raise MetadataGenerationFailed(package_details=details) from error; pip._internal.exceptions.MetadataGenerationFailed: metadata generation failed; Remote version of pip: 22.3.1; Local version of pip: 22.3.1; Was pip installed by pip? False; Removed numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) from build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'; Removed build tracker: '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:3281,Integrability,message,message,3281,"mba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>; _guard_py_ver(); File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver; raise RuntimeError(msg.format(cur_py, min_py, max_py)); RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported.; error: subprocess-exited-with-error; ; × python setup.py egg_info did not run successfully.; │ exit code: 1; ╰─> See above for output.; ; note: This error originates from a subprocess, and is likely not a problem with pip.; full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '; exec(compile('""'""''""'""''""'""'; # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py; #; # - It imports setuptools before invoking setup.py, to enable projects that directly; # import from `distutils.core` to work with newer packaging standards.; # - It provides a clear error message when setuptools is not installed.; # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so; # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:; # manifest_maker: standard file '""'""'-c'""'""' not found"".; # - It generates a shim setup.py, for handling setup.cfg-only projects.; import os, sys, tokenize; ; try:; import setuptools; except ImportError as error:; print(; ""ERROR: Can not execute `setup.py` since setuptools is not available in ""; ""the build environment."",; file=sys.stderr,; ); sys.exit(1); ; __file__ = %r; sys.argv[0] = __file__; ; if os.path.exists(__file__):; filename = __file__; with tokenize.open(__file__) as f:; setup_py_code = f.read(); else:; filename = ""<auto-generated setuptools caller>""; setup_py_code = ""from setuptools import setup; setup()""; ; exec(compile(setup_py_code, filename, ""exec"")); '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:5744,Integrability,wrap,wrapper,5744,"ioned above, not pip.; hint: See above for details.; Exception information:; Traceback (most recent call last):; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata; call_subprocess(; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess; raise error; pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper; status = run_func(*args); ^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper; return func(self, options, args); ^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/commands/install.py"", line 400, in run; requirement_set = resolver.resolve(; ^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py"", line 92, in resolve; result = self._result = resolver.resolve(; ^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 481, in resolve; state = resolution.resolve(requirements, max_rounds=max_rounds); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 373, in resolve; failure_causes = self._attempt_to_pin_criterion(name); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", lin",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:1212,Performance,cache,cache,1212,"ss CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0; - feature:|@/osx-64::__osx==10.16=0; - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16; ```. Repeating this with python=3.10 does not give an error.; Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```; Collecting numba>=0.41.0; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod; Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache; Current age based on date: 1302943; Ignoring unknown cache-control directive: immutable; Freshness lifetime from max-age: 365000000; The response is ""fresh"", returning cached response; 365000000 > 1302943; Using cached numba-0.56.4.tar.gz (2.4 MB); Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'; Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q; Running command python setup.py egg_info; Traceback (most recent call last):; File ""<string>"", line 2, in <module>; File ""<pip-setuptools-caller>"", line 34, in <module>; File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/se",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:1272,Performance,cache,cache-control,1272,"ss CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0; - feature:|@/osx-64::__osx==10.16=0; - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16; ```. Repeating this with python=3.10 does not give an error.; Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```; Collecting numba>=0.41.0; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod; Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache; Current age based on date: 1302943; Ignoring unknown cache-control directive: immutable; Freshness lifetime from max-age: 365000000; The response is ""fresh"", returning cached response; 365000000 > 1302943; Using cached numba-0.56.4.tar.gz (2.4 MB); Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'; Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q; Running command python setup.py egg_info; Traceback (most recent call last):; File ""<string>"", line 2, in <module>; File ""<pip-setuptools-caller>"", line 34, in <module>; File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/se",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:1387,Performance,cache,cached,1387,"ss CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0; - feature:|@/osx-64::__osx==10.16=0; - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16; ```. Repeating this with python=3.10 does not give an error.; Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```; Collecting numba>=0.41.0; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod; Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache; Current age based on date: 1302943; Ignoring unknown cache-control directive: immutable; Freshness lifetime from max-age: 365000000; The response is ""fresh"", returning cached response; 365000000 > 1302943; Using cached numba-0.56.4.tar.gz (2.4 MB); Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'; Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q; Running command python setup.py egg_info; Traceback (most recent call last):; File ""<string>"", line 2, in <module>; File ""<pip-setuptools-caller>"", line 34, in <module>; File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/se",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:1431,Performance,cache,cached,1431,"ss CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0; - feature:|@/osx-64::__osx==10.16=0; - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16; ```. Repeating this with python=3.10 does not give an error.; Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```; Collecting numba>=0.41.0; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod; Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache; Current age based on date: 1302943; Ignoring unknown cache-control directive: immutable; Freshness lifetime from max-age: 365000000; The response is ""fresh"", returning cached response; 365000000 > 1302943; Using cached numba-0.56.4.tar.gz (2.4 MB); Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'; Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q; Running command python setup.py egg_info; Traceback (most recent call last):; File ""<string>"", line 2, in <module>; File ""<pip-setuptools-caller>"", line 34, in <module>; File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/se",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:336,Safety,abort,abort,336,"The problem is that it does not install at all. ; When I run; ```; conda create -n test; conda activate test; conda install python=3.11; conda install -c conda-forge scanpy; ```; I get an error output for the last line, which is:; ```; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0; - feature:|@/osx-64::__osx==10.16=0; - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16; ```. Repeating this with python=3.10 does not give an error.; Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```; Collecting numba>=0.41.0; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod; Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache; Current age based on date: 1302943; Ignoring unknown cache-control directive: immutable; Freshness lifetime from max-age: 365000000; The response is ""fresh"", returning cached response; 365000000 > 1302943; Using cached numba-0.56.4.tar.gz (2.4 MB); Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'; Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:3465,Safety,avoid,avoids,3465," line 48, in _guard_py_ver; raise RuntimeError(msg.format(cur_py, min_py, max_py)); RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported.; error: subprocess-exited-with-error; ; × python setup.py egg_info did not run successfully.; │ exit code: 1; ╰─> See above for output.; ; note: This error originates from a subprocess, and is likely not a problem with pip.; full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '; exec(compile('""'""''""'""''""'""'; # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py; #; # - It imports setuptools before invoking setup.py, to enable projects that directly; # import from `distutils.core` to work with newer packaging standards.; # - It provides a clear error message when setuptools is not installed.; # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so; # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:; # manifest_maker: standard file '""'""'-c'""'""' not found"".; # - It generates a shim setup.py, for handling setup.cfg-only projects.; import os, sys, tokenize; ; try:; import setuptools; except ImportError as error:; print(; ""ERROR: Can not execute `setup.py` since setuptools is not available in ""; ""the build environment."",; file=sys.stderr,; ); sys.exit(1); ; __file__ = %r; sys.argv[0] = __file__; ; if os.path.exists(__file__):; filename = __file__; with tokenize.open(__file__) as f:; setup_py_code = f.read(); else:; filename = ""<auto-generated setuptools caller>""; setup_py_code = ""from setuptools import setup; setup()""; ; exec(compile(setup_py_code, filename, ""exec"")); '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q; cwd: /private/var/folders/8z/k5cyv",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:83,Testability,test,test,83,"The problem is that it does not install at all. ; When I run; ```; conda create -n test; conda activate test; conda install python=3.11; conda install -c conda-forge scanpy; ```; I get an error output for the last line, which is:; ```; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0; - feature:|@/osx-64::__osx==10.16=0; - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16; ```. Repeating this with python=3.10 does not give an error.; Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```; Collecting numba>=0.41.0; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod; Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache; Current age based on date: 1302943; Ignoring unknown cache-control directive: immutable; Freshness lifetime from max-age: 365000000; The response is ""fresh"", returning cached response; 365000000 > 1302943; Using cached numba-0.56.4.tar.gz (2.4 MB); Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'; Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:104,Testability,test,test,104,"The problem is that it does not install at all. ; When I run; ```; conda create -n test; conda activate test; conda install python=3.11; conda install -c conda-forge scanpy; ```; I get an error output for the last line, which is:; ```; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0; - feature:|@/osx-64::__osx==10.16=0; - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16; ```. Repeating this with python=3.10 does not give an error.; Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```; Collecting numba>=0.41.0; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod; Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache; Current age based on date: 1302943; Ignoring unknown cache-control directive: immutable; Freshness lifetime from max-age: 365000000; The response is ""fresh"", returning cached response; 365000000 > 1302943; Using cached numba-0.56.4.tar.gz (2.4 MB); Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'; Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:2957,Testability,test,test,2957,"ry: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q; Running command python setup.py egg_info; Traceback (most recent call last):; File ""<string>"", line 2, in <module>; File ""<pip-setuptools-caller>"", line 34, in <module>; File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>; _guard_py_ver(); File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver; raise RuntimeError(msg.format(cur_py, min_py, max_py)); RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported.; error: subprocess-exited-with-error; ; × python setup.py egg_info did not run successfully.; │ exit code: 1; ╰─> See above for output.; ; note: This error originates from a subprocess, and is likely not a problem with pip.; full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '; exec(compile('""'""''""'""''""'""'; # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py; #; # - It imports setuptools before invoking setup.py, to enable projects that directly; # import from `distutils.core` to work with newer packaging standards.; # - It provides a clear error message when setuptools is not installed.; # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so; # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:; # manifest_maker: standard file '""'""'-c'""'""' not found"".; # - It generates a shim setup.py, for handling setup.cfg-only projects.; import os, sys, tokenize; ; try:; import setuptools; except ImportError as error:; print(; ""ERROR: Can not execute `setup.py` since setuptools is not available in ""; ""the build environment."",; file=sys.stderr,; ); sys.exit(1); ; __file__ = %r; sys.argv[0] = __file__; ; if os.path.exists(__file__):; filename = __f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:4950,Testability,test,test,4950,"exists(__file__):; filename = __file__; with tokenize.open(__file__) as f:; setup_py_code = f.read(); else:; filename = ""<auto-generated setuptools caller>""; setup_py_code = ""from setuptools import setup; setup()""; ; exec(compile(setup_py_code, filename, ""exec"")); '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q; cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/; Preparing metadata (setup.py) ... error; error: metadata-generation-failed. × Encountered error while generating package metadata.; ╰─> See above for output. note: This is an issue with the package mentioned above, not pip.; hint: See above for details.; Exception information:; Traceback (most recent call last):; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata; call_subprocess(; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess; raise error; pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper; status = run_func(*args); ^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper; return func(self, options, args); ^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/command",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:5124,Testability,test,test,5124,"m setuptools import setup; setup()""; ; exec(compile(setup_py_code, filename, ""exec"")); '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q; cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/; Preparing metadata (setup.py) ... error; error: metadata-generation-failed. × Encountered error while generating package metadata.; ╰─> See above for output. note: This is an issue with the package mentioned above, not pip.; hint: See above for details.; Exception information:; Traceback (most recent call last):; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata; call_subprocess(; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess; raise error; pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper; status = run_func(*args); ^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper; return func(self, options, args); ^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/commands/install.py"", line 400, in run; requirement_set = resolver.resolve(; ^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/re",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:5476,Testability,test,test,5476,"ip-pip-egg-info-tlduu_0q; cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/; Preparing metadata (setup.py) ... error; error: metadata-generation-failed. × Encountered error while generating package metadata.; ╰─> See above for output. note: This is an issue with the package mentioned above, not pip.; hint: See above for details.; Exception information:; Traceback (most recent call last):; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata; call_subprocess(; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess; raise error; pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper; status = run_func(*args); ^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper; return func(self, options, args); ^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/commands/install.py"", line 400, in run; requirement_set = resolver.resolve(; ^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py"", line 92, in resolve; result = self._result = resolver.resolve(; ^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 481, in resolve; state = resolution.resolve(requirements, max_rounds=max_rounds); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:5662,Testability,test,test,5662,"data (setup.py) ... error; error: metadata-generation-failed. × Encountered error while generating package metadata.; ╰─> See above for output. note: This is an issue with the package mentioned above, not pip.; hint: See above for details.; Exception information:; Traceback (most recent call last):; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata; call_subprocess(; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess; raise error; pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper; status = run_func(*args); ^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper; return func(self, options, args); ^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/commands/install.py"", line 400, in run; requirement_set = resolver.resolve(; ^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py"", line 92, in resolve; result = self._result = resolver.resolve(; ^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 481, in resolve; state = resolution.resolve(requirements, max_rounds=max_rounds); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 373, in resolve; failure_causes = se",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:5853,Testability,test,test,5853,"ioned above, not pip.; hint: See above for details.; Exception information:; Traceback (most recent call last):; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata; call_subprocess(; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess; raise error; pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper; status = run_func(*args); ^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper; return func(self, options, args); ^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/commands/install.py"", line 400, in run; requirement_set = resolver.resolve(; ^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py"", line 92, in resolve; result = self._result = resolver.resolve(; ^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 481, in resolve; state = resolution.resolve(requirements, max_rounds=max_rounds); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 373, in resolve; failure_causes = self._attempt_to_pin_criterion(name); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", lin",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:6036,Testability,test,test,6036,"uild/metadata_legacy.py"", line 64, in generate_metadata; call_subprocess(; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess; raise error; pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper; status = run_func(*args); ^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper; return func(self, options, args); ^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/commands/install.py"", line 400, in run; requirement_set = resolver.resolve(; ^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py"", line 92, in resolve; result = self._result = resolver.resolve(; ^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 481, in resolve; state = resolution.resolve(requirements, max_rounds=max_rounds); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 373, in resolve; failure_causes = self._attempt_to_pin_criterion(name); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 213, in _attempt_to_pin_criterion; criteria = self._get_updated_criteria(candidate); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/re",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:6242,Testability,test,test,6242,"rocess; raise error; pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper; status = run_func(*args); ^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper; return func(self, options, args); ^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/commands/install.py"", line 400, in run; requirement_set = resolver.resolve(; ^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py"", line 92, in resolve; result = self._result = resolver.resolve(; ^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 481, in resolve; state = resolution.resolve(requirements, max_rounds=max_rounds); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 373, in resolve; failure_causes = self._attempt_to_pin_criterion(name); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 213, in _attempt_to_pin_criterion; criteria = self._get_updated_criteria(candidate); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 204, in _get_updated_criteria; self._add_to_criteria(criteria, requirement, parent=candidate); File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vend",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:6497,Testability,test,test,6497,":; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper; status = run_func(*args); ^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper; return func(self, options, args); ^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/commands/install.py"", line 400, in run; requirement_set = resolver.resolve(; ^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py"", line 92, in resolve; result = self._result = resolver.resolve(; ^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 481, in resolve; state = resolution.resolve(requirements, max_rounds=max_rounds); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 373, in resolve; failure_causes = self._attempt_to_pin_criterion(name); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 213, in _attempt_to_pin_criterion; criteria = self._get_updated_criteria(candidate); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 204, in _get_updated_criteria; self._add_to_criteria(criteria, requirement, parent=candidate); File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 172, in _add_to_criteria; if not criterion.candidates:; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/structs.py"", line 151, in __bool",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:6723,Testability,test,test,6723,"n3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper; return func(self, options, args); ^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/commands/install.py"", line 400, in run; requirement_set = resolver.resolve(; ^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py"", line 92, in resolve; result = self._result = resolver.resolve(; ^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 481, in resolve; state = resolution.resolve(requirements, max_rounds=max_rounds); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 373, in resolve; failure_causes = self._attempt_to_pin_criterion(name); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 213, in _attempt_to_pin_criterion; criteria = self._get_updated_criteria(candidate); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 204, in _get_updated_criteria; self._add_to_criteria(criteria, requirement, parent=candidate); File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 172, in _add_to_criteria; if not criterion.candidates:; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/structs.py"", line 151, in __bool__; return bool(self._sequence); ^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 155, in __bool__; return any(self); ^^^^^^^^^; File",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:6963,Testability,test,test,6963,"ll.py"", line 400, in run; requirement_set = resolver.resolve(; ^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py"", line 92, in resolve; result = self._result = resolver.resolve(; ^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 481, in resolve; state = resolution.resolve(requirements, max_rounds=max_rounds); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 373, in resolve; failure_causes = self._attempt_to_pin_criterion(name); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 213, in _attempt_to_pin_criterion; criteria = self._get_updated_criteria(candidate); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 204, in _get_updated_criteria; self._add_to_criteria(criteria, requirement, parent=candidate); File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 172, in _add_to_criteria; if not criterion.candidates:; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/structs.py"", line 151, in __bool__; return bool(self._sequence); ^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 155, in __bool__; return any(self); ^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 143, in <genexpr>; return (c for c in iterator if id(c) not in self._incompatible_ids); ^^^^^^^^^^^^^^^^^^^",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:7174,Testability,test,test,7174,"esolve; result = self._result = resolver.resolve(; ^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 481, in resolve; state = resolution.resolve(requirements, max_rounds=max_rounds); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 373, in resolve; failure_causes = self._attempt_to_pin_criterion(name); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 213, in _attempt_to_pin_criterion; criteria = self._get_updated_criteria(candidate); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 204, in _get_updated_criteria; self._add_to_criteria(criteria, requirement, parent=candidate); File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 172, in _add_to_criteria; if not criterion.candidates:; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/structs.py"", line 151, in __bool__; return bool(self._sequence); ^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 155, in __bool__; return any(self); ^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 143, in <genexpr>; return (c for c in iterator if id(c) not in self._incompatible_ids); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 47, in _iter_built; candidate = func();",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:7346,Testability,test,test,7346,"esolve; state = resolution.resolve(requirements, max_rounds=max_rounds); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 373, in resolve; failure_causes = self._attempt_to_pin_criterion(name); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 213, in _attempt_to_pin_criterion; criteria = self._get_updated_criteria(candidate); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 204, in _get_updated_criteria; self._add_to_criteria(criteria, requirement, parent=candidate); File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 172, in _add_to_criteria; if not criterion.candidates:; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/structs.py"", line 151, in __bool__; return bool(self._sequence); ^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 155, in __bool__; return any(self); ^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 143, in <genexpr>; return (c for c in iterator if id(c) not in self._incompatible_ids); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 47, in _iter_built; candidate = func(); ^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/factory.py"", line 206, in _make_candidate_from_link; self._link_candidate_cac",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:7529,Testability,test,test,7529,"/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 373, in resolve; failure_causes = self._attempt_to_pin_criterion(name); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 213, in _attempt_to_pin_criterion; criteria = self._get_updated_criteria(candidate); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 204, in _get_updated_criteria; self._add_to_criteria(criteria, requirement, parent=candidate); File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 172, in _add_to_criteria; if not criterion.candidates:; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/structs.py"", line 151, in __bool__; return bool(self._sequence); ^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 155, in __bool__; return any(self); ^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 143, in <genexpr>; return (c for c in iterator if id(c) not in self._incompatible_ids); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 47, in _iter_built; candidate = func(); ^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/factory.py"", line 206, in _make_candidate_from_link; self._link_candidate_cache[link] = LinkCandidate(; ^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:7712,Testability,test,test,7712,"^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 213, in _attempt_to_pin_criterion; criteria = self._get_updated_criteria(candidate); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 204, in _get_updated_criteria; self._add_to_criteria(criteria, requirement, parent=candidate); File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 172, in _add_to_criteria; if not criterion.candidates:; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/structs.py"", line 151, in __bool__; return bool(self._sequence); ^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 155, in __bool__; return any(self); ^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 143, in <genexpr>; return (c for c in iterator if id(c) not in self._incompatible_ids); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 47, in _iter_built; candidate = func(); ^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/factory.py"", line 206, in _make_candidate_from_link; self._link_candidate_cache[link] = LinkCandidate(; ^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 297, in __init__; super().__init__(; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 162,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:7998,Testability,test,test,7998,"miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 204, in _get_updated_criteria; self._add_to_criteria(criteria, requirement, parent=candidate); File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 172, in _add_to_criteria; if not criterion.candidates:; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/structs.py"", line 151, in __bool__; return bool(self._sequence); ^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 155, in __bool__; return any(self); ^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 143, in <genexpr>; return (c for c in iterator if id(c) not in self._incompatible_ids); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 47, in _iter_built; candidate = func(); ^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/factory.py"", line 206, in _make_candidate_from_link; self._link_candidate_cache[link] = LinkCandidate(; ^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 297, in __init__; super().__init__(; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 162, in __init__; self.dist = self._prepare(); ^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 231, in _prepare; dist = self._prepare_distribution(); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:8182,Testability,test,test,8182,"Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 172, in _add_to_criteria; if not criterion.candidates:; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_vendor/resolvelib/structs.py"", line 151, in __bool__; return bool(self._sequence); ^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 155, in __bool__; return any(self); ^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 143, in <genexpr>; return (c for c in iterator if id(c) not in self._incompatible_ids); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 47, in _iter_built; candidate = func(); ^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/factory.py"", line 206, in _make_candidate_from_link; self._link_candidate_cache[link] = LinkCandidate(; ^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 297, in __init__; super().__init__(; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 162, in __init__; self.dist = self._prepare(); ^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 231, in _prepare; dist = self._prepare_distribution(); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 308, in _prepare_distribution; return preparer.prepare_linked_re",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:8411,Testability,test,test,8411,"e-packages/pip/_vendor/resolvelib/structs.py"", line 151, in __bool__; return bool(self._sequence); ^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 155, in __bool__; return any(self); ^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 143, in <genexpr>; return (c for c in iterator if id(c) not in self._incompatible_ids); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 47, in _iter_built; candidate = func(); ^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/factory.py"", line 206, in _make_candidate_from_link; self._link_candidate_cache[link] = LinkCandidate(; ^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 297, in __init__; super().__init__(; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 162, in __init__; self.dist = self._prepare(); ^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 231, in _prepare; dist = self._prepare_distribution(); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 308, in _prepare_distribution; return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:8578,Testability,test,test,8578,"s/pip/_internal/resolution/resolvelib/found_candidates.py"", line 155, in __bool__; return any(self); ^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 143, in <genexpr>; return (c for c in iterator if id(c) not in self._incompatible_ids); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 47, in _iter_built; candidate = func(); ^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/factory.py"", line 206, in _make_candidate_from_link; self._link_candidate_cache[link] = LinkCandidate(; ^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 297, in __init__; super().__init__(; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 162, in __init__; self.dist = self._prepare(); ^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 231, in _prepare; dist = self._prepare_distribution(); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 308, in _prepare_distribution; return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement; return self._prepare_linked_requirement(req, parallel_builds); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:8772,Testability,test,test,8772,"pip/_internal/resolution/resolvelib/found_candidates.py"", line 143, in <genexpr>; return (c for c in iterator if id(c) not in self._incompatible_ids); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 47, in _iter_built; candidate = func(); ^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/factory.py"", line 206, in _make_candidate_from_link; self._link_candidate_cache[link] = LinkCandidate(; ^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 297, in __init__; super().__init__(; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 162, in __init__; self.dist = self._prepare(); ^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 231, in _prepare; dist = self._prepare_distribution(); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 308, in _prepare_distribution; return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement; return self._prepare_linked_requirement(req, parallel_builds); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 577, in _prepare_linked_requirement; dist = _get_prepared_distribution(; ^^^^^^^^^^^^^^^^^^^^^^^^^^^; ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:8987,Testability,test,test,8987,"^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 47, in _iter_built; candidate = func(); ^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/factory.py"", line 206, in _make_candidate_from_link; self._link_candidate_cache[link] = LinkCandidate(; ^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 297, in __init__; super().__init__(; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 162, in __init__; self.dist = self._prepare(); ^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 231, in _prepare; dist = self._prepare_distribution(); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 308, in _prepare_distribution; return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement; return self._prepare_linked_requirement(req, parallel_builds); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 577, in _prepare_linked_requirement; dist = _get_prepared_distribution(; ^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 69, in _get_prepared_distribution; abstract_dist.prepare_distribution_metadata(; File ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:9297,Testability,test,test,9297,"ution/resolvelib/factory.py"", line 206, in _make_candidate_from_link; self._link_candidate_cache[link] = LinkCandidate(; ^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 297, in __init__; super().__init__(; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 162, in __init__; self.dist = self._prepare(); ^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 231, in _prepare; dist = self._prepare_distribution(); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 308, in _prepare_distribution; return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement; return self._prepare_linked_requirement(req, parallel_builds); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 577, in _prepare_linked_requirement; dist = _get_prepared_distribution(; ^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 69, in _get_prepared_distribution; abstract_dist.prepare_distribution_metadata(; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/distributions/sdist.py"", line 61, in prepare_distribution_metadata; self.req.prepare_metadata(); File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/req/req_install.py"", ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:9568,Testability,test,test,9568,"97, in __init__; super().__init__(; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 162, in __init__; self.dist = self._prepare(); ^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 231, in _prepare; dist = self._prepare_distribution(); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 308, in _prepare_distribution; return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement; return self._prepare_linked_requirement(req, parallel_builds); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 577, in _prepare_linked_requirement; dist = _get_prepared_distribution(; ^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 69, in _get_prepared_distribution; abstract_dist.prepare_distribution_metadata(; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/distributions/sdist.py"", line 61, in prepare_distribution_metadata; self.req.prepare_metadata(); File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/req/req_install.py"", line 541, in prepare_metadata; self.metadata_directory = generate_metadata_legacy(; ^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 71, in generate_metadata; r",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:9786,Testability,test,test,9786,"^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 231, in _prepare; dist = self._prepare_distribution(); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 308, in _prepare_distribution; return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement; return self._prepare_linked_requirement(req, parallel_builds); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 577, in _prepare_linked_requirement; dist = _get_prepared_distribution(; ^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 69, in _get_prepared_distribution; abstract_dist.prepare_distribution_metadata(; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/distributions/sdist.py"", line 61, in prepare_distribution_metadata; self.req.prepare_metadata(); File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/req/req_install.py"", line 541, in prepare_metadata; self.metadata_directory = generate_metadata_legacy(; ^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 71, in generate_metadata; raise MetadataGenerationFailed(package_details=details) from error; pip._internal.exceptions.MetadataGenerationFailed: metadata generation failed; Remote version of pip: 22.3.1; Local version of pip: 22.3.1; Was pip ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:9983,Testability,test,test,9983,"sers/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 308, in _prepare_distribution; return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement; return self._prepare_linked_requirement(req, parallel_builds); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 577, in _prepare_linked_requirement; dist = _get_prepared_distribution(; ^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 69, in _get_prepared_distribution; abstract_dist.prepare_distribution_metadata(; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/distributions/sdist.py"", line 61, in prepare_distribution_metadata; self.req.prepare_metadata(); File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/req/req_install.py"", line 541, in prepare_metadata; self.metadata_directory = generate_metadata_legacy(; ^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 71, in generate_metadata; raise MetadataGenerationFailed(package_details=details) from error; pip._internal.exceptions.MetadataGenerationFailed: metadata generation failed; Remote version of pip: 22.3.1; Local version of pip: 22.3.1; Was pip installed by pip? False; Removed numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) from build tracker '/private/var/folders/8z/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:10167,Testability,test,test,10167,"e_linked_requirement(self._ireq, parallel_builds=True); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement; return self._prepare_linked_requirement(req, parallel_builds); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 577, in _prepare_linked_requirement; dist = _get_prepared_distribution(; ^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 69, in _get_prepared_distribution; abstract_dist.prepare_distribution_metadata(; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/distributions/sdist.py"", line 61, in prepare_distribution_metadata; self.req.prepare_metadata(); File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/req/req_install.py"", line 541, in prepare_metadata; self.metadata_directory = generate_metadata_legacy(; ^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 71, in generate_metadata; raise MetadataGenerationFailed(package_details=details) from error; pip._internal.exceptions.MetadataGenerationFailed: metadata generation failed; Remote version of pip: 22.3.1; Local version of pip: 22.3.1; Was pip installed by pip? False; Removed numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) from build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'; Removed build tracker: '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:10386,Testability,test,test,10386,"e_linked_requirement(self._ireq, parallel_builds=True); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement; return self._prepare_linked_requirement(req, parallel_builds); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 577, in _prepare_linked_requirement; dist = _get_prepared_distribution(; ^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 69, in _get_prepared_distribution; abstract_dist.prepare_distribution_metadata(; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/distributions/sdist.py"", line 61, in prepare_distribution_metadata; self.req.prepare_metadata(); File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/req/req_install.py"", line 541, in prepare_metadata; self.metadata_directory = generate_metadata_legacy(; ^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 71, in generate_metadata; raise MetadataGenerationFailed(package_details=details) from error; pip._internal.exceptions.MetadataGenerationFailed: metadata generation failed; Remote version of pip: 22.3.1; Local version of pip: 22.3.1; Was pip installed by pip? False; Removed numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) from build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'; Removed build tracker: '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:3269,Usability,clear,clear,3269,"mba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>; _guard_py_ver(); File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver; raise RuntimeError(msg.format(cur_py, min_py, max_py)); RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported.; error: subprocess-exited-with-error; ; × python setup.py egg_info did not run successfully.; │ exit code: 1; ╰─> See above for output.; ; note: This error originates from a subprocess, and is likely not a problem with pip.; full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '; exec(compile('""'""''""'""''""'""'; # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py; #; # - It imports setuptools before invoking setup.py, to enable projects that directly; # import from `distutils.core` to work with newer packaging standards.; # - It provides a clear error message when setuptools is not installed.; # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so; # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:; # manifest_maker: standard file '""'""'-c'""'""' not found"".; # - It generates a shim setup.py, for handling setup.cfg-only projects.; import os, sys, tokenize; ; try:; import setuptools; except ImportError as error:; print(; ""ERROR: Can not execute `setup.py` since setuptools is not available in ""; ""the build environment."",; file=sys.stderr,; ); sys.exit(1); ; __file__ = %r; sys.argv[0] = __file__; ; if os.path.exists(__file__):; filename = __file__; with tokenize.open(__file__) as f:; setup_py_code = f.read(); else:; filename = ""<auto-generated setuptools caller>""; setup_py_code = ""from setuptools import setup; setup()""; ; exec(compile(setup_py_code, filename, ""exec"")); '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209
https://github.com/scverse/scanpy/issues/2369#issuecomment-1332466200:22,Deployability,install,install,22,"`RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported.`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332466200
https://github.com/scverse/scanpy/issues/2369#issuecomment-1333418043:94,Availability,error,error,94,"> When I run [`conda install python=3.11` and `conda install -c conda-forge scanpy`] I get an error . Yeah no idea how to debug conda conflicts. I’ve often seen things like this: completely unrelated packages “conflicting” containing cryptic symbols like `feature:|@/osx-64::__osx==10.16=0`. No clue what that means. Conda seems to be unable to figure out which user-specified versions are in conflict with each other. Pip seems to do a better job these days:. > Running this with `pip -vv install scanpy` as you suggested indeed gives an error with numba. Exactly, so this is a numba issue. Please follow https://github.com/numba/numba/issues/8304. Once numba supports Python 3.11, you’ll be able to install any dependent project there (including scanpy)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1333418043
https://github.com/scverse/scanpy/issues/2369#issuecomment-1333418043:539,Availability,error,error,539,"> When I run [`conda install python=3.11` and `conda install -c conda-forge scanpy`] I get an error . Yeah no idea how to debug conda conflicts. I’ve often seen things like this: completely unrelated packages “conflicting” containing cryptic symbols like `feature:|@/osx-64::__osx==10.16=0`. No clue what that means. Conda seems to be unable to figure out which user-specified versions are in conflict with each other. Pip seems to do a better job these days:. > Running this with `pip -vv install scanpy` as you suggested indeed gives an error with numba. Exactly, so this is a numba issue. Please follow https://github.com/numba/numba/issues/8304. Once numba supports Python 3.11, you’ll be able to install any dependent project there (including scanpy)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1333418043
https://github.com/scverse/scanpy/issues/2369#issuecomment-1333418043:21,Deployability,install,install,21,"> When I run [`conda install python=3.11` and `conda install -c conda-forge scanpy`] I get an error . Yeah no idea how to debug conda conflicts. I’ve often seen things like this: completely unrelated packages “conflicting” containing cryptic symbols like `feature:|@/osx-64::__osx==10.16=0`. No clue what that means. Conda seems to be unable to figure out which user-specified versions are in conflict with each other. Pip seems to do a better job these days:. > Running this with `pip -vv install scanpy` as you suggested indeed gives an error with numba. Exactly, so this is a numba issue. Please follow https://github.com/numba/numba/issues/8304. Once numba supports Python 3.11, you’ll be able to install any dependent project there (including scanpy)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1333418043
https://github.com/scverse/scanpy/issues/2369#issuecomment-1333418043:53,Deployability,install,install,53,"> When I run [`conda install python=3.11` and `conda install -c conda-forge scanpy`] I get an error . Yeah no idea how to debug conda conflicts. I’ve often seen things like this: completely unrelated packages “conflicting” containing cryptic symbols like `feature:|@/osx-64::__osx==10.16=0`. No clue what that means. Conda seems to be unable to figure out which user-specified versions are in conflict with each other. Pip seems to do a better job these days:. > Running this with `pip -vv install scanpy` as you suggested indeed gives an error with numba. Exactly, so this is a numba issue. Please follow https://github.com/numba/numba/issues/8304. Once numba supports Python 3.11, you’ll be able to install any dependent project there (including scanpy)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1333418043
https://github.com/scverse/scanpy/issues/2369#issuecomment-1333418043:490,Deployability,install,install,490,"> When I run [`conda install python=3.11` and `conda install -c conda-forge scanpy`] I get an error . Yeah no idea how to debug conda conflicts. I’ve often seen things like this: completely unrelated packages “conflicting” containing cryptic symbols like `feature:|@/osx-64::__osx==10.16=0`. No clue what that means. Conda seems to be unable to figure out which user-specified versions are in conflict with each other. Pip seems to do a better job these days:. > Running this with `pip -vv install scanpy` as you suggested indeed gives an error with numba. Exactly, so this is a numba issue. Please follow https://github.com/numba/numba/issues/8304. Once numba supports Python 3.11, you’ll be able to install any dependent project there (including scanpy)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1333418043
https://github.com/scverse/scanpy/issues/2369#issuecomment-1333418043:701,Deployability,install,install,701,"> When I run [`conda install python=3.11` and `conda install -c conda-forge scanpy`] I get an error . Yeah no idea how to debug conda conflicts. I’ve often seen things like this: completely unrelated packages “conflicting” containing cryptic symbols like `feature:|@/osx-64::__osx==10.16=0`. No clue what that means. Conda seems to be unable to figure out which user-specified versions are in conflict with each other. Pip seems to do a better job these days:. > Running this with `pip -vv install scanpy` as you suggested indeed gives an error with numba. Exactly, so this is a numba issue. Please follow https://github.com/numba/numba/issues/8304. Once numba supports Python 3.11, you’ll be able to install any dependent project there (including scanpy)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1333418043
https://github.com/scverse/scanpy/issues/2369#issuecomment-1333418043:713,Integrability,depend,dependent,713,"> When I run [`conda install python=3.11` and `conda install -c conda-forge scanpy`] I get an error . Yeah no idea how to debug conda conflicts. I’ve often seen things like this: completely unrelated packages “conflicting” containing cryptic symbols like `feature:|@/osx-64::__osx==10.16=0`. No clue what that means. Conda seems to be unable to figure out which user-specified versions are in conflict with each other. Pip seems to do a better job these days:. > Running this with `pip -vv install scanpy` as you suggested indeed gives an error with numba. Exactly, so this is a numba issue. Please follow https://github.com/numba/numba/issues/8304. Once numba supports Python 3.11, you’ll be able to install any dependent project there (including scanpy)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1333418043
https://github.com/scverse/scanpy/issues/2383#issuecomment-1367301208:428,Availability,error,errors,428,"> @brainfo I'm afraid that we only speak English. Hi sorry and indeed that's an automatic reply from the email service I just changed the email address so this would not be a problem later. To add one more problem encountered when writing out anndata object: ; When the anndata has 'predicted_doublet' in obs annotation from sc.external.pp.scrublet, the boolean values could not be implicitly converted to strings so that gives errors: . ```{py}; TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'predicted_doublet' of <class 'h5py._hl.group.Group'> to /; ```. Users can map the values like this but would it be better to have the implicit conversion while read/write anndatas?; ```{py}; anndata.obs['predicted_doublet'] = anndata.obs['predicted_doublet'].map({True: 'True', False: 'False'}); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2383#issuecomment-1367301208
https://github.com/scverse/scanpy/issues/2383#issuecomment-1367301208:520,Availability,error,error,520,"> @brainfo I'm afraid that we only speak English. Hi sorry and indeed that's an automatic reply from the email service I just changed the email address so this would not be a problem later. To add one more problem encountered when writing out anndata object: ; When the anndata has 'predicted_doublet' in obs annotation from sc.external.pp.scrublet, the boolean values could not be implicitly converted to strings so that gives errors: . ```{py}; TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'predicted_doublet' of <class 'h5py._hl.group.Group'> to /; ```. Users can map the values like this but would it be better to have the implicit conversion while read/write anndatas?; ```{py}; anndata.obs['predicted_doublet'] = anndata.obs['predicted_doublet'].map({True: 'True', False: 'False'}); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2383#issuecomment-1367301208
https://github.com/scverse/scanpy/issues/2386#issuecomment-1364138151:353,Testability,log,log-transforming,353,"Hi danli249, . what dataset are you using? If this is your own dataset, can you instead replicate this behavior on a public dataset? e.g. the clustering tutorial https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html?. without much needed context, this looks like some oversight in the preprocessing, for example not normalizing your data or not log-transforming it. Michael",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2386#issuecomment-1364138151
https://github.com/scverse/scanpy/issues/2386#issuecomment-1364160150:86,Usability,learn,learn,86,"Hi Michael:. I compare the `umap` in `scanpy` with the original [`umap`](https://umap-learn.readthedocs.io/en/latest/plotting.html) (https://umap-learn.readthedocs.io/en/latest/plotting.html) using the same dataset, the original `umap` works well, I think the problem is in `scanpy`. I edited my question to include this.; Do you have some suggestions?; Thanks. Dan",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2386#issuecomment-1364160150
https://github.com/scverse/scanpy/issues/2386#issuecomment-1364160150:146,Usability,learn,learn,146,"Hi Michael:. I compare the `umap` in `scanpy` with the original [`umap`](https://umap-learn.readthedocs.io/en/latest/plotting.html) (https://umap-learn.readthedocs.io/en/latest/plotting.html) using the same dataset, the original `umap` works well, I think the problem is in `scanpy`. I edited my question to include this.; Do you have some suggestions?; Thanks. Dan",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2386#issuecomment-1364160150
https://github.com/scverse/scanpy/issues/2386#issuecomment-1364246721:621,Deployability,install,installation,621,"Hi Dan, . When you perform the umap calculation using sc.tl.umap, the default matrix used is adata.obsm['X_pca']. Given this, you wouldn't expect the same embedding the way you've done it. if instead you did this. `mapper = umap.UMAP().fit(adata.obsm['X_pca'])` . you'd likely find a very similar embedding to the ones you've shown scanpy producing. As such, I'm guessing there is problem with how you've preprocessed the data, such that the PCA space is not behaving as expected. . why don't you attempt running this notebook "" wget https://github.com/scverse/scanpy-tutorials/raw/master/pbmc3k.ipynb"" with your current installation, and let us know if you can reproduce the tutorial. Then I would suggest adding your data, changing else, and reporting back.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2386#issuecomment-1364246721
https://github.com/scverse/scanpy/issues/2386#issuecomment-1364246721:19,Performance,perform,perform,19,"Hi Dan, . When you perform the umap calculation using sc.tl.umap, the default matrix used is adata.obsm['X_pca']. Given this, you wouldn't expect the same embedding the way you've done it. if instead you did this. `mapper = umap.UMAP().fit(adata.obsm['X_pca'])` . you'd likely find a very similar embedding to the ones you've shown scanpy producing. As such, I'm guessing there is problem with how you've preprocessed the data, such that the PCA space is not behaving as expected. . why don't you attempt running this notebook "" wget https://github.com/scverse/scanpy-tutorials/raw/master/pbmc3k.ipynb"" with your current installation, and let us know if you can reproduce the tutorial. Then I would suggest adding your data, changing else, and reporting back.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2386#issuecomment-1364246721
https://github.com/scverse/scanpy/issues/2386#issuecomment-1364270613:292,Availability,down,down,292,"Hi Michael:. Thanks for your suggestion, I run the tutorial without changing anything: https://github.com/scverse/scanpy-tutorials/raw/master/pbmc3k.ipynb, ; ![image](https://user-images.githubusercontent.com/33963919/209399067-2287268f-a77c-4f12-ba5b-d56e4370b2f2.png). My `scanpy` can't do down dimension correctly in the `pbmc3k` data.; ![image](https://user-images.githubusercontent.com/33963919/209398837-d2f77dfa-5855-4bf7-9c7d-33625909af09.png); Can you please let me know what is wrong?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2386#issuecomment-1364270613
https://github.com/scverse/scanpy/issues/2386#issuecomment-1364279207:99,Deployability,update,update,99,"This does seem more like a bug now. I noticed you're using a pretty old version of scanpy. can you update to a more current version, e.g. 1.9* so that we can understand if it is reproducible on the distribution that people are using?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2386#issuecomment-1364279207
https://github.com/scverse/scanpy/issues/2386#issuecomment-1364339487:2,Deployability,upgrade,upgrade,2,"I upgrade `scanpy` to `1.9.1`, and now `sc.tl.umap` works as expected:. ![image](https://user-images.githubusercontent.com/33963919/209405851-2798000b-0e90-4b3f-982c-f0de196489c5.png). Thanks",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2386#issuecomment-1364339487
https://github.com/scverse/scanpy/issues/2386#issuecomment-1364366326:941,Safety,predict,predict,941,"Hi Michael. For my own data, ; I compared `scanpy` `umap` with the original `umap`; The original `umap` output is:; ```; import umap; import umap.plot; mapper = umap.UMAP().fit(adata.X); umap.plot.points(mapper, labels=adata.obs['batch']); ```; ![image](https://user-images.githubusercontent.com/33963919/209409453-578ce08c-3eed-4b42-a0c9-e3165d5859cc.png). ```; mapper2 = umap.UMAP().fit(adata.obsm['X_pca']); umap.plot.points(mapper2, labels=adata.obs['batch']); ```; ![image](https://user-images.githubusercontent.com/33963919/209409492-9559fc2e-817e-4003-b8e2-560a5687b241.png). The `scanpy` output is:; ```; sc.pp.filter_cells(adata, min_counts = 100); adata = adata[adata.obs['mt_frac'] < 0.2]; sc.pp.filter_cells(adata, min_genes = 1); sc.pp.filter_genes(adata, min_cells=1). import doubletdetection; clf = doubletdetection.BoostClassifier(; n_iters=10, ; use_phenograph=False, ; standard_scaling=True; ); doublets = clf.fit(adata.X).predict(p_thresh=1e-16, voter_thresh=0.5); doublet_score = clf.doublet_score(); adata.obs[""doublet""] = doublets; adata = adata[adata.obs[""doublet""] == 0.0] # filter out doublets . sc.pp.normalize_total(adata, target_sum=1e6); sc.pp.log1p(adata, base=2). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5, ; flavor='cell_ranger'); sc.pp.scale(adata, max_value=10); sc.pp.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=15); sc.tl.umap(adata, min_dist=0.5, spread = 1.0); sc.pl.umap(adata, color='batch', use_raw=False, save='batch_umap.pdf'). ```. ![image](https://user-images.githubusercontent.com/33963919/209409864-0c0c0207-c3af-40f3-8af4-c3448f9ca0f1.png). If I do not run pca, then run `sc.tl.umap` I will get:. ![image](https://user-images.githubusercontent.com/33963919/209410266-efca8967-c8d0-4253-b273-3a048ae27653.png). 1. What should I do to get more compact clusters?; 2. Why the output so different between `scanpy.tl.umap` and the orignal `umap`?; 3. Should I use PCA for umap or not?; 4. Should I us",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2386#issuecomment-1364366326
https://github.com/scverse/scanpy/issues/2389#issuecomment-1371002904:67,Modifiability,layers,layers,67,"normalize total operates inplace. in the code example above `adata.layers[""counts""]` and `adata.X` are referencing the same object. You should add `.copy()` if you want independent behavior",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389#issuecomment-1371002904
https://github.com/scverse/scanpy/issues/2389#issuecomment-1413251794:51,Modifiability,layers,layers,51,So one should always use .copy() when creating new layers from .X?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389#issuecomment-1413251794
https://github.com/scverse/scanpy/issues/2390#issuecomment-1387422639:187,Availability,avail,available,187,"cc: @Zethson @grst. Hey, . In principle this sounds good, but I'd like to hear a little bit more about the usecase. For context on our side, there are some other paths for speeding up DE available (probably some form of calculating statistics via https://github.com/scverse/anndata/pull/564). There're also increased momentum on more featureful DE in the scverse ecosystem. If you are specifically looking for faster scanpy DE, this makes sense, though there may be some easier paths forward (at least to me). If you need anything fancier or even just different, it could be good to check in with other efforts. E.g. . * https://github.com/theislab/pertpy/issues/189",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2390#issuecomment-1387422639
https://github.com/scverse/scanpy/issues/2390#issuecomment-1387503006:706,Usability,simpl,simple,706,"Hi @ivirshup . Thanks for the help. In terms of the use cases here:. (1) Any user doing data processing or interactive analysis could benefit from multithreading here. Consider the two big for-loops which through all of the genes between compared in the samples, and the for loop which automatically does this for each ""group"" in the ScanPy object. . I'm a bit confused why Seurat or ScanPy never did this....but then I realize that Pagoda2 didn't either: https://github.com/kharchenkolab/pagoda2/blob/main/R/Pagoda2.R#L900. (There's a bit of multithreading there at the end...). Given the file sizes nowadays and the number of ""groups"", this is getting fairly computationally intensive. It's one of those simple things your biologists will love (""this is so fast now!""). (2) In terms of our use case, an interactive way to run DE via the client is too slow. We've just started to implement the above ourselves. . **RE: pertpy**. Could does this relate to @davidsebfischer and diffxpy?. Best, Evan",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2390#issuecomment-1387503006
https://github.com/scverse/scanpy/issues/2390#issuecomment-1396521226:779,Deployability,release,released,779,"> Given the file sizes nowadays and the number of ""groups"", this is getting fairly computationally intensive. It's one of those simple things your biologists will love (""this is so fast now!""). I agree it doesn't harm to have `rank_genes_groups` parallelized (given that it should be straightforward to implement). ; What @ivirshup was referring to though, is that `rank_genes_groups` on single cells in general isn't seen anymore as best practice for DE analysis because it doesn't account for pseudoreplication bias. Please take a look at @Zethson's [book chapter](https://www.sc-best-practices.org/conditions/differential_gene_expression.html). . > RE: pertpy; >; > Could does this relate to @davidsebfischer and diffxpy?. Diffxpy is currently being reimplemented. Once it is released, it would likely be included in pertpy as an additional method. I.e. pertpy is more general and strives to provide a consistent interface to multiple methods.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2390#issuecomment-1396521226
https://github.com/scverse/scanpy/issues/2390#issuecomment-1396521226:916,Integrability,interface,interface,916,"> Given the file sizes nowadays and the number of ""groups"", this is getting fairly computationally intensive. It's one of those simple things your biologists will love (""this is so fast now!""). I agree it doesn't harm to have `rank_genes_groups` parallelized (given that it should be straightforward to implement). ; What @ivirshup was referring to though, is that `rank_genes_groups` on single cells in general isn't seen anymore as best practice for DE analysis because it doesn't account for pseudoreplication bias. Please take a look at @Zethson's [book chapter](https://www.sc-best-practices.org/conditions/differential_gene_expression.html). . > RE: pertpy; >; > Could does this relate to @davidsebfischer and diffxpy?. Diffxpy is currently being reimplemented. Once it is released, it would likely be included in pertpy as an additional method. I.e. pertpy is more general and strives to provide a consistent interface to multiple methods.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2390#issuecomment-1396521226
https://github.com/scverse/scanpy/issues/2390#issuecomment-1396521226:128,Usability,simpl,simple,128,"> Given the file sizes nowadays and the number of ""groups"", this is getting fairly computationally intensive. It's one of those simple things your biologists will love (""this is so fast now!""). I agree it doesn't harm to have `rank_genes_groups` parallelized (given that it should be straightforward to implement). ; What @ivirshup was referring to though, is that `rank_genes_groups` on single cells in general isn't seen anymore as best practice for DE analysis because it doesn't account for pseudoreplication bias. Please take a look at @Zethson's [book chapter](https://www.sc-best-practices.org/conditions/differential_gene_expression.html). . > RE: pertpy; >; > Could does this relate to @davidsebfischer and diffxpy?. Diffxpy is currently being reimplemented. Once it is released, it would likely be included in pertpy as an additional method. I.e. pertpy is more general and strives to provide a consistent interface to multiple methods.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2390#issuecomment-1396521226
https://github.com/scverse/scanpy/issues/2390#issuecomment-1397484486:598,Availability,mask,mask,598,"> (1) Any user doing data processing or interactive analysis could benefit from multithreading here. Consider the two big for-loops which through all of the genes between compared in the samples, and the for loop which automatically does this for each ""group"" in the ScanPy object. My concern is that there will be issues if you keep the current calculations, but parallelize over the groups. Within that loop, I believe large amounts of memory can be allocated. If it's ""group vs rest"", at least one `X` worth of memory is allocated per loop from matrix subsetting – since there's an `X_group = X[mask]; X_rest = X[~mask]`. If you parallelize over groups, now the max memory usage can be `~ min(n_procs, n_groups) * X` as opposed to `~2X`. For large `X` (probably where you want to see the speed up most), this can make you run out of memory. https://github.com/scverse/scanpy/blob/d26be443373549f26226de367f0213f153556915/scanpy/tools/_rank_genes_groups.py#L164-L178. Another memory related concern comes from `multiprocessing` (mentioned in your email). I think there's recently been some improvement here, but my impression was it's difficult/ impossible to share memory with `multiprocessing` – so everything that goes into or out of a subprocess has to be copied. So while I think we can absolutely make use of more processing power here, I think we need to consider the approach. * The link I mentioned above should reduce copies, and could potentially use a parallelized BLAS for compute; * Much of the loops over ""all of the genes between compared samples"" are already in compiled code, but could be parallelized. > In terms of our use case, an interactive way to run DE via the client is too slow. What is the interface here? Scanpy computes results for all groups at once, but in most interfaces I've used you can only really ""ask"" for one comparison at a time. This could also be much faster, if you can just reduce total computation. ---------. > What @ivirshup was referring to though, i",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2390#issuecomment-1397484486
https://github.com/scverse/scanpy/issues/2390#issuecomment-1397484486:617,Availability,mask,mask,617,"> (1) Any user doing data processing or interactive analysis could benefit from multithreading here. Consider the two big for-loops which through all of the genes between compared in the samples, and the for loop which automatically does this for each ""group"" in the ScanPy object. My concern is that there will be issues if you keep the current calculations, but parallelize over the groups. Within that loop, I believe large amounts of memory can be allocated. If it's ""group vs rest"", at least one `X` worth of memory is allocated per loop from matrix subsetting – since there's an `X_group = X[mask]; X_rest = X[~mask]`. If you parallelize over groups, now the max memory usage can be `~ min(n_procs, n_groups) * X` as opposed to `~2X`. For large `X` (probably where you want to see the speed up most), this can make you run out of memory. https://github.com/scverse/scanpy/blob/d26be443373549f26226de367f0213f153556915/scanpy/tools/_rank_genes_groups.py#L164-L178. Another memory related concern comes from `multiprocessing` (mentioned in your email). I think there's recently been some improvement here, but my impression was it's difficult/ impossible to share memory with `multiprocessing` – so everything that goes into or out of a subprocess has to be copied. So while I think we can absolutely make use of more processing power here, I think we need to consider the approach. * The link I mentioned above should reduce copies, and could potentially use a parallelized BLAS for compute; * Much of the loops over ""all of the genes between compared samples"" are already in compiled code, but could be parallelized. > In terms of our use case, an interactive way to run DE via the client is too slow. What is the interface here? Scanpy computes results for all groups at once, but in most interfaces I've used you can only really ""ask"" for one comparison at a time. This could also be much faster, if you can just reduce total computation. ---------. > What @ivirshup was referring to though, i",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2390#issuecomment-1397484486
https://github.com/scverse/scanpy/issues/2390#issuecomment-1397484486:452,Energy Efficiency,allocate,allocated,452,"> (1) Any user doing data processing or interactive analysis could benefit from multithreading here. Consider the two big for-loops which through all of the genes between compared in the samples, and the for loop which automatically does this for each ""group"" in the ScanPy object. My concern is that there will be issues if you keep the current calculations, but parallelize over the groups. Within that loop, I believe large amounts of memory can be allocated. If it's ""group vs rest"", at least one `X` worth of memory is allocated per loop from matrix subsetting – since there's an `X_group = X[mask]; X_rest = X[~mask]`. If you parallelize over groups, now the max memory usage can be `~ min(n_procs, n_groups) * X` as opposed to `~2X`. For large `X` (probably where you want to see the speed up most), this can make you run out of memory. https://github.com/scverse/scanpy/blob/d26be443373549f26226de367f0213f153556915/scanpy/tools/_rank_genes_groups.py#L164-L178. Another memory related concern comes from `multiprocessing` (mentioned in your email). I think there's recently been some improvement here, but my impression was it's difficult/ impossible to share memory with `multiprocessing` – so everything that goes into or out of a subprocess has to be copied. So while I think we can absolutely make use of more processing power here, I think we need to consider the approach. * The link I mentioned above should reduce copies, and could potentially use a parallelized BLAS for compute; * Much of the loops over ""all of the genes between compared samples"" are already in compiled code, but could be parallelized. > In terms of our use case, an interactive way to run DE via the client is too slow. What is the interface here? Scanpy computes results for all groups at once, but in most interfaces I've used you can only really ""ask"" for one comparison at a time. This could also be much faster, if you can just reduce total computation. ---------. > What @ivirshup was referring to though, i",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2390#issuecomment-1397484486
https://github.com/scverse/scanpy/issues/2390#issuecomment-1397484486:524,Energy Efficiency,allocate,allocated,524,"> (1) Any user doing data processing or interactive analysis could benefit from multithreading here. Consider the two big for-loops which through all of the genes between compared in the samples, and the for loop which automatically does this for each ""group"" in the ScanPy object. My concern is that there will be issues if you keep the current calculations, but parallelize over the groups. Within that loop, I believe large amounts of memory can be allocated. If it's ""group vs rest"", at least one `X` worth of memory is allocated per loop from matrix subsetting – since there's an `X_group = X[mask]; X_rest = X[~mask]`. If you parallelize over groups, now the max memory usage can be `~ min(n_procs, n_groups) * X` as opposed to `~2X`. For large `X` (probably where you want to see the speed up most), this can make you run out of memory. https://github.com/scverse/scanpy/blob/d26be443373549f26226de367f0213f153556915/scanpy/tools/_rank_genes_groups.py#L164-L178. Another memory related concern comes from `multiprocessing` (mentioned in your email). I think there's recently been some improvement here, but my impression was it's difficult/ impossible to share memory with `multiprocessing` – so everything that goes into or out of a subprocess has to be copied. So while I think we can absolutely make use of more processing power here, I think we need to consider the approach. * The link I mentioned above should reduce copies, and could potentially use a parallelized BLAS for compute; * Much of the loops over ""all of the genes between compared samples"" are already in compiled code, but could be parallelized. > In terms of our use case, an interactive way to run DE via the client is too slow. What is the interface here? Scanpy computes results for all groups at once, but in most interfaces I've used you can only really ""ask"" for one comparison at a time. This could also be much faster, if you can just reduce total computation. ---------. > What @ivirshup was referring to though, i",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2390#issuecomment-1397484486
https://github.com/scverse/scanpy/issues/2390#issuecomment-1397484486:1333,Energy Efficiency,power,power,1333,"u keep the current calculations, but parallelize over the groups. Within that loop, I believe large amounts of memory can be allocated. If it's ""group vs rest"", at least one `X` worth of memory is allocated per loop from matrix subsetting – since there's an `X_group = X[mask]; X_rest = X[~mask]`. If you parallelize over groups, now the max memory usage can be `~ min(n_procs, n_groups) * X` as opposed to `~2X`. For large `X` (probably where you want to see the speed up most), this can make you run out of memory. https://github.com/scverse/scanpy/blob/d26be443373549f26226de367f0213f153556915/scanpy/tools/_rank_genes_groups.py#L164-L178. Another memory related concern comes from `multiprocessing` (mentioned in your email). I think there's recently been some improvement here, but my impression was it's difficult/ impossible to share memory with `multiprocessing` – so everything that goes into or out of a subprocess has to be copied. So while I think we can absolutely make use of more processing power here, I think we need to consider the approach. * The link I mentioned above should reduce copies, and could potentially use a parallelized BLAS for compute; * Much of the loops over ""all of the genes between compared samples"" are already in compiled code, but could be parallelized. > In terms of our use case, an interactive way to run DE via the client is too slow. What is the interface here? Scanpy computes results for all groups at once, but in most interfaces I've used you can only really ""ask"" for one comparison at a time. This could also be much faster, if you can just reduce total computation. ---------. > What @ivirshup was referring to though, is that rank_genes_groups on single cells in general isn't seen anymore as best practice for DE analysis because it doesn't account for pseudoreplication bias. Partially, I'm not sure what comparisons are actually being run. I was also wondering if you'd benefit from something fancy like a covariate. > Diffxpy is currently bei",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2390#issuecomment-1397484486
https://github.com/scverse/scanpy/issues/2390#issuecomment-1397484486:1423,Energy Efficiency,reduce,reduce,1423,"Within that loop, I believe large amounts of memory can be allocated. If it's ""group vs rest"", at least one `X` worth of memory is allocated per loop from matrix subsetting – since there's an `X_group = X[mask]; X_rest = X[~mask]`. If you parallelize over groups, now the max memory usage can be `~ min(n_procs, n_groups) * X` as opposed to `~2X`. For large `X` (probably where you want to see the speed up most), this can make you run out of memory. https://github.com/scverse/scanpy/blob/d26be443373549f26226de367f0213f153556915/scanpy/tools/_rank_genes_groups.py#L164-L178. Another memory related concern comes from `multiprocessing` (mentioned in your email). I think there's recently been some improvement here, but my impression was it's difficult/ impossible to share memory with `multiprocessing` – so everything that goes into or out of a subprocess has to be copied. So while I think we can absolutely make use of more processing power here, I think we need to consider the approach. * The link I mentioned above should reduce copies, and could potentially use a parallelized BLAS for compute; * Much of the loops over ""all of the genes between compared samples"" are already in compiled code, but could be parallelized. > In terms of our use case, an interactive way to run DE via the client is too slow. What is the interface here? Scanpy computes results for all groups at once, but in most interfaces I've used you can only really ""ask"" for one comparison at a time. This could also be much faster, if you can just reduce total computation. ---------. > What @ivirshup was referring to though, is that rank_genes_groups on single cells in general isn't seen anymore as best practice for DE analysis because it doesn't account for pseudoreplication bias. Partially, I'm not sure what comparisons are actually being run. I was also wondering if you'd benefit from something fancy like a covariate. > Diffxpy is currently being reimplemented. . As a heads up, I'm unaware of a timeline here",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2390#issuecomment-1397484486
https://github.com/scverse/scanpy/issues/2390#issuecomment-1397484486:1921,Energy Efficiency,reduce,reduce,1921,"Within that loop, I believe large amounts of memory can be allocated. If it's ""group vs rest"", at least one `X` worth of memory is allocated per loop from matrix subsetting – since there's an `X_group = X[mask]; X_rest = X[~mask]`. If you parallelize over groups, now the max memory usage can be `~ min(n_procs, n_groups) * X` as opposed to `~2X`. For large `X` (probably where you want to see the speed up most), this can make you run out of memory. https://github.com/scverse/scanpy/blob/d26be443373549f26226de367f0213f153556915/scanpy/tools/_rank_genes_groups.py#L164-L178. Another memory related concern comes from `multiprocessing` (mentioned in your email). I think there's recently been some improvement here, but my impression was it's difficult/ impossible to share memory with `multiprocessing` – so everything that goes into or out of a subprocess has to be copied. So while I think we can absolutely make use of more processing power here, I think we need to consider the approach. * The link I mentioned above should reduce copies, and could potentially use a parallelized BLAS for compute; * Much of the loops over ""all of the genes between compared samples"" are already in compiled code, but could be parallelized. > In terms of our use case, an interactive way to run DE via the client is too slow. What is the interface here? Scanpy computes results for all groups at once, but in most interfaces I've used you can only really ""ask"" for one comparison at a time. This could also be much faster, if you can just reduce total computation. ---------. > What @ivirshup was referring to though, is that rank_genes_groups on single cells in general isn't seen anymore as best practice for DE analysis because it doesn't account for pseudoreplication bias. Partially, I'm not sure what comparisons are actually being run. I was also wondering if you'd benefit from something fancy like a covariate. > Diffxpy is currently being reimplemented. . As a heads up, I'm unaware of a timeline here",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2390#issuecomment-1397484486
https://github.com/scverse/scanpy/issues/2390#issuecomment-1397484486:1720,Integrability,interface,interface,1720,"Within that loop, I believe large amounts of memory can be allocated. If it's ""group vs rest"", at least one `X` worth of memory is allocated per loop from matrix subsetting – since there's an `X_group = X[mask]; X_rest = X[~mask]`. If you parallelize over groups, now the max memory usage can be `~ min(n_procs, n_groups) * X` as opposed to `~2X`. For large `X` (probably where you want to see the speed up most), this can make you run out of memory. https://github.com/scverse/scanpy/blob/d26be443373549f26226de367f0213f153556915/scanpy/tools/_rank_genes_groups.py#L164-L178. Another memory related concern comes from `multiprocessing` (mentioned in your email). I think there's recently been some improvement here, but my impression was it's difficult/ impossible to share memory with `multiprocessing` – so everything that goes into or out of a subprocess has to be copied. So while I think we can absolutely make use of more processing power here, I think we need to consider the approach. * The link I mentioned above should reduce copies, and could potentially use a parallelized BLAS for compute; * Much of the loops over ""all of the genes between compared samples"" are already in compiled code, but could be parallelized. > In terms of our use case, an interactive way to run DE via the client is too slow. What is the interface here? Scanpy computes results for all groups at once, but in most interfaces I've used you can only really ""ask"" for one comparison at a time. This could also be much faster, if you can just reduce total computation. ---------. > What @ivirshup was referring to though, is that rank_genes_groups on single cells in general isn't seen anymore as best practice for DE analysis because it doesn't account for pseudoreplication bias. Partially, I'm not sure what comparisons are actually being run. I was also wondering if you'd benefit from something fancy like a covariate. > Diffxpy is currently being reimplemented. . As a heads up, I'm unaware of a timeline here",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2390#issuecomment-1397484486
https://github.com/scverse/scanpy/issues/2390#issuecomment-1397484486:1796,Integrability,interface,interfaces,1796,"Within that loop, I believe large amounts of memory can be allocated. If it's ""group vs rest"", at least one `X` worth of memory is allocated per loop from matrix subsetting – since there's an `X_group = X[mask]; X_rest = X[~mask]`. If you parallelize over groups, now the max memory usage can be `~ min(n_procs, n_groups) * X` as opposed to `~2X`. For large `X` (probably where you want to see the speed up most), this can make you run out of memory. https://github.com/scverse/scanpy/blob/d26be443373549f26226de367f0213f153556915/scanpy/tools/_rank_genes_groups.py#L164-L178. Another memory related concern comes from `multiprocessing` (mentioned in your email). I think there's recently been some improvement here, but my impression was it's difficult/ impossible to share memory with `multiprocessing` – so everything that goes into or out of a subprocess has to be copied. So while I think we can absolutely make use of more processing power here, I think we need to consider the approach. * The link I mentioned above should reduce copies, and could potentially use a parallelized BLAS for compute; * Much of the loops over ""all of the genes between compared samples"" are already in compiled code, but could be parallelized. > In terms of our use case, an interactive way to run DE via the client is too slow. What is the interface here? Scanpy computes results for all groups at once, but in most interfaces I've used you can only really ""ask"" for one comparison at a time. This could also be much faster, if you can just reduce total computation. ---------. > What @ivirshup was referring to though, is that rank_genes_groups on single cells in general isn't seen anymore as best practice for DE analysis because it doesn't account for pseudoreplication bias. Partially, I'm not sure what comparisons are actually being run. I was also wondering if you'd benefit from something fancy like a covariate. > Diffxpy is currently being reimplemented. . As a heads up, I'm unaware of a timeline here",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2390#issuecomment-1397484486
https://github.com/scverse/scanpy/issues/2391#issuecomment-1412756118:330,Performance,load,load,330,"> . Hi Alex,. I basically followed the discussion thread in Seurat: remove the header of the tissue_positions.csv, and change this file name to tissue_positions_list.csv. Based on the discussion of another thread, the scanpy authors are maintaining squidpy for the spatial transcriptomics part. If you use the squidpy function to load the data, there's no such issue (they considered the versions in their code). Best,; Changfeng",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391#issuecomment-1412756118
https://github.com/scverse/scanpy/issues/2393#issuecomment-1372394524:333,Deployability,pipeline,pipeline,333,"Hi thank you so much for you reply. Initially I didn't understand your former statement, but looking at the features table, I understand what you mean now, it's strange that cellranger mixed species alignment adds mm10 or GRCh38 infront of the gene symbols as well which wasn't letting it find the mito-genes on following the scanpy pipeline at the pre-filtering mito genes steps.; ![Screenshot 2023-01-05 at 15 41 09](https://user-images.githubusercontent.com/122033428/210822795-0eb1f9c8-cf9f-4949-a3cf-33dd07a20b03.png); ![Screenshot 2023-01-05 at 15 43 50](https://user-images.githubusercontent.com/122033428/210822805-3b292da8-35d0-4e4a-a600-12eeff38ac7b.png); .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2393#issuecomment-1372394524
https://github.com/scverse/scanpy/issues/2398#issuecomment-1386019022:57,Performance,load,load,57,"Hey @kchl5 and @vitkl,. Muon (`mu.read_10x_h5()`) should load it correctly if the `feature_types` value for the gRNAs is different from the one for the genes. As they are missing, I assume it is. Moreover, just in case you're interested, splitting by `feature_types` is even [a feature](https://github.com/scverse/mudata/blob/4d3b5f4e6039b4a31519584db5461a5809741dce/mudata/_core/mudata.py#L88) of the `MuData` initialiser, so running . ```py; adata = sc.read_10x_h5(h5file, gex_only=False); mdata = MuData(adata); ```. should also work, and this is roughly what muon does. (Thanks for tagging me, @adamgayoso!)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2398#issuecomment-1386019022
https://github.com/scverse/scanpy/issues/2402#issuecomment-2073491552:56,Availability,error,error,56,@mmarwaosman what was the fix. I am getting the similar error,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402#issuecomment-2073491552
https://github.com/scverse/scanpy/pull/2409#issuecomment-1429441613:503,Availability,error,error,503,"Hi @ivirshup, ; I am part of Intel Labs and we are trying to accelerate the genomics pipeline. We are trying to push some changes into scanpy details about which are mentioned in the blog : [https://community.intel.com/t5/Blogs/Tech-Innovation/Artificial-Intelligence-AI/Intel-Labs-Accelerates-Single-cell-RNA-Seq-Analysis/post/1390715#:~:text=Intel%20Labs%20has%20accelerated%20a,of%20a%20single%20A100%20GPU.](url) ; We are facing some issues while pushing some changes in the leiden and louvain. The error states some issues with pca in the scanpy/tests/external/test_scrublet.py::test_scrublet_params when we have not made any changes for the same. Can you please help us to resolve this issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2409#issuecomment-1429441613
https://github.com/scverse/scanpy/pull/2409#issuecomment-1429441613:85,Deployability,pipeline,pipeline,85,"Hi @ivirshup, ; I am part of Intel Labs and we are trying to accelerate the genomics pipeline. We are trying to push some changes into scanpy details about which are mentioned in the blog : [https://community.intel.com/t5/Blogs/Tech-Innovation/Artificial-Intelligence-AI/Intel-Labs-Accelerates-Single-cell-RNA-Seq-Analysis/post/1390715#:~:text=Intel%20Labs%20has%20accelerated%20a,of%20a%20single%20A100%20GPU.](url) ; We are facing some issues while pushing some changes in the leiden and louvain. The error states some issues with pca in the scanpy/tests/external/test_scrublet.py::test_scrublet_params when we have not made any changes for the same. Can you please help us to resolve this issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2409#issuecomment-1429441613
https://github.com/scverse/scanpy/pull/2409#issuecomment-1429441613:551,Testability,test,tests,551,"Hi @ivirshup, ; I am part of Intel Labs and we are trying to accelerate the genomics pipeline. We are trying to push some changes into scanpy details about which are mentioned in the blog : [https://community.intel.com/t5/Blogs/Tech-Innovation/Artificial-Intelligence-AI/Intel-Labs-Accelerates-Single-cell-RNA-Seq-Analysis/post/1390715#:~:text=Intel%20Labs%20has%20accelerated%20a,of%20a%20single%20A100%20GPU.](url) ; We are facing some issues while pushing some changes in the leiden and louvain. The error states some issues with pca in the scanpy/tests/external/test_scrublet.py::test_scrublet_params when we have not made any changes for the same. Can you please help us to resolve this issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2409#issuecomment-1429441613
https://github.com/scverse/scanpy/pull/2409#issuecomment-1432748647:76,Deployability,update,updates,76,"Hi @Zethson,; Thank you so much for the response. Please let us know if any updates/changes are required to be done from our side in the above contribution, we will do them at the earliest. Also, please let us know if we need to do anything else for fixing the issues in the PR at the moment.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2409#issuecomment-1432748647
https://github.com/scverse/scanpy/issues/2411#issuecomment-1429887964:59,Deployability,install,installing,59,"To users: you can work around this in your environments by installing the previous version of matplotlib, for example with:. ```; $ pip install 'matplotlib<3.7'; ```. and/or adding a similar version specification to your `pyproject.toml`/`setup.py`/equivalent file, like https://github.com/single-cell-data/TileDB-SOMA/commit/0bc97e893edd2ab6b8dc7d76635a079ae7f91516.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2411#issuecomment-1429887964
https://github.com/scverse/scanpy/issues/2411#issuecomment-1429887964:136,Deployability,install,install,136,"To users: you can work around this in your environments by installing the previous version of matplotlib, for example with:. ```; $ pip install 'matplotlib<3.7'; ```. and/or adding a similar version specification to your `pyproject.toml`/`setup.py`/equivalent file, like https://github.com/single-cell-data/TileDB-SOMA/commit/0bc97e893edd2ab6b8dc7d76635a079ae7f91516.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2411#issuecomment-1429887964
https://github.com/scverse/scanpy/issues/2413#issuecomment-1801466509:143,Availability,mainten,maintenance,143,"#2733 bumps the minimum version **up** to 3.6 and adds two good reasons why that exact minimum version requirement is chosen:. 1. matplotlib’s maintenance schedule drops support for 3.5 in a little bit; 2. we use a feature from 3.5. If some piece of infrastructure doesn’t allow bumping versions of client libraries, that piece of infrastructure needs improvement. Jupyter allows distinct environments for kernels and the server for a reason. So while colab should be able to pin and use whatever they need on the server, there’s zero reason why colab should dictate any version of anything other than `ipykernel` for the user environment.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2413#issuecomment-1801466509
https://github.com/scverse/scanpy/issues/2413#issuecomment-1801466509:155,Energy Efficiency,schedul,schedule,155,"#2733 bumps the minimum version **up** to 3.6 and adds two good reasons why that exact minimum version requirement is chosen:. 1. matplotlib’s maintenance schedule drops support for 3.5 in a little bit; 2. we use a feature from 3.5. If some piece of infrastructure doesn’t allow bumping versions of client libraries, that piece of infrastructure needs improvement. Jupyter allows distinct environments for kernels and the server for a reason. So while colab should be able to pin and use whatever they need on the server, there’s zero reason why colab should dictate any version of anything other than `ipykernel` for the user environment.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2413#issuecomment-1801466509
https://github.com/scverse/scanpy/pull/2419#issuecomment-1433063184:326,Availability,error,error-reference,326,# [Codecov](https://codecov.io/gh/scverse/scanpy/pull/2419?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@97c2617`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 72ea692 differs from pull request most recent head 8fb038a. Consider uploading reports for the commit 8fb038a to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2419 +/- ##; ========================================; Coverage ? 71.83% ; ========================================; Files ? 98 ; Lines ? 11543 ; Branches ? 0 ; ========================================; Hits ? 8292 ; Misses ? 3251 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2419#issuecomment-1433063184
https://github.com/scverse/scanpy/pull/2419#issuecomment-1433063184:274,Usability,learn,learn,274,# [Codecov](https://codecov.io/gh/scverse/scanpy/pull/2419?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@97c2617`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 72ea692 differs from pull request most recent head 8fb038a. Consider uploading reports for the commit 8fb038a to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2419 +/- ##; ========================================; Coverage ? 71.83% ; ========================================; Files ? 98 ; Lines ? 11543 ; Branches ? 0 ; ========================================; Hits ? 8292 ; Misses ? 3251 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2419#issuecomment-1433063184
https://github.com/scverse/scanpy/pull/2424#issuecomment-1450549756:82,Deployability,release,release,82,"> @giovp feel free to approve and merge. One request first:; > ; > Can this get a release note?. for sure, @LLehner could you? think he's is on holiday until next week",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2424#issuecomment-1450549756
https://github.com/scverse/scanpy/pull/2424#issuecomment-1910300363:257,Safety,avoid,avoid,257,"With https://github.com/scverse/spatialdata-io/pull/102 we could consider replacing `scanpy.read_visium` with. ```python; def read_visium(*args, **kwargs): ; import spatialdata_io; return spatialdata_io.visium(*args, **kwargs).to_legacy_anndata(); ```. and avoid maintaing the annoying spaceranger output parsing in multiple locations.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2424#issuecomment-1910300363
https://github.com/scverse/scanpy/issues/2427#issuecomment-1860902089:71,Deployability,release,released,71,Thanks! you can just specify `n_top_genes=2000` or so until the fix is released,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2427#issuecomment-1860902089
https://github.com/scverse/scanpy/issues/2430#issuecomment-1442858802:63,Availability,error,error,63,"but when i run ; sc.pl.pca(adata, color='CST3'); it return the error,how could i fix it?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430#issuecomment-1442858802
https://github.com/scverse/scanpy/issues/2431#issuecomment-1452342219:233,Availability,error,error,233,"> No worries. I meant here: https://github.com/scverse/scanpy/blob/master/scanpy/tools/_leiden.py. Sorry I still don't really know what to do. After the RandomState object is passed to leiden, it passes it to igraph, which raises an error because igraph wants an int to initialize [it's own rng system](https://igraph.org/c/doc/igraph-Random.html). It seems to me like there's no easy way to fix this, no?. Maybe I should just give it an int instead? I'd just like my clustering to be reproducible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2431#issuecomment-1452342219
https://github.com/scverse/scanpy/pull/2435#issuecomment-1451099582:326,Availability,error,error-reference,326,# [Codecov](https://codecov.io/gh/scverse/scanpy/pull/2435?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@1fbbfcd`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2435 +/- ##; ========================================; Coverage ? 71.88% ; ========================================; Files ? 98 ; Lines ? 11546 ; Branches ? 0 ; ========================================; Hits ? 8300 ; Misses ? 3246 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2435#issuecomment-1451099582
https://github.com/scverse/scanpy/pull/2435#issuecomment-1451099582:274,Usability,learn,learn,274,# [Codecov](https://codecov.io/gh/scverse/scanpy/pull/2435?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@1fbbfcd`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2435 +/- ##; ========================================; Coverage ? 71.88% ; ========================================; Files ? 98 ; Lines ? 11546 ; Branches ? 0 ; ========================================; Hits ? 8300 ; Misses ? 3246 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2435#issuecomment-1451099582
https://github.com/scverse/scanpy/issues/2436#issuecomment-1465318104:502,Integrability,Message,Message,502,"Hi Lukas,. I am sorry, but what is a PR?. Best; Jin. ᐧ. On Fri, Mar 10, 2023 at 5:02 AM Lukas Heumos ***@***.***>; wrote:. > Would you be willing to file a PR for this? Thank you!; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/scverse/scanpy/issues/2436#issuecomment-1463561536>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AFOKIW345IGREVLPLR7F6BLW3L32JANCNFSM6AAAAAAVQOJ5FE>; > .; > You are receiving this because you authored the thread.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2436#issuecomment-1465318104
https://github.com/scverse/scanpy/issues/2436#issuecomment-1479764509:670,Integrability,Message,Message,670,"I have been trying but I am not sure how to do it in an appropriate way. Can you teach me how to do it? I am not super familiar with git stuff since; I am not really using it.; ᐧ. On Mon, Mar 13, 2023 at 5:10 AM Lukas Heumos ***@***.***>; wrote:. > A pull request that fixes this :); >; > See https://scanpy.readthedocs.io/en/stable/dev/index.html; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/scverse/scanpy/issues/2436#issuecomment-1465764371>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AFOKIW6MR6MSUCKJ2YTVG53W33P75ANCNFSM6AAAAAAVQOJ5FE>; > .; > You are receiving this because you authored the thread.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2436#issuecomment-1479764509
https://github.com/scverse/scanpy/issues/2438#issuecomment-1474040127:23,Deployability,install,installed,23,I uninstalled and then installed scanpy. This resolves the issue.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2438#issuecomment-1474040127
https://github.com/scverse/scanpy/issues/2440#issuecomment-1652367453:29,Availability,error,error,29,"I have also encountered this error, but specifically in the scanpy tutorial outlined [here](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). That should make reproducibility easier. The error occurs under the _Finding Marker Genes_ heading, specifically the following line:. ```py; sc.tl.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'); sc.pl.rank_genes_groups(adata, groups=['0'], n_genes=20); ```. With an error output of the following:. ```pytb; ranking genes; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); Cell In[49], line 1; ----> 1 sc.tl.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'); 2 sc.pl.rank_genes_groups(adata, groups=['0'], n_genes=20). File ~/Desktop/data/env/lib/python3.11/site-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds); 580 adata.uns[key_added] = {}; 581 adata.uns[key_added]['params'] = dict(; 582 groupby=groupby,; 583 reference=reference,; (...); 587 corr_method=corr_method,; 588 ); --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts); 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':; 593 logg.warning(; 594 ""It seems you use rank_genes_groups on the raw count data. ""; 595 ""Please logarithmize your data before calling rank_genes_groups.""; 596 ). File ~/Desktop/data/env/lib/python3.11/site-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts); 82 def __init__(; 83 self,; 84 adata,; (...); 90 comp_pts=False,; 91 ):; ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:; 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])); 95 else:. KeyError: '",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440#issuecomment-1652367453
https://github.com/scverse/scanpy/issues/2440#issuecomment-1652367453:201,Availability,error,error,201,"I have also encountered this error, but specifically in the scanpy tutorial outlined [here](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). That should make reproducibility easier. The error occurs under the _Finding Marker Genes_ heading, specifically the following line:. ```py; sc.tl.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'); sc.pl.rank_genes_groups(adata, groups=['0'], n_genes=20); ```. With an error output of the following:. ```pytb; ranking genes; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); Cell In[49], line 1; ----> 1 sc.tl.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'); 2 sc.pl.rank_genes_groups(adata, groups=['0'], n_genes=20). File ~/Desktop/data/env/lib/python3.11/site-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds); 580 adata.uns[key_added] = {}; 581 adata.uns[key_added]['params'] = dict(; 582 groupby=groupby,; 583 reference=reference,; (...); 587 corr_method=corr_method,; 588 ); --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts); 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':; 593 logg.warning(; 594 ""It seems you use rank_genes_groups on the raw count data. ""; 595 ""Please logarithmize your data before calling rank_genes_groups.""; 596 ). File ~/Desktop/data/env/lib/python3.11/site-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts); 82 def __init__(; 83 self,; 84 adata,; (...); 90 comp_pts=False,; 91 ):; ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:; 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])); 95 else:. KeyError: '",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440#issuecomment-1652367453
https://github.com/scverse/scanpy/issues/2440#issuecomment-1652367453:458,Availability,error,error,458,"I have also encountered this error, but specifically in the scanpy tutorial outlined [here](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). That should make reproducibility easier. The error occurs under the _Finding Marker Genes_ heading, specifically the following line:. ```py; sc.tl.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'); sc.pl.rank_genes_groups(adata, groups=['0'], n_genes=20); ```. With an error output of the following:. ```pytb; ranking genes; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); Cell In[49], line 1; ----> 1 sc.tl.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'); 2 sc.pl.rank_genes_groups(adata, groups=['0'], n_genes=20). File ~/Desktop/data/env/lib/python3.11/site-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds); 580 adata.uns[key_added] = {}; 581 adata.uns[key_added]['params'] = dict(; 582 groupby=groupby,; 583 reference=reference,; (...); 587 corr_method=corr_method,; 588 ); --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts); 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':; 593 logg.warning(; 594 ""It seems you use rank_genes_groups on the raw count data. ""; 595 ""Please logarithmize your data before calling rank_genes_groups.""; 596 ). File ~/Desktop/data/env/lib/python3.11/site-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts); 82 def __init__(; 83 self,; 84 adata,; (...); 90 comp_pts=False,; 91 ):; ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:; 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])); 95 else:. KeyError: '",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440#issuecomment-1652367453
https://github.com/scverse/scanpy/issues/2440#issuecomment-1652367453:2220,Deployability,install,install,2220,"8 ); --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts); 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':; 593 logg.warning(; 594 ""It seems you use rank_genes_groups on the raw count data. ""; 595 ""Please logarithmize your data before calling rank_genes_groups.""; 596 ). File ~/Desktop/data/env/lib/python3.11/site-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts); 82 def __init__(; 83 self,; 84 adata,; (...); 90 comp_pts=False,; 91 ):; ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:; 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])); 95 else:. KeyError: 'base'; ```. I've pasted the output of scanpy.logging.print_versions() details below as requested, which includes a verification of used scanpy version (latest version, 1.9.3). It may not be important, but I also had to install `leidenalg` manually in the middle of the tutorial. That's the only deviation I made from the original tutorial. <details>. ```; -----; anndata 0.9.2; scanpy 1.9.3; -----; PIL 10.0.0; appnope 0.1.3; asttokens NA; backcall 0.2.0; comm 0.1.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; executing 1.2.0; h5py 3.9.0; igraph 0.10.6; ipykernel 6.25.0; jedi 0.18.2; joblib 1.3.1; kiwisolver 1.4.4; leidenalg 0.10.1; llvmlite 0.40.1; matplotlib 3.7.2; mpl_toolkits NA; natsort 8.4.0; numba 0.57.1; numpy 1.24.4; packaging 23.1; pandas 2.0.3; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.9.1; prompt_toolkit 3.0.39; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.15.1; pyparsing 3.0.9; pytz 2023.3; scipy 1.11.1; session_info 1.0.0; sitecustomize NA; six 1.16.0; sklearn 1.3.0; stack_data 0.6.2; texttable 1.6.7; ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440#issuecomment-1652367453
https://github.com/scverse/scanpy/issues/2440#issuecomment-1652367453:3519,Deployability,update,updated,3519," ~/Desktop/data/env/lib/python3.11/site-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts); 82 def __init__(; 83 self,; 84 adata,; (...); 90 comp_pts=False,; 91 ):; ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:; 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])); 95 else:. KeyError: 'base'; ```. I've pasted the output of scanpy.logging.print_versions() details below as requested, which includes a verification of used scanpy version (latest version, 1.9.3). It may not be important, but I also had to install `leidenalg` manually in the middle of the tutorial. That's the only deviation I made from the original tutorial. <details>. ```; -----; anndata 0.9.2; scanpy 1.9.3; -----; PIL 10.0.0; appnope 0.1.3; asttokens NA; backcall 0.2.0; comm 0.1.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; executing 1.2.0; h5py 3.9.0; igraph 0.10.6; ipykernel 6.25.0; jedi 0.18.2; joblib 1.3.1; kiwisolver 1.4.4; leidenalg 0.10.1; llvmlite 0.40.1; matplotlib 3.7.2; mpl_toolkits NA; natsort 8.4.0; numba 0.57.1; numpy 1.24.4; packaging 23.1; pandas 2.0.3; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.9.1; prompt_toolkit 3.0.39; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.15.1; pyparsing 3.0.9; pytz 2023.3; scipy 1.11.1; session_info 1.0.0; sitecustomize NA; six 1.16.0; sklearn 1.3.0; stack_data 0.6.2; texttable 1.6.7; threadpoolctl 3.2.0; tornado 6.3.2; traitlets 5.9.0; wcwidth 0.2.6; zmq 25.1.0; -----; IPython 8.14.0; jupyter_client 8.3.0; jupyter_core 5.3.1; -----; Python 3.11.4 (main, Jun 20 2023, 17:23:00) [Clang 14.0.3 (clang-1403.0.22.14.1)]; macOS-13.5-arm64-i386-64bit; -----; Session information updated at 2023-07-26 10:47; ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440#issuecomment-1652367453
https://github.com/scverse/scanpy/issues/2440#issuecomment-1652367453:1386,Testability,log,logreg,1386," sc.pl.rank_genes_groups(adata, groups=['0'], n_genes=20); ```. With an error output of the following:. ```pytb; ranking genes; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); Cell In[49], line 1; ----> 1 sc.tl.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'); 2 sc.pl.rank_genes_groups(adata, groups=['0'], n_genes=20). File ~/Desktop/data/env/lib/python3.11/site-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds); 580 adata.uns[key_added] = {}; 581 adata.uns[key_added]['params'] = dict(; 582 groupby=groupby,; 583 reference=reference,; (...); 587 corr_method=corr_method,; 588 ); --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts); 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':; 593 logg.warning(; 594 ""It seems you use rank_genes_groups on the raw count data. ""; 595 ""Please logarithmize your data before calling rank_genes_groups.""; 596 ). File ~/Desktop/data/env/lib/python3.11/site-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts); 82 def __init__(; 83 self,; 84 adata,; (...); 90 comp_pts=False,; 91 ):; ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:; 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])); 95 else:. KeyError: 'base'; ```. I've pasted the output of scanpy.logging.print_versions() details below as requested, which includes a verification of used scanpy version (latest version, 1.9.3). It may not be important, but I also had to install `leidenalg` manually in the middle of the tutorial. That's the only deviation I made from the original tutorial. <details>. ```; -----; anndata 0.9.2; scanpy 1",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440#issuecomment-1652367453
https://github.com/scverse/scanpy/issues/2440#issuecomment-1652367453:1400,Testability,log,logg,1400," sc.pl.rank_genes_groups(adata, groups=['0'], n_genes=20); ```. With an error output of the following:. ```pytb; ranking genes; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); Cell In[49], line 1; ----> 1 sc.tl.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'); 2 sc.pl.rank_genes_groups(adata, groups=['0'], n_genes=20). File ~/Desktop/data/env/lib/python3.11/site-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds); 580 adata.uns[key_added] = {}; 581 adata.uns[key_added]['params'] = dict(; 582 groupby=groupby,; 583 reference=reference,; (...); 587 corr_method=corr_method,; 588 ); --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts); 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':; 593 logg.warning(; 594 ""It seems you use rank_genes_groups on the raw count data. ""; 595 ""Please logarithmize your data before calling rank_genes_groups.""; 596 ). File ~/Desktop/data/env/lib/python3.11/site-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts); 82 def __init__(; 83 self,; 84 adata,; (...); 90 comp_pts=False,; 91 ):; ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:; 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])); 95 else:. KeyError: 'base'; ```. I've pasted the output of scanpy.logging.print_versions() details below as requested, which includes a verification of used scanpy version (latest version, 1.9.3). It may not be important, but I also had to install `leidenalg` manually in the middle of the tutorial. That's the only deviation I made from the original tutorial. <details>. ```; -----; anndata 0.9.2; scanpy 1",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440#issuecomment-1652367453
https://github.com/scverse/scanpy/issues/2440#issuecomment-1652367453:1493,Testability,log,logarithmize,1493," ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); Cell In[49], line 1; ----> 1 sc.tl.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'); 2 sc.pl.rank_genes_groups(adata, groups=['0'], n_genes=20). File ~/Desktop/data/env/lib/python3.11/site-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds); 580 adata.uns[key_added] = {}; 581 adata.uns[key_added]['params'] = dict(; 582 groupby=groupby,; 583 reference=reference,; (...); 587 corr_method=corr_method,; 588 ); --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts); 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':; 593 logg.warning(; 594 ""It seems you use rank_genes_groups on the raw count data. ""; 595 ""Please logarithmize your data before calling rank_genes_groups.""; 596 ). File ~/Desktop/data/env/lib/python3.11/site-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts); 82 def __init__(; 83 self,; 84 adata,; (...); 90 comp_pts=False,; 91 ):; ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:; 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])); 95 else:. KeyError: 'base'; ```. I've pasted the output of scanpy.logging.print_versions() details below as requested, which includes a verification of used scanpy version (latest version, 1.9.3). It may not be important, but I also had to install `leidenalg` manually in the middle of the tutorial. That's the only deviation I made from the original tutorial. <details>. ```; -----; anndata 0.9.2; scanpy 1.9.3; -----; PIL 10.0.0; appnope 0.1.3; asttokens NA; backcall 0.2.0; comm 0.1.3; cycler 0.10.0; cython_runtime NA; dateutil 2",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440#issuecomment-1652367453
https://github.com/scverse/scanpy/issues/2440#issuecomment-1652367453:1946,Testability,log,log,1946,", groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds); 580 adata.uns[key_added] = {}; 581 adata.uns[key_added]['params'] = dict(; 582 groupby=groupby,; 583 reference=reference,; (...); 587 corr_method=corr_method,; 588 ); --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts); 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':; 593 logg.warning(; 594 ""It seems you use rank_genes_groups on the raw count data. ""; 595 ""Please logarithmize your data before calling rank_genes_groups.""; 596 ). File ~/Desktop/data/env/lib/python3.11/site-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts); 82 def __init__(; 83 self,; 84 adata,; (...); 90 comp_pts=False,; 91 ):; ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:; 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])); 95 else:. KeyError: 'base'; ```. I've pasted the output of scanpy.logging.print_versions() details below as requested, which includes a verification of used scanpy version (latest version, 1.9.3). It may not be important, but I also had to install `leidenalg` manually in the middle of the tutorial. That's the only deviation I made from the original tutorial. <details>. ```; -----; anndata 0.9.2; scanpy 1.9.3; -----; PIL 10.0.0; appnope 0.1.3; asttokens NA; backcall 0.2.0; comm 0.1.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; executing 1.2.0; h5py 3.9.0; igraph 0.10.6; ipykernel 6.25.0; jedi 0.18.2; joblib 1.3.1; kiwisolver 1.4.4; leidenalg 0.10.1; llvmlite 0.40.1; matplotlib 3.7.2; mpl_toolkits NA; natsort 8.4.0; numba 0.57.1; numpy 1.24.4; packaging 23.1; pandas 2.0.3; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.9.1; prompt_toolkit 3.0.39; psutil 5.9.5; ptyprocess 0.7.0; pure_eval ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440#issuecomment-1652367453
https://github.com/scverse/scanpy/issues/2440#issuecomment-1652367453:2046,Testability,log,logging,2046,"ayer, **kwds); 580 adata.uns[key_added] = {}; 581 adata.uns[key_added]['params'] = dict(; 582 groupby=groupby,; 583 reference=reference,; (...); 587 corr_method=corr_method,; 588 ); --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts); 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':; 593 logg.warning(; 594 ""It seems you use rank_genes_groups on the raw count data. ""; 595 ""Please logarithmize your data before calling rank_genes_groups.""; 596 ). File ~/Desktop/data/env/lib/python3.11/site-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts); 82 def __init__(; 83 self,; 84 adata,; (...); 90 comp_pts=False,; 91 ):; ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:; 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])); 95 else:. KeyError: 'base'; ```. I've pasted the output of scanpy.logging.print_versions() details below as requested, which includes a verification of used scanpy version (latest version, 1.9.3). It may not be important, but I also had to install `leidenalg` manually in the middle of the tutorial. That's the only deviation I made from the original tutorial. <details>. ```; -----; anndata 0.9.2; scanpy 1.9.3; -----; PIL 10.0.0; appnope 0.1.3; asttokens NA; backcall 0.2.0; comm 0.1.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; executing 1.2.0; h5py 3.9.0; igraph 0.10.6; ipykernel 6.25.0; jedi 0.18.2; joblib 1.3.1; kiwisolver 1.4.4; leidenalg 0.10.1; llvmlite 0.40.1; matplotlib 3.7.2; mpl_toolkits NA; natsort 8.4.0; numba 0.57.1; numpy 1.24.4; packaging 23.1; pandas 2.0.3; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.9.1; prompt_toolkit 3.0.39; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; py",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440#issuecomment-1652367453
https://github.com/scverse/scanpy/issues/2442#issuecomment-1520632755:59,Deployability,update,updates,59,I have the same issue. I am eager to hear if there are any updates.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2442#issuecomment-1520632755
https://github.com/scverse/scanpy/issues/2444#issuecomment-2084906007:224,Deployability,integrat,integrating,224,"Hi, I've now implemented many scanpy plots using Marsilea in the notebook. Please let me know what you think of it and if you have any further questions or requests that could be useful for the community. Looking forward to integrating this!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444#issuecomment-2084906007
https://github.com/scverse/scanpy/issues/2444#issuecomment-2084906007:224,Integrability,integrat,integrating,224,"Hi, I've now implemented many scanpy plots using Marsilea in the notebook. Please let me know what you think of it and if you have any further questions or requests that could be useful for the community. Looking forward to integrating this!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444#issuecomment-2084906007
https://github.com/scverse/scanpy/issues/2444#issuecomment-2352465866:229,Performance,perform,performance,229,"@Mr-Milk Could you elaborate on why you think this functionality belongs within scanpy? Recently, we've been thinking a bit about what should go in vs. what should not, and most of the recent/upcoming additions are around either performance (dask) or vendoring tools that are either essential + in need of some love (maybe bbknn) or tools that we once relied on, but are no longer maintained and we need to bring in to the package to ensure continuity (scrublet). . Your tool seems great, well-maintained, and has a clean API so I am not sure what it would add for either project to have it in `scanpy`. But I am open to be convinced!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444#issuecomment-2352465866
https://github.com/scverse/scanpy/issues/2444#issuecomment-2352637693:572,Availability,mainten,maintenance,572,"Hi Ilan, thanks for your interest. One of the main advantages of Marsilea is the flexibility for layout plots and adding/removing components compared to the pre-defined visualization APIs in Scanpy. From my perspective, there could be two ways of integration: . 1) Reimplement some of the visualization APIs in scanpy using Marsilea, but we don't expose Marsilea to the user. You will always have a plot with known rendered size and fixed layout compared to directly using matplotlib. This could significantly reduce the code base complexities on the scanpy side, so less maintenance work. 2) Exposing the Marsilea API, we can create a visualization object that simulates the Marsilea API but is tailored specifically for `AnnData`. Maybe include some data transformation and aggregation functions that the user could directly apply during visualization. But this design doesn't make much difference compared to directly using Masilea as shown in the [notebook](https://scanpy.readthedocs.io/en/stable/how-to/plotting-with-marsilea.html).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444#issuecomment-2352637693
https://github.com/scverse/scanpy/issues/2444#issuecomment-2352637693:247,Deployability,integrat,integration,247,"Hi Ilan, thanks for your interest. One of the main advantages of Marsilea is the flexibility for layout plots and adding/removing components compared to the pre-defined visualization APIs in Scanpy. From my perspective, there could be two ways of integration: . 1) Reimplement some of the visualization APIs in scanpy using Marsilea, but we don't expose Marsilea to the user. You will always have a plot with known rendered size and fixed layout compared to directly using matplotlib. This could significantly reduce the code base complexities on the scanpy side, so less maintenance work. 2) Exposing the Marsilea API, we can create a visualization object that simulates the Marsilea API but is tailored specifically for `AnnData`. Maybe include some data transformation and aggregation functions that the user could directly apply during visualization. But this design doesn't make much difference compared to directly using Masilea as shown in the [notebook](https://scanpy.readthedocs.io/en/stable/how-to/plotting-with-marsilea.html).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444#issuecomment-2352637693
https://github.com/scverse/scanpy/issues/2444#issuecomment-2352637693:510,Energy Efficiency,reduce,reduce,510,"Hi Ilan, thanks for your interest. One of the main advantages of Marsilea is the flexibility for layout plots and adding/removing components compared to the pre-defined visualization APIs in Scanpy. From my perspective, there could be two ways of integration: . 1) Reimplement some of the visualization APIs in scanpy using Marsilea, but we don't expose Marsilea to the user. You will always have a plot with known rendered size and fixed layout compared to directly using matplotlib. This could significantly reduce the code base complexities on the scanpy side, so less maintenance work. 2) Exposing the Marsilea API, we can create a visualization object that simulates the Marsilea API but is tailored specifically for `AnnData`. Maybe include some data transformation and aggregation functions that the user could directly apply during visualization. But this design doesn't make much difference compared to directly using Masilea as shown in the [notebook](https://scanpy.readthedocs.io/en/stable/how-to/plotting-with-marsilea.html).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444#issuecomment-2352637693
https://github.com/scverse/scanpy/issues/2444#issuecomment-2352637693:247,Integrability,integrat,integration,247,"Hi Ilan, thanks for your interest. One of the main advantages of Marsilea is the flexibility for layout plots and adding/removing components compared to the pre-defined visualization APIs in Scanpy. From my perspective, there could be two ways of integration: . 1) Reimplement some of the visualization APIs in scanpy using Marsilea, but we don't expose Marsilea to the user. You will always have a plot with known rendered size and fixed layout compared to directly using matplotlib. This could significantly reduce the code base complexities on the scanpy side, so less maintenance work. 2) Exposing the Marsilea API, we can create a visualization object that simulates the Marsilea API but is tailored specifically for `AnnData`. Maybe include some data transformation and aggregation functions that the user could directly apply during visualization. But this design doesn't make much difference compared to directly using Masilea as shown in the [notebook](https://scanpy.readthedocs.io/en/stable/how-to/plotting-with-marsilea.html).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444#issuecomment-2352637693
https://github.com/scverse/scanpy/issues/2444#issuecomment-2352637693:347,Security,expose,expose,347,"Hi Ilan, thanks for your interest. One of the main advantages of Marsilea is the flexibility for layout plots and adding/removing components compared to the pre-defined visualization APIs in Scanpy. From my perspective, there could be two ways of integration: . 1) Reimplement some of the visualization APIs in scanpy using Marsilea, but we don't expose Marsilea to the user. You will always have a plot with known rendered size and fixed layout compared to directly using matplotlib. This could significantly reduce the code base complexities on the scanpy side, so less maintenance work. 2) Exposing the Marsilea API, we can create a visualization object that simulates the Marsilea API but is tailored specifically for `AnnData`. Maybe include some data transformation and aggregation functions that the user could directly apply during visualization. But this design doesn't make much difference compared to directly using Masilea as shown in the [notebook](https://scanpy.readthedocs.io/en/stable/how-to/plotting-with-marsilea.html).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444#issuecomment-2352637693
https://github.com/scverse/scanpy/issues/2444#issuecomment-2371719939:303,Deployability,integrat,integrating,303,"@Mr-Milk I see. I think right now, it's probably not going to go into scanpy pre 2.0.0 (as marked by the milestone). @flying-sheep is leading the new plotting effort so I'll step back. But roughly from my perspective, 1. seems useful perhaps for some internal stuff but 2. seems perhaps a point against integrating directly since; > this design doesn't make much difference compared to directly using Marsilea. Maybe there's some middle ground? Some definte API for integration into 2.0.0 that wouldn't require full integration but could give this sort of `return` functionality?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444#issuecomment-2371719939
https://github.com/scverse/scanpy/issues/2444#issuecomment-2371719939:466,Deployability,integrat,integration,466,"@Mr-Milk I see. I think right now, it's probably not going to go into scanpy pre 2.0.0 (as marked by the milestone). @flying-sheep is leading the new plotting effort so I'll step back. But roughly from my perspective, 1. seems useful perhaps for some internal stuff but 2. seems perhaps a point against integrating directly since; > this design doesn't make much difference compared to directly using Marsilea. Maybe there's some middle ground? Some definte API for integration into 2.0.0 that wouldn't require full integration but could give this sort of `return` functionality?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444#issuecomment-2371719939
https://github.com/scverse/scanpy/issues/2444#issuecomment-2371719939:516,Deployability,integrat,integration,516,"@Mr-Milk I see. I think right now, it's probably not going to go into scanpy pre 2.0.0 (as marked by the milestone). @flying-sheep is leading the new plotting effort so I'll step back. But roughly from my perspective, 1. seems useful perhaps for some internal stuff but 2. seems perhaps a point against integrating directly since; > this design doesn't make much difference compared to directly using Marsilea. Maybe there's some middle ground? Some definte API for integration into 2.0.0 that wouldn't require full integration but could give this sort of `return` functionality?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444#issuecomment-2371719939
https://github.com/scverse/scanpy/issues/2444#issuecomment-2371719939:303,Integrability,integrat,integrating,303,"@Mr-Milk I see. I think right now, it's probably not going to go into scanpy pre 2.0.0 (as marked by the milestone). @flying-sheep is leading the new plotting effort so I'll step back. But roughly from my perspective, 1. seems useful perhaps for some internal stuff but 2. seems perhaps a point against integrating directly since; > this design doesn't make much difference compared to directly using Marsilea. Maybe there's some middle ground? Some definte API for integration into 2.0.0 that wouldn't require full integration but could give this sort of `return` functionality?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444#issuecomment-2371719939
https://github.com/scverse/scanpy/issues/2444#issuecomment-2371719939:466,Integrability,integrat,integration,466,"@Mr-Milk I see. I think right now, it's probably not going to go into scanpy pre 2.0.0 (as marked by the milestone). @flying-sheep is leading the new plotting effort so I'll step back. But roughly from my perspective, 1. seems useful perhaps for some internal stuff but 2. seems perhaps a point against integrating directly since; > this design doesn't make much difference compared to directly using Marsilea. Maybe there's some middle ground? Some definte API for integration into 2.0.0 that wouldn't require full integration but could give this sort of `return` functionality?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444#issuecomment-2371719939
https://github.com/scverse/scanpy/issues/2444#issuecomment-2371719939:516,Integrability,integrat,integration,516,"@Mr-Milk I see. I think right now, it's probably not going to go into scanpy pre 2.0.0 (as marked by the milestone). @flying-sheep is leading the new plotting effort so I'll step back. But roughly from my perspective, 1. seems useful perhaps for some internal stuff but 2. seems perhaps a point against integrating directly since; > this design doesn't make much difference compared to directly using Marsilea. Maybe there's some middle ground? Some definte API for integration into 2.0.0 that wouldn't require full integration but could give this sort of `return` functionality?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444#issuecomment-2371719939
https://github.com/scverse/scanpy/issues/2444#issuecomment-2379271488:75,Deployability,integrat,integration,75,"Thanks for the clarification. I don't have a good idea for a middle ground integration now. If possible, I would like to hear what @flying-sheep suggests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444#issuecomment-2379271488
https://github.com/scverse/scanpy/issues/2444#issuecomment-2379271488:75,Integrability,integrat,integration,75,"Thanks for the clarification. I don't have a good idea for a middle ground integration now. If possible, I would like to hear what @flying-sheep suggests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444#issuecomment-2379271488
https://github.com/scverse/scanpy/issues/2445#issuecomment-1462121858:19,Deployability,install,install,19,resolved via . pip install 'matplotlib<3.7',MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445#issuecomment-1462121858
https://github.com/scverse/scanpy/issues/2445#issuecomment-1462142035:28,Deployability,release,releases,28,This is also fixed by newer releases of scanpy,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445#issuecomment-1462142035
https://github.com/scverse/scanpy/issues/2449#issuecomment-1465762834:15,Availability,error,error,15,That's an HTTP error. You need to report this to the data hoster aka EBI,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449#issuecomment-1465762834
https://github.com/scverse/scanpy/pull/2457#issuecomment-1511587339:230,Availability,avail,available,230,"Hi @Zethson ,; The reason why we introduced flavors here is that we wanted the traditional implementation to be present in case anyone wanted to use it. We just introduced our implementation as a faster alternative to the already available one. In case replacing the code is required, we can do that as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1511587339
https://github.com/scverse/scanpy/pull/2457#issuecomment-1533308183:1839,Availability,error,errors,1839," _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _; ../../miniconda3/envs/scanpy/lib/python3.9/functools.py:888: in wrapper; return dispatch(args[0].__class__)(*args, **kw); scanpy/preprocessing/_simple.py:888: in scale_anndata; X, adata.var[""mean""], adata.var[""std""] = do_scale(; ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:468: in _compile_for_args; error_rewrite(e, 'typing'); _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. e = TypingError('Failed in nopython mode pipeline (step: nopython frontend)\nnon-precise type pyobject\nDuring: typing of ...y the following argument(s):\n- argument 0: Cannot determine Numba type of <class \'scipy.sparse._csr.csr_matrix\'>\n'); issue_type = 'typing'. def error_rewrite(e, issue_type):; """"""; Rewrite and raise Exception `e` with help supplied based on the; specified issue_type.; """"""; if config.SHOW_HELP:; help_msg = errors.error_extras[issue_type]; e.patch_message('\n'.join((str(e).rstrip(), help_msg))); if config.FULL_TRACEBACKS:; raise e; else:; > raise e.with_traceback(None); E numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); E non-precise type pyobject; E During: typing of argument at /home/zeth/PycharmProjects/scanpy/scanpy/preprocessing/_simple.py (763); E ; E File ""scanpy/preprocessing/_simple.py"", line 763:; E def do_scale(X, maxv, nthr):; E <source elided>; E # t0= time.time(); E s = np.zeros((nthr, X.shape[1])); E ^ ; E ; E This error may have been caused by the following argument(s):; E - argument 0: Cannot determine Numba type of <class 'scipy.sparse._csr.csr_matrix'>. ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:409: TypingError; ```. When trying to use the new flavor with the existing test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1533308183
https://github.com/scverse/scanpy/pull/2457#issuecomment-1533308183:2018,Availability,error,errors,2018," _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _; ../../miniconda3/envs/scanpy/lib/python3.9/functools.py:888: in wrapper; return dispatch(args[0].__class__)(*args, **kw); scanpy/preprocessing/_simple.py:888: in scale_anndata; X, adata.var[""mean""], adata.var[""std""] = do_scale(; ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:468: in _compile_for_args; error_rewrite(e, 'typing'); _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. e = TypingError('Failed in nopython mode pipeline (step: nopython frontend)\nnon-precise type pyobject\nDuring: typing of ...y the following argument(s):\n- argument 0: Cannot determine Numba type of <class \'scipy.sparse._csr.csr_matrix\'>\n'); issue_type = 'typing'. def error_rewrite(e, issue_type):; """"""; Rewrite and raise Exception `e` with help supplied based on the; specified issue_type.; """"""; if config.SHOW_HELP:; help_msg = errors.error_extras[issue_type]; e.patch_message('\n'.join((str(e).rstrip(), help_msg))); if config.FULL_TRACEBACKS:; raise e; else:; > raise e.with_traceback(None); E numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); E non-precise type pyobject; E During: typing of argument at /home/zeth/PycharmProjects/scanpy/scanpy/preprocessing/_simple.py (763); E ; E File ""scanpy/preprocessing/_simple.py"", line 763:; E def do_scale(X, maxv, nthr):; E <source elided>; E # t0= time.time(); E s = np.zeros((nthr, X.shape[1])); E ^ ; E ; E This error may have been caused by the following argument(s):; E - argument 0: Cannot determine Numba type of <class 'scipy.sparse._csr.csr_matrix'>. ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:409: TypingError; ```. When trying to use the new flavor with the existing test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1533308183
https://github.com/scverse/scanpy/pull/2457#issuecomment-1533308183:2414,Availability,error,error,2414," _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _; ../../miniconda3/envs/scanpy/lib/python3.9/functools.py:888: in wrapper; return dispatch(args[0].__class__)(*args, **kw); scanpy/preprocessing/_simple.py:888: in scale_anndata; X, adata.var[""mean""], adata.var[""std""] = do_scale(; ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:468: in _compile_for_args; error_rewrite(e, 'typing'); _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. e = TypingError('Failed in nopython mode pipeline (step: nopython frontend)\nnon-precise type pyobject\nDuring: typing of ...y the following argument(s):\n- argument 0: Cannot determine Numba type of <class \'scipy.sparse._csr.csr_matrix\'>\n'); issue_type = 'typing'. def error_rewrite(e, issue_type):; """"""; Rewrite and raise Exception `e` with help supplied based on the; specified issue_type.; """"""; if config.SHOW_HELP:; help_msg = errors.error_extras[issue_type]; e.patch_message('\n'.join((str(e).rstrip(), help_msg))); if config.FULL_TRACEBACKS:; raise e; else:; > raise e.with_traceback(None); E numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); E non-precise type pyobject; E During: typing of argument at /home/zeth/PycharmProjects/scanpy/scanpy/preprocessing/_simple.py (763); E ; E File ""scanpy/preprocessing/_simple.py"", line 763:; E def do_scale(X, maxv, nthr):; E <source elided>; E # t0= time.time(); E s = np.zeros((nthr, X.shape[1])); E ^ ; E ; E This error may have been caused by the following argument(s):; E - argument 0: Cannot determine Numba type of <class 'scipy.sparse._csr.csr_matrix'>. ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:409: TypingError; ```. When trying to use the new flavor with the existing test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1533308183
https://github.com/scverse/scanpy/pull/2457#issuecomment-1533308183:1445,Deployability,pipeline,pipeline,1445,"com/scverse/anndata/issues/171#issuecomment-508689965; assert v.is_view; with pytest.warns(Warning, match=""view""):; > sc.pp.scale(v, flavor=flavor). scanpy/tests/test_preprocessing.py:127: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _; ../../miniconda3/envs/scanpy/lib/python3.9/functools.py:888: in wrapper; return dispatch(args[0].__class__)(*args, **kw); scanpy/preprocessing/_simple.py:888: in scale_anndata; X, adata.var[""mean""], adata.var[""std""] = do_scale(; ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:468: in _compile_for_args; error_rewrite(e, 'typing'); _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. e = TypingError('Failed in nopython mode pipeline (step: nopython frontend)\nnon-precise type pyobject\nDuring: typing of ...y the following argument(s):\n- argument 0: Cannot determine Numba type of <class \'scipy.sparse._csr.csr_matrix\'>\n'); issue_type = 'typing'. def error_rewrite(e, issue_type):; """"""; Rewrite and raise Exception `e` with help supplied based on the; specified issue_type.; """"""; if config.SHOW_HELP:; help_msg = errors.error_extras[issue_type]; e.patch_message('\n'.join((str(e).rstrip(), help_msg))); if config.FULL_TRACEBACKS:; raise e; else:; > raise e.with_traceback(None); E numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); E non-precise type pyobject; E During: typing of argument at /home/zeth/PycharmProjects/scanpy/scanpy/preprocessing/_simple.py (763); E ; E File ""scanpy/preprocessing/_simple.py"", line 763:; E def do_scale(X, maxv, nthr):; E <source elided>; E # t0= time.time(); E s = np.zeros((nthr, X.shape[1])); E ^ ; E ; E This error may have been caused by the following argumen",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1533308183
https://github.com/scverse/scanpy/pull/2457#issuecomment-1533308183:2062,Deployability,pipeline,pipeline,2062," _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _; ../../miniconda3/envs/scanpy/lib/python3.9/functools.py:888: in wrapper; return dispatch(args[0].__class__)(*args, **kw); scanpy/preprocessing/_simple.py:888: in scale_anndata; X, adata.var[""mean""], adata.var[""std""] = do_scale(; ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:468: in _compile_for_args; error_rewrite(e, 'typing'); _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. e = TypingError('Failed in nopython mode pipeline (step: nopython frontend)\nnon-precise type pyobject\nDuring: typing of ...y the following argument(s):\n- argument 0: Cannot determine Numba type of <class \'scipy.sparse._csr.csr_matrix\'>\n'); issue_type = 'typing'. def error_rewrite(e, issue_type):; """"""; Rewrite and raise Exception `e` with help supplied based on the; specified issue_type.; """"""; if config.SHOW_HELP:; help_msg = errors.error_extras[issue_type]; e.patch_message('\n'.join((str(e).rstrip(), help_msg))); if config.FULL_TRACEBACKS:; raise e; else:; > raise e.with_traceback(None); E numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); E non-precise type pyobject; E During: typing of argument at /home/zeth/PycharmProjects/scanpy/scanpy/preprocessing/_simple.py (763); E ; E File ""scanpy/preprocessing/_simple.py"", line 763:; E def do_scale(X, maxv, nthr):; E <source elided>; E # t0= time.time(); E s = np.zeros((nthr, X.shape[1])); E ^ ; E ; E This error may have been caused by the following argument(s):; E - argument 0: Cannot determine Numba type of <class 'scipy.sparse._csr.csr_matrix'>. ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:409: TypingError; ```. When trying to use the new flavor with the existing test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1533308183
https://github.com/scverse/scanpy/pull/2457#issuecomment-1533308183:911,Integrability,wrap,wrapper,911,"Unfortunately, I run into. ```; __________________________________________________________________________________ test_scale[use_fastpp] ___________________________________________________________________________________. flavor = 'use_fastpp'. @pytest.mark.parametrize(""flavor"", [""default"", ""use_fastpp""]); def test_scale(flavor):; adata = pbmc68k_reduced(); adata.X = adata.raw.X; v = adata[:, 0 : adata.shape[1] // 2]; # Should turn view to copy https://github.com/scverse/anndata/issues/171#issuecomment-508689965; assert v.is_view; with pytest.warns(Warning, match=""view""):; > sc.pp.scale(v, flavor=flavor). scanpy/tests/test_preprocessing.py:127: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _; ../../miniconda3/envs/scanpy/lib/python3.9/functools.py:888: in wrapper; return dispatch(args[0].__class__)(*args, **kw); scanpy/preprocessing/_simple.py:888: in scale_anndata; X, adata.var[""mean""], adata.var[""std""] = do_scale(; ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:468: in _compile_for_args; error_rewrite(e, 'typing'); _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. e = TypingError('Failed in nopython mode pipeline (step: nopython frontend)\nnon-precise type pyobject\nDuring: typing of ...y the following argument(s):\n- argument 0: Cannot determine Numba type of <class \'scipy.sparse._csr.csr_matrix\'>\n'); issue_type = 'typing'. def error_rewrite(e, issue_type):; """"""; Rewrite and raise Exception `e` with help supplied based on the; specified issue_type.; """"""; if config.SHOW_HELP:; help_msg = errors.error_extras[issue_type]; e.patch_message('\n'.join((str(e).rstrip(), help_msg))); if config.FULL_TRACEBACKS:; raise e; else:; > raise e.with_traceback(Non",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1533308183
https://github.com/scverse/scanpy/pull/2457#issuecomment-1533308183:1713,Modifiability,Rewrite,Rewrite,1713," _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _; ../../miniconda3/envs/scanpy/lib/python3.9/functools.py:888: in wrapper; return dispatch(args[0].__class__)(*args, **kw); scanpy/preprocessing/_simple.py:888: in scale_anndata; X, adata.var[""mean""], adata.var[""std""] = do_scale(; ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:468: in _compile_for_args; error_rewrite(e, 'typing'); _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. e = TypingError('Failed in nopython mode pipeline (step: nopython frontend)\nnon-precise type pyobject\nDuring: typing of ...y the following argument(s):\n- argument 0: Cannot determine Numba type of <class \'scipy.sparse._csr.csr_matrix\'>\n'); issue_type = 'typing'. def error_rewrite(e, issue_type):; """"""; Rewrite and raise Exception `e` with help supplied based on the; specified issue_type.; """"""; if config.SHOW_HELP:; help_msg = errors.error_extras[issue_type]; e.patch_message('\n'.join((str(e).rstrip(), help_msg))); if config.FULL_TRACEBACKS:; raise e; else:; > raise e.with_traceback(None); E numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); E non-precise type pyobject; E During: typing of argument at /home/zeth/PycharmProjects/scanpy/scanpy/preprocessing/_simple.py (763); E ; E File ""scanpy/preprocessing/_simple.py"", line 763:; E def do_scale(X, maxv, nthr):; E <source elided>; E # t0= time.time(); E s = np.zeros((nthr, X.shape[1])); E ^ ; E ; E This error may have been caused by the following argument(s):; E - argument 0: Cannot determine Numba type of <class 'scipy.sparse._csr.csr_matrix'>. ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:409: TypingError; ```. When trying to use the new flavor with the existing test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1533308183
https://github.com/scverse/scanpy/pull/2457#issuecomment-1533308183:1809,Modifiability,config,config,1809," _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _; ../../miniconda3/envs/scanpy/lib/python3.9/functools.py:888: in wrapper; return dispatch(args[0].__class__)(*args, **kw); scanpy/preprocessing/_simple.py:888: in scale_anndata; X, adata.var[""mean""], adata.var[""std""] = do_scale(; ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:468: in _compile_for_args; error_rewrite(e, 'typing'); _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. e = TypingError('Failed in nopython mode pipeline (step: nopython frontend)\nnon-precise type pyobject\nDuring: typing of ...y the following argument(s):\n- argument 0: Cannot determine Numba type of <class \'scipy.sparse._csr.csr_matrix\'>\n'); issue_type = 'typing'. def error_rewrite(e, issue_type):; """"""; Rewrite and raise Exception `e` with help supplied based on the; specified issue_type.; """"""; if config.SHOW_HELP:; help_msg = errors.error_extras[issue_type]; e.patch_message('\n'.join((str(e).rstrip(), help_msg))); if config.FULL_TRACEBACKS:; raise e; else:; > raise e.with_traceback(None); E numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); E non-precise type pyobject; E During: typing of argument at /home/zeth/PycharmProjects/scanpy/scanpy/preprocessing/_simple.py (763); E ; E File ""scanpy/preprocessing/_simple.py"", line 763:; E def do_scale(X, maxv, nthr):; E <source elided>; E # t0= time.time(); E s = np.zeros((nthr, X.shape[1])); E ^ ; E ; E This error may have been caused by the following argument(s):; E - argument 0: Cannot determine Numba type of <class 'scipy.sparse._csr.csr_matrix'>. ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:409: TypingError; ```. When trying to use the new flavor with the existing test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1533308183
https://github.com/scverse/scanpy/pull/2457#issuecomment-1533308183:1932,Modifiability,config,config,1932," _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _; ../../miniconda3/envs/scanpy/lib/python3.9/functools.py:888: in wrapper; return dispatch(args[0].__class__)(*args, **kw); scanpy/preprocessing/_simple.py:888: in scale_anndata; X, adata.var[""mean""], adata.var[""std""] = do_scale(; ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:468: in _compile_for_args; error_rewrite(e, 'typing'); _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. e = TypingError('Failed in nopython mode pipeline (step: nopython frontend)\nnon-precise type pyobject\nDuring: typing of ...y the following argument(s):\n- argument 0: Cannot determine Numba type of <class \'scipy.sparse._csr.csr_matrix\'>\n'); issue_type = 'typing'. def error_rewrite(e, issue_type):; """"""; Rewrite and raise Exception `e` with help supplied based on the; specified issue_type.; """"""; if config.SHOW_HELP:; help_msg = errors.error_extras[issue_type]; e.patch_message('\n'.join((str(e).rstrip(), help_msg))); if config.FULL_TRACEBACKS:; raise e; else:; > raise e.with_traceback(None); E numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); E non-precise type pyobject; E During: typing of argument at /home/zeth/PycharmProjects/scanpy/scanpy/preprocessing/_simple.py (763); E ; E File ""scanpy/preprocessing/_simple.py"", line 763:; E def do_scale(X, maxv, nthr):; E <source elided>; E # t0= time.time(); E s = np.zeros((nthr, X.shape[1])); E ^ ; E ; E This error may have been caused by the following argument(s):; E - argument 0: Cannot determine Numba type of <class 'scipy.sparse._csr.csr_matrix'>. ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:409: TypingError; ```. When trying to use the new flavor with the existing test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1533308183
https://github.com/scverse/scanpy/pull/2457#issuecomment-1533308183:520,Testability,assert,assert,520,"Unfortunately, I run into. ```; __________________________________________________________________________________ test_scale[use_fastpp] ___________________________________________________________________________________. flavor = 'use_fastpp'. @pytest.mark.parametrize(""flavor"", [""default"", ""use_fastpp""]); def test_scale(flavor):; adata = pbmc68k_reduced(); adata.X = adata.raw.X; v = adata[:, 0 : adata.shape[1] // 2]; # Should turn view to copy https://github.com/scverse/anndata/issues/171#issuecomment-508689965; assert v.is_view; with pytest.warns(Warning, match=""view""):; > sc.pp.scale(v, flavor=flavor). scanpy/tests/test_preprocessing.py:127: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _; ../../miniconda3/envs/scanpy/lib/python3.9/functools.py:888: in wrapper; return dispatch(args[0].__class__)(*args, **kw); scanpy/preprocessing/_simple.py:888: in scale_anndata; X, adata.var[""mean""], adata.var[""std""] = do_scale(; ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:468: in _compile_for_args; error_rewrite(e, 'typing'); _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. e = TypingError('Failed in nopython mode pipeline (step: nopython frontend)\nnon-precise type pyobject\nDuring: typing of ...y the following argument(s):\n- argument 0: Cannot determine Numba type of <class \'scipy.sparse._csr.csr_matrix\'>\n'); issue_type = 'typing'. def error_rewrite(e, issue_type):; """"""; Rewrite and raise Exception `e` with help supplied based on the; specified issue_type.; """"""; if config.SHOW_HELP:; help_msg = errors.error_extras[issue_type]; e.patch_message('\n'.join((str(e).rstrip(), help_msg))); if config.FULL_TRACEBACKS:; raise e; else:; > raise e.with_traceback(Non",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1533308183
https://github.com/scverse/scanpy/pull/2457#issuecomment-1533308183:621,Testability,test,tests,621,"Unfortunately, I run into. ```; __________________________________________________________________________________ test_scale[use_fastpp] ___________________________________________________________________________________. flavor = 'use_fastpp'. @pytest.mark.parametrize(""flavor"", [""default"", ""use_fastpp""]); def test_scale(flavor):; adata = pbmc68k_reduced(); adata.X = adata.raw.X; v = adata[:, 0 : adata.shape[1] // 2]; # Should turn view to copy https://github.com/scverse/anndata/issues/171#issuecomment-508689965; assert v.is_view; with pytest.warns(Warning, match=""view""):; > sc.pp.scale(v, flavor=flavor). scanpy/tests/test_preprocessing.py:127: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _; ../../miniconda3/envs/scanpy/lib/python3.9/functools.py:888: in wrapper; return dispatch(args[0].__class__)(*args, **kw); scanpy/preprocessing/_simple.py:888: in scale_anndata; X, adata.var[""mean""], adata.var[""std""] = do_scale(; ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:468: in _compile_for_args; error_rewrite(e, 'typing'); _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. e = TypingError('Failed in nopython mode pipeline (step: nopython frontend)\nnon-precise type pyobject\nDuring: typing of ...y the following argument(s):\n- argument 0: Cannot determine Numba type of <class \'scipy.sparse._csr.csr_matrix\'>\n'); issue_type = 'typing'. def error_rewrite(e, issue_type):; """"""; Rewrite and raise Exception `e` with help supplied based on the; specified issue_type.; """"""; if config.SHOW_HELP:; help_msg = errors.error_extras[issue_type]; e.patch_message('\n'.join((str(e).rstrip(), help_msg))); if config.FULL_TRACEBACKS:; raise e; else:; > raise e.with_traceback(Non",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1533308183
https://github.com/scverse/scanpy/pull/2457#issuecomment-1533308183:2716,Testability,test,test,2716," _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _; ../../miniconda3/envs/scanpy/lib/python3.9/functools.py:888: in wrapper; return dispatch(args[0].__class__)(*args, **kw); scanpy/preprocessing/_simple.py:888: in scale_anndata; X, adata.var[""mean""], adata.var[""std""] = do_scale(; ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:468: in _compile_for_args; error_rewrite(e, 'typing'); _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. e = TypingError('Failed in nopython mode pipeline (step: nopython frontend)\nnon-precise type pyobject\nDuring: typing of ...y the following argument(s):\n- argument 0: Cannot determine Numba type of <class \'scipy.sparse._csr.csr_matrix\'>\n'); issue_type = 'typing'. def error_rewrite(e, issue_type):; """"""; Rewrite and raise Exception `e` with help supplied based on the; specified issue_type.; """"""; if config.SHOW_HELP:; help_msg = errors.error_extras[issue_type]; e.patch_message('\n'.join((str(e).rstrip(), help_msg))); if config.FULL_TRACEBACKS:; raise e; else:; > raise e.with_traceback(None); E numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); E non-precise type pyobject; E During: typing of argument at /home/zeth/PycharmProjects/scanpy/scanpy/preprocessing/_simple.py (763); E ; E File ""scanpy/preprocessing/_simple.py"", line 763:; E def do_scale(X, maxv, nthr):; E <source elided>; E # t0= time.time(); E s = np.zeros((nthr, X.shape[1])); E ^ ; E ; E This error may have been caused by the following argument(s):; E - argument 0: Cannot determine Numba type of <class 'scipy.sparse._csr.csr_matrix'>. ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:409: TypingError; ```. When trying to use the new flavor with the existing test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1533308183
https://github.com/scverse/scanpy/pull/2457#issuecomment-1540006717:1925,Availability,error,errors,1925,"/scanpy/lib/python3.9/functools.py:888: in wrapper; > return dispatch(args[0].__class__)(*args, **kw); > scanpy/preprocessing/_simple.py:888: in scale_anndata; > X, adata.var[""mean""], adata.var[""std""] = do_scale(; > ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:468: in _compile_for_args; > error_rewrite(e, 'typing'); > _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _; > ; > e = TypingError('Failed in nopython mode pipeline (step: nopython frontend)\nnon-precise type pyobject\nDuring: typing of ...y the following argument(s):\n- argument 0: Cannot determine Numba type of <class \'scipy.sparse._csr.csr_matrix\'>\n'); > issue_type = 'typing'; > ; > def error_rewrite(e, issue_type):; > """"""; > Rewrite and raise Exception `e` with help supplied based on the; > specified issue_type.; > """"""; > if config.SHOW_HELP:; > help_msg = errors.error_extras[issue_type]; > e.patch_message('\n'.join((str(e).rstrip(), help_msg))); > if config.FULL_TRACEBACKS:; > raise e; > else:; > > raise e.with_traceback(None); > E numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); > E non-precise type pyobject; > E During: typing of argument at /home/zeth/PycharmProjects/scanpy/scanpy/preprocessing/_simple.py (763); > E ; > E File ""scanpy/preprocessing/_simple.py"", line 763:; > E def do_scale(X, maxv, nthr):; > E <source elided>; > E # t0= time.time(); > E s = np.zeros((nthr, X.shape[1])); > E ^ ; > E ; > E This error may have been caused by the following argument(s):; > E - argument 0: Cannot determine Numba type of <class 'scipy.sparse._csr.csr_matrix'>; > ; > ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:409: TypingError; > ```; > ; > When trying to use the new flavor with the existing test. Hi @Zethson ,; We are not able to see this issue with the ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1540006717
https://github.com/scverse/scanpy/pull/2457#issuecomment-1540006717:2116,Availability,error,errors,2116,"0].__class__)(*args, **kw); > scanpy/preprocessing/_simple.py:888: in scale_anndata; > X, adata.var[""mean""], adata.var[""std""] = do_scale(; > ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:468: in _compile_for_args; > error_rewrite(e, 'typing'); > _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _; > ; > e = TypingError('Failed in nopython mode pipeline (step: nopython frontend)\nnon-precise type pyobject\nDuring: typing of ...y the following argument(s):\n- argument 0: Cannot determine Numba type of <class \'scipy.sparse._csr.csr_matrix\'>\n'); > issue_type = 'typing'; > ; > def error_rewrite(e, issue_type):; > """"""; > Rewrite and raise Exception `e` with help supplied based on the; > specified issue_type.; > """"""; > if config.SHOW_HELP:; > help_msg = errors.error_extras[issue_type]; > e.patch_message('\n'.join((str(e).rstrip(), help_msg))); > if config.FULL_TRACEBACKS:; > raise e; > else:; > > raise e.with_traceback(None); > E numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); > E non-precise type pyobject; > E During: typing of argument at /home/zeth/PycharmProjects/scanpy/scanpy/preprocessing/_simple.py (763); > E ; > E File ""scanpy/preprocessing/_simple.py"", line 763:; > E def do_scale(X, maxv, nthr):; > E <source elided>; > E # t0= time.time(); > E s = np.zeros((nthr, X.shape[1])); > E ^ ; > E ; > E This error may have been caused by the following argument(s):; > E - argument 0: Cannot determine Numba type of <class 'scipy.sparse._csr.csr_matrix'>; > ; > ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:409: TypingError; > ```; > ; > When trying to use the new flavor with the existing test. Hi @Zethson ,; We are not able to see this issue with the latest commit. Can you please retry with the latest commit in scale branch.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1540006717
https://github.com/scverse/scanpy/pull/2457#issuecomment-1540006717:2534,Availability,error,error,2534,"0].__class__)(*args, **kw); > scanpy/preprocessing/_simple.py:888: in scale_anndata; > X, adata.var[""mean""], adata.var[""std""] = do_scale(; > ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:468: in _compile_for_args; > error_rewrite(e, 'typing'); > _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _; > ; > e = TypingError('Failed in nopython mode pipeline (step: nopython frontend)\nnon-precise type pyobject\nDuring: typing of ...y the following argument(s):\n- argument 0: Cannot determine Numba type of <class \'scipy.sparse._csr.csr_matrix\'>\n'); > issue_type = 'typing'; > ; > def error_rewrite(e, issue_type):; > """"""; > Rewrite and raise Exception `e` with help supplied based on the; > specified issue_type.; > """"""; > if config.SHOW_HELP:; > help_msg = errors.error_extras[issue_type]; > e.patch_message('\n'.join((str(e).rstrip(), help_msg))); > if config.FULL_TRACEBACKS:; > raise e; > else:; > > raise e.with_traceback(None); > E numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); > E non-precise type pyobject; > E During: typing of argument at /home/zeth/PycharmProjects/scanpy/scanpy/preprocessing/_simple.py (763); > E ; > E File ""scanpy/preprocessing/_simple.py"", line 763:; > E def do_scale(X, maxv, nthr):; > E <source elided>; > E # t0= time.time(); > E s = np.zeros((nthr, X.shape[1])); > E ^ ; > E ; > E This error may have been caused by the following argument(s):; > E - argument 0: Cannot determine Numba type of <class 'scipy.sparse._csr.csr_matrix'>; > ; > ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:409: TypingError; > ```; > ; > When trying to use the new flavor with the existing test. Hi @Zethson ,; We are not able to see this issue with the latest commit. Can you please retry with the latest commit in scale branch.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1540006717
https://github.com/scverse/scanpy/pull/2457#issuecomment-1540006717:1511,Deployability,pipeline,pipeline,1511,"ta.raw.X; > v = adata[:, 0 : adata.shape[1] // 2]; > # Should turn view to copy https://github.com/scverse/anndata/issues/171#issuecomment-508689965; > assert v.is_view; > with pytest.warns(Warning, match=""view""):; > > sc.pp.scale(v, flavor=flavor); > ; > scanpy/tests/test_preprocessing.py:127: ; > _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _; > ../../miniconda3/envs/scanpy/lib/python3.9/functools.py:888: in wrapper; > return dispatch(args[0].__class__)(*args, **kw); > scanpy/preprocessing/_simple.py:888: in scale_anndata; > X, adata.var[""mean""], adata.var[""std""] = do_scale(; > ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:468: in _compile_for_args; > error_rewrite(e, 'typing'); > _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _; > ; > e = TypingError('Failed in nopython mode pipeline (step: nopython frontend)\nnon-precise type pyobject\nDuring: typing of ...y the following argument(s):\n- argument 0: Cannot determine Numba type of <class \'scipy.sparse._csr.csr_matrix\'>\n'); > issue_type = 'typing'; > ; > def error_rewrite(e, issue_type):; > """"""; > Rewrite and raise Exception `e` with help supplied based on the; > specified issue_type.; > """"""; > if config.SHOW_HELP:; > help_msg = errors.error_extras[issue_type]; > e.patch_message('\n'.join((str(e).rstrip(), help_msg))); > if config.FULL_TRACEBACKS:; > raise e; > else:; > > raise e.with_traceback(None); > E numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); > E non-precise type pyobject; > E During: typing of argument at /home/zeth/PycharmProjects/scanpy/scanpy/preprocessing/_simple.py (763); > E ; > E File ""scanpy/preprocessing/_simple.py"", line 763:; > E def",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1540006717
https://github.com/scverse/scanpy/pull/2457#issuecomment-1540006717:2160,Deployability,pipeline,pipeline,2160,"0].__class__)(*args, **kw); > scanpy/preprocessing/_simple.py:888: in scale_anndata; > X, adata.var[""mean""], adata.var[""std""] = do_scale(; > ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:468: in _compile_for_args; > error_rewrite(e, 'typing'); > _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _; > ; > e = TypingError('Failed in nopython mode pipeline (step: nopython frontend)\nnon-precise type pyobject\nDuring: typing of ...y the following argument(s):\n- argument 0: Cannot determine Numba type of <class \'scipy.sparse._csr.csr_matrix\'>\n'); > issue_type = 'typing'; > ; > def error_rewrite(e, issue_type):; > """"""; > Rewrite and raise Exception `e` with help supplied based on the; > specified issue_type.; > """"""; > if config.SHOW_HELP:; > help_msg = errors.error_extras[issue_type]; > e.patch_message('\n'.join((str(e).rstrip(), help_msg))); > if config.FULL_TRACEBACKS:; > raise e; > else:; > > raise e.with_traceback(None); > E numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); > E non-precise type pyobject; > E During: typing of argument at /home/zeth/PycharmProjects/scanpy/scanpy/preprocessing/_simple.py (763); > E ; > E File ""scanpy/preprocessing/_simple.py"", line 763:; > E def do_scale(X, maxv, nthr):; > E <source elided>; > E # t0= time.time(); > E s = np.zeros((nthr, X.shape[1])); > E ^ ; > E ; > E This error may have been caused by the following argument(s):; > E - argument 0: Cannot determine Numba type of <class 'scipy.sparse._csr.csr_matrix'>; > ; > ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:409: TypingError; > ```; > ; > When trying to use the new flavor with the existing test. Hi @Zethson ,; We are not able to see this issue with the latest commit. Can you please retry with the latest commit in scale branch.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1540006717
https://github.com/scverse/scanpy/pull/2457#issuecomment-1540006717:959,Integrability,wrap,wrapper,959,"> Unfortunately, I run into; > ; > ```; > __________________________________________________________________________________ test_scale[use_fastpp] ___________________________________________________________________________________; > ; > flavor = 'use_fastpp'; > ; > @pytest.mark.parametrize(""flavor"", [""default"", ""use_fastpp""]); > def test_scale(flavor):; > adata = pbmc68k_reduced(); > adata.X = adata.raw.X; > v = adata[:, 0 : adata.shape[1] // 2]; > # Should turn view to copy https://github.com/scverse/anndata/issues/171#issuecomment-508689965; > assert v.is_view; > with pytest.warns(Warning, match=""view""):; > > sc.pp.scale(v, flavor=flavor); > ; > scanpy/tests/test_preprocessing.py:127: ; > _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _; > ../../miniconda3/envs/scanpy/lib/python3.9/functools.py:888: in wrapper; > return dispatch(args[0].__class__)(*args, **kw); > scanpy/preprocessing/_simple.py:888: in scale_anndata; > X, adata.var[""mean""], adata.var[""std""] = do_scale(; > ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:468: in _compile_for_args; > error_rewrite(e, 'typing'); > _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _; > ; > e = TypingError('Failed in nopython mode pipeline (step: nopython frontend)\nnon-precise type pyobject\nDuring: typing of ...y the following argument(s):\n- argument 0: Cannot determine Numba type of <class \'scipy.sparse._csr.csr_matrix\'>\n'); > issue_type = 'typing'; > ; > def error_rewrite(e, issue_type):; > """"""; > Rewrite and raise Exception `e` with help supplied based on the; > specified issue_type.; > """"""; > if config.SHOW_HELP:; > help_msg = errors.error_extras[issue_type]; > e.patch_message('\n'.join((str(e).rstrip(",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1540006717
https://github.com/scverse/scanpy/pull/2457#issuecomment-1540006717:1791,Modifiability,Rewrite,Rewrite,1791,"_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _; > ../../miniconda3/envs/scanpy/lib/python3.9/functools.py:888: in wrapper; > return dispatch(args[0].__class__)(*args, **kw); > scanpy/preprocessing/_simple.py:888: in scale_anndata; > X, adata.var[""mean""], adata.var[""std""] = do_scale(; > ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:468: in _compile_for_args; > error_rewrite(e, 'typing'); > _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _; > ; > e = TypingError('Failed in nopython mode pipeline (step: nopython frontend)\nnon-precise type pyobject\nDuring: typing of ...y the following argument(s):\n- argument 0: Cannot determine Numba type of <class \'scipy.sparse._csr.csr_matrix\'>\n'); > issue_type = 'typing'; > ; > def error_rewrite(e, issue_type):; > """"""; > Rewrite and raise Exception `e` with help supplied based on the; > specified issue_type.; > """"""; > if config.SHOW_HELP:; > help_msg = errors.error_extras[issue_type]; > e.patch_message('\n'.join((str(e).rstrip(), help_msg))); > if config.FULL_TRACEBACKS:; > raise e; > else:; > > raise e.with_traceback(None); > E numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); > E non-precise type pyobject; > E During: typing of argument at /home/zeth/PycharmProjects/scanpy/scanpy/preprocessing/_simple.py (763); > E ; > E File ""scanpy/preprocessing/_simple.py"", line 763:; > E def do_scale(X, maxv, nthr):; > E <source elided>; > E # t0= time.time(); > E s = np.zeros((nthr, X.shape[1])); > E ^ ; > E ; > E This error may have been caused by the following argument(s):; > E - argument 0: Cannot determine Numba type of <class 'scipy.sparse._csr.csr_matrix'>; > ; > ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:409: TypingError; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1540006717
https://github.com/scverse/scanpy/pull/2457#issuecomment-1540006717:1893,Modifiability,config,config,1893," _; > ../../miniconda3/envs/scanpy/lib/python3.9/functools.py:888: in wrapper; > return dispatch(args[0].__class__)(*args, **kw); > scanpy/preprocessing/_simple.py:888: in scale_anndata; > X, adata.var[""mean""], adata.var[""std""] = do_scale(; > ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:468: in _compile_for_args; > error_rewrite(e, 'typing'); > _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _; > ; > e = TypingError('Failed in nopython mode pipeline (step: nopython frontend)\nnon-precise type pyobject\nDuring: typing of ...y the following argument(s):\n- argument 0: Cannot determine Numba type of <class \'scipy.sparse._csr.csr_matrix\'>\n'); > issue_type = 'typing'; > ; > def error_rewrite(e, issue_type):; > """"""; > Rewrite and raise Exception `e` with help supplied based on the; > specified issue_type.; > """"""; > if config.SHOW_HELP:; > help_msg = errors.error_extras[issue_type]; > e.patch_message('\n'.join((str(e).rstrip(), help_msg))); > if config.FULL_TRACEBACKS:; > raise e; > else:; > > raise e.with_traceback(None); > E numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); > E non-precise type pyobject; > E During: typing of argument at /home/zeth/PycharmProjects/scanpy/scanpy/preprocessing/_simple.py (763); > E ; > E File ""scanpy/preprocessing/_simple.py"", line 763:; > E def do_scale(X, maxv, nthr):; > E <source elided>; > E # t0= time.time(); > E s = np.zeros((nthr, X.shape[1])); > E ^ ; > E ; > E This error may have been caused by the following argument(s):; > E - argument 0: Cannot determine Numba type of <class 'scipy.sparse._csr.csr_matrix'>; > ; > ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:409: TypingError; > ```; > ; > When trying to use the new flavor with the existing test. Hi @Zethson ,; We are not able t",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1540006717
https://github.com/scverse/scanpy/pull/2457#issuecomment-1540006717:2022,Modifiability,config,config,2022,"0].__class__)(*args, **kw); > scanpy/preprocessing/_simple.py:888: in scale_anndata; > X, adata.var[""mean""], adata.var[""std""] = do_scale(; > ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:468: in _compile_for_args; > error_rewrite(e, 'typing'); > _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _; > ; > e = TypingError('Failed in nopython mode pipeline (step: nopython frontend)\nnon-precise type pyobject\nDuring: typing of ...y the following argument(s):\n- argument 0: Cannot determine Numba type of <class \'scipy.sparse._csr.csr_matrix\'>\n'); > issue_type = 'typing'; > ; > def error_rewrite(e, issue_type):; > """"""; > Rewrite and raise Exception `e` with help supplied based on the; > specified issue_type.; > """"""; > if config.SHOW_HELP:; > help_msg = errors.error_extras[issue_type]; > e.patch_message('\n'.join((str(e).rstrip(), help_msg))); > if config.FULL_TRACEBACKS:; > raise e; > else:; > > raise e.with_traceback(None); > E numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); > E non-precise type pyobject; > E During: typing of argument at /home/zeth/PycharmProjects/scanpy/scanpy/preprocessing/_simple.py (763); > E ; > E File ""scanpy/preprocessing/_simple.py"", line 763:; > E def do_scale(X, maxv, nthr):; > E <source elided>; > E # t0= time.time(); > E s = np.zeros((nthr, X.shape[1])); > E ^ ; > E ; > E This error may have been caused by the following argument(s):; > E - argument 0: Cannot determine Numba type of <class 'scipy.sparse._csr.csr_matrix'>; > ; > ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:409: TypingError; > ```; > ; > When trying to use the new flavor with the existing test. Hi @Zethson ,; We are not able to see this issue with the latest commit. Can you please retry with the latest commit in scale branch.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1540006717
https://github.com/scverse/scanpy/pull/2457#issuecomment-1540006717:554,Testability,assert,assert,554,"> Unfortunately, I run into; > ; > ```; > __________________________________________________________________________________ test_scale[use_fastpp] ___________________________________________________________________________________; > ; > flavor = 'use_fastpp'; > ; > @pytest.mark.parametrize(""flavor"", [""default"", ""use_fastpp""]); > def test_scale(flavor):; > adata = pbmc68k_reduced(); > adata.X = adata.raw.X; > v = adata[:, 0 : adata.shape[1] // 2]; > # Should turn view to copy https://github.com/scverse/anndata/issues/171#issuecomment-508689965; > assert v.is_view; > with pytest.warns(Warning, match=""view""):; > > sc.pp.scale(v, flavor=flavor); > ; > scanpy/tests/test_preprocessing.py:127: ; > _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _; > ../../miniconda3/envs/scanpy/lib/python3.9/functools.py:888: in wrapper; > return dispatch(args[0].__class__)(*args, **kw); > scanpy/preprocessing/_simple.py:888: in scale_anndata; > X, adata.var[""mean""], adata.var[""std""] = do_scale(; > ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:468: in _compile_for_args; > error_rewrite(e, 'typing'); > _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _; > ; > e = TypingError('Failed in nopython mode pipeline (step: nopython frontend)\nnon-precise type pyobject\nDuring: typing of ...y the following argument(s):\n- argument 0: Cannot determine Numba type of <class \'scipy.sparse._csr.csr_matrix\'>\n'); > issue_type = 'typing'; > ; > def error_rewrite(e, issue_type):; > """"""; > Rewrite and raise Exception `e` with help supplied based on the; > specified issue_type.; > """"""; > if config.SHOW_HELP:; > help_msg = errors.error_extras[issue_type]; > e.patch_message('\n'.join((str(e).rstrip(",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1540006717
https://github.com/scverse/scanpy/pull/2457#issuecomment-1540006717:665,Testability,test,tests,665,"> Unfortunately, I run into; > ; > ```; > __________________________________________________________________________________ test_scale[use_fastpp] ___________________________________________________________________________________; > ; > flavor = 'use_fastpp'; > ; > @pytest.mark.parametrize(""flavor"", [""default"", ""use_fastpp""]); > def test_scale(flavor):; > adata = pbmc68k_reduced(); > adata.X = adata.raw.X; > v = adata[:, 0 : adata.shape[1] // 2]; > # Should turn view to copy https://github.com/scverse/anndata/issues/171#issuecomment-508689965; > assert v.is_view; > with pytest.warns(Warning, match=""view""):; > > sc.pp.scale(v, flavor=flavor); > ; > scanpy/tests/test_preprocessing.py:127: ; > _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _; > ../../miniconda3/envs/scanpy/lib/python3.9/functools.py:888: in wrapper; > return dispatch(args[0].__class__)(*args, **kw); > scanpy/preprocessing/_simple.py:888: in scale_anndata; > X, adata.var[""mean""], adata.var[""std""] = do_scale(; > ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:468: in _compile_for_args; > error_rewrite(e, 'typing'); > _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _; > ; > e = TypingError('Failed in nopython mode pipeline (step: nopython frontend)\nnon-precise type pyobject\nDuring: typing of ...y the following argument(s):\n- argument 0: Cannot determine Numba type of <class \'scipy.sparse._csr.csr_matrix\'>\n'); > issue_type = 'typing'; > ; > def error_rewrite(e, issue_type):; > """"""; > Rewrite and raise Exception `e` with help supplied based on the; > specified issue_type.; > """"""; > if config.SHOW_HELP:; > help_msg = errors.error_extras[issue_type]; > e.patch_message('\n'.join((str(e).rstrip(",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1540006717
https://github.com/scverse/scanpy/pull/2457#issuecomment-1540006717:2852,Testability,test,test,2852,"0].__class__)(*args, **kw); > scanpy/preprocessing/_simple.py:888: in scale_anndata; > X, adata.var[""mean""], adata.var[""std""] = do_scale(; > ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:468: in _compile_for_args; > error_rewrite(e, 'typing'); > _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _; > ; > e = TypingError('Failed in nopython mode pipeline (step: nopython frontend)\nnon-precise type pyobject\nDuring: typing of ...y the following argument(s):\n- argument 0: Cannot determine Numba type of <class \'scipy.sparse._csr.csr_matrix\'>\n'); > issue_type = 'typing'; > ; > def error_rewrite(e, issue_type):; > """"""; > Rewrite and raise Exception `e` with help supplied based on the; > specified issue_type.; > """"""; > if config.SHOW_HELP:; > help_msg = errors.error_extras[issue_type]; > e.patch_message('\n'.join((str(e).rstrip(), help_msg))); > if config.FULL_TRACEBACKS:; > raise e; > else:; > > raise e.with_traceback(None); > E numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); > E non-precise type pyobject; > E During: typing of argument at /home/zeth/PycharmProjects/scanpy/scanpy/preprocessing/_simple.py (763); > E ; > E File ""scanpy/preprocessing/_simple.py"", line 763:; > E def do_scale(X, maxv, nthr):; > E <source elided>; > E # t0= time.time(); > E s = np.zeros((nthr, X.shape[1])); > E ^ ; > E ; > E This error may have been caused by the following argument(s):; > E - argument 0: Cannot determine Numba type of <class 'scipy.sparse._csr.csr_matrix'>; > ; > ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:409: TypingError; > ```; > ; > When trying to use the new flavor with the existing test. Hi @Zethson ,; We are not able to see this issue with the latest commit. Can you please retry with the latest commit in scale branch.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1540006717
https://github.com/scverse/scanpy/pull/2457#issuecomment-1540014267:677,Availability,error,errors,677,"Please adapt the corresponding test to:. ```; @pytest.mark.parametrize(""flavor"", [""default"", ""use_fastpp""]); def test_scale(flavor):; adata = pbmc68k_reduced(); adata.X = adata.raw.X; v = adata[:, 0 : adata.shape[1] // 2]; # Should turn view to copy https://github.com/scverse/anndata/issues/171#issuecomment-508689965; assert v.is_view; with pytest.warns(Warning, match=""view""):; sc.pp.scale(v, flavor=flavor); assert not v.is_view; assert_allclose(v.X.var(axis=0), np.ones(v.shape[1]), atol=0.01); assert_allclose(v.X.mean(axis=0), np.zeros(v.shape[1]), atol=0.00001); ```. It fails for me with `FAILED scanpy/tests/test_preprocessing.py::test_scale[use_fastpp] - numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend)`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1540014267
https://github.com/scverse/scanpy/pull/2457#issuecomment-1540014267:721,Deployability,pipeline,pipeline,721,"Please adapt the corresponding test to:. ```; @pytest.mark.parametrize(""flavor"", [""default"", ""use_fastpp""]); def test_scale(flavor):; adata = pbmc68k_reduced(); adata.X = adata.raw.X; v = adata[:, 0 : adata.shape[1] // 2]; # Should turn view to copy https://github.com/scverse/anndata/issues/171#issuecomment-508689965; assert v.is_view; with pytest.warns(Warning, match=""view""):; sc.pp.scale(v, flavor=flavor); assert not v.is_view; assert_allclose(v.X.var(axis=0), np.ones(v.shape[1]), atol=0.01); assert_allclose(v.X.mean(axis=0), np.zeros(v.shape[1]), atol=0.00001); ```. It fails for me with `FAILED scanpy/tests/test_preprocessing.py::test_scale[use_fastpp] - numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend)`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1540014267
https://github.com/scverse/scanpy/pull/2457#issuecomment-1540014267:7,Energy Efficiency,adapt,adapt,7,"Please adapt the corresponding test to:. ```; @pytest.mark.parametrize(""flavor"", [""default"", ""use_fastpp""]); def test_scale(flavor):; adata = pbmc68k_reduced(); adata.X = adata.raw.X; v = adata[:, 0 : adata.shape[1] // 2]; # Should turn view to copy https://github.com/scverse/anndata/issues/171#issuecomment-508689965; assert v.is_view; with pytest.warns(Warning, match=""view""):; sc.pp.scale(v, flavor=flavor); assert not v.is_view; assert_allclose(v.X.var(axis=0), np.ones(v.shape[1]), atol=0.01); assert_allclose(v.X.mean(axis=0), np.zeros(v.shape[1]), atol=0.00001); ```. It fails for me with `FAILED scanpy/tests/test_preprocessing.py::test_scale[use_fastpp] - numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend)`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1540014267
https://github.com/scverse/scanpy/pull/2457#issuecomment-1540014267:7,Modifiability,adapt,adapt,7,"Please adapt the corresponding test to:. ```; @pytest.mark.parametrize(""flavor"", [""default"", ""use_fastpp""]); def test_scale(flavor):; adata = pbmc68k_reduced(); adata.X = adata.raw.X; v = adata[:, 0 : adata.shape[1] // 2]; # Should turn view to copy https://github.com/scverse/anndata/issues/171#issuecomment-508689965; assert v.is_view; with pytest.warns(Warning, match=""view""):; sc.pp.scale(v, flavor=flavor); assert not v.is_view; assert_allclose(v.X.var(axis=0), np.ones(v.shape[1]), atol=0.01); assert_allclose(v.X.mean(axis=0), np.zeros(v.shape[1]), atol=0.00001); ```. It fails for me with `FAILED scanpy/tests/test_preprocessing.py::test_scale[use_fastpp] - numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend)`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1540014267
https://github.com/scverse/scanpy/pull/2457#issuecomment-1540014267:31,Testability,test,test,31,"Please adapt the corresponding test to:. ```; @pytest.mark.parametrize(""flavor"", [""default"", ""use_fastpp""]); def test_scale(flavor):; adata = pbmc68k_reduced(); adata.X = adata.raw.X; v = adata[:, 0 : adata.shape[1] // 2]; # Should turn view to copy https://github.com/scverse/anndata/issues/171#issuecomment-508689965; assert v.is_view; with pytest.warns(Warning, match=""view""):; sc.pp.scale(v, flavor=flavor); assert not v.is_view; assert_allclose(v.X.var(axis=0), np.ones(v.shape[1]), atol=0.01); assert_allclose(v.X.mean(axis=0), np.zeros(v.shape[1]), atol=0.00001); ```. It fails for me with `FAILED scanpy/tests/test_preprocessing.py::test_scale[use_fastpp] - numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend)`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1540014267
https://github.com/scverse/scanpy/pull/2457#issuecomment-1540014267:320,Testability,assert,assert,320,"Please adapt the corresponding test to:. ```; @pytest.mark.parametrize(""flavor"", [""default"", ""use_fastpp""]); def test_scale(flavor):; adata = pbmc68k_reduced(); adata.X = adata.raw.X; v = adata[:, 0 : adata.shape[1] // 2]; # Should turn view to copy https://github.com/scverse/anndata/issues/171#issuecomment-508689965; assert v.is_view; with pytest.warns(Warning, match=""view""):; sc.pp.scale(v, flavor=flavor); assert not v.is_view; assert_allclose(v.X.var(axis=0), np.ones(v.shape[1]), atol=0.01); assert_allclose(v.X.mean(axis=0), np.zeros(v.shape[1]), atol=0.00001); ```. It fails for me with `FAILED scanpy/tests/test_preprocessing.py::test_scale[use_fastpp] - numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend)`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1540014267
https://github.com/scverse/scanpy/pull/2457#issuecomment-1540014267:412,Testability,assert,assert,412,"Please adapt the corresponding test to:. ```; @pytest.mark.parametrize(""flavor"", [""default"", ""use_fastpp""]); def test_scale(flavor):; adata = pbmc68k_reduced(); adata.X = adata.raw.X; v = adata[:, 0 : adata.shape[1] // 2]; # Should turn view to copy https://github.com/scverse/anndata/issues/171#issuecomment-508689965; assert v.is_view; with pytest.warns(Warning, match=""view""):; sc.pp.scale(v, flavor=flavor); assert not v.is_view; assert_allclose(v.X.var(axis=0), np.ones(v.shape[1]), atol=0.01); assert_allclose(v.X.mean(axis=0), np.zeros(v.shape[1]), atol=0.00001); ```. It fails for me with `FAILED scanpy/tests/test_preprocessing.py::test_scale[use_fastpp] - numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend)`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1540014267
https://github.com/scverse/scanpy/pull/2457#issuecomment-1540014267:612,Testability,test,tests,612,"Please adapt the corresponding test to:. ```; @pytest.mark.parametrize(""flavor"", [""default"", ""use_fastpp""]); def test_scale(flavor):; adata = pbmc68k_reduced(); adata.X = adata.raw.X; v = adata[:, 0 : adata.shape[1] // 2]; # Should turn view to copy https://github.com/scverse/anndata/issues/171#issuecomment-508689965; assert v.is_view; with pytest.warns(Warning, match=""view""):; sc.pp.scale(v, flavor=flavor); assert not v.is_view; assert_allclose(v.X.var(axis=0), np.ones(v.shape[1]), atol=0.01); assert_allclose(v.X.mean(axis=0), np.zeros(v.shape[1]), atol=0.00001); ```. It fails for me with `FAILED scanpy/tests/test_preprocessing.py::test_scale[use_fastpp] - numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend)`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1540014267
https://github.com/scverse/scanpy/pull/2457#issuecomment-1541518384:81,Testability,test,test,81,I pushed to your branch. It failed yesterday while Github was having issues. The test should pass.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1541518384
https://github.com/scverse/scanpy/pull/2457#issuecomment-1566771839:109,Testability,test,testcase,109,"> @pytest.mark.parametrize(""flavor"", [""default"", ""use_fastpp""]). Hi @Zethson ,; I tried running the modified testcase mentioned above , but it seems it is failing because sparse matrix is being passed in it as a parameter. As of now, our scale function is not implemented for the sparse matrices. It is expected that these tests will fail.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1566771839
https://github.com/scverse/scanpy/pull/2457#issuecomment-1566771839:323,Testability,test,tests,323,"> @pytest.mark.parametrize(""flavor"", [""default"", ""use_fastpp""]). Hi @Zethson ,; I tried running the modified testcase mentioned above , but it seems it is failing because sparse matrix is being passed in it as a parameter. As of now, our scale function is not implemented for the sparse matrices. It is expected that these tests will fail.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1566771839
https://github.com/scverse/scanpy/pull/2460#issuecomment-1493446043:29,Testability,test,test,29,@Zethson do we really need a test here?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2460#issuecomment-1493446043
https://github.com/scverse/scanpy/pull/2460#issuecomment-1493979120:31,Testability,test,test,31,> @Zethson do we really need a test here?. Yes!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2460#issuecomment-1493979120
https://github.com/scverse/scanpy/pull/2460#issuecomment-1500883671:387,Deployability,continuous,continuous,387,"@ivirshup coloring by boolean values `(True, False)` is now possible:. 1) The solution is based on casting the boolean columns to string columns, so that they can be colored in a categorical way. Actual columns in the anndata object are not modified. 2) I was thinking about the case where True is 1 and False is 0. Current behaviour: colorbar is plotted, since 0 and 1 are treated like continuous variables. Does it make sense to handle this case in scanpy?. 3) Tests fail due to new pandas version, they do not fail locally though. . What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2460#issuecomment-1500883671
https://github.com/scverse/scanpy/pull/2460#issuecomment-1500883671:398,Modifiability,variab,variables,398,"@ivirshup coloring by boolean values `(True, False)` is now possible:. 1) The solution is based on casting the boolean columns to string columns, so that they can be colored in a categorical way. Actual columns in the anndata object are not modified. 2) I was thinking about the case where True is 1 and False is 0. Current behaviour: colorbar is plotted, since 0 and 1 are treated like continuous variables. Does it make sense to handle this case in scanpy?. 3) Tests fail due to new pandas version, they do not fail locally though. . What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2460#issuecomment-1500883671
https://github.com/scverse/scanpy/pull/2460#issuecomment-1500883671:463,Testability,Test,Tests,463,"@ivirshup coloring by boolean values `(True, False)` is now possible:. 1) The solution is based on casting the boolean columns to string columns, so that they can be colored in a categorical way. Actual columns in the anndata object are not modified. 2) I was thinking about the case where True is 1 and False is 0. Current behaviour: colorbar is plotted, since 0 and 1 are treated like continuous variables. Does it make sense to handle this case in scanpy?. 3) Tests fail due to new pandas version, they do not fail locally though. . What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2460#issuecomment-1500883671
https://github.com/scverse/scanpy/pull/2460#issuecomment-1693958817:59,Deployability,release,release,59,Thanks for the fix! Can we include this in the next scanpy release?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2460#issuecomment-1693958817
https://github.com/scverse/scanpy/pull/2460#issuecomment-1693979810:32,Deployability,release,release,32,"It will be included in the next release, don't worry :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2460#issuecomment-1693979810
https://github.com/scverse/scanpy/issues/2462#issuecomment-1503220199:30,Deployability,release,release,30,Yes! Please wait for the next release. Please also checkout squidpy.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2462#issuecomment-1503220199
https://github.com/scverse/scanpy/issues/2471#issuecomment-1513322610:27,Integrability,depend,dependencies,27,"Hi,. different versions of dependencies can lead to such changes. This is nothing major, don't worry about this. The general embedding structure will always be very similar though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2471#issuecomment-1513322610
https://github.com/scverse/scanpy/issues/2472#issuecomment-1718993973:107,Modifiability,extend,extend,107,"Hi,. thanks for you interest in scanpy!. Does this issue still persist for you?; If yes, is it possible to extend your example so that I can test it too, to see what might cause the computation to fail?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472#issuecomment-1718993973
https://github.com/scverse/scanpy/issues/2472#issuecomment-1718993973:141,Testability,test,test,141,"Hi,. thanks for you interest in scanpy!. Does this issue still persist for you?; If yes, is it possible to extend your example so that I can test it too, to see what might cause the computation to fail?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472#issuecomment-1718993973
https://github.com/scverse/scanpy/issues/2480#issuecomment-1531696555:6,Availability,recover,recover,6,"I can recover the previous behavior, i.e., different runs of the notebook give identical UMAP and leiden clusters, by downgrading to scanpy version 1.9.2 (and also pandas to version 1.5.3). I do this in conda and in this environment other relevant installed package versions are numpy 1.23.5, scipy 1.10.1 and scikit-learn 1.2.2.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1531696555
https://github.com/scverse/scanpy/issues/2480#issuecomment-1531696555:118,Availability,down,downgrading,118,"I can recover the previous behavior, i.e., different runs of the notebook give identical UMAP and leiden clusters, by downgrading to scanpy version 1.9.2 (and also pandas to version 1.5.3). I do this in conda and in this environment other relevant installed package versions are numpy 1.23.5, scipy 1.10.1 and scikit-learn 1.2.2.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1531696555
https://github.com/scverse/scanpy/issues/2480#issuecomment-1531696555:248,Deployability,install,installed,248,"I can recover the previous behavior, i.e., different runs of the notebook give identical UMAP and leiden clusters, by downgrading to scanpy version 1.9.2 (and also pandas to version 1.5.3). I do this in conda and in this environment other relevant installed package versions are numpy 1.23.5, scipy 1.10.1 and scikit-learn 1.2.2.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1531696555
https://github.com/scverse/scanpy/issues/2480#issuecomment-1531696555:6,Safety,recover,recover,6,"I can recover the previous behavior, i.e., different runs of the notebook give identical UMAP and leiden clusters, by downgrading to scanpy version 1.9.2 (and also pandas to version 1.5.3). I do this in conda and in this environment other relevant installed package versions are numpy 1.23.5, scipy 1.10.1 and scikit-learn 1.2.2.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1531696555
https://github.com/scverse/scanpy/issues/2480#issuecomment-1531696555:317,Usability,learn,learn,317,"I can recover the previous behavior, i.e., different runs of the notebook give identical UMAP and leiden clusters, by downgrading to scanpy version 1.9.2 (and also pandas to version 1.5.3). I do this in conda and in this environment other relevant installed package versions are numpy 1.23.5, scipy 1.10.1 and scikit-learn 1.2.2.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1531696555
https://github.com/scverse/scanpy/issues/2480#issuecomment-1531836933:1753,Deployability,update,updated,1753,"And now I checked that the problem exists in the master branch. Versions used below:. <details><summary>Details</summary>; <p>. -----; anndata 0.9.1; scanpy 1.10.0.dev57+g08be4e9a; -----; PIL 9.4.0; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; colorama 0.4.6; comm 0.1.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; executing 1.2.0; gmpy2 2.1.2; google NA; h5py 3.8.0; hypergeom_ufunc NA; igraph 0.10.4; invgauss_ufunc NA; ipykernel 6.22.0; ipywidgets 8.0.6; jedi 0.18.2; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.39.1; matplotlib 3.7.1; matplotlib_inline 0.1.6; mpl_toolkits NA; mpmath 1.3.0; natsort 8.3.1; nbinom_ufunc NA; ncf_ufunc NA; nct_ufunc NA; ncx2_ufunc NA; numba 0.56.4; numpy 1.23.5; nvfuser NA; opt_einsum v3.3.0; packaging 23.1; pandas 2.0.1; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.5.0; prompt_toolkit 3.0.38; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.15.1; pynndescent 0.5.10; pyparsing 3.0.9; pytz 2023.3; scipy 1.10.1; session_info 1.0.0; setuptools 67.7.2; setuptools_scm NA; six 1.16.0; skewnorm_ufunc NA; sklearn 1.2.2; stack_data 0.6.2; sympy 1.11.1; texttable 1.6.7; threadpoolctl 3.1.0; torch 2.0.0; tornado 6.3; tqdm 4.65.0; traitlets 5.9.0; typing_extensions NA; umap 0.5.3; wcwidth 0.2.6; yaml 6.0; zmq 25.0.2; zoneinfo NA; -----; IPython 8.12.1; jupyter_client 8.2.0; jupyter_core 5.3.0; -----; Python 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]; Linux-5.19.0-41-generic-x86_64-with-glibc2.36; -----; Session information updated at 2023-05-03 02:03. </p>; </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1531836933
https://github.com/scverse/scanpy/issues/2480#issuecomment-1532980542:66,Deployability,install,installed,66,"To add more confusion I created a new environment in which I only installed from conda-forge scanpy (1.9.3) and leidenalg. Now the plots are reproducible. Installed package versions bellow. My guess now is that there is some unexpected change in the random number generator caused by some other package? Perhaps it has to do something with pytorch 2.x? This one is installed because I have in the same environment scvi-tools. But if we pass the random_state, as umap and leiden methods do, shouldn't that work anyway?. <details><summary>Details</summary>; <p>. -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.5.0; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; colorama 0.4.6; comm 0.1.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; executing 1.2.0; h5py 3.8.0; hypergeom_ufunc NA; igraph 0.10.3; invgauss_ufunc NA; ipykernel 6.22.0; jedi 0.18.2; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.39.1; matplotlib 3.7.1; matplotlib_inline 0.1.6; mpl_toolkits NA; natsort 8.3.1; nbinom_ufunc NA; ncf_ufunc NA; nct_ufunc NA; ncx2_ufunc NA; numba 0.56.4; numpy 1.23.5; packaging 23.1; pandas 2.0.1; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.5.0; prompt_toolkit 3.0.38; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.15.1; pynndescent 0.5.10; pyparsing 3.0.9; pytz 2023.3; scipy 1.10.1; session_info 1.0.0; setuptools 67.7.2; six 1.16.0; skewnorm_ufunc NA; sklearn 1.2.2; stack_data 0.6.2; texttable 1.6.7; threadpoolctl 3.1.0; tornado 6.3; tqdm 4.65.0; traitlets 5.9.0; typing_extensions NA; umap 0.5.3; wcwidth 0.2.6; zmq 25.0.2; zoneinfo NA; -----; IPython 8.13.1; jupyter_client 8.2.0; jupyter_core 5.3.0; -----; Python 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]; Linux-5.19.0-41-generic-x86_64-with-glibc2.36; --",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1532980542
https://github.com/scverse/scanpy/issues/2480#issuecomment-1532980542:155,Deployability,Install,Installed,155,"To add more confusion I created a new environment in which I only installed from conda-forge scanpy (1.9.3) and leidenalg. Now the plots are reproducible. Installed package versions bellow. My guess now is that there is some unexpected change in the random number generator caused by some other package? Perhaps it has to do something with pytorch 2.x? This one is installed because I have in the same environment scvi-tools. But if we pass the random_state, as umap and leiden methods do, shouldn't that work anyway?. <details><summary>Details</summary>; <p>. -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.5.0; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; colorama 0.4.6; comm 0.1.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; executing 1.2.0; h5py 3.8.0; hypergeom_ufunc NA; igraph 0.10.3; invgauss_ufunc NA; ipykernel 6.22.0; jedi 0.18.2; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.39.1; matplotlib 3.7.1; matplotlib_inline 0.1.6; mpl_toolkits NA; natsort 8.3.1; nbinom_ufunc NA; ncf_ufunc NA; nct_ufunc NA; ncx2_ufunc NA; numba 0.56.4; numpy 1.23.5; packaging 23.1; pandas 2.0.1; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.5.0; prompt_toolkit 3.0.38; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.15.1; pynndescent 0.5.10; pyparsing 3.0.9; pytz 2023.3; scipy 1.10.1; session_info 1.0.0; setuptools 67.7.2; six 1.16.0; skewnorm_ufunc NA; sklearn 1.2.2; stack_data 0.6.2; texttable 1.6.7; threadpoolctl 3.1.0; tornado 6.3; tqdm 4.65.0; traitlets 5.9.0; typing_extensions NA; umap 0.5.3; wcwidth 0.2.6; zmq 25.0.2; zoneinfo NA; -----; IPython 8.13.1; jupyter_client 8.2.0; jupyter_core 5.3.0; -----; Python 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]; Linux-5.19.0-41-generic-x86_64-with-glibc2.36; --",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1532980542
https://github.com/scverse/scanpy/issues/2480#issuecomment-1532980542:365,Deployability,install,installed,365,"To add more confusion I created a new environment in which I only installed from conda-forge scanpy (1.9.3) and leidenalg. Now the plots are reproducible. Installed package versions bellow. My guess now is that there is some unexpected change in the random number generator caused by some other package? Perhaps it has to do something with pytorch 2.x? This one is installed because I have in the same environment scvi-tools. But if we pass the random_state, as umap and leiden methods do, shouldn't that work anyway?. <details><summary>Details</summary>; <p>. -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.5.0; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; colorama 0.4.6; comm 0.1.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; executing 1.2.0; h5py 3.8.0; hypergeom_ufunc NA; igraph 0.10.3; invgauss_ufunc NA; ipykernel 6.22.0; jedi 0.18.2; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.39.1; matplotlib 3.7.1; matplotlib_inline 0.1.6; mpl_toolkits NA; natsort 8.3.1; nbinom_ufunc NA; ncf_ufunc NA; nct_ufunc NA; ncx2_ufunc NA; numba 0.56.4; numpy 1.23.5; packaging 23.1; pandas 2.0.1; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.5.0; prompt_toolkit 3.0.38; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.15.1; pynndescent 0.5.10; pyparsing 3.0.9; pytz 2023.3; scipy 1.10.1; session_info 1.0.0; setuptools 67.7.2; six 1.16.0; skewnorm_ufunc NA; sklearn 1.2.2; stack_data 0.6.2; texttable 1.6.7; threadpoolctl 3.1.0; tornado 6.3; tqdm 4.65.0; traitlets 5.9.0; typing_extensions NA; umap 0.5.3; wcwidth 0.2.6; zmq 25.0.2; zoneinfo NA; -----; IPython 8.13.1; jupyter_client 8.2.0; jupyter_core 5.3.0; -----; Python 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]; Linux-5.19.0-41-generic-x86_64-with-glibc2.36; --",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1532980542
https://github.com/scverse/scanpy/issues/2480#issuecomment-1532980542:2026,Deployability,update,updated,2026,"lled from conda-forge scanpy (1.9.3) and leidenalg. Now the plots are reproducible. Installed package versions bellow. My guess now is that there is some unexpected change in the random number generator caused by some other package? Perhaps it has to do something with pytorch 2.x? This one is installed because I have in the same environment scvi-tools. But if we pass the random_state, as umap and leiden methods do, shouldn't that work anyway?. <details><summary>Details</summary>; <p>. -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.5.0; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; colorama 0.4.6; comm 0.1.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; executing 1.2.0; h5py 3.8.0; hypergeom_ufunc NA; igraph 0.10.3; invgauss_ufunc NA; ipykernel 6.22.0; jedi 0.18.2; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.39.1; matplotlib 3.7.1; matplotlib_inline 0.1.6; mpl_toolkits NA; natsort 8.3.1; nbinom_ufunc NA; ncf_ufunc NA; nct_ufunc NA; ncx2_ufunc NA; numba 0.56.4; numpy 1.23.5; packaging 23.1; pandas 2.0.1; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.5.0; prompt_toolkit 3.0.38; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.15.1; pynndescent 0.5.10; pyparsing 3.0.9; pytz 2023.3; scipy 1.10.1; session_info 1.0.0; setuptools 67.7.2; six 1.16.0; skewnorm_ufunc NA; sklearn 1.2.2; stack_data 0.6.2; texttable 1.6.7; threadpoolctl 3.1.0; tornado 6.3; tqdm 4.65.0; traitlets 5.9.0; typing_extensions NA; umap 0.5.3; wcwidth 0.2.6; zmq 25.0.2; zoneinfo NA; -----; IPython 8.13.1; jupyter_client 8.2.0; jupyter_core 5.3.0; -----; Python 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]; Linux-5.19.0-41-generic-x86_64-with-glibc2.36; -----; Session information updated at 2023-05-03 21:49. </p>; </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1532980542
https://github.com/scverse/scanpy/issues/2480#issuecomment-1533334993:67,Deployability,install,installed,67,"The last test. In an environment with scanpy (1.9.3) and leidenalg installed, I can get reproducible runs for the code above. If I install the following packages:. ```; conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia; ```; Then I start to have problems with reproducibility. I have no idea how this is possible but perhaps one clue is that torch is being reported in the package versions even though I am not loading it or using scvi-tools. Probably this is related to the latest update in anndata. <details><summary>Details</summary>; <p>. -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.4.0; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; colorama 0.4.6; comm 0.1.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; executing 1.2.0; gmpy2 2.1.2; h5py 3.8.0; hypergeom_ufunc NA; igraph 0.10.3; invgauss_ufunc NA; ipykernel 6.22.0; jedi 0.18.2; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.39.1; matplotlib 3.7.1; matplotlib_inline 0.1.6; mpl_toolkits NA; mpmath 1.3.0; natsort 8.3.1; nbinom_ufunc NA; ncf_ufunc NA; nct_ufunc NA; ncx2_ufunc NA; numba 0.56.4; numpy 1.23.5; nvfuser NA; packaging 23.1; pandas 2.0.1; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.5.0; prompt_toolkit 3.0.38; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.15.1; pynndescent 0.5.10; pyparsing 3.0.9; pytz 2023.3; scipy 1.10.1; session_info 1.0.0; setuptools 67.7.2; six 1.16.0; skewnorm_ufunc NA; sklearn 1.2.2; stack_data 0.6.2; sympy 1.11.1; texttable 1.6.7; threadpoolctl 3.1.0; torch 2.0.0; tornado 6.3; tqdm 4.65.0; traitlets 5.9.0; typing_extensions NA; umap 0.5.3; wcwidth 0.2.6; zmq 25.0.2; zoneinfo NA; -----; IPython 8.13.1; jupyter_client 8.2.0; jupyter_core 5.3.0; -----; Python 3.10.10 | packaged by conda-forge | (main, Mar ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1533334993
https://github.com/scverse/scanpy/issues/2480#issuecomment-1533334993:131,Deployability,install,install,131,"The last test. In an environment with scanpy (1.9.3) and leidenalg installed, I can get reproducible runs for the code above. If I install the following packages:. ```; conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia; ```; Then I start to have problems with reproducibility. I have no idea how this is possible but perhaps one clue is that torch is being reported in the package versions even though I am not loading it or using scvi-tools. Probably this is related to the latest update in anndata. <details><summary>Details</summary>; <p>. -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.4.0; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; colorama 0.4.6; comm 0.1.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; executing 1.2.0; gmpy2 2.1.2; h5py 3.8.0; hypergeom_ufunc NA; igraph 0.10.3; invgauss_ufunc NA; ipykernel 6.22.0; jedi 0.18.2; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.39.1; matplotlib 3.7.1; matplotlib_inline 0.1.6; mpl_toolkits NA; mpmath 1.3.0; natsort 8.3.1; nbinom_ufunc NA; ncf_ufunc NA; nct_ufunc NA; ncx2_ufunc NA; numba 0.56.4; numpy 1.23.5; nvfuser NA; packaging 23.1; pandas 2.0.1; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.5.0; prompt_toolkit 3.0.38; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.15.1; pynndescent 0.5.10; pyparsing 3.0.9; pytz 2023.3; scipy 1.10.1; session_info 1.0.0; setuptools 67.7.2; six 1.16.0; skewnorm_ufunc NA; sklearn 1.2.2; stack_data 0.6.2; sympy 1.11.1; texttable 1.6.7; threadpoolctl 3.1.0; torch 2.0.0; tornado 6.3; tqdm 4.65.0; traitlets 5.9.0; typing_extensions NA; umap 0.5.3; wcwidth 0.2.6; zmq 25.0.2; zoneinfo NA; -----; IPython 8.13.1; jupyter_client 8.2.0; jupyter_core 5.3.0; -----; Python 3.10.10 | packaged by conda-forge | (main, Mar ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1533334993
https://github.com/scverse/scanpy/issues/2480#issuecomment-1533334993:175,Deployability,install,install,175,"The last test. In an environment with scanpy (1.9.3) and leidenalg installed, I can get reproducible runs for the code above. If I install the following packages:. ```; conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia; ```; Then I start to have problems with reproducibility. I have no idea how this is possible but perhaps one clue is that torch is being reported in the package versions even though I am not loading it or using scvi-tools. Probably this is related to the latest update in anndata. <details><summary>Details</summary>; <p>. -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.4.0; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; colorama 0.4.6; comm 0.1.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; executing 1.2.0; gmpy2 2.1.2; h5py 3.8.0; hypergeom_ufunc NA; igraph 0.10.3; invgauss_ufunc NA; ipykernel 6.22.0; jedi 0.18.2; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.39.1; matplotlib 3.7.1; matplotlib_inline 0.1.6; mpl_toolkits NA; mpmath 1.3.0; natsort 8.3.1; nbinom_ufunc NA; ncf_ufunc NA; nct_ufunc NA; ncx2_ufunc NA; numba 0.56.4; numpy 1.23.5; nvfuser NA; packaging 23.1; pandas 2.0.1; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.5.0; prompt_toolkit 3.0.38; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.15.1; pynndescent 0.5.10; pyparsing 3.0.9; pytz 2023.3; scipy 1.10.1; session_info 1.0.0; setuptools 67.7.2; six 1.16.0; skewnorm_ufunc NA; sklearn 1.2.2; stack_data 0.6.2; sympy 1.11.1; texttable 1.6.7; threadpoolctl 3.1.0; torch 2.0.0; tornado 6.3; tqdm 4.65.0; traitlets 5.9.0; typing_extensions NA; umap 0.5.3; wcwidth 0.2.6; zmq 25.0.2; zoneinfo NA; -----; IPython 8.13.1; jupyter_client 8.2.0; jupyter_core 5.3.0; -----; Python 3.10.10 | packaged by conda-forge | (main, Mar ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1533334993
https://github.com/scverse/scanpy/issues/2480#issuecomment-1533334993:516,Deployability,update,update,516,"The last test. In an environment with scanpy (1.9.3) and leidenalg installed, I can get reproducible runs for the code above. If I install the following packages:. ```; conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia; ```; Then I start to have problems with reproducibility. I have no idea how this is possible but perhaps one clue is that torch is being reported in the package versions even though I am not loading it or using scvi-tools. Probably this is related to the latest update in anndata. <details><summary>Details</summary>; <p>. -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.4.0; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; colorama 0.4.6; comm 0.1.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; executing 1.2.0; gmpy2 2.1.2; h5py 3.8.0; hypergeom_ufunc NA; igraph 0.10.3; invgauss_ufunc NA; ipykernel 6.22.0; jedi 0.18.2; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.39.1; matplotlib 3.7.1; matplotlib_inline 0.1.6; mpl_toolkits NA; mpmath 1.3.0; natsort 8.3.1; nbinom_ufunc NA; ncf_ufunc NA; nct_ufunc NA; ncx2_ufunc NA; numba 0.56.4; numpy 1.23.5; nvfuser NA; packaging 23.1; pandas 2.0.1; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.5.0; prompt_toolkit 3.0.38; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.15.1; pynndescent 0.5.10; pyparsing 3.0.9; pytz 2023.3; scipy 1.10.1; session_info 1.0.0; setuptools 67.7.2; six 1.16.0; skewnorm_ufunc NA; sklearn 1.2.2; stack_data 0.6.2; sympy 1.11.1; texttable 1.6.7; threadpoolctl 3.1.0; torch 2.0.0; tornado 6.3; tqdm 4.65.0; traitlets 5.9.0; typing_extensions NA; umap 0.5.3; wcwidth 0.2.6; zmq 25.0.2; zoneinfo NA; -----; IPython 8.13.1; jupyter_client 8.2.0; jupyter_core 5.3.0; -----; Python 3.10.10 | packaged by conda-forge | (main, Mar ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1533334993
https://github.com/scverse/scanpy/issues/2480#issuecomment-1533334993:2108,Deployability,update,updated,2108,"packages:. ```; conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia; ```; Then I start to have problems with reproducibility. I have no idea how this is possible but perhaps one clue is that torch is being reported in the package versions even though I am not loading it or using scvi-tools. Probably this is related to the latest update in anndata. <details><summary>Details</summary>; <p>. -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.4.0; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; colorama 0.4.6; comm 0.1.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; executing 1.2.0; gmpy2 2.1.2; h5py 3.8.0; hypergeom_ufunc NA; igraph 0.10.3; invgauss_ufunc NA; ipykernel 6.22.0; jedi 0.18.2; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.39.1; matplotlib 3.7.1; matplotlib_inline 0.1.6; mpl_toolkits NA; mpmath 1.3.0; natsort 8.3.1; nbinom_ufunc NA; ncf_ufunc NA; nct_ufunc NA; ncx2_ufunc NA; numba 0.56.4; numpy 1.23.5; nvfuser NA; packaging 23.1; pandas 2.0.1; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.5.0; prompt_toolkit 3.0.38; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.15.1; pynndescent 0.5.10; pyparsing 3.0.9; pytz 2023.3; scipy 1.10.1; session_info 1.0.0; setuptools 67.7.2; six 1.16.0; skewnorm_ufunc NA; sklearn 1.2.2; stack_data 0.6.2; sympy 1.11.1; texttable 1.6.7; threadpoolctl 3.1.0; torch 2.0.0; tornado 6.3; tqdm 4.65.0; traitlets 5.9.0; typing_extensions NA; umap 0.5.3; wcwidth 0.2.6; zmq 25.0.2; zoneinfo NA; -----; IPython 8.13.1; jupyter_client 8.2.0; jupyter_core 5.3.0; -----; Python 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]; Linux-5.19.0-41-generic-x86_64-with-glibc2.36; -----; Session information updated at 2023-05-04 01:16. </p>; </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1533334993
https://github.com/scverse/scanpy/issues/2480#issuecomment-1533334993:445,Performance,load,loading,445,"The last test. In an environment with scanpy (1.9.3) and leidenalg installed, I can get reproducible runs for the code above. If I install the following packages:. ```; conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia; ```; Then I start to have problems with reproducibility. I have no idea how this is possible but perhaps one clue is that torch is being reported in the package versions even though I am not loading it or using scvi-tools. Probably this is related to the latest update in anndata. <details><summary>Details</summary>; <p>. -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.4.0; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; colorama 0.4.6; comm 0.1.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; executing 1.2.0; gmpy2 2.1.2; h5py 3.8.0; hypergeom_ufunc NA; igraph 0.10.3; invgauss_ufunc NA; ipykernel 6.22.0; jedi 0.18.2; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.39.1; matplotlib 3.7.1; matplotlib_inline 0.1.6; mpl_toolkits NA; mpmath 1.3.0; natsort 8.3.1; nbinom_ufunc NA; ncf_ufunc NA; nct_ufunc NA; ncx2_ufunc NA; numba 0.56.4; numpy 1.23.5; nvfuser NA; packaging 23.1; pandas 2.0.1; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.5.0; prompt_toolkit 3.0.38; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.15.1; pynndescent 0.5.10; pyparsing 3.0.9; pytz 2023.3; scipy 1.10.1; session_info 1.0.0; setuptools 67.7.2; six 1.16.0; skewnorm_ufunc NA; sklearn 1.2.2; stack_data 0.6.2; sympy 1.11.1; texttable 1.6.7; threadpoolctl 3.1.0; torch 2.0.0; tornado 6.3; tqdm 4.65.0; traitlets 5.9.0; typing_extensions NA; umap 0.5.3; wcwidth 0.2.6; zmq 25.0.2; zoneinfo NA; -----; IPython 8.13.1; jupyter_client 8.2.0; jupyter_core 5.3.0; -----; Python 3.10.10 | packaged by conda-forge | (main, Mar ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1533334993
https://github.com/scverse/scanpy/issues/2480#issuecomment-1533334993:9,Testability,test,test,9,"The last test. In an environment with scanpy (1.9.3) and leidenalg installed, I can get reproducible runs for the code above. If I install the following packages:. ```; conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia; ```; Then I start to have problems with reproducibility. I have no idea how this is possible but perhaps one clue is that torch is being reported in the package versions even though I am not loading it or using scvi-tools. Probably this is related to the latest update in anndata. <details><summary>Details</summary>; <p>. -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.4.0; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; colorama 0.4.6; comm 0.1.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; executing 1.2.0; gmpy2 2.1.2; h5py 3.8.0; hypergeom_ufunc NA; igraph 0.10.3; invgauss_ufunc NA; ipykernel 6.22.0; jedi 0.18.2; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.39.1; matplotlib 3.7.1; matplotlib_inline 0.1.6; mpl_toolkits NA; mpmath 1.3.0; natsort 8.3.1; nbinom_ufunc NA; ncf_ufunc NA; nct_ufunc NA; ncx2_ufunc NA; numba 0.56.4; numpy 1.23.5; nvfuser NA; packaging 23.1; pandas 2.0.1; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.5.0; prompt_toolkit 3.0.38; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.15.1; pynndescent 0.5.10; pyparsing 3.0.9; pytz 2023.3; scipy 1.10.1; session_info 1.0.0; setuptools 67.7.2; six 1.16.0; skewnorm_ufunc NA; sklearn 1.2.2; stack_data 0.6.2; sympy 1.11.1; texttable 1.6.7; threadpoolctl 3.1.0; torch 2.0.0; tornado 6.3; tqdm 4.65.0; traitlets 5.9.0; typing_extensions NA; umap 0.5.3; wcwidth 0.2.6; zmq 25.0.2; zoneinfo NA; -----; IPython 8.13.1; jupyter_client 8.2.0; jupyter_core 5.3.0; -----; Python 3.10.10 | packaged by conda-forge | (main, Mar ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1533334993
https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205:874,Availability,down,download,874,"Based on [this conversation](https://discourse.scverse.org/t/scgen-generate-irreproducible-output/1622/3) on the scverse discourse site I found out that the behavior shown here does not happen if I install scanpy and pytorch (CUDA) from PyPI. It is however still happening if I install scanpy and pytorch (CUDA) using conda. I still do not know why this is happening but this shows it is not likely a problem with scanpy but some strange interaction. I will leave here the description of the packages installed in both cases for reference, and then close the issue:. 1. The behavior shown in this issue does not happen if I create an environment in conda with python installed, and then install all packages using pip like this:. ```; conda create -n scanpy_test1 python; pip install scanpy leidenalg scvi-tools; pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118; ```. This allows me to have GPU support with scvi-tools and different runs are reproducible. The packages in this environment:. <details><summary>Packages</summary>; <p>. # Name Version Build Channel; _libgcc_mutex 0.1 conda_forge conda-forge; _openmp_mutex 4.5 2_gnu conda-forge; absl-py 1.4.0 pypi_0 pypi; adjusttext 0.8 pypi_0 pypi; aiohttp 3.8.5 pypi_0 pypi; aiosignal 1.3.1 pypi_0 pypi; airr 1.4.1 pypi_0 pypi; anndata 0.9.1 pypi_0 pypi; anyio 3.7.1 pypi_0 pypi; arrow 1.2.3 pypi_0 pypi; asttokens 2.2.1 pyhd8ed1ab_0 conda-forge; async-timeout 4.0.2 pypi_0 pypi; attrs 23.1.0 pypi_0 pypi; awkward 2.3.1 pypi_0 pypi; awkward-cpp 21 pypi_0 pypi; backcall 0.2.0 pyh9f0ad1d_0 conda-forge; backoff 2.2.1 pypi_0 pypi; backports 1.0 pyhd8ed1ab_3 conda-forge; backports.functools_lru_cache 1.6.5 pyhd8ed1ab_0 conda-forge; beautifulsoup4 4.12.2 pypi_0 pypi; blessed 1.20.0 pypi_0 pypi; brotli-python 1.0.9 py311ha362b79_9 conda-forge; bzip2 1.0.8 h7f98852_4 conda-forge; ca-certificates 2023.7.22 hbcca054_0 conda-forge; certifi 2022.12.7 pypi_0 pypi; charset-normalizer 2.1.1 pypi_0 pypi; chex 0.1.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205
https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205:5147,Availability,checkpoint,checkpoint,5147,onda-forge; libstdcxx-ng 13.1.0 hfd8a6a1_0 conda-forge; libuuid 2.38.1 h0b41bf4_0 conda-forge; libzlib 1.2.13 hd590300_5 conda-forge; lightning 2.0.5 pypi_0 pypi; lightning-cloud 0.5.37 pypi_0 pypi; lightning-utilities 0.9.0 pypi_0 pypi; lit 15.0.7 pypi_0 pypi; llvmlite 0.40.1 pypi_0 pypi; markdown-it-py 3.0.0 pypi_0 pypi; markupsafe 2.1.2 pypi_0 pypi; matplotlib 3.7.2 pypi_0 pypi; matplotlib-inline 0.1.6 pyhd8ed1ab_0 conda-forge; mdurl 0.1.2 pypi_0 pypi; ml-collections 0.1.1 pypi_0 pypi; ml-dtypes 0.2.0 pypi_0 pypi; mpmath 1.2.1 pypi_0 pypi; msgpack 1.0.5 pypi_0 pypi; mudata 0.2.3 pypi_0 pypi; multidict 6.0.4 pypi_0 pypi; multipledispatch 1.0.0 pypi_0 pypi; muon 0.1.5 pypi_0 pypi; natsort 8.4.0 pypi_0 pypi; ncurses 6.4 hcb278e6_0 conda-forge; nest-asyncio 1.5.6 pyhd8ed1ab_0 conda-forge; networkx 3.1 pypi_0 pypi; numba 0.57.1 pypi_0 pypi; numpy 1.24.4 pypi_0 pypi; numpyro 0.12.1 pypi_0 pypi; openssl 3.1.1 hd590300_1 conda-forge; opt-einsum 3.3.0 pypi_0 pypi; optax 0.1.5 pypi_0 pypi; orbax-checkpoint 0.2.7 pypi_0 pypi; ordered-set 4.1.0 pypi_0 pypi; packaging 23.1 pyhd8ed1ab_0 conda-forge; pandas 2.0.3 pypi_0 pypi; parasail 1.3.4 pypi_0 pypi; parso 0.8.3 pyhd8ed1ab_0 conda-forge; patsy 0.5.3 pypi_0 pypi; pexpect 4.8.0 pyh1a96a4e_2 conda-forge; pickleshare 0.7.5 py_1003 conda-forge; pillow 10.0.0 pypi_0 pypi; pip 23.2.1 pyhd8ed1ab_0 conda-forge; platformdirs 3.9.1 pyhd8ed1ab_0 conda-forge; pooch 1.7.0 pyha770c72_3 conda-forge; prompt-toolkit 3.0.39 pyha770c72_0 conda-forge; prompt_toolkit 3.0.39 hd8ed1ab_0 conda-forge; protobuf 4.23.4 pypi_0 pypi; psutil 5.9.5 py311h2582759_0 conda-forge; ptyprocess 0.7.0 pyhd3deb0d_0 conda-forge; pure_eval 0.2.2 pyhd8ed1ab_0 conda-forge; pydantic 1.10.11 pypi_0 pypi; pygments 2.15.1 pyhd8ed1ab_0 conda-forge; pyjwt 2.8.0 pypi_0 pypi; pynndescent 0.5.10 pypi_0 pypi; pyparsing 3.0.9 pypi_0 pypi; pyro-api 0.1.2 pypi_0 pypi; pyro-ppl 1.8.5 pypi_0 pypi; pysocks 1.7.1 pyha2e5f31_6 conda-forge; python 3.11.4 hab00c5b_0_cpython conda-forge; p,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205
https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205:198,Deployability,install,install,198,"Based on [this conversation](https://discourse.scverse.org/t/scgen-generate-irreproducible-output/1622/3) on the scverse discourse site I found out that the behavior shown here does not happen if I install scanpy and pytorch (CUDA) from PyPI. It is however still happening if I install scanpy and pytorch (CUDA) using conda. I still do not know why this is happening but this shows it is not likely a problem with scanpy but some strange interaction. I will leave here the description of the packages installed in both cases for reference, and then close the issue:. 1. The behavior shown in this issue does not happen if I create an environment in conda with python installed, and then install all packages using pip like this:. ```; conda create -n scanpy_test1 python; pip install scanpy leidenalg scvi-tools; pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118; ```. This allows me to have GPU support with scvi-tools and different runs are reproducible. The packages in this environment:. <details><summary>Packages</summary>; <p>. # Name Version Build Channel; _libgcc_mutex 0.1 conda_forge conda-forge; _openmp_mutex 4.5 2_gnu conda-forge; absl-py 1.4.0 pypi_0 pypi; adjusttext 0.8 pypi_0 pypi; aiohttp 3.8.5 pypi_0 pypi; aiosignal 1.3.1 pypi_0 pypi; airr 1.4.1 pypi_0 pypi; anndata 0.9.1 pypi_0 pypi; anyio 3.7.1 pypi_0 pypi; arrow 1.2.3 pypi_0 pypi; asttokens 2.2.1 pyhd8ed1ab_0 conda-forge; async-timeout 4.0.2 pypi_0 pypi; attrs 23.1.0 pypi_0 pypi; awkward 2.3.1 pypi_0 pypi; awkward-cpp 21 pypi_0 pypi; backcall 0.2.0 pyh9f0ad1d_0 conda-forge; backoff 2.2.1 pypi_0 pypi; backports 1.0 pyhd8ed1ab_3 conda-forge; backports.functools_lru_cache 1.6.5 pyhd8ed1ab_0 conda-forge; beautifulsoup4 4.12.2 pypi_0 pypi; blessed 1.20.0 pypi_0 pypi; brotli-python 1.0.9 py311ha362b79_9 conda-forge; bzip2 1.0.8 h7f98852_4 conda-forge; ca-certificates 2023.7.22 hbcca054_0 conda-forge; certifi 2022.12.7 pypi_0 pypi; charset-normalizer 2.1.1 pypi_0 pypi; chex 0.1.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205
https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205:278,Deployability,install,install,278,"Based on [this conversation](https://discourse.scverse.org/t/scgen-generate-irreproducible-output/1622/3) on the scverse discourse site I found out that the behavior shown here does not happen if I install scanpy and pytorch (CUDA) from PyPI. It is however still happening if I install scanpy and pytorch (CUDA) using conda. I still do not know why this is happening but this shows it is not likely a problem with scanpy but some strange interaction. I will leave here the description of the packages installed in both cases for reference, and then close the issue:. 1. The behavior shown in this issue does not happen if I create an environment in conda with python installed, and then install all packages using pip like this:. ```; conda create -n scanpy_test1 python; pip install scanpy leidenalg scvi-tools; pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118; ```. This allows me to have GPU support with scvi-tools and different runs are reproducible. The packages in this environment:. <details><summary>Packages</summary>; <p>. # Name Version Build Channel; _libgcc_mutex 0.1 conda_forge conda-forge; _openmp_mutex 4.5 2_gnu conda-forge; absl-py 1.4.0 pypi_0 pypi; adjusttext 0.8 pypi_0 pypi; aiohttp 3.8.5 pypi_0 pypi; aiosignal 1.3.1 pypi_0 pypi; airr 1.4.1 pypi_0 pypi; anndata 0.9.1 pypi_0 pypi; anyio 3.7.1 pypi_0 pypi; arrow 1.2.3 pypi_0 pypi; asttokens 2.2.1 pyhd8ed1ab_0 conda-forge; async-timeout 4.0.2 pypi_0 pypi; attrs 23.1.0 pypi_0 pypi; awkward 2.3.1 pypi_0 pypi; awkward-cpp 21 pypi_0 pypi; backcall 0.2.0 pyh9f0ad1d_0 conda-forge; backoff 2.2.1 pypi_0 pypi; backports 1.0 pyhd8ed1ab_3 conda-forge; backports.functools_lru_cache 1.6.5 pyhd8ed1ab_0 conda-forge; beautifulsoup4 4.12.2 pypi_0 pypi; blessed 1.20.0 pypi_0 pypi; brotli-python 1.0.9 py311ha362b79_9 conda-forge; bzip2 1.0.8 h7f98852_4 conda-forge; ca-certificates 2023.7.22 hbcca054_0 conda-forge; certifi 2022.12.7 pypi_0 pypi; charset-normalizer 2.1.1 pypi_0 pypi; chex 0.1.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205
https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205:501,Deployability,install,installed,501,"Based on [this conversation](https://discourse.scverse.org/t/scgen-generate-irreproducible-output/1622/3) on the scverse discourse site I found out that the behavior shown here does not happen if I install scanpy and pytorch (CUDA) from PyPI. It is however still happening if I install scanpy and pytorch (CUDA) using conda. I still do not know why this is happening but this shows it is not likely a problem with scanpy but some strange interaction. I will leave here the description of the packages installed in both cases for reference, and then close the issue:. 1. The behavior shown in this issue does not happen if I create an environment in conda with python installed, and then install all packages using pip like this:. ```; conda create -n scanpy_test1 python; pip install scanpy leidenalg scvi-tools; pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118; ```. This allows me to have GPU support with scvi-tools and different runs are reproducible. The packages in this environment:. <details><summary>Packages</summary>; <p>. # Name Version Build Channel; _libgcc_mutex 0.1 conda_forge conda-forge; _openmp_mutex 4.5 2_gnu conda-forge; absl-py 1.4.0 pypi_0 pypi; adjusttext 0.8 pypi_0 pypi; aiohttp 3.8.5 pypi_0 pypi; aiosignal 1.3.1 pypi_0 pypi; airr 1.4.1 pypi_0 pypi; anndata 0.9.1 pypi_0 pypi; anyio 3.7.1 pypi_0 pypi; arrow 1.2.3 pypi_0 pypi; asttokens 2.2.1 pyhd8ed1ab_0 conda-forge; async-timeout 4.0.2 pypi_0 pypi; attrs 23.1.0 pypi_0 pypi; awkward 2.3.1 pypi_0 pypi; awkward-cpp 21 pypi_0 pypi; backcall 0.2.0 pyh9f0ad1d_0 conda-forge; backoff 2.2.1 pypi_0 pypi; backports 1.0 pyhd8ed1ab_3 conda-forge; backports.functools_lru_cache 1.6.5 pyhd8ed1ab_0 conda-forge; beautifulsoup4 4.12.2 pypi_0 pypi; blessed 1.20.0 pypi_0 pypi; brotli-python 1.0.9 py311ha362b79_9 conda-forge; bzip2 1.0.8 h7f98852_4 conda-forge; ca-certificates 2023.7.22 hbcca054_0 conda-forge; certifi 2022.12.7 pypi_0 pypi; charset-normalizer 2.1.1 pypi_0 pypi; chex 0.1.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205
https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205:667,Deployability,install,installed,667,"Based on [this conversation](https://discourse.scverse.org/t/scgen-generate-irreproducible-output/1622/3) on the scverse discourse site I found out that the behavior shown here does not happen if I install scanpy and pytorch (CUDA) from PyPI. It is however still happening if I install scanpy and pytorch (CUDA) using conda. I still do not know why this is happening but this shows it is not likely a problem with scanpy but some strange interaction. I will leave here the description of the packages installed in both cases for reference, and then close the issue:. 1. The behavior shown in this issue does not happen if I create an environment in conda with python installed, and then install all packages using pip like this:. ```; conda create -n scanpy_test1 python; pip install scanpy leidenalg scvi-tools; pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118; ```. This allows me to have GPU support with scvi-tools and different runs are reproducible. The packages in this environment:. <details><summary>Packages</summary>; <p>. # Name Version Build Channel; _libgcc_mutex 0.1 conda_forge conda-forge; _openmp_mutex 4.5 2_gnu conda-forge; absl-py 1.4.0 pypi_0 pypi; adjusttext 0.8 pypi_0 pypi; aiohttp 3.8.5 pypi_0 pypi; aiosignal 1.3.1 pypi_0 pypi; airr 1.4.1 pypi_0 pypi; anndata 0.9.1 pypi_0 pypi; anyio 3.7.1 pypi_0 pypi; arrow 1.2.3 pypi_0 pypi; asttokens 2.2.1 pyhd8ed1ab_0 conda-forge; async-timeout 4.0.2 pypi_0 pypi; attrs 23.1.0 pypi_0 pypi; awkward 2.3.1 pypi_0 pypi; awkward-cpp 21 pypi_0 pypi; backcall 0.2.0 pyh9f0ad1d_0 conda-forge; backoff 2.2.1 pypi_0 pypi; backports 1.0 pyhd8ed1ab_3 conda-forge; backports.functools_lru_cache 1.6.5 pyhd8ed1ab_0 conda-forge; beautifulsoup4 4.12.2 pypi_0 pypi; blessed 1.20.0 pypi_0 pypi; brotli-python 1.0.9 py311ha362b79_9 conda-forge; bzip2 1.0.8 h7f98852_4 conda-forge; ca-certificates 2023.7.22 hbcca054_0 conda-forge; certifi 2022.12.7 pypi_0 pypi; charset-normalizer 2.1.1 pypi_0 pypi; chex 0.1.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205
https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205:687,Deployability,install,install,687,"Based on [this conversation](https://discourse.scverse.org/t/scgen-generate-irreproducible-output/1622/3) on the scverse discourse site I found out that the behavior shown here does not happen if I install scanpy and pytorch (CUDA) from PyPI. It is however still happening if I install scanpy and pytorch (CUDA) using conda. I still do not know why this is happening but this shows it is not likely a problem with scanpy but some strange interaction. I will leave here the description of the packages installed in both cases for reference, and then close the issue:. 1. The behavior shown in this issue does not happen if I create an environment in conda with python installed, and then install all packages using pip like this:. ```; conda create -n scanpy_test1 python; pip install scanpy leidenalg scvi-tools; pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118; ```. This allows me to have GPU support with scvi-tools and different runs are reproducible. The packages in this environment:. <details><summary>Packages</summary>; <p>. # Name Version Build Channel; _libgcc_mutex 0.1 conda_forge conda-forge; _openmp_mutex 4.5 2_gnu conda-forge; absl-py 1.4.0 pypi_0 pypi; adjusttext 0.8 pypi_0 pypi; aiohttp 3.8.5 pypi_0 pypi; aiosignal 1.3.1 pypi_0 pypi; airr 1.4.1 pypi_0 pypi; anndata 0.9.1 pypi_0 pypi; anyio 3.7.1 pypi_0 pypi; arrow 1.2.3 pypi_0 pypi; asttokens 2.2.1 pyhd8ed1ab_0 conda-forge; async-timeout 4.0.2 pypi_0 pypi; attrs 23.1.0 pypi_0 pypi; awkward 2.3.1 pypi_0 pypi; awkward-cpp 21 pypi_0 pypi; backcall 0.2.0 pyh9f0ad1d_0 conda-forge; backoff 2.2.1 pypi_0 pypi; backports 1.0 pyhd8ed1ab_3 conda-forge; backports.functools_lru_cache 1.6.5 pyhd8ed1ab_0 conda-forge; beautifulsoup4 4.12.2 pypi_0 pypi; blessed 1.20.0 pypi_0 pypi; brotli-python 1.0.9 py311ha362b79_9 conda-forge; bzip2 1.0.8 h7f98852_4 conda-forge; ca-certificates 2023.7.22 hbcca054_0 conda-forge; certifi 2022.12.7 pypi_0 pypi; charset-normalizer 2.1.1 pypi_0 pypi; chex 0.1.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205
https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205:776,Deployability,install,install,776,"Based on [this conversation](https://discourse.scverse.org/t/scgen-generate-irreproducible-output/1622/3) on the scverse discourse site I found out that the behavior shown here does not happen if I install scanpy and pytorch (CUDA) from PyPI. It is however still happening if I install scanpy and pytorch (CUDA) using conda. I still do not know why this is happening but this shows it is not likely a problem with scanpy but some strange interaction. I will leave here the description of the packages installed in both cases for reference, and then close the issue:. 1. The behavior shown in this issue does not happen if I create an environment in conda with python installed, and then install all packages using pip like this:. ```; conda create -n scanpy_test1 python; pip install scanpy leidenalg scvi-tools; pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118; ```. This allows me to have GPU support with scvi-tools and different runs are reproducible. The packages in this environment:. <details><summary>Packages</summary>; <p>. # Name Version Build Channel; _libgcc_mutex 0.1 conda_forge conda-forge; _openmp_mutex 4.5 2_gnu conda-forge; absl-py 1.4.0 pypi_0 pypi; adjusttext 0.8 pypi_0 pypi; aiohttp 3.8.5 pypi_0 pypi; aiosignal 1.3.1 pypi_0 pypi; airr 1.4.1 pypi_0 pypi; anndata 0.9.1 pypi_0 pypi; anyio 3.7.1 pypi_0 pypi; arrow 1.2.3 pypi_0 pypi; asttokens 2.2.1 pyhd8ed1ab_0 conda-forge; async-timeout 4.0.2 pypi_0 pypi; attrs 23.1.0 pypi_0 pypi; awkward 2.3.1 pypi_0 pypi; awkward-cpp 21 pypi_0 pypi; backcall 0.2.0 pyh9f0ad1d_0 conda-forge; backoff 2.2.1 pypi_0 pypi; backports 1.0 pyhd8ed1ab_3 conda-forge; backports.functools_lru_cache 1.6.5 pyhd8ed1ab_0 conda-forge; beautifulsoup4 4.12.2 pypi_0 pypi; blessed 1.20.0 pypi_0 pypi; brotli-python 1.0.9 py311ha362b79_9 conda-forge; bzip2 1.0.8 h7f98852_4 conda-forge; ca-certificates 2023.7.22 hbcca054_0 conda-forge; certifi 2022.12.7 pypi_0 pypi; charset-normalizer 2.1.1 pypi_0 pypi; chex 0.1.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205
https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205:817,Deployability,install,install,817,"Based on [this conversation](https://discourse.scverse.org/t/scgen-generate-irreproducible-output/1622/3) on the scverse discourse site I found out that the behavior shown here does not happen if I install scanpy and pytorch (CUDA) from PyPI. It is however still happening if I install scanpy and pytorch (CUDA) using conda. I still do not know why this is happening but this shows it is not likely a problem with scanpy but some strange interaction. I will leave here the description of the packages installed in both cases for reference, and then close the issue:. 1. The behavior shown in this issue does not happen if I create an environment in conda with python installed, and then install all packages using pip like this:. ```; conda create -n scanpy_test1 python; pip install scanpy leidenalg scvi-tools; pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118; ```. This allows me to have GPU support with scvi-tools and different runs are reproducible. The packages in this environment:. <details><summary>Packages</summary>; <p>. # Name Version Build Channel; _libgcc_mutex 0.1 conda_forge conda-forge; _openmp_mutex 4.5 2_gnu conda-forge; absl-py 1.4.0 pypi_0 pypi; adjusttext 0.8 pypi_0 pypi; aiohttp 3.8.5 pypi_0 pypi; aiosignal 1.3.1 pypi_0 pypi; airr 1.4.1 pypi_0 pypi; anndata 0.9.1 pypi_0 pypi; anyio 3.7.1 pypi_0 pypi; arrow 1.2.3 pypi_0 pypi; asttokens 2.2.1 pyhd8ed1ab_0 conda-forge; async-timeout 4.0.2 pypi_0 pypi; attrs 23.1.0 pypi_0 pypi; awkward 2.3.1 pypi_0 pypi; awkward-cpp 21 pypi_0 pypi; backcall 0.2.0 pyh9f0ad1d_0 conda-forge; backoff 2.2.1 pypi_0 pypi; backports 1.0 pyhd8ed1ab_3 conda-forge; backports.functools_lru_cache 1.6.5 pyhd8ed1ab_0 conda-forge; beautifulsoup4 4.12.2 pypi_0 pypi; blessed 1.20.0 pypi_0 pypi; brotli-python 1.0.9 py311ha362b79_9 conda-forge; bzip2 1.0.8 h7f98852_4 conda-forge; ca-certificates 2023.7.22 hbcca054_0 conda-forge; certifi 2022.12.7 pypi_0 pypi; charset-normalizer 2.1.1 pypi_0 pypi; chex 0.1.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205
https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205:8418,Deployability,install,install,8418,"ypi_0 pypi; torchmetrics 1.0.1 pypi_0 pypi; torchvision 0.15.2+cu118 pypi_0 pypi; tornado 6.3.2 py311h459d7ec_0 conda-forge; tqdm 4.65.0 pyhd8ed1ab_1 conda-forge; traitlets 5.9.0 pyhd8ed1ab_0 conda-forge; triton 2.0.0 pypi_0 pypi; typing-extensions 4.7.1 hd8ed1ab_0 conda-forge; typing_extensions 4.7.1 pyha770c72_0 conda-forge; tzdata 2023.3 pypi_0 pypi; umap-learn 0.5.3 pypi_0 pypi; urllib3 1.26.13 pypi_0 pypi; uvicorn 0.23.1 pypi_0 pypi; wcwidth 0.2.6 pyhd8ed1ab_0 conda-forge; websocket-client 1.6.1 pypi_0 pypi; websockets 11.0.3 pypi_0 pypi; wheel 0.41.0 pyhd8ed1ab_0 conda-forge; widgetsnbextension 4.0.8 pyhd8ed1ab_0 conda-forge; xarray 2023.7.0 pypi_0 pypi; xz 5.2.6 h166bdaf_0 conda-forge; yamlordereddictloader 0.4.0 pypi_0 pypi; yarl 1.9.2 pypi_0 pypi; zeromq 4.3.4 h9c3ff4c_1 conda-forge; zipp 3.16.2 pyhd8ed1ab_0 conda-forge. </p>; </details> . 2. If I create an environment and install scanpy and pytorch (GPU) from conda, then different runs are not reproducible:; ```; conda create -n scanpy_test2; conda install -c conda-forge scanpy leidenalg scvi-tools; conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia; ```; The packages in this environment:. <details><summary>Packages</summary>; <p>. # Name Version Build Channel; _libgcc_mutex 0.1 conda_forge conda-forge; _openmp_mutex 4.5 2_kmp_llvm conda-forge; absl-py 1.4.0 pyhd8ed1ab_0 conda-forge; anndata 0.9.1 pyhd8ed1ab_0 conda-forge; annotated-types 0.5.0 pyhd8ed1ab_0 conda-forge; anyio 3.7.1 pyhd8ed1ab_0 conda-forge; arpack 3.7.0 hdefa2d7_2 conda-forge; arrow 1.2.3 pyhd8ed1ab_0 conda-forge; asttokens 2.2.1 pyhd8ed1ab_0 conda-forge; attrs 23.1.0 pyh71513ae_1 conda-forge; backcall 0.2.0 pyh9f0ad1d_0 conda-forge; backports 1.0 pyhd8ed1ab_3 conda-forge; backports.cached-property 1.0.2 pyhd8ed1ab_0 conda-forge; backports.functools_lru_cache 1.6.5 pyhd8ed1ab_0 conda-forge; beautifulsoup4 4.12.2 pyha770c72_0 conda-forge; blas 1.0 mkl conda-forge; blessed 1.19.1 pyhe4f9e05_2 conda-forge; bro",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205
https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205:8547,Deployability,install,install,8547,"ypi_0 pypi; torchmetrics 1.0.1 pypi_0 pypi; torchvision 0.15.2+cu118 pypi_0 pypi; tornado 6.3.2 py311h459d7ec_0 conda-forge; tqdm 4.65.0 pyhd8ed1ab_1 conda-forge; traitlets 5.9.0 pyhd8ed1ab_0 conda-forge; triton 2.0.0 pypi_0 pypi; typing-extensions 4.7.1 hd8ed1ab_0 conda-forge; typing_extensions 4.7.1 pyha770c72_0 conda-forge; tzdata 2023.3 pypi_0 pypi; umap-learn 0.5.3 pypi_0 pypi; urllib3 1.26.13 pypi_0 pypi; uvicorn 0.23.1 pypi_0 pypi; wcwidth 0.2.6 pyhd8ed1ab_0 conda-forge; websocket-client 1.6.1 pypi_0 pypi; websockets 11.0.3 pypi_0 pypi; wheel 0.41.0 pyhd8ed1ab_0 conda-forge; widgetsnbextension 4.0.8 pyhd8ed1ab_0 conda-forge; xarray 2023.7.0 pypi_0 pypi; xz 5.2.6 h166bdaf_0 conda-forge; yamlordereddictloader 0.4.0 pypi_0 pypi; yarl 1.9.2 pypi_0 pypi; zeromq 4.3.4 h9c3ff4c_1 conda-forge; zipp 3.16.2 pyhd8ed1ab_0 conda-forge. </p>; </details> . 2. If I create an environment and install scanpy and pytorch (GPU) from conda, then different runs are not reproducible:; ```; conda create -n scanpy_test2; conda install -c conda-forge scanpy leidenalg scvi-tools; conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia; ```; The packages in this environment:. <details><summary>Packages</summary>; <p>. # Name Version Build Channel; _libgcc_mutex 0.1 conda_forge conda-forge; _openmp_mutex 4.5 2_kmp_llvm conda-forge; absl-py 1.4.0 pyhd8ed1ab_0 conda-forge; anndata 0.9.1 pyhd8ed1ab_0 conda-forge; annotated-types 0.5.0 pyhd8ed1ab_0 conda-forge; anyio 3.7.1 pyhd8ed1ab_0 conda-forge; arpack 3.7.0 hdefa2d7_2 conda-forge; arrow 1.2.3 pyhd8ed1ab_0 conda-forge; asttokens 2.2.1 pyhd8ed1ab_0 conda-forge; attrs 23.1.0 pyh71513ae_1 conda-forge; backcall 0.2.0 pyh9f0ad1d_0 conda-forge; backports 1.0 pyhd8ed1ab_3 conda-forge; backports.cached-property 1.0.2 pyhd8ed1ab_0 conda-forge; backports.functools_lru_cache 1.6.5 pyhd8ed1ab_0 conda-forge; beautifulsoup4 4.12.2 pyha770c72_0 conda-forge; blas 1.0 mkl conda-forge; blessed 1.19.1 pyhe4f9e05_2 conda-forge; bro",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205
https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205:8605,Deployability,install,install,8605,"ypi_0 pypi; torchmetrics 1.0.1 pypi_0 pypi; torchvision 0.15.2+cu118 pypi_0 pypi; tornado 6.3.2 py311h459d7ec_0 conda-forge; tqdm 4.65.0 pyhd8ed1ab_1 conda-forge; traitlets 5.9.0 pyhd8ed1ab_0 conda-forge; triton 2.0.0 pypi_0 pypi; typing-extensions 4.7.1 hd8ed1ab_0 conda-forge; typing_extensions 4.7.1 pyha770c72_0 conda-forge; tzdata 2023.3 pypi_0 pypi; umap-learn 0.5.3 pypi_0 pypi; urllib3 1.26.13 pypi_0 pypi; uvicorn 0.23.1 pypi_0 pypi; wcwidth 0.2.6 pyhd8ed1ab_0 conda-forge; websocket-client 1.6.1 pypi_0 pypi; websockets 11.0.3 pypi_0 pypi; wheel 0.41.0 pyhd8ed1ab_0 conda-forge; widgetsnbextension 4.0.8 pyhd8ed1ab_0 conda-forge; xarray 2023.7.0 pypi_0 pypi; xz 5.2.6 h166bdaf_0 conda-forge; yamlordereddictloader 0.4.0 pypi_0 pypi; yarl 1.9.2 pypi_0 pypi; zeromq 4.3.4 h9c3ff4c_1 conda-forge; zipp 3.16.2 pyhd8ed1ab_0 conda-forge. </p>; </details> . 2. If I create an environment and install scanpy and pytorch (GPU) from conda, then different runs are not reproducible:; ```; conda create -n scanpy_test2; conda install -c conda-forge scanpy leidenalg scvi-tools; conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia; ```; The packages in this environment:. <details><summary>Packages</summary>; <p>. # Name Version Build Channel; _libgcc_mutex 0.1 conda_forge conda-forge; _openmp_mutex 4.5 2_kmp_llvm conda-forge; absl-py 1.4.0 pyhd8ed1ab_0 conda-forge; anndata 0.9.1 pyhd8ed1ab_0 conda-forge; annotated-types 0.5.0 pyhd8ed1ab_0 conda-forge; anyio 3.7.1 pyhd8ed1ab_0 conda-forge; arpack 3.7.0 hdefa2d7_2 conda-forge; arrow 1.2.3 pyhd8ed1ab_0 conda-forge; asttokens 2.2.1 pyhd8ed1ab_0 conda-forge; attrs 23.1.0 pyh71513ae_1 conda-forge; backcall 0.2.0 pyh9f0ad1d_0 conda-forge; backports 1.0 pyhd8ed1ab_3 conda-forge; backports.cached-property 1.0.2 pyhd8ed1ab_0 conda-forge; backports.functools_lru_cache 1.6.5 pyhd8ed1ab_0 conda-forge; beautifulsoup4 4.12.2 pyha770c72_0 conda-forge; blas 1.0 mkl conda-forge; blessed 1.19.1 pyhe4f9e05_2 conda-forge; bro",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205
https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205:18493,Deployability,install,installer,18493,prompt-toolkit 3.0.39 pyha770c72_0 conda-forge; prompt_toolkit 3.0.39 hd8ed1ab_0 conda-forge; psutil 5.9.5 py310h1fa729e_0 conda-forge; pthread-stubs 0.4 h36c2ea0_1001 conda-forge; ptyprocess 0.7.0 pyhd3deb0d_0 conda-forge; pure_eval 0.2.2 pyhd8ed1ab_0 conda-forge; pycparser 2.21 pyhd8ed1ab_0 conda-forge; pydantic 2.0.3 pyhd8ed1ab_1 conda-forge; pydantic-core 2.3.0 py310hcb5633a_0 conda-forge; pygments 2.15.1 pyhd8ed1ab_0 conda-forge; pyjwt 2.8.0 pyhd8ed1ab_0 conda-forge; pynndescent 0.5.10 pyh1a96a4e_0 conda-forge; pyopenssl 23.2.0 pyhd8ed1ab_1 conda-forge; pyparsing 3.1.0 pyhd8ed1ab_0 conda-forge; pyproject_hooks 1.0.0 pyhd8ed1ab_0 conda-forge; pyro-api 0.1.2 pyhd8ed1ab_0 conda-forge; pyro-ppl 1.8.4 pyhd8ed1ab_0 conda-forge; pysocks 1.7.1 pyha2e5f31_6 conda-forge; python 3.10.12 hd12c33a_0_cpython conda-forge; python-build 0.10.0 pyhd8ed1ab_1 conda-forge; python-dateutil 2.8.2 pyhd8ed1ab_0 conda-forge; python-editor 1.0.4 py_0 conda-forge; python-igraph 0.10.6 py310h33b8572_0 conda-forge; python-installer 0.7.0 pyhd8ed1ab_0 conda-forge; python-multipart 0.0.6 pyhd8ed1ab_0 conda-forge; python-tzdata 2023.3 pyhd8ed1ab_0 conda-forge; python_abi 3.10 3_cp310 conda-forge; pytorch 2.0.1 py3.10_cuda11.8_cudnn8.7.0_0 pytorch; pytorch-cuda 11.8 h7e8668a_5 pytorch; pytorch-lightning 2.0.4 pyhd8ed1ab_0 conda-forge; pytorch-mutex 1.0 cuda pytorch; pytz 2023.3 pyhd8ed1ab_0 conda-forge; pyyaml 6.0 py310h5764c6d_5 conda-forge; pyzmq 25.1.0 py310h5bbb5d0_0 conda-forge; rapidfuzz 2.15.1 py310heca2aa9_0 conda-forge; re2 2023.03.02 h8c504da_0 conda-forge; readchar 4.0.5 pyhd8ed1ab_0 conda-forge; readline 8.2 h8228510_1 conda-forge; referencing 0.30.0 pyhd8ed1ab_0 conda-forge; requests 2.31.0 pyhd8ed1ab_0 conda-forge; requests-toolbelt 1.0.0 pyhd8ed1ab_0 conda-forge; rich 13.4.2 pyhd8ed1ab_0 conda-forge; rpds-py 0.9.2 py310hcb5633a_0 conda-forge; scanpy 1.9.3 pyhd8ed1ab_0 conda-forge; scikit-learn 1.3.0 py310hf7d194e_0 conda-forge; scipy 1.11.1 py310ha4c1d20_0 conda-forge; scvi-tools,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205
https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205:17396,Modifiability,plugin,plugin-export,17396, conda-forge; numpy 1.24.4 py310ha4c1d20_0 conda-forge; numpyro 0.12.1 pyhd8ed1ab_0 conda-forge; openh264 2.1.1 h780b84a_0 conda-forge; openjpeg 2.5.0 hfec8fc6_2 conda-forge; openpyxl 3.1.2 py310h2372a71_0 conda-forge; openssl 3.1.1 hd590300_1 conda-forge; opt_einsum 3.3.0 pyhd8ed1ab_1 conda-forge; optax 0.1.5 pyhd8ed1ab_0 conda-forge; ordered-set 4.1.0 pyhd8ed1ab_0 conda-forge; orjson 3.9.2 py310h1e2579a_0 conda-forge; packaging 23.1 pyhd8ed1ab_0 conda-forge; pandas 2.0.3 py310h7cbd5c2_1 conda-forge; parso 0.8.3 pyhd8ed1ab_0 conda-forge; patsy 0.5.3 pyhd8ed1ab_0 conda-forge; pcre2 10.40 hc3806b6_0 conda-forge; pexpect 4.8.0 pyh1a96a4e_2 conda-forge; pickleshare 0.7.5 py_1003 conda-forge; pillow 9.4.0 py310h023d228_1 conda-forge; pip 23.2 pyhd8ed1ab_0 conda-forge; pkginfo 1.9.6 pyhd8ed1ab_0 conda-forge; pkgutil-resolve-name 1.3.10 pyhd8ed1ab_0 conda-forge; platformdirs 3.9.1 pyhd8ed1ab_0 conda-forge; poetry 1.5.1 linux_pyhd8ed1ab_0 conda-forge; poetry-core 1.6.1 pyhd8ed1ab_0 conda-forge; poetry-plugin-export 1.4.0 pyhd8ed1ab_0 conda-forge; pooch 1.7.0 pyha770c72_3 conda-forge; prompt-toolkit 3.0.39 pyha770c72_0 conda-forge; prompt_toolkit 3.0.39 hd8ed1ab_0 conda-forge; psutil 5.9.5 py310h1fa729e_0 conda-forge; pthread-stubs 0.4 h36c2ea0_1001 conda-forge; ptyprocess 0.7.0 pyhd3deb0d_0 conda-forge; pure_eval 0.2.2 pyhd8ed1ab_0 conda-forge; pycparser 2.21 pyhd8ed1ab_0 conda-forge; pydantic 2.0.3 pyhd8ed1ab_1 conda-forge; pydantic-core 2.3.0 py310hcb5633a_0 conda-forge; pygments 2.15.1 pyhd8ed1ab_0 conda-forge; pyjwt 2.8.0 pyhd8ed1ab_0 conda-forge; pynndescent 0.5.10 pyh1a96a4e_0 conda-forge; pyopenssl 23.2.0 pyhd8ed1ab_1 conda-forge; pyparsing 3.1.0 pyhd8ed1ab_0 conda-forge; pyproject_hooks 1.0.0 pyhd8ed1ab_0 conda-forge; pyro-api 0.1.2 pyhd8ed1ab_0 conda-forge; pyro-ppl 1.8.4 pyhd8ed1ab_0 conda-forge; pysocks 1.7.1 pyha2e5f31_6 conda-forge; python 3.10.12 hd12c33a_0_cpython conda-forge; python-build 0.10.0 pyhd8ed1ab_1 conda-forge; python-dateutil 2.8.2 pyhd8ed1ab_0 co,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205
https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205:9295,Performance,cache,cached-property,9295,"9c3ff4c_1 conda-forge; zipp 3.16.2 pyhd8ed1ab_0 conda-forge. </p>; </details> . 2. If I create an environment and install scanpy and pytorch (GPU) from conda, then different runs are not reproducible:; ```; conda create -n scanpy_test2; conda install -c conda-forge scanpy leidenalg scvi-tools; conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia; ```; The packages in this environment:. <details><summary>Packages</summary>; <p>. # Name Version Build Channel; _libgcc_mutex 0.1 conda_forge conda-forge; _openmp_mutex 4.5 2_kmp_llvm conda-forge; absl-py 1.4.0 pyhd8ed1ab_0 conda-forge; anndata 0.9.1 pyhd8ed1ab_0 conda-forge; annotated-types 0.5.0 pyhd8ed1ab_0 conda-forge; anyio 3.7.1 pyhd8ed1ab_0 conda-forge; arpack 3.7.0 hdefa2d7_2 conda-forge; arrow 1.2.3 pyhd8ed1ab_0 conda-forge; asttokens 2.2.1 pyhd8ed1ab_0 conda-forge; attrs 23.1.0 pyh71513ae_1 conda-forge; backcall 0.2.0 pyh9f0ad1d_0 conda-forge; backports 1.0 pyhd8ed1ab_3 conda-forge; backports.cached-property 1.0.2 pyhd8ed1ab_0 conda-forge; backports.functools_lru_cache 1.6.5 pyhd8ed1ab_0 conda-forge; beautifulsoup4 4.12.2 pyha770c72_0 conda-forge; blas 1.0 mkl conda-forge; blessed 1.19.1 pyhe4f9e05_2 conda-forge; brotli 1.0.9 h166bdaf_9 conda-forge; brotli-bin 1.0.9 h166bdaf_9 conda-forge; brotlipy 0.7.0 py310h5764c6d_1005 conda-forge; bzip2 1.0.8 h7f98852_4 conda-forge; c-ares 1.19.1 hd590300_0 conda-forge; ca-certificates 2023.7.22 hbcca054_0 conda-forge; cachecontrol 0.12.14 pyhd8ed1ab_0 conda-forge; cachecontrol-with-filecache 0.12.14 pyhd8ed1ab_0 conda-forge; cached-property 1.5.2 hd8ed1ab_1 conda-forge; cached_property 1.5.2 pyha770c72_1 conda-forge; certifi 2023.7.22 pyhd8ed1ab_0 conda-forge; cffi 1.15.1 py310h255011f_3 conda-forge; charset-normalizer 3.2.0 pyhd8ed1ab_0 conda-forge; chex 0.1.82 pyhd8ed1ab_0 conda-forge; cleo 2.0.1 pyhd8ed1ab_0 conda-forge; click 8.1.6 unix_pyh707e725_0 conda-forge; colorama 0.4.6 pyhd8ed1ab_0 conda-forge; comm 0.1.3 pyhd8ed1ab_0 conda-forge; ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205
https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205:9769,Performance,cache,cachecontrol,9769,p>. # Name Version Build Channel; _libgcc_mutex 0.1 conda_forge conda-forge; _openmp_mutex 4.5 2_kmp_llvm conda-forge; absl-py 1.4.0 pyhd8ed1ab_0 conda-forge; anndata 0.9.1 pyhd8ed1ab_0 conda-forge; annotated-types 0.5.0 pyhd8ed1ab_0 conda-forge; anyio 3.7.1 pyhd8ed1ab_0 conda-forge; arpack 3.7.0 hdefa2d7_2 conda-forge; arrow 1.2.3 pyhd8ed1ab_0 conda-forge; asttokens 2.2.1 pyhd8ed1ab_0 conda-forge; attrs 23.1.0 pyh71513ae_1 conda-forge; backcall 0.2.0 pyh9f0ad1d_0 conda-forge; backports 1.0 pyhd8ed1ab_3 conda-forge; backports.cached-property 1.0.2 pyhd8ed1ab_0 conda-forge; backports.functools_lru_cache 1.6.5 pyhd8ed1ab_0 conda-forge; beautifulsoup4 4.12.2 pyha770c72_0 conda-forge; blas 1.0 mkl conda-forge; blessed 1.19.1 pyhe4f9e05_2 conda-forge; brotli 1.0.9 h166bdaf_9 conda-forge; brotli-bin 1.0.9 h166bdaf_9 conda-forge; brotlipy 0.7.0 py310h5764c6d_1005 conda-forge; bzip2 1.0.8 h7f98852_4 conda-forge; c-ares 1.19.1 hd590300_0 conda-forge; ca-certificates 2023.7.22 hbcca054_0 conda-forge; cachecontrol 0.12.14 pyhd8ed1ab_0 conda-forge; cachecontrol-with-filecache 0.12.14 pyhd8ed1ab_0 conda-forge; cached-property 1.5.2 hd8ed1ab_1 conda-forge; cached_property 1.5.2 pyha770c72_1 conda-forge; certifi 2023.7.22 pyhd8ed1ab_0 conda-forge; cffi 1.15.1 py310h255011f_3 conda-forge; charset-normalizer 3.2.0 pyhd8ed1ab_0 conda-forge; chex 0.1.82 pyhd8ed1ab_0 conda-forge; cleo 2.0.1 pyhd8ed1ab_0 conda-forge; click 8.1.6 unix_pyh707e725_0 conda-forge; colorama 0.4.6 pyhd8ed1ab_0 conda-forge; comm 0.1.3 pyhd8ed1ab_0 conda-forge; contextlib2 21.6.0 pyhd8ed1ab_0 conda-forge; contourpy 1.1.0 py310hd41b1e2_0 conda-forge; crashtest 0.4.1 pyhd8ed1ab_0 conda-forge; croniter 1.3.15 pyhd8ed1ab_0 conda-forge; cryptography 41.0.2 py310h75e40e8_0 conda-forge; cuda-cudart 11.8.89 0 nvidia; cuda-cupti 11.8.87 0 nvidia; cuda-libraries 11.8.0 0 nvidia; cuda-nvrtc 11.8.89 0 nvidia; cuda-nvtx 11.8.86 0 nvidia; cuda-runtime 11.8.0 0 nvidia; cycler 0.11.0 pyhd8ed1ab_0 conda-forge; dateutils 0.6.12 p,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205
https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205:9816,Performance,cache,cachecontrol-with-filecache,9816,onda_forge conda-forge; _openmp_mutex 4.5 2_kmp_llvm conda-forge; absl-py 1.4.0 pyhd8ed1ab_0 conda-forge; anndata 0.9.1 pyhd8ed1ab_0 conda-forge; annotated-types 0.5.0 pyhd8ed1ab_0 conda-forge; anyio 3.7.1 pyhd8ed1ab_0 conda-forge; arpack 3.7.0 hdefa2d7_2 conda-forge; arrow 1.2.3 pyhd8ed1ab_0 conda-forge; asttokens 2.2.1 pyhd8ed1ab_0 conda-forge; attrs 23.1.0 pyh71513ae_1 conda-forge; backcall 0.2.0 pyh9f0ad1d_0 conda-forge; backports 1.0 pyhd8ed1ab_3 conda-forge; backports.cached-property 1.0.2 pyhd8ed1ab_0 conda-forge; backports.functools_lru_cache 1.6.5 pyhd8ed1ab_0 conda-forge; beautifulsoup4 4.12.2 pyha770c72_0 conda-forge; blas 1.0 mkl conda-forge; blessed 1.19.1 pyhe4f9e05_2 conda-forge; brotli 1.0.9 h166bdaf_9 conda-forge; brotli-bin 1.0.9 h166bdaf_9 conda-forge; brotlipy 0.7.0 py310h5764c6d_1005 conda-forge; bzip2 1.0.8 h7f98852_4 conda-forge; c-ares 1.19.1 hd590300_0 conda-forge; ca-certificates 2023.7.22 hbcca054_0 conda-forge; cachecontrol 0.12.14 pyhd8ed1ab_0 conda-forge; cachecontrol-with-filecache 0.12.14 pyhd8ed1ab_0 conda-forge; cached-property 1.5.2 hd8ed1ab_1 conda-forge; cached_property 1.5.2 pyha770c72_1 conda-forge; certifi 2023.7.22 pyhd8ed1ab_0 conda-forge; cffi 1.15.1 py310h255011f_3 conda-forge; charset-normalizer 3.2.0 pyhd8ed1ab_0 conda-forge; chex 0.1.82 pyhd8ed1ab_0 conda-forge; cleo 2.0.1 pyhd8ed1ab_0 conda-forge; click 8.1.6 unix_pyh707e725_0 conda-forge; colorama 0.4.6 pyhd8ed1ab_0 conda-forge; comm 0.1.3 pyhd8ed1ab_0 conda-forge; contextlib2 21.6.0 pyhd8ed1ab_0 conda-forge; contourpy 1.1.0 py310hd41b1e2_0 conda-forge; crashtest 0.4.1 pyhd8ed1ab_0 conda-forge; croniter 1.3.15 pyhd8ed1ab_0 conda-forge; cryptography 41.0.2 py310h75e40e8_0 conda-forge; cuda-cudart 11.8.89 0 nvidia; cuda-cupti 11.8.87 0 nvidia; cuda-libraries 11.8.0 0 nvidia; cuda-nvrtc 11.8.89 0 nvidia; cuda-nvtx 11.8.86 0 nvidia; cuda-runtime 11.8.0 0 nvidia; cycler 0.11.0 pyhd8ed1ab_0 conda-forge; dateutils 0.6.12 py_0 conda-forge; dbus 1.13.6 h5008d03_3 conda-forge; d,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205
https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205:9878,Performance,cache,cached-property,9878,da-forge; absl-py 1.4.0 pyhd8ed1ab_0 conda-forge; anndata 0.9.1 pyhd8ed1ab_0 conda-forge; annotated-types 0.5.0 pyhd8ed1ab_0 conda-forge; anyio 3.7.1 pyhd8ed1ab_0 conda-forge; arpack 3.7.0 hdefa2d7_2 conda-forge; arrow 1.2.3 pyhd8ed1ab_0 conda-forge; asttokens 2.2.1 pyhd8ed1ab_0 conda-forge; attrs 23.1.0 pyh71513ae_1 conda-forge; backcall 0.2.0 pyh9f0ad1d_0 conda-forge; backports 1.0 pyhd8ed1ab_3 conda-forge; backports.cached-property 1.0.2 pyhd8ed1ab_0 conda-forge; backports.functools_lru_cache 1.6.5 pyhd8ed1ab_0 conda-forge; beautifulsoup4 4.12.2 pyha770c72_0 conda-forge; blas 1.0 mkl conda-forge; blessed 1.19.1 pyhe4f9e05_2 conda-forge; brotli 1.0.9 h166bdaf_9 conda-forge; brotli-bin 1.0.9 h166bdaf_9 conda-forge; brotlipy 0.7.0 py310h5764c6d_1005 conda-forge; bzip2 1.0.8 h7f98852_4 conda-forge; c-ares 1.19.1 hd590300_0 conda-forge; ca-certificates 2023.7.22 hbcca054_0 conda-forge; cachecontrol 0.12.14 pyhd8ed1ab_0 conda-forge; cachecontrol-with-filecache 0.12.14 pyhd8ed1ab_0 conda-forge; cached-property 1.5.2 hd8ed1ab_1 conda-forge; cached_property 1.5.2 pyha770c72_1 conda-forge; certifi 2023.7.22 pyhd8ed1ab_0 conda-forge; cffi 1.15.1 py310h255011f_3 conda-forge; charset-normalizer 3.2.0 pyhd8ed1ab_0 conda-forge; chex 0.1.82 pyhd8ed1ab_0 conda-forge; cleo 2.0.1 pyhd8ed1ab_0 conda-forge; click 8.1.6 unix_pyh707e725_0 conda-forge; colorama 0.4.6 pyhd8ed1ab_0 conda-forge; comm 0.1.3 pyhd8ed1ab_0 conda-forge; contextlib2 21.6.0 pyhd8ed1ab_0 conda-forge; contourpy 1.1.0 py310hd41b1e2_0 conda-forge; crashtest 0.4.1 pyhd8ed1ab_0 conda-forge; croniter 1.3.15 pyhd8ed1ab_0 conda-forge; cryptography 41.0.2 py310h75e40e8_0 conda-forge; cuda-cudart 11.8.89 0 nvidia; cuda-cupti 11.8.87 0 nvidia; cuda-libraries 11.8.0 0 nvidia; cuda-nvrtc 11.8.89 0 nvidia; cuda-nvtx 11.8.86 0 nvidia; cuda-runtime 11.8.0 0 nvidia; cycler 0.11.0 pyhd8ed1ab_0 conda-forge; dateutils 0.6.12 py_0 conda-forge; dbus 1.13.6 h5008d03_3 conda-forge; debugpy 1.6.7 py310heca2aa9_0 conda-forge; decorator 5.1.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205
https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205:1447,Safety,timeout,timeout,1447,"ge interaction. I will leave here the description of the packages installed in both cases for reference, and then close the issue:. 1. The behavior shown in this issue does not happen if I create an environment in conda with python installed, and then install all packages using pip like this:. ```; conda create -n scanpy_test1 python; pip install scanpy leidenalg scvi-tools; pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118; ```. This allows me to have GPU support with scvi-tools and different runs are reproducible. The packages in this environment:. <details><summary>Packages</summary>; <p>. # Name Version Build Channel; _libgcc_mutex 0.1 conda_forge conda-forge; _openmp_mutex 4.5 2_gnu conda-forge; absl-py 1.4.0 pypi_0 pypi; adjusttext 0.8 pypi_0 pypi; aiohttp 3.8.5 pypi_0 pypi; aiosignal 1.3.1 pypi_0 pypi; airr 1.4.1 pypi_0 pypi; anndata 0.9.1 pypi_0 pypi; anyio 3.7.1 pypi_0 pypi; arrow 1.2.3 pypi_0 pypi; asttokens 2.2.1 pyhd8ed1ab_0 conda-forge; async-timeout 4.0.2 pypi_0 pypi; attrs 23.1.0 pypi_0 pypi; awkward 2.3.1 pypi_0 pypi; awkward-cpp 21 pypi_0 pypi; backcall 0.2.0 pyh9f0ad1d_0 conda-forge; backoff 2.2.1 pypi_0 pypi; backports 1.0 pyhd8ed1ab_3 conda-forge; backports.functools_lru_cache 1.6.5 pyhd8ed1ab_0 conda-forge; beautifulsoup4 4.12.2 pypi_0 pypi; blessed 1.20.0 pypi_0 pypi; brotli-python 1.0.9 py311ha362b79_9 conda-forge; bzip2 1.0.8 h7f98852_4 conda-forge; ca-certificates 2023.7.22 hbcca054_0 conda-forge; certifi 2022.12.7 pypi_0 pypi; charset-normalizer 2.1.1 pypi_0 pypi; chex 0.1.7 pypi_0 pypi; click 8.1.6 pypi_0 pypi; cmake 3.25.0 pypi_0 pypi; colorama 0.4.6 pyhd8ed1ab_0 conda-forge; comm 0.1.3 pyhd8ed1ab_0 conda-forge; contextlib2 21.6.0 pypi_0 pypi; contourpy 1.1.0 pypi_0 pypi; croniter 1.4.1 pypi_0 pypi; cycler 0.11.0 pypi_0 pypi; dateutils 0.6.12 pypi_0 pypi; debugpy 1.6.7 py311hcafe171_0 conda-forge; decorator 5.1.1 pyhd8ed1ab_0 conda-forge; deepdiff 6.3.1 pypi_0 pypi; dm-tree 0.1.8 pypi_0 pypi; docr",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205
https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205:1876,Security,certificate,certificates,1876,s://download.pytorch.org/whl/cu118; ```. This allows me to have GPU support with scvi-tools and different runs are reproducible. The packages in this environment:. <details><summary>Packages</summary>; <p>. # Name Version Build Channel; _libgcc_mutex 0.1 conda_forge conda-forge; _openmp_mutex 4.5 2_gnu conda-forge; absl-py 1.4.0 pypi_0 pypi; adjusttext 0.8 pypi_0 pypi; aiohttp 3.8.5 pypi_0 pypi; aiosignal 1.3.1 pypi_0 pypi; airr 1.4.1 pypi_0 pypi; anndata 0.9.1 pypi_0 pypi; anyio 3.7.1 pypi_0 pypi; arrow 1.2.3 pypi_0 pypi; asttokens 2.2.1 pyhd8ed1ab_0 conda-forge; async-timeout 4.0.2 pypi_0 pypi; attrs 23.1.0 pypi_0 pypi; awkward 2.3.1 pypi_0 pypi; awkward-cpp 21 pypi_0 pypi; backcall 0.2.0 pyh9f0ad1d_0 conda-forge; backoff 2.2.1 pypi_0 pypi; backports 1.0 pyhd8ed1ab_3 conda-forge; backports.functools_lru_cache 1.6.5 pyhd8ed1ab_0 conda-forge; beautifulsoup4 4.12.2 pypi_0 pypi; blessed 1.20.0 pypi_0 pypi; brotli-python 1.0.9 py311ha362b79_9 conda-forge; bzip2 1.0.8 h7f98852_4 conda-forge; ca-certificates 2023.7.22 hbcca054_0 conda-forge; certifi 2022.12.7 pypi_0 pypi; charset-normalizer 2.1.1 pypi_0 pypi; chex 0.1.7 pypi_0 pypi; click 8.1.6 pypi_0 pypi; cmake 3.25.0 pypi_0 pypi; colorama 0.4.6 pyhd8ed1ab_0 conda-forge; comm 0.1.3 pyhd8ed1ab_0 conda-forge; contextlib2 21.6.0 pypi_0 pypi; contourpy 1.1.0 pypi_0 pypi; croniter 1.4.1 pypi_0 pypi; cycler 0.11.0 pypi_0 pypi; dateutils 0.6.12 pypi_0 pypi; debugpy 1.6.7 py311hcafe171_0 conda-forge; decorator 5.1.1 pyhd8ed1ab_0 conda-forge; deepdiff 6.3.1 pypi_0 pypi; dm-tree 0.1.8 pypi_0 pypi; docrep 0.3.2 pypi_0 pypi; etils 1.3.0 pypi_0 pypi; executing 1.2.0 pyhd8ed1ab_0 conda-forge; fa2 0.3.5 py311hd4cff14_2 conda-forge; fastapi 0.100.0 pypi_0 pypi; filelock 3.9.0 pypi_0 pypi; flax 0.7.0 pypi_0 pypi; fonttools 4.41.1 pypi_0 pypi; frozenlist 1.4.0 pypi_0 pypi; fsspec 2023.6.0 pypi_0 pypi; h11 0.14.0 pypi_0 pypi; h5py 3.9.0 pypi_0 pypi; idna 3.4 pyhd8ed1ab_0 conda-forge; igraph 0.10.6 pypi_0 pypi; importlib-metadata 6.8.0 pyh,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205
https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205:9722,Security,certificate,certificates,9722,nment:. <details><summary>Packages</summary>; <p>. # Name Version Build Channel; _libgcc_mutex 0.1 conda_forge conda-forge; _openmp_mutex 4.5 2_kmp_llvm conda-forge; absl-py 1.4.0 pyhd8ed1ab_0 conda-forge; anndata 0.9.1 pyhd8ed1ab_0 conda-forge; annotated-types 0.5.0 pyhd8ed1ab_0 conda-forge; anyio 3.7.1 pyhd8ed1ab_0 conda-forge; arpack 3.7.0 hdefa2d7_2 conda-forge; arrow 1.2.3 pyhd8ed1ab_0 conda-forge; asttokens 2.2.1 pyhd8ed1ab_0 conda-forge; attrs 23.1.0 pyh71513ae_1 conda-forge; backcall 0.2.0 pyh9f0ad1d_0 conda-forge; backports 1.0 pyhd8ed1ab_3 conda-forge; backports.cached-property 1.0.2 pyhd8ed1ab_0 conda-forge; backports.functools_lru_cache 1.6.5 pyhd8ed1ab_0 conda-forge; beautifulsoup4 4.12.2 pyha770c72_0 conda-forge; blas 1.0 mkl conda-forge; blessed 1.19.1 pyhe4f9e05_2 conda-forge; brotli 1.0.9 h166bdaf_9 conda-forge; brotli-bin 1.0.9 h166bdaf_9 conda-forge; brotlipy 0.7.0 py310h5764c6d_1005 conda-forge; bzip2 1.0.8 h7f98852_4 conda-forge; c-ares 1.19.1 hd590300_0 conda-forge; ca-certificates 2023.7.22 hbcca054_0 conda-forge; cachecontrol 0.12.14 pyhd8ed1ab_0 conda-forge; cachecontrol-with-filecache 0.12.14 pyhd8ed1ab_0 conda-forge; cached-property 1.5.2 hd8ed1ab_1 conda-forge; cached_property 1.5.2 pyha770c72_1 conda-forge; certifi 2023.7.22 pyhd8ed1ab_0 conda-forge; cffi 1.15.1 py310h255011f_3 conda-forge; charset-normalizer 3.2.0 pyhd8ed1ab_0 conda-forge; chex 0.1.82 pyhd8ed1ab_0 conda-forge; cleo 2.0.1 pyhd8ed1ab_0 conda-forge; click 8.1.6 unix_pyh707e725_0 conda-forge; colorama 0.4.6 pyhd8ed1ab_0 conda-forge; comm 0.1.3 pyhd8ed1ab_0 conda-forge; contextlib2 21.6.0 pyhd8ed1ab_0 conda-forge; contourpy 1.1.0 py310hd41b1e2_0 conda-forge; crashtest 0.4.1 pyhd8ed1ab_0 conda-forge; croniter 1.3.15 pyhd8ed1ab_0 conda-forge; cryptography 41.0.2 py310h75e40e8_0 conda-forge; cuda-cudart 11.8.89 0 nvidia; cuda-cupti 11.8.87 0 nvidia; cuda-libraries 11.8.0 0 nvidia; cuda-nvrtc 11.8.89 0 nvidia; cuda-nvtx 11.8.86 0 nvidia; cuda-runtime 11.8.0 0 nvidia; cycler 0.11.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205
https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205:17624,Testability,stub,stubs,17624,nssl 3.1.1 hd590300_1 conda-forge; opt_einsum 3.3.0 pyhd8ed1ab_1 conda-forge; optax 0.1.5 pyhd8ed1ab_0 conda-forge; ordered-set 4.1.0 pyhd8ed1ab_0 conda-forge; orjson 3.9.2 py310h1e2579a_0 conda-forge; packaging 23.1 pyhd8ed1ab_0 conda-forge; pandas 2.0.3 py310h7cbd5c2_1 conda-forge; parso 0.8.3 pyhd8ed1ab_0 conda-forge; patsy 0.5.3 pyhd8ed1ab_0 conda-forge; pcre2 10.40 hc3806b6_0 conda-forge; pexpect 4.8.0 pyh1a96a4e_2 conda-forge; pickleshare 0.7.5 py_1003 conda-forge; pillow 9.4.0 py310h023d228_1 conda-forge; pip 23.2 pyhd8ed1ab_0 conda-forge; pkginfo 1.9.6 pyhd8ed1ab_0 conda-forge; pkgutil-resolve-name 1.3.10 pyhd8ed1ab_0 conda-forge; platformdirs 3.9.1 pyhd8ed1ab_0 conda-forge; poetry 1.5.1 linux_pyhd8ed1ab_0 conda-forge; poetry-core 1.6.1 pyhd8ed1ab_0 conda-forge; poetry-plugin-export 1.4.0 pyhd8ed1ab_0 conda-forge; pooch 1.7.0 pyha770c72_3 conda-forge; prompt-toolkit 3.0.39 pyha770c72_0 conda-forge; prompt_toolkit 3.0.39 hd8ed1ab_0 conda-forge; psutil 5.9.5 py310h1fa729e_0 conda-forge; pthread-stubs 0.4 h36c2ea0_1001 conda-forge; ptyprocess 0.7.0 pyhd3deb0d_0 conda-forge; pure_eval 0.2.2 pyhd8ed1ab_0 conda-forge; pycparser 2.21 pyhd8ed1ab_0 conda-forge; pydantic 2.0.3 pyhd8ed1ab_1 conda-forge; pydantic-core 2.3.0 py310hcb5633a_0 conda-forge; pygments 2.15.1 pyhd8ed1ab_0 conda-forge; pyjwt 2.8.0 pyhd8ed1ab_0 conda-forge; pynndescent 0.5.10 pyh1a96a4e_0 conda-forge; pyopenssl 23.2.0 pyhd8ed1ab_1 conda-forge; pyparsing 3.1.0 pyhd8ed1ab_0 conda-forge; pyproject_hooks 1.0.0 pyhd8ed1ab_0 conda-forge; pyro-api 0.1.2 pyhd8ed1ab_0 conda-forge; pyro-ppl 1.8.4 pyhd8ed1ab_0 conda-forge; pysocks 1.7.1 pyha2e5f31_6 conda-forge; python 3.10.12 hd12c33a_0_cpython conda-forge; python-build 0.10.0 pyhd8ed1ab_1 conda-forge; python-dateutil 2.8.2 pyhd8ed1ab_0 conda-forge; python-editor 1.0.4 py_0 conda-forge; python-igraph 0.10.6 py310h33b8572_0 conda-forge; python-installer 0.7.0 pyhd8ed1ab_0 conda-forge; python-multipart 0.0.6 pyhd8ed1ab_0 conda-forge; python-tzdata 2023.3 pyhd,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205
https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205:6680,Usability,learn,learn,6680,conda-forge; protobuf 4.23.4 pypi_0 pypi; psutil 5.9.5 py311h2582759_0 conda-forge; ptyprocess 0.7.0 pyhd3deb0d_0 conda-forge; pure_eval 0.2.2 pyhd8ed1ab_0 conda-forge; pydantic 1.10.11 pypi_0 pypi; pygments 2.15.1 pyhd8ed1ab_0 conda-forge; pyjwt 2.8.0 pypi_0 pypi; pynndescent 0.5.10 pypi_0 pypi; pyparsing 3.0.9 pypi_0 pypi; pyro-api 0.1.2 pypi_0 pypi; pyro-ppl 1.8.5 pypi_0 pypi; pysocks 1.7.1 pyha2e5f31_6 conda-forge; python 3.11.4 hab00c5b_0_cpython conda-forge; python-dateutil 2.8.2 pyhd8ed1ab_0 conda-forge; python-editor 1.0.4 pypi_0 pypi; python-igraph 0.10.6 pypi_0 pypi; python-levenshtein 0.21.1 pypi_0 pypi; python-multipart 0.0.6 pypi_0 pypi; python_abi 3.11 3_cp311 conda-forge; pytorch-lightning 2.0.5 pypi_0 pypi; pytz 2023.3 pypi_0 pypi; pyyaml 6.0.1 pypi_0 pypi; pyzmq 25.1.0 py311h75c88c4_0 conda-forge; rapidfuzz 3.1.2 pypi_0 pypi; readchar 4.0.5 pypi_0 pypi; readline 8.2 h8228510_1 conda-forge; requests 2.28.1 pypi_0 pypi; rich 13.4.2 pypi_0 pypi; scanpy 1.9.3 pypi_0 pypi; scikit-learn 1.3.0 pypi_0 pypi; scipy 1.11.1 py311h64a7726_0 conda-forge; scirpy 0.13.0 pypi_0 pypi; scmisc 0.0.1 pypi_0 pypi; scvi-tools 1.0.2 pypi_0 pypi; seaborn 0.12.2 pypi_0 pypi; session-info 1.0.0 pypi_0 pypi; setuptools 68.0.0 pyhd8ed1ab_0 conda-forge; singlecellhaystack 0.0.5 pypi_0 pypi; six 1.16.0 pyh6c4a22f_0 conda-forge; sniffio 1.3.0 pypi_0 pypi; soupsieve 2.4.1 pypi_0 pypi; sparse 0.14.0 pypi_0 pypi; squarify 0.4.3 pypi_0 pypi; stack_data 0.6.2 pyhd8ed1ab_0 conda-forge; starlette 0.27.0 pypi_0 pypi; starsessions 1.3.0 pypi_0 pypi; statsmodels 0.14.0 pypi_0 pypi; stdlib-list 0.9.0 pypi_0 pypi; sympy 1.11.1 pypi_0 pypi; tensorstore 0.1.40 pypi_0 pypi; texttable 1.6.7 pypi_0 pypi; threadpoolctl 3.2.0 pypi_0 pypi; tk 8.6.12 h27826a3_0 conda-forge; toolz 0.12.0 pypi_0 pypi; torch 2.0.1+cu118 pypi_0 pypi; torchaudio 2.0.2+cu118 pypi_0 pypi; torchmetrics 1.0.1 pypi_0 pypi; torchvision 0.15.2+cu118 pypi_0 pypi; tornado 6.3.2 py311h459d7ec_0 conda-forge; tqdm 4.65.0 pyhd8ed1ab_1 ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205
https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205:7884,Usability,learn,learn,7884,"ypi_0 pypi; setuptools 68.0.0 pyhd8ed1ab_0 conda-forge; singlecellhaystack 0.0.5 pypi_0 pypi; six 1.16.0 pyh6c4a22f_0 conda-forge; sniffio 1.3.0 pypi_0 pypi; soupsieve 2.4.1 pypi_0 pypi; sparse 0.14.0 pypi_0 pypi; squarify 0.4.3 pypi_0 pypi; stack_data 0.6.2 pyhd8ed1ab_0 conda-forge; starlette 0.27.0 pypi_0 pypi; starsessions 1.3.0 pypi_0 pypi; statsmodels 0.14.0 pypi_0 pypi; stdlib-list 0.9.0 pypi_0 pypi; sympy 1.11.1 pypi_0 pypi; tensorstore 0.1.40 pypi_0 pypi; texttable 1.6.7 pypi_0 pypi; threadpoolctl 3.2.0 pypi_0 pypi; tk 8.6.12 h27826a3_0 conda-forge; toolz 0.12.0 pypi_0 pypi; torch 2.0.1+cu118 pypi_0 pypi; torchaudio 2.0.2+cu118 pypi_0 pypi; torchmetrics 1.0.1 pypi_0 pypi; torchvision 0.15.2+cu118 pypi_0 pypi; tornado 6.3.2 py311h459d7ec_0 conda-forge; tqdm 4.65.0 pyhd8ed1ab_1 conda-forge; traitlets 5.9.0 pyhd8ed1ab_0 conda-forge; triton 2.0.0 pypi_0 pypi; typing-extensions 4.7.1 hd8ed1ab_0 conda-forge; typing_extensions 4.7.1 pyha770c72_0 conda-forge; tzdata 2023.3 pypi_0 pypi; umap-learn 0.5.3 pypi_0 pypi; urllib3 1.26.13 pypi_0 pypi; uvicorn 0.23.1 pypi_0 pypi; wcwidth 0.2.6 pyhd8ed1ab_0 conda-forge; websocket-client 1.6.1 pypi_0 pypi; websockets 11.0.3 pypi_0 pypi; wheel 0.41.0 pyhd8ed1ab_0 conda-forge; widgetsnbextension 4.0.8 pyhd8ed1ab_0 conda-forge; xarray 2023.7.0 pypi_0 pypi; xz 5.2.6 h166bdaf_0 conda-forge; yamlordereddictloader 0.4.0 pypi_0 pypi; yarl 1.9.2 pypi_0 pypi; zeromq 4.3.4 h9c3ff4c_1 conda-forge; zipp 3.16.2 pyhd8ed1ab_0 conda-forge. </p>; </details> . 2. If I create an environment and install scanpy and pytorch (GPU) from conda, then different runs are not reproducible:; ```; conda create -n scanpy_test2; conda install -c conda-forge scanpy leidenalg scvi-tools; conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia; ```; The packages in this environment:. <details><summary>Packages</summary>; <p>. # Name Version Build Channel; _libgcc_mutex 0.1 conda_forge conda-forge; _openmp_mutex 4.5 2_kmp_llvm conda-for",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205
https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205:19387,Usability,learn,learn,19387,yhd8ed1ab_0 conda-forge; python-editor 1.0.4 py_0 conda-forge; python-igraph 0.10.6 py310h33b8572_0 conda-forge; python-installer 0.7.0 pyhd8ed1ab_0 conda-forge; python-multipart 0.0.6 pyhd8ed1ab_0 conda-forge; python-tzdata 2023.3 pyhd8ed1ab_0 conda-forge; python_abi 3.10 3_cp310 conda-forge; pytorch 2.0.1 py3.10_cuda11.8_cudnn8.7.0_0 pytorch; pytorch-cuda 11.8 h7e8668a_5 pytorch; pytorch-lightning 2.0.4 pyhd8ed1ab_0 conda-forge; pytorch-mutex 1.0 cuda pytorch; pytz 2023.3 pyhd8ed1ab_0 conda-forge; pyyaml 6.0 py310h5764c6d_5 conda-forge; pyzmq 25.1.0 py310h5bbb5d0_0 conda-forge; rapidfuzz 2.15.1 py310heca2aa9_0 conda-forge; re2 2023.03.02 h8c504da_0 conda-forge; readchar 4.0.5 pyhd8ed1ab_0 conda-forge; readline 8.2 h8228510_1 conda-forge; referencing 0.30.0 pyhd8ed1ab_0 conda-forge; requests 2.31.0 pyhd8ed1ab_0 conda-forge; requests-toolbelt 1.0.0 pyhd8ed1ab_0 conda-forge; rich 13.4.2 pyhd8ed1ab_0 conda-forge; rpds-py 0.9.2 py310hcb5633a_0 conda-forge; scanpy 1.9.3 pyhd8ed1ab_0 conda-forge; scikit-learn 1.3.0 py310hf7d194e_0 conda-forge; scipy 1.11.1 py310ha4c1d20_0 conda-forge; scvi-tools 1.0.2 pyhd8ed1ab_0 conda-forge; seaborn 0.12.2 hd8ed1ab_0 conda-forge; seaborn-base 0.12.2 pyhd8ed1ab_0 conda-forge; secretstorage 3.3.3 py310hff52083_1 conda-forge; session-info 1.0.0 pyhd8ed1ab_0 conda-forge; setuptools 68.0.0 pyhd8ed1ab_0 conda-forge; shellingham 1.5.1 pyhd8ed1ab_0 conda-forge; six 1.16.0 pyh6c4a22f_0 conda-forge; sleef 3.5.1 h9b69904_2 conda-forge; sniffio 1.3.0 pyhd8ed1ab_0 conda-forge; soupsieve 2.3.2.post1 pyhd8ed1ab_0 conda-forge; sparse 0.14.0 pyhd8ed1ab_0 conda-forge; stack_data 0.6.2 pyhd8ed1ab_0 conda-forge; starlette 0.27.0 pyhd8ed1ab_0 conda-forge; starsessions 1.3.0 pyhd8ed1ab_0 conda-forge; statsmodels 0.14.0 py310h278f3c1_1 conda-forge; stdlib-list 0.8.0 pyhd8ed1ab_0 conda-forge; suitesparse 5.10.1 h9e50725_1 conda-forge; sympy 1.12 pypyh9d50eac_103 conda-forge; tbb 2021.9.0 hf52228f_0 conda-forge; texttable 1.6.7 pyhd8ed1ab_0 conda-forge; threadp,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205
https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205:21080,Usability,learn,learn,21080,ed1ab_0 conda-forge; stack_data 0.6.2 pyhd8ed1ab_0 conda-forge; starlette 0.27.0 pyhd8ed1ab_0 conda-forge; starsessions 1.3.0 pyhd8ed1ab_0 conda-forge; statsmodels 0.14.0 py310h278f3c1_1 conda-forge; stdlib-list 0.8.0 pyhd8ed1ab_0 conda-forge; suitesparse 5.10.1 h9e50725_1 conda-forge; sympy 1.12 pypyh9d50eac_103 conda-forge; tbb 2021.9.0 hf52228f_0 conda-forge; texttable 1.6.7 pyhd8ed1ab_0 conda-forge; threadpoolctl 3.2.0 pyha21a80b_0 conda-forge; tk 8.6.12 h27826a3_0 conda-forge; tomli 2.0.1 pyhd8ed1ab_0 conda-forge; tomlkit 0.11.8 pyha770c72_0 conda-forge; toolz 0.12.0 pyhd8ed1ab_0 conda-forge; torchaudio 2.0.2 py310_cu118 pytorch; torchmetrics 0.11.4 pyhd8ed1ab_0 conda-forge; torchtriton 2.0.0 py310 pytorch; torchvision 0.15.2 py310_cu118 pytorch; tornado 6.3.2 py310h2372a71_0 conda-forge; tqdm 4.65.0 pyhd8ed1ab_1 conda-forge; traitlets 5.9.0 pyhd8ed1ab_0 conda-forge; trove-classifiers 2023.7.6 pyhd8ed1ab_0 conda-forge; typing 3.10.0.0 pyhd8ed1ab_0 conda-forge; typing-extensions 4.7.1 hd8ed1ab_0 conda-forge; typing_extensions 4.7.1 pyha770c72_0 conda-forge; tzdata 2023c h71feb2d_0 conda-forge; umap-learn 0.5.3 py310hff52083_1 conda-forge; unicodedata2 15.0.0 py310h5764c6d_0 conda-forge; urllib3 1.26.15 pyhd8ed1ab_0 conda-forge; uvicorn 0.23.1 py310hff52083_0 conda-forge; virtualenv 20.24.1 pyhd8ed1ab_0 conda-forge; wcwidth 0.2.6 pyhd8ed1ab_0 conda-forge; webencodings 0.5.1 py_1 conda-forge; websocket-client 1.6.1 pyhd8ed1ab_0 conda-forge; websockets 11.0.3 py310h2372a71_0 conda-forge; wheel 0.40.0 pyhd8ed1ab_1 conda-forge; widgetsnbextension 4.0.8 pyhd8ed1ab_0 conda-forge; xarray 2023.7.0 pyhd8ed1ab_0 conda-forge; xlrd 1.2.0 pyh9f0ad1d_1 conda-forge; xorg-libxau 1.0.11 hd590300_0 conda-forge; xorg-libxdmcp 1.1.3 h7f98852_0 conda-forge; xz 5.2.6 h166bdaf_0 conda-forge; yaml 0.2.5 h7f98852_2 conda-forge; zeromq 4.3.4 h9c3ff4c_1 conda-forge; zipp 3.16.2 pyhd8ed1ab_0 conda-forge; zlib 1.2.13 hd590300_5 conda-forge; zstd 1.5.2 hfc55251_7 conda-forge. </p>; </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205
https://github.com/scverse/scanpy/pull/2482#issuecomment-1535967746:234,Testability,test,tests,234,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2482?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Comparison is base [(`48b495d`)](https://app.codecov.io/gh/scverse/scanpy/commit/48b495d983a2873083b823e9be5e98f6082ac88c?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 74.81% compared to head [(`f8368c6`)](https://app.codecov.io/gh/scverse/scanpy/pull/2482?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 74.81%. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2482 +/- ##; =======================================; Coverage 74.81% 74.81% ; =======================================; Files 116 116 ; Lines 12822 12822 ; =======================================; Hits 9593 9593 ; Misses 3229 3229 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2482#issuecomment-1535967746
https://github.com/scverse/scanpy/issues/2485#issuecomment-1538590107:601,Availability,down,download-,601,"Hi, @GeoffSCollins ! To do that, you need to add new columns to `adata.obs` table. A column should contain one value (e.g. `True`) for the group of interest and another value (e.g. `False`) for all the other groups. This is how you can create such columns for each of the values of column `leiden`:. ```python; import pandas as pd. adata.obs = pd.concat([; adata.obs,; pd.get_dummies(adata.obs[""leiden""], prefix=""is_cell_type"").astype(bool).astype(""category""),; ], axis=1); ```. Then you can build a violin plot:. ```python; sc.pl.violin(adata, keys=""total_counts"", groupby=""is_cell_type_NK""); ```; ![download-8](https://user-images.githubusercontent.com/35199218/236865939-768d759a-a581-4ba9-acb9-0104cbf16efd.png). I hope this is useful! Also, a small note: ""UMAP cluster"" is not a correct term. Clusters are obtained completely independently of UMAP by running leiden clustering algorithm. UMAP is just a nice visualisation (which is, however, built ignorant of cluster information).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2485#issuecomment-1538590107
https://github.com/scverse/scanpy/issues/2485#issuecomment-1542320460:319,Availability,down,down,319,"Hi @VladimirShitov . Thank you for the help (and the information about leiden vs UMAP). I think the code provided shows something slightly different. You are plotting False vs True here, but we would want something like False vs all. So, the True violin plot would be a little different. Regardless, I am just going to down this route :D",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2485#issuecomment-1542320460
https://github.com/scverse/scanpy/issues/2485#issuecomment-1542320460:329,Integrability,rout,route,329,"Hi @VladimirShitov . Thank you for the help (and the information about leiden vs UMAP). I think the code provided shows something slightly different. You are plotting False vs True here, but we would want something like False vs all. So, the True violin plot would be a little different. Regardless, I am just going to down this route :D",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2485#issuecomment-1542320460
https://github.com/scverse/scanpy/issues/2488#issuecomment-1650697912:264,Availability,down,download,264,"This is updated in the newest version of the module, where it looks for either `tissue_positions.csv` or `tissue_positions_list.csv`. The code on the github project works, but unfortunately the most recent version on PyPi was from Mar 2, 2023. . An easy fix is to download the github project directly, using something like ; `pip install git+https://github.com/scverse/scanpy.git#egg=scanpy`. I did it recently in a Google Colaboratory Notebook with a file with `tissue_positions.csv`, and it worked.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2488#issuecomment-1650697912
https://github.com/scverse/scanpy/issues/2488#issuecomment-1650697912:8,Deployability,update,updated,8,"This is updated in the newest version of the module, where it looks for either `tissue_positions.csv` or `tissue_positions_list.csv`. The code on the github project works, but unfortunately the most recent version on PyPi was from Mar 2, 2023. . An easy fix is to download the github project directly, using something like ; `pip install git+https://github.com/scverse/scanpy.git#egg=scanpy`. I did it recently in a Google Colaboratory Notebook with a file with `tissue_positions.csv`, and it worked.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2488#issuecomment-1650697912
https://github.com/scverse/scanpy/issues/2488#issuecomment-1650697912:330,Deployability,install,install,330,"This is updated in the newest version of the module, where it looks for either `tissue_positions.csv` or `tissue_positions_list.csv`. The code on the github project works, but unfortunately the most recent version on PyPi was from Mar 2, 2023. . An easy fix is to download the github project directly, using something like ; `pip install git+https://github.com/scverse/scanpy.git#egg=scanpy`. I did it recently in a Google Colaboratory Notebook with a file with `tissue_positions.csv`, and it worked.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2488#issuecomment-1650697912
https://github.com/scverse/scanpy/issues/2488#issuecomment-1652910834:388,Deployability,release,release,388,"> in the outs/spatial file, change the tissue_positions.csv to tissue_positions_list.csv, it should work out. Doing this will cause issues when you try to spatially plot the data because the coordinates dtype is a string instead of int. You have to also do this suggestion after: https://github.com/scverse/squidpy/issues/623#issuecomment-1339403351. It would be great if the next scanpy release included the read_visium() update or revisit the idea to [remove it in scanpy in favor of squidpy](https://github.com/scverse/scanpy/issues/2331).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2488#issuecomment-1652910834
https://github.com/scverse/scanpy/issues/2488#issuecomment-1652910834:423,Deployability,update,update,423,"> in the outs/spatial file, change the tissue_positions.csv to tissue_positions_list.csv, it should work out. Doing this will cause issues when you try to spatially plot the data because the coordinates dtype is a string instead of int. You have to also do this suggestion after: https://github.com/scverse/squidpy/issues/623#issuecomment-1339403351. It would be great if the next scanpy release included the read_visium() update or revisit the idea to [remove it in scanpy in favor of squidpy](https://github.com/scverse/scanpy/issues/2331).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2488#issuecomment-1652910834
https://github.com/scverse/scanpy/issues/2488#issuecomment-1653487974:49,Deployability,release,release,49,"duplicate of #2345, #2565, and so on. we’ll do a release soon",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2488#issuecomment-1653487974
https://github.com/scverse/scanpy/issues/2494#issuecomment-1564798184:0,Availability,Error,Error,0,Error here; ![image](https://github.com/scverse/scanpy/assets/117483585/c23b446d-f5f9-4775-95ce-eda0a49aba81). ![image](https://github.com/scverse/scanpy/assets/117483585/09ee6450-66b0-43e2-8079-fcb3e06735d4),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2494#issuecomment-1564798184
https://github.com/scverse/scanpy/issues/2495#issuecomment-1683604054:280,Availability,error,error,280,"Hi,. thanks for the input and the nice description. Agree that this would be nice to have within scanpy itself. And agree, as you’ve shown in your example, that this should be the case when setting `copy=True`. I have set up a draft PR for the moment, with a suggestion where the error message especially persists when `copy=False`; I’d suggest to keep it this way:. - Overwriting the backed file seems not to be the expected behaviour to me; - Writing a new file for backing would occur in a rather hidden manner, confusing the user or even unexpectedly further fill the disk at worst over time",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2495#issuecomment-1683604054
https://github.com/scverse/scanpy/issues/2495#issuecomment-1683604054:286,Integrability,message,message,286,"Hi,. thanks for the input and the nice description. Agree that this would be nice to have within scanpy itself. And agree, as you’ve shown in your example, that this should be the case when setting `copy=True`. I have set up a draft PR for the moment, with a suggestion where the error message especially persists when `copy=False`; I’d suggest to keep it this way:. - Overwriting the backed file seems not to be the expected behaviour to me; - Writing a new file for backing would occur in a rather hidden manner, confusing the user or even unexpectedly further fill the disk at worst over time",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2495#issuecomment-1683604054
https://github.com/scverse/scanpy/issues/2496#issuecomment-1778940190:48,Modifiability,layers,layers,48,"I've run into the same issue. In my case `adata.layers[""analytic_pearson_residuals""].sum(1)` gives an array of nans because there are nans in `analytic_pearson[""X""]`, as indicated by RuntimeWarning. . I am still only investigating this, but if treating nans as 0 is OK there is numpy.nansum function that could be used instead of sum.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2496#issuecomment-1778940190
https://github.com/scverse/scanpy/issues/2498#issuecomment-1576510979:0,Integrability,Depend,Depends,0,Depends on how you calculate your neighbors graph: https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.neighbors.html#scanpy.pp.neighbors,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2498#issuecomment-1576510979
https://github.com/scverse/scanpy/issues/2499#issuecomment-1588980574:141,Availability,error,error,141,"Hmm, that sounds like the code is trying to do something like `['a', 'b'] * 1.5`, i.e. repeating a sequence by multiplying. But the line the error points to looks correct: `np.multiply` should try to do element-wise multiplication as intended. Please create a minimal reproducible example. We don’t know what in `slide` causes the bug because we don’t know what it is.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2499#issuecomment-1588980574
https://github.com/scverse/scanpy/issues/2499#issuecomment-1607076461:967,Deployability,pipeline,pipeline,967,"I see! File looks like this:. ```csv; barcode,in_tissue,array_row,array_col,pxl_row_in_fullres,pxl_col_in_fullres; GTCACTTCCTTCTAGA-1,0,0,0,-1567,2629; CACGGTCTCCTTACGA-1,0,0,2,-1569,2811; ATAGCTGCGGATAAGA-1,0,0,4,-1571,2993; GTCAGTATGTCCGGCG-1,0,0,6,-1573,3174; ...; ```. @RaphaelBuzzi you mean `read_visium`, right? There is no `read_spatial` in scanpy. That one seems to assume that; - if the file is called `tissue_positions.csv`, it has a header on the second row (index 1), and; - if it is called `tissue_positions_list.csv`, it has no header line:. https://github.com/scverse/scanpy/blob/692c9e536ab1d3b0a7d16e9c2c6e7d53390f9b5a/scanpy/readwrite.py#L461-L465. The only thing that looks weird about that is the index 1 instead of 0, otherwise it looks identical to the PR by 10x: https://github.com/satijalab/seurat/pull/6208/files. So the question is: why is there a file called `tissue_positions_list.csv` that has a header? That doesn’t seem like what 10x’s pipeline does.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2499#issuecomment-1607076461
https://github.com/scverse/scanpy/issues/2499#issuecomment-1607223772:42,Deployability,release,release,42,It’s actually still unreleased. We should release 1.9.3 soon!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2499#issuecomment-1607223772
https://github.com/scverse/scanpy/issues/2499#issuecomment-1607268186:20,Performance,perform,perform,20,So we still need to perform the following work around:; 1) change file name of file `tissue_positions.csv` to `tissue_positions_list.csv`; 2) delete the header in the file. Right?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2499#issuecomment-1607268186
https://github.com/scverse/scanpy/issues/2499#issuecomment-1607290916:7,Deployability,install,install,7,Or you install the development version of scanpy: `pip install git+https://github.com/scverse/scanpy.git`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2499#issuecomment-1607290916
https://github.com/scverse/scanpy/issues/2499#issuecomment-1607290916:55,Deployability,install,install,55,Or you install the development version of scanpy: `pip install git+https://github.com/scverse/scanpy.git`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2499#issuecomment-1607290916
https://github.com/scverse/scanpy/issues/2500#issuecomment-1580655895:37,Availability,error,error,37,"Given the old function now raises an error, could you at least add a; FutureWarning (or np.exceptions.VisibleDeprecationWarning) indicating the; new function to be used? Thanks!. On Wed, 7 June 2023, 05:35 Philipp A., ***@***.***> wrote:. > Closed #2500; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/scverse/scanpy/issues/2500&g=ZWVjM2FjODk0ZjdmMTI1Nw==&h=N2Y4NmFmODU2ZTBlYjI1NzEzZDVlY2M3ZDQxMmVkMGVkZjY2OGMxZjEzMjZiMjNlODhmMGFhMTkwYjFmNGVjOQ==&p=YzJlOmltbXVuYWk6YzpnOjlhYTRmOGNmMDU2NDdjZTQ1ZTI0NjFjZmQ1OTY3NjljOnYxOmg6VA==>; > as not planned.; >; > —; > Reply to this email directly, view it on GitHub; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/scverse/scanpy/issues/2500%23event-9456493371&g=ZGJmZGZhMzNmOTM5ZTgzYQ==&h=Y2JmZjM5MDc2MjMzNjM3MGQwMzk1MDYxZmE3MDZlYzBiNWEzYzdjMTMwNWY5MjgxNTU5YmQ3NDI0ZDBjNWRhZg==&p=YzJlOmltbXVuYWk6YzpnOjlhYTRmOGNmMDU2NDdjZTQ1ZTI0NjFjZmQ1OTY3NjljOnYxOmg6VA==>,; > or unsubscribe; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/notifications/unsubscribe-auth/AUHCMAWZ7ISUHUBPHQDLLCDXKBDOHANCNFSM6AAAAAAY3HAO3E&g=NDU3YTZlZTA4ZDE0MzNhZQ==&h=OWQzOWMxNDgxMjZkZGM3ZWUxMmQ1ZTFlN2UwNjI5ZDI4YjFmMDA3OGVmYjc5MTljZDVkMDlhMTE1YjRiODBmNg==&p=YzJlOmltbXVuYWk6YzpnOjlhYTRmOGNmMDU2NDdjZTQ1ZTI0NjFjZmQ1OTY3NjljOnYxOmg6VA==>; > .; > You are receiving this because you authored the thread.Message ID:; > ***@***.***>; >. -- ; PLEASE NOTE: The information contained in this message is privileged and ; confidential, and is intended only for the use of the individual to whom it ; is addressed and others who have been specifically authorized to receive ; it. If you are not the intended recipient, you are hereby notified that any ; dissemination, distribution, or copying of this communication is strictly ; prohibited. If you have received this communication in error, or if any ; problems occur with the transmission, please contact the sender.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2500#issuecomment-1580655895
https://github.com/scverse/scanpy/issues/2500#issuecomment-1580655895:266,Availability,checkpoint,checkpoint,266,"Given the old function now raises an error, could you at least add a; FutureWarning (or np.exceptions.VisibleDeprecationWarning) indicating the; new function to be used? Thanks!. On Wed, 7 June 2023, 05:35 Philipp A., ***@***.***> wrote:. > Closed #2500; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/scverse/scanpy/issues/2500&g=ZWVjM2FjODk0ZjdmMTI1Nw==&h=N2Y4NmFmODU2ZTBlYjI1NzEzZDVlY2M3ZDQxMmVkMGVkZjY2OGMxZjEzMjZiMjNlODhmMGFhMTkwYjFmNGVjOQ==&p=YzJlOmltbXVuYWk6YzpnOjlhYTRmOGNmMDU2NDdjZTQ1ZTI0NjFjZmQ1OTY3NjljOnYxOmg6VA==>; > as not planned.; >; > —; > Reply to this email directly, view it on GitHub; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/scverse/scanpy/issues/2500%23event-9456493371&g=ZGJmZGZhMzNmOTM5ZTgzYQ==&h=Y2JmZjM5MDc2MjMzNjM3MGQwMzk1MDYxZmE3MDZlYzBiNWEzYzdjMTMwNWY5MjgxNTU5YmQ3NDI0ZDBjNWRhZg==&p=YzJlOmltbXVuYWk6YzpnOjlhYTRmOGNmMDU2NDdjZTQ1ZTI0NjFjZmQ1OTY3NjljOnYxOmg6VA==>,; > or unsubscribe; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/notifications/unsubscribe-auth/AUHCMAWZ7ISUHUBPHQDLLCDXKBDOHANCNFSM6AAAAAAY3HAO3E&g=NDU3YTZlZTA4ZDE0MzNhZQ==&h=OWQzOWMxNDgxMjZkZGM3ZWUxMmQ1ZTFlN2UwNjI5ZDI4YjFmMDA3OGVmYjc5MTljZDVkMDlhMTE1YjRiODBmNg==&p=YzJlOmltbXVuYWk6YzpnOjlhYTRmOGNmMDU2NDdjZTQ1ZTI0NjFjZmQ1OTY3NjljOnYxOmg6VA==>; > .; > You are receiving this because you authored the thread.Message ID:; > ***@***.***>; >. -- ; PLEASE NOTE: The information contained in this message is privileged and ; confidential, and is intended only for the use of the individual to whom it ; is addressed and others who have been specifically authorized to receive ; it. If you are not the intended recipient, you are hereby notified that any ; dissemination, distribution, or copying of this communication is strictly ; prohibited. If you have received this communication in error, or if any ; problems occur with the transmission, please contact the sender.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2500#issuecomment-1580655895
https://github.com/scverse/scanpy/issues/2500#issuecomment-1580655895:641,Availability,checkpoint,checkpoint,641,"Given the old function now raises an error, could you at least add a; FutureWarning (or np.exceptions.VisibleDeprecationWarning) indicating the; new function to be used? Thanks!. On Wed, 7 June 2023, 05:35 Philipp A., ***@***.***> wrote:. > Closed #2500; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/scverse/scanpy/issues/2500&g=ZWVjM2FjODk0ZjdmMTI1Nw==&h=N2Y4NmFmODU2ZTBlYjI1NzEzZDVlY2M3ZDQxMmVkMGVkZjY2OGMxZjEzMjZiMjNlODhmMGFhMTkwYjFmNGVjOQ==&p=YzJlOmltbXVuYWk6YzpnOjlhYTRmOGNmMDU2NDdjZTQ1ZTI0NjFjZmQ1OTY3NjljOnYxOmg6VA==>; > as not planned.; >; > —; > Reply to this email directly, view it on GitHub; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/scverse/scanpy/issues/2500%23event-9456493371&g=ZGJmZGZhMzNmOTM5ZTgzYQ==&h=Y2JmZjM5MDc2MjMzNjM3MGQwMzk1MDYxZmE3MDZlYzBiNWEzYzdjMTMwNWY5MjgxNTU5YmQ3NDI0ZDBjNWRhZg==&p=YzJlOmltbXVuYWk6YzpnOjlhYTRmOGNmMDU2NDdjZTQ1ZTI0NjFjZmQ1OTY3NjljOnYxOmg6VA==>,; > or unsubscribe; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/notifications/unsubscribe-auth/AUHCMAWZ7ISUHUBPHQDLLCDXKBDOHANCNFSM6AAAAAAY3HAO3E&g=NDU3YTZlZTA4ZDE0MzNhZQ==&h=OWQzOWMxNDgxMjZkZGM3ZWUxMmQ1ZTFlN2UwNjI5ZDI4YjFmMDA3OGVmYjc5MTljZDVkMDlhMTE1YjRiODBmNg==&p=YzJlOmltbXVuYWk6YzpnOjlhYTRmOGNmMDU2NDdjZTQ1ZTI0NjFjZmQ1OTY3NjljOnYxOmg6VA==>; > .; > You are receiving this because you authored the thread.Message ID:; > ***@***.***>; >. -- ; PLEASE NOTE: The information contained in this message is privileged and ; confidential, and is intended only for the use of the individual to whom it ; is addressed and others who have been specifically authorized to receive ; it. If you are not the intended recipient, you are hereby notified that any ; dissemination, distribution, or copying of this communication is strictly ; prohibited. If you have received this communication in error, or if any ; problems occur with the transmission, please contact the sender.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2500#issuecomment-1580655895
https://github.com/scverse/scanpy/issues/2500#issuecomment-1580655895:976,Availability,checkpoint,checkpoint,976,"Given the old function now raises an error, could you at least add a; FutureWarning (or np.exceptions.VisibleDeprecationWarning) indicating the; new function to be used? Thanks!. On Wed, 7 June 2023, 05:35 Philipp A., ***@***.***> wrote:. > Closed #2500; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/scverse/scanpy/issues/2500&g=ZWVjM2FjODk0ZjdmMTI1Nw==&h=N2Y4NmFmODU2ZTBlYjI1NzEzZDVlY2M3ZDQxMmVkMGVkZjY2OGMxZjEzMjZiMjNlODhmMGFhMTkwYjFmNGVjOQ==&p=YzJlOmltbXVuYWk6YzpnOjlhYTRmOGNmMDU2NDdjZTQ1ZTI0NjFjZmQ1OTY3NjljOnYxOmg6VA==>; > as not planned.; >; > —; > Reply to this email directly, view it on GitHub; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/scverse/scanpy/issues/2500%23event-9456493371&g=ZGJmZGZhMzNmOTM5ZTgzYQ==&h=Y2JmZjM5MDc2MjMzNjM3MGQwMzk1MDYxZmE3MDZlYzBiNWEzYzdjMTMwNWY5MjgxNTU5YmQ3NDI0ZDBjNWRhZg==&p=YzJlOmltbXVuYWk6YzpnOjlhYTRmOGNmMDU2NDdjZTQ1ZTI0NjFjZmQ1OTY3NjljOnYxOmg6VA==>,; > or unsubscribe; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/notifications/unsubscribe-auth/AUHCMAWZ7ISUHUBPHQDLLCDXKBDOHANCNFSM6AAAAAAY3HAO3E&g=NDU3YTZlZTA4ZDE0MzNhZQ==&h=OWQzOWMxNDgxMjZkZGM3ZWUxMmQ1ZTFlN2UwNjI5ZDI4YjFmMDA3OGVmYjc5MTljZDVkMDlhMTE1YjRiODBmNg==&p=YzJlOmltbXVuYWk6YzpnOjlhYTRmOGNmMDU2NDdjZTQ1ZTI0NjFjZmQ1OTY3NjljOnYxOmg6VA==>; > .; > You are receiving this because you authored the thread.Message ID:; > ***@***.***>; >. -- ; PLEASE NOTE: The information contained in this message is privileged and ; confidential, and is intended only for the use of the individual to whom it ; is addressed and others who have been specifically authorized to receive ; it. If you are not the intended recipient, you are hereby notified that any ; dissemination, distribution, or copying of this communication is strictly ; prohibited. If you have received this communication in error, or if any ; problems occur with the transmission, please contact the sender.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2500#issuecomment-1580655895
https://github.com/scverse/scanpy/issues/2500#issuecomment-1580655895:1853,Availability,error,error,1853,"Given the old function now raises an error, could you at least add a; FutureWarning (or np.exceptions.VisibleDeprecationWarning) indicating the; new function to be used? Thanks!. On Wed, 7 June 2023, 05:35 Philipp A., ***@***.***> wrote:. > Closed #2500; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/scverse/scanpy/issues/2500&g=ZWVjM2FjODk0ZjdmMTI1Nw==&h=N2Y4NmFmODU2ZTBlYjI1NzEzZDVlY2M3ZDQxMmVkMGVkZjY2OGMxZjEzMjZiMjNlODhmMGFhMTkwYjFmNGVjOQ==&p=YzJlOmltbXVuYWk6YzpnOjlhYTRmOGNmMDU2NDdjZTQ1ZTI0NjFjZmQ1OTY3NjljOnYxOmg6VA==>; > as not planned.; >; > —; > Reply to this email directly, view it on GitHub; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/scverse/scanpy/issues/2500%23event-9456493371&g=ZGJmZGZhMzNmOTM5ZTgzYQ==&h=Y2JmZjM5MDc2MjMzNjM3MGQwMzk1MDYxZmE3MDZlYzBiNWEzYzdjMTMwNWY5MjgxNTU5YmQ3NDI0ZDBjNWRhZg==&p=YzJlOmltbXVuYWk6YzpnOjlhYTRmOGNmMDU2NDdjZTQ1ZTI0NjFjZmQ1OTY3NjljOnYxOmg6VA==>,; > or unsubscribe; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/notifications/unsubscribe-auth/AUHCMAWZ7ISUHUBPHQDLLCDXKBDOHANCNFSM6AAAAAAY3HAO3E&g=NDU3YTZlZTA4ZDE0MzNhZQ==&h=OWQzOWMxNDgxMjZkZGM3ZWUxMmQ1ZTFlN2UwNjI5ZDI4YjFmMDA3OGVmYjc5MTljZDVkMDlhMTE1YjRiODBmNg==&p=YzJlOmltbXVuYWk6YzpnOjlhYTRmOGNmMDU2NDdjZTQ1ZTI0NjFjZmQ1OTY3NjljOnYxOmg6VA==>; > .; > You are receiving this because you authored the thread.Message ID:; > ***@***.***>; >. -- ; PLEASE NOTE: The information contained in this message is privileged and ; confidential, and is intended only for the use of the individual to whom it ; is addressed and others who have been specifically authorized to receive ; it. If you are not the intended recipient, you are hereby notified that any ; dissemination, distribution, or copying of this communication is strictly ; prohibited. If you have received this communication in error, or if any ; problems occur with the transmission, please contact the sender.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2500#issuecomment-1580655895
https://github.com/scverse/scanpy/issues/2500#issuecomment-1580655895:1379,Integrability,Message,Message,1379,"Given the old function now raises an error, could you at least add a; FutureWarning (or np.exceptions.VisibleDeprecationWarning) indicating the; new function to be used? Thanks!. On Wed, 7 June 2023, 05:35 Philipp A., ***@***.***> wrote:. > Closed #2500; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/scverse/scanpy/issues/2500&g=ZWVjM2FjODk0ZjdmMTI1Nw==&h=N2Y4NmFmODU2ZTBlYjI1NzEzZDVlY2M3ZDQxMmVkMGVkZjY2OGMxZjEzMjZiMjNlODhmMGFhMTkwYjFmNGVjOQ==&p=YzJlOmltbXVuYWk6YzpnOjlhYTRmOGNmMDU2NDdjZTQ1ZTI0NjFjZmQ1OTY3NjljOnYxOmg6VA==>; > as not planned.; >; > —; > Reply to this email directly, view it on GitHub; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/scverse/scanpy/issues/2500%23event-9456493371&g=ZGJmZGZhMzNmOTM5ZTgzYQ==&h=Y2JmZjM5MDc2MjMzNjM3MGQwMzk1MDYxZmE3MDZlYzBiNWEzYzdjMTMwNWY5MjgxNTU5YmQ3NDI0ZDBjNWRhZg==&p=YzJlOmltbXVuYWk6YzpnOjlhYTRmOGNmMDU2NDdjZTQ1ZTI0NjFjZmQ1OTY3NjljOnYxOmg6VA==>,; > or unsubscribe; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/notifications/unsubscribe-auth/AUHCMAWZ7ISUHUBPHQDLLCDXKBDOHANCNFSM6AAAAAAY3HAO3E&g=NDU3YTZlZTA4ZDE0MzNhZQ==&h=OWQzOWMxNDgxMjZkZGM3ZWUxMmQ1ZTFlN2UwNjI5ZDI4YjFmMDA3OGVmYjc5MTljZDVkMDlhMTE1YjRiODBmNg==&p=YzJlOmltbXVuYWk6YzpnOjlhYTRmOGNmMDU2NDdjZTQ1ZTI0NjFjZmQ1OTY3NjljOnYxOmg6VA==>; > .; > You are receiving this because you authored the thread.Message ID:; > ***@***.***>; >. -- ; PLEASE NOTE: The information contained in this message is privileged and ; confidential, and is intended only for the use of the individual to whom it ; is addressed and others who have been specifically authorized to receive ; it. If you are not the intended recipient, you are hereby notified that any ; dissemination, distribution, or copying of this communication is strictly ; prohibited. If you have received this communication in error, or if any ; problems occur with the transmission, please contact the sender.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2500#issuecomment-1580655895
https://github.com/scverse/scanpy/issues/2500#issuecomment-1580655895:1463,Integrability,message,message,1463,"Given the old function now raises an error, could you at least add a; FutureWarning (or np.exceptions.VisibleDeprecationWarning) indicating the; new function to be used? Thanks!. On Wed, 7 June 2023, 05:35 Philipp A., ***@***.***> wrote:. > Closed #2500; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/scverse/scanpy/issues/2500&g=ZWVjM2FjODk0ZjdmMTI1Nw==&h=N2Y4NmFmODU2ZTBlYjI1NzEzZDVlY2M3ZDQxMmVkMGVkZjY2OGMxZjEzMjZiMjNlODhmMGFhMTkwYjFmNGVjOQ==&p=YzJlOmltbXVuYWk6YzpnOjlhYTRmOGNmMDU2NDdjZTQ1ZTI0NjFjZmQ1OTY3NjljOnYxOmg6VA==>; > as not planned.; >; > —; > Reply to this email directly, view it on GitHub; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/scverse/scanpy/issues/2500%23event-9456493371&g=ZGJmZGZhMzNmOTM5ZTgzYQ==&h=Y2JmZjM5MDc2MjMzNjM3MGQwMzk1MDYxZmE3MDZlYzBiNWEzYzdjMTMwNWY5MjgxNTU5YmQ3NDI0ZDBjNWRhZg==&p=YzJlOmltbXVuYWk6YzpnOjlhYTRmOGNmMDU2NDdjZTQ1ZTI0NjFjZmQ1OTY3NjljOnYxOmg6VA==>,; > or unsubscribe; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/notifications/unsubscribe-auth/AUHCMAWZ7ISUHUBPHQDLLCDXKBDOHANCNFSM6AAAAAAY3HAO3E&g=NDU3YTZlZTA4ZDE0MzNhZQ==&h=OWQzOWMxNDgxMjZkZGM3ZWUxMmQ1ZTFlN2UwNjI5ZDI4YjFmMDA3OGVmYjc5MTljZDVkMDlhMTE1YjRiODBmNg==&p=YzJlOmltbXVuYWk6YzpnOjlhYTRmOGNmMDU2NDdjZTQ1ZTI0NjFjZmQ1OTY3NjljOnYxOmg6VA==>; > .; > You are receiving this because you authored the thread.Message ID:; > ***@***.***>; >. -- ; PLEASE NOTE: The information contained in this message is privileged and ; confidential, and is intended only for the use of the individual to whom it ; is addressed and others who have been specifically authorized to receive ; it. If you are not the intended recipient, you are hereby notified that any ; dissemination, distribution, or copying of this communication is strictly ; prohibited. If you have received this communication in error, or if any ; problems occur with the transmission, please contact the sender.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2500#issuecomment-1580655895
https://github.com/scverse/scanpy/issues/2500#issuecomment-1580655895:1491,Security,confidential,confidential,1491,"Given the old function now raises an error, could you at least add a; FutureWarning (or np.exceptions.VisibleDeprecationWarning) indicating the; new function to be used? Thanks!. On Wed, 7 June 2023, 05:35 Philipp A., ***@***.***> wrote:. > Closed #2500; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/scverse/scanpy/issues/2500&g=ZWVjM2FjODk0ZjdmMTI1Nw==&h=N2Y4NmFmODU2ZTBlYjI1NzEzZDVlY2M3ZDQxMmVkMGVkZjY2OGMxZjEzMjZiMjNlODhmMGFhMTkwYjFmNGVjOQ==&p=YzJlOmltbXVuYWk6YzpnOjlhYTRmOGNmMDU2NDdjZTQ1ZTI0NjFjZmQ1OTY3NjljOnYxOmg6VA==>; > as not planned.; >; > —; > Reply to this email directly, view it on GitHub; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/scverse/scanpy/issues/2500%23event-9456493371&g=ZGJmZGZhMzNmOTM5ZTgzYQ==&h=Y2JmZjM5MDc2MjMzNjM3MGQwMzk1MDYxZmE3MDZlYzBiNWEzYzdjMTMwNWY5MjgxNTU5YmQ3NDI0ZDBjNWRhZg==&p=YzJlOmltbXVuYWk6YzpnOjlhYTRmOGNmMDU2NDdjZTQ1ZTI0NjFjZmQ1OTY3NjljOnYxOmg6VA==>,; > or unsubscribe; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/notifications/unsubscribe-auth/AUHCMAWZ7ISUHUBPHQDLLCDXKBDOHANCNFSM6AAAAAAY3HAO3E&g=NDU3YTZlZTA4ZDE0MzNhZQ==&h=OWQzOWMxNDgxMjZkZGM3ZWUxMmQ1ZTFlN2UwNjI5ZDI4YjFmMDA3OGVmYjc5MTljZDVkMDlhMTE1YjRiODBmNg==&p=YzJlOmltbXVuYWk6YzpnOjlhYTRmOGNmMDU2NDdjZTQ1ZTI0NjFjZmQ1OTY3NjljOnYxOmg6VA==>; > .; > You are receiving this because you authored the thread.Message ID:; > ***@***.***>; >. -- ; PLEASE NOTE: The information contained in this message is privileged and ; confidential, and is intended only for the use of the individual to whom it ; is addressed and others who have been specifically authorized to receive ; it. If you are not the intended recipient, you are hereby notified that any ; dissemination, distribution, or copying of this communication is strictly ; prohibited. If you have received this communication in error, or if any ; problems occur with the transmission, please contact the sender.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2500#issuecomment-1580655895
https://github.com/scverse/scanpy/issues/2500#issuecomment-1580655895:1620,Security,authoriz,authorized,1620,"Given the old function now raises an error, could you at least add a; FutureWarning (or np.exceptions.VisibleDeprecationWarning) indicating the; new function to be used? Thanks!. On Wed, 7 June 2023, 05:35 Philipp A., ***@***.***> wrote:. > Closed #2500; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/scverse/scanpy/issues/2500&g=ZWVjM2FjODk0ZjdmMTI1Nw==&h=N2Y4NmFmODU2ZTBlYjI1NzEzZDVlY2M3ZDQxMmVkMGVkZjY2OGMxZjEzMjZiMjNlODhmMGFhMTkwYjFmNGVjOQ==&p=YzJlOmltbXVuYWk6YzpnOjlhYTRmOGNmMDU2NDdjZTQ1ZTI0NjFjZmQ1OTY3NjljOnYxOmg6VA==>; > as not planned.; >; > —; > Reply to this email directly, view it on GitHub; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/scverse/scanpy/issues/2500%23event-9456493371&g=ZGJmZGZhMzNmOTM5ZTgzYQ==&h=Y2JmZjM5MDc2MjMzNjM3MGQwMzk1MDYxZmE3MDZlYzBiNWEzYzdjMTMwNWY5MjgxNTU5YmQ3NDI0ZDBjNWRhZg==&p=YzJlOmltbXVuYWk6YzpnOjlhYTRmOGNmMDU2NDdjZTQ1ZTI0NjFjZmQ1OTY3NjljOnYxOmg6VA==>,; > or unsubscribe; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/notifications/unsubscribe-auth/AUHCMAWZ7ISUHUBPHQDLLCDXKBDOHANCNFSM6AAAAAAY3HAO3E&g=NDU3YTZlZTA4ZDE0MzNhZQ==&h=OWQzOWMxNDgxMjZkZGM3ZWUxMmQ1ZTFlN2UwNjI5ZDI4YjFmMDA3OGVmYjc5MTljZDVkMDlhMTE1YjRiODBmNg==&p=YzJlOmltbXVuYWk6YzpnOjlhYTRmOGNmMDU2NDdjZTQ1ZTI0NjFjZmQ1OTY3NjljOnYxOmg6VA==>; > .; > You are receiving this because you authored the thread.Message ID:; > ***@***.***>; >. -- ; PLEASE NOTE: The information contained in this message is privileged and ; confidential, and is intended only for the use of the individual to whom it ; is addressed and others who have been specifically authorized to receive ; it. If you are not the intended recipient, you are hereby notified that any ; dissemination, distribution, or copying of this communication is strictly ; prohibited. If you have received this communication in error, or if any ; problems occur with the transmission, please contact the sender.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2500#issuecomment-1580655895
https://github.com/scverse/scanpy/issues/2500#issuecomment-1580840698:126,Availability,checkpoint,checkpoint,126,"Thanks!. On Wed, Jun 7, 2023 at 9:34 AM Philipp A. ***@***.***> wrote:. > I had the same thought and opened #2505; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/scverse/scanpy/issues/2505&g=NmVkM2RiMWY2M2U4YzZhYw==&h=YTlmZWU5MDlhNTJlOWJjMTkxZDczZTg2MGE2ODdiNzU2NmIwYjE2OTMzZTczY2M1ZjNlNzEyM2Q0Mjc1OWM5Yg==&p=YzJlOmltbXVuYWk6YzpnOjBhNjA3ZDgxZmY2OGQ1YTVjYWY3YWUzM2MzZGM0MDU3OnYxOmg6VA==>; > to track that!; >; > —; > Reply to this email directly, view it on GitHub; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/scverse/scanpy/issues/2500%23issuecomment-1580835422&g=YWNlMjU3YjI5ODM4NTJkYQ==&h=ZTJiNzVlYzQ0NzM5YmY0ZTdiMWEzMDQ2MmQ0MGMwOWZmZTVlOGRhN2JmYjZiYTcxYjg1Nzg3OTRjMzEwZDY3OA==&p=YzJlOmltbXVuYWk6YzpnOjBhNjA3ZDgxZmY2OGQ1YTVjYWY3YWUzM2MzZGM0MDU3OnYxOmg6VA==>,; > or unsubscribe; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/notifications/unsubscribe-auth/AUHCMAR6XJXLYMBK224NMETXKB7MDANCNFSM6AAAAAAY3HAO3E&g=OGRhMDE2YzcyZWIwNGMxNg==&h=M2I1NTIwM2JlNTIwNjA4MGViYjE3YTRmYjQ0MWM3NzNhYzNkNjBlNzVjYjg1NDUwMGVkMjJhNWFkYmZlZTIxYQ==&p=YzJlOmltbXVuYWk6YzpnOjBhNjA3ZDgxZmY2OGQ1YTVjYWY3YWUzM2MzZGM0MDU3OnYxOmg6VA==>; > .; > You are receiving this because you authored the thread.Message ID:; > ***@***.***>; >. -- ; PLEASE NOTE: The information contained in this message is privileged and ; confidential, and is intended only for the use of the individual to whom it ; is addressed and others who have been specifically authorized to receive ; it. If you are not the intended recipient, you are hereby notified that any ; dissemination, distribution, or copying of this communication is strictly ; prohibited. If you have received this communication in error, or if any ; problems occur with the transmission, please contact the sender.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2500#issuecomment-1580840698
https://github.com/scverse/scanpy/issues/2500#issuecomment-1580840698:500,Availability,checkpoint,checkpoint,500,"Thanks!. On Wed, Jun 7, 2023 at 9:34 AM Philipp A. ***@***.***> wrote:. > I had the same thought and opened #2505; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/scverse/scanpy/issues/2505&g=NmVkM2RiMWY2M2U4YzZhYw==&h=YTlmZWU5MDlhNTJlOWJjMTkxZDczZTg2MGE2ODdiNzU2NmIwYjE2OTMzZTczY2M1ZjNlNzEyM2Q0Mjc1OWM5Yg==&p=YzJlOmltbXVuYWk6YzpnOjBhNjA3ZDgxZmY2OGQ1YTVjYWY3YWUzM2MzZGM0MDU3OnYxOmg6VA==>; > to track that!; >; > —; > Reply to this email directly, view it on GitHub; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/scverse/scanpy/issues/2500%23issuecomment-1580835422&g=YWNlMjU3YjI5ODM4NTJkYQ==&h=ZTJiNzVlYzQ0NzM5YmY0ZTdiMWEzMDQ2MmQ0MGMwOWZmZTVlOGRhN2JmYjZiYTcxYjg1Nzg3OTRjMzEwZDY3OA==&p=YzJlOmltbXVuYWk6YzpnOjBhNjA3ZDgxZmY2OGQ1YTVjYWY3YWUzM2MzZGM0MDU3OnYxOmg6VA==>,; > or unsubscribe; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/notifications/unsubscribe-auth/AUHCMAR6XJXLYMBK224NMETXKB7MDANCNFSM6AAAAAAY3HAO3E&g=OGRhMDE2YzcyZWIwNGMxNg==&h=M2I1NTIwM2JlNTIwNjA4MGViYjE3YTRmYjQ0MWM3NzNhYzNkNjBlNzVjYjg1NDUwMGVkMjJhNWFkYmZlZTIxYQ==&p=YzJlOmltbXVuYWk6YzpnOjBhNjA3ZDgxZmY2OGQ1YTVjYWY3YWUzM2MzZGM0MDU3OnYxOmg6VA==>; > .; > You are receiving this because you authored the thread.Message ID:; > ***@***.***>; >. -- ; PLEASE NOTE: The information contained in this message is privileged and ; confidential, and is intended only for the use of the individual to whom it ; is addressed and others who have been specifically authorized to receive ; it. If you are not the intended recipient, you are hereby notified that any ; dissemination, distribution, or copying of this communication is strictly ; prohibited. If you have received this communication in error, or if any ; problems occur with the transmission, please contact the sender.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2500#issuecomment-1580840698
https://github.com/scverse/scanpy/issues/2500#issuecomment-1580840698:842,Availability,checkpoint,checkpoint,842,"Thanks!. On Wed, Jun 7, 2023 at 9:34 AM Philipp A. ***@***.***> wrote:. > I had the same thought and opened #2505; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/scverse/scanpy/issues/2505&g=NmVkM2RiMWY2M2U4YzZhYw==&h=YTlmZWU5MDlhNTJlOWJjMTkxZDczZTg2MGE2ODdiNzU2NmIwYjE2OTMzZTczY2M1ZjNlNzEyM2Q0Mjc1OWM5Yg==&p=YzJlOmltbXVuYWk6YzpnOjBhNjA3ZDgxZmY2OGQ1YTVjYWY3YWUzM2MzZGM0MDU3OnYxOmg6VA==>; > to track that!; >; > —; > Reply to this email directly, view it on GitHub; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/scverse/scanpy/issues/2500%23issuecomment-1580835422&g=YWNlMjU3YjI5ODM4NTJkYQ==&h=ZTJiNzVlYzQ0NzM5YmY0ZTdiMWEzMDQ2MmQ0MGMwOWZmZTVlOGRhN2JmYjZiYTcxYjg1Nzg3OTRjMzEwZDY3OA==&p=YzJlOmltbXVuYWk6YzpnOjBhNjA3ZDgxZmY2OGQ1YTVjYWY3YWUzM2MzZGM0MDU3OnYxOmg6VA==>,; > or unsubscribe; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/notifications/unsubscribe-auth/AUHCMAR6XJXLYMBK224NMETXKB7MDANCNFSM6AAAAAAY3HAO3E&g=OGRhMDE2YzcyZWIwNGMxNg==&h=M2I1NTIwM2JlNTIwNjA4MGViYjE3YTRmYjQ0MWM3NzNhYzNkNjBlNzVjYjg1NDUwMGVkMjJhNWFkYmZlZTIxYQ==&p=YzJlOmltbXVuYWk6YzpnOjBhNjA3ZDgxZmY2OGQ1YTVjYWY3YWUzM2MzZGM0MDU3OnYxOmg6VA==>; > .; > You are receiving this because you authored the thread.Message ID:; > ***@***.***>; >. -- ; PLEASE NOTE: The information contained in this message is privileged and ; confidential, and is intended only for the use of the individual to whom it ; is addressed and others who have been specifically authorized to receive ; it. If you are not the intended recipient, you are hereby notified that any ; dissemination, distribution, or copying of this communication is strictly ; prohibited. If you have received this communication in error, or if any ; problems occur with the transmission, please contact the sender.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2500#issuecomment-1580840698
https://github.com/scverse/scanpy/issues/2500#issuecomment-1580840698:1719,Availability,error,error,1719,"Thanks!. On Wed, Jun 7, 2023 at 9:34 AM Philipp A. ***@***.***> wrote:. > I had the same thought and opened #2505; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/scverse/scanpy/issues/2505&g=NmVkM2RiMWY2M2U4YzZhYw==&h=YTlmZWU5MDlhNTJlOWJjMTkxZDczZTg2MGE2ODdiNzU2NmIwYjE2OTMzZTczY2M1ZjNlNzEyM2Q0Mjc1OWM5Yg==&p=YzJlOmltbXVuYWk6YzpnOjBhNjA3ZDgxZmY2OGQ1YTVjYWY3YWUzM2MzZGM0MDU3OnYxOmg6VA==>; > to track that!; >; > —; > Reply to this email directly, view it on GitHub; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/scverse/scanpy/issues/2500%23issuecomment-1580835422&g=YWNlMjU3YjI5ODM4NTJkYQ==&h=ZTJiNzVlYzQ0NzM5YmY0ZTdiMWEzMDQ2MmQ0MGMwOWZmZTVlOGRhN2JmYjZiYTcxYjg1Nzg3OTRjMzEwZDY3OA==&p=YzJlOmltbXVuYWk6YzpnOjBhNjA3ZDgxZmY2OGQ1YTVjYWY3YWUzM2MzZGM0MDU3OnYxOmg6VA==>,; > or unsubscribe; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/notifications/unsubscribe-auth/AUHCMAR6XJXLYMBK224NMETXKB7MDANCNFSM6AAAAAAY3HAO3E&g=OGRhMDE2YzcyZWIwNGMxNg==&h=M2I1NTIwM2JlNTIwNjA4MGViYjE3YTRmYjQ0MWM3NzNhYzNkNjBlNzVjYjg1NDUwMGVkMjJhNWFkYmZlZTIxYQ==&p=YzJlOmltbXVuYWk6YzpnOjBhNjA3ZDgxZmY2OGQ1YTVjYWY3YWUzM2MzZGM0MDU3OnYxOmg6VA==>; > .; > You are receiving this because you authored the thread.Message ID:; > ***@***.***>; >. -- ; PLEASE NOTE: The information contained in this message is privileged and ; confidential, and is intended only for the use of the individual to whom it ; is addressed and others who have been specifically authorized to receive ; it. If you are not the intended recipient, you are hereby notified that any ; dissemination, distribution, or copying of this communication is strictly ; prohibited. If you have received this communication in error, or if any ; problems occur with the transmission, please contact the sender.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2500#issuecomment-1580840698
https://github.com/scverse/scanpy/issues/2500#issuecomment-1580840698:1245,Integrability,Message,Message,1245,"Thanks!. On Wed, Jun 7, 2023 at 9:34 AM Philipp A. ***@***.***> wrote:. > I had the same thought and opened #2505; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/scverse/scanpy/issues/2505&g=NmVkM2RiMWY2M2U4YzZhYw==&h=YTlmZWU5MDlhNTJlOWJjMTkxZDczZTg2MGE2ODdiNzU2NmIwYjE2OTMzZTczY2M1ZjNlNzEyM2Q0Mjc1OWM5Yg==&p=YzJlOmltbXVuYWk6YzpnOjBhNjA3ZDgxZmY2OGQ1YTVjYWY3YWUzM2MzZGM0MDU3OnYxOmg6VA==>; > to track that!; >; > —; > Reply to this email directly, view it on GitHub; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/scverse/scanpy/issues/2500%23issuecomment-1580835422&g=YWNlMjU3YjI5ODM4NTJkYQ==&h=ZTJiNzVlYzQ0NzM5YmY0ZTdiMWEzMDQ2MmQ0MGMwOWZmZTVlOGRhN2JmYjZiYTcxYjg1Nzg3OTRjMzEwZDY3OA==&p=YzJlOmltbXVuYWk6YzpnOjBhNjA3ZDgxZmY2OGQ1YTVjYWY3YWUzM2MzZGM0MDU3OnYxOmg6VA==>,; > or unsubscribe; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/notifications/unsubscribe-auth/AUHCMAR6XJXLYMBK224NMETXKB7MDANCNFSM6AAAAAAY3HAO3E&g=OGRhMDE2YzcyZWIwNGMxNg==&h=M2I1NTIwM2JlNTIwNjA4MGViYjE3YTRmYjQ0MWM3NzNhYzNkNjBlNzVjYjg1NDUwMGVkMjJhNWFkYmZlZTIxYQ==&p=YzJlOmltbXVuYWk6YzpnOjBhNjA3ZDgxZmY2OGQ1YTVjYWY3YWUzM2MzZGM0MDU3OnYxOmg6VA==>; > .; > You are receiving this because you authored the thread.Message ID:; > ***@***.***>; >. -- ; PLEASE NOTE: The information contained in this message is privileged and ; confidential, and is intended only for the use of the individual to whom it ; is addressed and others who have been specifically authorized to receive ; it. If you are not the intended recipient, you are hereby notified that any ; dissemination, distribution, or copying of this communication is strictly ; prohibited. If you have received this communication in error, or if any ; problems occur with the transmission, please contact the sender.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2500#issuecomment-1580840698
https://github.com/scverse/scanpy/issues/2500#issuecomment-1580840698:1329,Integrability,message,message,1329,"Thanks!. On Wed, Jun 7, 2023 at 9:34 AM Philipp A. ***@***.***> wrote:. > I had the same thought and opened #2505; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/scverse/scanpy/issues/2505&g=NmVkM2RiMWY2M2U4YzZhYw==&h=YTlmZWU5MDlhNTJlOWJjMTkxZDczZTg2MGE2ODdiNzU2NmIwYjE2OTMzZTczY2M1ZjNlNzEyM2Q0Mjc1OWM5Yg==&p=YzJlOmltbXVuYWk6YzpnOjBhNjA3ZDgxZmY2OGQ1YTVjYWY3YWUzM2MzZGM0MDU3OnYxOmg6VA==>; > to track that!; >; > —; > Reply to this email directly, view it on GitHub; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/scverse/scanpy/issues/2500%23issuecomment-1580835422&g=YWNlMjU3YjI5ODM4NTJkYQ==&h=ZTJiNzVlYzQ0NzM5YmY0ZTdiMWEzMDQ2MmQ0MGMwOWZmZTVlOGRhN2JmYjZiYTcxYjg1Nzg3OTRjMzEwZDY3OA==&p=YzJlOmltbXVuYWk6YzpnOjBhNjA3ZDgxZmY2OGQ1YTVjYWY3YWUzM2MzZGM0MDU3OnYxOmg6VA==>,; > or unsubscribe; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/notifications/unsubscribe-auth/AUHCMAR6XJXLYMBK224NMETXKB7MDANCNFSM6AAAAAAY3HAO3E&g=OGRhMDE2YzcyZWIwNGMxNg==&h=M2I1NTIwM2JlNTIwNjA4MGViYjE3YTRmYjQ0MWM3NzNhYzNkNjBlNzVjYjg1NDUwMGVkMjJhNWFkYmZlZTIxYQ==&p=YzJlOmltbXVuYWk6YzpnOjBhNjA3ZDgxZmY2OGQ1YTVjYWY3YWUzM2MzZGM0MDU3OnYxOmg6VA==>; > .; > You are receiving this because you authored the thread.Message ID:; > ***@***.***>; >. -- ; PLEASE NOTE: The information contained in this message is privileged and ; confidential, and is intended only for the use of the individual to whom it ; is addressed and others who have been specifically authorized to receive ; it. If you are not the intended recipient, you are hereby notified that any ; dissemination, distribution, or copying of this communication is strictly ; prohibited. If you have received this communication in error, or if any ; problems occur with the transmission, please contact the sender.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2500#issuecomment-1580840698
https://github.com/scverse/scanpy/issues/2500#issuecomment-1580840698:1357,Security,confidential,confidential,1357,"Thanks!. On Wed, Jun 7, 2023 at 9:34 AM Philipp A. ***@***.***> wrote:. > I had the same thought and opened #2505; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/scverse/scanpy/issues/2505&g=NmVkM2RiMWY2M2U4YzZhYw==&h=YTlmZWU5MDlhNTJlOWJjMTkxZDczZTg2MGE2ODdiNzU2NmIwYjE2OTMzZTczY2M1ZjNlNzEyM2Q0Mjc1OWM5Yg==&p=YzJlOmltbXVuYWk6YzpnOjBhNjA3ZDgxZmY2OGQ1YTVjYWY3YWUzM2MzZGM0MDU3OnYxOmg6VA==>; > to track that!; >; > —; > Reply to this email directly, view it on GitHub; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/scverse/scanpy/issues/2500%23issuecomment-1580835422&g=YWNlMjU3YjI5ODM4NTJkYQ==&h=ZTJiNzVlYzQ0NzM5YmY0ZTdiMWEzMDQ2MmQ0MGMwOWZmZTVlOGRhN2JmYjZiYTcxYjg1Nzg3OTRjMzEwZDY3OA==&p=YzJlOmltbXVuYWk6YzpnOjBhNjA3ZDgxZmY2OGQ1YTVjYWY3YWUzM2MzZGM0MDU3OnYxOmg6VA==>,; > or unsubscribe; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/notifications/unsubscribe-auth/AUHCMAR6XJXLYMBK224NMETXKB7MDANCNFSM6AAAAAAY3HAO3E&g=OGRhMDE2YzcyZWIwNGMxNg==&h=M2I1NTIwM2JlNTIwNjA4MGViYjE3YTRmYjQ0MWM3NzNhYzNkNjBlNzVjYjg1NDUwMGVkMjJhNWFkYmZlZTIxYQ==&p=YzJlOmltbXVuYWk6YzpnOjBhNjA3ZDgxZmY2OGQ1YTVjYWY3YWUzM2MzZGM0MDU3OnYxOmg6VA==>; > .; > You are receiving this because you authored the thread.Message ID:; > ***@***.***>; >. -- ; PLEASE NOTE: The information contained in this message is privileged and ; confidential, and is intended only for the use of the individual to whom it ; is addressed and others who have been specifically authorized to receive ; it. If you are not the intended recipient, you are hereby notified that any ; dissemination, distribution, or copying of this communication is strictly ; prohibited. If you have received this communication in error, or if any ; problems occur with the transmission, please contact the sender.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2500#issuecomment-1580840698
https://github.com/scverse/scanpy/issues/2500#issuecomment-1580840698:1486,Security,authoriz,authorized,1486,"Thanks!. On Wed, Jun 7, 2023 at 9:34 AM Philipp A. ***@***.***> wrote:. > I had the same thought and opened #2505; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/scverse/scanpy/issues/2505&g=NmVkM2RiMWY2M2U4YzZhYw==&h=YTlmZWU5MDlhNTJlOWJjMTkxZDczZTg2MGE2ODdiNzU2NmIwYjE2OTMzZTczY2M1ZjNlNzEyM2Q0Mjc1OWM5Yg==&p=YzJlOmltbXVuYWk6YzpnOjBhNjA3ZDgxZmY2OGQ1YTVjYWY3YWUzM2MzZGM0MDU3OnYxOmg6VA==>; > to track that!; >; > —; > Reply to this email directly, view it on GitHub; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/scverse/scanpy/issues/2500%23issuecomment-1580835422&g=YWNlMjU3YjI5ODM4NTJkYQ==&h=ZTJiNzVlYzQ0NzM5YmY0ZTdiMWEzMDQ2MmQ0MGMwOWZmZTVlOGRhN2JmYjZiYTcxYjg1Nzg3OTRjMzEwZDY3OA==&p=YzJlOmltbXVuYWk6YzpnOjBhNjA3ZDgxZmY2OGQ1YTVjYWY3YWUzM2MzZGM0MDU3OnYxOmg6VA==>,; > or unsubscribe; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/notifications/unsubscribe-auth/AUHCMAR6XJXLYMBK224NMETXKB7MDANCNFSM6AAAAAAY3HAO3E&g=OGRhMDE2YzcyZWIwNGMxNg==&h=M2I1NTIwM2JlNTIwNjA4MGViYjE3YTRmYjQ0MWM3NzNhYzNkNjBlNzVjYjg1NDUwMGVkMjJhNWFkYmZlZTIxYQ==&p=YzJlOmltbXVuYWk6YzpnOjBhNjA3ZDgxZmY2OGQ1YTVjYWY3YWUzM2MzZGM0MDU3OnYxOmg6VA==>; > .; > You are receiving this because you authored the thread.Message ID:; > ***@***.***>; >. -- ; PLEASE NOTE: The information contained in this message is privileged and ; confidential, and is intended only for the use of the individual to whom it ; is addressed and others who have been specifically authorized to receive ; it. If you are not the intended recipient, you are hereby notified that any ; dissemination, distribution, or copying of this communication is strictly ; prohibited. If you have received this communication in error, or if any ; problems occur with the transmission, please contact the sender.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2500#issuecomment-1580840698
https://github.com/scverse/scanpy/pull/2502#issuecomment-1580570725:31,Availability,ping,ping,31,"@grst is also a good person to ping for tutorials. In general, we'll also want to link to more scverse tutorials eventually",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2502#issuecomment-1580570725
https://github.com/scverse/scanpy/pull/2502#issuecomment-1580575932:35,Usability,learn,learn,35,"Relevant issues about `scverse.org/learn`: . * https://github.com/scverse/scverse-tutorials/issues/58; * https://github.com/scverse/scverse-tutorials/issues/60. Tutorial registry is [here](https://github.com/scverse/scverse-tutorials/tree/main/tutorial-registry) and works in principle, but needs to be filled with content as described in https://github.com/scverse/scverse-tutorials/issues/58",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2502#issuecomment-1580575932
https://github.com/scverse/scanpy/pull/2512#issuecomment-1594388914:52,Energy Efficiency,reduce,reduce,52,"Hi, we’re currently planning scanpy 2.0. We want to reduce the number of ways people can make heatmaps, but maybe marsilea would be a good base for the new version. We’ll keep an eye on it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2512#issuecomment-1594388914
https://github.com/scverse/scanpy/pull/2512#issuecomment-1597429208:364,Integrability,depend,dependency,364,"Thanks for the PR! We've been thinking about refactoring this part of the package, and this looks like an interesting way to do it. However, we're not accepting any additions to the `external` module anymore. Instead we are pointing people to the broader [scverse ecosystem](https://scverse.org/packages/#ecosystem). We may be interested in using this as a direct dependency but may need to do some research into this first + request/ add a few features in `Marsilea` such as dot plots. cc @grst",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2512#issuecomment-1597429208
https://github.com/scverse/scanpy/pull/2512#issuecomment-1597429208:45,Modifiability,refactor,refactoring,45,"Thanks for the PR! We've been thinking about refactoring this part of the package, and this looks like an interesting way to do it. However, we're not accepting any additions to the `external` module anymore. Instead we are pointing people to the broader [scverse ecosystem](https://scverse.org/packages/#ecosystem). We may be interested in using this as a direct dependency but may need to do some research into this first + request/ add a few features in `Marsilea` such as dot plots. cc @grst",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2512#issuecomment-1597429208
https://github.com/scverse/scanpy/pull/2512#issuecomment-1598070226:393,Availability,avail,available,393,Thanks for your interest! It would be cool if `Marsilea` could be part of `Scanpy`. . The `Marsilea` is shipped with a wide range of plot options which already include the [dot plot](https://marsilea.readthedocs.io/en/latest/tutorial/heatmap.html#matrix-heatmap-with-sized-elements) (We call it Sized Heatmap). Here is a [list](https://marsilea.readthedocs.io/en/latest/api/plots.html) of all available plot options for your reference. . Any further suggestions or requests to expand the plot options are welcome.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2512#issuecomment-1598070226
https://github.com/scverse/scanpy/pull/2516#issuecomment-1596813650:331,Availability,error,error-reference,331,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2516?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@2979f99`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2516 +/- ##; ========================================; Coverage ? 71.89% ; ========================================; Files ? 98 ; Lines ? 11488 ; Branches ? 0 ; ========================================; Hits ? 8259 ; Misses ? 3229 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2516#issuecomment-1596813650
https://github.com/scverse/scanpy/pull/2516#issuecomment-1596813650:279,Usability,learn,learn,279,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2516?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@2979f99`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2516 +/- ##; ========================================; Coverage ? 71.89% ; ========================================; Files ? 98 ; Lines ? 11488 ; Branches ? 0 ; ========================================; Hits ? 8259 ; Misses ? 3229 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2516#issuecomment-1596813650
https://github.com/scverse/scanpy/issues/2519#issuecomment-1602758898:29,Deployability,install,install,29,faiss was reasonably easy to install via conda and has fairly easy to use gpu support which is nice,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2519#issuecomment-1602758898
https://github.com/scverse/scanpy/issues/2519#issuecomment-1603957399:405,Integrability,depend,dependency,405,"We’re thinking about making the backend configurable through something like https://github.com/frankier/sklearn-ann (that specific one doesn’t seem maintained though). A recipe for this is found here: https://scikit-learn.org/stable/auto_examples/neighbors/approximate_nearest_neighbors.html#sphx-glr-auto-examples-neighbors-approximate-nearest-neighbors-py. Faiss does seem nice as an option, but a hard dependency on something that isn’t on PyPI is out of the question.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2519#issuecomment-1603957399
https://github.com/scverse/scanpy/issues/2519#issuecomment-1603957399:40,Modifiability,config,configurable,40,"We’re thinking about making the backend configurable through something like https://github.com/frankier/sklearn-ann (that specific one doesn’t seem maintained though). A recipe for this is found here: https://scikit-learn.org/stable/auto_examples/neighbors/approximate_nearest_neighbors.html#sphx-glr-auto-examples-neighbors-approximate-nearest-neighbors-py. Faiss does seem nice as an option, but a hard dependency on something that isn’t on PyPI is out of the question.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2519#issuecomment-1603957399
https://github.com/scverse/scanpy/issues/2519#issuecomment-1603957399:216,Usability,learn,learn,216,"We’re thinking about making the backend configurable through something like https://github.com/frankier/sklearn-ann (that specific one doesn’t seem maintained though). A recipe for this is found here: https://scikit-learn.org/stable/auto_examples/neighbors/approximate_nearest_neighbors.html#sphx-glr-auto-examples-neighbors-approximate-nearest-neighbors-py. Faiss does seem nice as an option, but a hard dependency on something that isn’t on PyPI is out of the question.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2519#issuecomment-1603957399
https://github.com/scverse/scanpy/issues/2520#issuecomment-1598796691:115,Modifiability,layers,layers,115,"I wonder if `dimensions` does too much or too little. Dimensions should always match, no? Flipping just one of the layers while plotting has no use.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2520#issuecomment-1598796691
https://github.com/scverse/scanpy/issues/2520#issuecomment-1605898378:24,Integrability,synchroniz,synchronize,24,"Yes, the image does not synchronize with flipped spatial dots. ; I find a way to flip the image by changing the image coords:; hires_coord = slide.uns['spatial']['sample1']['images'][""hires""]; slide.uns['spatial']['sample1']['images'][""hires""] = hires_coord[:,:,::-1]",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2520#issuecomment-1605898378
https://github.com/scverse/scanpy/pull/2522#issuecomment-1598935568:387,Testability,test,test-utils,387,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2522?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > Merging [#2522](https://app.codecov.io/gh/scverse/scanpy/pull/2522?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) (2753e48) into [test-utils](https://app.codecov.io/gh/scverse/scanpy/commit/9e21b23737eec3584f7ccfd1a73a36929064765e?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) (9e21b23) will **decrease** coverage by `0.48%`.; > The diff coverage is `100.00%`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## test-utils #2522 +/- ##; ==============================================; - Coverage 72.20% 71.73% -0.48% ; ==============================================; Files 103 103 ; Lines 11687 11688 +1 ; ==============================================; - Hits 8439 8384 -55 ; - Misses 3248 3304 +56 ; ```. | [Impacted Files](https://app.codecov.io/gh/scverse/scanpy/pull/2522?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/testing/\_pytest/fixtures/data.py](https://app.codecov.io/gh/scverse/scanpy/pull/2522?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9maXh0dXJlcy9kYXRhLnB5) | `100.00% <100.00%> (ø)` | |. ... and [11 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2522/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2522#issuecomment-1598935568
https://github.com/scverse/scanpy/pull/2522#issuecomment-1598935568:781,Testability,test,test-utils,781,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2522?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > Merging [#2522](https://app.codecov.io/gh/scverse/scanpy/pull/2522?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) (2753e48) into [test-utils](https://app.codecov.io/gh/scverse/scanpy/commit/9e21b23737eec3584f7ccfd1a73a36929064765e?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) (9e21b23) will **decrease** coverage by `0.48%`.; > The diff coverage is `100.00%`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## test-utils #2522 +/- ##; ==============================================; - Coverage 72.20% 71.73% -0.48% ; ==============================================; Files 103 103 ; Lines 11687 11688 +1 ; ==============================================; - Hits 8439 8384 -55 ; - Misses 3248 3304 +56 ; ```. | [Impacted Files](https://app.codecov.io/gh/scverse/scanpy/pull/2522?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/testing/\_pytest/fixtures/data.py](https://app.codecov.io/gh/scverse/scanpy/pull/2522?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9maXh0dXJlcy9kYXRhLnB5) | `100.00% <100.00%> (ø)` | |. ... and [11 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2522/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2522#issuecomment-1598935568
https://github.com/scverse/scanpy/pull/2522#issuecomment-1598935568:1305,Testability,test,testing,1305,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2522?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > Merging [#2522](https://app.codecov.io/gh/scverse/scanpy/pull/2522?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) (2753e48) into [test-utils](https://app.codecov.io/gh/scverse/scanpy/commit/9e21b23737eec3584f7ccfd1a73a36929064765e?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) (9e21b23) will **decrease** coverage by `0.48%`.; > The diff coverage is `100.00%`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## test-utils #2522 +/- ##; ==============================================; - Coverage 72.20% 71.73% -0.48% ; ==============================================; Files 103 103 ; Lines 11687 11688 +1 ; ==============================================; - Hits 8439 8384 -55 ; - Misses 3248 3304 +56 ; ```. | [Impacted Files](https://app.codecov.io/gh/scverse/scanpy/pull/2522?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/testing/\_pytest/fixtures/data.py](https://app.codecov.io/gh/scverse/scanpy/pull/2522?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9maXh0dXJlcy9kYXRhLnB5) | `100.00% <100.00%> (ø)` | |. ... and [11 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2522/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2522#issuecomment-1598935568
https://github.com/scverse/scanpy/pull/2523#issuecomment-1599208625:331,Availability,error,error-reference,331,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2523?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@ec78ca9`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 249ef59 differs from pull request most recent head c69bc0f. Consider uploading reports for the commit c69bc0f to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2523 +/- ##; ========================================; Coverage ? 71.89% ; ========================================; Files ? 98 ; Lines ? 11488 ; Branches ? 0 ; ========================================; Hits ? 8259 ; Misses ? 3229 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2523#issuecomment-1599208625
https://github.com/scverse/scanpy/pull/2523#issuecomment-1599208625:279,Usability,learn,learn,279,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2523?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@ec78ca9`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 249ef59 differs from pull request most recent head c69bc0f. Consider uploading reports for the commit c69bc0f to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2523 +/- ##; ========================================; Coverage ? 71.89% ; ========================================; Files ? 98 ; Lines ? 11488 ; Branches ? 0 ; ========================================; Hits ? 8259 ; Misses ? 3229 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2523#issuecomment-1599208625
https://github.com/scverse/scanpy/pull/2528#issuecomment-1604254568:331,Availability,error,error-reference,331,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2528?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@af11c8f`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2528 +/- ##; ========================================; Coverage ? 72.13% ; ========================================; Files ? 104 ; Lines ? 11648 ; Branches ? 0 ; ========================================; Hits ? 8402 ; Misses ? 3246 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2528#issuecomment-1604254568
https://github.com/scverse/scanpy/pull/2528#issuecomment-1604254568:279,Usability,learn,learn,279,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2528?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@af11c8f`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2528 +/- ##; ========================================; Coverage ? 72.13% ; ========================================; Files ? 104 ; Lines ? 11648 ; Branches ? 0 ; ========================================; Hits ? 8402 ; Misses ? 3246 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2528#issuecomment-1604254568
https://github.com/scverse/scanpy/issues/2530#issuecomment-1609294829:456,Modifiability,flexible,flexible,456,"I see, there’s also code to make that exact shape. Seems like you need to override this as well:. https://github.com/scverse/scanpy/blob/ed3b277b2f498e3cab04c9416aaddf97eec8c3e2/scanpy/plotting/_baseplot_class.py#L522-L542. maybe simply. ```py; def _plot_legend(self, legend_ax, return_ax_dict, normalize): ; self._plot_colorbar(legend_ax, normalize) ; return_ax_dict['color_legend_ax'] = color_legend_ax; ```. but as said: we will start working on a more flexible and less fiddle plotting API",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2530#issuecomment-1609294829
https://github.com/scverse/scanpy/issues/2530#issuecomment-1609294829:230,Usability,simpl,simply,230,"I see, there’s also code to make that exact shape. Seems like you need to override this as well:. https://github.com/scverse/scanpy/blob/ed3b277b2f498e3cab04c9416aaddf97eec8c3e2/scanpy/plotting/_baseplot_class.py#L522-L542. maybe simply. ```py; def _plot_legend(self, legend_ax, return_ax_dict, normalize): ; self._plot_colorbar(legend_ax, normalize) ; return_ax_dict['color_legend_ax'] = color_legend_ax; ```. but as said: we will start working on a more flexible and less fiddle plotting API",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2530#issuecomment-1609294829
https://github.com/scverse/scanpy/issues/2530#issuecomment-1609649845:15,Usability,simpl,simply,15,That should be simply `groupby='sample'` instead of multiple plot calls.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2530#issuecomment-1609649845
https://github.com/scverse/scanpy/issues/2530#issuecomment-1609699372:82,Modifiability,variab,variable,82,"Yes I would like to separate both `sample` and `leiden_r1`, I should create a new variable `adata.obs['leiden+sample']`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2530#issuecomment-1609699372
https://github.com/scverse/scanpy/issues/2531#issuecomment-1607052906:902,Usability,learn,learn,902,"Hm, I can’t reproduce this, but I also can’t reproduce your environment, since scipy 1.9.1 doesn’t build on my system. With this environment, everything worked instantly. Can you try updating your environment?. ```; anndata==0.9.1; asttokens==2.2.1; backcall==0.2.0; contourpy==1.1.0; cycler==0.11.0; decorator==5.1.1; executing==1.2.0; fonttools==4.40.0; h5py==3.9.0; igraph==0.10.4; ipython==8.14.0; jedi==0.18.2; joblib==1.2.0; kiwisolver==1.4.4; llvmlite==0.40.1; louvain==0.8.0; matplotlib==3.7.1; matplotlib-inline==0.1.6; natsort==8.4.0; networkx==3.1; numba==0.57.1; numpy==1.24.3; packaging==23.1; pandas==2.0.2; parso==0.8.3; patsy==0.5.3; pexpect==4.8.0; pickleshare==0.7.5; Pillow==9.5.0; prompt-toolkit==3.0.38; ptyprocess==0.7.0; pure-eval==0.2.2; Pygments==2.15.1; pynndescent==0.5.10; pyparsing==3.1.0; python-dateutil==2.8.2; python-igraph==0.10.4; pytz==2023.3; scanpy==1.9.3; scikit-learn==1.2.2; scipy==1.11.0; seaborn==0.12.2; session-info==1.0.0; six==1.16.0; stack-data==0.6.2; statsmodels==0.14.0; stdlib-list==0.9.0; texttable==1.6.7; threadpoolctl==3.1.0; tqdm==4.65.0; traitlets==5.9.0; tzdata==2023.3; umap-learn==0.5.3; wcwidth==0.2.6; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2531#issuecomment-1607052906
https://github.com/scverse/scanpy/issues/2531#issuecomment-1607052906:1135,Usability,learn,learn,1135,"Hm, I can’t reproduce this, but I also can’t reproduce your environment, since scipy 1.9.1 doesn’t build on my system. With this environment, everything worked instantly. Can you try updating your environment?. ```; anndata==0.9.1; asttokens==2.2.1; backcall==0.2.0; contourpy==1.1.0; cycler==0.11.0; decorator==5.1.1; executing==1.2.0; fonttools==4.40.0; h5py==3.9.0; igraph==0.10.4; ipython==8.14.0; jedi==0.18.2; joblib==1.2.0; kiwisolver==1.4.4; llvmlite==0.40.1; louvain==0.8.0; matplotlib==3.7.1; matplotlib-inline==0.1.6; natsort==8.4.0; networkx==3.1; numba==0.57.1; numpy==1.24.3; packaging==23.1; pandas==2.0.2; parso==0.8.3; patsy==0.5.3; pexpect==4.8.0; pickleshare==0.7.5; Pillow==9.5.0; prompt-toolkit==3.0.38; ptyprocess==0.7.0; pure-eval==0.2.2; Pygments==2.15.1; pynndescent==0.5.10; pyparsing==3.1.0; python-dateutil==2.8.2; python-igraph==0.10.4; pytz==2023.3; scanpy==1.9.3; scikit-learn==1.2.2; scipy==1.11.0; seaborn==0.12.2; session-info==1.0.0; six==1.16.0; stack-data==0.6.2; statsmodels==0.14.0; stdlib-list==0.9.0; texttable==1.6.7; threadpoolctl==3.1.0; tqdm==4.65.0; traitlets==5.9.0; tzdata==2023.3; umap-learn==0.5.3; wcwidth==0.2.6; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2531#issuecomment-1607052906
https://github.com/scverse/scanpy/issues/2531#issuecomment-1608050519:144,Deployability,update,updated,144,"Thanks for getting back to me. I tried updating the environment (spicy now at 1.11.0), and it's still hanging during the PCA step. Here are the updated versions:. ### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.3; -----; CoreFoundation NA; Foundation NA; PIL 9.5.0; PyObjCTools NA; anyio NA; appnope 0.1.3; argcomplete NA; asttokens NA; attr 23.1.0; babel 2.12.1; backcall 0.2.0; certifi 2023.05.07; cffi 1.15.1; charset_normalizer 3.1.0; cloudpickle 2.2.1; colorama 0.4.6; comm 0.1.3; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.0; dask 2023.6.0; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; defusedxml 0.7.1; executing 1.2.0; fastjsonschema NA; google NA; h5py 3.9.0; idna 3.4; igraph 0.10.4; importlib_resources NA; ipykernel 6.23.3; ipython_genutils 0.2.0; ipywidgets 8.0.6; jedi 0.18.2; jinja2 3.1.2; joblib 1.2.0; json5 NA; jsonschema 4.17.3; jupyter_events 0.6.3; jupyter_server 2.6.0; jupyterlab_server 2.23.0; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.40.0; louvain 0.8.0; markupsafe 2.1.3; matplotlib 3.7.1; mpl_toolkits NA; natsort 8.4.0; nbformat 5.9.0; numba 0.57.0; numexpr 2.8.4; numpy 1.24.3; objc 9.2; overrides NA; packaging 23.1; pandas 2.0.2; parso 0.8.3; patsy 0.5.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.8.0; prometheus_client NA; prompt_toolkit 3.0.38; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pvectorc NA; pydev_jupyter_utils NA; pydev_jupyter_vars NA; pydevconsole NA; pydevd_file_utils NA; pydevd_plugins NA; pygments 2.15.1; pyparsing 3.1.0; pyrsistent NA; pythonjsonlogger NA; pytz 2023.3; requests 2.31.0; rfc3339_validator 0.1.4; rfc3986_validator 0.1.1; scipy 1.11.0; seaborn 0.12.2; send2trash NA; session_info 1.0.0; setuptools 68.0.0; six 1.16.0; sklearn 1.2.2; sniffio 1.3.0; socks 1.7.1; stack_data 0.6.2; statsmodels 0.14.0; texttable 1.6.7; threadpoolctl 3.1.0; tlz 0.12.0; toolz 0.12.0; torch 1.12.1; tornado 6.3.2; tqdm 4.65.0; traitlets 5.9.0; typing_extensions NA; urllib3 2.0.3; wcwidth 0.2.6; w",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2531#issuecomment-1608050519
https://github.com/scverse/scanpy/issues/2531#issuecomment-1608050519:2314,Deployability,update,updated,2314,"3.1.0; babel 2.12.1; backcall 0.2.0; certifi 2023.05.07; cffi 1.15.1; charset_normalizer 3.1.0; cloudpickle 2.2.1; colorama 0.4.6; comm 0.1.3; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.0; dask 2023.6.0; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; defusedxml 0.7.1; executing 1.2.0; fastjsonschema NA; google NA; h5py 3.9.0; idna 3.4; igraph 0.10.4; importlib_resources NA; ipykernel 6.23.3; ipython_genutils 0.2.0; ipywidgets 8.0.6; jedi 0.18.2; jinja2 3.1.2; joblib 1.2.0; json5 NA; jsonschema 4.17.3; jupyter_events 0.6.3; jupyter_server 2.6.0; jupyterlab_server 2.23.0; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.40.0; louvain 0.8.0; markupsafe 2.1.3; matplotlib 3.7.1; mpl_toolkits NA; natsort 8.4.0; nbformat 5.9.0; numba 0.57.0; numexpr 2.8.4; numpy 1.24.3; objc 9.2; overrides NA; packaging 23.1; pandas 2.0.2; parso 0.8.3; patsy 0.5.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.8.0; prometheus_client NA; prompt_toolkit 3.0.38; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pvectorc NA; pydev_jupyter_utils NA; pydev_jupyter_vars NA; pydevconsole NA; pydevd_file_utils NA; pydevd_plugins NA; pygments 2.15.1; pyparsing 3.1.0; pyrsistent NA; pythonjsonlogger NA; pytz 2023.3; requests 2.31.0; rfc3339_validator 0.1.4; rfc3986_validator 0.1.1; scipy 1.11.0; seaborn 0.12.2; send2trash NA; session_info 1.0.0; setuptools 68.0.0; six 1.16.0; sklearn 1.2.2; sniffio 1.3.0; socks 1.7.1; stack_data 0.6.2; statsmodels 0.14.0; texttable 1.6.7; threadpoolctl 3.1.0; tlz 0.12.0; toolz 0.12.0; torch 1.12.1; tornado 6.3.2; tqdm 4.65.0; traitlets 5.9.0; typing_extensions NA; urllib3 2.0.3; wcwidth 0.2.6; websocket 1.6.1; yaml 6.0; zipp NA; zmq 25.1.0; zoneinfo NA; -----; IPython 8.14.0; jupyter_client 8.3.0; jupyter_core 5.3.1; jupyterlab 4.0.2; notebook 6.5.4; -----; Python 3.9.16 | packaged by conda-forge | (main, Feb 1 2023, 21:42:20) [Clang 14.0.6 ]; macOS-12.6.6-x86_64-i386-64bit; -----; Session information updated at 2023-06-26 14:43. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2531#issuecomment-1608050519
https://github.com/scverse/scanpy/issues/2531#issuecomment-1609286107:38,Availability,avail,available,38,"Hm, PyTorch 1.12.1 doesn’t seem to be available, otherwise I was able to install all package versions you specified. I created an attempt at a reproducer here, but it just runs in less than a second for me: https://github.com/flying-sheep/scanpy-2531. No idea how to further debug this. Looks like you’re on macOS. one of the new M1 or M2 ones?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2531#issuecomment-1609286107
https://github.com/scverse/scanpy/issues/2531#issuecomment-1609286107:73,Deployability,install,install,73,"Hm, PyTorch 1.12.1 doesn’t seem to be available, otherwise I was able to install all package versions you specified. I created an attempt at a reproducer here, but it just runs in less than a second for me: https://github.com/flying-sheep/scanpy-2531. No idea how to further debug this. Looks like you’re on macOS. one of the new M1 or M2 ones?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2531#issuecomment-1609286107
https://github.com/scverse/scanpy/issues/2531#issuecomment-1619051615:196,Availability,down,download,196,"Thanks for getting back. I ran the reproducer on my system and it indeed works perfectly. Very weird. . When I ran the reproducer, I did get one warning:; ```; WARNING: The candidate selected for download or install is a yanked version: 'scipy' candidate (version 1.11.0 at https://files.pythonhosted.org/packages/2f/b5/b5387cdafc66805907424c3a95f773b84a5d452a0925801c6218727a766e/scipy-1.11.0-cp311-cp311-macosx_10_9_x86_64.whl (from https://pypi.org/simple/scipy/) (requires-python:<3.13,>=3.9)); Reason for being yanked: License Violation; ```; Other than that, it worked fine. I have a feeling it might be an issue with the installation? That scipy warning is suspicious? I'm using mamba (mambaforge specifically) to manage my packages, maybe something went wrong there. Have you hear of any issues with mamba? Let me trouble shoot my environment and I'll report back. . Yes, I am running macOS, but it's not the Apple Silicon, I'm still using the older Intel processors.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2531#issuecomment-1619051615
https://github.com/scverse/scanpy/issues/2531#issuecomment-1619051615:208,Deployability,install,install,208,"Thanks for getting back. I ran the reproducer on my system and it indeed works perfectly. Very weird. . When I ran the reproducer, I did get one warning:; ```; WARNING: The candidate selected for download or install is a yanked version: 'scipy' candidate (version 1.11.0 at https://files.pythonhosted.org/packages/2f/b5/b5387cdafc66805907424c3a95f773b84a5d452a0925801c6218727a766e/scipy-1.11.0-cp311-cp311-macosx_10_9_x86_64.whl (from https://pypi.org/simple/scipy/) (requires-python:<3.13,>=3.9)); Reason for being yanked: License Violation; ```; Other than that, it worked fine. I have a feeling it might be an issue with the installation? That scipy warning is suspicious? I'm using mamba (mambaforge specifically) to manage my packages, maybe something went wrong there. Have you hear of any issues with mamba? Let me trouble shoot my environment and I'll report back. . Yes, I am running macOS, but it's not the Apple Silicon, I'm still using the older Intel processors.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2531#issuecomment-1619051615
https://github.com/scverse/scanpy/issues/2531#issuecomment-1619051615:628,Deployability,install,installation,628,"Thanks for getting back. I ran the reproducer on my system and it indeed works perfectly. Very weird. . When I ran the reproducer, I did get one warning:; ```; WARNING: The candidate selected for download or install is a yanked version: 'scipy' candidate (version 1.11.0 at https://files.pythonhosted.org/packages/2f/b5/b5387cdafc66805907424c3a95f773b84a5d452a0925801c6218727a766e/scipy-1.11.0-cp311-cp311-macosx_10_9_x86_64.whl (from https://pypi.org/simple/scipy/) (requires-python:<3.13,>=3.9)); Reason for being yanked: License Violation; ```; Other than that, it worked fine. I have a feeling it might be an issue with the installation? That scipy warning is suspicious? I'm using mamba (mambaforge specifically) to manage my packages, maybe something went wrong there. Have you hear of any issues with mamba? Let me trouble shoot my environment and I'll report back. . Yes, I am running macOS, but it's not the Apple Silicon, I'm still using the older Intel processors.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2531#issuecomment-1619051615
https://github.com/scverse/scanpy/issues/2531#issuecomment-1619051615:452,Usability,simpl,simple,452,"Thanks for getting back. I ran the reproducer on my system and it indeed works perfectly. Very weird. . When I ran the reproducer, I did get one warning:; ```; WARNING: The candidate selected for download or install is a yanked version: 'scipy' candidate (version 1.11.0 at https://files.pythonhosted.org/packages/2f/b5/b5387cdafc66805907424c3a95f773b84a5d452a0925801c6218727a766e/scipy-1.11.0-cp311-cp311-macosx_10_9_x86_64.whl (from https://pypi.org/simple/scipy/) (requires-python:<3.13,>=3.9)); Reason for being yanked: License Violation; ```; Other than that, it worked fine. I have a feeling it might be an issue with the installation? That scipy warning is suspicious? I'm using mamba (mambaforge specifically) to manage my packages, maybe something went wrong there. Have you hear of any issues with mamba? Let me trouble shoot my environment and I'll report back. . Yes, I am running macOS, but it's not the Apple Silicon, I'm still using the older Intel processors.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2531#issuecomment-1619051615
https://github.com/scverse/scanpy/pull/2538#issuecomment-1609797792:331,Availability,error,error-reference,331,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2538?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@120dcd0`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2538 +/- ##; ========================================; Coverage ? 72.13% ; ========================================; Files ? 104 ; Lines ? 11648 ; Branches ? 0 ; ========================================; Hits ? 8402 ; Misses ? 3246 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2538#issuecomment-1609797792
https://github.com/scverse/scanpy/pull/2538#issuecomment-1609797792:279,Usability,learn,learn,279,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2538?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@120dcd0`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2538 +/- ##; ========================================; Coverage ? 72.13% ; ========================================; Files ? 104 ; Lines ? 11648 ; Branches ? 0 ; ========================================; Hits ? 8402 ; Misses ? 3246 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2538#issuecomment-1609797792
https://github.com/scverse/scanpy/issues/2540#issuecomment-1612612204:15,Deployability,update,update,15,can you please update your code sample so we can just copy and paste it? There’s an `import scanpy as ac` and a `adata = ???` missing,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2540#issuecomment-1612612204
https://github.com/scverse/scanpy/pull/2544#issuecomment-1619899808:157,Deployability,update,update,157,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 5ccce795b19a5aa59a6b1f1c3552884ed6fc94d1; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2544: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2544-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2544 on branch 1.9.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2544#issuecomment-1619899808
https://github.com/scverse/scanpy/pull/2544#issuecomment-1619899808:913,Deployability,continuous,continuous,913,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 5ccce795b19a5aa59a6b1f1c3552884ed6fc94d1; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2544: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2544-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2544 on branch 1.9.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2544#issuecomment-1619899808
https://github.com/scverse/scanpy/pull/2544#issuecomment-1619899808:924,Deployability,integrat,integration,924,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 5ccce795b19a5aa59a6b1f1c3552884ed6fc94d1; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2544: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2544-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2544 on branch 1.9.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2544#issuecomment-1619899808
https://github.com/scverse/scanpy/pull/2544#issuecomment-1619899808:924,Integrability,integrat,integration,924,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 5ccce795b19a5aa59a6b1f1c3552884ed6fc94d1; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2544: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2544-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2544 on branch 1.9.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2544#issuecomment-1619899808
https://github.com/scverse/scanpy/pull/2544#issuecomment-1619899808:899,Testability,test,tested,899,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 5ccce795b19a5aa59a6b1f1c3552884ed6fc94d1; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2544: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2544-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2544 on branch 1.9.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2544#issuecomment-1619899808
https://github.com/scverse/scanpy/pull/2545#issuecomment-1626372312:19,Testability,test,testing,19,"> Nice! Needs some testing though to make sure it works (e.g. specifying a sequence of markers); > ; > You should also make sure the types are correct: `Optional[X]` means `X | None`. Is `None` a valid option? Does it make sense that the type is different in multiple spots? (`Optional[Sequence[str]]` vs `Union[str, Sequence[str], None]` vs `Union[str, Sequence[str]]`). You're absolutely right about the types. I changed the types such as all are accepting the same `Union[str, Sequence[str]]` now.; I also tested several situations I could think of, in [this notebook](https://colab.research.google.com/drive/1ltg0Qs_dlxS_RMuN7z1DdLLV7VLBtZtd?usp=sharing) and they all worked fine. If any more tests (different situations) are needed, please let me know.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2545#issuecomment-1626372312
https://github.com/scverse/scanpy/pull/2545#issuecomment-1626372312:509,Testability,test,tested,509,"> Nice! Needs some testing though to make sure it works (e.g. specifying a sequence of markers); > ; > You should also make sure the types are correct: `Optional[X]` means `X | None`. Is `None` a valid option? Does it make sense that the type is different in multiple spots? (`Optional[Sequence[str]]` vs `Union[str, Sequence[str], None]` vs `Union[str, Sequence[str]]`). You're absolutely right about the types. I changed the types such as all are accepting the same `Union[str, Sequence[str]]` now.; I also tested several situations I could think of, in [this notebook](https://colab.research.google.com/drive/1ltg0Qs_dlxS_RMuN7z1DdLLV7VLBtZtd?usp=sharing) and they all worked fine. If any more tests (different situations) are needed, please let me know.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2545#issuecomment-1626372312
https://github.com/scverse/scanpy/pull/2545#issuecomment-1626372312:697,Testability,test,tests,697,"> Nice! Needs some testing though to make sure it works (e.g. specifying a sequence of markers); > ; > You should also make sure the types are correct: `Optional[X]` means `X | None`. Is `None` a valid option? Does it make sense that the type is different in multiple spots? (`Optional[Sequence[str]]` vs `Union[str, Sequence[str], None]` vs `Union[str, Sequence[str]]`). You're absolutely right about the types. I changed the types such as all are accepting the same `Union[str, Sequence[str]]` now.; I also tested several situations I could think of, in [this notebook](https://colab.research.google.com/drive/1ltg0Qs_dlxS_RMuN7z1DdLLV7VLBtZtd?usp=sharing) and they all worked fine. If any more tests (different situations) are needed, please let me know.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2545#issuecomment-1626372312
https://github.com/scverse/scanpy/pull/2545#issuecomment-1631074929:23,Testability,test,test,23,"I’m talking about unit test. please add one here. You can just add one or more parameter sets to the list, and the test will create a file at `scanpy/tests/figures/master_{id}.png`.; Just copy that file to `scanpy/tests/_images/` and commit it together with the added test. https://github.com/scverse/scanpy/blob/9c6996f374370a7d50768c634e76e50173d22839/scanpy/tests/test_plotting.py#L973-L1082. if you need help, please tell us!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2545#issuecomment-1631074929
https://github.com/scverse/scanpy/pull/2545#issuecomment-1631074929:115,Testability,test,test,115,"I’m talking about unit test. please add one here. You can just add one or more parameter sets to the list, and the test will create a file at `scanpy/tests/figures/master_{id}.png`.; Just copy that file to `scanpy/tests/_images/` and commit it together with the added test. https://github.com/scverse/scanpy/blob/9c6996f374370a7d50768c634e76e50173d22839/scanpy/tests/test_plotting.py#L973-L1082. if you need help, please tell us!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2545#issuecomment-1631074929
https://github.com/scverse/scanpy/pull/2545#issuecomment-1631074929:150,Testability,test,tests,150,"I’m talking about unit test. please add one here. You can just add one or more parameter sets to the list, and the test will create a file at `scanpy/tests/figures/master_{id}.png`.; Just copy that file to `scanpy/tests/_images/` and commit it together with the added test. https://github.com/scverse/scanpy/blob/9c6996f374370a7d50768c634e76e50173d22839/scanpy/tests/test_plotting.py#L973-L1082. if you need help, please tell us!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2545#issuecomment-1631074929
https://github.com/scverse/scanpy/pull/2545#issuecomment-1631074929:214,Testability,test,tests,214,"I’m talking about unit test. please add one here. You can just add one or more parameter sets to the list, and the test will create a file at `scanpy/tests/figures/master_{id}.png`.; Just copy that file to `scanpy/tests/_images/` and commit it together with the added test. https://github.com/scverse/scanpy/blob/9c6996f374370a7d50768c634e76e50173d22839/scanpy/tests/test_plotting.py#L973-L1082. if you need help, please tell us!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2545#issuecomment-1631074929
https://github.com/scverse/scanpy/pull/2545#issuecomment-1631074929:268,Testability,test,test,268,"I’m talking about unit test. please add one here. You can just add one or more parameter sets to the list, and the test will create a file at `scanpy/tests/figures/master_{id}.png`.; Just copy that file to `scanpy/tests/_images/` and commit it together with the added test. https://github.com/scverse/scanpy/blob/9c6996f374370a7d50768c634e76e50173d22839/scanpy/tests/test_plotting.py#L973-L1082. if you need help, please tell us!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2545#issuecomment-1631074929
https://github.com/scverse/scanpy/pull/2545#issuecomment-1631074929:361,Testability,test,tests,361,"I’m talking about unit test. please add one here. You can just add one or more parameter sets to the list, and the test will create a file at `scanpy/tests/figures/master_{id}.png`.; Just copy that file to `scanpy/tests/_images/` and commit it together with the added test. https://github.com/scverse/scanpy/blob/9c6996f374370a7d50768c634e76e50173d22839/scanpy/tests/test_plotting.py#L973-L1082. if you need help, please tell us!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2545#issuecomment-1631074929
https://github.com/scverse/scanpy/pull/2545#issuecomment-1631633257:239,Availability,error,error,239,"Thanks for the reference, I added a number of tests to where you mentioned. I also changed the `broadcasting` method for `markers` so now it has the same process as `color` and `dimensions`, and therefore if broadcasting fails, the output error is more understandable (same as when `color` and `dimensions` broadcasting fails). I also added a test for `marker broadcasting`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2545#issuecomment-1631633257
https://github.com/scverse/scanpy/pull/2545#issuecomment-1631633257:46,Testability,test,tests,46,"Thanks for the reference, I added a number of tests to where you mentioned. I also changed the `broadcasting` method for `markers` so now it has the same process as `color` and `dimensions`, and therefore if broadcasting fails, the output error is more understandable (same as when `color` and `dimensions` broadcasting fails). I also added a test for `marker broadcasting`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2545#issuecomment-1631633257
https://github.com/scverse/scanpy/pull/2545#issuecomment-1631633257:343,Testability,test,test,343,"Thanks for the reference, I added a number of tests to where you mentioned. I also changed the `broadcasting` method for `markers` so now it has the same process as `color` and `dimensions`, and therefore if broadcasting fails, the output error is more understandable (same as when `color` and `dimensions` broadcasting fails). I also added a test for `marker broadcasting`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2545#issuecomment-1631633257
https://github.com/scverse/scanpy/pull/2546#issuecomment-1625353939:10,Testability,test,test,10,I added a test that fails on master,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2546#issuecomment-1625353939
https://github.com/scverse/scanpy/issues/2547#issuecomment-1624533422:101,Energy Efficiency,reduce,reduce,101,I realized that this is an issue originated from coercing the sparse matrix to be of np.int8 type to reduce the size the ann object and the mtx file to be written for another application. Making it np.int32 fixes the issue.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2547#issuecomment-1624533422
https://github.com/scverse/scanpy/issues/2547#issuecomment-1689304524:51,Availability,error,error,51,"@maximillo Hi, sorry to bother you, I met the same error. But I don't konw how to change np.int8 to np.int32. Any help would be greatly appreciated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2547#issuecomment-1689304524
https://github.com/scverse/scanpy/pull/2549#issuecomment-1625396556:331,Availability,error,error-reference,331,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2549?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@c40d2ee`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2549 +/- ##; ========================================; Coverage ? 72.13% ; ========================================; Files ? 104 ; Lines ? 11648 ; Branches ? 0 ; ========================================; Hits ? 8402 ; Misses ? 3246 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2549#issuecomment-1625396556
https://github.com/scverse/scanpy/pull/2549#issuecomment-1625396556:279,Usability,learn,learn,279,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2549?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@c40d2ee`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2549 +/- ##; ========================================; Coverage ? 72.13% ; ========================================; Files ? 104 ; Lines ? 11648 ; Branches ? 0 ; ========================================; Hits ? 8402 ; Misses ? 3246 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2549#issuecomment-1625396556
https://github.com/scverse/scanpy/issues/2550#issuecomment-1640143156:284,Modifiability,enhance,enhance,284,"I’m not 100% up to date, but if you want more fancy differential expression analysis than what `rank_genes_groups` provides, you should give https://github.com/theislab/diffxpy a shot!. @davidsebfischer it’s maintained, right?. I’m going to close this unless I’m wrong and we want to enhance `rank_genes_groups` after all",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2550#issuecomment-1640143156
https://github.com/scverse/scanpy/issues/2550#issuecomment-1640417629:298,Modifiability,enhance,enhance,298,"> I’m not 100% up to date, but if you want more fancy differential expression analysis than what `rank_genes_groups` provides, you should give https://github.com/theislab/diffxpy a shot!; > ; > @davidsebfischer it’s maintained, right?; > ; > I’m going to close this unless I’m wrong and we want to enhance `rank_genes_groups` after all. Hi Philipp, I will try diffxpy. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2550#issuecomment-1640417629
https://github.com/scverse/scanpy/issues/2551#issuecomment-1630946384:74,Availability,error,error,74,"I’m unsure if we can help you with this, as it’s your system creating his error and we don’t have access to the data. There’s multiple possible causes and solutions:. - a misunderstanding: The arrays should require `310385 * 8563 * 8B = 21.3 GB`, no idea why it says 10. But of course that’s still not close to 100GB unless other people/processes are using the machine, or other arrays are allocated. Can you track the memory usage and see if it spikes close to the maximum before the code crashes?; - our implementation allocates memory it shouldn’t: this is the only one we can fix, but we’d have to figure out under which circumstances that happens, and where in our code.; - some machine problem, [like many people on stackoverflow](https://www.google.com/search?q=site%3Astackoverflow.com+%22Unable+to+allocate%22+%22GiB+for+an+array+with+shape%22+%22and+data+type%22): maybe your sysadmin can help?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2551#issuecomment-1630946384
https://github.com/scverse/scanpy/issues/2551#issuecomment-1630946384:390,Energy Efficiency,allocate,allocated,390,"I’m unsure if we can help you with this, as it’s your system creating his error and we don’t have access to the data. There’s multiple possible causes and solutions:. - a misunderstanding: The arrays should require `310385 * 8563 * 8B = 21.3 GB`, no idea why it says 10. But of course that’s still not close to 100GB unless other people/processes are using the machine, or other arrays are allocated. Can you track the memory usage and see if it spikes close to the maximum before the code crashes?; - our implementation allocates memory it shouldn’t: this is the only one we can fix, but we’d have to figure out under which circumstances that happens, and where in our code.; - some machine problem, [like many people on stackoverflow](https://www.google.com/search?q=site%3Astackoverflow.com+%22Unable+to+allocate%22+%22GiB+for+an+array+with+shape%22+%22and+data+type%22): maybe your sysadmin can help?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2551#issuecomment-1630946384
https://github.com/scverse/scanpy/issues/2551#issuecomment-1630946384:521,Energy Efficiency,allocate,allocates,521,"I’m unsure if we can help you with this, as it’s your system creating his error and we don’t have access to the data. There’s multiple possible causes and solutions:. - a misunderstanding: The arrays should require `310385 * 8563 * 8B = 21.3 GB`, no idea why it says 10. But of course that’s still not close to 100GB unless other people/processes are using the machine, or other arrays are allocated. Can you track the memory usage and see if it spikes close to the maximum before the code crashes?; - our implementation allocates memory it shouldn’t: this is the only one we can fix, but we’d have to figure out under which circumstances that happens, and where in our code.; - some machine problem, [like many people on stackoverflow](https://www.google.com/search?q=site%3Astackoverflow.com+%22Unable+to+allocate%22+%22GiB+for+an+array+with+shape%22+%22and+data+type%22): maybe your sysadmin can help?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2551#issuecomment-1630946384
https://github.com/scverse/scanpy/issues/2551#issuecomment-1630946384:807,Energy Efficiency,allocate,allocate,807,"I’m unsure if we can help you with this, as it’s your system creating his error and we don’t have access to the data. There’s multiple possible causes and solutions:. - a misunderstanding: The arrays should require `310385 * 8563 * 8B = 21.3 GB`, no idea why it says 10. But of course that’s still not close to 100GB unless other people/processes are using the machine, or other arrays are allocated. Can you track the memory usage and see if it spikes close to the maximum before the code crashes?; - our implementation allocates memory it shouldn’t: this is the only one we can fix, but we’d have to figure out under which circumstances that happens, and where in our code.; - some machine problem, [like many people on stackoverflow](https://www.google.com/search?q=site%3Astackoverflow.com+%22Unable+to+allocate%22+%22GiB+for+an+array+with+shape%22+%22and+data+type%22): maybe your sysadmin can help?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2551#issuecomment-1630946384
https://github.com/scverse/scanpy/issues/2551#issuecomment-1630946384:98,Security,access,access,98,"I’m unsure if we can help you with this, as it’s your system creating his error and we don’t have access to the data. There’s multiple possible causes and solutions:. - a misunderstanding: The arrays should require `310385 * 8563 * 8B = 21.3 GB`, no idea why it says 10. But of course that’s still not close to 100GB unless other people/processes are using the machine, or other arrays are allocated. Can you track the memory usage and see if it spikes close to the maximum before the code crashes?; - our implementation allocates memory it shouldn’t: this is the only one we can fix, but we’d have to figure out under which circumstances that happens, and where in our code.; - some machine problem, [like many people on stackoverflow](https://www.google.com/search?q=site%3Astackoverflow.com+%22Unable+to+allocate%22+%22GiB+for+an+array+with+shape%22+%22and+data+type%22): maybe your sysadmin can help?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2551#issuecomment-1630946384
https://github.com/scverse/scanpy/issues/2551#issuecomment-1640426447:76,Availability,error,error,76,"> I’m unsure if we can help you with this, as it’s your system creating his error and we don’t have access to the data. There’s multiple possible causes and solutions:; > ; > * a misunderstanding: The arrays should require `310385 * 8563 * 8B = 21.3 GB`, no idea why it says 10. But of course that’s still not close to 100GB unless other people/processes are using the machine, or other arrays are allocated. Can you track the memory usage and see if it spikes close to the maximum before the code crashes?; > * our implementation allocates memory it shouldn’t: this is the only one we can fix, but we’d have to figure out under which circumstances that happens, and where in our code.; > * some machine problem, [like many people on stackoverflow](https://www.google.com/search?q=site%3Astackoverflow.com+%22Unable+to+allocate%22+%22GiB+for+an+array+with+shape%22+%22and+data+type%22): maybe your sysadmin can help?. Thank you so much for all your assistance and detailed suggestion, I really appreciate it. I tracked the memory usage and found out that the free system memory is only about 5 GB, so apparently I have misunderstood the concept of ""memory usage"" before......Now I am going to turn to people who have encountered the same machine problem on stackoverflow and see if there is some advice. Thank you again for your time and attention!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2551#issuecomment-1640426447
https://github.com/scverse/scanpy/issues/2551#issuecomment-1640426447:398,Energy Efficiency,allocate,allocated,398,"> I’m unsure if we can help you with this, as it’s your system creating his error and we don’t have access to the data. There’s multiple possible causes and solutions:; > ; > * a misunderstanding: The arrays should require `310385 * 8563 * 8B = 21.3 GB`, no idea why it says 10. But of course that’s still not close to 100GB unless other people/processes are using the machine, or other arrays are allocated. Can you track the memory usage and see if it spikes close to the maximum before the code crashes?; > * our implementation allocates memory it shouldn’t: this is the only one we can fix, but we’d have to figure out under which circumstances that happens, and where in our code.; > * some machine problem, [like many people on stackoverflow](https://www.google.com/search?q=site%3Astackoverflow.com+%22Unable+to+allocate%22+%22GiB+for+an+array+with+shape%22+%22and+data+type%22): maybe your sysadmin can help?. Thank you so much for all your assistance and detailed suggestion, I really appreciate it. I tracked the memory usage and found out that the free system memory is only about 5 GB, so apparently I have misunderstood the concept of ""memory usage"" before......Now I am going to turn to people who have encountered the same machine problem on stackoverflow and see if there is some advice. Thank you again for your time and attention!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2551#issuecomment-1640426447
https://github.com/scverse/scanpy/issues/2551#issuecomment-1640426447:531,Energy Efficiency,allocate,allocates,531,"> I’m unsure if we can help you with this, as it’s your system creating his error and we don’t have access to the data. There’s multiple possible causes and solutions:; > ; > * a misunderstanding: The arrays should require `310385 * 8563 * 8B = 21.3 GB`, no idea why it says 10. But of course that’s still not close to 100GB unless other people/processes are using the machine, or other arrays are allocated. Can you track the memory usage and see if it spikes close to the maximum before the code crashes?; > * our implementation allocates memory it shouldn’t: this is the only one we can fix, but we’d have to figure out under which circumstances that happens, and where in our code.; > * some machine problem, [like many people on stackoverflow](https://www.google.com/search?q=site%3Astackoverflow.com+%22Unable+to+allocate%22+%22GiB+for+an+array+with+shape%22+%22and+data+type%22): maybe your sysadmin can help?. Thank you so much for all your assistance and detailed suggestion, I really appreciate it. I tracked the memory usage and found out that the free system memory is only about 5 GB, so apparently I have misunderstood the concept of ""memory usage"" before......Now I am going to turn to people who have encountered the same machine problem on stackoverflow and see if there is some advice. Thank you again for your time and attention!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2551#issuecomment-1640426447
https://github.com/scverse/scanpy/issues/2551#issuecomment-1640426447:819,Energy Efficiency,allocate,allocate,819,"> I’m unsure if we can help you with this, as it’s your system creating his error and we don’t have access to the data. There’s multiple possible causes and solutions:; > ; > * a misunderstanding: The arrays should require `310385 * 8563 * 8B = 21.3 GB`, no idea why it says 10. But of course that’s still not close to 100GB unless other people/processes are using the machine, or other arrays are allocated. Can you track the memory usage and see if it spikes close to the maximum before the code crashes?; > * our implementation allocates memory it shouldn’t: this is the only one we can fix, but we’d have to figure out under which circumstances that happens, and where in our code.; > * some machine problem, [like many people on stackoverflow](https://www.google.com/search?q=site%3Astackoverflow.com+%22Unable+to+allocate%22+%22GiB+for+an+array+with+shape%22+%22and+data+type%22): maybe your sysadmin can help?. Thank you so much for all your assistance and detailed suggestion, I really appreciate it. I tracked the memory usage and found out that the free system memory is only about 5 GB, so apparently I have misunderstood the concept of ""memory usage"" before......Now I am going to turn to people who have encountered the same machine problem on stackoverflow and see if there is some advice. Thank you again for your time and attention!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2551#issuecomment-1640426447
https://github.com/scverse/scanpy/issues/2551#issuecomment-1640426447:100,Security,access,access,100,"> I’m unsure if we can help you with this, as it’s your system creating his error and we don’t have access to the data. There’s multiple possible causes and solutions:; > ; > * a misunderstanding: The arrays should require `310385 * 8563 * 8B = 21.3 GB`, no idea why it says 10. But of course that’s still not close to 100GB unless other people/processes are using the machine, or other arrays are allocated. Can you track the memory usage and see if it spikes close to the maximum before the code crashes?; > * our implementation allocates memory it shouldn’t: this is the only one we can fix, but we’d have to figure out under which circumstances that happens, and where in our code.; > * some machine problem, [like many people on stackoverflow](https://www.google.com/search?q=site%3Astackoverflow.com+%22Unable+to+allocate%22+%22GiB+for+an+array+with+shape%22+%22and+data+type%22): maybe your sysadmin can help?. Thank you so much for all your assistance and detailed suggestion, I really appreciate it. I tracked the memory usage and found out that the free system memory is only about 5 GB, so apparently I have misunderstood the concept of ""memory usage"" before......Now I am going to turn to people who have encountered the same machine problem on stackoverflow and see if there is some advice. Thank you again for your time and attention!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2551#issuecomment-1640426447
https://github.com/scverse/scanpy/issues/2556#issuecomment-1643597794:162,Modifiability,layers,layers,162,"This is the anndata working properly:; ```; AnnData object with n_obs × n_vars = 24759 × 29612; obs: 'sample', 'batch', 'n_counts'; var: 'ensembl_id', 'n_cells'; layers: 'counts'; ```; After normalization and logarithmize it with:; ```; adata.X = sc.pp.normalize_total(adata, inplace=False)['X']; adata.X = sc.pp.log1p(adata.X); ```; And computing PCAs, neighbors and UMAP coordinates this is a plot showing the expression of GRIK1 f.e:. ![image](https://github.com/scverse/scanpy/assets/94078098/b2a1cc8e-d4d8-4a32-91e3-a2a55857a140). Then, this is the anndata that after normalization does not show gene expression in UMAP:; ```; AnnData object with n_obs × n_vars = 17217 × 33704; obs: 'Age', 'Condition', 'Origin', 'Region', 'Sex', 'Subject', 'louvain', 'louvain6', 'obs_names', 'sample', 'batch', 'dataset'; var: 'dispersions', 'dispersions_norm', 'gene_ids', 'highly_variable', 'means', 'n_cells', 'var_names'; obsm: 'X_umap'; layers: 'counts'; ```; Because this anndata has pre-computed UMAP coordinates and the raw data was normalized with sizefactors in R, when reading the file, adata.X is already normalized, and if I plot the UMAP for SLC5A11 f.e this is the result: ; ![image](https://github.com/scverse/scanpy/assets/94078098/9e0c6958-b882-4f28-b7ac-dda5d58cbcba). However, if I select the raw counts of this anndata (stored in layers['counts']) and normalize it with `sc.pp.normalize `function and logarithmize it, this is the output of `sc.pl.umap` (it doesn't matter re-computing PCAs, neighbors and UMAP):; ![image](https://github.com/scverse/scanpy/assets/94078098/365ec629-3eea-4e58-ad0d-6ff3004d3c13). UMAP after recomputing PCAs, etc:; ![image](https://github.com/scverse/scanpy/assets/94078098/6727a53b-31ac-414a-b93d-55baa1688f85)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2556#issuecomment-1643597794
https://github.com/scverse/scanpy/issues/2556#issuecomment-1643597794:933,Modifiability,layers,layers,933,"This is the anndata working properly:; ```; AnnData object with n_obs × n_vars = 24759 × 29612; obs: 'sample', 'batch', 'n_counts'; var: 'ensembl_id', 'n_cells'; layers: 'counts'; ```; After normalization and logarithmize it with:; ```; adata.X = sc.pp.normalize_total(adata, inplace=False)['X']; adata.X = sc.pp.log1p(adata.X); ```; And computing PCAs, neighbors and UMAP coordinates this is a plot showing the expression of GRIK1 f.e:. ![image](https://github.com/scverse/scanpy/assets/94078098/b2a1cc8e-d4d8-4a32-91e3-a2a55857a140). Then, this is the anndata that after normalization does not show gene expression in UMAP:; ```; AnnData object with n_obs × n_vars = 17217 × 33704; obs: 'Age', 'Condition', 'Origin', 'Region', 'Sex', 'Subject', 'louvain', 'louvain6', 'obs_names', 'sample', 'batch', 'dataset'; var: 'dispersions', 'dispersions_norm', 'gene_ids', 'highly_variable', 'means', 'n_cells', 'var_names'; obsm: 'X_umap'; layers: 'counts'; ```; Because this anndata has pre-computed UMAP coordinates and the raw data was normalized with sizefactors in R, when reading the file, adata.X is already normalized, and if I plot the UMAP for SLC5A11 f.e this is the result: ; ![image](https://github.com/scverse/scanpy/assets/94078098/9e0c6958-b882-4f28-b7ac-dda5d58cbcba). However, if I select the raw counts of this anndata (stored in layers['counts']) and normalize it with `sc.pp.normalize `function and logarithmize it, this is the output of `sc.pl.umap` (it doesn't matter re-computing PCAs, neighbors and UMAP):; ![image](https://github.com/scverse/scanpy/assets/94078098/365ec629-3eea-4e58-ad0d-6ff3004d3c13). UMAP after recomputing PCAs, etc:; ![image](https://github.com/scverse/scanpy/assets/94078098/6727a53b-31ac-414a-b93d-55baa1688f85)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2556#issuecomment-1643597794
https://github.com/scverse/scanpy/issues/2556#issuecomment-1643597794:1342,Modifiability,layers,layers,1342,"This is the anndata working properly:; ```; AnnData object with n_obs × n_vars = 24759 × 29612; obs: 'sample', 'batch', 'n_counts'; var: 'ensembl_id', 'n_cells'; layers: 'counts'; ```; After normalization and logarithmize it with:; ```; adata.X = sc.pp.normalize_total(adata, inplace=False)['X']; adata.X = sc.pp.log1p(adata.X); ```; And computing PCAs, neighbors and UMAP coordinates this is a plot showing the expression of GRIK1 f.e:. ![image](https://github.com/scverse/scanpy/assets/94078098/b2a1cc8e-d4d8-4a32-91e3-a2a55857a140). Then, this is the anndata that after normalization does not show gene expression in UMAP:; ```; AnnData object with n_obs × n_vars = 17217 × 33704; obs: 'Age', 'Condition', 'Origin', 'Region', 'Sex', 'Subject', 'louvain', 'louvain6', 'obs_names', 'sample', 'batch', 'dataset'; var: 'dispersions', 'dispersions_norm', 'gene_ids', 'highly_variable', 'means', 'n_cells', 'var_names'; obsm: 'X_umap'; layers: 'counts'; ```; Because this anndata has pre-computed UMAP coordinates and the raw data was normalized with sizefactors in R, when reading the file, adata.X is already normalized, and if I plot the UMAP for SLC5A11 f.e this is the result: ; ![image](https://github.com/scverse/scanpy/assets/94078098/9e0c6958-b882-4f28-b7ac-dda5d58cbcba). However, if I select the raw counts of this anndata (stored in layers['counts']) and normalize it with `sc.pp.normalize `function and logarithmize it, this is the output of `sc.pl.umap` (it doesn't matter re-computing PCAs, neighbors and UMAP):; ![image](https://github.com/scverse/scanpy/assets/94078098/365ec629-3eea-4e58-ad0d-6ff3004d3c13). UMAP after recomputing PCAs, etc:; ![image](https://github.com/scverse/scanpy/assets/94078098/6727a53b-31ac-414a-b93d-55baa1688f85)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2556#issuecomment-1643597794
https://github.com/scverse/scanpy/issues/2556#issuecomment-1643597794:209,Testability,log,logarithmize,209,"This is the anndata working properly:; ```; AnnData object with n_obs × n_vars = 24759 × 29612; obs: 'sample', 'batch', 'n_counts'; var: 'ensembl_id', 'n_cells'; layers: 'counts'; ```; After normalization and logarithmize it with:; ```; adata.X = sc.pp.normalize_total(adata, inplace=False)['X']; adata.X = sc.pp.log1p(adata.X); ```; And computing PCAs, neighbors and UMAP coordinates this is a plot showing the expression of GRIK1 f.e:. ![image](https://github.com/scverse/scanpy/assets/94078098/b2a1cc8e-d4d8-4a32-91e3-a2a55857a140). Then, this is the anndata that after normalization does not show gene expression in UMAP:; ```; AnnData object with n_obs × n_vars = 17217 × 33704; obs: 'Age', 'Condition', 'Origin', 'Region', 'Sex', 'Subject', 'louvain', 'louvain6', 'obs_names', 'sample', 'batch', 'dataset'; var: 'dispersions', 'dispersions_norm', 'gene_ids', 'highly_variable', 'means', 'n_cells', 'var_names'; obsm: 'X_umap'; layers: 'counts'; ```; Because this anndata has pre-computed UMAP coordinates and the raw data was normalized with sizefactors in R, when reading the file, adata.X is already normalized, and if I plot the UMAP for SLC5A11 f.e this is the result: ; ![image](https://github.com/scverse/scanpy/assets/94078098/9e0c6958-b882-4f28-b7ac-dda5d58cbcba). However, if I select the raw counts of this anndata (stored in layers['counts']) and normalize it with `sc.pp.normalize `function and logarithmize it, this is the output of `sc.pl.umap` (it doesn't matter re-computing PCAs, neighbors and UMAP):; ![image](https://github.com/scverse/scanpy/assets/94078098/365ec629-3eea-4e58-ad0d-6ff3004d3c13). UMAP after recomputing PCAs, etc:; ![image](https://github.com/scverse/scanpy/assets/94078098/6727a53b-31ac-414a-b93d-55baa1688f85)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2556#issuecomment-1643597794
https://github.com/scverse/scanpy/issues/2556#issuecomment-1643597794:1413,Testability,log,logarithmize,1413,"This is the anndata working properly:; ```; AnnData object with n_obs × n_vars = 24759 × 29612; obs: 'sample', 'batch', 'n_counts'; var: 'ensembl_id', 'n_cells'; layers: 'counts'; ```; After normalization and logarithmize it with:; ```; adata.X = sc.pp.normalize_total(adata, inplace=False)['X']; adata.X = sc.pp.log1p(adata.X); ```; And computing PCAs, neighbors and UMAP coordinates this is a plot showing the expression of GRIK1 f.e:. ![image](https://github.com/scverse/scanpy/assets/94078098/b2a1cc8e-d4d8-4a32-91e3-a2a55857a140). Then, this is the anndata that after normalization does not show gene expression in UMAP:; ```; AnnData object with n_obs × n_vars = 17217 × 33704; obs: 'Age', 'Condition', 'Origin', 'Region', 'Sex', 'Subject', 'louvain', 'louvain6', 'obs_names', 'sample', 'batch', 'dataset'; var: 'dispersions', 'dispersions_norm', 'gene_ids', 'highly_variable', 'means', 'n_cells', 'var_names'; obsm: 'X_umap'; layers: 'counts'; ```; Because this anndata has pre-computed UMAP coordinates and the raw data was normalized with sizefactors in R, when reading the file, adata.X is already normalized, and if I plot the UMAP for SLC5A11 f.e this is the result: ; ![image](https://github.com/scverse/scanpy/assets/94078098/9e0c6958-b882-4f28-b7ac-dda5d58cbcba). However, if I select the raw counts of this anndata (stored in layers['counts']) and normalize it with `sc.pp.normalize `function and logarithmize it, this is the output of `sc.pl.umap` (it doesn't matter re-computing PCAs, neighbors and UMAP):; ![image](https://github.com/scverse/scanpy/assets/94078098/365ec629-3eea-4e58-ad0d-6ff3004d3c13). UMAP after recomputing PCAs, etc:; ![image](https://github.com/scverse/scanpy/assets/94078098/6727a53b-31ac-414a-b93d-55baa1688f85)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2556#issuecomment-1643597794
https://github.com/scverse/scanpy/pull/2561#issuecomment-1693364079:40,Usability,simpl,simplifies,40,"@ivirshup and I went over this, it just simplifies the doc setup",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2561#issuecomment-1693364079
https://github.com/scverse/scanpy/pull/2563#issuecomment-1642729317:1745,Testability,test,testing,1745,nt=comment&utm_campaign=pr+comments&utm_term=scverse) (3d86e82) into [master](https://app.codecov.io/gh/scverse/scanpy/commit/b3d5a6ce60c0f5b8aad152325f6fbd89509322fd?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) (b3d5a6c) will **increase** coverage by `0.04%`.; > The diff coverage is `89.13%`. > :exclamation: Current head 3d86e82 differs from pull request most recent head 8541ce3. Consider uploading reports for the commit 8541ce3 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2563 +/- ##; ==========================================; + Coverage 72.27% 72.32% +0.04% ; ==========================================; Files 105 105 ; Lines 11753 11785 +32 ; ==========================================; + Hits 8495 8524 +29 ; - Misses 3258 3261 +3 ; ```. | [Files Changed](https://app.codecov.io/gh/scverse/scanpy/pull/2563?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/preprocessing/\_normalization.py](https://app.codecov.io/gh/scverse/scanpy/pull/2563?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX25vcm1hbGl6YXRpb24ucHk=) | `88.88% <ø> (ø)` | |; | [scanpy/testing/\_pytest/marks.py](https://app.codecov.io/gh/scverse/scanpy/pull/2563?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9tYXJrcy5weQ==) | `84.61% <ø> (ø)` | |; | [scanpy/preprocessing/\_pca.py](https://app.codecov.io/gh/scverse/scanpy/pull/2563?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX3BjYS5weQ==) | `94.30% <89.13%> (-0.94%)` | :arrow_down: |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2563#issuecomment-1642729317
https://github.com/scverse/scanpy/pull/2563#issuecomment-1682154329:100,Testability,test,testing,100,"@flying-sheep , haven't considered all combinations yet but wanted to check if this way is good for testing warnings.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2563#issuecomment-1682154329
https://github.com/scverse/scanpy/pull/2563#issuecomment-1682177199:66,Usability,simpl,simply,66,"Looks great! You can get rid of `expect_warning`, as you can just simply check `if expected_warning_message is not None` instead, otherwise pretty ideal!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2563#issuecomment-1682177199
https://github.com/scverse/scanpy/issues/2564#issuecomment-1645368662:76,Deployability,release,release,76,"You have scanpy 1.7.3, not the newest version. This is fixed in #2434. I’ll release 1.9.3 soon with the fix.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2564#issuecomment-1645368662
https://github.com/scverse/scanpy/issues/2565#issuecomment-1651665498:74,Deployability,install,installed,74,"Can confirm that `tissue_positions.csv` is not properly detected in 1.9.3 installed off pip, but everything works fine in 1.10.0.dev87+gd08518f5 installed off GitHub.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2565#issuecomment-1651665498
https://github.com/scverse/scanpy/issues/2565#issuecomment-1651665498:145,Deployability,install,installed,145,"Can confirm that `tissue_positions.csv` is not properly detected in 1.9.3 installed off pip, but everything works fine in 1.10.0.dev87+gd08518f5 installed off GitHub.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2565#issuecomment-1651665498
https://github.com/scverse/scanpy/issues/2565#issuecomment-1651665498:56,Safety,detect,detected,56,"Can confirm that `tissue_positions.csv` is not properly detected in 1.9.3 installed off pip, but everything works fine in 1.10.0.dev87+gd08518f5 installed off GitHub.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2565#issuecomment-1651665498
https://github.com/scverse/scanpy/issues/2565#issuecomment-1651773726:13,Deployability,release,release,13,Seems like a release is in order. that code was merged in April,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2565#issuecomment-1651773726
https://github.com/scverse/scanpy/pull/2566#issuecomment-1645346362:1408,Testability,log,logging,1408,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2566?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > Merging [#2566](https://app.codecov.io/gh/scverse/scanpy/pull/2566?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) (485dfda) into [master](https://app.codecov.io/gh/scverse/scanpy/commit/0594b7f03917f8c5166d5bb2752031e1665065de?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) (0594b7f) will **not change** coverage.; > The diff coverage is `n/a`. > :exclamation: Current head 485dfda differs from pull request most recent head f4ab24c. Consider uploading reports for the commit f4ab24c to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2566 +/- ##; =======================================; Coverage 72.12% 72.12% ; =======================================; Files 104 104 ; Lines 11688 11688 ; =======================================; Hits 8430 8430 ; Misses 3258 3258 ; ```. | [Impacted Files](https://app.codecov.io/gh/scverse/scanpy/pull/2566?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/logging.py](https://app.codecov.io/gh/scverse/scanpy/pull/2566?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2xvZ2dpbmcucHk=) | `95.04% <ø> (ø)` | |; | [scanpy/testing/\_pytest/marks.py](https://app.codecov.io/gh/scverse/scanpy/pull/2566?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9tYXJrcy5weQ==) | `84.61% <ø> (ø)` | |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2566#issuecomment-1645346362
https://github.com/scverse/scanpy/pull/2566#issuecomment-1645346362:1651,Testability,test,testing,1651,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2566?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > Merging [#2566](https://app.codecov.io/gh/scverse/scanpy/pull/2566?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) (485dfda) into [master](https://app.codecov.io/gh/scverse/scanpy/commit/0594b7f03917f8c5166d5bb2752031e1665065de?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) (0594b7f) will **not change** coverage.; > The diff coverage is `n/a`. > :exclamation: Current head 485dfda differs from pull request most recent head f4ab24c. Consider uploading reports for the commit f4ab24c to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2566 +/- ##; =======================================; Coverage 72.12% 72.12% ; =======================================; Files 104 104 ; Lines 11688 11688 ; =======================================; Hits 8430 8430 ; Misses 3258 3258 ; ```. | [Impacted Files](https://app.codecov.io/gh/scverse/scanpy/pull/2566?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/logging.py](https://app.codecov.io/gh/scverse/scanpy/pull/2566?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2xvZ2dpbmcucHk=) | `95.04% <ø> (ø)` | |; | [scanpy/testing/\_pytest/marks.py](https://app.codecov.io/gh/scverse/scanpy/pull/2566?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9tYXJrcy5weQ==) | `84.61% <ø> (ø)` | |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2566#issuecomment-1645346362
https://github.com/scverse/scanpy/pull/2567#issuecomment-1645436066:331,Availability,error,error-reference,331,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2567?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@759960d`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2567 +/- ##; ========================================; Coverage ? 72.13% ; ========================================; Files ? 104 ; Lines ? 11648 ; Branches ? 0 ; ========================================; Hits ? 8402 ; Misses ? 3246 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2567#issuecomment-1645436066
https://github.com/scverse/scanpy/pull/2567#issuecomment-1645436066:279,Usability,learn,learn,279,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2567?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@759960d`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2567 +/- ##; ========================================; Coverage ? 72.13% ; ========================================; Files ? 104 ; Lines ? 11648 ; Branches ? 0 ; ========================================; Hits ? 8402 ; Misses ? 3246 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2567#issuecomment-1645436066
https://github.com/scverse/scanpy/pull/2568#issuecomment-1645437518:331,Availability,error,error-reference,331,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2568?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@759960d`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2568 +/- ##; ========================================; Coverage ? 72.13% ; ========================================; Files ? 104 ; Lines ? 11648 ; Branches ? 0 ; ========================================; Hits ? 8402 ; Misses ? 3246 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2568#issuecomment-1645437518
https://github.com/scverse/scanpy/pull/2568#issuecomment-1645437518:279,Usability,learn,learn,279,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2568?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@759960d`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2568 +/- ##; ========================================; Coverage ? 72.13% ; ========================================; Files ? 104 ; Lines ? 11648 ; Branches ? 0 ; ========================================; Hits ? 8402 ; Misses ? 3246 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2568#issuecomment-1645437518
https://github.com/scverse/scanpy/pull/2569#issuecomment-1759813642:64,Deployability,release,release,64,"OK, this should work. The only issue is that if users check “No release notes necessary” while not checking another box, the “check-relnotes” job still runs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2569#issuecomment-1759813642
https://github.com/scverse/scanpy/pull/2574#issuecomment-1649346773:331,Availability,error,error-reference,331,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2574?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@053f47e`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2574 +/- ##; ========================================; Coverage ? 72.13% ; ========================================; Files ? 104 ; Lines ? 11648 ; Branches ? 0 ; ========================================; Hits ? 8402 ; Misses ? 3246 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2574#issuecomment-1649346773
https://github.com/scverse/scanpy/pull/2574#issuecomment-1649346773:279,Usability,learn,learn,279,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2574?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@053f47e`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2574 +/- ##; ========================================; Coverage ? 72.13% ; ========================================; Files ? 104 ; Lines ? 11648 ; Branches ? 0 ; ========================================; Hits ? 8402 ; Misses ? 3246 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2574#issuecomment-1649346773
https://github.com/scverse/scanpy/pull/2575#issuecomment-1650045709:1283,Testability,test,testing,1283,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2575?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > Merging [#2575](https://app.codecov.io/gh/scverse/scanpy/pull/2575?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) (e178114) into [master](https://app.codecov.io/gh/scverse/scanpy/commit/d843918e82a1e01a64237f7a03ccfcb4c3ad8cc5?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) (d843918) will **increase** coverage by `0.04%`.; > The diff coverage is `100.00%`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2575 +/- ##; ==========================================; + Coverage 72.17% 72.22% +0.04% ; ==========================================; Files 104 104 ; Lines 11718 11705 -13 ; ==========================================; - Hits 8458 8454 -4 ; + Misses 3260 3251 -9 ; ```. | [Files Changed](https://app.codecov.io/gh/scverse/scanpy/pull/2575?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/testing/\_pytest/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2575?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9fX2luaXRfXy5weQ==) | `100.00% <100.00%> (+39.13%)` | :arrow_up: |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2575#issuecomment-1650045709
https://github.com/scverse/scanpy/pull/2577#issuecomment-1654888369:1564,Testability,test,testing,1564,/app.codecov.io/gh/scverse/scanpy/commit/edd613026cd5991baf92c8308b5ee2375089adc8?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) (edd6130) will **increase** coverage by `0.03%`.; > The diff coverage is `88.46%`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2577 +/- ##; ==========================================; + Coverage 72.12% 72.16% +0.03% ; ==========================================; Files 104 105 +1 ; Lines 11688 11714 +26 ; ==========================================; + Hits 8430 8453 +23 ; - Misses 3258 3261 +3 ; ```. | [Files Changed](https://app.codecov.io/gh/scverse/scanpy/pull/2577?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/external/tl/\_palantir.py](https://app.codecov.io/gh/scverse/scanpy/pull/2577?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2V4dGVybmFsL3RsL19wYWxhbnRpci5weQ==) | `22.58% <ø> (ø)` | |; | [scanpy/testing/\_pytest/marks.py](https://app.codecov.io/gh/scverse/scanpy/pull/2577?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9tYXJrcy5weQ==) | `84.61% <ø> (ø)` | |; | [scanpy/external/tl/\_mellon.py](https://app.codecov.io/gh/scverse/scanpy/pull/2577?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2V4dGVybmFsL3RsL19tZWxsb24ucHk=) | `88.00% <88.00%> (ø)` | |; | [scanpy/external/tl/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2577?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2V4dGVybmFsL3RsL19faW5pdF9fLnB5) | `100.00% <100.00%> (ø)` | |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2577#issuecomment-1654888369
https://github.com/scverse/scanpy/pull/2577#issuecomment-1656331448:121,Integrability,depend,depend,121,"@Zethson thank you for the consideration and explanation. I am not sure Mellon would pass the criteria since it does not depend on or explicitly use AnnData although we do recommend using AnnData: https://mellon.readthedocs.io/en/latest/notebooks/basic_tutorial.html; Additionally, it relies on [Palantir](https://github.com/dpeerlab/Palantir) which does also not qualify since it does not have a CI yet.; Do you think we should try making a PR to https://github.com/scverse/ecosystem-packages regardless?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2577#issuecomment-1656331448
https://github.com/scverse/scanpy/pull/2577#issuecomment-1656332039:123,Integrability,depend,depend,123,"> @Zethson thank you for the consideration and explanation. I am not sure Mellon would pass the criteria since it does not depend on or explicitly use AnnData although we do recommend using AnnData: https://mellon.readthedocs.io/en/latest/notebooks/basic_tutorial.html Additionally, it relies on [Palantir](https://github.com/dpeerlab/Palantir) which does also not qualify since it does not have a CI yet. Do you think we should try making a PR to https://github.com/scverse/ecosystem-packages regardless?. No, I'm afraid that these are hard criteria. However, I can highly recommend that you support AnnData first class :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2577#issuecomment-1656332039
https://github.com/scverse/scanpy/pull/2577#issuecomment-1656364181:16,Integrability,depend,dependency,16,"AnnData a large dependency given that the only interaction is; ```python; ad.obs[""mellon_log_density""] = mellon.DensityEstimator().fit_predict(ad.obsm[""DM_EigenVectors""]); ```; I understand the criteria though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2577#issuecomment-1656364181
https://github.com/scverse/scanpy/issues/2578#issuecomment-1945679038:50,Energy Efficiency,reduce,reduced,50,"Not currently, but since the scope of that PR got reduced, it shouldn’t be too much work.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2578#issuecomment-1945679038
https://github.com/scverse/scanpy/issues/2583#issuecomment-1664197260:41,Modifiability,plugin,plugin,41,@flying-sheep suggested to write a hatch-plugin that can automatically create the respective @overload type hints,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2583#issuecomment-1664197260
https://github.com/scverse/scanpy/issues/2583#issuecomment-1664211852:86,Deployability,Update,Updated,86,"Notes from discussion with @Intron7, @flying-sheep, @gtca, and @grst at hackathon:. * Updated idea from @gtca, based on: https://github.com/scverse/anndata/issues/706; * Use `layer_to`, `layer_from`as argument. Has possibility to still do operations inplace on arrays if you only pass `layer_from`; * Could be useful to have semantically meaningful default arguments e.g. `layers_from=""counts""``layers_to=""normalized""`; * Returning a new `AnnData` object with only new arrays could be a flexible base, as discussed in https://github.com/scverse/anndata/issues/658; * `inplace=False` returning function specific types (sometimes an array, sometimes a dict of arrays) is bad. This would be an alternative. * Being able to update arrays inplace is still important for memory usage. * Lots of discussion of when/ how we want to modify the AnnData",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2583#issuecomment-1664211852
https://github.com/scverse/scanpy/issues/2583#issuecomment-1664211852:720,Deployability,update,update,720,"Notes from discussion with @Intron7, @flying-sheep, @gtca, and @grst at hackathon:. * Updated idea from @gtca, based on: https://github.com/scverse/anndata/issues/706; * Use `layer_to`, `layer_from`as argument. Has possibility to still do operations inplace on arrays if you only pass `layer_from`; * Could be useful to have semantically meaningful default arguments e.g. `layers_from=""counts""``layers_to=""normalized""`; * Returning a new `AnnData` object with only new arrays could be a flexible base, as discussed in https://github.com/scverse/anndata/issues/658; * `inplace=False` returning function specific types (sometimes an array, sometimes a dict of arrays) is bad. This would be an alternative. * Being able to update arrays inplace is still important for memory usage. * Lots of discussion of when/ how we want to modify the AnnData",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2583#issuecomment-1664211852
https://github.com/scverse/scanpy/issues/2583#issuecomment-1664211852:487,Modifiability,flexible,flexible,487,"Notes from discussion with @Intron7, @flying-sheep, @gtca, and @grst at hackathon:. * Updated idea from @gtca, based on: https://github.com/scverse/anndata/issues/706; * Use `layer_to`, `layer_from`as argument. Has possibility to still do operations inplace on arrays if you only pass `layer_from`; * Could be useful to have semantically meaningful default arguments e.g. `layers_from=""counts""``layers_to=""normalized""`; * Returning a new `AnnData` object with only new arrays could be a flexible base, as discussed in https://github.com/scverse/anndata/issues/658; * `inplace=False` returning function specific types (sometimes an array, sometimes a dict of arrays) is bad. This would be an alternative. * Being able to update arrays inplace is still important for memory usage. * Lots of discussion of when/ how we want to modify the AnnData",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2583#issuecomment-1664211852
https://github.com/scverse/scanpy/issues/2583#issuecomment-1664351687:72,Deployability,update,update,72,"Unformatted notes by me:. Behaviors that exist for `inplace`/`copy`:. - update AnnData in place (where appropriate, choose target layer, obsm[key], …); - leave original AnnData alone, return; - new AnnData; - newly created array. `inplace=False`/`copy=True` returning array instead of whole object (AnnData) is confusing, but is sometimes done.; but having a choice to return the array makes sense.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2583#issuecomment-1664351687
https://github.com/scverse/scanpy/issues/2583#issuecomment-1674322622:245,Integrability,rout,route,245,What if we had copy-on-write behavior for AnnData? Then we could never modify AnnData inplace but always return a view of an AnnData with references to the objects that were unchanged and only the new data added. . Pandas seems to be going that route: https://github.com/pandas-dev/pandas/blob/57390ada100466dac777e5b66d5a4f2a72700c38/web/pandas/pdeps/0008-inplace-methods-in-pandas.md (HT @bernheder),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2583#issuecomment-1674322622
https://github.com/scverse/scanpy/pull/2585#issuecomment-1662126000:234,Testability,test,tests,234,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2585?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Comparison is base [(`8986921`)](https://app.codecov.io/gh/scverse/scanpy/commit/8986921216553cf08db98b37082fffc5714c970c?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.85% compared to head [(`8316a69`)](https://app.codecov.io/gh/scverse/scanpy/pull/2585?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.85%. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2585 +/- ##; =======================================; Coverage 72.85% 72.85% ; =======================================; Files 111 111 ; Lines 12383 12383 ; =======================================; Hits 9022 9022 ; Misses 3361 3361 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2585?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/plotting/\_anndata.py](https://app.codecov.io/gh/scverse/scanpy/pull/2585?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL19hbm5kYXRhLnB5) | `84.97% <ø> (ø)` | |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2585#issuecomment-1662126000
https://github.com/scverse/scanpy/issues/2586#issuecomment-1717970663:83,Testability,test,test,83,"Hi,. thanks for your interest in scanpy!. Regarding your question on ordering, and test statistic scores vs p-values:. 1. The structured array is [ordered according to scores](https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.rank_genes_groups.html#scanpy.tl.rank_genes_groups), not the p-values. 2. For tests with a signed test statistic (for example the t-test and the wilcoxon test), a ‘larger’ score does necessarily correspond to a lower p-value: rather, a score ‘further away from 0’ corresponds to lower p-value. Hence as currently the output stored in `adata.uns['rank_genes_groups']` is ordered according to scores, this does not mean it is ordered according to p-values. To the part where you mention you went into the code: My best guess is you refer to [this computation](https://github.com/scverse/scanpy/blob/1df92d61f00cec83b2ab2feb9c977cfcda84ebc0/scanpy/tools/_rank_genes_groups.py#L290). Here, considering the absolute value is used to get the two tails of the distribution when using the survival function (`stats.distribution.sf`). Generally if you’re interested in the Wilcoxon computation and the normal approximation used here, you can check [this](https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test) for a start. This also introduces the relation between the scores and the p-value. Hope this helps!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2586#issuecomment-1717970663
https://github.com/scverse/scanpy/issues/2586#issuecomment-1717970663:314,Testability,test,tests,314,"Hi,. thanks for your interest in scanpy!. Regarding your question on ordering, and test statistic scores vs p-values:. 1. The structured array is [ordered according to scores](https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.rank_genes_groups.html#scanpy.tl.rank_genes_groups), not the p-values. 2. For tests with a signed test statistic (for example the t-test and the wilcoxon test), a ‘larger’ score does necessarily correspond to a lower p-value: rather, a score ‘further away from 0’ corresponds to lower p-value. Hence as currently the output stored in `adata.uns['rank_genes_groups']` is ordered according to scores, this does not mean it is ordered according to p-values. To the part where you mention you went into the code: My best guess is you refer to [this computation](https://github.com/scverse/scanpy/blob/1df92d61f00cec83b2ab2feb9c977cfcda84ebc0/scanpy/tools/_rank_genes_groups.py#L290). Here, considering the absolute value is used to get the two tails of the distribution when using the survival function (`stats.distribution.sf`). Generally if you’re interested in the Wilcoxon computation and the normal approximation used here, you can check [this](https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test) for a start. This also introduces the relation between the scores and the p-value. Hope this helps!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2586#issuecomment-1717970663
https://github.com/scverse/scanpy/issues/2586#issuecomment-1717970663:334,Testability,test,test,334,"Hi,. thanks for your interest in scanpy!. Regarding your question on ordering, and test statistic scores vs p-values:. 1. The structured array is [ordered according to scores](https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.rank_genes_groups.html#scanpy.tl.rank_genes_groups), not the p-values. 2. For tests with a signed test statistic (for example the t-test and the wilcoxon test), a ‘larger’ score does necessarily correspond to a lower p-value: rather, a score ‘further away from 0’ corresponds to lower p-value. Hence as currently the output stored in `adata.uns['rank_genes_groups']` is ordered according to scores, this does not mean it is ordered according to p-values. To the part where you mention you went into the code: My best guess is you refer to [this computation](https://github.com/scverse/scanpy/blob/1df92d61f00cec83b2ab2feb9c977cfcda84ebc0/scanpy/tools/_rank_genes_groups.py#L290). Here, considering the absolute value is used to get the two tails of the distribution when using the survival function (`stats.distribution.sf`). Generally if you’re interested in the Wilcoxon computation and the normal approximation used here, you can check [this](https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test) for a start. This also introduces the relation between the scores and the p-value. Hope this helps!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2586#issuecomment-1717970663
https://github.com/scverse/scanpy/issues/2586#issuecomment-1717970663:368,Testability,test,test,368,"Hi,. thanks for your interest in scanpy!. Regarding your question on ordering, and test statistic scores vs p-values:. 1. The structured array is [ordered according to scores](https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.rank_genes_groups.html#scanpy.tl.rank_genes_groups), not the p-values. 2. For tests with a signed test statistic (for example the t-test and the wilcoxon test), a ‘larger’ score does necessarily correspond to a lower p-value: rather, a score ‘further away from 0’ corresponds to lower p-value. Hence as currently the output stored in `adata.uns['rank_genes_groups']` is ordered according to scores, this does not mean it is ordered according to p-values. To the part where you mention you went into the code: My best guess is you refer to [this computation](https://github.com/scverse/scanpy/blob/1df92d61f00cec83b2ab2feb9c977cfcda84ebc0/scanpy/tools/_rank_genes_groups.py#L290). Here, considering the absolute value is used to get the two tails of the distribution when using the survival function (`stats.distribution.sf`). Generally if you’re interested in the Wilcoxon computation and the normal approximation used here, you can check [this](https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test) for a start. This also introduces the relation between the scores and the p-value. Hope this helps!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2586#issuecomment-1717970663
https://github.com/scverse/scanpy/issues/2586#issuecomment-1717970663:390,Testability,test,test,390,"Hi,. thanks for your interest in scanpy!. Regarding your question on ordering, and test statistic scores vs p-values:. 1. The structured array is [ordered according to scores](https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.rank_genes_groups.html#scanpy.tl.rank_genes_groups), not the p-values. 2. For tests with a signed test statistic (for example the t-test and the wilcoxon test), a ‘larger’ score does necessarily correspond to a lower p-value: rather, a score ‘further away from 0’ corresponds to lower p-value. Hence as currently the output stored in `adata.uns['rank_genes_groups']` is ordered according to scores, this does not mean it is ordered according to p-values. To the part where you mention you went into the code: My best guess is you refer to [this computation](https://github.com/scverse/scanpy/blob/1df92d61f00cec83b2ab2feb9c977cfcda84ebc0/scanpy/tools/_rank_genes_groups.py#L290). Here, considering the absolute value is used to get the two tails of the distribution when using the survival function (`stats.distribution.sf`). Generally if you’re interested in the Wilcoxon computation and the normal approximation used here, you can check [this](https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test) for a start. This also introduces the relation between the scores and the p-value. Hope this helps!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2586#issuecomment-1717970663
https://github.com/scverse/scanpy/issues/2586#issuecomment-2104192246:480,Availability,down,downregulation,480,"Hi, @eroell, I understand what you're saying. You're referring to tests with signed test statistics, like t-tests and Wilcoxon tests. You mentioned that larger scores typically correspond to lower p-values, and conversely, scores further from 0 also tend to have lower p-values. However, I am currently confused about what the positive and negative values of these scores represent. Previously, I believed that positive scores indicated upregulation and negative scores indicated downregulation, but recent results have shown me that this viewpoint is incorrect.; ![image](https://github.com/scverse/scanpy/assets/103617127/5f7d7b5b-939d-4ffe-8822-b68b59ac354f)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2586#issuecomment-2104192246
https://github.com/scverse/scanpy/issues/2586#issuecomment-2104192246:66,Testability,test,tests,66,"Hi, @eroell, I understand what you're saying. You're referring to tests with signed test statistics, like t-tests and Wilcoxon tests. You mentioned that larger scores typically correspond to lower p-values, and conversely, scores further from 0 also tend to have lower p-values. However, I am currently confused about what the positive and negative values of these scores represent. Previously, I believed that positive scores indicated upregulation and negative scores indicated downregulation, but recent results have shown me that this viewpoint is incorrect.; ![image](https://github.com/scverse/scanpy/assets/103617127/5f7d7b5b-939d-4ffe-8822-b68b59ac354f)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2586#issuecomment-2104192246
https://github.com/scverse/scanpy/issues/2586#issuecomment-2104192246:84,Testability,test,test,84,"Hi, @eroell, I understand what you're saying. You're referring to tests with signed test statistics, like t-tests and Wilcoxon tests. You mentioned that larger scores typically correspond to lower p-values, and conversely, scores further from 0 also tend to have lower p-values. However, I am currently confused about what the positive and negative values of these scores represent. Previously, I believed that positive scores indicated upregulation and negative scores indicated downregulation, but recent results have shown me that this viewpoint is incorrect.; ![image](https://github.com/scverse/scanpy/assets/103617127/5f7d7b5b-939d-4ffe-8822-b68b59ac354f)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2586#issuecomment-2104192246
https://github.com/scverse/scanpy/issues/2586#issuecomment-2104192246:108,Testability,test,tests,108,"Hi, @eroell, I understand what you're saying. You're referring to tests with signed test statistics, like t-tests and Wilcoxon tests. You mentioned that larger scores typically correspond to lower p-values, and conversely, scores further from 0 also tend to have lower p-values. However, I am currently confused about what the positive and negative values of these scores represent. Previously, I believed that positive scores indicated upregulation and negative scores indicated downregulation, but recent results have shown me that this viewpoint is incorrect.; ![image](https://github.com/scverse/scanpy/assets/103617127/5f7d7b5b-939d-4ffe-8822-b68b59ac354f)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2586#issuecomment-2104192246
https://github.com/scverse/scanpy/issues/2586#issuecomment-2104192246:127,Testability,test,tests,127,"Hi, @eroell, I understand what you're saying. You're referring to tests with signed test statistics, like t-tests and Wilcoxon tests. You mentioned that larger scores typically correspond to lower p-values, and conversely, scores further from 0 also tend to have lower p-values. However, I am currently confused about what the positive and negative values of these scores represent. Previously, I believed that positive scores indicated upregulation and negative scores indicated downregulation, but recent results have shown me that this viewpoint is incorrect.; ![image](https://github.com/scverse/scanpy/assets/103617127/5f7d7b5b-939d-4ffe-8822-b68b59ac354f)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2586#issuecomment-2104192246
https://github.com/scverse/scanpy/issues/2587#issuecomment-1691673182:603,Modifiability,flexible,flexible,603,"Hi Alma,. thanks for raising your thoughts here!. I’ll try to clarify the output a bit and tag @ivirshup here. `sc.pp.neighbors` produces two main results, which it indeed stores in the `ad.obsp`:. 1. A distance matrix in `adata.obsp['distances']`. This matrix has shape (n_obs, n_obs): for each observation, only `n_neighbors-1 `entries will be non-zero. The nearest neighbor of an observation, itself with distance 0, is discarded, hence the `-1`. It is probably what you have been thinking of in your description. 2. A connectivity graph in `adata.obsp['connectivity']`. This graph has shape (n_obs, flexible), where the flexible number of connections for each observation are determined during the UMAP algorithm. Hence if you’re interested in the distance matrix, `adata.obsp['distances']` would be what you’re looking for! Coming back to your code example, here the test should be a pass:; ```py; # Import packages. import scanpy as sc; import anndata as ad; import numpy as np. # set random seed; np.random.seed(42). # create dummy data; adata = ad.AnnData(shape=(1000,1)); adata.obsm['rep'] = np.random.random(size = (1000,2)). # get spatial connectivities; k = 10; sc.pp.neighbors(adata, n_neighbors=k, use_rep = 'rep', knn = True). # get and count connectivities for each cell; gr = adata.obsp['distances']; nn = (np.array(gr.todense()) > 0).sum(axis=1).flatten(). # check if neighbors are equal to k-1; np.testing.assert_equal(nn, k-1); ```. Might actually try to clarify this in documentation, small PR addressing this will follow soon. How does that sound to you? Please persist if you think I miss the point!. That being said, I think that the computation of the distance matrix and the connectivity graph are both correct.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2587#issuecomment-1691673182
https://github.com/scverse/scanpy/issues/2587#issuecomment-1691673182:624,Modifiability,flexible,flexible,624,"Hi Alma,. thanks for raising your thoughts here!. I’ll try to clarify the output a bit and tag @ivirshup here. `sc.pp.neighbors` produces two main results, which it indeed stores in the `ad.obsp`:. 1. A distance matrix in `adata.obsp['distances']`. This matrix has shape (n_obs, n_obs): for each observation, only `n_neighbors-1 `entries will be non-zero. The nearest neighbor of an observation, itself with distance 0, is discarded, hence the `-1`. It is probably what you have been thinking of in your description. 2. A connectivity graph in `adata.obsp['connectivity']`. This graph has shape (n_obs, flexible), where the flexible number of connections for each observation are determined during the UMAP algorithm. Hence if you’re interested in the distance matrix, `adata.obsp['distances']` would be what you’re looking for! Coming back to your code example, here the test should be a pass:; ```py; # Import packages. import scanpy as sc; import anndata as ad; import numpy as np. # set random seed; np.random.seed(42). # create dummy data; adata = ad.AnnData(shape=(1000,1)); adata.obsm['rep'] = np.random.random(size = (1000,2)). # get spatial connectivities; k = 10; sc.pp.neighbors(adata, n_neighbors=k, use_rep = 'rep', knn = True). # get and count connectivities for each cell; gr = adata.obsp['distances']; nn = (np.array(gr.todense()) > 0).sum(axis=1).flatten(). # check if neighbors are equal to k-1; np.testing.assert_equal(nn, k-1); ```. Might actually try to clarify this in documentation, small PR addressing this will follow soon. How does that sound to you? Please persist if you think I miss the point!. That being said, I think that the computation of the distance matrix and the connectivity graph are both correct.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2587#issuecomment-1691673182
https://github.com/scverse/scanpy/issues/2587#issuecomment-1691673182:872,Testability,test,test,872,"Hi Alma,. thanks for raising your thoughts here!. I’ll try to clarify the output a bit and tag @ivirshup here. `sc.pp.neighbors` produces two main results, which it indeed stores in the `ad.obsp`:. 1. A distance matrix in `adata.obsp['distances']`. This matrix has shape (n_obs, n_obs): for each observation, only `n_neighbors-1 `entries will be non-zero. The nearest neighbor of an observation, itself with distance 0, is discarded, hence the `-1`. It is probably what you have been thinking of in your description. 2. A connectivity graph in `adata.obsp['connectivity']`. This graph has shape (n_obs, flexible), where the flexible number of connections for each observation are determined during the UMAP algorithm. Hence if you’re interested in the distance matrix, `adata.obsp['distances']` would be what you’re looking for! Coming back to your code example, here the test should be a pass:; ```py; # Import packages. import scanpy as sc; import anndata as ad; import numpy as np. # set random seed; np.random.seed(42). # create dummy data; adata = ad.AnnData(shape=(1000,1)); adata.obsm['rep'] = np.random.random(size = (1000,2)). # get spatial connectivities; k = 10; sc.pp.neighbors(adata, n_neighbors=k, use_rep = 'rep', knn = True). # get and count connectivities for each cell; gr = adata.obsp['distances']; nn = (np.array(gr.todense()) > 0).sum(axis=1).flatten(). # check if neighbors are equal to k-1; np.testing.assert_equal(nn, k-1); ```. Might actually try to clarify this in documentation, small PR addressing this will follow soon. How does that sound to you? Please persist if you think I miss the point!. That being said, I think that the computation of the distance matrix and the connectivity graph are both correct.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2587#issuecomment-1691673182
https://github.com/scverse/scanpy/issues/2587#issuecomment-1691673182:1417,Testability,test,testing,1417,"Hi Alma,. thanks for raising your thoughts here!. I’ll try to clarify the output a bit and tag @ivirshup here. `sc.pp.neighbors` produces two main results, which it indeed stores in the `ad.obsp`:. 1. A distance matrix in `adata.obsp['distances']`. This matrix has shape (n_obs, n_obs): for each observation, only `n_neighbors-1 `entries will be non-zero. The nearest neighbor of an observation, itself with distance 0, is discarded, hence the `-1`. It is probably what you have been thinking of in your description. 2. A connectivity graph in `adata.obsp['connectivity']`. This graph has shape (n_obs, flexible), where the flexible number of connections for each observation are determined during the UMAP algorithm. Hence if you’re interested in the distance matrix, `adata.obsp['distances']` would be what you’re looking for! Coming back to your code example, here the test should be a pass:; ```py; # Import packages. import scanpy as sc; import anndata as ad; import numpy as np. # set random seed; np.random.seed(42). # create dummy data; adata = ad.AnnData(shape=(1000,1)); adata.obsm['rep'] = np.random.random(size = (1000,2)). # get spatial connectivities; k = 10; sc.pp.neighbors(adata, n_neighbors=k, use_rep = 'rep', knn = True). # get and count connectivities for each cell; gr = adata.obsp['distances']; nn = (np.array(gr.todense()) > 0).sum(axis=1).flatten(). # check if neighbors are equal to k-1; np.testing.assert_equal(nn, k-1); ```. Might actually try to clarify this in documentation, small PR addressing this will follow soon. How does that sound to you? Please persist if you think I miss the point!. That being said, I think that the computation of the distance matrix and the connectivity graph are both correct.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2587#issuecomment-1691673182
https://github.com/scverse/scanpy/pull/2589#issuecomment-1666905237:21,Deployability,release,release,21,I added a test and a release node,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2589#issuecomment-1666905237
https://github.com/scverse/scanpy/pull/2589#issuecomment-1666905237:10,Testability,test,test,10,I added a test and a release node,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2589#issuecomment-1666905237
https://github.com/scverse/scanpy/pull/2589#issuecomment-1668113430:18,Deployability,release,release,18,"@Intron7 FYI: the release notes were in the wrong file. this is in milestone 1.9.4, so they go in the 1.9.4 file",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2589#issuecomment-1668113430
https://github.com/scverse/scanpy/pull/2590#issuecomment-1665700077:60,Usability,guid,guidance,60,Ok @ivirshup I think we're ready to go here. Thanks for the guidance!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2590#issuecomment-1665700077
https://github.com/scverse/scanpy/pull/2590#issuecomment-1677604847:284,Testability,test,tests,284,"@flying-sheep Do you want me to resolve your comments as I addressed them or do you prefer to do that yourself? I've seen it done both ways. Once I know, I'll either resolve or not and then re-request your review. The only thing I'm personally still curious about is if you think the tests are ""too"" duplicated still, but there might be other new things/poorly-fixed old things to look at.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2590#issuecomment-1677604847
https://github.com/scverse/scanpy/pull/2590#issuecomment-1843407929:43,Deployability,update,updated,43,"This is getting pretty close to done. I've updated the comment at the top with a todo list. All the ""extras"" can be moved to an issue on merge. . Let me know if any of those aren't actually optional. I'm currently inclined to drop support for `weight`. Checking older commits, it doesn't seem to actually work for the variance calculation (returns all zeros), and isn't really something we support elsewhere. It would also make adding things like ""median"" significantly more complicated in the future.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2590#issuecomment-1843407929
https://github.com/scverse/scanpy/pull/2590#issuecomment-1887297037:657,Performance,cache,cached,657,"> also as I asked before: why go away from dataclasses?. I don't think that switching away from data classes removed any meaningful functionality here, but having to use `default_factory`, `InitVar`, and/or `__post_init__` would add more complexity. I don't think that there being some internal data classes is important here, especially since it's not user visible and may change at any time anyways. I have a few ideas for ways to change the implementation to add more methods, none of which are compatible with `Aggregate` being a data class. * One path forward just removes the class entirely, since it doesn't do much now; * The other uses a number of cached properties, which I don't think make a ton of sense to use with dataclasses. Is there some functionality the data class was adding that I'm missing?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2590#issuecomment-1887297037
https://github.com/scverse/scanpy/pull/2590#issuecomment-1953840990:204,Modifiability,parameteriz,parameterizing,204,"> sparse_indicator doesn’t have its weights branches hit at all, maybe we should remove that? Or will this be used at some point?. I think it will be used at some point, but also happy to remove. I think parameterizing `test_aggregate_axis_specification` is overkill for what the test does.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2590#issuecomment-1953840990
https://github.com/scverse/scanpy/pull/2590#issuecomment-1953840990:280,Testability,test,test,280,"> sparse_indicator doesn’t have its weights branches hit at all, maybe we should remove that? Or will this be used at some point?. I think it will be used at some point, but also happy to remove. I think parameterizing `test_aggregate_axis_specification` is overkill for what the test does.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2590#issuecomment-1953840990
https://github.com/scverse/scanpy/issues/2592#issuecomment-1743077209:25,Deployability,update,update,25,"All good, thanks for the update!; Glad to hear it works now as you'd expect it to :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592#issuecomment-1743077209
https://github.com/scverse/scanpy/pull/2595#issuecomment-1665544564:3201,Testability,test,testing,3201,e&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L19jb21wYXQucHk=) | `47.36% <33.33%> (-24.07%)` | :arrow_down: |; | [scanpy/metrics/\_gearys\_c.py](https://app.codecov.io/gh/scverse/scanpy/pull/2595?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L21ldHJpY3MvX2dlYXJ5c19jLnB5) | `38.39% <60.00%> (-14.60%)` | :arrow_down: |; | [scanpy/\_utils/compute/is\_constant.py](https://app.codecov.io/gh/scverse/scanpy/pull/2595?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L191dGlscy9jb21wdXRlL2lzX2NvbnN0YW50LnB5) | `37.66% <71.42%> (-33.11%)` | :arrow_down: |; | [scanpy/metrics/\_morans\_i.py](https://app.codecov.io/gh/scverse/scanpy/pull/2595?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L21ldHJpY3MvX21vcmFuc19pLnB5) | `48.80% <75.00%> (-7.29%)` | :arrow_down: |; | [scanpy/metrics/\_common.py](https://app.codecov.io/gh/scverse/scanpy/pull/2595?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L21ldHJpY3MvX2NvbW1vbi5weQ==) | `83.87% <83.87%> (ø)` | |; | [scanpy/preprocessing/\_normalization.py](https://app.codecov.io/gh/scverse/scanpy/pull/2595?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX25vcm1hbGl6YXRpb24ucHk=) | `88.88% <100.00%> (+3.00%)` | :arrow_up: |; | [scanpy/testing/\_pytest/fixtures/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2595?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9maXh0dXJlcy9fX2luaXRfXy5weQ==) | `95.00% <100.00%> (+3.33%)` | :arrow_up: |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2595#issuecomment-1665544564
https://github.com/scverse/scanpy/pull/2597#issuecomment-1665680324:331,Availability,error,error-reference,331,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2597?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@64fab42`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2597 +/- ##; ========================================; Coverage ? 72.13% ; ========================================; Files ? 104 ; Lines ? 11648 ; Branches ? 0 ; ========================================; Hits ? 8402 ; Misses ? 3246 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2597#issuecomment-1665680324
https://github.com/scverse/scanpy/pull/2597#issuecomment-1665680324:279,Usability,learn,learn,279,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2597?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@64fab42`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2597 +/- ##; ========================================; Coverage ? 72.13% ; ========================================; Files ? 104 ; Lines ? 11648 ; Branches ? 0 ; ========================================; Hits ? 8402 ; Misses ? 3246 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2597#issuecomment-1665680324
https://github.com/scverse/scanpy/issues/2598#issuecomment-1667789925:80,Deployability,release,release,80,"fixed in #2424, reported many times. please use the search function. we’ll do a release soon!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2598#issuecomment-1667789925
https://github.com/scverse/scanpy/pull/2605#issuecomment-1761383417:105,Availability,error,error,105,"@ivirshup any way to force Azure to clear its cache or use a different runner? The “invalid instruction” error here probably comes from using a binary wheel compiled for a newer CPU. /edit: wow, 9 attempts. Maybe just dropping Python 3.8 will get us there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2605#issuecomment-1761383417
https://github.com/scverse/scanpy/pull/2605#issuecomment-1761383417:46,Performance,cache,cache,46,"@ivirshup any way to force Azure to clear its cache or use a different runner? The “invalid instruction” error here probably comes from using a binary wheel compiled for a newer CPU. /edit: wow, 9 attempts. Maybe just dropping Python 3.8 will get us there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2605#issuecomment-1761383417
https://github.com/scverse/scanpy/pull/2605#issuecomment-1761383417:36,Usability,clear,clear,36,"@ivirshup any way to force Azure to clear its cache or use a different runner? The “invalid instruction” error here probably comes from using a binary wheel compiled for a newer CPU. /edit: wow, 9 attempts. Maybe just dropping Python 3.8 will get us there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2605#issuecomment-1761383417
https://github.com/scverse/scanpy/pull/2605#issuecomment-1772221723:9,Integrability,depend,dependencies,9,> If our dependencies have dropped support we can too. You mean like anndata? :laughing: . > Is this ready for review? I think it mostly looks good. yeah!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2605#issuecomment-1772221723
https://github.com/scverse/scanpy/pull/2605#issuecomment-1776722388:10,Availability,ping,ping,10,@ivirshup ping,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2605#issuecomment-1776722388
https://github.com/scverse/scanpy/pull/2606#issuecomment-1670939429:331,Availability,error,error-reference,331,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2606?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@b5506e1`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2606 +/- ##; ========================================; Coverage ? 72.18% ; ========================================; Files ? 104 ; Lines ? 11642 ; Branches ? 0 ; ========================================; Hits ? 8404 ; Misses ? 3238 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2606#issuecomment-1670939429
https://github.com/scverse/scanpy/pull/2606#issuecomment-1670939429:279,Usability,learn,learn,279,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2606?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@b5506e1`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2606 +/- ##; ========================================; Coverage ? 72.18% ; ========================================; Files ? 104 ; Lines ? 11642 ; Branches ? 0 ; ========================================; Hits ? 8404 ; Misses ? 3238 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2606#issuecomment-1670939429
https://github.com/scverse/scanpy/issues/2608#issuecomment-1671743412:23,Availability,error,error,23,"After fixing the above error locally and continuing I ran into a similar error in the next step:; `sc.external.tl.palantir_results(...)` internally [calls](https://github.com/scverse/scanpy/blob/master/scanpy/external/tl/_palantir.py#L294) `run_palantir(ms_data=ms_data, ...)` with keyword `ms_data` which seems to have changed to just `data` in the [recent version of palantir](https://github.com/dpeerlab/Palantir/blob/master/src/palantir/core.py#L35).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2608#issuecomment-1671743412
https://github.com/scverse/scanpy/issues/2608#issuecomment-1671743412:73,Availability,error,error,73,"After fixing the above error locally and continuing I ran into a similar error in the next step:; `sc.external.tl.palantir_results(...)` internally [calls](https://github.com/scverse/scanpy/blob/master/scanpy/external/tl/_palantir.py#L294) `run_palantir(ms_data=ms_data, ...)` with keyword `ms_data` which seems to have changed to just `data` in the [recent version of palantir](https://github.com/dpeerlab/Palantir/blob/master/src/palantir/core.py#L35).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2608#issuecomment-1671743412
https://github.com/scverse/scanpy/pull/2610#issuecomment-1677075979:5,Deployability,Release,Release,5,> 1. Release note please. I'll do so. > 2. Why do we have `N_PCS` in the settings? Wasn't aware of that actually. I don't know I just came across this while working on RSC and thought the behavior was not what I expected. I hope that this is more in line with what the user intended.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2610#issuecomment-1677075979
https://github.com/scverse/scanpy/issues/2611#issuecomment-1677594358:399,Usability,simpl,simple,399,"Hello,. thank you for your help. I was able to find the issue, I have >50 categories that were sorted, and I did not want to input them manually into a list (like your example). After sorting I got an object type 'pandas.core.arrays.categorical.Categorical', that dotplot is able to read the order from, but stacked_violin interpreted differently, using the 'Categories' section. My solution was as simple as converting to list with:; correct_order = new_order.tolist(). Thank you so much for your help",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2611#issuecomment-1677594358
https://github.com/scverse/scanpy/pull/2612#issuecomment-1688394266:617,Availability,fault,faults,617,"Perf measurements for the use case of running the HVG tests on my machine (not very accurate, and not very reminiscent of how users use it). Tests get a bit slower, real world gets faster. - scanpy master:. ```console; $ git switch master; $ perf stat -r 10 -B hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py; 	 Performance counter stats for 'hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py' (10 runs):; 	; 	 71.915,07 msec task-clock:u # 14,035 CPUs utilized ( +- 9,53% ); 	 0 context-switches:u # 0,000 /sec; 	 0 cpu-migrations:u # 0,000 /sec; 	 1.168.035 page-faults:u # 29,496 K/sec ( +- 9,58% ); 	 191.815.791.770 cycles:u # 4,844 GHz ( +- 9,53% ) (83,37%); 	 10.610.492.234 stalled-cycles-frontend:u # 10,05% frontend cycles idle ( +- 9,44% ) (83,34%); 	 59.853.476.395 stalled-cycles-backend:u # 56,69% backend cycles idle ( +- 9,56% ) (83,32%); 	 257.750.810.841 instructions:u # 2,44 insn per cycle; 	 # 0,13 stalled cycles per insn ( +- 9,57% ) (83,33%); 	 45.773.330.764 branches:u # 1,156 G/sec ( +- 9,58% ) (83,33%); 	 1.147.567.613 branch-misses:u # 4,56% of all branches ( +- 9,54% ) (83,37%); 	; 	 5,1241 +- 0,0242 seconds time elapsed ( +- 0,47% ); ```. - this PR:. ```console; $ git switch hvg_PR_numba; $ perf stat -r 10 -B hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py; 	 Performance counter stats for 'hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py' (10 runs):; 	; 	 113.085,21 msec task-clock:u # 15,789 CPUs utilized ( +- 9,56% ); 	 0 context-switches:u # 0,000 /sec; 	 0 cpu-migrations:u # 0,000 /sec; 	 1.636.606 page-faults:u # 26,373 K/sec ( +- 9,55% ); 	 310.410.832.165 cycles:u # 5,002 GHz ( +- 9,55% ) (83,35%); 	 14.117.222.045 stalled-cycles-frontend:u # 8,30% frontend cycles idle ( +- 9,46% ) (83,38%); 	 75.813.970.243 stalled-cycles-backend:u # 44,56% backend cycles idle ( +- 9,57% ) (83,35%); 	 373.047.679.552 instructions:u # 2,19 insn per cycle; 	 ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2612#issuecomment-1688394266
https://github.com/scverse/scanpy/pull/2612#issuecomment-1688394266:1654,Availability,fault,faults,1654,"B hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py; 	 Performance counter stats for 'hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py' (10 runs):; 	; 	 71.915,07 msec task-clock:u # 14,035 CPUs utilized ( +- 9,53% ); 	 0 context-switches:u # 0,000 /sec; 	 0 cpu-migrations:u # 0,000 /sec; 	 1.168.035 page-faults:u # 29,496 K/sec ( +- 9,58% ); 	 191.815.791.770 cycles:u # 4,844 GHz ( +- 9,53% ) (83,37%); 	 10.610.492.234 stalled-cycles-frontend:u # 10,05% frontend cycles idle ( +- 9,44% ) (83,34%); 	 59.853.476.395 stalled-cycles-backend:u # 56,69% backend cycles idle ( +- 9,56% ) (83,32%); 	 257.750.810.841 instructions:u # 2,44 insn per cycle; 	 # 0,13 stalled cycles per insn ( +- 9,57% ) (83,33%); 	 45.773.330.764 branches:u # 1,156 G/sec ( +- 9,58% ) (83,33%); 	 1.147.567.613 branch-misses:u # 4,56% of all branches ( +- 9,54% ) (83,37%); 	; 	 5,1241 +- 0,0242 seconds time elapsed ( +- 0,47% ); ```. - this PR:. ```console; $ git switch hvg_PR_numba; $ perf stat -r 10 -B hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py; 	 Performance counter stats for 'hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py' (10 runs):; 	; 	 113.085,21 msec task-clock:u # 15,789 CPUs utilized ( +- 9,56% ); 	 0 context-switches:u # 0,000 /sec; 	 0 cpu-migrations:u # 0,000 /sec; 	 1.636.606 page-faults:u # 26,373 K/sec ( +- 9,55% ); 	 310.410.832.165 cycles:u # 5,002 GHz ( +- 9,55% ) (83,35%); 	 14.117.222.045 stalled-cycles-frontend:u # 8,30% frontend cycles idle ( +- 9,46% ) (83,38%); 	 75.813.970.243 stalled-cycles-backend:u # 44,56% backend cycles idle ( +- 9,57% ) (83,35%); 	 373.047.679.552 instructions:u # 2,19 insn per cycle; 	 # 0,11 stalled cycles per insn ( +- 9,57% ) (83,34%); 	 67.830.590.839 branches:u # 1,093 G/sec ( +- 9,58% ) (83,35%); 	 1.702.825.180 branch-misses:u # 4,56% of all branches ( +- 9,56% ) (83,28%); 	; 	 7,1623 +- 0,0560 seconds time elapsed ( +- 0,78% ); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2612#issuecomment-1688394266
https://github.com/scverse/scanpy/pull/2612#issuecomment-1688394266:339,Performance,Perform,Performance,339,"Perf measurements for the use case of running the HVG tests on my machine (not very accurate, and not very reminiscent of how users use it). Tests get a bit slower, real world gets faster. - scanpy master:. ```console; $ git switch master; $ perf stat -r 10 -B hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py; 	 Performance counter stats for 'hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py' (10 runs):; 	; 	 71.915,07 msec task-clock:u # 14,035 CPUs utilized ( +- 9,53% ); 	 0 context-switches:u # 0,000 /sec; 	 0 cpu-migrations:u # 0,000 /sec; 	 1.168.035 page-faults:u # 29,496 K/sec ( +- 9,58% ); 	 191.815.791.770 cycles:u # 4,844 GHz ( +- 9,53% ) (83,37%); 	 10.610.492.234 stalled-cycles-frontend:u # 10,05% frontend cycles idle ( +- 9,44% ) (83,34%); 	 59.853.476.395 stalled-cycles-backend:u # 56,69% backend cycles idle ( +- 9,56% ) (83,32%); 	 257.750.810.841 instructions:u # 2,44 insn per cycle; 	 # 0,13 stalled cycles per insn ( +- 9,57% ) (83,33%); 	 45.773.330.764 branches:u # 1,156 G/sec ( +- 9,58% ) (83,33%); 	 1.147.567.613 branch-misses:u # 4,56% of all branches ( +- 9,54% ) (83,37%); 	; 	 5,1241 +- 0,0242 seconds time elapsed ( +- 0,47% ); ```. - this PR:. ```console; $ git switch hvg_PR_numba; $ perf stat -r 10 -B hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py; 	 Performance counter stats for 'hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py' (10 runs):; 	; 	 113.085,21 msec task-clock:u # 15,789 CPUs utilized ( +- 9,56% ); 	 0 context-switches:u # 0,000 /sec; 	 0 cpu-migrations:u # 0,000 /sec; 	 1.636.606 page-faults:u # 26,373 K/sec ( +- 9,55% ); 	 310.410.832.165 cycles:u # 5,002 GHz ( +- 9,55% ) (83,35%); 	 14.117.222.045 stalled-cycles-frontend:u # 8,30% frontend cycles idle ( +- 9,46% ) (83,38%); 	 75.813.970.243 stalled-cycles-backend:u # 44,56% backend cycles idle ( +- 9,57% ) (83,35%); 	 373.047.679.552 instructions:u # 2,19 insn per cycle; 	 ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2612#issuecomment-1688394266
https://github.com/scverse/scanpy/pull/2612#issuecomment-1688394266:1375,Performance,Perform,Performance,1375,"B hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py; 	 Performance counter stats for 'hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py' (10 runs):; 	; 	 71.915,07 msec task-clock:u # 14,035 CPUs utilized ( +- 9,53% ); 	 0 context-switches:u # 0,000 /sec; 	 0 cpu-migrations:u # 0,000 /sec; 	 1.168.035 page-faults:u # 29,496 K/sec ( +- 9,58% ); 	 191.815.791.770 cycles:u # 4,844 GHz ( +- 9,53% ) (83,37%); 	 10.610.492.234 stalled-cycles-frontend:u # 10,05% frontend cycles idle ( +- 9,44% ) (83,34%); 	 59.853.476.395 stalled-cycles-backend:u # 56,69% backend cycles idle ( +- 9,56% ) (83,32%); 	 257.750.810.841 instructions:u # 2,44 insn per cycle; 	 # 0,13 stalled cycles per insn ( +- 9,57% ) (83,33%); 	 45.773.330.764 branches:u # 1,156 G/sec ( +- 9,58% ) (83,33%); 	 1.147.567.613 branch-misses:u # 4,56% of all branches ( +- 9,54% ) (83,37%); 	; 	 5,1241 +- 0,0242 seconds time elapsed ( +- 0,47% ); ```. - this PR:. ```console; $ git switch hvg_PR_numba; $ perf stat -r 10 -B hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py; 	 Performance counter stats for 'hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py' (10 runs):; 	; 	 113.085,21 msec task-clock:u # 15,789 CPUs utilized ( +- 9,56% ); 	 0 context-switches:u # 0,000 /sec; 	 0 cpu-migrations:u # 0,000 /sec; 	 1.636.606 page-faults:u # 26,373 K/sec ( +- 9,55% ); 	 310.410.832.165 cycles:u # 5,002 GHz ( +- 9,55% ) (83,35%); 	 14.117.222.045 stalled-cycles-frontend:u # 8,30% frontend cycles idle ( +- 9,46% ) (83,38%); 	 75.813.970.243 stalled-cycles-backend:u # 44,56% backend cycles idle ( +- 9,57% ) (83,35%); 	 373.047.679.552 instructions:u # 2,19 insn per cycle; 	 # 0,11 stalled cycles per insn ( +- 9,57% ) (83,34%); 	 67.830.590.839 branches:u # 1,093 G/sec ( +- 9,58% ) (83,35%); 	 1.702.825.180 branch-misses:u # 4,56% of all branches ( +- 9,56% ) (83,28%); 	; 	 7,1623 +- 0,0560 seconds time elapsed ( +- 0,78% ); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2612#issuecomment-1688394266
https://github.com/scverse/scanpy/pull/2612#issuecomment-1688394266:54,Testability,test,tests,54,"Perf measurements for the use case of running the HVG tests on my machine (not very accurate, and not very reminiscent of how users use it). Tests get a bit slower, real world gets faster. - scanpy master:. ```console; $ git switch master; $ perf stat -r 10 -B hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py; 	 Performance counter stats for 'hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py' (10 runs):; 	; 	 71.915,07 msec task-clock:u # 14,035 CPUs utilized ( +- 9,53% ); 	 0 context-switches:u # 0,000 /sec; 	 0 cpu-migrations:u # 0,000 /sec; 	 1.168.035 page-faults:u # 29,496 K/sec ( +- 9,58% ); 	 191.815.791.770 cycles:u # 4,844 GHz ( +- 9,53% ) (83,37%); 	 10.610.492.234 stalled-cycles-frontend:u # 10,05% frontend cycles idle ( +- 9,44% ) (83,34%); 	 59.853.476.395 stalled-cycles-backend:u # 56,69% backend cycles idle ( +- 9,56% ) (83,32%); 	 257.750.810.841 instructions:u # 2,44 insn per cycle; 	 # 0,13 stalled cycles per insn ( +- 9,57% ) (83,33%); 	 45.773.330.764 branches:u # 1,156 G/sec ( +- 9,58% ) (83,33%); 	 1.147.567.613 branch-misses:u # 4,56% of all branches ( +- 9,54% ) (83,37%); 	; 	 5,1241 +- 0,0242 seconds time elapsed ( +- 0,47% ); ```. - this PR:. ```console; $ git switch hvg_PR_numba; $ perf stat -r 10 -B hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py; 	 Performance counter stats for 'hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py' (10 runs):; 	; 	 113.085,21 msec task-clock:u # 15,789 CPUs utilized ( +- 9,56% ); 	 0 context-switches:u # 0,000 /sec; 	 0 cpu-migrations:u # 0,000 /sec; 	 1.636.606 page-faults:u # 26,373 K/sec ( +- 9,55% ); 	 310.410.832.165 cycles:u # 5,002 GHz ( +- 9,55% ) (83,35%); 	 14.117.222.045 stalled-cycles-frontend:u # 8,30% frontend cycles idle ( +- 9,46% ) (83,38%); 	 75.813.970.243 stalled-cycles-backend:u # 44,56% backend cycles idle ( +- 9,57% ) (83,35%); 	 373.047.679.552 instructions:u # 2,19 insn per cycle; 	 ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2612#issuecomment-1688394266
https://github.com/scverse/scanpy/pull/2612#issuecomment-1688394266:141,Testability,Test,Tests,141,"Perf measurements for the use case of running the HVG tests on my machine (not very accurate, and not very reminiscent of how users use it). Tests get a bit slower, real world gets faster. - scanpy master:. ```console; $ git switch master; $ perf stat -r 10 -B hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py; 	 Performance counter stats for 'hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py' (10 runs):; 	; 	 71.915,07 msec task-clock:u # 14,035 CPUs utilized ( +- 9,53% ); 	 0 context-switches:u # 0,000 /sec; 	 0 cpu-migrations:u # 0,000 /sec; 	 1.168.035 page-faults:u # 29,496 K/sec ( +- 9,58% ); 	 191.815.791.770 cycles:u # 4,844 GHz ( +- 9,53% ) (83,37%); 	 10.610.492.234 stalled-cycles-frontend:u # 10,05% frontend cycles idle ( +- 9,44% ) (83,34%); 	 59.853.476.395 stalled-cycles-backend:u # 56,69% backend cycles idle ( +- 9,56% ) (83,32%); 	 257.750.810.841 instructions:u # 2,44 insn per cycle; 	 # 0,13 stalled cycles per insn ( +- 9,57% ) (83,33%); 	 45.773.330.764 branches:u # 1,156 G/sec ( +- 9,58% ) (83,33%); 	 1.147.567.613 branch-misses:u # 4,56% of all branches ( +- 9,54% ) (83,37%); 	; 	 5,1241 +- 0,0242 seconds time elapsed ( +- 0,47% ); ```. - this PR:. ```console; $ git switch hvg_PR_numba; $ perf stat -r 10 -B hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py; 	 Performance counter stats for 'hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py' (10 runs):; 	; 	 113.085,21 msec task-clock:u # 15,789 CPUs utilized ( +- 9,56% ); 	 0 context-switches:u # 0,000 /sec; 	 0 cpu-migrations:u # 0,000 /sec; 	 1.636.606 page-faults:u # 26,373 K/sec ( +- 9,55% ); 	 310.410.832.165 cycles:u # 5,002 GHz ( +- 9,55% ) (83,35%); 	 14.117.222.045 stalled-cycles-frontend:u # 8,30% frontend cycles idle ( +- 9,46% ) (83,38%); 	 75.813.970.243 stalled-cycles-backend:u # 44,56% backend cycles idle ( +- 9,57% ) (83,35%); 	 373.047.679.552 instructions:u # 2,19 insn per cycle; 	 ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2612#issuecomment-1688394266
https://github.com/scverse/scanpy/pull/2612#issuecomment-1688394266:280,Testability,test,test,280,"Perf measurements for the use case of running the HVG tests on my machine (not very accurate, and not very reminiscent of how users use it). Tests get a bit slower, real world gets faster. - scanpy master:. ```console; $ git switch master; $ perf stat -r 10 -B hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py; 	 Performance counter stats for 'hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py' (10 runs):; 	; 	 71.915,07 msec task-clock:u # 14,035 CPUs utilized ( +- 9,53% ); 	 0 context-switches:u # 0,000 /sec; 	 0 cpu-migrations:u # 0,000 /sec; 	 1.168.035 page-faults:u # 29,496 K/sec ( +- 9,58% ); 	 191.815.791.770 cycles:u # 4,844 GHz ( +- 9,53% ) (83,37%); 	 10.610.492.234 stalled-cycles-frontend:u # 10,05% frontend cycles idle ( +- 9,44% ) (83,34%); 	 59.853.476.395 stalled-cycles-backend:u # 56,69% backend cycles idle ( +- 9,56% ) (83,32%); 	 257.750.810.841 instructions:u # 2,44 insn per cycle; 	 # 0,13 stalled cycles per insn ( +- 9,57% ) (83,33%); 	 45.773.330.764 branches:u # 1,156 G/sec ( +- 9,58% ) (83,33%); 	 1.147.567.613 branch-misses:u # 4,56% of all branches ( +- 9,54% ) (83,37%); 	; 	 5,1241 +- 0,0242 seconds time elapsed ( +- 0,47% ); ```. - this PR:. ```console; $ git switch hvg_PR_numba; $ perf stat -r 10 -B hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py; 	 Performance counter stats for 'hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py' (10 runs):; 	; 	 113.085,21 msec task-clock:u # 15,789 CPUs utilized ( +- 9,56% ); 	 0 context-switches:u # 0,000 /sec; 	 0 cpu-migrations:u # 0,000 /sec; 	 1.636.606 page-faults:u # 26,373 K/sec ( +- 9,55% ); 	 310.410.832.165 cycles:u # 5,002 GHz ( +- 9,55% ) (83,35%); 	 14.117.222.045 stalled-cycles-frontend:u # 8,30% frontend cycles idle ( +- 9,46% ) (83,38%); 	 75.813.970.243 stalled-cycles-backend:u # 44,56% backend cycles idle ( +- 9,57% ) (83,35%); 	 373.047.679.552 instructions:u # 2,19 insn per cycle; 	 ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2612#issuecomment-1688394266
https://github.com/scverse/scanpy/pull/2612#issuecomment-1688394266:300,Testability,test,tests,300,"Perf measurements for the use case of running the HVG tests on my machine (not very accurate, and not very reminiscent of how users use it). Tests get a bit slower, real world gets faster. - scanpy master:. ```console; $ git switch master; $ perf stat -r 10 -B hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py; 	 Performance counter stats for 'hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py' (10 runs):; 	; 	 71.915,07 msec task-clock:u # 14,035 CPUs utilized ( +- 9,53% ); 	 0 context-switches:u # 0,000 /sec; 	 0 cpu-migrations:u # 0,000 /sec; 	 1.168.035 page-faults:u # 29,496 K/sec ( +- 9,58% ); 	 191.815.791.770 cycles:u # 4,844 GHz ( +- 9,53% ) (83,37%); 	 10.610.492.234 stalled-cycles-frontend:u # 10,05% frontend cycles idle ( +- 9,44% ) (83,34%); 	 59.853.476.395 stalled-cycles-backend:u # 56,69% backend cycles idle ( +- 9,56% ) (83,32%); 	 257.750.810.841 instructions:u # 2,44 insn per cycle; 	 # 0,13 stalled cycles per insn ( +- 9,57% ) (83,33%); 	 45.773.330.764 branches:u # 1,156 G/sec ( +- 9,58% ) (83,33%); 	 1.147.567.613 branch-misses:u # 4,56% of all branches ( +- 9,54% ) (83,37%); 	; 	 5,1241 +- 0,0242 seconds time elapsed ( +- 0,47% ); ```. - this PR:. ```console; $ git switch hvg_PR_numba; $ perf stat -r 10 -B hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py; 	 Performance counter stats for 'hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py' (10 runs):; 	; 	 113.085,21 msec task-clock:u # 15,789 CPUs utilized ( +- 9,56% ); 	 0 context-switches:u # 0,000 /sec; 	 0 cpu-migrations:u # 0,000 /sec; 	 1.636.606 page-faults:u # 26,373 K/sec ( +- 9,55% ); 	 310.410.832.165 cycles:u # 5,002 GHz ( +- 9,55% ) (83,35%); 	 14.117.222.045 stalled-cycles-frontend:u # 8,30% frontend cycles idle ( +- 9,46% ) (83,38%); 	 75.813.970.243 stalled-cycles-backend:u # 44,56% backend cycles idle ( +- 9,57% ) (83,35%); 	 373.047.679.552 instructions:u # 2,19 insn per cycle; 	 ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2612#issuecomment-1688394266
https://github.com/scverse/scanpy/pull/2612#issuecomment-1688394266:389,Testability,test,test,389,"Perf measurements for the use case of running the HVG tests on my machine (not very accurate, and not very reminiscent of how users use it). Tests get a bit slower, real world gets faster. - scanpy master:. ```console; $ git switch master; $ perf stat -r 10 -B hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py; 	 Performance counter stats for 'hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py' (10 runs):; 	; 	 71.915,07 msec task-clock:u # 14,035 CPUs utilized ( +- 9,53% ); 	 0 context-switches:u # 0,000 /sec; 	 0 cpu-migrations:u # 0,000 /sec; 	 1.168.035 page-faults:u # 29,496 K/sec ( +- 9,58% ); 	 191.815.791.770 cycles:u # 4,844 GHz ( +- 9,53% ) (83,37%); 	 10.610.492.234 stalled-cycles-frontend:u # 10,05% frontend cycles idle ( +- 9,44% ) (83,34%); 	 59.853.476.395 stalled-cycles-backend:u # 56,69% backend cycles idle ( +- 9,56% ) (83,32%); 	 257.750.810.841 instructions:u # 2,44 insn per cycle; 	 # 0,13 stalled cycles per insn ( +- 9,57% ) (83,33%); 	 45.773.330.764 branches:u # 1,156 G/sec ( +- 9,58% ) (83,33%); 	 1.147.567.613 branch-misses:u # 4,56% of all branches ( +- 9,54% ) (83,37%); 	; 	 5,1241 +- 0,0242 seconds time elapsed ( +- 0,47% ); ```. - this PR:. ```console; $ git switch hvg_PR_numba; $ perf stat -r 10 -B hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py; 	 Performance counter stats for 'hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py' (10 runs):; 	; 	 113.085,21 msec task-clock:u # 15,789 CPUs utilized ( +- 9,56% ); 	 0 context-switches:u # 0,000 /sec; 	 0 cpu-migrations:u # 0,000 /sec; 	 1.636.606 page-faults:u # 26,373 K/sec ( +- 9,55% ); 	 310.410.832.165 cycles:u # 5,002 GHz ( +- 9,55% ) (83,35%); 	 14.117.222.045 stalled-cycles-frontend:u # 8,30% frontend cycles idle ( +- 9,46% ) (83,38%); 	 75.813.970.243 stalled-cycles-backend:u # 44,56% backend cycles idle ( +- 9,57% ) (83,35%); 	 373.047.679.552 instructions:u # 2,19 insn per cycle; 	 ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2612#issuecomment-1688394266
https://github.com/scverse/scanpy/pull/2612#issuecomment-1688394266:409,Testability,test,tests,409,"Perf measurements for the use case of running the HVG tests on my machine (not very accurate, and not very reminiscent of how users use it). Tests get a bit slower, real world gets faster. - scanpy master:. ```console; $ git switch master; $ perf stat -r 10 -B hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py; 	 Performance counter stats for 'hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py' (10 runs):; 	; 	 71.915,07 msec task-clock:u # 14,035 CPUs utilized ( +- 9,53% ); 	 0 context-switches:u # 0,000 /sec; 	 0 cpu-migrations:u # 0,000 /sec; 	 1.168.035 page-faults:u # 29,496 K/sec ( +- 9,58% ); 	 191.815.791.770 cycles:u # 4,844 GHz ( +- 9,53% ) (83,37%); 	 10.610.492.234 stalled-cycles-frontend:u # 10,05% frontend cycles idle ( +- 9,44% ) (83,34%); 	 59.853.476.395 stalled-cycles-backend:u # 56,69% backend cycles idle ( +- 9,56% ) (83,32%); 	 257.750.810.841 instructions:u # 2,44 insn per cycle; 	 # 0,13 stalled cycles per insn ( +- 9,57% ) (83,33%); 	 45.773.330.764 branches:u # 1,156 G/sec ( +- 9,58% ) (83,33%); 	 1.147.567.613 branch-misses:u # 4,56% of all branches ( +- 9,54% ) (83,37%); 	; 	 5,1241 +- 0,0242 seconds time elapsed ( +- 0,47% ); ```. - this PR:. ```console; $ git switch hvg_PR_numba; $ perf stat -r 10 -B hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py; 	 Performance counter stats for 'hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py' (10 runs):; 	; 	 113.085,21 msec task-clock:u # 15,789 CPUs utilized ( +- 9,56% ); 	 0 context-switches:u # 0,000 /sec; 	 0 cpu-migrations:u # 0,000 /sec; 	 1.636.606 page-faults:u # 26,373 K/sec ( +- 9,55% ); 	 310.410.832.165 cycles:u # 5,002 GHz ( +- 9,55% ) (83,35%); 	 14.117.222.045 stalled-cycles-frontend:u # 8,30% frontend cycles idle ( +- 9,46% ) (83,38%); 	 75.813.970.243 stalled-cycles-backend:u # 44,56% backend cycles idle ( +- 9,57% ) (83,35%); 	 373.047.679.552 instructions:u # 2,19 insn per cycle; 	 ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2612#issuecomment-1688394266
https://github.com/scverse/scanpy/pull/2612#issuecomment-1688394266:1316,Testability,test,test,1316,"B hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py; 	 Performance counter stats for 'hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py' (10 runs):; 	; 	 71.915,07 msec task-clock:u # 14,035 CPUs utilized ( +- 9,53% ); 	 0 context-switches:u # 0,000 /sec; 	 0 cpu-migrations:u # 0,000 /sec; 	 1.168.035 page-faults:u # 29,496 K/sec ( +- 9,58% ); 	 191.815.791.770 cycles:u # 4,844 GHz ( +- 9,53% ) (83,37%); 	 10.610.492.234 stalled-cycles-frontend:u # 10,05% frontend cycles idle ( +- 9,44% ) (83,34%); 	 59.853.476.395 stalled-cycles-backend:u # 56,69% backend cycles idle ( +- 9,56% ) (83,32%); 	 257.750.810.841 instructions:u # 2,44 insn per cycle; 	 # 0,13 stalled cycles per insn ( +- 9,57% ) (83,33%); 	 45.773.330.764 branches:u # 1,156 G/sec ( +- 9,58% ) (83,33%); 	 1.147.567.613 branch-misses:u # 4,56% of all branches ( +- 9,54% ) (83,37%); 	; 	 5,1241 +- 0,0242 seconds time elapsed ( +- 0,47% ); ```. - this PR:. ```console; $ git switch hvg_PR_numba; $ perf stat -r 10 -B hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py; 	 Performance counter stats for 'hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py' (10 runs):; 	; 	 113.085,21 msec task-clock:u # 15,789 CPUs utilized ( +- 9,56% ); 	 0 context-switches:u # 0,000 /sec; 	 0 cpu-migrations:u # 0,000 /sec; 	 1.636.606 page-faults:u # 26,373 K/sec ( +- 9,55% ); 	 310.410.832.165 cycles:u # 5,002 GHz ( +- 9,55% ) (83,35%); 	 14.117.222.045 stalled-cycles-frontend:u # 8,30% frontend cycles idle ( +- 9,46% ) (83,38%); 	 75.813.970.243 stalled-cycles-backend:u # 44,56% backend cycles idle ( +- 9,57% ) (83,35%); 	 373.047.679.552 instructions:u # 2,19 insn per cycle; 	 # 0,11 stalled cycles per insn ( +- 9,57% ) (83,34%); 	 67.830.590.839 branches:u # 1,093 G/sec ( +- 9,58% ) (83,35%); 	 1.702.825.180 branch-misses:u # 4,56% of all branches ( +- 9,56% ) (83,28%); 	; 	 7,1623 +- 0,0560 seconds time elapsed ( +- 0,78% ); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2612#issuecomment-1688394266
https://github.com/scverse/scanpy/pull/2612#issuecomment-1688394266:1336,Testability,test,tests,1336,"B hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py; 	 Performance counter stats for 'hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py' (10 runs):; 	; 	 71.915,07 msec task-clock:u # 14,035 CPUs utilized ( +- 9,53% ); 	 0 context-switches:u # 0,000 /sec; 	 0 cpu-migrations:u # 0,000 /sec; 	 1.168.035 page-faults:u # 29,496 K/sec ( +- 9,58% ); 	 191.815.791.770 cycles:u # 4,844 GHz ( +- 9,53% ) (83,37%); 	 10.610.492.234 stalled-cycles-frontend:u # 10,05% frontend cycles idle ( +- 9,44% ) (83,34%); 	 59.853.476.395 stalled-cycles-backend:u # 56,69% backend cycles idle ( +- 9,56% ) (83,32%); 	 257.750.810.841 instructions:u # 2,44 insn per cycle; 	 # 0,13 stalled cycles per insn ( +- 9,57% ) (83,33%); 	 45.773.330.764 branches:u # 1,156 G/sec ( +- 9,58% ) (83,33%); 	 1.147.567.613 branch-misses:u # 4,56% of all branches ( +- 9,54% ) (83,37%); 	; 	 5,1241 +- 0,0242 seconds time elapsed ( +- 0,47% ); ```. - this PR:. ```console; $ git switch hvg_PR_numba; $ perf stat -r 10 -B hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py; 	 Performance counter stats for 'hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py' (10 runs):; 	; 	 113.085,21 msec task-clock:u # 15,789 CPUs utilized ( +- 9,56% ); 	 0 context-switches:u # 0,000 /sec; 	 0 cpu-migrations:u # 0,000 /sec; 	 1.636.606 page-faults:u # 26,373 K/sec ( +- 9,55% ); 	 310.410.832.165 cycles:u # 5,002 GHz ( +- 9,55% ) (83,35%); 	 14.117.222.045 stalled-cycles-frontend:u # 8,30% frontend cycles idle ( +- 9,46% ) (83,38%); 	 75.813.970.243 stalled-cycles-backend:u # 44,56% backend cycles idle ( +- 9,57% ) (83,35%); 	 373.047.679.552 instructions:u # 2,19 insn per cycle; 	 # 0,11 stalled cycles per insn ( +- 9,57% ) (83,34%); 	 67.830.590.839 branches:u # 1,093 G/sec ( +- 9,58% ) (83,35%); 	 1.702.825.180 branch-misses:u # 4,56% of all branches ( +- 9,56% ) (83,28%); 	; 	 7,1623 +- 0,0560 seconds time elapsed ( +- 0,78% ); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2612#issuecomment-1688394266
https://github.com/scverse/scanpy/pull/2612#issuecomment-1688394266:1425,Testability,test,test,1425,"B hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py; 	 Performance counter stats for 'hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py' (10 runs):; 	; 	 71.915,07 msec task-clock:u # 14,035 CPUs utilized ( +- 9,53% ); 	 0 context-switches:u # 0,000 /sec; 	 0 cpu-migrations:u # 0,000 /sec; 	 1.168.035 page-faults:u # 29,496 K/sec ( +- 9,58% ); 	 191.815.791.770 cycles:u # 4,844 GHz ( +- 9,53% ) (83,37%); 	 10.610.492.234 stalled-cycles-frontend:u # 10,05% frontend cycles idle ( +- 9,44% ) (83,34%); 	 59.853.476.395 stalled-cycles-backend:u # 56,69% backend cycles idle ( +- 9,56% ) (83,32%); 	 257.750.810.841 instructions:u # 2,44 insn per cycle; 	 # 0,13 stalled cycles per insn ( +- 9,57% ) (83,33%); 	 45.773.330.764 branches:u # 1,156 G/sec ( +- 9,58% ) (83,33%); 	 1.147.567.613 branch-misses:u # 4,56% of all branches ( +- 9,54% ) (83,37%); 	; 	 5,1241 +- 0,0242 seconds time elapsed ( +- 0,47% ); ```. - this PR:. ```console; $ git switch hvg_PR_numba; $ perf stat -r 10 -B hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py; 	 Performance counter stats for 'hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py' (10 runs):; 	; 	 113.085,21 msec task-clock:u # 15,789 CPUs utilized ( +- 9,56% ); 	 0 context-switches:u # 0,000 /sec; 	 0 cpu-migrations:u # 0,000 /sec; 	 1.636.606 page-faults:u # 26,373 K/sec ( +- 9,55% ); 	 310.410.832.165 cycles:u # 5,002 GHz ( +- 9,55% ) (83,35%); 	 14.117.222.045 stalled-cycles-frontend:u # 8,30% frontend cycles idle ( +- 9,46% ) (83,38%); 	 75.813.970.243 stalled-cycles-backend:u # 44,56% backend cycles idle ( +- 9,57% ) (83,35%); 	 373.047.679.552 instructions:u # 2,19 insn per cycle; 	 # 0,11 stalled cycles per insn ( +- 9,57% ) (83,34%); 	 67.830.590.839 branches:u # 1,093 G/sec ( +- 9,58% ) (83,35%); 	 1.702.825.180 branch-misses:u # 4,56% of all branches ( +- 9,56% ) (83,28%); 	; 	 7,1623 +- 0,0560 seconds time elapsed ( +- 0,78% ); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2612#issuecomment-1688394266
https://github.com/scverse/scanpy/pull/2612#issuecomment-1688394266:1445,Testability,test,tests,1445,"B hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py; 	 Performance counter stats for 'hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py' (10 runs):; 	; 	 71.915,07 msec task-clock:u # 14,035 CPUs utilized ( +- 9,53% ); 	 0 context-switches:u # 0,000 /sec; 	 0 cpu-migrations:u # 0,000 /sec; 	 1.168.035 page-faults:u # 29,496 K/sec ( +- 9,58% ); 	 191.815.791.770 cycles:u # 4,844 GHz ( +- 9,53% ) (83,37%); 	 10.610.492.234 stalled-cycles-frontend:u # 10,05% frontend cycles idle ( +- 9,44% ) (83,34%); 	 59.853.476.395 stalled-cycles-backend:u # 56,69% backend cycles idle ( +- 9,56% ) (83,32%); 	 257.750.810.841 instructions:u # 2,44 insn per cycle; 	 # 0,13 stalled cycles per insn ( +- 9,57% ) (83,33%); 	 45.773.330.764 branches:u # 1,156 G/sec ( +- 9,58% ) (83,33%); 	 1.147.567.613 branch-misses:u # 4,56% of all branches ( +- 9,54% ) (83,37%); 	; 	 5,1241 +- 0,0242 seconds time elapsed ( +- 0,47% ); ```. - this PR:. ```console; $ git switch hvg_PR_numba; $ perf stat -r 10 -B hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py; 	 Performance counter stats for 'hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py' (10 runs):; 	; 	 113.085,21 msec task-clock:u # 15,789 CPUs utilized ( +- 9,56% ); 	 0 context-switches:u # 0,000 /sec; 	 0 cpu-migrations:u # 0,000 /sec; 	 1.636.606 page-faults:u # 26,373 K/sec ( +- 9,55% ); 	 310.410.832.165 cycles:u # 5,002 GHz ( +- 9,55% ) (83,35%); 	 14.117.222.045 stalled-cycles-frontend:u # 8,30% frontend cycles idle ( +- 9,46% ) (83,38%); 	 75.813.970.243 stalled-cycles-backend:u # 44,56% backend cycles idle ( +- 9,57% ) (83,35%); 	 373.047.679.552 instructions:u # 2,19 insn per cycle; 	 # 0,11 stalled cycles per insn ( +- 9,57% ) (83,34%); 	 67.830.590.839 branches:u # 1,093 G/sec ( +- 9,58% ) (83,35%); 	 1.702.825.180 branch-misses:u # 4,56% of all branches ( +- 9,56% ) (83,28%); 	; 	 7,1623 +- 0,0560 seconds time elapsed ( +- 0,78% ); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2612#issuecomment-1688394266
https://github.com/scverse/scanpy/pull/2613#issuecomment-1677226444:331,Availability,error,error-reference,331,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2613?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@a8b931a`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2613 +/- ##; ========================================; Coverage ? 72.18% ; ========================================; Files ? 104 ; Lines ? 11643 ; Branches ? 0 ; ========================================; Hits ? 8405 ; Misses ? 3238 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2613#issuecomment-1677226444
https://github.com/scverse/scanpy/pull/2613#issuecomment-1677226444:279,Usability,learn,learn,279,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2613?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@a8b931a`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2613 +/- ##; ========================================; Coverage ? 72.18% ; ========================================; Files ? 104 ; Lines ? 11643 ; Branches ? 0 ; ========================================; Hits ? 8405 ; Misses ? 3238 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2613#issuecomment-1677226444
https://github.com/scverse/scanpy/pull/2616#issuecomment-1677462171:331,Availability,error,error-reference,331,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2616?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@a8b931a`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2616 +/- ##; ========================================; Coverage ? 72.18% ; ========================================; Files ? 104 ; Lines ? 11642 ; Branches ? 0 ; ========================================; Hits ? 8404 ; Misses ? 3238 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2616#issuecomment-1677462171
https://github.com/scverse/scanpy/pull/2616#issuecomment-1677462171:279,Usability,learn,learn,279,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2616?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@a8b931a`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2616 +/- ##; ========================================; Coverage ? 72.18% ; ========================================; Files ? 104 ; Lines ? 11642 ; Branches ? 0 ; ========================================; Hits ? 8404 ; Misses ? 3238 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2616#issuecomment-1677462171
https://github.com/scverse/scanpy/pull/2619#issuecomment-1678888447:331,Availability,error,error-reference,331,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2619?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@fbd73ac`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2619 +/- ##; ========================================; Coverage ? 72.18% ; ========================================; Files ? 104 ; Lines ? 11643 ; Branches ? 0 ; ========================================; Hits ? 8405 ; Misses ? 3238 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2619#issuecomment-1678888447
https://github.com/scverse/scanpy/pull/2619#issuecomment-1678888447:279,Usability,learn,learn,279,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2619?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@fbd73ac`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2619 +/- ##; ========================================; Coverage ? 72.18% ; ========================================; Files ? 104 ; Lines ? 11643 ; Branches ? 0 ; ========================================; Hits ? 8405 ; Misses ? 3238 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2619#issuecomment-1678888447
https://github.com/scverse/scanpy/pull/2620#issuecomment-1681915003:331,Availability,error,error-reference,331,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2620?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@a6f6c6d`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2620 +/- ##; ========================================; Coverage ? 72.18% ; ========================================; Files ? 104 ; Lines ? 11643 ; Branches ? 0 ; ========================================; Hits ? 8405 ; Misses ? 3238 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2620#issuecomment-1681915003
https://github.com/scverse/scanpy/pull/2620#issuecomment-1681915003:279,Usability,learn,learn,279,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2620?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@a6f6c6d`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2620 +/- ##; ========================================; Coverage ? 72.18% ; ========================================; Files ? 104 ; Lines ? 11643 ; Branches ? 0 ; ========================================; Hits ? 8405 ; Misses ? 3238 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2620#issuecomment-1681915003
https://github.com/scverse/scanpy/pull/2621#issuecomment-1682386508:2170,Testability,test,testing,2170,app.codecov.io/gh/scverse/scanpy/pull/2621?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2621?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L191dGlscy9fX2luaXRfXy5weQ==) | `65.74% <100.00%> (ø)` | |; | [scanpy/experimental/pp/\_highly\_variable\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/2621?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2V4cGVyaW1lbnRhbC9wcC9faGlnaGx5X3ZhcmlhYmxlX2dlbmVzLnB5) | `63.69% <100.00%> (ø)` | |; | [scanpy/preprocessing/\_utils.py](https://app.codecov.io/gh/scverse/scanpy/pull/2621?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX3V0aWxzLnB5) | `44.26% <100.00%> (+0.92%)` | :arrow_up: |; | [scanpy/testing/\_pytest/fixtures/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2621?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9maXh0dXJlcy9fX2luaXRfXy5weQ==) | `95.45% <100.00%> (+0.45%)` | :arrow_up: |; | [scanpy/tools/\_rank\_genes\_groups.py](https://app.codecov.io/gh/scverse/scanpy/pull/2621?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rvb2xzL19yYW5rX2dlbmVzX2dyb3Vwcy5weQ==) | `92.77% <100.00%> (-0.03%)` | :arrow_down: |; | [scanpy/\_utils/\_dask.py](https://app.codecov.io/gh/scverse/scanpy/pull/2621?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L191dGlscy9fZGFzay5weQ==) | `81.48% <81.48%> (ø)` | |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2621#issuecomment-1682386508
https://github.com/scverse/scanpy/pull/2621#issuecomment-1753182156:2458,Performance,optimiz,optimization,2458,"; 5336730508589856979 --> 8881403918513157720. 5898621639535744825((any)); 8881403918513157720 --> 5898621639535744825. 2373763162411159295[""(1, 1)""]; 2513425685193572888 --> 2373763162411159295. 1659302467096852217((any)); 2373763162411159295 --> 1659302467096852217. 7195453449900658805[""(0, 0)""]; 6263727941369393084 --> 7195453449900658805. 7976077601232067203((any-\naggregate)); 7195453449900658805 --> 7976077601232067203. 687812693798660380[""(0, 1)""]; 7256567839680908872 --> 687812693798660380; 687812693798660380 --> 7976077601232067203. 3901936098833081796[""(1, 0)""]; 5898621639535744825 --> 3901936098833081796; 3901936098833081796 --> 7976077601232067203. 8795010127805778162[""(1, 1)""]; 1659302467096852217 --> 8795010127805778162; 8795010127805778162 --> 7976077601232067203. 1203378416021505679[""()""]; 7976077601232067203 --> 1203378416021505679; 9179805111332178500((invert)). 1203378416021505679 --> 9179805111332178500; 5169565091578776769[""()""]; 9179805111332178500 --> 5169565091578776769; 814146044537405006((and)); 5169565091578776769 --> 814146044537405006. 1050532709569538834[""()""]; 814146044537405006 --> 1050532709569538834; ```. I *am* of course using `map_blocks`. If we really wanted, I assume we could still replace sequences of two operations like. ```mermaid; flowchart LR. step0[""(0, 0)""] --> op0((signbit)) --> step1[""(0, 0)""] --> op1((any)) --> step2[""(0, 0)""]; ```. with individual operations, but I’m not sure if that’s worth the code readability problems. Smells of premature optimization. <details>; <summary>mean_var graph</summary>. ```mermaid; flowchart LR. step000[""(0, 0)""] --> op000((mean_\nchunk)) --> step001[""(0, 0)""] --> op00((mean_agg-\naggregate)) --> step00[""0""]; step100[""(1, 0)""] --> op100((mean_\nchunk)) --> step101[""(1, 0)""] --> op00. step010[""(0, 1)""] --> op010((mean_\nchunk)) --> step011[""(0, 1)""] --> op10((mean_agg-\naggregate)) --> step10[""1""]; step110[""(1, 1)""] --> op110((mean_\nchunk)) --> step111[""(1, 1)""] --> op10; ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2621#issuecomment-1753182156
https://github.com/scverse/scanpy/pull/2624#issuecomment-1691512482:244,Performance,load,load,244,"When the object is backed, but `copy=False`, the ValueError, which before occured for both `copy=False` and `copy=True`, is shown:; `ValueError: To copy an AnnData object in backed mode, pass a filename: '.copy(filename='myfilename.h5ad')'. To load the object into memory, use '.to_memory()'.`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2624#issuecomment-1691512482
https://github.com/scverse/scanpy/pull/2624#issuecomment-1691514632:35,Availability,error,error,35,"Could you throw a more informative error message for `copy=False`? Maybe:. `NotImplementedError(""Inplace subsampling is not implemented for backed objects"")`. ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2624#issuecomment-1691514632
https://github.com/scverse/scanpy/pull/2624#issuecomment-1691514632:41,Integrability,message,message,41,"Could you throw a more informative error message for `copy=False`? Maybe:. `NotImplementedError(""Inplace subsampling is not implemented for backed objects"")`. ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2624#issuecomment-1691514632
https://github.com/scverse/scanpy/issues/2626#issuecomment-1748396363:627,Usability,guid,guidance,627,"Hi, thanks for your interest in scanpy!. For user questions, it would be great if you could ask your question on [Discourse](https://discourse.scverse.org/); this is the designated discussion forum for user questions regarding scverse tools (such as scanpy). This way, here at GitHub the focus can be put on development, while on Discourse user questions can be answered in more detail and in a manner that future users can better find previous questions. If you think your question is related to a development issue or I misinterpreted it as a user question, we're happy to look into it here on GitHub!. Hope this gives you a guidance for receiving helpful support for your question!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2626#issuecomment-1748396363
https://github.com/scverse/scanpy/issues/2628#issuecomment-1742964494:744,Deployability,update,updates,744,"Hi, . Thank you for your interest in scanpy and for raising your question here!. It looks like you are interested in getting the results of `sc.tl.rank_genes_groups`.; For this, we recommend using `sc.get.rank_genes_groups` - you can find more about scanpy’s getters [here](https://scanpy.readthedocs.io/en/stable/api.html#module-scanpy.get). This might look for example like this:. ```py; import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(pbmc, groupby=""louvain"", pts=True, use_raw=True). dedf = sc.get.rank_genes_groups_df(pbmc, group=""0""); ```. By accessing the `.uns` as you outlined, just using the ordering of the pts column might not match the ordering of the sorted genes.; This behaviour is subject to updates in the future - in any case `sc.get.rank_genes_groups` is the way to go here :). I hope this helps?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2628#issuecomment-1742964494
https://github.com/scverse/scanpy/issues/2628#issuecomment-1742964494:584,Security,access,accessing,584,"Hi, . Thank you for your interest in scanpy and for raising your question here!. It looks like you are interested in getting the results of `sc.tl.rank_genes_groups`.; For this, we recommend using `sc.get.rank_genes_groups` - you can find more about scanpy’s getters [here](https://scanpy.readthedocs.io/en/stable/api.html#module-scanpy.get). This might look for example like this:. ```py; import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(pbmc, groupby=""louvain"", pts=True, use_raw=True). dedf = sc.get.rank_genes_groups_df(pbmc, group=""0""); ```. By accessing the `.uns` as you outlined, just using the ordering of the pts column might not match the ordering of the sorted genes.; This behaviour is subject to updates in the future - in any case `sc.get.rank_genes_groups` is the way to go here :). I hope this helps?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2628#issuecomment-1742964494
https://github.com/scverse/scanpy/issues/2629#issuecomment-1708220273:162,Performance,Load,Loading,162,"Hi, thanks for your interest in scanpy!. I’ll try to comment on your observations here with your code example:. ```; import scanpy as sc; import numpy as np; ### Loading and preprocessing data; adata = sc.datasets.pbmc3k_processed(). ### Defining scale function; def mean_var(X, axis=0):; mean = np.mean(X, axis=axis, dtype=np.float64); mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64); var = mean_sq - mean**2; # enforce R convention (unbiased estimator) for variance; var *= X.shape[axis] / (X.shape[axis] - 1); return mean, var; ```. As a first note of caution, in your code your function actually modifies the original data matrix, of the scanpy object - which is used again later in the snippet.; → We should create a copy of `X`. Else the code overwrites this object, and ends up comparing an object with itself, while simply using two names for it (this caused your `==` comparisons to evaluate as `True`, but is not what you intend to test).; ```; def my_scale_function(X, clip=False):; # need to make a copy of X; Y = X.copy(); mean, var = mean_var(Y, axis=0); Y -= mean; std = np.sqrt(var); #std[std == 0] = 1; Y /= std; if clip:; Y = np.clip(X, -10, 10); return np.matrix(Y); ```. As a second note of caution, floating point numbers should not be compared with the `==` operator (see for example [here](https://randomascii.wordpress.com/2012/02/25/comparing-floating-point-numbers-2012-edition/)). → A more common way would be to use e.g. `np.allclose()` for this purpose. ```; ### Scanpy scale vs my_scale_function. print(""Rescaled with my_scale_function:""); mtx_rescaled = my_scale_function(adata.X). print(""Do a numpy check for closeness of floats:""); print(np.allclose(adata.X, mtx_rescaled)); ```. ```; Do a numpy check for closeness of floats:; False; ```. You can see that this test actually fails. This is because not all genes appear scaled, and your function now actually is doing that.; ```; adata.X.var(0); ```. ```; array([0.9996213 , 0.97964925, 0.29805112, ..., ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629#issuecomment-1708220273
https://github.com/scverse/scanpy/issues/2629#issuecomment-1708220273:956,Testability,test,test,956,"Hi, thanks for your interest in scanpy!. I’ll try to comment on your observations here with your code example:. ```; import scanpy as sc; import numpy as np; ### Loading and preprocessing data; adata = sc.datasets.pbmc3k_processed(). ### Defining scale function; def mean_var(X, axis=0):; mean = np.mean(X, axis=axis, dtype=np.float64); mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64); var = mean_sq - mean**2; # enforce R convention (unbiased estimator) for variance; var *= X.shape[axis] / (X.shape[axis] - 1); return mean, var; ```. As a first note of caution, in your code your function actually modifies the original data matrix, of the scanpy object - which is used again later in the snippet.; → We should create a copy of `X`. Else the code overwrites this object, and ends up comparing an object with itself, while simply using two names for it (this caused your `==` comparisons to evaluate as `True`, but is not what you intend to test).; ```; def my_scale_function(X, clip=False):; # need to make a copy of X; Y = X.copy(); mean, var = mean_var(Y, axis=0); Y -= mean; std = np.sqrt(var); #std[std == 0] = 1; Y /= std; if clip:; Y = np.clip(X, -10, 10); return np.matrix(Y); ```. As a second note of caution, floating point numbers should not be compared with the `==` operator (see for example [here](https://randomascii.wordpress.com/2012/02/25/comparing-floating-point-numbers-2012-edition/)). → A more common way would be to use e.g. `np.allclose()` for this purpose. ```; ### Scanpy scale vs my_scale_function. print(""Rescaled with my_scale_function:""); mtx_rescaled = my_scale_function(adata.X). print(""Do a numpy check for closeness of floats:""); print(np.allclose(adata.X, mtx_rescaled)); ```. ```; Do a numpy check for closeness of floats:; False; ```. You can see that this test actually fails. This is because not all genes appear scaled, and your function now actually is doing that.; ```; adata.X.var(0); ```. ```; array([0.9996213 , 0.97964925, 0.29805112, ..., ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629#issuecomment-1708220273
https://github.com/scverse/scanpy/issues/2629#issuecomment-1708220273:1809,Testability,test,test,1809,"g an object with itself, while simply using two names for it (this caused your `==` comparisons to evaluate as `True`, but is not what you intend to test).; ```; def my_scale_function(X, clip=False):; # need to make a copy of X; Y = X.copy(); mean, var = mean_var(Y, axis=0); Y -= mean; std = np.sqrt(var); #std[std == 0] = 1; Y /= std; if clip:; Y = np.clip(X, -10, 10); return np.matrix(Y); ```. As a second note of caution, floating point numbers should not be compared with the `==` operator (see for example [here](https://randomascii.wordpress.com/2012/02/25/comparing-floating-point-numbers-2012-edition/)). → A more common way would be to use e.g. `np.allclose()` for this purpose. ```; ### Scanpy scale vs my_scale_function. print(""Rescaled with my_scale_function:""); mtx_rescaled = my_scale_function(adata.X). print(""Do a numpy check for closeness of floats:""); print(np.allclose(adata.X, mtx_rescaled)); ```. ```; Do a numpy check for closeness of floats:; False; ```. You can see that this test actually fails. This is because not all genes appear scaled, and your function now actually is doing that.; ```; adata.X.var(0); ```. ```; array([0.9996213 , 0.97964925, 0.29805112, ..., 0.78701097, 0.9980862 ,; 0.9996219 ], dtype=float32); ```; This could happen if e.g. cells were used to scale gene expression, which were later discarded in quality control. So when calling `my_scale_function` or `sc.pp.scale`, we expect the cell-by-gene matrix to change at first. ```; mtx_rescaled_sc = sc.pp.scale(adata.X, copy=True). print(""Do a numpy check for closeness of floats:""); print(np.allclose(adata.X, mtx_rescaled_sc)); ```; ```; Do a numpy check for closeness of floats:; False; ```; But not anymore if we call `sc.pp.scale` again. ```; mtx_rescaled_sc_II = sc.pp.scale(mtx_rescaled_sc, copy=True). print(""Do a numpy check for closeness of floats:""); print(np.allclose(mtx_rescaled_sc, mtx_rescaled_sc_II)); ```. ```; Do a numpy check for closeness of floats:; True; ```. This is the behavi",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629#issuecomment-1708220273
https://github.com/scverse/scanpy/issues/2629#issuecomment-1708220273:838,Usability,simpl,simply,838,"Hi, thanks for your interest in scanpy!. I’ll try to comment on your observations here with your code example:. ```; import scanpy as sc; import numpy as np; ### Loading and preprocessing data; adata = sc.datasets.pbmc3k_processed(). ### Defining scale function; def mean_var(X, axis=0):; mean = np.mean(X, axis=axis, dtype=np.float64); mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64); var = mean_sq - mean**2; # enforce R convention (unbiased estimator) for variance; var *= X.shape[axis] / (X.shape[axis] - 1); return mean, var; ```. As a first note of caution, in your code your function actually modifies the original data matrix, of the scanpy object - which is used again later in the snippet.; → We should create a copy of `X`. Else the code overwrites this object, and ends up comparing an object with itself, while simply using two names for it (this caused your `==` comparisons to evaluate as `True`, but is not what you intend to test).; ```; def my_scale_function(X, clip=False):; # need to make a copy of X; Y = X.copy(); mean, var = mean_var(Y, axis=0); Y -= mean; std = np.sqrt(var); #std[std == 0] = 1; Y /= std; if clip:; Y = np.clip(X, -10, 10); return np.matrix(Y); ```. As a second note of caution, floating point numbers should not be compared with the `==` operator (see for example [here](https://randomascii.wordpress.com/2012/02/25/comparing-floating-point-numbers-2012-edition/)). → A more common way would be to use e.g. `np.allclose()` for this purpose. ```; ### Scanpy scale vs my_scale_function. print(""Rescaled with my_scale_function:""); mtx_rescaled = my_scale_function(adata.X). print(""Do a numpy check for closeness of floats:""); print(np.allclose(adata.X, mtx_rescaled)); ```. ```; Do a numpy check for closeness of floats:; False; ```. You can see that this test actually fails. This is because not all genes appear scaled, and your function now actually is doing that.; ```; adata.X.var(0); ```. ```; array([0.9996213 , 0.97964925, 0.29805112, ..., ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629#issuecomment-1708220273
https://github.com/scverse/scanpy/issues/2636#issuecomment-1691508076:206,Deployability,update,update,206,"Let’s coordinate here and come up with what we think is the best strategy:. - @grst and me thought both are fine solutions, that’s why we closed https://github.com/scverse/scanpy-tutorials/issues/64, let’s update that one with what we come up with; - I think the main discussion should happen in https://github.com/scverse/cookiecutter-scverse/issues/40, then we close this issue when we implemented that for scanpy",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2636#issuecomment-1691508076
https://github.com/scverse/scanpy/issues/2636#issuecomment-1904033065:204,Deployability,release,release,204,"After @ilan-gold mentioned that scanpy’s tutorials are actually not reproducible, I made an issue for that: https://github.com/scverse/scanpy-tutorials/issues/79. Maybe we need to address that before the release, that’ll also get rid of the warnings. If you need to suppress them, I think this extension could be an acceptable solution: https://github.com/picnixz/sphinx-zeta-suppress",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2636#issuecomment-1904033065
https://github.com/scverse/scanpy/pull/2638#issuecomment-1691735842:331,Availability,error,error-reference,331,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2638?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@9ba0251`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2638 +/- ##; ========================================; Coverage ? 72.18% ; ========================================; Files ? 104 ; Lines ? 11643 ; Branches ? 0 ; ========================================; Hits ? 8405 ; Misses ? 3238 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2638#issuecomment-1691735842
https://github.com/scverse/scanpy/pull/2638#issuecomment-1691735842:279,Usability,learn,learn,279,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2638?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@9ba0251`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2638 +/- ##; ========================================; Coverage ? 72.18% ; ========================================; Files ? 104 ; Lines ? 11643 ; Branches ? 0 ; ========================================; Hits ? 8405 ; Misses ? 3238 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2638#issuecomment-1691735842
https://github.com/scverse/scanpy/pull/2641#issuecomment-1691930772:331,Availability,error,error-reference,331,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2641?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@8aa93e2`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2641 +/- ##; ========================================; Coverage ? 72.18% ; ========================================; Files ? 104 ; Lines ? 11643 ; Branches ? 0 ; ========================================; Hits ? 8405 ; Misses ? 3238 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2641#issuecomment-1691930772
https://github.com/scverse/scanpy/pull/2641#issuecomment-1691930772:279,Usability,learn,learn,279,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2641?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@8aa93e2`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2641 +/- ##; ========================================; Coverage ? 72.18% ; ========================================; Files ? 104 ; Lines ? 11643 ; Branches ? 0 ; ========================================; Hits ? 8405 ; Misses ? 3238 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2641#issuecomment-1691930772
https://github.com/scverse/scanpy/pull/2643#issuecomment-1696930445:331,Availability,error,error-reference,331,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2643?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@6e8a8b4`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2643 +/- ##; ========================================; Coverage ? 72.18% ; ========================================; Files ? 104 ; Lines ? 11643 ; Branches ? 0 ; ========================================; Hits ? 8405 ; Misses ? 3238 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2643#issuecomment-1696930445
https://github.com/scverse/scanpy/pull/2643#issuecomment-1696930445:279,Usability,learn,learn,279,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2643?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@6e8a8b4`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2643 +/- ##; ========================================; Coverage ? 72.18% ; ========================================; Files ? 104 ; Lines ? 11643 ; Branches ? 0 ; ========================================; Hits ? 8405 ; Misses ? 3238 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2643#issuecomment-1696930445
https://github.com/scverse/scanpy/issues/2645#issuecomment-1701530406:34,Deployability,upgrade,upgraded,34,I noticed I'm on scanpy 1.9.3 and upgraded to scanpy 1.9.4 as well and tried again and have the same issue,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645#issuecomment-1701530406
https://github.com/scverse/scanpy/pull/2646#issuecomment-1702454355:42,Testability,test,tests,42,thanks! let’s see if re-running the flaky tests makes CI pass,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2646#issuecomment-1702454355
https://github.com/scverse/scanpy/pull/2647#issuecomment-1702451897:12,Testability,test,tests,12,"thanks! the tests here are a bit flaky it seems, and have nothing to do with your change",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2647#issuecomment-1702451897
https://github.com/scverse/scanpy/pull/2652#issuecomment-1706132242:331,Availability,error,error-reference,331,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2652?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@16e7e9f`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2652 +/- ##; ========================================; Coverage ? 72.18% ; ========================================; Files ? 104 ; Lines ? 11643 ; Branches ? 0 ; ========================================; Hits ? 8405 ; Misses ? 3238 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2652#issuecomment-1706132242
https://github.com/scverse/scanpy/pull/2652#issuecomment-1706132242:279,Usability,learn,learn,279,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2652?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@16e7e9f`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2652 +/- ##; ========================================; Coverage ? 72.18% ; ========================================; Files ? 104 ; Lines ? 11643 ; Branches ? 0 ; ========================================; Hits ? 8405 ; Misses ? 3238 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2652#issuecomment-1706132242
https://github.com/scverse/scanpy/issues/2653#issuecomment-1706324208:57,Security,validat,validate,57,Phenograph accepts all additional `**kwargs` and doesn’t validate them. We can’t do it for them.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2653#issuecomment-1706324208
https://github.com/scverse/scanpy/pull/2655#issuecomment-1822393557:167,Testability,test,testing,167,@WeipengMO if you calculate it like this you are right. However when we move from 64Bit to 32Bit for neighbors the results are reproducible at least to the best of my testing. I would still be open to round the results. @flying-sheep what do you think?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2655#issuecomment-1822393557
https://github.com/scverse/scanpy/pull/2655#issuecomment-1822719952:320,Availability,error,error,320,"Can you give me the full code you ran for testing and the results from numpy testing for; `np.testing.assert_array_equal(adata.obsm[""X_pca_harmony""], adata2.obsm[""X_pca_harmony""])`; `np.testing.assert_array_equal(adata.obsp[""connectivities""].data, adata2.obsp[""connectivities""].data)`.; The first one should give you an error. The second one shouldn't. How big is your dataset?; Please note that if you use scanpy 1.9.6 that changes of this PR won't have taken effect yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2655#issuecomment-1822719952
https://github.com/scverse/scanpy/pull/2655#issuecomment-1822719952:42,Testability,test,testing,42,"Can you give me the full code you ran for testing and the results from numpy testing for; `np.testing.assert_array_equal(adata.obsm[""X_pca_harmony""], adata2.obsm[""X_pca_harmony""])`; `np.testing.assert_array_equal(adata.obsp[""connectivities""].data, adata2.obsp[""connectivities""].data)`.; The first one should give you an error. The second one shouldn't. How big is your dataset?; Please note that if you use scanpy 1.9.6 that changes of this PR won't have taken effect yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2655#issuecomment-1822719952
https://github.com/scverse/scanpy/pull/2655#issuecomment-1822719952:77,Testability,test,testing,77,"Can you give me the full code you ran for testing and the results from numpy testing for; `np.testing.assert_array_equal(adata.obsm[""X_pca_harmony""], adata2.obsm[""X_pca_harmony""])`; `np.testing.assert_array_equal(adata.obsp[""connectivities""].data, adata2.obsp[""connectivities""].data)`.; The first one should give you an error. The second one shouldn't. How big is your dataset?; Please note that if you use scanpy 1.9.6 that changes of this PR won't have taken effect yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2655#issuecomment-1822719952
https://github.com/scverse/scanpy/pull/2655#issuecomment-1822719952:94,Testability,test,testing,94,"Can you give me the full code you ran for testing and the results from numpy testing for; `np.testing.assert_array_equal(adata.obsm[""X_pca_harmony""], adata2.obsm[""X_pca_harmony""])`; `np.testing.assert_array_equal(adata.obsp[""connectivities""].data, adata2.obsp[""connectivities""].data)`.; The first one should give you an error. The second one shouldn't. How big is your dataset?; Please note that if you use scanpy 1.9.6 that changes of this PR won't have taken effect yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2655#issuecomment-1822719952
https://github.com/scverse/scanpy/pull/2655#issuecomment-1822719952:186,Testability,test,testing,186,"Can you give me the full code you ran for testing and the results from numpy testing for; `np.testing.assert_array_equal(adata.obsm[""X_pca_harmony""], adata2.obsm[""X_pca_harmony""])`; `np.testing.assert_array_equal(adata.obsp[""connectivities""].data, adata2.obsp[""connectivities""].data)`.; The first one should give you an error. The second one shouldn't. How big is your dataset?; Please note that if you use scanpy 1.9.6 that changes of this PR won't have taken effect yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2655#issuecomment-1822719952
https://github.com/scverse/scanpy/pull/2655#issuecomment-1823084227:1652,Availability,Error,Error,1652,"d'). adata_merge = adata.copy(); adata_merge.X = adata_merge.layers['counts']; sc.experimental.pp.highly_variable_genes(adata_merge, n_top_genes=3000, batch_key='batch'). adata_merge = adata_merge[:, adata_merge.var['highly_variable']].copy(); sc.experimental.pp.normalize_pearson_residuals(adata_merge); adata_merge.layers['apr'] = adata_merge.X.copy(); sc.tl.pca(adata_merge, svd_solver=""arpack""); adata_merge.obsm['X_pca_30'] = adata_merge.obsm['X_pca'][:, :30]. adata1 = adata_merge.copy(); adata2 = adata_merge.copy(); ```. The frist test:. ```; # scanpy 1.9.6 that changes of this PR won't have taken effect yet.; # I copy the harmony_integrate from https://github.com/scverse/scanpy/blob/75cb4e750efaccc1413cb204ffa49d21db017079/scanpy/external/pp/_harmony_integrate.py; harmony_integrate(adata1, key='batch', basis='X_pca_30'); harmony_integrate(adata2, key='batch', basis='X_pca_30'); np.testing.assert_array_equal(adata1.obsm[""X_pca_harmony""], adata2.obsm[""X_pca_harmony""]); ```. It raised the Error:. ```; AssertionError: ; Arrays are not equal. Mismatched elements: 567291 [/](https://vscode-remote+ssh-002dremote-002bnansha.vscode-resource.vscode-cdn.net/) 572730 (99.1%); Max absolute difference: 1.20792265e-12; Max relative difference: 4.37537551e-09; x: array([[-0.954048, -7.21621 , -1.601975, ..., 0.059509, -0.436056,; 0.564897],; [-1.145477, 10.185449, 4.414117, ..., -0.087394, -1.327791,...; y: array([[-0.954048, -7.21621 , -1.601975, ..., 0.059509, -0.436056,; 0.564897],; [-1.145477, 10.185449, 4.414117, ..., -0.087394, -1.327791,...; ```. The second test:. ```; sc.pp.neighbors(adata1, n_pcs=30, use_rep='X_pca_harmony'); sc.pp.neighbors(adata2, n_pcs=30, use_rep='X_pca_harmony'); np.testing.assert_array_equal(adata1.obsp[""connectivities""].data, adata2.obsp[""connectivities""].data); ```. It raised the Error:. ```; AssertionError: ; Arrays are not equal. Mismatched elements: 268636 [/](https://vscode-remote+ssh-002dremote-002bnansha.vscode-resource.vscode-cdn.net/) 43",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2655#issuecomment-1823084227
https://github.com/scverse/scanpy/pull/2655#issuecomment-1823084227:2480,Availability,Error,Error,2480,"a_30'); harmony_integrate(adata2, key='batch', basis='X_pca_30'); np.testing.assert_array_equal(adata1.obsm[""X_pca_harmony""], adata2.obsm[""X_pca_harmony""]); ```. It raised the Error:. ```; AssertionError: ; Arrays are not equal. Mismatched elements: 567291 [/](https://vscode-remote+ssh-002dremote-002bnansha.vscode-resource.vscode-cdn.net/) 572730 (99.1%); Max absolute difference: 1.20792265e-12; Max relative difference: 4.37537551e-09; x: array([[-0.954048, -7.21621 , -1.601975, ..., 0.059509, -0.436056,; 0.564897],; [-1.145477, 10.185449, 4.414117, ..., -0.087394, -1.327791,...; y: array([[-0.954048, -7.21621 , -1.601975, ..., 0.059509, -0.436056,; 0.564897],; [-1.145477, 10.185449, 4.414117, ..., -0.087394, -1.327791,...; ```. The second test:. ```; sc.pp.neighbors(adata1, n_pcs=30, use_rep='X_pca_harmony'); sc.pp.neighbors(adata2, n_pcs=30, use_rep='X_pca_harmony'); np.testing.assert_array_equal(adata1.obsp[""connectivities""].data, adata2.obsp[""connectivities""].data); ```. It raised the Error:. ```; AssertionError: ; Arrays are not equal. Mismatched elements: 268636 [/](https://vscode-remote+ssh-002dremote-002bnansha.vscode-resource.vscode-cdn.net/) 434492 (61.8%); Max absolute difference: 0.99820393; Max relative difference: 810.4644; x: array([0.158963, 0.206843, 0.234457, ..., 0.095996, 0.179325, 1. ],; dtype=float32); y: array([0.158963, 0.206843, 0.234457, ..., 0.095996, 0.179324, 1. ],; dtype=float32); ```. This is my session_info:. ```; Click to view session information; -----; anndata 0.9.2; loguru 0.7.2; matplotlib 3.8.0; numpy 1.26.0; pandas 1.4.3; scanpy 1.9.6; seaborn 0.12.2; session_info 1.0.0; -----; Click to view modules imported as dependencies; PIL 9.4.0; argcomplete NA; asttokens NA; attr 23.1.0; awkward 2.4.2; awkward_cpp NA; backcall 0.2.0; cffi 1.15.1; comm 0.1.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.8.0; decorator 5.1.1; dot_parser NA; etils 1.4.1; exceptiongroup 1.1.3; executing 1.2.0; get_annotations NA; gmpy2 2.1.2; ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2655#issuecomment-1823084227
https://github.com/scverse/scanpy/pull/2655#issuecomment-1823084227:409,Deployability,install,install,409,"The size of my dataset is:. ```AnnData object with n_obs × n_vars = 19091 × 23315```. Here is the full code:. ```; import scanpy as sc; import pandas as pd; import numpy as np. from anndata import AnnData. def harmony_integrate(; adata: AnnData,; key: str,; basis: str = ""X_pca"",; adjusted_basis: str = ""X_pca_harmony"",; **kwargs,; ):; try:; import harmonypy; except ImportError:; raise ImportError(""\nplease install harmonypy:\n\n\tpip install harmonypy""). X = adata.obsm[basis].astype(np.float64). harmony_out = harmonypy.run_harmony(X, adata.obs, key, **kwargs). adata.obsm[adjusted_basis] = harmony_out.Z_corr.T. adata = sc.read_h5ad('adata.h5ad'). adata_merge = adata.copy(); adata_merge.X = adata_merge.layers['counts']; sc.experimental.pp.highly_variable_genes(adata_merge, n_top_genes=3000, batch_key='batch'). adata_merge = adata_merge[:, adata_merge.var['highly_variable']].copy(); sc.experimental.pp.normalize_pearson_residuals(adata_merge); adata_merge.layers['apr'] = adata_merge.X.copy(); sc.tl.pca(adata_merge, svd_solver=""arpack""); adata_merge.obsm['X_pca_30'] = adata_merge.obsm['X_pca'][:, :30]. adata1 = adata_merge.copy(); adata2 = adata_merge.copy(); ```. The frist test:. ```; # scanpy 1.9.6 that changes of this PR won't have taken effect yet.; # I copy the harmony_integrate from https://github.com/scverse/scanpy/blob/75cb4e750efaccc1413cb204ffa49d21db017079/scanpy/external/pp/_harmony_integrate.py; harmony_integrate(adata1, key='batch', basis='X_pca_30'); harmony_integrate(adata2, key='batch', basis='X_pca_30'); np.testing.assert_array_equal(adata1.obsm[""X_pca_harmony""], adata2.obsm[""X_pca_harmony""]); ```. It raised the Error:. ```; AssertionError: ; Arrays are not equal. Mismatched elements: 567291 [/](https://vscode-remote+ssh-002dremote-002bnansha.vscode-resource.vscode-cdn.net/) 572730 (99.1%); Max absolute difference: 1.20792265e-12; Max relative difference: 4.37537551e-09; x: array([[-0.954048, -7.21621 , -1.601975, ..., 0.059509, -0.436056,; 0.564897],; [-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2655#issuecomment-1823084227
https://github.com/scverse/scanpy/pull/2655#issuecomment-1823084227:437,Deployability,install,install,437,"The size of my dataset is:. ```AnnData object with n_obs × n_vars = 19091 × 23315```. Here is the full code:. ```; import scanpy as sc; import pandas as pd; import numpy as np. from anndata import AnnData. def harmony_integrate(; adata: AnnData,; key: str,; basis: str = ""X_pca"",; adjusted_basis: str = ""X_pca_harmony"",; **kwargs,; ):; try:; import harmonypy; except ImportError:; raise ImportError(""\nplease install harmonypy:\n\n\tpip install harmonypy""). X = adata.obsm[basis].astype(np.float64). harmony_out = harmonypy.run_harmony(X, adata.obs, key, **kwargs). adata.obsm[adjusted_basis] = harmony_out.Z_corr.T. adata = sc.read_h5ad('adata.h5ad'). adata_merge = adata.copy(); adata_merge.X = adata_merge.layers['counts']; sc.experimental.pp.highly_variable_genes(adata_merge, n_top_genes=3000, batch_key='batch'). adata_merge = adata_merge[:, adata_merge.var['highly_variable']].copy(); sc.experimental.pp.normalize_pearson_residuals(adata_merge); adata_merge.layers['apr'] = adata_merge.X.copy(); sc.tl.pca(adata_merge, svd_solver=""arpack""); adata_merge.obsm['X_pca_30'] = adata_merge.obsm['X_pca'][:, :30]. adata1 = adata_merge.copy(); adata2 = adata_merge.copy(); ```. The frist test:. ```; # scanpy 1.9.6 that changes of this PR won't have taken effect yet.; # I copy the harmony_integrate from https://github.com/scverse/scanpy/blob/75cb4e750efaccc1413cb204ffa49d21db017079/scanpy/external/pp/_harmony_integrate.py; harmony_integrate(adata1, key='batch', basis='X_pca_30'); harmony_integrate(adata2, key='batch', basis='X_pca_30'); np.testing.assert_array_equal(adata1.obsm[""X_pca_harmony""], adata2.obsm[""X_pca_harmony""]); ```. It raised the Error:. ```; AssertionError: ; Arrays are not equal. Mismatched elements: 567291 [/](https://vscode-remote+ssh-002dremote-002bnansha.vscode-resource.vscode-cdn.net/) 572730 (99.1%); Max absolute difference: 1.20792265e-12; Max relative difference: 4.37537551e-09; x: array([[-0.954048, -7.21621 , -1.601975, ..., 0.059509, -0.436056,; 0.564897],; [-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2655#issuecomment-1823084227
https://github.com/scverse/scanpy/pull/2655#issuecomment-1823084227:4731,Deployability,update,updated,4731,"2); ```. This is my session_info:. ```; Click to view session information; -----; anndata 0.9.2; loguru 0.7.2; matplotlib 3.8.0; numpy 1.26.0; pandas 1.4.3; scanpy 1.9.6; seaborn 0.12.2; session_info 1.0.0; -----; Click to view modules imported as dependencies; PIL 9.4.0; argcomplete NA; asttokens NA; attr 23.1.0; awkward 2.4.2; awkward_cpp NA; backcall 0.2.0; cffi 1.15.1; comm 0.1.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.8.0; decorator 5.1.1; dot_parser NA; etils 1.4.1; exceptiongroup 1.1.3; executing 1.2.0; get_annotations NA; gmpy2 2.1.2; h5py 3.9.0; harmonypy NA; igraph 0.10.8; importlib_metadata NA; importlib_resources NA; ipykernel 6.25.2; ipywidgets 8.1.1; jax 0.4.20; jaxlib 0.4.20; jedi 0.19.0; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.10.1; llvmlite 0.41.1; ml_dtypes 0.2.0; mpl_toolkits NA; mpmath 1.3.0; natsort 8.4.0; numba 0.58.1; nvfuser NA; opt_einsum v3.0.0; packaging 23.1; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.10.0; prompt_toolkit 3.0.39; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pyarrow 13.0.0; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pydot 1.4.2; pygments 2.16.1; pynndescent 0.5.5; pyparsing 3.0.9; pytz 2023.3.post1; rich NA; scipy 1.10.1; setuptools 68.0.0; six 1.16.0; sklearn 1.3.2; sparse 0.14.0; stack_data 0.6.2; statsmodels 0.13.1; sympy 1.11.1; texttable 1.6.7; threadpoolctl 3.2.0; torch 2.0.1; tornado 6.3.3; tqdm 4.66.1; traitlets 5.10.0; typing_extensions NA; umap 0.5.3; wcwidth 0.2.6; yaml 6.0; zipp NA; zmq 25.1.1; -----; IPython 8.15.0; jupyter_client 8.3.1; jupyter_core 5.3.1; -----; Python 3.9.18 (main, Sep 11 2023, 13:41:44) [GCC 11.2.0]; Linux-6.2.0-36-generic-x86_64-with-glibc2.35; -----; Session information updated at 2023-11-23 00:08; ```. I uploaded the ipynb file as attachment. 👇. [harmony_test.ipynb.zip](https://github.com/scverse/scanpy/files/13441924/harmony_test.ipynb.zip)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2655#issuecomment-1823084227
https://github.com/scverse/scanpy/pull/2655#issuecomment-1823084227:3154,Integrability,depend,dependencies,3154,"],; [-1.145477, 10.185449, 4.414117, ..., -0.087394, -1.327791,...; ```. The second test:. ```; sc.pp.neighbors(adata1, n_pcs=30, use_rep='X_pca_harmony'); sc.pp.neighbors(adata2, n_pcs=30, use_rep='X_pca_harmony'); np.testing.assert_array_equal(adata1.obsp[""connectivities""].data, adata2.obsp[""connectivities""].data); ```. It raised the Error:. ```; AssertionError: ; Arrays are not equal. Mismatched elements: 268636 [/](https://vscode-remote+ssh-002dremote-002bnansha.vscode-resource.vscode-cdn.net/) 434492 (61.8%); Max absolute difference: 0.99820393; Max relative difference: 810.4644; x: array([0.158963, 0.206843, 0.234457, ..., 0.095996, 0.179325, 1. ],; dtype=float32); y: array([0.158963, 0.206843, 0.234457, ..., 0.095996, 0.179324, 1. ],; dtype=float32); ```. This is my session_info:. ```; Click to view session information; -----; anndata 0.9.2; loguru 0.7.2; matplotlib 3.8.0; numpy 1.26.0; pandas 1.4.3; scanpy 1.9.6; seaborn 0.12.2; session_info 1.0.0; -----; Click to view modules imported as dependencies; PIL 9.4.0; argcomplete NA; asttokens NA; attr 23.1.0; awkward 2.4.2; awkward_cpp NA; backcall 0.2.0; cffi 1.15.1; comm 0.1.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.8.0; decorator 5.1.1; dot_parser NA; etils 1.4.1; exceptiongroup 1.1.3; executing 1.2.0; get_annotations NA; gmpy2 2.1.2; h5py 3.9.0; harmonypy NA; igraph 0.10.8; importlib_metadata NA; importlib_resources NA; ipykernel 6.25.2; ipywidgets 8.1.1; jax 0.4.20; jaxlib 0.4.20; jedi 0.19.0; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.10.1; llvmlite 0.41.1; ml_dtypes 0.2.0; mpl_toolkits NA; mpmath 1.3.0; natsort 8.4.0; numba 0.58.1; nvfuser NA; opt_einsum v3.0.0; packaging 23.1; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.10.0; prompt_toolkit 3.0.39; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pyarrow 13.0.0; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pydot 1.4.2;",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2655#issuecomment-1823084227
https://github.com/scverse/scanpy/pull/2655#issuecomment-1823084227:709,Modifiability,layers,layers,709,"The size of my dataset is:. ```AnnData object with n_obs × n_vars = 19091 × 23315```. Here is the full code:. ```; import scanpy as sc; import pandas as pd; import numpy as np. from anndata import AnnData. def harmony_integrate(; adata: AnnData,; key: str,; basis: str = ""X_pca"",; adjusted_basis: str = ""X_pca_harmony"",; **kwargs,; ):; try:; import harmonypy; except ImportError:; raise ImportError(""\nplease install harmonypy:\n\n\tpip install harmonypy""). X = adata.obsm[basis].astype(np.float64). harmony_out = harmonypy.run_harmony(X, adata.obs, key, **kwargs). adata.obsm[adjusted_basis] = harmony_out.Z_corr.T. adata = sc.read_h5ad('adata.h5ad'). adata_merge = adata.copy(); adata_merge.X = adata_merge.layers['counts']; sc.experimental.pp.highly_variable_genes(adata_merge, n_top_genes=3000, batch_key='batch'). adata_merge = adata_merge[:, adata_merge.var['highly_variable']].copy(); sc.experimental.pp.normalize_pearson_residuals(adata_merge); adata_merge.layers['apr'] = adata_merge.X.copy(); sc.tl.pca(adata_merge, svd_solver=""arpack""); adata_merge.obsm['X_pca_30'] = adata_merge.obsm['X_pca'][:, :30]. adata1 = adata_merge.copy(); adata2 = adata_merge.copy(); ```. The frist test:. ```; # scanpy 1.9.6 that changes of this PR won't have taken effect yet.; # I copy the harmony_integrate from https://github.com/scverse/scanpy/blob/75cb4e750efaccc1413cb204ffa49d21db017079/scanpy/external/pp/_harmony_integrate.py; harmony_integrate(adata1, key='batch', basis='X_pca_30'); harmony_integrate(adata2, key='batch', basis='X_pca_30'); np.testing.assert_array_equal(adata1.obsm[""X_pca_harmony""], adata2.obsm[""X_pca_harmony""]); ```. It raised the Error:. ```; AssertionError: ; Arrays are not equal. Mismatched elements: 567291 [/](https://vscode-remote+ssh-002dremote-002bnansha.vscode-resource.vscode-cdn.net/) 572730 (99.1%); Max absolute difference: 1.20792265e-12; Max relative difference: 4.37537551e-09; x: array([[-0.954048, -7.21621 , -1.601975, ..., 0.059509, -0.436056,; 0.564897],; [-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2655#issuecomment-1823084227
https://github.com/scverse/scanpy/pull/2655#issuecomment-1823084227:965,Modifiability,layers,layers,965,"The size of my dataset is:. ```AnnData object with n_obs × n_vars = 19091 × 23315```. Here is the full code:. ```; import scanpy as sc; import pandas as pd; import numpy as np. from anndata import AnnData. def harmony_integrate(; adata: AnnData,; key: str,; basis: str = ""X_pca"",; adjusted_basis: str = ""X_pca_harmony"",; **kwargs,; ):; try:; import harmonypy; except ImportError:; raise ImportError(""\nplease install harmonypy:\n\n\tpip install harmonypy""). X = adata.obsm[basis].astype(np.float64). harmony_out = harmonypy.run_harmony(X, adata.obs, key, **kwargs). adata.obsm[adjusted_basis] = harmony_out.Z_corr.T. adata = sc.read_h5ad('adata.h5ad'). adata_merge = adata.copy(); adata_merge.X = adata_merge.layers['counts']; sc.experimental.pp.highly_variable_genes(adata_merge, n_top_genes=3000, batch_key='batch'). adata_merge = adata_merge[:, adata_merge.var['highly_variable']].copy(); sc.experimental.pp.normalize_pearson_residuals(adata_merge); adata_merge.layers['apr'] = adata_merge.X.copy(); sc.tl.pca(adata_merge, svd_solver=""arpack""); adata_merge.obsm['X_pca_30'] = adata_merge.obsm['X_pca'][:, :30]. adata1 = adata_merge.copy(); adata2 = adata_merge.copy(); ```. The frist test:. ```; # scanpy 1.9.6 that changes of this PR won't have taken effect yet.; # I copy the harmony_integrate from https://github.com/scverse/scanpy/blob/75cb4e750efaccc1413cb204ffa49d21db017079/scanpy/external/pp/_harmony_integrate.py; harmony_integrate(adata1, key='batch', basis='X_pca_30'); harmony_integrate(adata2, key='batch', basis='X_pca_30'); np.testing.assert_array_equal(adata1.obsm[""X_pca_harmony""], adata2.obsm[""X_pca_harmony""]); ```. It raised the Error:. ```; AssertionError: ; Arrays are not equal. Mismatched elements: 567291 [/](https://vscode-remote+ssh-002dremote-002bnansha.vscode-resource.vscode-cdn.net/) 572730 (99.1%); Max absolute difference: 1.20792265e-12; Max relative difference: 4.37537551e-09; x: array([[-0.954048, -7.21621 , -1.601975, ..., 0.059509, -0.436056,; 0.564897],; [-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2655#issuecomment-1823084227
https://github.com/scverse/scanpy/pull/2655#issuecomment-1823084227:1187,Testability,test,test,1187,"ndata import AnnData. def harmony_integrate(; adata: AnnData,; key: str,; basis: str = ""X_pca"",; adjusted_basis: str = ""X_pca_harmony"",; **kwargs,; ):; try:; import harmonypy; except ImportError:; raise ImportError(""\nplease install harmonypy:\n\n\tpip install harmonypy""). X = adata.obsm[basis].astype(np.float64). harmony_out = harmonypy.run_harmony(X, adata.obs, key, **kwargs). adata.obsm[adjusted_basis] = harmony_out.Z_corr.T. adata = sc.read_h5ad('adata.h5ad'). adata_merge = adata.copy(); adata_merge.X = adata_merge.layers['counts']; sc.experimental.pp.highly_variable_genes(adata_merge, n_top_genes=3000, batch_key='batch'). adata_merge = adata_merge[:, adata_merge.var['highly_variable']].copy(); sc.experimental.pp.normalize_pearson_residuals(adata_merge); adata_merge.layers['apr'] = adata_merge.X.copy(); sc.tl.pca(adata_merge, svd_solver=""arpack""); adata_merge.obsm['X_pca_30'] = adata_merge.obsm['X_pca'][:, :30]. adata1 = adata_merge.copy(); adata2 = adata_merge.copy(); ```. The frist test:. ```; # scanpy 1.9.6 that changes of this PR won't have taken effect yet.; # I copy the harmony_integrate from https://github.com/scverse/scanpy/blob/75cb4e750efaccc1413cb204ffa49d21db017079/scanpy/external/pp/_harmony_integrate.py; harmony_integrate(adata1, key='batch', basis='X_pca_30'); harmony_integrate(adata2, key='batch', basis='X_pca_30'); np.testing.assert_array_equal(adata1.obsm[""X_pca_harmony""], adata2.obsm[""X_pca_harmony""]); ```. It raised the Error:. ```; AssertionError: ; Arrays are not equal. Mismatched elements: 567291 [/](https://vscode-remote+ssh-002dremote-002bnansha.vscode-resource.vscode-cdn.net/) 572730 (99.1%); Max absolute difference: 1.20792265e-12; Max relative difference: 4.37537551e-09; x: array([[-0.954048, -7.21621 , -1.601975, ..., 0.059509, -0.436056,; 0.564897],; [-1.145477, 10.185449, 4.414117, ..., -0.087394, -1.327791,...; y: array([[-0.954048, -7.21621 , -1.601975, ..., 0.059509, -0.436056,; 0.564897],; [-1.145477, 10.185449, 4.414117, ..., -",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2655#issuecomment-1823084227
https://github.com/scverse/scanpy/pull/2655#issuecomment-1823084227:1545,Testability,test,testing,1545," key, **kwargs). adata.obsm[adjusted_basis] = harmony_out.Z_corr.T. adata = sc.read_h5ad('adata.h5ad'). adata_merge = adata.copy(); adata_merge.X = adata_merge.layers['counts']; sc.experimental.pp.highly_variable_genes(adata_merge, n_top_genes=3000, batch_key='batch'). adata_merge = adata_merge[:, adata_merge.var['highly_variable']].copy(); sc.experimental.pp.normalize_pearson_residuals(adata_merge); adata_merge.layers['apr'] = adata_merge.X.copy(); sc.tl.pca(adata_merge, svd_solver=""arpack""); adata_merge.obsm['X_pca_30'] = adata_merge.obsm['X_pca'][:, :30]. adata1 = adata_merge.copy(); adata2 = adata_merge.copy(); ```. The frist test:. ```; # scanpy 1.9.6 that changes of this PR won't have taken effect yet.; # I copy the harmony_integrate from https://github.com/scverse/scanpy/blob/75cb4e750efaccc1413cb204ffa49d21db017079/scanpy/external/pp/_harmony_integrate.py; harmony_integrate(adata1, key='batch', basis='X_pca_30'); harmony_integrate(adata2, key='batch', basis='X_pca_30'); np.testing.assert_array_equal(adata1.obsm[""X_pca_harmony""], adata2.obsm[""X_pca_harmony""]); ```. It raised the Error:. ```; AssertionError: ; Arrays are not equal. Mismatched elements: 567291 [/](https://vscode-remote+ssh-002dremote-002bnansha.vscode-resource.vscode-cdn.net/) 572730 (99.1%); Max absolute difference: 1.20792265e-12; Max relative difference: 4.37537551e-09; x: array([[-0.954048, -7.21621 , -1.601975, ..., 0.059509, -0.436056,; 0.564897],; [-1.145477, 10.185449, 4.414117, ..., -0.087394, -1.327791,...; y: array([[-0.954048, -7.21621 , -1.601975, ..., 0.059509, -0.436056,; 0.564897],; [-1.145477, 10.185449, 4.414117, ..., -0.087394, -1.327791,...; ```. The second test:. ```; sc.pp.neighbors(adata1, n_pcs=30, use_rep='X_pca_harmony'); sc.pp.neighbors(adata2, n_pcs=30, use_rep='X_pca_harmony'); np.testing.assert_array_equal(adata1.obsp[""connectivities""].data, adata2.obsp[""connectivities""].data); ```. It raised the Error:. ```; AssertionError: ; Arrays are not equal. Mismatched eleme",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2655#issuecomment-1823084227
https://github.com/scverse/scanpy/pull/2655#issuecomment-1823084227:1665,Testability,Assert,AssertionError,1665,"adata_merge.X = adata_merge.layers['counts']; sc.experimental.pp.highly_variable_genes(adata_merge, n_top_genes=3000, batch_key='batch'). adata_merge = adata_merge[:, adata_merge.var['highly_variable']].copy(); sc.experimental.pp.normalize_pearson_residuals(adata_merge); adata_merge.layers['apr'] = adata_merge.X.copy(); sc.tl.pca(adata_merge, svd_solver=""arpack""); adata_merge.obsm['X_pca_30'] = adata_merge.obsm['X_pca'][:, :30]. adata1 = adata_merge.copy(); adata2 = adata_merge.copy(); ```. The frist test:. ```; # scanpy 1.9.6 that changes of this PR won't have taken effect yet.; # I copy the harmony_integrate from https://github.com/scverse/scanpy/blob/75cb4e750efaccc1413cb204ffa49d21db017079/scanpy/external/pp/_harmony_integrate.py; harmony_integrate(adata1, key='batch', basis='X_pca_30'); harmony_integrate(adata2, key='batch', basis='X_pca_30'); np.testing.assert_array_equal(adata1.obsm[""X_pca_harmony""], adata2.obsm[""X_pca_harmony""]); ```. It raised the Error:. ```; AssertionError: ; Arrays are not equal. Mismatched elements: 567291 [/](https://vscode-remote+ssh-002dremote-002bnansha.vscode-resource.vscode-cdn.net/) 572730 (99.1%); Max absolute difference: 1.20792265e-12; Max relative difference: 4.37537551e-09; x: array([[-0.954048, -7.21621 , -1.601975, ..., 0.059509, -0.436056,; 0.564897],; [-1.145477, 10.185449, 4.414117, ..., -0.087394, -1.327791,...; y: array([[-0.954048, -7.21621 , -1.601975, ..., 0.059509, -0.436056,; 0.564897],; [-1.145477, 10.185449, 4.414117, ..., -0.087394, -1.327791,...; ```. The second test:. ```; sc.pp.neighbors(adata1, n_pcs=30, use_rep='X_pca_harmony'); sc.pp.neighbors(adata2, n_pcs=30, use_rep='X_pca_harmony'); np.testing.assert_array_equal(adata1.obsp[""connectivities""].data, adata2.obsp[""connectivities""].data); ```. It raised the Error:. ```; AssertionError: ; Arrays are not equal. Mismatched elements: 268636 [/](https://vscode-remote+ssh-002dremote-002bnansha.vscode-resource.vscode-cdn.net/) 434492 (61.8%); Max absolute differe",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2655#issuecomment-1823084227
https://github.com/scverse/scanpy/pull/2655#issuecomment-1823084227:2226,Testability,test,test,2226,"ges of this PR won't have taken effect yet.; # I copy the harmony_integrate from https://github.com/scverse/scanpy/blob/75cb4e750efaccc1413cb204ffa49d21db017079/scanpy/external/pp/_harmony_integrate.py; harmony_integrate(adata1, key='batch', basis='X_pca_30'); harmony_integrate(adata2, key='batch', basis='X_pca_30'); np.testing.assert_array_equal(adata1.obsm[""X_pca_harmony""], adata2.obsm[""X_pca_harmony""]); ```. It raised the Error:. ```; AssertionError: ; Arrays are not equal. Mismatched elements: 567291 [/](https://vscode-remote+ssh-002dremote-002bnansha.vscode-resource.vscode-cdn.net/) 572730 (99.1%); Max absolute difference: 1.20792265e-12; Max relative difference: 4.37537551e-09; x: array([[-0.954048, -7.21621 , -1.601975, ..., 0.059509, -0.436056,; 0.564897],; [-1.145477, 10.185449, 4.414117, ..., -0.087394, -1.327791,...; y: array([[-0.954048, -7.21621 , -1.601975, ..., 0.059509, -0.436056,; 0.564897],; [-1.145477, 10.185449, 4.414117, ..., -0.087394, -1.327791,...; ```. The second test:. ```; sc.pp.neighbors(adata1, n_pcs=30, use_rep='X_pca_harmony'); sc.pp.neighbors(adata2, n_pcs=30, use_rep='X_pca_harmony'); np.testing.assert_array_equal(adata1.obsp[""connectivities""].data, adata2.obsp[""connectivities""].data); ```. It raised the Error:. ```; AssertionError: ; Arrays are not equal. Mismatched elements: 268636 [/](https://vscode-remote+ssh-002dremote-002bnansha.vscode-resource.vscode-cdn.net/) 434492 (61.8%); Max absolute difference: 0.99820393; Max relative difference: 810.4644; x: array([0.158963, 0.206843, 0.234457, ..., 0.095996, 0.179325, 1. ],; dtype=float32); y: array([0.158963, 0.206843, 0.234457, ..., 0.095996, 0.179324, 1. ],; dtype=float32); ```. This is my session_info:. ```; Click to view session information; -----; anndata 0.9.2; loguru 0.7.2; matplotlib 3.8.0; numpy 1.26.0; pandas 1.4.3; scanpy 1.9.6; seaborn 0.12.2; session_info 1.0.0; -----; Click to view modules imported as dependencies; PIL 9.4.0; argcomplete NA; asttokens NA; attr 23.1.0; a",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2655#issuecomment-1823084227
https://github.com/scverse/scanpy/pull/2655#issuecomment-1823084227:2361,Testability,test,testing,2361,"04ffa49d21db017079/scanpy/external/pp/_harmony_integrate.py; harmony_integrate(adata1, key='batch', basis='X_pca_30'); harmony_integrate(adata2, key='batch', basis='X_pca_30'); np.testing.assert_array_equal(adata1.obsm[""X_pca_harmony""], adata2.obsm[""X_pca_harmony""]); ```. It raised the Error:. ```; AssertionError: ; Arrays are not equal. Mismatched elements: 567291 [/](https://vscode-remote+ssh-002dremote-002bnansha.vscode-resource.vscode-cdn.net/) 572730 (99.1%); Max absolute difference: 1.20792265e-12; Max relative difference: 4.37537551e-09; x: array([[-0.954048, -7.21621 , -1.601975, ..., 0.059509, -0.436056,; 0.564897],; [-1.145477, 10.185449, 4.414117, ..., -0.087394, -1.327791,...; y: array([[-0.954048, -7.21621 , -1.601975, ..., 0.059509, -0.436056,; 0.564897],; [-1.145477, 10.185449, 4.414117, ..., -0.087394, -1.327791,...; ```. The second test:. ```; sc.pp.neighbors(adata1, n_pcs=30, use_rep='X_pca_harmony'); sc.pp.neighbors(adata2, n_pcs=30, use_rep='X_pca_harmony'); np.testing.assert_array_equal(adata1.obsp[""connectivities""].data, adata2.obsp[""connectivities""].data); ```. It raised the Error:. ```; AssertionError: ; Arrays are not equal. Mismatched elements: 268636 [/](https://vscode-remote+ssh-002dremote-002bnansha.vscode-resource.vscode-cdn.net/) 434492 (61.8%); Max absolute difference: 0.99820393; Max relative difference: 810.4644; x: array([0.158963, 0.206843, 0.234457, ..., 0.095996, 0.179325, 1. ],; dtype=float32); y: array([0.158963, 0.206843, 0.234457, ..., 0.095996, 0.179324, 1. ],; dtype=float32); ```. This is my session_info:. ```; Click to view session information; -----; anndata 0.9.2; loguru 0.7.2; matplotlib 3.8.0; numpy 1.26.0; pandas 1.4.3; scanpy 1.9.6; seaborn 0.12.2; session_info 1.0.0; -----; Click to view modules imported as dependencies; PIL 9.4.0; argcomplete NA; asttokens NA; attr 23.1.0; awkward 2.4.2; awkward_cpp NA; backcall 0.2.0; cffi 1.15.1; comm 0.1.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.8.0; decora",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2655#issuecomment-1823084227
https://github.com/scverse/scanpy/pull/2655#issuecomment-1823084227:2493,Testability,Assert,AssertionError,2493," key='batch', basis='X_pca_30'); np.testing.assert_array_equal(adata1.obsm[""X_pca_harmony""], adata2.obsm[""X_pca_harmony""]); ```. It raised the Error:. ```; AssertionError: ; Arrays are not equal. Mismatched elements: 567291 [/](https://vscode-remote+ssh-002dremote-002bnansha.vscode-resource.vscode-cdn.net/) 572730 (99.1%); Max absolute difference: 1.20792265e-12; Max relative difference: 4.37537551e-09; x: array([[-0.954048, -7.21621 , -1.601975, ..., 0.059509, -0.436056,; 0.564897],; [-1.145477, 10.185449, 4.414117, ..., -0.087394, -1.327791,...; y: array([[-0.954048, -7.21621 , -1.601975, ..., 0.059509, -0.436056,; 0.564897],; [-1.145477, 10.185449, 4.414117, ..., -0.087394, -1.327791,...; ```. The second test:. ```; sc.pp.neighbors(adata1, n_pcs=30, use_rep='X_pca_harmony'); sc.pp.neighbors(adata2, n_pcs=30, use_rep='X_pca_harmony'); np.testing.assert_array_equal(adata1.obsp[""connectivities""].data, adata2.obsp[""connectivities""].data); ```. It raised the Error:. ```; AssertionError: ; Arrays are not equal. Mismatched elements: 268636 [/](https://vscode-remote+ssh-002dremote-002bnansha.vscode-resource.vscode-cdn.net/) 434492 (61.8%); Max absolute difference: 0.99820393; Max relative difference: 810.4644; x: array([0.158963, 0.206843, 0.234457, ..., 0.095996, 0.179325, 1. ],; dtype=float32); y: array([0.158963, 0.206843, 0.234457, ..., 0.095996, 0.179324, 1. ],; dtype=float32); ```. This is my session_info:. ```; Click to view session information; -----; anndata 0.9.2; loguru 0.7.2; matplotlib 3.8.0; numpy 1.26.0; pandas 1.4.3; scanpy 1.9.6; seaborn 0.12.2; session_info 1.0.0; -----; Click to view modules imported as dependencies; PIL 9.4.0; argcomplete NA; asttokens NA; attr 23.1.0; awkward 2.4.2; awkward_cpp NA; backcall 0.2.0; cffi 1.15.1; comm 0.1.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.8.0; decorator 5.1.1; dot_parser NA; etils 1.4.1; exceptiongroup 1.1.3; executing 1.2.0; get_annotations NA; gmpy2 2.1.2; h5py 3.9.0; harmonypy NA; igraph 0",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2655#issuecomment-1823084227
https://github.com/scverse/scanpy/pull/2655#issuecomment-1823084227:3003,Testability,log,loguru,3003,"477, 10.185449, 4.414117, ..., -0.087394, -1.327791,...; y: array([[-0.954048, -7.21621 , -1.601975, ..., 0.059509, -0.436056,; 0.564897],; [-1.145477, 10.185449, 4.414117, ..., -0.087394, -1.327791,...; ```. The second test:. ```; sc.pp.neighbors(adata1, n_pcs=30, use_rep='X_pca_harmony'); sc.pp.neighbors(adata2, n_pcs=30, use_rep='X_pca_harmony'); np.testing.assert_array_equal(adata1.obsp[""connectivities""].data, adata2.obsp[""connectivities""].data); ```. It raised the Error:. ```; AssertionError: ; Arrays are not equal. Mismatched elements: 268636 [/](https://vscode-remote+ssh-002dremote-002bnansha.vscode-resource.vscode-cdn.net/) 434492 (61.8%); Max absolute difference: 0.99820393; Max relative difference: 810.4644; x: array([0.158963, 0.206843, 0.234457, ..., 0.095996, 0.179325, 1. ],; dtype=float32); y: array([0.158963, 0.206843, 0.234457, ..., 0.095996, 0.179324, 1. ],; dtype=float32); ```. This is my session_info:. ```; Click to view session information; -----; anndata 0.9.2; loguru 0.7.2; matplotlib 3.8.0; numpy 1.26.0; pandas 1.4.3; scanpy 1.9.6; seaborn 0.12.2; session_info 1.0.0; -----; Click to view modules imported as dependencies; PIL 9.4.0; argcomplete NA; asttokens NA; attr 23.1.0; awkward 2.4.2; awkward_cpp NA; backcall 0.2.0; cffi 1.15.1; comm 0.1.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.8.0; decorator 5.1.1; dot_parser NA; etils 1.4.1; exceptiongroup 1.1.3; executing 1.2.0; get_annotations NA; gmpy2 2.1.2; h5py 3.9.0; harmonypy NA; igraph 0.10.8; importlib_metadata NA; importlib_resources NA; ipykernel 6.25.2; ipywidgets 8.1.1; jax 0.4.20; jaxlib 0.4.20; jedi 0.19.0; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.10.1; llvmlite 0.41.1; ml_dtypes 0.2.0; mpl_toolkits NA; mpmath 1.3.0; natsort 8.4.0; numba 0.58.1; nvfuser NA; opt_einsum v3.0.0; packaging 23.1; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.10.0; prompt_toolkit 3.0.39; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pyarrow 13.0.0; p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2655#issuecomment-1823084227
https://github.com/scverse/scanpy/issues/2656#issuecomment-1709960901:91,Integrability,depend,dependencies,91,"How would you suggest doing the API for this? Another `kwarg` for backend?. The additional dependencies aren't so bad. They are `xarray`, `dask`, and `pillow`. But still, I probably wouldn't be up for data shader as a required dependency.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2656#issuecomment-1709960901
https://github.com/scverse/scanpy/issues/2656#issuecomment-1709960901:227,Integrability,depend,dependency,227,"How would you suggest doing the API for this? Another `kwarg` for backend?. The additional dependencies aren't so bad. They are `xarray`, `dask`, and `pillow`. But still, I probably wouldn't be up for data shader as a required dependency.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2656#issuecomment-1709960901
https://github.com/scverse/scanpy/issues/2656#issuecomment-1711727606:107,Integrability,interface,interface,107,"I would like this be to somewhere where it'd also work for CPU. I think we can implement a `__dataframe__` interface that passes either GPU or CPU memory to data shader, then let data shader handle the rest.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2656#issuecomment-1711727606
https://github.com/scverse/scanpy/pull/2657#issuecomment-1711823534:1546,Usability,feedback,feedback,1546,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2657?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > Merging [#2657](https://app.codecov.io/gh/scverse/scanpy/pull/2657?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) (2bf5f18) into [master](https://app.codecov.io/gh/scverse/scanpy/commit/3a50e60a77ced96d877448c6d9f8c27705ae949e?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) (3a50e60) will **not change** coverage.; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2657 +/- ##; =======================================; Coverage 72.16% 72.16% ; =======================================; Files 108 108 ; Lines 11906 11906 ; =======================================; Hits 8592 8592 ; Misses 3314 3314 ; ```. | [Files Changed](https://app.codecov.io/gh/scverse/scanpy/pull/2657?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/tools/\_rank\_genes\_groups.py](https://app.codecov.io/gh/scverse/scanpy/pull/2657?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rvb2xzL19yYW5rX2dlbmVzX2dyb3Vwcy5weQ==) | `94.23% <ø> (ø)` | |. </details>; :loudspeaker: Have feedback on the report? [Share it here](https://about.codecov.io/codecov-pr-comment-feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2657#issuecomment-1711823534
https://github.com/scverse/scanpy/pull/2657#issuecomment-1711823534:1630,Usability,feedback,feedback,1630,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2657?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > Merging [#2657](https://app.codecov.io/gh/scverse/scanpy/pull/2657?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) (2bf5f18) into [master](https://app.codecov.io/gh/scverse/scanpy/commit/3a50e60a77ced96d877448c6d9f8c27705ae949e?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) (3a50e60) will **not change** coverage.; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2657 +/- ##; =======================================; Coverage 72.16% 72.16% ; =======================================; Files 108 108 ; Lines 11906 11906 ; =======================================; Hits 8592 8592 ; Misses 3314 3314 ; ```. | [Files Changed](https://app.codecov.io/gh/scverse/scanpy/pull/2657?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/tools/\_rank\_genes\_groups.py](https://app.codecov.io/gh/scverse/scanpy/pull/2657?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rvb2xzL19yYW5rX2dlbmVzX2dyb3Vwcy5weQ==) | `94.23% <ø> (ø)` | |. </details>; :loudspeaker: Have feedback on the report? [Share it here](https://about.codecov.io/codecov-pr-comment-feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2657#issuecomment-1711823534
https://github.com/scverse/scanpy/pull/2657#issuecomment-1719024055:62,Availability,failure,failure,62,"@flying-sheep Yup, I think we need to at least print a better failure message than just returning -1 for the milestone check. It's not a good experience for people that are not familiar with this. @lazappi thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2657#issuecomment-1719024055
https://github.com/scverse/scanpy/pull/2657#issuecomment-1719024055:70,Integrability,message,message,70,"@flying-sheep Yup, I think we need to at least print a better failure message than just returning -1 for the milestone check. It's not a good experience for people that are not familiar with this. @lazappi thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2657#issuecomment-1719024055
https://github.com/scverse/scanpy/pull/2658#issuecomment-1712098187:1688,Testability,test,testing,1688,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2658?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > Merging [#2658](https://app.codecov.io/gh/scverse/scanpy/pull/2658?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) (32c1ab6) into [master](https://app.codecov.io/gh/scverse/scanpy/commit/3a50e60a77ced96d877448c6d9f8c27705ae949e?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) (3a50e60) will **not change** coverage.; > The diff coverage is `100.00%`. > :exclamation: Current head 32c1ab6 differs from pull request most recent head 8e75cef. Consider uploading reports for the commit 8e75cef to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2658 +/- ##; =======================================; Coverage 72.16% 72.16% ; =======================================; Files 108 108 ; Lines 11906 11906 ; =======================================; Hits 8592 8592 ; Misses 3314 3314 ; ```. | [Files Changed](https://app.codecov.io/gh/scverse/scanpy/pull/2658?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/datasets/\_datasets.py](https://app.codecov.io/gh/scverse/scanpy/pull/2658?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2RhdGFzZXRzL19kYXRhc2V0cy5weQ==) | `69.29% <100.00%> (ø)` | |; | [scanpy/testing/\_helpers/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2658?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX2hlbHBlcnMvX19pbml0X18ucHk=) | `100.00% <100.00%> (ø)` | |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2658#issuecomment-1712098187
https://github.com/scverse/scanpy/pull/2659#issuecomment-1712163821:331,Availability,error,error-reference,331,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2659?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@efce8f8`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head eea03bb differs from pull request most recent head 256ce44. Consider uploading reports for the commit 256ce44 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2659 +/- ##; ========================================; Coverage ? 72.18% ; ========================================; Files ? 104 ; Lines ? 11643 ; Branches ? 0 ; ========================================; Hits ? 8405 ; Misses ? 3238 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2659#issuecomment-1712163821
https://github.com/scverse/scanpy/pull/2659#issuecomment-1712163821:279,Usability,learn,learn,279,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2659?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@efce8f8`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head eea03bb differs from pull request most recent head 256ce44. Consider uploading reports for the commit 256ce44 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2659 +/- ##; ========================================; Coverage ? 72.18% ; ========================================; Files ? 104 ; Lines ? 11643 ; Branches ? 0 ; ========================================; Hits ? 8405 ; Misses ? 3238 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2659#issuecomment-1712163821
https://github.com/scverse/scanpy/issues/2662#issuecomment-1723238652:80,Deployability,integrat,integrate,80,Please ask usage questions here: https://discourse.scverse.org/. You should not integrate normalized and unnormalized counts. Consider getting the raw counts or integrating on the normalized counts,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2662#issuecomment-1723238652
https://github.com/scverse/scanpy/issues/2662#issuecomment-1723238652:161,Deployability,integrat,integrating,161,Please ask usage questions here: https://discourse.scverse.org/. You should not integrate normalized and unnormalized counts. Consider getting the raw counts or integrating on the normalized counts,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2662#issuecomment-1723238652
https://github.com/scverse/scanpy/issues/2662#issuecomment-1723238652:80,Integrability,integrat,integrate,80,Please ask usage questions here: https://discourse.scverse.org/. You should not integrate normalized and unnormalized counts. Consider getting the raw counts or integrating on the normalized counts,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2662#issuecomment-1723238652
https://github.com/scverse/scanpy/issues/2662#issuecomment-1723238652:161,Integrability,integrat,integrating,161,Please ask usage questions here: https://discourse.scverse.org/. You should not integrate normalized and unnormalized counts. Consider getting the raw counts or integrating on the normalized counts,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2662#issuecomment-1723238652
https://github.com/scverse/scanpy/issues/2667#issuecomment-1803434731:10,Availability,error,error,10,"> From my error log it seems the only non-noarch dependency is [h5py](https://beta.mamba.pm/channels/conda-forge/packages/h5py). That’s surprising! I think numba is our most complex dependency, and umap’s dependency PyNNDescent is also compiled. I think if this isn’t a mistake and it’s really just about h5py, we can think about it. Trying to install scanpy and following JupyterLite’s debug instructions gives:. ![image](https://github.com/scverse/scanpy/assets/291575/07a30013-e78d-46af-80fd-fb48af71d45b). ```pytb; ValueError: Can't find a pure Python 3 wheel for: 'umap-learn>=0.3.10', 'session-info', 'numba>=0.41.0'; See: https://pyodide.org/en/stable/usage/faq.html#why-can-t-micropip-find-a-pure-python-wheel-for-a-package; ```. (session-info isn’t a problem, it’s just an old package that doesn’t publish wheels)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2667#issuecomment-1803434731
https://github.com/scverse/scanpy/issues/2667#issuecomment-1803434731:344,Deployability,install,install,344,"> From my error log it seems the only non-noarch dependency is [h5py](https://beta.mamba.pm/channels/conda-forge/packages/h5py). That’s surprising! I think numba is our most complex dependency, and umap’s dependency PyNNDescent is also compiled. I think if this isn’t a mistake and it’s really just about h5py, we can think about it. Trying to install scanpy and following JupyterLite’s debug instructions gives:. ![image](https://github.com/scverse/scanpy/assets/291575/07a30013-e78d-46af-80fd-fb48af71d45b). ```pytb; ValueError: Can't find a pure Python 3 wheel for: 'umap-learn>=0.3.10', 'session-info', 'numba>=0.41.0'; See: https://pyodide.org/en/stable/usage/faq.html#why-can-t-micropip-find-a-pure-python-wheel-for-a-package; ```. (session-info isn’t a problem, it’s just an old package that doesn’t publish wheels)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2667#issuecomment-1803434731
https://github.com/scverse/scanpy/issues/2667#issuecomment-1803434731:49,Integrability,depend,dependency,49,"> From my error log it seems the only non-noarch dependency is [h5py](https://beta.mamba.pm/channels/conda-forge/packages/h5py). That’s surprising! I think numba is our most complex dependency, and umap’s dependency PyNNDescent is also compiled. I think if this isn’t a mistake and it’s really just about h5py, we can think about it. Trying to install scanpy and following JupyterLite’s debug instructions gives:. ![image](https://github.com/scverse/scanpy/assets/291575/07a30013-e78d-46af-80fd-fb48af71d45b). ```pytb; ValueError: Can't find a pure Python 3 wheel for: 'umap-learn>=0.3.10', 'session-info', 'numba>=0.41.0'; See: https://pyodide.org/en/stable/usage/faq.html#why-can-t-micropip-find-a-pure-python-wheel-for-a-package; ```. (session-info isn’t a problem, it’s just an old package that doesn’t publish wheels)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2667#issuecomment-1803434731
https://github.com/scverse/scanpy/issues/2667#issuecomment-1803434731:182,Integrability,depend,dependency,182,"> From my error log it seems the only non-noarch dependency is [h5py](https://beta.mamba.pm/channels/conda-forge/packages/h5py). That’s surprising! I think numba is our most complex dependency, and umap’s dependency PyNNDescent is also compiled. I think if this isn’t a mistake and it’s really just about h5py, we can think about it. Trying to install scanpy and following JupyterLite’s debug instructions gives:. ![image](https://github.com/scverse/scanpy/assets/291575/07a30013-e78d-46af-80fd-fb48af71d45b). ```pytb; ValueError: Can't find a pure Python 3 wheel for: 'umap-learn>=0.3.10', 'session-info', 'numba>=0.41.0'; See: https://pyodide.org/en/stable/usage/faq.html#why-can-t-micropip-find-a-pure-python-wheel-for-a-package; ```. (session-info isn’t a problem, it’s just an old package that doesn’t publish wheels)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2667#issuecomment-1803434731
https://github.com/scverse/scanpy/issues/2667#issuecomment-1803434731:205,Integrability,depend,dependency,205,"> From my error log it seems the only non-noarch dependency is [h5py](https://beta.mamba.pm/channels/conda-forge/packages/h5py). That’s surprising! I think numba is our most complex dependency, and umap’s dependency PyNNDescent is also compiled. I think if this isn’t a mistake and it’s really just about h5py, we can think about it. Trying to install scanpy and following JupyterLite’s debug instructions gives:. ![image](https://github.com/scverse/scanpy/assets/291575/07a30013-e78d-46af-80fd-fb48af71d45b). ```pytb; ValueError: Can't find a pure Python 3 wheel for: 'umap-learn>=0.3.10', 'session-info', 'numba>=0.41.0'; See: https://pyodide.org/en/stable/usage/faq.html#why-can-t-micropip-find-a-pure-python-wheel-for-a-package; ```. (session-info isn’t a problem, it’s just an old package that doesn’t publish wheels)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2667#issuecomment-1803434731
https://github.com/scverse/scanpy/issues/2667#issuecomment-1803434731:16,Testability,log,log,16,"> From my error log it seems the only non-noarch dependency is [h5py](https://beta.mamba.pm/channels/conda-forge/packages/h5py). That’s surprising! I think numba is our most complex dependency, and umap’s dependency PyNNDescent is also compiled. I think if this isn’t a mistake and it’s really just about h5py, we can think about it. Trying to install scanpy and following JupyterLite’s debug instructions gives:. ![image](https://github.com/scverse/scanpy/assets/291575/07a30013-e78d-46af-80fd-fb48af71d45b). ```pytb; ValueError: Can't find a pure Python 3 wheel for: 'umap-learn>=0.3.10', 'session-info', 'numba>=0.41.0'; See: https://pyodide.org/en/stable/usage/faq.html#why-can-t-micropip-find-a-pure-python-wheel-for-a-package; ```. (session-info isn’t a problem, it’s just an old package that doesn’t publish wheels)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2667#issuecomment-1803434731
https://github.com/scverse/scanpy/issues/2667#issuecomment-1803434731:575,Usability,learn,learn,575,"> From my error log it seems the only non-noarch dependency is [h5py](https://beta.mamba.pm/channels/conda-forge/packages/h5py). That’s surprising! I think numba is our most complex dependency, and umap’s dependency PyNNDescent is also compiled. I think if this isn’t a mistake and it’s really just about h5py, we can think about it. Trying to install scanpy and following JupyterLite’s debug instructions gives:. ![image](https://github.com/scverse/scanpy/assets/291575/07a30013-e78d-46af-80fd-fb48af71d45b). ```pytb; ValueError: Can't find a pure Python 3 wheel for: 'umap-learn>=0.3.10', 'session-info', 'numba>=0.41.0'; See: https://pyodide.org/en/stable/usage/faq.html#why-can-t-micropip-find-a-pure-python-wheel-for-a-package; ```. (session-info isn’t a problem, it’s just an old package that doesn’t publish wheels)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2667#issuecomment-1803434731
https://github.com/scverse/scanpy/issues/2667#issuecomment-1804146936:299,Integrability,depend,depends,299,"`numba` really is the main blocker, see also: . * Tracking issue: https://github.com/pyodide/pyodide/issues/621; * Potential PR: https://github.com/emscripten-forge/recipes/pull/168; * Unfortunately, the author recently founded prefix.dev so may not have time to complete this 😢. `pynndescent` also depends on numba. I am hopeful that numba's new AOT backend may make this easier in the future. Unclear how painful it would be to distribute binaries capable of multithreading though. I think `h5py` would also be pretty reasonable to make optional if we could otherwise run in pyodide, since we wouldn't have a filesystem anyways. Though I think pytables runs in pyodide, so it's probably reasonable to get `h5py` there too.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2667#issuecomment-1804146936
https://github.com/scverse/scanpy/issues/2668#issuecomment-1766402734:295,Testability,log,log,295,"So for a fix, we’d simply need to change. https://github.com/scverse/scanpy/blob/414092f68b4b40aa99153556377c32839b392636/scanpy/preprocessing/_highly_variable_genes.py#L197-L199. into. ```py; X = X.copy(); if 'log1p' in adata.uns_keys() and adata.uns['log1p'].get('base') is not None:; X *= np.log(adata.uns['log1p']['base']); np.expm1(X, out=X); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2668#issuecomment-1766402734
https://github.com/scverse/scanpy/issues/2668#issuecomment-1766402734:19,Usability,simpl,simply,19,"So for a fix, we’d simply need to change. https://github.com/scverse/scanpy/blob/414092f68b4b40aa99153556377c32839b392636/scanpy/preprocessing/_highly_variable_genes.py#L197-L199. into. ```py; X = X.copy(); if 'log1p' in adata.uns_keys() and adata.uns['log1p'].get('base') is not None:; X *= np.log(adata.uns['log1p']['base']); np.expm1(X, out=X); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2668#issuecomment-1766402734
https://github.com/scverse/scanpy/issues/2668#issuecomment-1768622814:245,Testability,log,log,245,"Description of the bug for anyone interested. As @SabrinaRichter and @TyberiusPrime noted, `sc.pp.highly_variable_genes` modified the `layer` used in one case, which is; 1. `sc.pp.log1p(adata, base=b)` with `b != None` has been done (so another log than the default natural logarithm); 2. `sc.highly_variable_genes(adata, flavor='seurat') `has been used (note that flavor='seurat' is the default). (Reproducible) example:. ```py; adata = sc.datasets.pbmc3k(); sc.pp.filter_genes(adata, min_counts=1); sc.pp.log1p(adata, base=10). print('original'); print(adata.X.A[1:6,10:15]). sc.pp.highly_variable_genes(adata, flavor='seurat'); print('after hvg'); print(adata.X.A[1:6,10:15]); ```. Output; ```; original; [[0. 0. 0. 0. 0. ]; [0. 0. 0. 0. 0.30102998]; [0. 0. 0. 0. 1. ]; [0. 0. 0. 0. 0. ]; [0. 0. 0. 0. 0.30102998]]; after hvg; [[0. 0. 0. 0. 0. ]; [0. 0. 0. 0. 0.6931472]; [0. 0. 0. 0. 2.3025851]; [0. 0. 0. 0. 0. ]; [0. 0. 0. 0. 0.6931472]]; ```. The modification of the data which happened in this case is a rebasing; the data in X is log1p transformed with the natural logarithm, instead of the logarithm previously selected by the user. This is unintended and fixed for the next scanpy version.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2668#issuecomment-1768622814
https://github.com/scverse/scanpy/issues/2668#issuecomment-1768622814:274,Testability,log,logarithm,274,"Description of the bug for anyone interested. As @SabrinaRichter and @TyberiusPrime noted, `sc.pp.highly_variable_genes` modified the `layer` used in one case, which is; 1. `sc.pp.log1p(adata, base=b)` with `b != None` has been done (so another log than the default natural logarithm); 2. `sc.highly_variable_genes(adata, flavor='seurat') `has been used (note that flavor='seurat' is the default). (Reproducible) example:. ```py; adata = sc.datasets.pbmc3k(); sc.pp.filter_genes(adata, min_counts=1); sc.pp.log1p(adata, base=10). print('original'); print(adata.X.A[1:6,10:15]). sc.pp.highly_variable_genes(adata, flavor='seurat'); print('after hvg'); print(adata.X.A[1:6,10:15]); ```. Output; ```; original; [[0. 0. 0. 0. 0. ]; [0. 0. 0. 0. 0.30102998]; [0. 0. 0. 0. 1. ]; [0. 0. 0. 0. 0. ]; [0. 0. 0. 0. 0.30102998]]; after hvg; [[0. 0. 0. 0. 0. ]; [0. 0. 0. 0. 0.6931472]; [0. 0. 0. 0. 2.3025851]; [0. 0. 0. 0. 0. ]; [0. 0. 0. 0. 0.6931472]]; ```. The modification of the data which happened in this case is a rebasing; the data in X is log1p transformed with the natural logarithm, instead of the logarithm previously selected by the user. This is unintended and fixed for the next scanpy version.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2668#issuecomment-1768622814
https://github.com/scverse/scanpy/issues/2668#issuecomment-1768622814:1074,Testability,log,logarithm,1074,"Description of the bug for anyone interested. As @SabrinaRichter and @TyberiusPrime noted, `sc.pp.highly_variable_genes` modified the `layer` used in one case, which is; 1. `sc.pp.log1p(adata, base=b)` with `b != None` has been done (so another log than the default natural logarithm); 2. `sc.highly_variable_genes(adata, flavor='seurat') `has been used (note that flavor='seurat' is the default). (Reproducible) example:. ```py; adata = sc.datasets.pbmc3k(); sc.pp.filter_genes(adata, min_counts=1); sc.pp.log1p(adata, base=10). print('original'); print(adata.X.A[1:6,10:15]). sc.pp.highly_variable_genes(adata, flavor='seurat'); print('after hvg'); print(adata.X.A[1:6,10:15]); ```. Output; ```; original; [[0. 0. 0. 0. 0. ]; [0. 0. 0. 0. 0.30102998]; [0. 0. 0. 0. 1. ]; [0. 0. 0. 0. 0. ]; [0. 0. 0. 0. 0.30102998]]; after hvg; [[0. 0. 0. 0. 0. ]; [0. 0. 0. 0. 0.6931472]; [0. 0. 0. 0. 2.3025851]; [0. 0. 0. 0. 0. ]; [0. 0. 0. 0. 0.6931472]]; ```. The modification of the data which happened in this case is a rebasing; the data in X is log1p transformed with the natural logarithm, instead of the logarithm previously selected by the user. This is unintended and fixed for the next scanpy version.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2668#issuecomment-1768622814
https://github.com/scverse/scanpy/issues/2668#issuecomment-1768622814:1100,Testability,log,logarithm,1100,"Description of the bug for anyone interested. As @SabrinaRichter and @TyberiusPrime noted, `sc.pp.highly_variable_genes` modified the `layer` used in one case, which is; 1. `sc.pp.log1p(adata, base=b)` with `b != None` has been done (so another log than the default natural logarithm); 2. `sc.highly_variable_genes(adata, flavor='seurat') `has been used (note that flavor='seurat' is the default). (Reproducible) example:. ```py; adata = sc.datasets.pbmc3k(); sc.pp.filter_genes(adata, min_counts=1); sc.pp.log1p(adata, base=10). print('original'); print(adata.X.A[1:6,10:15]). sc.pp.highly_variable_genes(adata, flavor='seurat'); print('after hvg'); print(adata.X.A[1:6,10:15]); ```. Output; ```; original; [[0. 0. 0. 0. 0. ]; [0. 0. 0. 0. 0.30102998]; [0. 0. 0. 0. 1. ]; [0. 0. 0. 0. 0. ]; [0. 0. 0. 0. 0.30102998]]; after hvg; [[0. 0. 0. 0. 0. ]; [0. 0. 0. 0. 0.6931472]; [0. 0. 0. 0. 2.3025851]; [0. 0. 0. 0. 0. ]; [0. 0. 0. 0. 0.6931472]]; ```. The modification of the data which happened in this case is a rebasing; the data in X is log1p transformed with the natural logarithm, instead of the logarithm previously selected by the user. This is unintended and fixed for the next scanpy version.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2668#issuecomment-1768622814
https://github.com/scverse/scanpy/issues/2669#issuecomment-1733630090:27,Availability,error,error,27,I am encountering the same error. Have you fixed it?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669#issuecomment-1733630090
https://github.com/scverse/scanpy/issues/2669#issuecomment-1768365664:190,Availability,error,error,190,"Hi, everyone, @DawnChou , @Aeget1000 , @iamsalil . I faced the same problem as well. TLDR: choose a higher `span` value in `sc.pp.highly_variable_genes`. The default is 0.3, which caused an error for me as well. 0.5 worked fine in my case. The information below might be interesting for developers or anyone who wants to understand this error more deeply. I got the error when using HLCA data. If scanpy developers are interested, I can point to the dataset to reproduce this problem. It is quite big, but I don't know any other example yet. The error is caused by [this line](https://github.com/scverse/scanpy/blob/27e5f1fa62ec05ee9db0dfa7a9decbf8f25caa31/scanpy/preprocessing/_highly_variable_genes.py#L84C20-L84C20). I got it when selecting HVGs by ""dataset"" batch key in HLCA. Batch ""Sims_2019"" caused the problem. Surprisingly, relationships between `mean` and `var` as well as between `x` and `y` seemed ok:. ![mean_var_relationship](https://github.com/scverse/scanpy/assets/35199218/c3462393-acb5-40fd-80eb-0a45172adce9). ![x_y_relationship](https://github.com/scverse/scanpy/assets/35199218/00e0f6e4-c7d9-4a3d-aeb3-655f185f4f0e). However, something was still causing the problem. I tried to locate the error in the[ loess calucation](https://github.com/has2k1/scikit-misc/blob/269f61e722f81c5bfea964b80b3c20871f2ffe22/skmisc/loess/src/_loess.pyx#L919) in the original package but did not succeed. Anyway, this is a bit out of the scope of scanpy. Setting `span` to a higher value (0.5) solved the problem for me. If there is no strong argument against it, I suggest changing the default value from 0.3 to 0.5. By the way, there is another potential bug in [this function](https://github.com/scverse/scanpy/blob/27e5f1fa62ec05ee9db0dfa7a9decbf8f25caa31/scanpy/preprocessing/_highly_variable_genes.py#L84C20-L84C20). If all the values are constant and `not_const` only consists of False, kernel dies when trying to run `model.fit()`. Maybe it is prevented previously, but in case it isn't, you m",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669#issuecomment-1768365664
https://github.com/scverse/scanpy/issues/2669#issuecomment-1768365664:337,Availability,error,error,337,"Hi, everyone, @DawnChou , @Aeget1000 , @iamsalil . I faced the same problem as well. TLDR: choose a higher `span` value in `sc.pp.highly_variable_genes`. The default is 0.3, which caused an error for me as well. 0.5 worked fine in my case. The information below might be interesting for developers or anyone who wants to understand this error more deeply. I got the error when using HLCA data. If scanpy developers are interested, I can point to the dataset to reproduce this problem. It is quite big, but I don't know any other example yet. The error is caused by [this line](https://github.com/scverse/scanpy/blob/27e5f1fa62ec05ee9db0dfa7a9decbf8f25caa31/scanpy/preprocessing/_highly_variable_genes.py#L84C20-L84C20). I got it when selecting HVGs by ""dataset"" batch key in HLCA. Batch ""Sims_2019"" caused the problem. Surprisingly, relationships between `mean` and `var` as well as between `x` and `y` seemed ok:. ![mean_var_relationship](https://github.com/scverse/scanpy/assets/35199218/c3462393-acb5-40fd-80eb-0a45172adce9). ![x_y_relationship](https://github.com/scverse/scanpy/assets/35199218/00e0f6e4-c7d9-4a3d-aeb3-655f185f4f0e). However, something was still causing the problem. I tried to locate the error in the[ loess calucation](https://github.com/has2k1/scikit-misc/blob/269f61e722f81c5bfea964b80b3c20871f2ffe22/skmisc/loess/src/_loess.pyx#L919) in the original package but did not succeed. Anyway, this is a bit out of the scope of scanpy. Setting `span` to a higher value (0.5) solved the problem for me. If there is no strong argument against it, I suggest changing the default value from 0.3 to 0.5. By the way, there is another potential bug in [this function](https://github.com/scverse/scanpy/blob/27e5f1fa62ec05ee9db0dfa7a9decbf8f25caa31/scanpy/preprocessing/_highly_variable_genes.py#L84C20-L84C20). If all the values are constant and `not_const` only consists of False, kernel dies when trying to run `model.fit()`. Maybe it is prevented previously, but in case it isn't, you m",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669#issuecomment-1768365664
https://github.com/scverse/scanpy/issues/2669#issuecomment-1768365664:366,Availability,error,error,366,"Hi, everyone, @DawnChou , @Aeget1000 , @iamsalil . I faced the same problem as well. TLDR: choose a higher `span` value in `sc.pp.highly_variable_genes`. The default is 0.3, which caused an error for me as well. 0.5 worked fine in my case. The information below might be interesting for developers or anyone who wants to understand this error more deeply. I got the error when using HLCA data. If scanpy developers are interested, I can point to the dataset to reproduce this problem. It is quite big, but I don't know any other example yet. The error is caused by [this line](https://github.com/scverse/scanpy/blob/27e5f1fa62ec05ee9db0dfa7a9decbf8f25caa31/scanpy/preprocessing/_highly_variable_genes.py#L84C20-L84C20). I got it when selecting HVGs by ""dataset"" batch key in HLCA. Batch ""Sims_2019"" caused the problem. Surprisingly, relationships between `mean` and `var` as well as between `x` and `y` seemed ok:. ![mean_var_relationship](https://github.com/scverse/scanpy/assets/35199218/c3462393-acb5-40fd-80eb-0a45172adce9). ![x_y_relationship](https://github.com/scverse/scanpy/assets/35199218/00e0f6e4-c7d9-4a3d-aeb3-655f185f4f0e). However, something was still causing the problem. I tried to locate the error in the[ loess calucation](https://github.com/has2k1/scikit-misc/blob/269f61e722f81c5bfea964b80b3c20871f2ffe22/skmisc/loess/src/_loess.pyx#L919) in the original package but did not succeed. Anyway, this is a bit out of the scope of scanpy. Setting `span` to a higher value (0.5) solved the problem for me. If there is no strong argument against it, I suggest changing the default value from 0.3 to 0.5. By the way, there is another potential bug in [this function](https://github.com/scverse/scanpy/blob/27e5f1fa62ec05ee9db0dfa7a9decbf8f25caa31/scanpy/preprocessing/_highly_variable_genes.py#L84C20-L84C20). If all the values are constant and `not_const` only consists of False, kernel dies when trying to run `model.fit()`. Maybe it is prevented previously, but in case it isn't, you m",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669#issuecomment-1768365664
https://github.com/scverse/scanpy/issues/2669#issuecomment-1768365664:546,Availability,error,error,546,"Hi, everyone, @DawnChou , @Aeget1000 , @iamsalil . I faced the same problem as well. TLDR: choose a higher `span` value in `sc.pp.highly_variable_genes`. The default is 0.3, which caused an error for me as well. 0.5 worked fine in my case. The information below might be interesting for developers or anyone who wants to understand this error more deeply. I got the error when using HLCA data. If scanpy developers are interested, I can point to the dataset to reproduce this problem. It is quite big, but I don't know any other example yet. The error is caused by [this line](https://github.com/scverse/scanpy/blob/27e5f1fa62ec05ee9db0dfa7a9decbf8f25caa31/scanpy/preprocessing/_highly_variable_genes.py#L84C20-L84C20). I got it when selecting HVGs by ""dataset"" batch key in HLCA. Batch ""Sims_2019"" caused the problem. Surprisingly, relationships between `mean` and `var` as well as between `x` and `y` seemed ok:. ![mean_var_relationship](https://github.com/scverse/scanpy/assets/35199218/c3462393-acb5-40fd-80eb-0a45172adce9). ![x_y_relationship](https://github.com/scverse/scanpy/assets/35199218/00e0f6e4-c7d9-4a3d-aeb3-655f185f4f0e). However, something was still causing the problem. I tried to locate the error in the[ loess calucation](https://github.com/has2k1/scikit-misc/blob/269f61e722f81c5bfea964b80b3c20871f2ffe22/skmisc/loess/src/_loess.pyx#L919) in the original package but did not succeed. Anyway, this is a bit out of the scope of scanpy. Setting `span` to a higher value (0.5) solved the problem for me. If there is no strong argument against it, I suggest changing the default value from 0.3 to 0.5. By the way, there is another potential bug in [this function](https://github.com/scverse/scanpy/blob/27e5f1fa62ec05ee9db0dfa7a9decbf8f25caa31/scanpy/preprocessing/_highly_variable_genes.py#L84C20-L84C20). If all the values are constant and `not_const` only consists of False, kernel dies when trying to run `model.fit()`. Maybe it is prevented previously, but in case it isn't, you m",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669#issuecomment-1768365664
https://github.com/scverse/scanpy/issues/2669#issuecomment-1768365664:1210,Availability,error,error,1210," @Aeget1000 , @iamsalil . I faced the same problem as well. TLDR: choose a higher `span` value in `sc.pp.highly_variable_genes`. The default is 0.3, which caused an error for me as well. 0.5 worked fine in my case. The information below might be interesting for developers or anyone who wants to understand this error more deeply. I got the error when using HLCA data. If scanpy developers are interested, I can point to the dataset to reproduce this problem. It is quite big, but I don't know any other example yet. The error is caused by [this line](https://github.com/scverse/scanpy/blob/27e5f1fa62ec05ee9db0dfa7a9decbf8f25caa31/scanpy/preprocessing/_highly_variable_genes.py#L84C20-L84C20). I got it when selecting HVGs by ""dataset"" batch key in HLCA. Batch ""Sims_2019"" caused the problem. Surprisingly, relationships between `mean` and `var` as well as between `x` and `y` seemed ok:. ![mean_var_relationship](https://github.com/scverse/scanpy/assets/35199218/c3462393-acb5-40fd-80eb-0a45172adce9). ![x_y_relationship](https://github.com/scverse/scanpy/assets/35199218/00e0f6e4-c7d9-4a3d-aeb3-655f185f4f0e). However, something was still causing the problem. I tried to locate the error in the[ loess calucation](https://github.com/has2k1/scikit-misc/blob/269f61e722f81c5bfea964b80b3c20871f2ffe22/skmisc/loess/src/_loess.pyx#L919) in the original package but did not succeed. Anyway, this is a bit out of the scope of scanpy. Setting `span` to a higher value (0.5) solved the problem for me. If there is no strong argument against it, I suggest changing the default value from 0.3 to 0.5. By the way, there is another potential bug in [this function](https://github.com/scverse/scanpy/blob/27e5f1fa62ec05ee9db0dfa7a9decbf8f25caa31/scanpy/preprocessing/_highly_variable_genes.py#L84C20-L84C20). If all the values are constant and `not_const` only consists of False, kernel dies when trying to run `model.fit()`. Maybe it is prevented previously, but in case it isn't, you might want to check that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669#issuecomment-1768365664
https://github.com/scverse/scanpy/pull/2671#issuecomment-1733834995:252,Testability,test,tests,252,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2671?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 72.16%. Comparing base [(`0d4c6d2`)](https://app.codecov.io/gh/scverse/scanpy/commit/0d4c6d2b90c7c01a50ebffd33e6c79d2916b3f09?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`3abf5c2`)](https://app.codecov.io/gh/scverse/scanpy/commit/3abf5c2b2893848fa5ded71f2b656e7d8833e53e?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 228 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2671 +/- ##; =======================================; Coverage 72.16% 72.16% ; =======================================; Files 108 108 ; Lines 11908 11908 ; =======================================; + Hits 8593 8594 +1 ; + Misses 3315 3314 -1 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/2671?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/tools/\_tsne.py](https://app.codecov.io/gh/scverse/scanpy/pull/2671?src=pr&el=tree&filepath=scanpy%2Ftools%2F_tsne.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rvb2xzL190c25lLnB5) | `90.00% <ø> (ø)` | |. ... and [1 file with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2671/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2671#issuecomment-1733834995
https://github.com/scverse/scanpy/pull/2672#issuecomment-1764686065:24,Deployability,release,release,24,"ah, and I forgot to add release notes. I need to get https://github.com/scverse/scanpy/pull/2569 done …",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2672#issuecomment-1764686065
https://github.com/scverse/scanpy/issues/2675#issuecomment-1750301889:123,Deployability,configurat,configuration,123,"Hi. This is unlikely to be a scanpy issue. You probably don’t have enough memory or there’s some problem with your Jupyter configuration. But in any case, we need more information to tell which one it is. Please share the logs that `jupyter lab` created, especially any stack traces around “kernel died, restarting”",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2675#issuecomment-1750301889
https://github.com/scverse/scanpy/issues/2675#issuecomment-1750301889:123,Modifiability,config,configuration,123,"Hi. This is unlikely to be a scanpy issue. You probably don’t have enough memory or there’s some problem with your Jupyter configuration. But in any case, we need more information to tell which one it is. Please share the logs that `jupyter lab` created, especially any stack traces around “kernel died, restarting”",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2675#issuecomment-1750301889
https://github.com/scverse/scanpy/issues/2675#issuecomment-1750301889:222,Testability,log,logs,222,"Hi. This is unlikely to be a scanpy issue. You probably don’t have enough memory or there’s some problem with your Jupyter configuration. But in any case, we need more information to tell which one it is. Please share the logs that `jupyter lab` created, especially any stack traces around “kernel died, restarting”",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2675#issuecomment-1750301889
https://github.com/scverse/scanpy/issues/2675#issuecomment-1801420450:120,Testability,log,logs,120,Closing due to lack of information. @jsteward2930 please reopen if the problem persists and you can provide us with the logs.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2675#issuecomment-1801420450
https://github.com/scverse/scanpy/pull/2676#issuecomment-1753090073:331,Availability,error,error-reference,331,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2676?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@fc498c3`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2676 +/- ##; ========================================; Coverage ? 72.00% ; ========================================; Files ? 104 ; Lines ? 11640 ; Branches ? 0 ; ========================================; Hits ? 8381 ; Misses ? 3259 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2676#issuecomment-1753090073
https://github.com/scverse/scanpy/pull/2676#issuecomment-1753090073:279,Usability,learn,learn,279,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2676?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@fc498c3`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2676 +/- ##; ========================================; Coverage ? 72.00% ; ========================================; Files ? 104 ; Lines ? 11640 ; Branches ? 0 ; ========================================; Hits ? 8381 ; Misses ? 3259 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2676#issuecomment-1753090073
https://github.com/scverse/scanpy/pull/2677#issuecomment-1753261271:331,Availability,error,error-reference,331,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2677?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@46969b4`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2677 +/- ##; ========================================; Coverage ? 71.69% ; ========================================; Files ? 104 ; Lines ? 11643 ; Branches ? 0 ; ========================================; Hits ? 8347 ; Misses ? 3296 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2677#issuecomment-1753261271
https://github.com/scverse/scanpy/pull/2677#issuecomment-1753261271:279,Usability,learn,learn,279,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2677?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@46969b4`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2677 +/- ##; ========================================; Coverage ? 71.69% ; ========================================; Files ? 104 ; Lines ? 11643 ; Branches ? 0 ; ========================================; Hits ? 8347 ; Misses ? 3296 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2677#issuecomment-1753261271
https://github.com/scverse/scanpy/issues/2680#issuecomment-1757262413:34,Availability,error,error,34,I also have encountered this same error when trying to use sc.pl.violin,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680#issuecomment-1757262413
https://github.com/scverse/scanpy/issues/2680#issuecomment-1761837779:16,Availability,error,error,16,"I have the same error on scanpy 1.9.5, seaborn 0.13.0, the error seems to be specific to 'multi_panel = True' and produces 3 empty graphs that all inherit the ""n_genes_by_counts"" x-label instead of the proper one.; The same graph is produced normally with 'multi_panel = False'. `sc.pl.violin(full_adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_MT'], multi_panel=True, stripplot=False)`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680#issuecomment-1761837779
https://github.com/scverse/scanpy/issues/2680#issuecomment-1761837779:59,Availability,error,error,59,"I have the same error on scanpy 1.9.5, seaborn 0.13.0, the error seems to be specific to 'multi_panel = True' and produces 3 empty graphs that all inherit the ""n_genes_by_counts"" x-label instead of the proper one.; The same graph is produced normally with 'multi_panel = False'. `sc.pl.violin(full_adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_MT'], multi_panel=True, stripplot=False)`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680#issuecomment-1761837779
https://github.com/scverse/scanpy/issues/2680#issuecomment-1761837779:147,Modifiability,inherit,inherit,147,"I have the same error on scanpy 1.9.5, seaborn 0.13.0, the error seems to be specific to 'multi_panel = True' and produces 3 empty graphs that all inherit the ""n_genes_by_counts"" x-label instead of the proper one.; The same graph is produced normally with 'multi_panel = False'. `sc.pl.violin(full_adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_MT'], multi_panel=True, stripplot=False)`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680#issuecomment-1761837779
https://github.com/scverse/scanpy/issues/2680#issuecomment-1761944327:139,Deployability,update,updated,139,"We're also hitting this. I didnt test this yet, but from our CI history it seems like this worked with seaborn-0.12.2, but broke when that updated to seaborn-0.13.0",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680#issuecomment-1761944327
https://github.com/scverse/scanpy/issues/2680#issuecomment-1761944327:33,Testability,test,test,33,"We're also hitting this. I didnt test this yet, but from our CI history it seems like this worked with seaborn-0.12.2, but broke when that updated to seaborn-0.13.0",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680#issuecomment-1761944327
https://github.com/scverse/scanpy/issues/2680#issuecomment-1762847854:272,Availability,error,error,272,"Hey,; thanks a lot for raising this @Kiliankleemann! And thanks a lot for showing the Version details, big help here. I'll look into this, for the moment it appears that for the violin plot; - indeed as @JacquesFGD mentioned it seems that using seaborn-0.13.0 raises this error when setting `multi_panel=True`: the plot obtainable from `multi_panel=False` seems to work.; - as @bbimber noted, using seaborn-0.12.2 seems to work, also with the `multi_panel=True` option. For urgent violin plots, either of these two options should produce them. Will get back to this asap.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680#issuecomment-1762847854
https://github.com/scverse/scanpy/issues/2680#issuecomment-1764383215:452,Deployability,install,install,452,"Hey,. indeed there seems to be an [issue](https://github.com/mwaskom/seaborn/issues/3522) with our current usage of `seaborn`, not working with `seaborn 0.13.0`.; This has been fixed on the main branch [here](https://github.com/scverse/scanpy/pull/2661), and we'll eventually take over the newest `seaborn` version once this is cleared. For users running into this issue now ; - first check if you indeed have `seaborn 0.13.0`. If yes, then do; - `pip install seaborn==0.12.2` if using pip or; - `conda install seaborn=0.12.2` if using conda. this makes sure you are using the working version of seaborn. Hope this helps!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680#issuecomment-1764383215
https://github.com/scverse/scanpy/issues/2680#issuecomment-1764383215:503,Deployability,install,install,503,"Hey,. indeed there seems to be an [issue](https://github.com/mwaskom/seaborn/issues/3522) with our current usage of `seaborn`, not working with `seaborn 0.13.0`.; This has been fixed on the main branch [here](https://github.com/scverse/scanpy/pull/2661), and we'll eventually take over the newest `seaborn` version once this is cleared. For users running into this issue now ; - first check if you indeed have `seaborn 0.13.0`. If yes, then do; - `pip install seaborn==0.12.2` if using pip or; - `conda install seaborn=0.12.2` if using conda. this makes sure you are using the working version of seaborn. Hope this helps!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680#issuecomment-1764383215
https://github.com/scverse/scanpy/issues/2680#issuecomment-1764383215:328,Usability,clear,cleared,328,"Hey,. indeed there seems to be an [issue](https://github.com/mwaskom/seaborn/issues/3522) with our current usage of `seaborn`, not working with `seaborn 0.13.0`.; This has been fixed on the main branch [here](https://github.com/scverse/scanpy/pull/2661), and we'll eventually take over the newest `seaborn` version once this is cleared. For users running into this issue now ; - first check if you indeed have `seaborn 0.13.0`. If yes, then do; - `pip install seaborn==0.12.2` if using pip or; - `conda install seaborn=0.12.2` if using conda. this makes sure you are using the working version of seaborn. Hope this helps!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680#issuecomment-1764383215
https://github.com/scverse/scanpy/issues/2680#issuecomment-1791425380:162,Integrability,depend,dependency,162,"Hey @victorlga are you still interested in fixing this? :); I think deleting the line order=keys where catplot is used should do the trick, then also the seaborn dependency could be loosened to allow for `0.13.0`...; What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680#issuecomment-1791425380
https://github.com/scverse/scanpy/issues/2680#issuecomment-1812184578:80,Deployability,release,release,80,"Hi,; thanks for fixing this task so quickly! When would you estimate that a new release comes (to pypi) which allows for seaborn>=0.13.0?. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680#issuecomment-1812184578
https://github.com/scverse/scanpy/issues/2680#issuecomment-1814013706:15,Deployability,release,release,15,"We sped up our release process, which means it’s not a huge deal to make one. But it’s still more than just clicking a button, so since we just made a release, maybe in 1-2 weeks?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680#issuecomment-1814013706
https://github.com/scverse/scanpy/issues/2680#issuecomment-1814013706:151,Deployability,release,release,151,"We sped up our release process, which means it’s not a huge deal to make one. But it’s still more than just clicking a button, so since we just made a release, maybe in 1-2 weeks?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680#issuecomment-1814013706
https://github.com/scverse/scanpy/issues/2681#issuecomment-1757749996:48,Testability,test,test,48,See #2682 for a putative fix. Might need a unit test though.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2681#issuecomment-1757749996
https://github.com/scverse/scanpy/pull/2682#issuecomment-1761498585:35,Safety,safe,safer,35,"I think the alternative version is safer, as it’ll work even if they change the format of that autogenerated label. Unless they document it somewhere that it’s that, I assume it’s an implementation detauil.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2682#issuecomment-1761498585
https://github.com/scverse/scanpy/pull/2684#issuecomment-1763195554:215,Deployability,Patch,Patch,215,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2684?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `83.33333%` with `1 line` in your changes missing coverage. Please review.; > Project coverage is 71.83%. Comparing base [(`42e3c2a`)](https://app.codecov.io/gh/scverse/scanpy/commit/42e3c2a04e2bee8431da4e831abd16d198bc8323?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`7b6a875`)](https://app.codecov.io/gh/scverse/scanpy/commit/7b6a875a75529e41e4a53993a0e04a4ad04a9d78?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 223 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/2684?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [scanpy/tools/\_umap.py](https://app.codecov.io/gh/scverse/scanpy/pull/2684?src=pr&el=tree&filepath=scanpy%2Ftools%2F_umap.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rvb2xzL191bWFwLnB5) | 83.33% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/2684?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2684 +/- ##; ==========================================; - Coverage 71.98% 71.83% -0.16% ; ==========================================; Files 108 108 ; Lines 11920 11921 +1 ; ==========================================; - Hits 8581 8563 -18 ; - Misses 3339 3358 +19 ; ```. | [Files with missing lines](https://a,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2684#issuecomment-1763195554
https://github.com/scverse/scanpy/pull/2684#issuecomment-1763195554:1085,Deployability,Patch,Patch,1085,ov.io/gh/scverse/scanpy/pull/2684?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `83.33333%` with `1 line` in your changes missing coverage. Please review.; > Project coverage is 71.83%. Comparing base [(`42e3c2a`)](https://app.codecov.io/gh/scverse/scanpy/commit/42e3c2a04e2bee8431da4e831abd16d198bc8323?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`7b6a875`)](https://app.codecov.io/gh/scverse/scanpy/commit/7b6a875a75529e41e4a53993a0e04a4ad04a9d78?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 223 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/2684?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [scanpy/tools/\_umap.py](https://app.codecov.io/gh/scverse/scanpy/pull/2684?src=pr&el=tree&filepath=scanpy%2Ftools%2F_umap.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rvb2xzL191bWFwLnB5) | 83.33% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/2684?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2684 +/- ##; ==========================================; - Coverage 71.98% 71.83% -0.16% ; ==========================================; Files 108 108 ; Lines 11920 11921 +1 ; ==========================================; - Hits 8581 8563 -18 ; - Misses 3339 3358 +19 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scverse/scan,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2684#issuecomment-1763195554
https://github.com/scverse/scanpy/pull/2684#issuecomment-1764564449:279,Deployability,release,release,279,"I see, [densmap](https://umap-learn.readthedocs.io/en/latest/densmap_demo.html). Hmm, I think that `method='densmap'` and `method_kwds={...}` would be a better API for us (which would then be translated into `densmap=True, densmap_kwds=method_kwds`). This also needs tests and a release note. Also we probably should just remove the umap 0.4 compatibility code, what do you think @ivirshup?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2684#issuecomment-1764564449
https://github.com/scverse/scanpy/pull/2684#issuecomment-1764564449:267,Testability,test,tests,267,"I see, [densmap](https://umap-learn.readthedocs.io/en/latest/densmap_demo.html). Hmm, I think that `method='densmap'` and `method_kwds={...}` would be a better API for us (which would then be translated into `densmap=True, densmap_kwds=method_kwds`). This also needs tests and a release note. Also we probably should just remove the umap 0.4 compatibility code, what do you think @ivirshup?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2684#issuecomment-1764564449
https://github.com/scverse/scanpy/pull/2684#issuecomment-1764564449:30,Usability,learn,learn,30,"I see, [densmap](https://umap-learn.readthedocs.io/en/latest/densmap_demo.html). Hmm, I think that `method='densmap'` and `method_kwds={...}` would be a better API for us (which would then be translated into `densmap=True, densmap_kwds=method_kwds`). This also needs tests and a release note. Also we probably should just remove the umap 0.4 compatibility code, what do you think @ivirshup?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2684#issuecomment-1764564449
https://github.com/scverse/scanpy/issues/2685#issuecomment-1763966212:15,Availability,error,error,15,Thanks but the error persists even after using `adata.obs_names_make_unique()`.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685#issuecomment-1763966212
https://github.com/scverse/scanpy/issues/2685#issuecomment-1763972254:58,Modifiability,variab,variable,58,Does using `adata.var_names_make_unique()` also makes the variable names of `adata.X` unique?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685#issuecomment-1763972254
https://github.com/scverse/scanpy/issues/2685#issuecomment-1763974778:46,Availability,error,error,46,"It would help to tell *where* in the code the error is thrown. Please provide a traceback. > Does using adata.var_names_make_unique() also makes the variable names of adata.X unique?. If X is a DataFrame, yes. Otherwise X doesn’t have any names stored inside (`var_names` are stored as `.var.index`.)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685#issuecomment-1763974778
https://github.com/scverse/scanpy/issues/2685#issuecomment-1763974778:149,Modifiability,variab,variable,149,"It would help to tell *where* in the code the error is thrown. Please provide a traceback. > Does using adata.var_names_make_unique() also makes the variable names of adata.X unique?. If X is a DataFrame, yes. Otherwise X doesn’t have any names stored inside (`var_names` are stored as `.var.index`.)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685#issuecomment-1763974778
https://github.com/scverse/scanpy/issues/2685#issuecomment-1763978277:9,Availability,Error,Error,9,"```pytb; Error in data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), : ; duplicate row.names: TBCE, LINC01238, CYB561D2, MATR3, LINC01505, HSPA14, GOLGA8M, GGT1, ARMCX5-GPRASP2, TMSB15B; ---------------------------------------------------------------------------; RRuntimeError Traceback (most recent call last); File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/ipython/rmagic.py:385, in RMagics.eval(self, code); 383 try:; 384 # Need the newline in case the last line in code is a comment.; --> 385 value, visible = ro.r(""withVisible({%s\n})"" % code); 386 except (ri.embedded.RRuntimeError, ValueError) as exception:; 387 # Otherwise next return seems to have copy of error. File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/robjects/__init__.py:459, in R.__call__(self, string); 458 p = rinterface.parse(string); --> 459 res = self.eval(p); 460 return conversion.get_conversion().rpy2py(res). File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/robjects/functions.py:208, in SignatureTranslatedFunction.__call__(self, *args, **kwargs); 207 kwargs[r_k] = v; --> 208 return (super(SignatureTranslatedFunction, self); 209 .__call__(*args, **kwargs)). File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/robjects/functions.py:131, in Function.__call__(self, *args, **kwargs); 130 new_kwargs[k] = cv.py2rpy(v); --> 131 res = super(Function, self).__call__(*new_args, **new_kwargs); 132 res = cv.rpy2py(res). File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/rinterface_lib/conversion.py:45, in _cdata_res_to_rinterface.<locals>._(*args, **kwargs); 44 def _(*args, **kwargs):; ---> 45 cdata = function(*args, **kwargs); 46 # TODO: test cdata is of the expected CType. File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/rinterface.py:817, in SexpClosure.__call__(self, *args,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685#issuecomment-1763978277
https://github.com/scverse/scanpy/issues/2685#issuecomment-1763978277:725,Availability,error,error,725,"```pytb; Error in data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), : ; duplicate row.names: TBCE, LINC01238, CYB561D2, MATR3, LINC01505, HSPA14, GOLGA8M, GGT1, ARMCX5-GPRASP2, TMSB15B; ---------------------------------------------------------------------------; RRuntimeError Traceback (most recent call last); File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/ipython/rmagic.py:385, in RMagics.eval(self, code); 383 try:; 384 # Need the newline in case the last line in code is a comment.; --> 385 value, visible = ro.r(""withVisible({%s\n})"" % code); 386 except (ri.embedded.RRuntimeError, ValueError) as exception:; 387 # Otherwise next return seems to have copy of error. File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/robjects/__init__.py:459, in R.__call__(self, string); 458 p = rinterface.parse(string); --> 459 res = self.eval(p); 460 return conversion.get_conversion().rpy2py(res). File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/robjects/functions.py:208, in SignatureTranslatedFunction.__call__(self, *args, **kwargs); 207 kwargs[r_k] = v; --> 208 return (super(SignatureTranslatedFunction, self); 209 .__call__(*args, **kwargs)). File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/robjects/functions.py:131, in Function.__call__(self, *args, **kwargs); 130 new_kwargs[k] = cv.py2rpy(v); --> 131 res = super(Function, self).__call__(*new_args, **new_kwargs); 132 res = cv.rpy2py(res). File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/rinterface_lib/conversion.py:45, in _cdata_res_to_rinterface.<locals>._(*args, **kwargs); 44 def _(*args, **kwargs):; ---> 45 cdata = function(*args, **kwargs); 46 # TODO: test cdata is of the expected CType. File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/rinterface.py:817, in SexpClosure.__call__(self, *args,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685#issuecomment-1763978277
https://github.com/scverse/scanpy/issues/2685#issuecomment-1763978277:2138,Availability,Error,Error,2138,"__(self, *args, **kwargs); 207 kwargs[r_k] = v; --> 208 return (super(SignatureTranslatedFunction, self); 209 .__call__(*args, **kwargs)). File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/robjects/functions.py:131, in Function.__call__(self, *args, **kwargs); 130 new_kwargs[k] = cv.py2rpy(v); --> 131 res = super(Function, self).__call__(*new_args, **new_kwargs); 132 res = cv.rpy2py(res). File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/rinterface_lib/conversion.py:45, in _cdata_res_to_rinterface.<locals>._(*args, **kwargs); 44 def _(*args, **kwargs):; ---> 45 cdata = function(*args, **kwargs); 46 # TODO: test cdata is of the expected CType. File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/rinterface.py:817, in SexpClosure.__call__(self, *args, **kwargs); 816 if error_occured[0]:; --> 817 raise embedded.RRuntimeError(_rinterface._geterrmessage()); 818 return res. RRuntimeError: Error in data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), : ; duplicate row.names: TBCE, LINC01238, CYB561D2, MATR3, LINC01505, HSPA14, GOLGA8M, GGT1, ARMCX5-GPRASP2, TMSB15B. During handling of the above exception, another exception occurred:. RInterpreterError Traceback (most recent call last); Cell In[48], line 1; ----> 1 get_ipython().run_cell_magic('R', '-i data -i data_tod -i genes -i cells -i soupx_groups -o out', '\n# specify row and column names of data\nrownames(data) = genes\ncolnames(data) = cells\n# ensure correct sparse format for table of counts and table of droplets\ndata <- as(data, ""sparseMatrix"")\ndata_tod <- as(data_tod, ""sparseMatrix"")\n\n# Generate SoupChannel Object for SoupX \nsc = SoupChannel(data_tod, data, calcSoupProfile = FALSE)\n\n# Add extra meta data to the SoupChannel object\nsoupProf = data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), counts = rowSums(data))\nsc = setSoupProfile(sc, soupProf)\n# Set cluster inf",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685#issuecomment-1763978277
https://github.com/scverse/scanpy/issues/2685#issuecomment-1763978277:4743,Availability,error,error,4743,"ut from being displayed; 2496 # when using magics with decorator @output_can_be_silenced; 2497 # when the last Python token in the expression is a ';'.; 2498 if getattr(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, False):. File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/ipython/rmagic.py:943, in RMagics.R(self, line, cell, local_ns); 941 if not e.stdout.endswith(e.err):; 942 print(e.err); --> 943 raise e; 944 finally:; 945 if self.device in DEVICES_STATIC:. File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/ipython/rmagic.py:923, in RMagics.R(self, line, cell, local_ns); 921 return_output = False; 922 else:; --> 923 text_result, result, visible = self.eval(code); 924 text_output += text_result; 925 if visible:. File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/ipython/rmagic.py:389, in RMagics.eval(self, code); 386 except (ri.embedded.RRuntimeError, ValueError) as exception:; 387 # Otherwise next return seems to have copy of error.; 388 warning_or_other_msg = self.flush(); --> 389 raise RInterpreterError(code, str(exception),; 390 warning_or_other_msg); 391 text_output = self.flush(); 392 return text_output, value, visible[0]. RInterpreterError: Failed to parse and evaluate line '\n# specify row and column names of data\nrownames(data) = genes\ncolnames(data) = cells\n# ensure correct sparse format for table of counts and table of droplets\ndata <- as(data, ""sparseMatrix"")\ndata_tod <- as(data_tod, ""sparseMatrix"")\n\n# Generate SoupChannel Object for SoupX \nsc = SoupChannel(data_tod, data, calcSoupProfile = FALSE)\n\n# Add extra meta data to the SoupChannel object\nsoupProf = data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), counts = rowSums(data))\nsc = setSoupProfile(sc, soupProf)\n# Set cluster information in SoupChannel\nsc = setClusters(sc, soupx_groups)\n\n# Estimate contamination fraction\nsc = autoEstCont(sc, doPlot=FALSE)\n# Infer cor",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685#issuecomment-1763978277
https://github.com/scverse/scanpy/issues/2685#issuecomment-1763978277:5794,Availability,error,error,5794,"rmagic.py:943, in RMagics.R(self, line, cell, local_ns); 941 if not e.stdout.endswith(e.err):; 942 print(e.err); --> 943 raise e; 944 finally:; 945 if self.device in DEVICES_STATIC:. File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/ipython/rmagic.py:923, in RMagics.R(self, line, cell, local_ns); 921 return_output = False; 922 else:; --> 923 text_result, result, visible = self.eval(code); 924 text_output += text_result; 925 if visible:. File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/ipython/rmagic.py:389, in RMagics.eval(self, code); 386 except (ri.embedded.RRuntimeError, ValueError) as exception:; 387 # Otherwise next return seems to have copy of error.; 388 warning_or_other_msg = self.flush(); --> 389 raise RInterpreterError(code, str(exception),; 390 warning_or_other_msg); 391 text_output = self.flush(); 392 return text_output, value, visible[0]. RInterpreterError: Failed to parse and evaluate line '\n# specify row and column names of data\nrownames(data) = genes\ncolnames(data) = cells\n# ensure correct sparse format for table of counts and table of droplets\ndata <- as(data, ""sparseMatrix"")\ndata_tod <- as(data_tod, ""sparseMatrix"")\n\n# Generate SoupChannel Object for SoupX \nsc = SoupChannel(data_tod, data, calcSoupProfile = FALSE)\n\n# Add extra meta data to the SoupChannel object\nsoupProf = data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), counts = rowSums(data))\nsc = setSoupProfile(sc, soupProf)\n# Set cluster information in SoupChannel\nsc = setClusters(sc, soupx_groups)\n\n# Estimate contamination fraction\nsc = autoEstCont(sc, doPlot=FALSE)\n# Infer corrected table of counts and rount to integer\nout = adjustCounts(sc, roundToInt = TRUE)\n'.; R error message: 'Error in data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), : \n duplicate row.names: TBCE, LINC01238, CYB561D2, MATR3, LINC01505, HSPA14, GOLGA8M, GGT1, ARMCX5-GPRASP2, TMSB15B'; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685#issuecomment-1763978277
https://github.com/scverse/scanpy/issues/2685#issuecomment-1763978277:5810,Availability,Error,Error,5810,"rmagic.py:943, in RMagics.R(self, line, cell, local_ns); 941 if not e.stdout.endswith(e.err):; 942 print(e.err); --> 943 raise e; 944 finally:; 945 if self.device in DEVICES_STATIC:. File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/ipython/rmagic.py:923, in RMagics.R(self, line, cell, local_ns); 921 return_output = False; 922 else:; --> 923 text_result, result, visible = self.eval(code); 924 text_output += text_result; 925 if visible:. File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/ipython/rmagic.py:389, in RMagics.eval(self, code); 386 except (ri.embedded.RRuntimeError, ValueError) as exception:; 387 # Otherwise next return seems to have copy of error.; 388 warning_or_other_msg = self.flush(); --> 389 raise RInterpreterError(code, str(exception),; 390 warning_or_other_msg); 391 text_output = self.flush(); 392 return text_output, value, visible[0]. RInterpreterError: Failed to parse and evaluate line '\n# specify row and column names of data\nrownames(data) = genes\ncolnames(data) = cells\n# ensure correct sparse format for table of counts and table of droplets\ndata <- as(data, ""sparseMatrix"")\ndata_tod <- as(data_tod, ""sparseMatrix"")\n\n# Generate SoupChannel Object for SoupX \nsc = SoupChannel(data_tod, data, calcSoupProfile = FALSE)\n\n# Add extra meta data to the SoupChannel object\nsoupProf = data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), counts = rowSums(data))\nsc = setSoupProfile(sc, soupProf)\n# Set cluster information in SoupChannel\nsc = setClusters(sc, soupx_groups)\n\n# Estimate contamination fraction\nsc = autoEstCont(sc, doPlot=FALSE)\n# Infer corrected table of counts and rount to integer\nout = adjustCounts(sc, roundToInt = TRUE)\n'.; R error message: 'Error in data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), : \n duplicate row.names: TBCE, LINC01238, CYB561D2, MATR3, LINC01505, HSPA14, GOLGA8M, GGT1, ARMCX5-GPRASP2, TMSB15B'; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685#issuecomment-1763978277
https://github.com/scverse/scanpy/issues/2685#issuecomment-1763978277:5800,Integrability,message,message,5800,"rmagic.py:943, in RMagics.R(self, line, cell, local_ns); 941 if not e.stdout.endswith(e.err):; 942 print(e.err); --> 943 raise e; 944 finally:; 945 if self.device in DEVICES_STATIC:. File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/ipython/rmagic.py:923, in RMagics.R(self, line, cell, local_ns); 921 return_output = False; 922 else:; --> 923 text_result, result, visible = self.eval(code); 924 text_output += text_result; 925 if visible:. File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/ipython/rmagic.py:389, in RMagics.eval(self, code); 386 except (ri.embedded.RRuntimeError, ValueError) as exception:; 387 # Otherwise next return seems to have copy of error.; 388 warning_or_other_msg = self.flush(); --> 389 raise RInterpreterError(code, str(exception),; 390 warning_or_other_msg); 391 text_output = self.flush(); 392 return text_output, value, visible[0]. RInterpreterError: Failed to parse and evaluate line '\n# specify row and column names of data\nrownames(data) = genes\ncolnames(data) = cells\n# ensure correct sparse format for table of counts and table of droplets\ndata <- as(data, ""sparseMatrix"")\ndata_tod <- as(data_tod, ""sparseMatrix"")\n\n# Generate SoupChannel Object for SoupX \nsc = SoupChannel(data_tod, data, calcSoupProfile = FALSE)\n\n# Add extra meta data to the SoupChannel object\nsoupProf = data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), counts = rowSums(data))\nsc = setSoupProfile(sc, soupProf)\n# Set cluster information in SoupChannel\nsc = setClusters(sc, soupx_groups)\n\n# Estimate contamination fraction\nsc = autoEstCont(sc, doPlot=FALSE)\n# Infer corrected table of counts and rount to integer\nout = adjustCounts(sc, roundToInt = TRUE)\n'.; R error message: 'Error in data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), : \n duplicate row.names: TBCE, LINC01238, CYB561D2, MATR3, LINC01505, HSPA14, GOLGA8M, GGT1, ARMCX5-GPRASP2, TMSB15B'; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685#issuecomment-1763978277
https://github.com/scverse/scanpy/issues/2685#issuecomment-1763978277:1823,Testability,test,test,1823,"ython3.9/site-packages/rpy2/robjects/__init__.py:459, in R.__call__(self, string); 458 p = rinterface.parse(string); --> 459 res = self.eval(p); 460 return conversion.get_conversion().rpy2py(res). File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/robjects/functions.py:208, in SignatureTranslatedFunction.__call__(self, *args, **kwargs); 207 kwargs[r_k] = v; --> 208 return (super(SignatureTranslatedFunction, self); 209 .__call__(*args, **kwargs)). File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/robjects/functions.py:131, in Function.__call__(self, *args, **kwargs); 130 new_kwargs[k] = cv.py2rpy(v); --> 131 res = super(Function, self).__call__(*new_args, **new_kwargs); 132 res = cv.rpy2py(res). File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/rinterface_lib/conversion.py:45, in _cdata_res_to_rinterface.<locals>._(*args, **kwargs); 44 def _(*args, **kwargs):; ---> 45 cdata = function(*args, **kwargs); 46 # TODO: test cdata is of the expected CType. File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/rinterface.py:817, in SexpClosure.__call__(self, *args, **kwargs); 816 if error_occured[0]:; --> 817 raise embedded.RRuntimeError(_rinterface._geterrmessage()); 818 return res. RRuntimeError: Error in data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), : ; duplicate row.names: TBCE, LINC01238, CYB561D2, MATR3, LINC01505, HSPA14, GOLGA8M, GGT1, ARMCX5-GPRASP2, TMSB15B. During handling of the above exception, another exception occurred:. RInterpreterError Traceback (most recent call last); Cell In[48], line 1; ----> 1 get_ipython().run_cell_magic('R', '-i data -i data_tod -i genes -i cells -i soupx_groups -o out', '\n# specify row and column names of data\nrownames(data) = genes\ncolnames(data) = cells\n# ensure correct sparse format for table of counts and table of droplets\ndata <- as(data, ""sparseMatrix"")\ndata_to",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685#issuecomment-1763978277
https://github.com/scverse/scanpy/pull/2686#issuecomment-1764071999:331,Availability,error,error-reference,331,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2686?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@418baff`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 503876d differs from pull request most recent head 5c315d4. Consider uploading reports for the commit 5c315d4 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2686 +/- ##; ========================================; Coverage ? 71.98% ; ========================================; Files ? 104 ; Lines ? 11642 ; Branches ? 0 ; ========================================; Hits ? 8381 ; Misses ? 3261 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2686#issuecomment-1764071999
https://github.com/scverse/scanpy/pull/2686#issuecomment-1764071999:279,Usability,learn,learn,279,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2686?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@418baff`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 503876d differs from pull request most recent head 5c315d4. Consider uploading reports for the commit 5c315d4 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2686 +/- ##; ========================================; Coverage ? 71.98% ; ========================================; Files ? 104 ; Lines ? 11642 ; Branches ? 0 ; ========================================; Hits ? 8381 ; Misses ? 3261 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2686#issuecomment-1764071999
https://github.com/scverse/scanpy/pull/2687#issuecomment-1764131250:332,Availability,error,error-reference,332,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2687?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`master@8353e45`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 601888e differs from pull request most recent head f257b7f. Consider uploading reports for the commit f257b7f to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2687 +/- ##; =========================================; Coverage ? 71.97% ; =========================================; Files ? 108 ; Lines ? 11907 ; Branches ? 0 ; =========================================; Hits ? 8570 ; Misses ? 3337 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2687#issuecomment-1764131250
https://github.com/scverse/scanpy/pull/2687#issuecomment-1764131250:280,Usability,learn,learn,280,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2687?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`master@8353e45`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 601888e differs from pull request most recent head f257b7f. Consider uploading reports for the commit f257b7f to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2687 +/- ##; =========================================; Coverage ? 71.97% ; =========================================; Files ? 108 ; Lines ? 11907 ; Branches ? 0 ; =========================================; Hits ? 8570 ; Misses ? 3337 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2687#issuecomment-1764131250
https://github.com/scverse/scanpy/pull/2690#issuecomment-1764724800:331,Availability,error,error-reference,331,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2690?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@3c15b99`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2690 +/- ##; ========================================; Coverage ? 71.99% ; ========================================; Files ? 104 ; Lines ? 11643 ; Branches ? 0 ; ========================================; Hits ? 8382 ; Misses ? 3261 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2690#issuecomment-1764724800
https://github.com/scverse/scanpy/pull/2690#issuecomment-1764724800:279,Usability,learn,learn,279,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2690?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@3c15b99`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2690 +/- ##; ========================================; Coverage ? 71.99% ; ========================================; Files ? 104 ; Lines ? 11643 ; Branches ? 0 ; ========================================; Hits ? 8382 ; Misses ? 3261 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2690#issuecomment-1764724800
https://github.com/scverse/scanpy/pull/2696#issuecomment-1766017585:1896,Testability,test,testing,1896,==================; Files 110 111 +1 ; Lines 12100 12133 +33 ; ==========================================; + Hits 8818 8848 +30 ; - Misses 3282 3285 +3 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2696?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/experimental/pp/\_highly\_variable\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/2696?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2V4cGVyaW1lbnRhbC9wcC9faGlnaGx5X3ZhcmlhYmxlX2dlbmVzLnB5) | `63.69% <100.00%> (ø)` | |; | [scanpy/preprocessing/\_utils.py](https://app.codecov.io/gh/scverse/scanpy/pull/2696?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX3V0aWxzLnB5) | `45.16% <100.00%> (+1.82%)` | :arrow_up: |; | [scanpy/testing/\_pytest/fixtures/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2696?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9maXh0dXJlcy9fX2luaXRfXy5weQ==) | `94.11% <ø> (-2.44%)` | :arrow_down: |; | [scanpy/tools/\_rank\_genes\_groups.py](https://app.codecov.io/gh/scverse/scanpy/pull/2696?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rvb2xzL19yYW5rX2dlbmVzX2dyb3Vwcy5weQ==) | `92.77% <100.00%> (-0.03%)` | :arrow_down: |; | [scanpy/testing/\_pytest/params.py](https://app.codecov.io/gh/scverse/scanpy/pull/2696?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9wYXJhbXMucHk=) | `94.73% <94.73%> (ø)` | |; | [scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2696?src=p,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2696#issuecomment-1766017585
https://github.com/scverse/scanpy/pull/2696#issuecomment-1766017585:2535,Testability,test,testing,2535,/pull/2696?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/experimental/pp/\_highly\_variable\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/2696?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2V4cGVyaW1lbnRhbC9wcC9faGlnaGx5X3ZhcmlhYmxlX2dlbmVzLnB5) | `63.69% <100.00%> (ø)` | |; | [scanpy/preprocessing/\_utils.py](https://app.codecov.io/gh/scverse/scanpy/pull/2696?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX3V0aWxzLnB5) | `45.16% <100.00%> (+1.82%)` | :arrow_up: |; | [scanpy/testing/\_pytest/fixtures/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2696?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9maXh0dXJlcy9fX2luaXRfXy5weQ==) | `94.11% <ø> (-2.44%)` | :arrow_down: |; | [scanpy/tools/\_rank\_genes\_groups.py](https://app.codecov.io/gh/scverse/scanpy/pull/2696?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rvb2xzL19yYW5rX2dlbmVzX2dyb3Vwcy5weQ==) | `92.77% <100.00%> (-0.03%)` | :arrow_down: |; | [scanpy/testing/\_pytest/params.py](https://app.codecov.io/gh/scverse/scanpy/pull/2696?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9wYXJhbXMucHk=) | `94.73% <94.73%> (ø)` | |; | [scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2696?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L191dGlscy9fX2luaXRfXy5weQ==) | `65.32% <94.11%> (+2.05%)` | :arrow_up: |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2696#issuecomment-1766017585
https://github.com/scverse/scanpy/pull/2696#issuecomment-1781361678:844,Integrability,depend,depend,844,"I went over all the places where we use the `array_type` fixture and thought about your idea to use `@pytest.mark.parametrize` and I came around to it for this case:. For **unfinished** features, it’s great. Everwhere we can’t say “we fully support this” and gradually build in support, we should use it. It has its disadvantages:. - `@pytest.mark.parametrize(""array_type"", ARRAY_TYPES)` is so long that in practice, it’s hard to see the difference to something like this: `@pytest.mark.parametrize(""array_type"", ARRAY_TYPES_XYZ)`. 	E.g. I don’t like seeing; 	; 	```py; 	@pytest.mark.parametrize(""array_type"", ARRAY_TYPES); 	@pytest.mark.parametrize(""dtype"", [""float32"", ""int64""]); 	```. 	4 times in `test_normalize_total`. If the 3rd test had a different list of values in one of the params, it would be near impossible to see. - Fixtures can depend on other fixtures, but can’t easily have a parameter matrix without that. (`pytest.fixture(params=...)` only accepts a single list of parameters, we’d have to manually use `product` in there for a matrix). That’s why I didn’t go away from a fixture in `test_pca.py`. I therefore propose that we use `@pytest.mark.parametrize` for. - things that aren’t heavily reused; - things we don’t fully support. and fixtures for everything where there’s ~3 or more test functions using the same list of parameter values.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2696#issuecomment-1781361678
https://github.com/scverse/scanpy/pull/2696#issuecomment-1781361678:735,Testability,test,test,735,"I went over all the places where we use the `array_type` fixture and thought about your idea to use `@pytest.mark.parametrize` and I came around to it for this case:. For **unfinished** features, it’s great. Everwhere we can’t say “we fully support this” and gradually build in support, we should use it. It has its disadvantages:. - `@pytest.mark.parametrize(""array_type"", ARRAY_TYPES)` is so long that in practice, it’s hard to see the difference to something like this: `@pytest.mark.parametrize(""array_type"", ARRAY_TYPES_XYZ)`. 	E.g. I don’t like seeing; 	; 	```py; 	@pytest.mark.parametrize(""array_type"", ARRAY_TYPES); 	@pytest.mark.parametrize(""dtype"", [""float32"", ""int64""]); 	```. 	4 times in `test_normalize_total`. If the 3rd test had a different list of values in one of the params, it would be near impossible to see. - Fixtures can depend on other fixtures, but can’t easily have a parameter matrix without that. (`pytest.fixture(params=...)` only accepts a single list of parameters, we’d have to manually use `product` in there for a matrix). That’s why I didn’t go away from a fixture in `test_pca.py`. I therefore propose that we use `@pytest.mark.parametrize` for. - things that aren’t heavily reused; - things we don’t fully support. and fixtures for everything where there’s ~3 or more test functions using the same list of parameter values.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2696#issuecomment-1781361678
https://github.com/scverse/scanpy/pull/2696#issuecomment-1781361678:1305,Testability,test,test,1305,"I went over all the places where we use the `array_type` fixture and thought about your idea to use `@pytest.mark.parametrize` and I came around to it for this case:. For **unfinished** features, it’s great. Everwhere we can’t say “we fully support this” and gradually build in support, we should use it. It has its disadvantages:. - `@pytest.mark.parametrize(""array_type"", ARRAY_TYPES)` is so long that in practice, it’s hard to see the difference to something like this: `@pytest.mark.parametrize(""array_type"", ARRAY_TYPES_XYZ)`. 	E.g. I don’t like seeing; 	; 	```py; 	@pytest.mark.parametrize(""array_type"", ARRAY_TYPES); 	@pytest.mark.parametrize(""dtype"", [""float32"", ""int64""]); 	```. 	4 times in `test_normalize_total`. If the 3rd test had a different list of values in one of the params, it would be near impossible to see. - Fixtures can depend on other fixtures, but can’t easily have a parameter matrix without that. (`pytest.fixture(params=...)` only accepts a single list of parameters, we’d have to manually use `product` in there for a matrix). That’s why I didn’t go away from a fixture in `test_pca.py`. I therefore propose that we use `@pytest.mark.parametrize` for. - things that aren’t heavily reused; - things we don’t fully support. and fixtures for everything where there’s ~3 or more test functions using the same list of parameter values.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2696#issuecomment-1781361678
https://github.com/scverse/scanpy/pull/2697#issuecomment-1766637428:331,Availability,error,error-reference,331,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2697?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@d71a4a9`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2697 +/- ##; ========================================; Coverage ? 72.01% ; ========================================; Files ? 104 ; Lines ? 11656 ; Branches ? 0 ; ========================================; Hits ? 8394 ; Misses ? 3262 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2697#issuecomment-1766637428
https://github.com/scverse/scanpy/pull/2697#issuecomment-1766637428:279,Usability,learn,learn,279,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2697?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@d71a4a9`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2697 +/- ##; ========================================; Coverage ? 72.01% ; ========================================; Files ? 104 ; Lines ? 11656 ; Branches ? 0 ; ========================================; Hits ? 8394 ; Misses ? 3262 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2697#issuecomment-1766637428
https://github.com/scverse/scanpy/pull/2698#issuecomment-1770654161:79,Deployability,release,release,79,"OK! This is a bugfix, so I added this PR to the bugfix milestone. Please add a release note for 1.9.6, then it’s ready!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2698#issuecomment-1770654161
https://github.com/scverse/scanpy/pull/2701#issuecomment-1772240411:18,Modifiability,config,configure,18,"> Why did we ever configure black?. because Alex liked `'` more. I think at the time we didn’t know of `pre-commit-hooks`’ `double-quote-string-fixer`, or it didn‘t exist yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2701#issuecomment-1772240411
https://github.com/scverse/scanpy/pull/2703#issuecomment-1775039451:2451,Testability,log,logging,2451,&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L191dGlscy9fX2luaXRfXy5weQ==) | `67.20% <100.00%> (+0.35%)` | :arrow_up: |; | [scanpy/external/pl.py](https://app.codecov.io/gh/scverse/scanpy/pull/2703?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2V4dGVybmFsL3BsLnB5) | `32.63% <100.00%> (-17.74%)` | :arrow_down: |; | [scanpy/external/pp/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2703?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2V4dGVybmFsL3BwL19faW5pdF9fLnB5) | `100.00% <100.00%> (ø)` | |; | [scanpy/get/get.py](https://app.codecov.io/gh/scverse/scanpy/pull/2703?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2dldC9nZXQucHk=) | `92.59% <ø> (ø)` | |; | [scanpy/logging.py](https://app.codecov.io/gh/scverse/scanpy/pull/2703?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2xvZ2dpbmcucHk=) | `95.12% <ø> (ø)` | |; | [scanpy/neighbors/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2703?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L25laWdoYm9ycy9fX2luaXRfXy5weQ==) | `80.75% <100.00%> (+3.28%)` | :arrow_up: |; | [scanpy/neighbors/\_common.py](https://app.codecov.io/gh/scverse/scanpy/pull/2703?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L25laWdoYm9ycy9fY29tbW9uLnB5) | `64.91% <100.00%> (ø)` | |; | [scanpy/neighbors/\_types.py](https://app.codecov.io/gh/scverse/scanpy/pull/2703?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2703#issuecomment-1775039451
https://github.com/scverse/scanpy/pull/2703#issuecomment-1787395391:23,Testability,test,tests,23,TODO: add quantitative tests,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2703#issuecomment-1787395391
https://github.com/scverse/scanpy/pull/2704#issuecomment-1776676386:157,Deployability,update,update,157,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 95206dc54c8bb0d9d478f09f47dff9477a5c58c4; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2704: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2704-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2704 on branch 1.9.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2704#issuecomment-1776676386
https://github.com/scverse/scanpy/pull/2704#issuecomment-1776676386:913,Deployability,continuous,continuous,913,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 95206dc54c8bb0d9d478f09f47dff9477a5c58c4; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2704: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2704-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2704 on branch 1.9.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2704#issuecomment-1776676386
https://github.com/scverse/scanpy/pull/2704#issuecomment-1776676386:924,Deployability,integrat,integration,924,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 95206dc54c8bb0d9d478f09f47dff9477a5c58c4; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2704: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2704-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2704 on branch 1.9.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2704#issuecomment-1776676386
https://github.com/scverse/scanpy/pull/2704#issuecomment-1776676386:924,Integrability,integrat,integration,924,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 95206dc54c8bb0d9d478f09f47dff9477a5c58c4; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2704: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2704-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2704 on branch 1.9.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2704#issuecomment-1776676386
https://github.com/scverse/scanpy/pull/2704#issuecomment-1776676386:899,Testability,test,tested,899,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 95206dc54c8bb0d9d478f09f47dff9477a5c58c4; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2704: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2704-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2704 on branch 1.9.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2704#issuecomment-1776676386
https://github.com/scverse/scanpy/pull/2705#issuecomment-1777219410:234,Testability,test,tests,234,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2705?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Comparison is base [(`bf5f27a`)](https://app.codecov.io/gh/scverse/scanpy/commit/bf5f27aa9e968de6e73fc7abb46a89084ddf6880?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.72% compared to head [(`28c2def`)](https://app.codecov.io/gh/scverse/scanpy/pull/2705?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.72%.; > Report is 1 commits behind head on master. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2705 +/- ##; =======================================; Coverage 72.72% 72.72% ; =======================================; Files 111 111 ; Lines 12383 12383 ; =======================================; Hits 9005 9005 ; Misses 3378 3378 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2705?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/plotting/\_utils.py](https://app.codecov.io/gh/scverse/scanpy/pull/2705?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL191dGlscy5weQ==) | `56.33% <100.00%> (ø)` | |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2705#issuecomment-1777219410
https://github.com/scverse/scanpy/issues/2706#issuecomment-1777066040:10,Deployability,install,installed,10,"`tbb` was installed via conda i guess, try to uninstall `tbb` with conda and then install `scanpy` again.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2706#issuecomment-1777066040
https://github.com/scverse/scanpy/issues/2706#issuecomment-1777066040:82,Deployability,install,install,82,"`tbb` was installed via conda i guess, try to uninstall `tbb` with conda and then install `scanpy` again.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2706#issuecomment-1777066040
https://github.com/scverse/scanpy/pull/2707#issuecomment-1777515803:1275,Testability,test,testing,1275,gn=pr+comments&utm_term=scverse) Report; > Merging [#2707](https://app.codecov.io/gh/scverse/scanpy/pull/2707?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) (39c3397) into [master](https://app.codecov.io/gh/scverse/scanpy/commit/973c4c3e84661bbce06be8c85ffe7d34d8e32191?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) (973c4c3) will **increase** coverage by `0.08%`.; > The diff coverage is `91.66%`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2707 +/- ##; ==========================================; + Coverage 73.13% 73.21% +0.08% ; ==========================================; Files 111 111 ; Lines 12220 12246 +26 ; ==========================================; + Hits 8937 8966 +29 ; + Misses 3283 3280 -3 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2707?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/testing/\_pytest/marks.py](https://app.codecov.io/gh/scverse/scanpy/pull/2707?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9tYXJrcy5weQ==) | `100.00% <100.00%> (+26.31%)` | :arrow_up: |; | [scanpy/testing/\_pytest/params.py](https://app.codecov.io/gh/scverse/scanpy/pull/2707?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9wYXJhbXMucHk=) | `94.73% <ø> (ø)` | |; | [scanpy/testing/\_doctests.py](https://app.codecov.io/gh/scverse/scanpy/pull/2707?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX2RvY3Rlc3RzLnB5) | `80.76% <60.00%> (-4.95%)` | :arrow_down: |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2707#issuecomment-1777515803
https://github.com/scverse/scanpy/pull/2707#issuecomment-1777515803:1577,Testability,test,testing,1577,gn=pr+comments&utm_term=scverse) Report; > Merging [#2707](https://app.codecov.io/gh/scverse/scanpy/pull/2707?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) (39c3397) into [master](https://app.codecov.io/gh/scverse/scanpy/commit/973c4c3e84661bbce06be8c85ffe7d34d8e32191?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) (973c4c3) will **increase** coverage by `0.08%`.; > The diff coverage is `91.66%`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2707 +/- ##; ==========================================; + Coverage 73.13% 73.21% +0.08% ; ==========================================; Files 111 111 ; Lines 12220 12246 +26 ; ==========================================; + Hits 8937 8966 +29 ; + Misses 3283 3280 -3 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2707?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/testing/\_pytest/marks.py](https://app.codecov.io/gh/scverse/scanpy/pull/2707?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9tYXJrcy5weQ==) | `100.00% <100.00%> (+26.31%)` | :arrow_up: |; | [scanpy/testing/\_pytest/params.py](https://app.codecov.io/gh/scverse/scanpy/pull/2707?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9wYXJhbXMucHk=) | `94.73% <ø> (ø)` | |; | [scanpy/testing/\_doctests.py](https://app.codecov.io/gh/scverse/scanpy/pull/2707?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX2RvY3Rlc3RzLnB5) | `80.76% <60.00%> (-4.95%)` | :arrow_down: |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2707#issuecomment-1777515803
https://github.com/scverse/scanpy/pull/2707#issuecomment-1777515803:1856,Testability,test,testing,1856,gn=pr+comments&utm_term=scverse) Report; > Merging [#2707](https://app.codecov.io/gh/scverse/scanpy/pull/2707?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) (39c3397) into [master](https://app.codecov.io/gh/scverse/scanpy/commit/973c4c3e84661bbce06be8c85ffe7d34d8e32191?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) (973c4c3) will **increase** coverage by `0.08%`.; > The diff coverage is `91.66%`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2707 +/- ##; ==========================================; + Coverage 73.13% 73.21% +0.08% ; ==========================================; Files 111 111 ; Lines 12220 12246 +26 ; ==========================================; + Hits 8937 8966 +29 ; + Misses 3283 3280 -3 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2707?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/testing/\_pytest/marks.py](https://app.codecov.io/gh/scverse/scanpy/pull/2707?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9tYXJrcy5weQ==) | `100.00% <100.00%> (+26.31%)` | :arrow_up: |; | [scanpy/testing/\_pytest/params.py](https://app.codecov.io/gh/scverse/scanpy/pull/2707?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9wYXJhbXMucHk=) | `94.73% <ø> (ø)` | |; | [scanpy/testing/\_doctests.py](https://app.codecov.io/gh/scverse/scanpy/pull/2707?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX2RvY3Rlc3RzLnB5) | `80.76% <60.00%> (-4.95%)` | :arrow_down: |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2707#issuecomment-1777515803
https://github.com/scverse/scanpy/issues/2708#issuecomment-1803768928:454,Integrability,wrap,wraps,454,"They are capitalized, which means they are treated as constants and shouldn’t be modified. They *are* the original default value you want to refer to, so if you change them, you can’t do that anymore. So yes, `style` or the parameters in `def dotplot` are the correct way to do this. If you want a customized version, just do:. ```py; my_style = dict(...) # resusable customizations. sc.pl.dotplot(..., **my_style); ```. or. ```py; from functools import wraps. @wraps(sc.pl.dotplot); def my_dotpot(*args, return_fig: bool = False, **kw):; dp = sc.pl.dotplot(*args, **kw, return_fig=True); dp.style(...) # customize here; if return_fig:; return dp; dp.show(); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2708#issuecomment-1803768928
https://github.com/scverse/scanpy/issues/2708#issuecomment-1803768928:462,Integrability,wrap,wraps,462,"They are capitalized, which means they are treated as constants and shouldn’t be modified. They *are* the original default value you want to refer to, so if you change them, you can’t do that anymore. So yes, `style` or the parameters in `def dotplot` are the correct way to do this. If you want a customized version, just do:. ```py; my_style = dict(...) # resusable customizations. sc.pl.dotplot(..., **my_style); ```. or. ```py; from functools import wraps. @wraps(sc.pl.dotplot); def my_dotpot(*args, return_fig: bool = False, **kw):; dp = sc.pl.dotplot(*args, **kw, return_fig=True); dp.style(...) # customize here; if return_fig:; return dp; dp.show(); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2708#issuecomment-1803768928
https://github.com/scverse/scanpy/pull/2716#issuecomment-1780921886:157,Deployability,update,update,157,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 c2f706b35d52a5e21ccf84f1cd299b0dadf49668; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2716: Add missing link targets'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2716-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2716 on branch 1.9.x (Add missing link targets)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2716#issuecomment-1780921886
https://github.com/scverse/scanpy/pull/2716#issuecomment-1780921886:887,Deployability,continuous,continuous,887,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 c2f706b35d52a5e21ccf84f1cd299b0dadf49668; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2716: Add missing link targets'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2716-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2716 on branch 1.9.x (Add missing link targets)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2716#issuecomment-1780921886
https://github.com/scverse/scanpy/pull/2716#issuecomment-1780921886:898,Deployability,integrat,integration,898,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 c2f706b35d52a5e21ccf84f1cd299b0dadf49668; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2716: Add missing link targets'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2716-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2716 on branch 1.9.x (Add missing link targets)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2716#issuecomment-1780921886
https://github.com/scverse/scanpy/pull/2716#issuecomment-1780921886:898,Integrability,integrat,integration,898,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 c2f706b35d52a5e21ccf84f1cd299b0dadf49668; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2716: Add missing link targets'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2716-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2716 on branch 1.9.x (Add missing link targets)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2716#issuecomment-1780921886
https://github.com/scverse/scanpy/pull/2716#issuecomment-1780921886:873,Testability,test,tested,873,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 c2f706b35d52a5e21ccf84f1cd299b0dadf49668; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2716: Add missing link targets'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2716-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2716 on branch 1.9.x (Add missing link targets)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2716#issuecomment-1780921886
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:930,Availability,ERROR,ERROR,930,"Hm, there’s something messed up with the test runner. It fails these tests:. ```; scanpy/tests/test_embedding_plots.py::test_visium_circles FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_visium_default FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_visium_empty_img_key FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_general FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_external_img FAILED [ 14%]; ...; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-10] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[cell_ranger-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-100-30-False] ERROR [ 30%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variab",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:1077,Availability,ERROR,ERROR,1077,fails these tests:. ```; scanpy/tests/test_embedding_plots.py::test_visium_circles FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_visium_default FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_visium_empty_img_key FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_general FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_external_img FAILED [ 14%]; ...; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-10] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[cell_ranger-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-100-30-False] ERROR [ 30%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:1225,Availability,ERROR,ERROR,1225,default FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_visium_empty_img_key FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_general FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_external_img FAILED [ 14%]; ...; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-10] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[cell_ranger-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-100-30-False] ERROR [ 30%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residual,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:1371,Availability,ERROR,ERROR,1371,atial_general FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_external_img FAILED [ 14%]; ...; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-10] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[cell_ranger-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-100-30-False] ERROR [ 30%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:1518,Availability,ERROR,ERROR,1518,_genes.py::test_highly_variable_genes_keep_layer[seurat-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-10] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[cell_ranger-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-100-30-False] ERROR [ 30%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:1663,Availability,ERROR,ERROR,1663,s_keep_layer[seurat-10] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[cell_ranger-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-100-30-False] ERROR [ 30%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:1809,Availability,ERROR,ERROR,1809,[ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-100-30-False] ERROR [ 30%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:1956,Availability,ERROR,ERROR,1956,[ 30%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:2104,Availability,ERROR,ERROR,2104, 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residual,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:2250,Availability,ERROR,ERROR,2250,[ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:2397,Availability,ERROR,ERROR,2397,[ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:2542,Availability,ERROR,ERROR,2542, [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:2688,Availability,ERROR,ERROR,2688,[ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:2835,Availability,ERROR,ERROR,2835,[ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:2983,Availability,ERROR,ERROR,2983, 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:3129,Availability,ERROR,ERROR,3129,[ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-Fals,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:3276,Availability,ERROR,ERROR,3276,[ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:3421,Availability,ERROR,ERROR,3421, [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:3567,Availability,ERROR,ERROR,3567,[ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:3703,Availability,ERROR,ERROR,3703,RROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; s,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:3840,Availability,ERROR,ERROR,3840,one-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_norma,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:3976,Availability,ERROR,ERROR,3976,-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_nor,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:4113,Availability,ERROR,ERROR,4113,csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_res,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:4226,Availability,ERROR,ERROR,4226,earson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_highly_variable_genes.py::test_higly_variable_gene,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:4338,Availability,ERROR,ERROR,4338,s.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_highly_variable_genes.py::test_higly_variable_genes_compare_to_seurat FAILED [ 33%]; ...; scanpy/tests/test_highly_variable_genes.py::test_filter_genes_dispersion,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:4450,Availability,ERROR,ERROR,4450,y/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_highly_variable_genes.py::test_higly_variable_genes_compare_to_seurat FAILED [ 33%]; ...; scanpy/tests/test_highly_variable_genes.py::test_filter_genes_dispersion_compare_to_seurat FAILED [ 34%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_batches,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:4562,Availability,ERROR,ERROR,4562,-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_highly_variable_genes.py::test_higly_variable_genes_compare_to_seurat FAILED [ 33%]; ...; scanpy/tests/test_highly_variable_genes.py::test_filter_genes_dispersion_compare_to_seurat FAILED [ 34%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_batches FAILED [ 34%]; ```. and then gets stuck after. ```; scanpy/tests/test_preprocessing.py::test_scale_array[<lambd,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:4674,Availability,ERROR,ERROR,4674,duals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_highly_variable_genes.py::test_higly_variable_genes_compare_to_seurat FAILED [ 33%]; ...; scanpy/tests/test_highly_variable_genes.py::test_filter_genes_dispersion_compare_to_seurat FAILED [ 34%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_batches FAILED [ 34%]; ```. and then gets stuck after. ```; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-False] PASSED [ 83%]; scan,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:4789,Availability,ERROR,ERROR,4789,able_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_highly_variable_genes.py::test_higly_variable_genes_compare_to_seurat FAILED [ 33%]; ...; scanpy/tests/test_highly_variable_genes.py::test_filter_genes_dispersion_compare_to_seurat FAILED [ 34%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_batches FAILED [ 34%]; ```. and then gets stuck after. ```; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-False] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csr_matrix-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.p,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:4904,Availability,ERROR,ERROR,4904,s.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_highly_variable_genes.py::test_higly_variable_genes_compare_to_seurat FAILED [ 33%]; ...; scanpy/tests/test_highly_variable_genes.py::test_filter_genes_dispersion_compare_to_seurat FAILED [ 34%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_batches FAILED [ 34%]; ```. and then gets stuck after. ```; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-False] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csr_matrix-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csr_matrix-False] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csc_matri,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:5019,Availability,ERROR,ERROR,5019,_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_highly_variable_genes.py::test_higly_variable_genes_compare_to_seurat FAILED [ 33%]; ...; scanpy/tests/test_highly_variable_genes.py::test_filter_genes_dispersion_compare_to_seurat FAILED [ 34%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_batches FAILED [ 34%]; ```. and then gets stuck after. ```; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-False] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csr_matrix-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csr_matrix-False] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csc_matrix-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csc_matrix-False] PASSED [ 83%]; ```. s,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:5134,Availability,ERROR,ERROR,5134,highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_highly_variable_genes.py::test_higly_variable_genes_compare_to_seurat FAILED [ 33%]; ...; scanpy/tests/test_highly_variable_genes.py::test_filter_genes_dispersion_compare_to_seurat FAILED [ 34%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_batches FAILED [ 34%]; ```. and then gets stuck after. ```; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-False] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csr_matrix-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csr_matrix-False] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csc_matrix-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csc_matrix-False] PASSED [ 83%]; ```. so maybe `test_recipe_plotting`?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:41,Testability,test,test,41,"Hm, there’s something messed up with the test runner. It fails these tests:. ```; scanpy/tests/test_embedding_plots.py::test_visium_circles FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_visium_default FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_visium_empty_img_key FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_general FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_external_img FAILED [ 14%]; ...; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-10] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[cell_ranger-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-100-30-False] ERROR [ 30%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variab",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:69,Testability,test,tests,69,"Hm, there’s something messed up with the test runner. It fails these tests:. ```; scanpy/tests/test_embedding_plots.py::test_visium_circles FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_visium_default FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_visium_empty_img_key FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_general FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_external_img FAILED [ 14%]; ...; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-10] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[cell_ranger-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-100-30-False] ERROR [ 30%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variab",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:89,Testability,test,tests,89,"Hm, there’s something messed up with the test runner. It fails these tests:. ```; scanpy/tests/test_embedding_plots.py::test_visium_circles FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_visium_default FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_visium_empty_img_key FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_general FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_external_img FAILED [ 14%]; ...; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-10] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[cell_ranger-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-100-30-False] ERROR [ 30%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variab",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:162,Testability,test,tests,162,"Hm, there’s something messed up with the test runner. It fails these tests:. ```; scanpy/tests/test_embedding_plots.py::test_visium_circles FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_visium_default FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_visium_empty_img_key FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_general FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_external_img FAILED [ 14%]; ...; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-10] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[cell_ranger-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-100-30-False] ERROR [ 30%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variab",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:235,Testability,test,tests,235,"Hm, there’s something messed up with the test runner. It fails these tests:. ```; scanpy/tests/test_embedding_plots.py::test_visium_circles FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_visium_default FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_visium_empty_img_key FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_general FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_external_img FAILED [ 14%]; ...; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-10] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[cell_ranger-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-100-30-False] ERROR [ 30%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variab",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:314,Testability,test,tests,314,"Hm, there’s something messed up with the test runner. It fails these tests:. ```; scanpy/tests/test_embedding_plots.py::test_visium_circles FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_visium_default FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_visium_empty_img_key FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_general FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_external_img FAILED [ 14%]; ...; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-10] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[cell_ranger-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-100-30-False] ERROR [ 30%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variab",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:388,Testability,test,tests,388,"Hm, there’s something messed up with the test runner. It fails these tests:. ```; scanpy/tests/test_embedding_plots.py::test_visium_circles FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_visium_default FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_visium_empty_img_key FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_general FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_external_img FAILED [ 14%]; ...; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-10] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[cell_ranger-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-100-30-False] ERROR [ 30%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variab",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:472,Testability,test,tests,472,"Hm, there’s something messed up with the test runner. It fails these tests:. ```; scanpy/tests/test_embedding_plots.py::test_visium_circles FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_visium_default FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_visium_empty_img_key FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_general FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_external_img FAILED [ 14%]; ...; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-10] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[cell_ranger-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-100-30-False] ERROR [ 30%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variab",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:582,Testability,test,tests,582,"Hm, there’s something messed up with the test runner. It fails these tests:. ```; scanpy/tests/test_embedding_plots.py::test_visium_circles FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_visium_default FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_visium_empty_img_key FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_general FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_external_img FAILED [ 14%]; ...; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-10] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[cell_ranger-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-100-30-False] ERROR [ 30%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variab",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:690,Testability,test,tests,690,"Hm, there’s something messed up with the test runner. It fails these tests:. ```; scanpy/tests/test_embedding_plots.py::test_visium_circles FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_visium_default FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_visium_empty_img_key FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_general FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_external_img FAILED [ 14%]; ...; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-10] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[cell_ranger-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-100-30-False] ERROR [ 30%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variab",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:805,Testability,test,tests,805,"Hm, there’s something messed up with the test runner. It fails these tests:. ```; scanpy/tests/test_embedding_plots.py::test_visium_circles FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_visium_default FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_visium_empty_img_key FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_general FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_external_img FAILED [ 14%]; ...; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-10] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[cell_ranger-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-100-30-False] ERROR [ 30%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variab",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:951,Testability,test,tests,951,"Hm, there’s something messed up with the test runner. It fails these tests:. ```; scanpy/tests/test_embedding_plots.py::test_visium_circles FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_visium_default FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_visium_empty_img_key FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_general FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_external_img FAILED [ 14%]; ...; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-10] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[cell_ranger-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-100-30-False] ERROR [ 30%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variab",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:1098,Testability,test,tests,1098,fails these tests:. ```; scanpy/tests/test_embedding_plots.py::test_visium_circles FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_visium_default FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_visium_empty_img_key FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_general FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_external_img FAILED [ 14%]; ...; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-10] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[cell_ranger-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-100-30-False] ERROR [ 30%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:1246,Testability,test,tests,1246,default FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_visium_empty_img_key FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_general FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_external_img FAILED [ 14%]; ...; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-10] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[cell_ranger-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-100-30-False] ERROR [ 30%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residual,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:1392,Testability,test,tests,1392,atial_general FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_external_img FAILED [ 14%]; ...; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-10] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[cell_ranger-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-100-30-False] ERROR [ 30%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:1539,Testability,test,tests,1539,_genes.py::test_highly_variable_genes_keep_layer[seurat-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-10] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[cell_ranger-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-100-30-False] ERROR [ 30%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:1684,Testability,test,tests,1684,s_keep_layer[seurat-10] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[cell_ranger-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-100-30-False] ERROR [ 30%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:1830,Testability,test,tests,1830,[ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-100-30-False] ERROR [ 30%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:1977,Testability,test,tests,1977,[ 30%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:2125,Testability,test,tests,2125, 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residual,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:2271,Testability,test,tests,2271,[ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:2418,Testability,test,tests,2418,[ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:2563,Testability,test,tests,2563, [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:2709,Testability,test,tests,2709,[ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:2856,Testability,test,tests,2856,[ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:3004,Testability,test,tests,3004, 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:3150,Testability,test,tests,3150,[ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-Fals,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:3297,Testability,test,tests,3297,[ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:3442,Testability,test,tests,3442, [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:3588,Testability,test,tests,3588,[ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:3724,Testability,test,tests,3724,RROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; s,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:3861,Testability,test,tests,3861,one-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_norma,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:3997,Testability,test,tests,3997,-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_nor,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:4134,Testability,test,tests,4134,csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_res,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:4247,Testability,test,tests,4247,earson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_highly_variable_genes.py::test_higly_variable_gene,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:4359,Testability,test,tests,4359,s.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_highly_variable_genes.py::test_higly_variable_genes_compare_to_seurat FAILED [ 33%]; ...; scanpy/tests/test_highly_variable_genes.py::test_filter_genes_dispersion,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:4471,Testability,test,tests,4471,y/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_highly_variable_genes.py::test_higly_variable_genes_compare_to_seurat FAILED [ 33%]; ...; scanpy/tests/test_highly_variable_genes.py::test_filter_genes_dispersion_compare_to_seurat FAILED [ 34%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_batches,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:4583,Testability,test,tests,4583,-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_highly_variable_genes.py::test_higly_variable_genes_compare_to_seurat FAILED [ 33%]; ...; scanpy/tests/test_highly_variable_genes.py::test_filter_genes_dispersion_compare_to_seurat FAILED [ 34%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_batches FAILED [ 34%]; ```. and then gets stuck after. ```; scanpy/tests/test_preprocessing.py::test_scale_array[<lambd,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:4695,Testability,test,tests,4695,duals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_highly_variable_genes.py::test_higly_variable_genes_compare_to_seurat FAILED [ 33%]; ...; scanpy/tests/test_highly_variable_genes.py::test_filter_genes_dispersion_compare_to_seurat FAILED [ 34%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_batches FAILED [ 34%]; ```. and then gets stuck after. ```; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-False] PASSED [ 83%]; scan,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:4810,Testability,test,tests,4810,able_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_highly_variable_genes.py::test_higly_variable_genes_compare_to_seurat FAILED [ 33%]; ...; scanpy/tests/test_highly_variable_genes.py::test_filter_genes_dispersion_compare_to_seurat FAILED [ 34%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_batches FAILED [ 34%]; ```. and then gets stuck after. ```; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-False] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csr_matrix-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.p,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:4925,Testability,test,tests,4925,s.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_highly_variable_genes.py::test_higly_variable_genes_compare_to_seurat FAILED [ 33%]; ...; scanpy/tests/test_highly_variable_genes.py::test_filter_genes_dispersion_compare_to_seurat FAILED [ 34%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_batches FAILED [ 34%]; ```. and then gets stuck after. ```; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-False] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csr_matrix-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csr_matrix-False] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csc_matri,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:5040,Testability,test,tests,5040,_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_highly_variable_genes.py::test_higly_variable_genes_compare_to_seurat FAILED [ 33%]; ...; scanpy/tests/test_highly_variable_genes.py::test_filter_genes_dispersion_compare_to_seurat FAILED [ 34%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_batches FAILED [ 34%]; ```. and then gets stuck after. ```; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-False] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csr_matrix-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csr_matrix-False] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csc_matrix-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csc_matrix-False] PASSED [ 83%]; ```. s,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:5155,Testability,test,tests,5155,highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_highly_variable_genes.py::test_higly_variable_genes_compare_to_seurat FAILED [ 33%]; ...; scanpy/tests/test_highly_variable_genes.py::test_filter_genes_dispersion_compare_to_seurat FAILED [ 34%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_batches FAILED [ 34%]; ```. and then gets stuck after. ```; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-False] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csr_matrix-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csr_matrix-False] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csc_matrix-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csc_matrix-False] PASSED [ 83%]; ```. so maybe `test_recipe_plotting`?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:5263,Testability,test,tests,5263,highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_highly_variable_genes.py::test_higly_variable_genes_compare_to_seurat FAILED [ 33%]; ...; scanpy/tests/test_highly_variable_genes.py::test_filter_genes_dispersion_compare_to_seurat FAILED [ 34%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_batches FAILED [ 34%]; ```. and then gets stuck after. ```; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-False] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csr_matrix-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csr_matrix-False] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csc_matrix-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csc_matrix-False] PASSED [ 83%]; ```. so maybe `test_recipe_plotting`?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:5369,Testability,test,tests,5369,highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_highly_variable_genes.py::test_higly_variable_genes_compare_to_seurat FAILED [ 33%]; ...; scanpy/tests/test_highly_variable_genes.py::test_filter_genes_dispersion_compare_to_seurat FAILED [ 34%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_batches FAILED [ 34%]; ```. and then gets stuck after. ```; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-False] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csr_matrix-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csr_matrix-False] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csc_matrix-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csc_matrix-False] PASSED [ 83%]; ```. so maybe `test_recipe_plotting`?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:5500,Testability,test,tests,5500,highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_highly_variable_genes.py::test_higly_variable_genes_compare_to_seurat FAILED [ 33%]; ...; scanpy/tests/test_highly_variable_genes.py::test_filter_genes_dispersion_compare_to_seurat FAILED [ 34%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_batches FAILED [ 34%]; ```. and then gets stuck after. ```; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-False] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csr_matrix-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csr_matrix-False] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csc_matrix-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csc_matrix-False] PASSED [ 83%]; ```. so maybe `test_recipe_plotting`?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:5583,Testability,test,tests,5583,highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_highly_variable_genes.py::test_higly_variable_genes_compare_to_seurat FAILED [ 33%]; ...; scanpy/tests/test_highly_variable_genes.py::test_filter_genes_dispersion_compare_to_seurat FAILED [ 34%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_batches FAILED [ 34%]; ```. and then gets stuck after. ```; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-False] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csr_matrix-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csr_matrix-False] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csc_matrix-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csc_matrix-False] PASSED [ 83%]; ```. so maybe `test_recipe_plotting`?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:5667,Testability,test,tests,5667,highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_highly_variable_genes.py::test_higly_variable_genes_compare_to_seurat FAILED [ 33%]; ...; scanpy/tests/test_highly_variable_genes.py::test_filter_genes_dispersion_compare_to_seurat FAILED [ 34%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_batches FAILED [ 34%]; ```. and then gets stuck after. ```; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-False] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csr_matrix-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csr_matrix-False] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csc_matrix-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csc_matrix-False] PASSED [ 83%]; ```. so maybe `test_recipe_plotting`?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:5752,Testability,test,tests,5752,highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_highly_variable_genes.py::test_higly_variable_genes_compare_to_seurat FAILED [ 33%]; ...; scanpy/tests/test_highly_variable_genes.py::test_filter_genes_dispersion_compare_to_seurat FAILED [ 34%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_batches FAILED [ 34%]; ```. and then gets stuck after. ```; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-False] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csr_matrix-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csr_matrix-False] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csc_matrix-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csc_matrix-False] PASSED [ 83%]; ```. so maybe `test_recipe_plotting`?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:5838,Testability,test,tests,5838,highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_highly_variable_genes.py::test_higly_variable_genes_compare_to_seurat FAILED [ 33%]; ...; scanpy/tests/test_highly_variable_genes.py::test_filter_genes_dispersion_compare_to_seurat FAILED [ 34%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_batches FAILED [ 34%]; ```. and then gets stuck after. ```; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-False] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csr_matrix-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csr_matrix-False] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csc_matrix-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csc_matrix-False] PASSED [ 83%]; ```. so maybe `test_recipe_plotting`?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:5923,Testability,test,tests,5923,highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_highly_variable_genes.py::test_higly_variable_genes_compare_to_seurat FAILED [ 33%]; ...; scanpy/tests/test_highly_variable_genes.py::test_filter_genes_dispersion_compare_to_seurat FAILED [ 34%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_batches FAILED [ 34%]; ```. and then gets stuck after. ```; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-False] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csr_matrix-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csr_matrix-False] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csc_matrix-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csc_matrix-False] PASSED [ 83%]; ```. so maybe `test_recipe_plotting`?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316
https://github.com/scverse/scanpy/pull/2720#issuecomment-1785549678:438,Deployability,release,releases,438,"> Can we keep the docs on what exactly is happening + how to troubleshoot somewhere in this doc? This means things like: How to tag + build locally, twine check, list contents of distributed file etc. Sure, as we agreed on in person, I’ll just add a section to the end of the document.; If the build process or package structure aren’t touched, doing things manually isn’t necessary. > We should also automate some checks to avoid broken releases. As we agreed in person: Let’s postpone this. E.g. don't allow this except on specific branches + probably turn on merge queue so we know only commits that pass tests + doc builds get to those branches. This PR automatically does `twine check`, which is enough improvement over “trust the person doing the release to do that” to be worth the change, even if it wasn’t for the added convenience!. /edit: all addressed",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2720#issuecomment-1785549678
https://github.com/scverse/scanpy/pull/2720#issuecomment-1785549678:753,Deployability,release,release,753,"> Can we keep the docs on what exactly is happening + how to troubleshoot somewhere in this doc? This means things like: How to tag + build locally, twine check, list contents of distributed file etc. Sure, as we agreed on in person, I’ll just add a section to the end of the document.; If the build process or package structure aren’t touched, doing things manually isn’t necessary. > We should also automate some checks to avoid broken releases. As we agreed in person: Let’s postpone this. E.g. don't allow this except on specific branches + probably turn on merge queue so we know only commits that pass tests + doc builds get to those branches. This PR automatically does `twine check`, which is enough improvement over “trust the person doing the release to do that” to be worth the change, even if it wasn’t for the added convenience!. /edit: all addressed",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2720#issuecomment-1785549678
https://github.com/scverse/scanpy/pull/2720#issuecomment-1785549678:568,Performance,queue,queue,568,"> Can we keep the docs on what exactly is happening + how to troubleshoot somewhere in this doc? This means things like: How to tag + build locally, twine check, list contents of distributed file etc. Sure, as we agreed on in person, I’ll just add a section to the end of the document.; If the build process or package structure aren’t touched, doing things manually isn’t necessary. > We should also automate some checks to avoid broken releases. As we agreed in person: Let’s postpone this. E.g. don't allow this except on specific branches + probably turn on merge queue so we know only commits that pass tests + doc builds get to those branches. This PR automatically does `twine check`, which is enough improvement over “trust the person doing the release to do that” to be worth the change, even if it wasn’t for the added convenience!. /edit: all addressed",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2720#issuecomment-1785549678
https://github.com/scverse/scanpy/pull/2720#issuecomment-1785549678:425,Safety,avoid,avoid,425,"> Can we keep the docs on what exactly is happening + how to troubleshoot somewhere in this doc? This means things like: How to tag + build locally, twine check, list contents of distributed file etc. Sure, as we agreed on in person, I’ll just add a section to the end of the document.; If the build process or package structure aren’t touched, doing things manually isn’t necessary. > We should also automate some checks to avoid broken releases. As we agreed in person: Let’s postpone this. E.g. don't allow this except on specific branches + probably turn on merge queue so we know only commits that pass tests + doc builds get to those branches. This PR automatically does `twine check`, which is enough improvement over “trust the person doing the release to do that” to be worth the change, even if it wasn’t for the added convenience!. /edit: all addressed",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2720#issuecomment-1785549678
https://github.com/scverse/scanpy/pull/2720#issuecomment-1785549678:608,Testability,test,tests,608,"> Can we keep the docs on what exactly is happening + how to troubleshoot somewhere in this doc? This means things like: How to tag + build locally, twine check, list contents of distributed file etc. Sure, as we agreed on in person, I’ll just add a section to the end of the document.; If the build process or package structure aren’t touched, doing things manually isn’t necessary. > We should also automate some checks to avoid broken releases. As we agreed in person: Let’s postpone this. E.g. don't allow this except on specific branches + probably turn on merge queue so we know only commits that pass tests + doc builds get to those branches. This PR automatically does `twine check`, which is enough improvement over “trust the person doing the release to do that” to be worth the change, even if it wasn’t for the added convenience!. /edit: all addressed",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2720#issuecomment-1785549678
https://github.com/scverse/scanpy/pull/2721#issuecomment-1785251436:331,Availability,error,error-reference,331,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2721?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@05405f1`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2721 +/- ##; ========================================; Coverage ? 72.03% ; ========================================; Files ? 104 ; Lines ? 11659 ; Branches ? 0 ; ========================================; Hits ? 8398 ; Misses ? 3261 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2721#issuecomment-1785251436
https://github.com/scverse/scanpy/pull/2721#issuecomment-1785251436:279,Usability,learn,learn,279,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2721?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@05405f1`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2721 +/- ##; ========================================; Coverage ? 72.03% ; ========================================; Files ? 104 ; Lines ? 11659 ; Branches ? 0 ; ========================================; Hits ? 8398 ; Misses ? 3261 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2721#issuecomment-1785251436
https://github.com/scverse/scanpy/pull/2722#issuecomment-1787308099:331,Availability,error,error-reference,331,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2722?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@4936b7e`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2722 +/- ##; ========================================; Coverage ? 72.03% ; ========================================; Files ? 104 ; Lines ? 11659 ; Branches ? 0 ; ========================================; Hits ? 8398 ; Misses ? 3261 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2722#issuecomment-1787308099
https://github.com/scverse/scanpy/pull/2722#issuecomment-1787308099:279,Usability,learn,learn,279,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2722?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@4936b7e`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2722 +/- ##; ========================================; Coverage ? 72.03% ; ========================================; Files ? 104 ; Lines ? 11659 ; Branches ? 0 ; ========================================; Hits ? 8398 ; Misses ? 3261 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2722#issuecomment-1787308099
https://github.com/scverse/scanpy/pull/2723#issuecomment-1787464686:234,Testability,test,tests,234,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2723?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Comparison is base [(`42143d8`)](https://app.codecov.io/gh/scverse/scanpy/commit/42143d88a0d499130fac8e5ca60eef0c19163734?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 73.19% compared to head [(`bd47788`)](https://app.codecov.io/gh/scverse/scanpy/pull/2723?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 74.07%. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## add-scrublet #2723 +/- ##; ================================================; + Coverage 73.19% 74.07% +0.88% ; ================================================; Files 116 115 -1 ; Lines 12634 12613 -21 ; ================================================; + Hits 9247 9343 +96 ; + Misses 3387 3270 -117 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2723?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/neighbors/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2723?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L25laWdoYm9ycy9fX2luaXRfXy5weQ==) | `80.75% <100.00%> (+3.28%)` | :arrow_up: |; | [scanpy/neighbors/\_common.py](https://app.codecov.io/gh/scverse/scanpy/pull/2723?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L25laWdoYm9ycy9fY29tbW9uLnB5) | `64.91% <100.00%> (ø)` | |; | [scanpy/neighbors/\_types.py](https://app.codecov.io/gh/scverse/scanpy/pull/2723?src=pr&el=tree&utm_medium=,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2723#issuecomment-1787464686
https://github.com/scverse/scanpy/pull/2727#issuecomment-1787571772:331,Availability,error,error-reference,331,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2727?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@0b624b0`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2727 +/- ##; ========================================; Coverage ? 72.00% ; ========================================; Files ? 103 ; Lines ? 11641 ; Branches ? 0 ; ========================================; Hits ? 8382 ; Misses ? 3259 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2727#issuecomment-1787571772
https://github.com/scverse/scanpy/pull/2727#issuecomment-1787571772:279,Usability,learn,learn,279,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2727?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@0b624b0`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2727 +/- ##; ========================================; Coverage ? 72.00% ; ========================================; Files ? 103 ; Lines ? 11641 ; Branches ? 0 ; ========================================; Hits ? 8382 ; Misses ? 3259 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2727#issuecomment-1787571772
https://github.com/scverse/scanpy/pull/2728#issuecomment-1787613419:331,Availability,error,error-reference,331,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2728?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@1083b36`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2728 +/- ##; ========================================; Coverage ? 72.00% ; ========================================; Files ? 103 ; Lines ? 11641 ; Branches ? 0 ; ========================================; Hits ? 8382 ; Misses ? 3259 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2728#issuecomment-1787613419
https://github.com/scverse/scanpy/pull/2728#issuecomment-1787613419:279,Usability,learn,learn,279,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2728?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@1083b36`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2728 +/- ##; ========================================; Coverage ? 72.00% ; ========================================; Files ? 103 ; Lines ? 11641 ; Branches ? 0 ; ========================================; Hits ? 8382 ; Misses ? 3259 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2728#issuecomment-1787613419
https://github.com/scverse/scanpy/issues/2729#issuecomment-1934516029:482,Integrability,depend,dependencies,482,"The problem referenced above is that we want to skip some doctests when using pandas<2 since outputs changed slightly. doctestplus doesn't currently solve that problem, since we use `doctest-requires` to skip a block when that block exists in a docstring. `doctest-requires` blocks only work in `.rst` files. For code files there's only the option to skip the whole file via `__doctest_requires__`. https://github.com/scientific-python/pytest-doctestplus?tab=readme-ov-file#doctest-dependencies. I think we can request this feature, but it doesn't exist now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2729#issuecomment-1934516029
https://github.com/scverse/scanpy/pull/2731#issuecomment-1798081456:170,Testability,test,test,170,"Hi! Can you explain a bit what use cases this helps people with? When would one want to set this to True?. Once we have a good example, you can use that to write a small test that checks if it works as intended.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2731#issuecomment-1798081456
https://github.com/scverse/scanpy/pull/2731#issuecomment-1800547868:104,Modifiability,variab,variable,104,"Thanks for implementing this! I used it to regress out total counts and cell cycle scores before highly variable gene selection, and it worked well. The clusters are better separated without artifacts, unlike running regressing function after HVG.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2731#issuecomment-1800547868
https://github.com/scverse/scanpy/pull/2731#issuecomment-1803331795:101,Testability,test,test,101,"> Is this enough to get started?. For sure, thank you for the context!. Is it possible to add a unit test that checks that with this set to `True`, clusters are better separated?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2731#issuecomment-1803331795
https://github.com/scverse/scanpy/pull/2732#issuecomment-1795950835:157,Deployability,update,update,157,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 b23229f9bfc95ff90a5d6393b4d53d062190d5bb; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2732: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2732-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2732 on branch 1.9.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2732#issuecomment-1795950835
https://github.com/scverse/scanpy/pull/2732#issuecomment-1795950835:913,Deployability,continuous,continuous,913,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 b23229f9bfc95ff90a5d6393b4d53d062190d5bb; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2732: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2732-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2732 on branch 1.9.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2732#issuecomment-1795950835
https://github.com/scverse/scanpy/pull/2732#issuecomment-1795950835:924,Deployability,integrat,integration,924,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 b23229f9bfc95ff90a5d6393b4d53d062190d5bb; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2732: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2732-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2732 on branch 1.9.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2732#issuecomment-1795950835
https://github.com/scverse/scanpy/pull/2732#issuecomment-1795950835:924,Integrability,integrat,integration,924,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 b23229f9bfc95ff90a5d6393b4d53d062190d5bb; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2732: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2732-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2732 on branch 1.9.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2732#issuecomment-1795950835
https://github.com/scverse/scanpy/pull/2732#issuecomment-1795950835:899,Testability,test,tested,899,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 b23229f9bfc95ff90a5d6393b4d53d062190d5bb; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2732: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2732-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2732 on branch 1.9.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2732#issuecomment-1795950835
https://github.com/scverse/scanpy/pull/2733#issuecomment-1798483923:51,Integrability,depend,dependencies,51,@ivirshup I assume you caught that in your minimal-dependencies branch already? Maybe it’s a good time to push it!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2733#issuecomment-1798483923
https://github.com/scverse/scanpy/pull/2733#issuecomment-1799255825:21,Deployability,release,release,21,Do you want to add a release note entry?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2733#issuecomment-1799255825
https://github.com/scverse/scanpy/pull/2733#issuecomment-1799724990:23,Deployability,release,release,23,> Do you want to add a release note entry?. Added. I believe I got the format right.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2733#issuecomment-1799724990
https://github.com/scverse/scanpy/pull/2738#issuecomment-1801509928:331,Availability,error,error-reference,331,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2738?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@d1fe8da`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2738 +/- ##; ========================================; Coverage ? 72.00% ; ========================================; Files ? 103 ; Lines ? 11642 ; Branches ? 0 ; ========================================; Hits ? 8383 ; Misses ? 3259 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2738#issuecomment-1801509928
https://github.com/scverse/scanpy/pull/2738#issuecomment-1801509928:279,Usability,learn,learn,279,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2738?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@d1fe8da`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2738 +/- ##; ========================================; Coverage ? 72.00% ; ========================================; Files ? 103 ; Lines ? 11642 ; Branches ? 0 ; ========================================; Hits ? 8383 ; Misses ? 3259 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2738#issuecomment-1801509928
https://github.com/scverse/scanpy/pull/2739#issuecomment-1803766618:94,Testability,log,logs,94,test_pca failing [here](https://dev.azure.com/scverse/scanpy/_build/results?buildId=4765&view=logs&j=50ff7263-9206-5a84-1219-938c9ee7fde7&t=2e49bd34-47bd-5a56-3183-6247e293d44d&l=804) and [here](https://dev.azure.com/scverse/scanpy/_build/results?buildId=4765&view=logs&j=50ff7263-9206-5a84-1219-938c9ee7fde7&t=2e49bd34-47bd-5a56-3183-6247e293d44d&l=798)?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2739#issuecomment-1803766618
https://github.com/scverse/scanpy/pull/2739#issuecomment-1803766618:265,Testability,log,logs,265,test_pca failing [here](https://dev.azure.com/scverse/scanpy/_build/results?buildId=4765&view=logs&j=50ff7263-9206-5a84-1219-938c9ee7fde7&t=2e49bd34-47bd-5a56-3183-6247e293d44d&l=804) and [here](https://dev.azure.com/scverse/scanpy/_build/results?buildId=4765&view=logs&j=50ff7263-9206-5a84-1219-938c9ee7fde7&t=2e49bd34-47bd-5a56-3183-6247e293d44d&l=798)?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2739#issuecomment-1803766618
https://github.com/scverse/scanpy/pull/2739#issuecomment-1803777453:296,Availability,error,error,296,"To see tracebacks, you need to scroll up from the end past the enormous [warnings list](https://dev.azure.com/scverse/scanpy/_build/results?buildId=4765&view=logs&j=50ff7263-9206-5a84-1219-938c9ee7fde7&t=2e49bd34-47bd-5a56-3183-6247e293d44d&l=1951) (I’m working on that), then you see the actual error. ```pytb; E UserWarning: The problem size 5 minus the constraints size 0 is too small relative to the block size 4. Using a dense eigensolver instead of LOBPCG iterations.No output of the history of the iterations. /opt/hostedtoolcache/Python/3.11.6/x64/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/lobpcg/lobpcg.py:493: UserWarning; ```. This test has stared to become flaky some time ago, needs some investigation to make this work reliably again.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2739#issuecomment-1803777453
https://github.com/scverse/scanpy/pull/2739#issuecomment-1803777453:747,Availability,reliab,reliably,747,"To see tracebacks, you need to scroll up from the end past the enormous [warnings list](https://dev.azure.com/scverse/scanpy/_build/results?buildId=4765&view=logs&j=50ff7263-9206-5a84-1219-938c9ee7fde7&t=2e49bd34-47bd-5a56-3183-6247e293d44d&l=1951) (I’m working on that), then you see the actual error. ```pytb; E UserWarning: The problem size 5 minus the constraints size 0 is too small relative to the block size 4. Using a dense eigensolver instead of LOBPCG iterations.No output of the history of the iterations. /opt/hostedtoolcache/Python/3.11.6/x64/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/lobpcg/lobpcg.py:493: UserWarning; ```. This test has stared to become flaky some time ago, needs some investigation to make this work reliably again.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2739#issuecomment-1803777453
https://github.com/scverse/scanpy/pull/2739#issuecomment-1803777453:158,Testability,log,logs,158,"To see tracebacks, you need to scroll up from the end past the enormous [warnings list](https://dev.azure.com/scverse/scanpy/_build/results?buildId=4765&view=logs&j=50ff7263-9206-5a84-1219-938c9ee7fde7&t=2e49bd34-47bd-5a56-3183-6247e293d44d&l=1951) (I’m working on that), then you see the actual error. ```pytb; E UserWarning: The problem size 5 minus the constraints size 0 is too small relative to the block size 4. Using a dense eigensolver instead of LOBPCG iterations.No output of the history of the iterations. /opt/hostedtoolcache/Python/3.11.6/x64/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/lobpcg/lobpcg.py:493: UserWarning; ```. This test has stared to become flaky some time ago, needs some investigation to make this work reliably again.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2739#issuecomment-1803777453
https://github.com/scverse/scanpy/pull/2739#issuecomment-1803777453:657,Testability,test,test,657,"To see tracebacks, you need to scroll up from the end past the enormous [warnings list](https://dev.azure.com/scverse/scanpy/_build/results?buildId=4765&view=logs&j=50ff7263-9206-5a84-1219-938c9ee7fde7&t=2e49bd34-47bd-5a56-3183-6247e293d44d&l=1951) (I’m working on that), then you see the actual error. ```pytb; E UserWarning: The problem size 5 minus the constraints size 0 is too small relative to the block size 4. Using a dense eigensolver instead of LOBPCG iterations.No output of the history of the iterations. /opt/hostedtoolcache/Python/3.11.6/x64/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/lobpcg/lobpcg.py:493: UserWarning; ```. This test has stared to become flaky some time ago, needs some investigation to make this work reliably again.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2739#issuecomment-1803777453
https://github.com/scverse/scanpy/pull/2739#issuecomment-1803816341:79,Deployability,update,update,79,Yeah noted there is an issue with scipy... Not related to this the single-line update?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2739#issuecomment-1803816341
https://github.com/scverse/scanpy/pull/2742#issuecomment-1812943870:136,Modifiability,layers,layers,136,"Reviewed harmonization paying attention to some more details. What do you think of using the `|` separator to describe `adata.X | adata.layers[layer]` e.g. [here](https://icb-scanpy--2742.com.readthedocs.build/en/2742/generated/scanpy.pp.regress_out.html)?. Some things causing some sort of heterogeneity and are NOT taken care of here:; - the inconsistent and mixed use of `inplace` and `copy` (effort: lot of work); - some inconsistent use of `key_added` & flavours thereof, which affect the return section (effort: medium amount of work). What is also not taken care of here:; - Other small things, such as [ingest](https://scanpy.readthedocs.io/en/latest/generated/scanpy.tl.ingest.html) not having a `return_joint` argument although this is mentioned in its doc. Might raise smaller issues in the future for these specific things rather than bloating this purpose-driven PR up?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2742#issuecomment-1812943870
https://github.com/scverse/scanpy/pull/2742#issuecomment-1814024532:73,Modifiability,layers,layers,73,"> What do you think of using the | separator to describe adata.X | adata.layers[layer] e.g. [here](https://icb-scanpy--2742.com.readthedocs.build/en/2742/generated/scanpy.pp.regress_out.html)?. works for me!. > the inconsistent and mixed use of inplace and copy (effort: lot of work). yeah, we definitely need to do this … in a dedicated PR. > Might raise smaller issues in the future for these specific things rather than bloating this purpose-driven PR up?. Yeah! please add them here: https://github.com/orgs/scverse/projects/18/views/1",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2742#issuecomment-1814024532
https://github.com/scverse/scanpy/pull/2742#issuecomment-1814222794:32,Availability,error,errors,32,"No, those “invalid instruction” errors pop up sometimes. I think they’re caused by some dependency being compiled for an instruction set that not all GitHub runners support. Ways to deal with it:. 1. just restart until it works (annoying, but not much work); 2. figure out broken dependency, then; 1. if the wheel on PyPI is broken, raise an issue upstream; 2. if we compile it in the runner ourselves, set a compile flag to make it only use instructions that are compatible with all runners (i.e. not `-m arch=native` but select [an older architecture](https://en.wikipedia.org/wiki/X86-64#Microarchitecture_levels))",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2742#issuecomment-1814222794
https://github.com/scverse/scanpy/pull/2742#issuecomment-1814222794:88,Integrability,depend,dependency,88,"No, those “invalid instruction” errors pop up sometimes. I think they’re caused by some dependency being compiled for an instruction set that not all GitHub runners support. Ways to deal with it:. 1. just restart until it works (annoying, but not much work); 2. figure out broken dependency, then; 1. if the wheel on PyPI is broken, raise an issue upstream; 2. if we compile it in the runner ourselves, set a compile flag to make it only use instructions that are compatible with all runners (i.e. not `-m arch=native` but select [an older architecture](https://en.wikipedia.org/wiki/X86-64#Microarchitecture_levels))",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2742#issuecomment-1814222794
https://github.com/scverse/scanpy/pull/2742#issuecomment-1814222794:280,Integrability,depend,dependency,280,"No, those “invalid instruction” errors pop up sometimes. I think they’re caused by some dependency being compiled for an instruction set that not all GitHub runners support. Ways to deal with it:. 1. just restart until it works (annoying, but not much work); 2. figure out broken dependency, then; 1. if the wheel on PyPI is broken, raise an issue upstream; 2. if we compile it in the runner ourselves, set a compile flag to make it only use instructions that are compatible with all runners (i.e. not `-m arch=native` but select [an older architecture](https://en.wikipedia.org/wiki/X86-64#Microarchitecture_levels))",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2742#issuecomment-1814222794
https://github.com/scverse/scanpy/pull/2742#issuecomment-1814325890:113,Safety,safe,safer,113,"Hm. Are all functions that you edit in 1.9.6? Then we could set the milestone to 1.9.7. If you’re not sure, it’s safer to set it to 1.10.0",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2742#issuecomment-1814325890
https://github.com/scverse/scanpy/pull/2742#issuecomment-1814510857:122,Safety,safe,safer,122,"> Hm. Are all functions that you edit in 1.9.6? Then we could set the milestone to 1.9.7.; > ; > If you’re not sure, it’s safer to set it to 1.10.0. I think `sc.pp.normalize_per_cell` is not in the API section of the doc of 1.9.6 (intentionally?).; Other functions I modified are listed there as far as I checked.... You have `pp` or `tl` methods in mind which could conflict here?; Not 100% sure I don’t miss anything, so can add 1.10.0 👍",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2742#issuecomment-1814510857
https://github.com/scverse/scanpy/pull/2743#issuecomment-1805786269:34,Deployability,release,released,34,"Great! And indeed, it hasn’t been released yet, so if you don’t want one, we don’t need a release note.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2743#issuecomment-1805786269
https://github.com/scverse/scanpy/pull/2743#issuecomment-1805786269:90,Deployability,release,release,90,"Great! And indeed, it hasn’t been released yet, so if you don’t want one, we don’t need a release note.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2743#issuecomment-1805786269
https://github.com/scverse/scanpy/pull/2751#issuecomment-1808250177:331,Availability,error,error-reference,331,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2751?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@ec4d79f`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2751 +/- ##; ========================================; Coverage ? 71.87% ; ========================================; Files ? 103 ; Lines ? 11635 ; Branches ? 0 ; ========================================; Hits ? 8363 ; Misses ? 3272 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2751#issuecomment-1808250177
https://github.com/scverse/scanpy/pull/2751#issuecomment-1808250177:279,Usability,learn,learn,279,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2751?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@ec4d79f`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2751 +/- ##; ========================================; Coverage ? 71.87% ; ========================================; Files ? 103 ; Lines ? 11635 ; Branches ? 0 ; ========================================; Hits ? 8363 ; Misses ? 3272 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2751#issuecomment-1808250177
https://github.com/scverse/scanpy/pull/2752#issuecomment-1808445091:331,Availability,error,error-reference,331,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2752?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@295d889`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2752 +/- ##; ========================================; Coverage ? 72.10% ; ========================================; Files ? 103 ; Lines ? 11635 ; Branches ? 0 ; ========================================; Hits ? 8389 ; Misses ? 3246 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2752#issuecomment-1808445091
https://github.com/scverse/scanpy/pull/2752#issuecomment-1808445091:279,Usability,learn,learn,279,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2752?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@295d889`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2752 +/- ##; ========================================; Coverage ? 72.10% ; ========================================; Files ? 103 ; Lines ? 11635 ; Branches ? 0 ; ========================================; Hits ? 8389 ; Misses ? 3246 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2752#issuecomment-1808445091
https://github.com/scverse/scanpy/pull/2753#issuecomment-1809942763:157,Deployability,update,update,157,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 05dcf68f32ce255447ea804de55babefb3c47c92; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2753: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2753-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2753 on branch 1.9.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2753#issuecomment-1809942763
https://github.com/scverse/scanpy/pull/2753#issuecomment-1809942763:913,Deployability,continuous,continuous,913,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 05dcf68f32ce255447ea804de55babefb3c47c92; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2753: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2753-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2753 on branch 1.9.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2753#issuecomment-1809942763
https://github.com/scverse/scanpy/pull/2753#issuecomment-1809942763:924,Deployability,integrat,integration,924,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 05dcf68f32ce255447ea804de55babefb3c47c92; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2753: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2753-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2753 on branch 1.9.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2753#issuecomment-1809942763
https://github.com/scverse/scanpy/pull/2753#issuecomment-1809942763:924,Integrability,integrat,integration,924,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 05dcf68f32ce255447ea804de55babefb3c47c92; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2753: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2753-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2753 on branch 1.9.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2753#issuecomment-1809942763
https://github.com/scverse/scanpy/pull/2753#issuecomment-1809942763:899,Testability,test,tested,899,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 05dcf68f32ce255447ea804de55babefb3c47c92; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2753: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2753-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2753 on branch 1.9.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2753#issuecomment-1809942763
https://github.com/scverse/scanpy/issues/2754#issuecomment-1817861190:710,Integrability,Message,Message,710,"Thanks for your answer！; I will spend time finding where the problem is.; ^-^. ---Original---; From: ""Philipp ***@***.***&gt;; Date: Thu, Nov 16, 2023 16:49 PM; To: ***@***.***&gt;;; Cc: ***@***.******@***.***&gt;;; Subject: Re: [scverse/scanpy] sc.pp.filter_genes runs out of memory (Issue#2754). ; Seems like you ran out of memory. Maybe you only have enough memory to run store your data once, but for calculating this, a second copy has to be made.; ; If you think this is a bug and scanpy uses much more memory than it should here, please tell us and we will reopen this issue.; ; —; Reply to this email directly, view it on GitHub, or unsubscribe.; You are receiving this because you authored the thread.Message ID: ***@***.***&gt;",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2754#issuecomment-1817861190
https://github.com/scverse/scanpy/pull/2756#issuecomment-1816509533:137,Performance,perform,performance,137,"@Intron7 this was surprisingly hard to get right. Unfortunately, there are now a few more checks and some `hstack`ing. Do those tank the performance?. /edit: I benchmarked some, this is better than what we had before",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2756#issuecomment-1816509533
https://github.com/scverse/scanpy/pull/2756#issuecomment-1816509533:160,Testability,benchmark,benchmarked,160,"@Intron7 this was surprisingly hard to get right. Unfortunately, there are now a few more checks and some `hstack`ing. Do those tank the performance?. /edit: I benchmarked some, this is better than what we had before",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2756#issuecomment-1816509533
https://github.com/scverse/scanpy/issues/2763#issuecomment-1825412324:325,Modifiability,plugin,plugins,325,"In https://github.com/scverse/scanpy/pull/2220, DocSearch was removed from the `latest` docs. Our current theme would probably support it, so we could re-introduce it (https://github.com/pydata/pydata-sphinx-theme/issues/795). @ivirshup how do I get access to our DocSearch account?. PS: There’s more discussion about search plugins supported by our theme here: https://github.com/pydata/pydata-sphinx-theme/issues/202",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2763#issuecomment-1825412324
https://github.com/scverse/scanpy/issues/2763#issuecomment-1825412324:250,Security,access,access,250,"In https://github.com/scverse/scanpy/pull/2220, DocSearch was removed from the `latest` docs. Our current theme would probably support it, so we could re-introduce it (https://github.com/pydata/pydata-sphinx-theme/issues/795). @ivirshup how do I get access to our DocSearch account?. PS: There’s more discussion about search plugins supported by our theme here: https://github.com/pydata/pydata-sphinx-theme/issues/202",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2763#issuecomment-1825412324
https://github.com/scverse/scanpy/issues/2764#issuecomment-2012543319:122,Integrability,wrap,wrapping,122,"I don't think we're going to get this implemented for sparse dataset per-se, but we have implemented this for dask arrays wrapping the sparse dataset in. * https://github.com/scverse/scanpy/pull/2856",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2764#issuecomment-2012543319
https://github.com/scverse/scanpy/issues/2768#issuecomment-1917783573:223,Availability,down,downsampling,223,"UMAP is a scatterplot, thus the X and Y dimension both carry information, jitter would distort the data (beyond what UMAP already does) ; ; If you're concerned about overplotting, you can try changing the size and alpha or downsampling: ; `sc.pl.umap(adata, size = 5, alpha = 0.5)`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2768#issuecomment-1917783573
https://github.com/scverse/scanpy/pull/2769#issuecomment-1830133314:215,Deployability,Patch,Patch,215,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2769?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `54.23729%` with `27 lines` in your changes are missing coverage. Please review.; > Project coverage is 75.12%. Comparing base [(`6542113`)](https://app.codecov.io/gh/scverse/scanpy/commit/6542113d9e7f6a9e1a287aa940ec5564b60a247d?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`1c4740e`)](https://app.codecov.io/gh/scverse/scanpy/pull/2769?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2769 +/- ##; ==========================================; - Coverage 75.24% 75.12% -0.13% ; ==========================================; Files 116 116 ; Lines 12802 12847 +45 ; ==========================================; + Hits 9633 9651 +18 ; - Misses 3169 3196 +27 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2769?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/plotting/\_anndata.py](https://app.codecov.io/gh/scverse/scanpy/pull/2769?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL19hbm5kYXRhLnB5) | `84.98% <100.00%> (ø)` | |; | [scanpy/plotting/\_docs.py](https://app.codecov.io/gh/scverse/scanpy/pull/2769?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL19kb2NzLnB5) | `100.00% <ø> (ø)` | |; | [scanpy/plotting/\_tools/\_\_init\_\_.py](https://app.codecov.i,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2769#issuecomment-1830133314
https://github.com/scverse/scanpy/pull/2769#issuecomment-1830133314:2235,Testability,test,testing,2235,?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/plotting/\_anndata.py](https://app.codecov.io/gh/scverse/scanpy/pull/2769?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL19hbm5kYXRhLnB5) | `84.98% <100.00%> (ø)` | |; | [scanpy/plotting/\_docs.py](https://app.codecov.io/gh/scverse/scanpy/pull/2769?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL19kb2NzLnB5) | `100.00% <ø> (ø)` | |; | [scanpy/plotting/\_tools/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2769?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL190b29scy9fX2luaXRfXy5weQ==) | `77.28% <ø> (ø)` | |; | [scanpy/testing/\_helpers/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2769?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX2hlbHBlcnMvX19pbml0X18ucHk=) | `100.00% <100.00%> (ø)` | |; | [scanpy/plotting/\_matrixplot.py](https://app.codecov.io/gh/scverse/scanpy/pull/2769?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL19tYXRyaXhwbG90LnB5) | `95.69% <66.66%> (-1.01%)` | :arrow_down: |; | [scanpy/plotting/\_dotplot.py](https://app.codecov.io/gh/scverse/scanpy/pull/2769?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL19kb3RwbG90LnB5) | `91.28% <71.42%> (-0.61%)` | :arrow_down: |; | [scanpy/plotting/\_stacked\_violin.py](https://app.codecov.io/gh/scverse/scanpy/pull/2769?src=pr&el=tree&utm_medium=referral&utm,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2769#issuecomment-1830133314
https://github.com/scverse/scanpy/pull/2771#issuecomment-1898572961:4,Deployability,update,updated,4,"OK, updated this so it follows the decision implemented in #1244",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2771#issuecomment-1898572961
https://github.com/scverse/scanpy/pull/2771#issuecomment-1947264348:58,Usability,clear,clear,58,"@flying-sheep the first is easy to fix. For 2. , it's not clear to me what you're asking for here. It's been a while since I worked on this. Am I supposed to import this function in the `__init__.py` for `tl` and `pl`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2771#issuecomment-1947264348
https://github.com/scverse/scanpy/pull/2771#issuecomment-1947927869:265,Energy Efficiency,adapt,adapted,265,"Hi Dan, about 1.: I’m asking you what the semantic meaning is :smile: . about 2.: there are two functions called `dendrogram`, and they have compatible signatures. Each computed dendrogram can be plotted. So what I’m saying is that the plotting version hasn’t been adapted. Also an important question: in `tl.dendrogram`, we call `_choose_representation`, which will compute a PCA for the .obs axis. When specifying `axis='var'`, should it compute a PCA for the `var` axis instead?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2771#issuecomment-1947927869
https://github.com/scverse/scanpy/pull/2771#issuecomment-1947927869:265,Modifiability,adapt,adapted,265,"Hi Dan, about 1.: I’m asking you what the semantic meaning is :smile: . about 2.: there are two functions called `dendrogram`, and they have compatible signatures. Each computed dendrogram can be plotted. So what I’m saying is that the plotting version hasn’t been adapted. Also an important question: in `tl.dendrogram`, we call `_choose_representation`, which will compute a PCA for the .obs axis. When specifying `axis='var'`, should it compute a PCA for the `var` axis instead?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2771#issuecomment-1947927869
https://github.com/scverse/scanpy/pull/2772#issuecomment-1833851711:215,Deployability,Patch,Patch,215,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2772?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `88.88889%` with `2 lines` in your changes missing coverage. Please review.; > Project coverage is 72.47%. Comparing base [(`bc349b9`)](https://app.codecov.io/gh/scverse/scanpy/commit/bc349b999be62196aa51b59db6e2daa37f428322?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`a0670c7`)](https://app.codecov.io/gh/scverse/scanpy/commit/a0670c7d3ba4db77d4016365484b79b9a6a2d522?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 143 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2772 +/- ##; ==========================================; + Coverage 72.46% 72.47% +0.01% ; ==========================================; Files 111 111 ; Lines 12418 12430 +12 ; ==========================================; + Hits 8999 9009 +10 ; - Misses 3419 3421 +2 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2772?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/preprocessing/\_simple.py](https://app.codecov.io/gh/scverse/scanpy/pull/2772?src=pr&el=tree&filepath=scanpy%2Fpreprocessing%2F_simple.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX3NpbXBsZS5weQ==) | `82.29% <88.88%> (+0.02%)` | :arrow_up: |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2772#issuecomment-1833851711
https://github.com/scverse/scanpy/pull/2774#issuecomment-1838034698:331,Availability,error,error-reference,331,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2774?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@70d55d5`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2774 +/- ##; ========================================; Coverage ? 72.11% ; ========================================; Files ? 103 ; Lines ? 11640 ; Branches ? 0 ; ========================================; Hits ? 8394 ; Misses ? 3246 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2774#issuecomment-1838034698
https://github.com/scverse/scanpy/pull/2774#issuecomment-1838034698:279,Usability,learn,learn,279,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2774?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@70d55d5`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2774 +/- ##; ========================================; Coverage ? 72.11% ; ========================================; Files ? 103 ; Lines ? 11640 ; Branches ? 0 ; ========================================; Hits ? 8394 ; Misses ? 3246 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2774#issuecomment-1838034698
https://github.com/scverse/scanpy/pull/2776#issuecomment-1857829967:49,Testability,test,tests,49,"OK, since Isaac has no time, I guess we add more tests in a follow-up PR if necessary",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2776#issuecomment-1857829967
https://github.com/scverse/scanpy/issues/2778#issuecomment-1845023488:265,Availability,error,error,265,"Hi, please provide the data you use, otherwise this is not reproducible:. ```pytb; FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '\external/CytAssist_FFPE_Human_Lung_Squamous_Cell_Carcinoma_filtered_feature_bc_matrix.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2778#issuecomment-1845023488
https://github.com/scverse/scanpy/issues/2778#issuecomment-1845023488:271,Integrability,message,message,271,"Hi, please provide the data you use, otherwise this is not reproducible:. ```pytb; FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '\external/CytAssist_FFPE_Human_Lung_Squamous_Cell_Carcinoma_filtered_feature_bc_matrix.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2778#issuecomment-1845023488
https://github.com/scverse/scanpy/issues/2778#issuecomment-1845048906:271,Availability,error,error,271,"> Hi, please provide the data you use, otherwise this is not reproducible:; > ; > ```; > FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '\external/CytAssist_FFPE_Human_Lung_Squamous_Cell_Carcinoma_filtered_feature_bc_matrix.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0); > ```. Hey, the data is publicly available under this link: https://www.10xgenomics.com/resources/datasets/human-lung-cancer-ffpe-2-standard. I simple copied the `curl` bash script to download all the files and then unzipped the file corresponding to the images to get the ""spatial"" folder",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2778#issuecomment-1845048906
https://github.com/scverse/scanpy/issues/2778#issuecomment-1845048906:374,Availability,avail,available,374,"> Hi, please provide the data you use, otherwise this is not reproducible:; > ; > ```; > FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '\external/CytAssist_FFPE_Human_Lung_Squamous_Cell_Carcinoma_filtered_feature_bc_matrix.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0); > ```. Hey, the data is publicly available under this link: https://www.10xgenomics.com/resources/datasets/human-lung-cancer-ffpe-2-standard. I simple copied the `curl` bash script to download all the files and then unzipped the file corresponding to the images to get the ""spatial"" folder",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2778#issuecomment-1845048906
https://github.com/scverse/scanpy/issues/2778#issuecomment-1845048906:525,Availability,down,download,525,"> Hi, please provide the data you use, otherwise this is not reproducible:; > ; > ```; > FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '\external/CytAssist_FFPE_Human_Lung_Squamous_Cell_Carcinoma_filtered_feature_bc_matrix.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0); > ```. Hey, the data is publicly available under this link: https://www.10xgenomics.com/resources/datasets/human-lung-cancer-ffpe-2-standard. I simple copied the `curl` bash script to download all the files and then unzipped the file corresponding to the images to get the ""spatial"" folder",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2778#issuecomment-1845048906
https://github.com/scverse/scanpy/issues/2778#issuecomment-1845048906:277,Integrability,message,message,277,"> Hi, please provide the data you use, otherwise this is not reproducible:; > ; > ```; > FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '\external/CytAssist_FFPE_Human_Lung_Squamous_Cell_Carcinoma_filtered_feature_bc_matrix.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0); > ```. Hey, the data is publicly available under this link: https://www.10xgenomics.com/resources/datasets/human-lung-cancer-ffpe-2-standard. I simple copied the `curl` bash script to download all the files and then unzipped the file corresponding to the images to get the ""spatial"" folder",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2778#issuecomment-1845048906
https://github.com/scverse/scanpy/issues/2778#issuecomment-1845048906:485,Usability,simpl,simple,485,"> Hi, please provide the data you use, otherwise this is not reproducible:; > ; > ```; > FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '\external/CytAssist_FFPE_Human_Lung_Squamous_Cell_Carcinoma_filtered_feature_bc_matrix.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0); > ```. Hey, the data is publicly available under this link: https://www.10xgenomics.com/resources/datasets/human-lung-cancer-ffpe-2-standard. I simple copied the `curl` bash script to download all the files and then unzipped the file corresponding to the images to get the ""spatial"" folder",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2778#issuecomment-1845048906
https://github.com/scverse/scanpy/issues/2778#issuecomment-1846833078:301,Availability,Error,Error,301,"@flying-sheep Added this snippet to eval the coordinates as int and not str (plotting > _utils.py > circles, lines 1138 - 1145):. ```; if not np.issubdtype(x.dtype, np.integer) or not np.issubdtype(; y.dtype, np.integer; ):; try:; x = x.astype(int); y = y.astype(int); except ValueError as e:; print(""Error converting to int:"", e); ```. This has solved my issue and can now see the tissue images using `sc.pl.spatial`. Do feel free to change the code though, this would be my first contribution!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2778#issuecomment-1846833078
https://github.com/scverse/scanpy/issues/2778#issuecomment-1846864918:89,Deployability,release,release,89,This was fixed in https://github.com/scverse/scanpy/pull/2424:. @ivirshup when should we release 1.10?. ![image](https://github.com/scverse/scanpy/assets/291575/f1d7f2e3-1943-492c-a1f6-2b0499affe94),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2778#issuecomment-1846864918
https://github.com/scverse/scanpy/pull/2779#issuecomment-1846869505:2460,Testability,test,testing,2460,+comments&utm_term=scverse#diff-c2NhbnB5L2RhdGFzZXRzL19lYmlfZXhwcmVzc2lvbl9hdGxhcy5weQ==) | `90.36% <100.00%> (ø)` | |; | [scanpy/external/pp/\_bbknn.py](https://app.codecov.io/gh/scverse/scanpy/pull/2779?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2V4dGVybmFsL3BwL19iYmtubi5weQ==) | `50.00% <ø> (+3.84%)` | :arrow_up: |; | [scanpy/external/pp/\_hashsolo.py](https://app.codecov.io/gh/scverse/scanpy/pull/2779?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2V4dGVybmFsL3BwL19oYXNoc29sby5weQ==) | `89.56% <ø> (+0.67%)` | :arrow_up: |; | [scanpy/preprocessing/\_simple.py](https://app.codecov.io/gh/scverse/scanpy/pull/2779?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX3NpbXBsZS5weQ==) | `82.81% <ø> (+0.54%)` | :arrow_up: |; | [scanpy/testing/\_helpers/data.py](https://app.codecov.io/gh/scverse/scanpy/pull/2779?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX2hlbHBlcnMvZGF0YS5weQ==) | `89.47% <100.00%> (+2.98%)` | :arrow_up: |; | [scanpy/tools/\_rank\_genes\_groups.py](https://app.codecov.io/gh/scverse/scanpy/pull/2779?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rvb2xzL19yYW5rX2dlbmVzX2dyb3Vwcy5weQ==) | `94.30% <100.00%> (+0.78%)` | :arrow_up: |; | [scanpy/readwrite.py](https://app.codecov.io/gh/scverse/scanpy/pull/2779?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3JlYWR3cml0ZS5weQ==) | `67.95% <0.00%> (-0.08%)` | :arrow_down: |; | [scanpy/testing/\_pytest/fixtures/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2779?src=pr&el=tree&utm_med,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2779#issuecomment-1846869505
https://github.com/scverse/scanpy/pull/2779#issuecomment-1846869505:3340,Testability,test,testing,3340,codecov.io/gh/scverse/scanpy/pull/2779?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2V4dGVybmFsL3BwL19oYXNoc29sby5weQ==) | `89.56% <ø> (+0.67%)` | :arrow_up: |; | [scanpy/preprocessing/\_simple.py](https://app.codecov.io/gh/scverse/scanpy/pull/2779?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX3NpbXBsZS5weQ==) | `82.81% <ø> (+0.54%)` | :arrow_up: |; | [scanpy/testing/\_helpers/data.py](https://app.codecov.io/gh/scverse/scanpy/pull/2779?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX2hlbHBlcnMvZGF0YS5weQ==) | `89.47% <100.00%> (+2.98%)` | :arrow_up: |; | [scanpy/tools/\_rank\_genes\_groups.py](https://app.codecov.io/gh/scverse/scanpy/pull/2779?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rvb2xzL19yYW5rX2dlbmVzX2dyb3Vwcy5weQ==) | `94.30% <100.00%> (+0.78%)` | :arrow_up: |; | [scanpy/readwrite.py](https://app.codecov.io/gh/scverse/scanpy/pull/2779?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3JlYWR3cml0ZS5weQ==) | `67.95% <0.00%> (-0.08%)` | :arrow_down: |; | [scanpy/testing/\_pytest/fixtures/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2779?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9maXh0dXJlcy9fX2luaXRfXy5weQ==) | `96.66% <92.85%> (+1.92%)` | :arrow_up: |. ... and [70 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2779/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2779#issuecomment-1846869505
https://github.com/scverse/scanpy/pull/2779#issuecomment-1858121974:157,Deployability,update,update,157,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 86dc4d5d96eb7547833e7805ea2f7d603bd3ba2d; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2779: Fix anndata warnings'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2779-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2779 on branch 1.9.x (Fix anndata warnings)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2779#issuecomment-1858121974
https://github.com/scverse/scanpy/pull/2779#issuecomment-1858121974:879,Deployability,continuous,continuous,879,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 86dc4d5d96eb7547833e7805ea2f7d603bd3ba2d; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2779: Fix anndata warnings'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2779-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2779 on branch 1.9.x (Fix anndata warnings)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2779#issuecomment-1858121974
https://github.com/scverse/scanpy/pull/2779#issuecomment-1858121974:890,Deployability,integrat,integration,890,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 86dc4d5d96eb7547833e7805ea2f7d603bd3ba2d; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2779: Fix anndata warnings'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2779-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2779 on branch 1.9.x (Fix anndata warnings)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2779#issuecomment-1858121974
https://github.com/scverse/scanpy/pull/2779#issuecomment-1858121974:890,Integrability,integrat,integration,890,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 86dc4d5d96eb7547833e7805ea2f7d603bd3ba2d; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2779: Fix anndata warnings'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2779-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2779 on branch 1.9.x (Fix anndata warnings)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2779#issuecomment-1858121974
https://github.com/scverse/scanpy/pull/2779#issuecomment-1858121974:865,Testability,test,tested,865,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 86dc4d5d96eb7547833e7805ea2f7d603bd3ba2d; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2779: Fix anndata warnings'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2779-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2779 on branch 1.9.x (Fix anndata warnings)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2779#issuecomment-1858121974
https://github.com/scverse/scanpy/issues/2780#issuecomment-1865046956:36,Availability,recover,recovered,36,"Yes, I'll send an example in a bit, recovered variable genes seem wildly discrepant. I can get to this tomorrow! Thanks for your quick response",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2780#issuecomment-1865046956
https://github.com/scverse/scanpy/issues/2780#issuecomment-1865046956:46,Modifiability,variab,variable,46,"Yes, I'll send an example in a bit, recovered variable genes seem wildly discrepant. I can get to this tomorrow! Thanks for your quick response",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2780#issuecomment-1865046956
https://github.com/scverse/scanpy/issues/2780#issuecomment-1865046956:36,Safety,recover,recovered,36,"Yes, I'll send an example in a bit, recovered variable genes seem wildly discrepant. I can get to this tomorrow! Thanks for your quick response",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2780#issuecomment-1865046956
https://github.com/scverse/scanpy/issues/2780#issuecomment-1867897023:58,Modifiability,variab,variable,58,"Hi everyone, here is the way I extracted the top 500 most variable gees in seurat: ; ![Screen Shot 2023-12-22 at 11 58 39 AM](https://github.com/scverse/scanpy/assets/65792233/5b59b6d1-696e-4695-a7df-ad8f74d6412f)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2780#issuecomment-1867897023
https://github.com/scverse/scanpy/issues/2780#issuecomment-1867897471:37,Modifiability,variab,variable,37,Here is the way I extracted the most variable genes in scanpy: ; ![Screen Shot 2023-12-22 at 11 59 13 AM](https://github.com/scverse/scanpy/assets/65792233/97be237d-eff8-4910-b858-163d301c2bf6),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2780#issuecomment-1867897471
https://github.com/scverse/scanpy/issues/2780#issuecomment-1867898442:86,Usability,guid,guidance,86,"Even when using the Seurat flavor in scanpy, the differences seem pretty drastic. Any guidance on this would be appreciated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2780#issuecomment-1867898442
https://github.com/scverse/scanpy/issues/2780#issuecomment-1871205457:4,Deployability,update,update,4,any update on this?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2780#issuecomment-1871205457
https://github.com/scverse/scanpy/issues/2780#issuecomment-1892069618:46,Deployability,update,update,46,"Hi, just wanted to ask again if there was any update on this. Thanks in advance!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2780#issuecomment-1892069618
https://github.com/scverse/scanpy/issues/2780#issuecomment-1892350467:6,Deployability,update,update,6,We’ll update this issue when we merge the PR. You can subscribe to scanpy releases on GitHub to be notified when we release something!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2780#issuecomment-1892350467
https://github.com/scverse/scanpy/issues/2780#issuecomment-1892350467:74,Deployability,release,releases,74,We’ll update this issue when we merge the PR. You can subscribe to scanpy releases on GitHub to be notified when we release something!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2780#issuecomment-1892350467
https://github.com/scverse/scanpy/issues/2780#issuecomment-1892350467:116,Deployability,release,release,116,We’ll update this issue when we merge the PR. You can subscribe to scanpy releases on GitHub to be notified when we release something!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2780#issuecomment-1892350467
https://github.com/scverse/scanpy/issues/2780#issuecomment-1892761935:1106,Performance,perform,perform,1106,"et things a bit into order here, as at the moment some wrong impressions are around I think:. **1. Incorrect comparisons done here**; To my current knowledge,; - `sc.pp.highly_variable_genes(…, flavor=“seurat”)` mimics `FindVariableFeatures(…, method=“mean.var.plot”)`, operating on count-normalised, log1p-ed data.; - `sc.pp.highly_variable_genes(…, flavor=“seurat_v3”)` mimics `FindVariableFeatures(…, method=“vst”)` operating on raw gene counts (from the [Stuart et al. 2019 Seurat Version 3 paper](https://www.cell.com/cell/pdf/S0092-8674(19)30559-8.pdf)). @flying-sheep, lets put something like this into the doctstring in #2792? Will add a suggestion for you to check there. Think this is very useful information super hard to find atm. These are 2 different methods, which scanpy implements. > Even when using the Seurat flavor in scanpy, the differences seem pretty drastic. Any guidance on this would be appreciated. Guidance:; In your example, you are comparing two different methods, that produce different results (like really just perform different computations). Notice `flavor=“seurat”` is default in `sc.pp.highly_variable_genes`, but `method=""vst""` is default in `FindVariableFeatures`. (I see this can be confusing, we'll try to make this as clear as possible in the doc). **2. Incorrect assumption about Seurat**; > This means that the implementation in scanpy is according to the method in the paper? And the implementation in Seurat uses some other method. Thanks!. This is not correct. There are 2 options of Seurat mixed up in this conversation here, causing quite some confusion. Seurat is giving the selected features based on what they write to the best of my knowledge. **3. Open question on small detail**; > Yes: While working on #2792, @eroell has discovered that seurat’s gene ordering doesn’t match their definition in the paper. The one in the paper makes most sense, as it’s stable (hvg(..., n_top_genes=n) == hvg(..., n_top_genes=n+i)[:n]). Need to emphasise this is",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2780#issuecomment-1892761935
https://github.com/scverse/scanpy/issues/2780#issuecomment-1892761935:949,Usability,guid,guidance,949,"Hi,. Thanks @carversh for opening the discussion!. Trying to get things a bit into order here, as at the moment some wrong impressions are around I think:. **1. Incorrect comparisons done here**; To my current knowledge,; - `sc.pp.highly_variable_genes(…, flavor=“seurat”)` mimics `FindVariableFeatures(…, method=“mean.var.plot”)`, operating on count-normalised, log1p-ed data.; - `sc.pp.highly_variable_genes(…, flavor=“seurat_v3”)` mimics `FindVariableFeatures(…, method=“vst”)` operating on raw gene counts (from the [Stuart et al. 2019 Seurat Version 3 paper](https://www.cell.com/cell/pdf/S0092-8674(19)30559-8.pdf)). @flying-sheep, lets put something like this into the doctstring in #2792? Will add a suggestion for you to check there. Think this is very useful information super hard to find atm. These are 2 different methods, which scanpy implements. > Even when using the Seurat flavor in scanpy, the differences seem pretty drastic. Any guidance on this would be appreciated. Guidance:; In your example, you are comparing two different methods, that produce different results (like really just perform different computations). Notice `flavor=“seurat”` is default in `sc.pp.highly_variable_genes`, but `method=""vst""` is default in `FindVariableFeatures`. (I see this can be confusing, we'll try to make this as clear as possible in the doc). **2. Incorrect assumption about Seurat**; > This means that the implementation in scanpy is according to the method in the paper? And the implementation in Seurat uses some other method. Thanks!. This is not correct. There are 2 options of Seurat mixed up in this conversation here, causing quite some confusion. Seurat is giving the selected features based on what they write to the best of my knowledge. **3. Open question on small detail**; > Yes: While working on #2792, @eroell has discovered that seurat’s gene ordering doesn’t match their definition in the paper. The one in the paper makes most sense, as it’s stable (hvg(..., n_top_genes=n",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2780#issuecomment-1892761935
https://github.com/scverse/scanpy/issues/2780#issuecomment-1892761935:988,Usability,Guid,Guidance,988,"et things a bit into order here, as at the moment some wrong impressions are around I think:. **1. Incorrect comparisons done here**; To my current knowledge,; - `sc.pp.highly_variable_genes(…, flavor=“seurat”)` mimics `FindVariableFeatures(…, method=“mean.var.plot”)`, operating on count-normalised, log1p-ed data.; - `sc.pp.highly_variable_genes(…, flavor=“seurat_v3”)` mimics `FindVariableFeatures(…, method=“vst”)` operating on raw gene counts (from the [Stuart et al. 2019 Seurat Version 3 paper](https://www.cell.com/cell/pdf/S0092-8674(19)30559-8.pdf)). @flying-sheep, lets put something like this into the doctstring in #2792? Will add a suggestion for you to check there. Think this is very useful information super hard to find atm. These are 2 different methods, which scanpy implements. > Even when using the Seurat flavor in scanpy, the differences seem pretty drastic. Any guidance on this would be appreciated. Guidance:; In your example, you are comparing two different methods, that produce different results (like really just perform different computations). Notice `flavor=“seurat”` is default in `sc.pp.highly_variable_genes`, but `method=""vst""` is default in `FindVariableFeatures`. (I see this can be confusing, we'll try to make this as clear as possible in the doc). **2. Incorrect assumption about Seurat**; > This means that the implementation in scanpy is according to the method in the paper? And the implementation in Seurat uses some other method. Thanks!. This is not correct. There are 2 options of Seurat mixed up in this conversation here, causing quite some confusion. Seurat is giving the selected features based on what they write to the best of my knowledge. **3. Open question on small detail**; > Yes: While working on #2792, @eroell has discovered that seurat’s gene ordering doesn’t match their definition in the paper. The one in the paper makes most sense, as it’s stable (hvg(..., n_top_genes=n) == hvg(..., n_top_genes=n+i)[:n]). Need to emphasise this is",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2780#issuecomment-1892761935
https://github.com/scverse/scanpy/issues/2780#issuecomment-1892761935:1322,Usability,clear,clear,1322,"thod=“mean.var.plot”)`, operating on count-normalised, log1p-ed data.; - `sc.pp.highly_variable_genes(…, flavor=“seurat_v3”)` mimics `FindVariableFeatures(…, method=“vst”)` operating on raw gene counts (from the [Stuart et al. 2019 Seurat Version 3 paper](https://www.cell.com/cell/pdf/S0092-8674(19)30559-8.pdf)). @flying-sheep, lets put something like this into the doctstring in #2792? Will add a suggestion for you to check there. Think this is very useful information super hard to find atm. These are 2 different methods, which scanpy implements. > Even when using the Seurat flavor in scanpy, the differences seem pretty drastic. Any guidance on this would be appreciated. Guidance:; In your example, you are comparing two different methods, that produce different results (like really just perform different computations). Notice `flavor=“seurat”` is default in `sc.pp.highly_variable_genes`, but `method=""vst""` is default in `FindVariableFeatures`. (I see this can be confusing, we'll try to make this as clear as possible in the doc). **2. Incorrect assumption about Seurat**; > This means that the implementation in scanpy is according to the method in the paper? And the implementation in Seurat uses some other method. Thanks!. This is not correct. There are 2 options of Seurat mixed up in this conversation here, causing quite some confusion. Seurat is giving the selected features based on what they write to the best of my knowledge. **3. Open question on small detail**; > Yes: While working on #2792, @eroell has discovered that seurat’s gene ordering doesn’t match their definition in the paper. The one in the paper makes most sense, as it’s stable (hvg(..., n_top_genes=n) == hvg(..., n_top_genes=n+i)[:n]). Need to emphasise this is; - a) only a question currently open (I am really not particularly an expert in R with limited bandwidth to check things there so waiting for their answer).; - b) Even if true, this does not affect our examples here. It comes into play when we t",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2780#issuecomment-1892761935
https://github.com/scverse/scanpy/issues/2780#issuecomment-1892761935:2529,Usability,guid,guidance,2529,"8.pdf)). @flying-sheep, lets put something like this into the doctstring in #2792? Will add a suggestion for you to check there. Think this is very useful information super hard to find atm. These are 2 different methods, which scanpy implements. > Even when using the Seurat flavor in scanpy, the differences seem pretty drastic. Any guidance on this would be appreciated. Guidance:; In your example, you are comparing two different methods, that produce different results (like really just perform different computations). Notice `flavor=“seurat”` is default in `sc.pp.highly_variable_genes`, but `method=""vst""` is default in `FindVariableFeatures`. (I see this can be confusing, we'll try to make this as clear as possible in the doc). **2. Incorrect assumption about Seurat**; > This means that the implementation in scanpy is according to the method in the paper? And the implementation in Seurat uses some other method. Thanks!. This is not correct. There are 2 options of Seurat mixed up in this conversation here, causing quite some confusion. Seurat is giving the selected features based on what they write to the best of my knowledge. **3. Open question on small detail**; > Yes: While working on #2792, @eroell has discovered that seurat’s gene ordering doesn’t match their definition in the paper. The one in the paper makes most sense, as it’s stable (hvg(..., n_top_genes=n) == hvg(..., n_top_genes=n+i)[:n]). Need to emphasise this is; - a) only a question currently open (I am really not particularly an expert in R with limited bandwidth to check things there so waiting for their answer).; - b) Even if true, this does not affect our examples here. It comes into play when we try to further be as consistent with Seurat and their textual description as possible. Yes, this is confusing :) Hope I did not confuse something myself here, checked but consider it a to-the-best-of-my-current-knowledge guidance towards a working solution for you rather than peer-reviewed ground truth ;)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2780#issuecomment-1892761935
https://github.com/scverse/scanpy/issues/2780#issuecomment-1892766132:3415,Deployability,patch,patchwork,3415,"sort_values(""dispersions_norm"", ascending=False).iloc[:10, :]; print(top10_scanpy[[""means"", ""dispersions"", ""dispersions_norm""]]); ```. ```; mvp.mean mvp.dispersion mvp.dispersion.scaled; CEP128 0.151130 5.858001 7.996479; DOK3 0.272308 5.838402 7.958147; ARVCF 0.129909 5.807068 7.896862; YPEL2 0.242922 5.806298 7.895355; UBE2D4 0.254622 5.778868 7.841706; FAM210B 0.266598 5.724431 7.735234; CTB-113I20.2 0.126570 5.654503 7.598463; GBGT1 0.177501 5.604167 7.500014; LRRIQ3 0.098048 5.437717 7.174459; MTIF2 0.220279 5.371215 7.044389; means dispersions dispersions_norm; index ; CEP128 0.151130 5.858001 7.996479; DOK3 0.272308 5.838402 7.958147; ARVCF 0.129909 5.807068 7.896862; YPEL2 0.242923 5.806298 7.895356; UBE2D4 0.254622 5.778868 7.841706; FAM210B 0.266598 5.724431 7.735234; CTB-113I20.2 0.126570 5.654503 7.598464; GBGT1 0.177501 5.604167 7.500014; LRRIQ3 0.098048 5.437717 7.174459; MTIF2 0.220279 5.371215 7.044389; ```. To generate seurat_hvg_mvp.csv, I used; ```R; library(dplyr); library(Seurat); library(patchwork). ################################################################################; ### FindVariableFeatures (no batch covariate). # Load the PBMC dataset - load the data from the link above!; # pbmc.data <- Read10X(data.dir = ""<INSERT_PATH_TO_DATA_HERE>/filtered_gene_bc_matrices/hg19/""); pbmc.data <- Read10X(data.dir = ""/Users/eljas.roellin/Documents/R_stuff/filtered_gene_bc_matrices/hg19/""). # Initialize the Seurat object with the raw (non-normalized data).; pbmc <- CreateSeuratObject(counts = pbmc.data, project = ""pbmc3k"", min.cells = 3, min.features = 200); pbmc <- NormalizeData(pbmc, normalization.method=""LogNormalize"", scale.factor=10000). pbmc <- FindVariableFeatures(pbmc, selection.method = ""mean.var.plot""). hvf_info <- HVFInfo(pbmc). write.csv(hvf_info, ""seurat_hvg_mvp.csv""); ```. And to generate seurat_hvg_v3.csv, I used; ```R; ################################################################################; ### FindVariableFeatures (no batch",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2780#issuecomment-1892766132
https://github.com/scverse/scanpy/issues/2780#issuecomment-1892766132:3558,Performance,Load,Load,3558,"30 5.858001 7.996479; DOK3 0.272308 5.838402 7.958147; ARVCF 0.129909 5.807068 7.896862; YPEL2 0.242922 5.806298 7.895355; UBE2D4 0.254622 5.778868 7.841706; FAM210B 0.266598 5.724431 7.735234; CTB-113I20.2 0.126570 5.654503 7.598463; GBGT1 0.177501 5.604167 7.500014; LRRIQ3 0.098048 5.437717 7.174459; MTIF2 0.220279 5.371215 7.044389; means dispersions dispersions_norm; index ; CEP128 0.151130 5.858001 7.996479; DOK3 0.272308 5.838402 7.958147; ARVCF 0.129909 5.807068 7.896862; YPEL2 0.242923 5.806298 7.895356; UBE2D4 0.254622 5.778868 7.841706; FAM210B 0.266598 5.724431 7.735234; CTB-113I20.2 0.126570 5.654503 7.598464; GBGT1 0.177501 5.604167 7.500014; LRRIQ3 0.098048 5.437717 7.174459; MTIF2 0.220279 5.371215 7.044389; ```. To generate seurat_hvg_mvp.csv, I used; ```R; library(dplyr); library(Seurat); library(patchwork). ################################################################################; ### FindVariableFeatures (no batch covariate). # Load the PBMC dataset - load the data from the link above!; # pbmc.data <- Read10X(data.dir = ""<INSERT_PATH_TO_DATA_HERE>/filtered_gene_bc_matrices/hg19/""); pbmc.data <- Read10X(data.dir = ""/Users/eljas.roellin/Documents/R_stuff/filtered_gene_bc_matrices/hg19/""). # Initialize the Seurat object with the raw (non-normalized data).; pbmc <- CreateSeuratObject(counts = pbmc.data, project = ""pbmc3k"", min.cells = 3, min.features = 200); pbmc <- NormalizeData(pbmc, normalization.method=""LogNormalize"", scale.factor=10000). pbmc <- FindVariableFeatures(pbmc, selection.method = ""mean.var.plot""). hvf_info <- HVFInfo(pbmc). write.csv(hvf_info, ""seurat_hvg_mvp.csv""); ```. And to generate seurat_hvg_v3.csv, I used; ```R; ################################################################################; ### FindVariableFeatures (no batch covariate). # Load the PBMC dataset - load the data from the link above!; # pbmc.data <- Read10X(data.dir = ""<INSERT_PATH_TO_DATA_HERE>/filtered_gene_bc_matrices/hg19/""); pbmc.data <- Read10X(data.d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2780#issuecomment-1892766132
https://github.com/scverse/scanpy/issues/2780#issuecomment-1892766132:3582,Performance,load,load,3582,"30 5.858001 7.996479; DOK3 0.272308 5.838402 7.958147; ARVCF 0.129909 5.807068 7.896862; YPEL2 0.242922 5.806298 7.895355; UBE2D4 0.254622 5.778868 7.841706; FAM210B 0.266598 5.724431 7.735234; CTB-113I20.2 0.126570 5.654503 7.598463; GBGT1 0.177501 5.604167 7.500014; LRRIQ3 0.098048 5.437717 7.174459; MTIF2 0.220279 5.371215 7.044389; means dispersions dispersions_norm; index ; CEP128 0.151130 5.858001 7.996479; DOK3 0.272308 5.838402 7.958147; ARVCF 0.129909 5.807068 7.896862; YPEL2 0.242923 5.806298 7.895356; UBE2D4 0.254622 5.778868 7.841706; FAM210B 0.266598 5.724431 7.735234; CTB-113I20.2 0.126570 5.654503 7.598464; GBGT1 0.177501 5.604167 7.500014; LRRIQ3 0.098048 5.437717 7.174459; MTIF2 0.220279 5.371215 7.044389; ```. To generate seurat_hvg_mvp.csv, I used; ```R; library(dplyr); library(Seurat); library(patchwork). ################################################################################; ### FindVariableFeatures (no batch covariate). # Load the PBMC dataset - load the data from the link above!; # pbmc.data <- Read10X(data.dir = ""<INSERT_PATH_TO_DATA_HERE>/filtered_gene_bc_matrices/hg19/""); pbmc.data <- Read10X(data.dir = ""/Users/eljas.roellin/Documents/R_stuff/filtered_gene_bc_matrices/hg19/""). # Initialize the Seurat object with the raw (non-normalized data).; pbmc <- CreateSeuratObject(counts = pbmc.data, project = ""pbmc3k"", min.cells = 3, min.features = 200); pbmc <- NormalizeData(pbmc, normalization.method=""LogNormalize"", scale.factor=10000). pbmc <- FindVariableFeatures(pbmc, selection.method = ""mean.var.plot""). hvf_info <- HVFInfo(pbmc). write.csv(hvf_info, ""seurat_hvg_mvp.csv""); ```. And to generate seurat_hvg_v3.csv, I used; ```R; ################################################################################; ### FindVariableFeatures (no batch covariate). # Load the PBMC dataset - load the data from the link above!; # pbmc.data <- Read10X(data.dir = ""<INSERT_PATH_TO_DATA_HERE>/filtered_gene_bc_matrices/hg19/""); pbmc.data <- Read10X(data.d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2780#issuecomment-1892766132
https://github.com/scverse/scanpy/issues/2780#issuecomment-1892766132:4406,Performance,Load,Load,4406,"hvg_mvp.csv, I used; ```R; library(dplyr); library(Seurat); library(patchwork). ################################################################################; ### FindVariableFeatures (no batch covariate). # Load the PBMC dataset - load the data from the link above!; # pbmc.data <- Read10X(data.dir = ""<INSERT_PATH_TO_DATA_HERE>/filtered_gene_bc_matrices/hg19/""); pbmc.data <- Read10X(data.dir = ""/Users/eljas.roellin/Documents/R_stuff/filtered_gene_bc_matrices/hg19/""). # Initialize the Seurat object with the raw (non-normalized data).; pbmc <- CreateSeuratObject(counts = pbmc.data, project = ""pbmc3k"", min.cells = 3, min.features = 200); pbmc <- NormalizeData(pbmc, normalization.method=""LogNormalize"", scale.factor=10000). pbmc <- FindVariableFeatures(pbmc, selection.method = ""mean.var.plot""). hvf_info <- HVFInfo(pbmc). write.csv(hvf_info, ""seurat_hvg_mvp.csv""); ```. And to generate seurat_hvg_v3.csv, I used; ```R; ################################################################################; ### FindVariableFeatures (no batch covariate). # Load the PBMC dataset - load the data from the link above!; # pbmc.data <- Read10X(data.dir = ""<INSERT_PATH_TO_DATA_HERE>/filtered_gene_bc_matrices/hg19/""); pbmc.data <- Read10X(data.dir = ""/Users/eljas.roellin/Documents/R_stuff/filtered_gene_bc_matrices/hg19/""). # Initialize the Seurat object with the raw (non-normalized data).; pbmc <- CreateSeuratObject(counts = pbmc.data, project = ""pbmc3k"", min.cells = 3, min.features = 200); pbmc. pbmc <- FindVariableFeatures(pbmc, mean.function=ExpMean, selection.method = 'vst', nfeatures = 2000). hvf_info <- HVFInfo(pbmc). write.csv(hvf_info, ""seurat_hvg_v3.csv""); ```. *unless when using `batches`, a bug we are currently solving. Nevertheless, implementation details, choices for numeric stability and numerics of the underlying libraries are indeed a challenge and do cause some discrepancies - surely interested how your comparison looks @carversh if you give these suggestions here a try!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2780#issuecomment-1892766132
https://github.com/scverse/scanpy/issues/2780#issuecomment-1892766132:4430,Performance,load,load,4430,"hvg_mvp.csv, I used; ```R; library(dplyr); library(Seurat); library(patchwork). ################################################################################; ### FindVariableFeatures (no batch covariate). # Load the PBMC dataset - load the data from the link above!; # pbmc.data <- Read10X(data.dir = ""<INSERT_PATH_TO_DATA_HERE>/filtered_gene_bc_matrices/hg19/""); pbmc.data <- Read10X(data.dir = ""/Users/eljas.roellin/Documents/R_stuff/filtered_gene_bc_matrices/hg19/""). # Initialize the Seurat object with the raw (non-normalized data).; pbmc <- CreateSeuratObject(counts = pbmc.data, project = ""pbmc3k"", min.cells = 3, min.features = 200); pbmc <- NormalizeData(pbmc, normalization.method=""LogNormalize"", scale.factor=10000). pbmc <- FindVariableFeatures(pbmc, selection.method = ""mean.var.plot""). hvf_info <- HVFInfo(pbmc). write.csv(hvf_info, ""seurat_hvg_mvp.csv""); ```. And to generate seurat_hvg_v3.csv, I used; ```R; ################################################################################; ### FindVariableFeatures (no batch covariate). # Load the PBMC dataset - load the data from the link above!; # pbmc.data <- Read10X(data.dir = ""<INSERT_PATH_TO_DATA_HERE>/filtered_gene_bc_matrices/hg19/""); pbmc.data <- Read10X(data.dir = ""/Users/eljas.roellin/Documents/R_stuff/filtered_gene_bc_matrices/hg19/""). # Initialize the Seurat object with the raw (non-normalized data).; pbmc <- CreateSeuratObject(counts = pbmc.data, project = ""pbmc3k"", min.cells = 3, min.features = 200); pbmc. pbmc <- FindVariableFeatures(pbmc, mean.function=ExpMean, selection.method = 'vst', nfeatures = 2000). hvf_info <- HVFInfo(pbmc). write.csv(hvf_info, ""seurat_hvg_v3.csv""); ```. *unless when using `batches`, a bug we are currently solving. Nevertheless, implementation details, choices for numeric stability and numerics of the underlying libraries are indeed a challenge and do cause some discrepancies - surely interested how your comparison looks @carversh if you give these suggestions here a try!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2780#issuecomment-1892766132
https://github.com/scverse/scanpy/issues/2780#issuecomment-1892766132:4043,Testability,Log,LogNormalize,4043,"29909 5.807068 7.896862; YPEL2 0.242923 5.806298 7.895356; UBE2D4 0.254622 5.778868 7.841706; FAM210B 0.266598 5.724431 7.735234; CTB-113I20.2 0.126570 5.654503 7.598464; GBGT1 0.177501 5.604167 7.500014; LRRIQ3 0.098048 5.437717 7.174459; MTIF2 0.220279 5.371215 7.044389; ```. To generate seurat_hvg_mvp.csv, I used; ```R; library(dplyr); library(Seurat); library(patchwork). ################################################################################; ### FindVariableFeatures (no batch covariate). # Load the PBMC dataset - load the data from the link above!; # pbmc.data <- Read10X(data.dir = ""<INSERT_PATH_TO_DATA_HERE>/filtered_gene_bc_matrices/hg19/""); pbmc.data <- Read10X(data.dir = ""/Users/eljas.roellin/Documents/R_stuff/filtered_gene_bc_matrices/hg19/""). # Initialize the Seurat object with the raw (non-normalized data).; pbmc <- CreateSeuratObject(counts = pbmc.data, project = ""pbmc3k"", min.cells = 3, min.features = 200); pbmc <- NormalizeData(pbmc, normalization.method=""LogNormalize"", scale.factor=10000). pbmc <- FindVariableFeatures(pbmc, selection.method = ""mean.var.plot""). hvf_info <- HVFInfo(pbmc). write.csv(hvf_info, ""seurat_hvg_mvp.csv""); ```. And to generate seurat_hvg_v3.csv, I used; ```R; ################################################################################; ### FindVariableFeatures (no batch covariate). # Load the PBMC dataset - load the data from the link above!; # pbmc.data <- Read10X(data.dir = ""<INSERT_PATH_TO_DATA_HERE>/filtered_gene_bc_matrices/hg19/""); pbmc.data <- Read10X(data.dir = ""/Users/eljas.roellin/Documents/R_stuff/filtered_gene_bc_matrices/hg19/""). # Initialize the Seurat object with the raw (non-normalized data).; pbmc <- CreateSeuratObject(counts = pbmc.data, project = ""pbmc3k"", min.cells = 3, min.features = 200); pbmc. pbmc <- FindVariableFeatures(pbmc, mean.function=ExpMean, selection.method = 'vst', nfeatures = 2000). hvf_info <- HVFInfo(pbmc). write.csv(hvf_info, ""seurat_hvg_v3.csv""); ```. *unless when using `batche",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2780#issuecomment-1892766132
https://github.com/scverse/scanpy/issues/2781#issuecomment-1860968991:182,Usability,simpl,simple-py,182,"Not sure, according to [this page](https://joblib.readthedocs.io/en/latest/auto_examples/parallel/distributed_backend_simple.html#sphx-glr-auto-examples-parallel-distributed-backend-simple-py) function code should be changed. It would be handy to add the backend as option to `regress_out`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2781#issuecomment-1860968991
https://github.com/scverse/scanpy/pull/2783#issuecomment-1860972298:331,Availability,error,error-reference,331,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2783?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@4058e36`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 09a432a differs from pull request most recent head 3b44d11. Consider uploading reports for the commit 3b44d11 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2783 +/- ##; ========================================; Coverage ? 17.51% ; ========================================; Files ? 103 ; Lines ? 11645 ; Branches ? 0 ; ========================================; Hits ? 2040 ; Misses ? 9605 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2783#issuecomment-1860972298
https://github.com/scverse/scanpy/pull/2783#issuecomment-1860972298:279,Usability,learn,learn,279,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2783?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@4058e36`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 09a432a differs from pull request most recent head 3b44d11. Consider uploading reports for the commit 3b44d11 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2783 +/- ##; ========================================; Coverage ? 17.51% ; ========================================; Files ? 103 ; Lines ? 11645 ; Branches ? 0 ; ========================================; Hits ? 2040 ; Misses ? 9605 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2783#issuecomment-1860972298
https://github.com/scverse/scanpy/pull/2784#issuecomment-1862463379:157,Deployability,update,update,157,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 47664d83a7bc47756356b907e5719076ab187361; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2784: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2784-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2784 on branch 1.9.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2784#issuecomment-1862463379
https://github.com/scverse/scanpy/pull/2784#issuecomment-1862463379:913,Deployability,continuous,continuous,913,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 47664d83a7bc47756356b907e5719076ab187361; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2784: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2784-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2784 on branch 1.9.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2784#issuecomment-1862463379
https://github.com/scverse/scanpy/pull/2784#issuecomment-1862463379:924,Deployability,integrat,integration,924,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 47664d83a7bc47756356b907e5719076ab187361; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2784: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2784-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2784 on branch 1.9.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2784#issuecomment-1862463379
https://github.com/scverse/scanpy/pull/2784#issuecomment-1862463379:924,Integrability,integrat,integration,924,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 47664d83a7bc47756356b907e5719076ab187361; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2784: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2784-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2784 on branch 1.9.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2784#issuecomment-1862463379
https://github.com/scverse/scanpy/pull/2784#issuecomment-1862463379:899,Testability,test,tested,899,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 47664d83a7bc47756356b907e5719076ab187361; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2784: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2784-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2784 on branch 1.9.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2784#issuecomment-1862463379
https://github.com/scverse/scanpy/issues/2791#issuecomment-1952249236:60,Deployability,release,releases,60,"Indeed scanpy 1.9.6 required `seaborn!=0.13.0`, while newer releases have been update to require `seaborn>=0.13.0` (when you look here on GitHub, you will find this updated requirement as you mentioned). If you want to use scanpy 1.9.6 for a specific reason, your environment should use a seaborn version that is not 0.13.x, e.g. the latest 0.12 version. Does upgrading to the latest scanpy version resolve this issue for you?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2791#issuecomment-1952249236
https://github.com/scverse/scanpy/issues/2791#issuecomment-1952249236:79,Deployability,update,update,79,"Indeed scanpy 1.9.6 required `seaborn!=0.13.0`, while newer releases have been update to require `seaborn>=0.13.0` (when you look here on GitHub, you will find this updated requirement as you mentioned). If you want to use scanpy 1.9.6 for a specific reason, your environment should use a seaborn version that is not 0.13.x, e.g. the latest 0.12 version. Does upgrading to the latest scanpy version resolve this issue for you?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2791#issuecomment-1952249236
https://github.com/scverse/scanpy/issues/2791#issuecomment-1952249236:165,Deployability,update,updated,165,"Indeed scanpy 1.9.6 required `seaborn!=0.13.0`, while newer releases have been update to require `seaborn>=0.13.0` (when you look here on GitHub, you will find this updated requirement as you mentioned). If you want to use scanpy 1.9.6 for a specific reason, your environment should use a seaborn version that is not 0.13.x, e.g. the latest 0.12 version. Does upgrading to the latest scanpy version resolve this issue for you?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2791#issuecomment-1952249236
https://github.com/scverse/scanpy/pull/2792#issuecomment-1892277383:84,Testability,log,logic,84,"I think this looks pretty good. One thing we had discussed was moving out the merge logic for multiple batches from being specified by `flavor` to being specified by a different argument, maybe `merge_flavor` or `batch_flavor`. Have you thought about/ looked into this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2792#issuecomment-1892277383
https://github.com/scverse/scanpy/pull/2792#issuecomment-1892297913:164,Testability,log,logic,164,"I think this is orthogonal to that. The idea with having a separate argument for how we merge the results from different batches would mean factoring out the merge logic from each flavor and having it be a stand alone operation. It would also change the API here, since we wouldn't be adding a new `flavor`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2792#issuecomment-1892297913
https://github.com/scverse/scanpy/pull/2792#issuecomment-1892781138:308,Safety,risk,risk,308,"> One thing we had discussed was moving out the merge logic for multiple batches from being specified by `flavor` to being specified by a different argument, maybe `merge_flavor` or `batch_flavor`. Have you thought about/ looked into this?. I see what you mean. Not yet looked into that here, indeed. Slight risk of increasing confusion potential for users?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2792#issuecomment-1892781138
https://github.com/scverse/scanpy/pull/2792#issuecomment-1892781138:54,Testability,log,logic,54,"> One thing we had discussed was moving out the merge logic for multiple batches from being specified by `flavor` to being specified by a different argument, maybe `merge_flavor` or `batch_flavor`. Have you thought about/ looked into this?. I see what you mean. Not yet looked into that here, indeed. Slight risk of increasing confusion potential for users?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2792#issuecomment-1892781138
https://github.com/scverse/scanpy/pull/2792#issuecomment-1893265335:198,Modifiability,config,configure,198,"I think the two best ways to go forward:. - Either the Seurat people agree their implementation’s order is a bug and we switch to the paper order. Then we don’t _necessarily_ need to add any way to configure it, just to follow suit. But we could add a way to configure it to support different possible orderings; - Or they decide that it isn’t, in which case we should add that way to configure things. I think it makes more sense to encode orthogonal choices into orthogonal options. If it makes sense to offer a common set of orderings for all flavors, it should definitely be a separate option. E.g. if the following makes sense, then it should for sure be multiple options:. ```python; for flavor, order in product(; ('seurat_v3', 'seurat'),; ('rank', 'batches'),; ):; hvg(…, flavor=flavor, order=order); ```. (`order`, `'rank'`, and `'batches'` are ad-hoc names, not necessarily good ones)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2792#issuecomment-1893265335
https://github.com/scverse/scanpy/pull/2792#issuecomment-1893265335:259,Modifiability,config,configure,259,"I think the two best ways to go forward:. - Either the Seurat people agree their implementation’s order is a bug and we switch to the paper order. Then we don’t _necessarily_ need to add any way to configure it, just to follow suit. But we could add a way to configure it to support different possible orderings; - Or they decide that it isn’t, in which case we should add that way to configure things. I think it makes more sense to encode orthogonal choices into orthogonal options. If it makes sense to offer a common set of orderings for all flavors, it should definitely be a separate option. E.g. if the following makes sense, then it should for sure be multiple options:. ```python; for flavor, order in product(; ('seurat_v3', 'seurat'),; ('rank', 'batches'),; ):; hvg(…, flavor=flavor, order=order); ```. (`order`, `'rank'`, and `'batches'` are ad-hoc names, not necessarily good ones)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2792#issuecomment-1893265335
https://github.com/scverse/scanpy/pull/2792#issuecomment-1893265335:385,Modifiability,config,configure,385,"I think the two best ways to go forward:. - Either the Seurat people agree their implementation’s order is a bug and we switch to the paper order. Then we don’t _necessarily_ need to add any way to configure it, just to follow suit. But we could add a way to configure it to support different possible orderings; - Or they decide that it isn’t, in which case we should add that way to configure things. I think it makes more sense to encode orthogonal choices into orthogonal options. If it makes sense to offer a common set of orderings for all flavors, it should definitely be a separate option. E.g. if the following makes sense, then it should for sure be multiple options:. ```python; for flavor, order in product(; ('seurat_v3', 'seurat'),; ('rank', 'batches'),; ):; hvg(…, flavor=flavor, order=order); ```. (`order`, `'rank'`, and `'batches'` are ad-hoc names, not necessarily good ones)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2792#issuecomment-1893265335
https://github.com/scverse/scanpy/pull/2792#issuecomment-1919485285:372,Availability,mainten,maintenance,372,"What is there in the latest update:; - The simple adoption, at the heart of this PR, that `flavor=seurat_v3_paper` matches Seurat better when using `batch_key`.; - The `flavor=seurat_v3` remains untouched, hence not a breaking change.; - The doc is more detailed now. What is not there:; - Refactoring of single vs multi batch. Reason: While this effort will enhance code maintenance, it may quickly require almost the entire _highly_variable_genes.py to be touched. Suggest to do this thorough & separately?; - orthogonality of flavor and ordering. Reason: I think this is very hard to understand and match against other methods for users. . > If it makes sense to offer a common set of orderings for all flavors, it should definitely be a separate option. Does it make sense? There isn't benchmarking literature I know, and the flavors don't offer a decoupled ordering choice themselves. From user issues, I experience the consistency with other tools to be the primary concern.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2792#issuecomment-1919485285
https://github.com/scverse/scanpy/pull/2792#issuecomment-1919485285:28,Deployability,update,update,28,"What is there in the latest update:; - The simple adoption, at the heart of this PR, that `flavor=seurat_v3_paper` matches Seurat better when using `batch_key`.; - The `flavor=seurat_v3` remains untouched, hence not a breaking change.; - The doc is more detailed now. What is not there:; - Refactoring of single vs multi batch. Reason: While this effort will enhance code maintenance, it may quickly require almost the entire _highly_variable_genes.py to be touched. Suggest to do this thorough & separately?; - orthogonality of flavor and ordering. Reason: I think this is very hard to understand and match against other methods for users. . > If it makes sense to offer a common set of orderings for all flavors, it should definitely be a separate option. Does it make sense? There isn't benchmarking literature I know, and the flavors don't offer a decoupled ordering choice themselves. From user issues, I experience the consistency with other tools to be the primary concern.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2792#issuecomment-1919485285
https://github.com/scverse/scanpy/pull/2792#issuecomment-1919485285:290,Modifiability,Refactor,Refactoring,290,"What is there in the latest update:; - The simple adoption, at the heart of this PR, that `flavor=seurat_v3_paper` matches Seurat better when using `batch_key`.; - The `flavor=seurat_v3` remains untouched, hence not a breaking change.; - The doc is more detailed now. What is not there:; - Refactoring of single vs multi batch. Reason: While this effort will enhance code maintenance, it may quickly require almost the entire _highly_variable_genes.py to be touched. Suggest to do this thorough & separately?; - orthogonality of flavor and ordering. Reason: I think this is very hard to understand and match against other methods for users. . > If it makes sense to offer a common set of orderings for all flavors, it should definitely be a separate option. Does it make sense? There isn't benchmarking literature I know, and the flavors don't offer a decoupled ordering choice themselves. From user issues, I experience the consistency with other tools to be the primary concern.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2792#issuecomment-1919485285
https://github.com/scverse/scanpy/pull/2792#issuecomment-1919485285:359,Modifiability,enhance,enhance,359,"What is there in the latest update:; - The simple adoption, at the heart of this PR, that `flavor=seurat_v3_paper` matches Seurat better when using `batch_key`.; - The `flavor=seurat_v3` remains untouched, hence not a breaking change.; - The doc is more detailed now. What is not there:; - Refactoring of single vs multi batch. Reason: While this effort will enhance code maintenance, it may quickly require almost the entire _highly_variable_genes.py to be touched. Suggest to do this thorough & separately?; - orthogonality of flavor and ordering. Reason: I think this is very hard to understand and match against other methods for users. . > If it makes sense to offer a common set of orderings for all flavors, it should definitely be a separate option. Does it make sense? There isn't benchmarking literature I know, and the flavors don't offer a decoupled ordering choice themselves. From user issues, I experience the consistency with other tools to be the primary concern.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2792#issuecomment-1919485285
https://github.com/scverse/scanpy/pull/2792#issuecomment-1919485285:790,Testability,benchmark,benchmarking,790,"What is there in the latest update:; - The simple adoption, at the heart of this PR, that `flavor=seurat_v3_paper` matches Seurat better when using `batch_key`.; - The `flavor=seurat_v3` remains untouched, hence not a breaking change.; - The doc is more detailed now. What is not there:; - Refactoring of single vs multi batch. Reason: While this effort will enhance code maintenance, it may quickly require almost the entire _highly_variable_genes.py to be touched. Suggest to do this thorough & separately?; - orthogonality of flavor and ordering. Reason: I think this is very hard to understand and match against other methods for users. . > If it makes sense to offer a common set of orderings for all flavors, it should definitely be a separate option. Does it make sense? There isn't benchmarking literature I know, and the flavors don't offer a decoupled ordering choice themselves. From user issues, I experience the consistency with other tools to be the primary concern.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2792#issuecomment-1919485285
https://github.com/scverse/scanpy/pull/2792#issuecomment-1919485285:43,Usability,simpl,simple,43,"What is there in the latest update:; - The simple adoption, at the heart of this PR, that `flavor=seurat_v3_paper` matches Seurat better when using `batch_key`.; - The `flavor=seurat_v3` remains untouched, hence not a breaking change.; - The doc is more detailed now. What is not there:; - Refactoring of single vs multi batch. Reason: While this effort will enhance code maintenance, it may quickly require almost the entire _highly_variable_genes.py to be touched. Suggest to do this thorough & separately?; - orthogonality of flavor and ordering. Reason: I think this is very hard to understand and match against other methods for users. . > If it makes sense to offer a common set of orderings for all flavors, it should definitely be a separate option. Does it make sense? There isn't benchmarking literature I know, and the flavors don't offer a decoupled ordering choice themselves. From user issues, I experience the consistency with other tools to be the primary concern.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2792#issuecomment-1919485285
https://github.com/scverse/scanpy/pull/2792#issuecomment-1943677733:17,Deployability,release,release,17,OK! Please add a release note and we’re good to go I think.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2792#issuecomment-1943677733
https://github.com/scverse/scanpy/pull/2792#issuecomment-1944145708:19,Deployability,release,release,19,"> OK! Please add a release note and we’re good to go I think. Added note, under features",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2792#issuecomment-1944145708
https://github.com/scverse/scanpy/pull/2793#issuecomment-1868667393:234,Testability,test,tests,234,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2793?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Comparison is base [(`d7e7132`)](https://app.codecov.io/gh/scverse/scanpy/commit/d7e713258ba130b5b96c5c785e259c8140d59f3a?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.84% compared to head [(`d5f04fb`)](https://app.codecov.io/gh/scverse/scanpy/pull/2793?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.84%. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2793 +/- ##; =======================================; Coverage 72.84% 72.84% ; =======================================; Files 111 111 ; Lines 12382 12382 ; =======================================; Hits 9020 9020 ; Misses 3362 3362 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2793?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/preprocessing/\_docs.py](https://app.codecov.io/gh/scverse/scanpy/pull/2793?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX2RvY3MucHk=) | `100.00% <ø> (ø)` | |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2793#issuecomment-1868667393
https://github.com/scverse/scanpy/pull/2794#issuecomment-1869073837:234,Testability,test,tests,234,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2794?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Comparison is base [(`d7e7132`)](https://app.codecov.io/gh/scverse/scanpy/commit/d7e713258ba130b5b96c5c785e259c8140d59f3a?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.84% compared to head [(`d5144ce`)](https://app.codecov.io/gh/scverse/scanpy/pull/2794?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.84%. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2794 +/- ##; =======================================; Coverage 72.84% 72.84% ; =======================================; Files 111 111 ; Lines 12382 12382 ; =======================================; Hits 9020 9020 ; Misses 3362 3362 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2794?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/plotting/\_baseplot\_class.py](https://app.codecov.io/gh/scverse/scanpy/pull/2794?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL19iYXNlcGxvdF9jbGFzcy5weQ==) | `90.14% <ø> (ø)` | |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2794#issuecomment-1869073837
https://github.com/scverse/scanpy/pull/2796#issuecomment-1870329572:405,Availability,error,error-reference,405,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2796?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > :exclamation: No coverage uploaded for pull request base (`1.9.x@1daae5b`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2796 +/- ##; ========================================; Coverage ? 71.35% ; ========================================; Files ? 103 ; Lines ? 11645 ; Branches ? 0 ; ========================================; Hits ? 8309 ; Misses ? 3336 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2796#issuecomment-1870329572
https://github.com/scverse/scanpy/pull/2796#issuecomment-1870329572:234,Testability,test,tests,234,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2796?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > :exclamation: No coverage uploaded for pull request base (`1.9.x@1daae5b`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2796 +/- ##; ========================================; Coverage ? 71.35% ; ========================================; Files ? 103 ; Lines ? 11645 ; Branches ? 0 ; ========================================; Hits ? 8309 ; Misses ? 3336 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2796#issuecomment-1870329572
https://github.com/scverse/scanpy/pull/2796#issuecomment-1870329572:353,Usability,learn,learn,353,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2796?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > :exclamation: No coverage uploaded for pull request base (`1.9.x@1daae5b`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2796 +/- ##; ========================================; Coverage ? 71.35% ; ========================================; Files ? 103 ; Lines ? 11645 ; Branches ? 0 ; ========================================; Hits ? 8309 ; Misses ? 3336 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2796#issuecomment-1870329572
https://github.com/scverse/scanpy/pull/2798#issuecomment-1879728557:234,Testability,test,tests,234,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2798?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Comparison is base [(`86b85ee`)](https://app.codecov.io/gh/scverse/scanpy/commit/86b85ee2f4e8acfc9db3ce4cfff6e905d96a59eb?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.72% compared to head [(`7da3064`)](https://app.codecov.io/gh/scverse/scanpy/pull/2798?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.83%. > :exclamation: Current head 7da3064 differs from pull request most recent head 8a1e576. Consider uploading reports for the commit 8a1e576 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2798 +/- ##; ==========================================; + Coverage 72.72% 72.83% +0.11% ; ==========================================; Files 111 111 ; Lines 12384 12367 -17 ; ==========================================; + Hits 9006 9008 +2 ; + Misses 3378 3359 -19 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2798?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/tools/\_rank\_genes\_groups.py](https://app.codecov.io/gh/scverse/scanpy/pull/2798?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rvb2xzL19yYW5rX2dlbmVzX2dyb3Vwcy5weQ==) | `94.33% <ø> (-0.02%)` | :arrow_down: |. ... and [4 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2798/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scv,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2798#issuecomment-1879728557
https://github.com/scverse/scanpy/pull/2798#issuecomment-1882964041:20,Deployability,patch,patch,20,"Great, but not in a patch release. We should do a feature release really soon anyway. Please add a release note, then this can be merged.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2798#issuecomment-1882964041
https://github.com/scverse/scanpy/pull/2798#issuecomment-1882964041:26,Deployability,release,release,26,"Great, but not in a patch release. We should do a feature release really soon anyway. Please add a release note, then this can be merged.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2798#issuecomment-1882964041
https://github.com/scverse/scanpy/pull/2798#issuecomment-1882964041:58,Deployability,release,release,58,"Great, but not in a patch release. We should do a feature release really soon anyway. Please add a release note, then this can be merged.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2798#issuecomment-1882964041
https://github.com/scverse/scanpy/pull/2798#issuecomment-1882964041:99,Deployability,release,release,99,"Great, but not in a patch release. We should do a feature release really soon anyway. Please add a release note, then this can be merged.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2798#issuecomment-1882964041
https://github.com/scverse/scanpy/pull/2798#issuecomment-1884401677:53,Deployability,release,release,53,"@flying-sheep Thought it'd be minor enough to skip a release note, but I added one now. Thanks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2798#issuecomment-1884401677
https://github.com/scverse/scanpy/pull/2798#issuecomment-1885167604:13,Availability,error,errors,13,Several HTTP errors,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2798#issuecomment-1885167604
https://github.com/scverse/scanpy/pull/2799#issuecomment-1881589152:234,Testability,test,tests,234,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2799?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Comparison is base [(`9b08d35`)](https://app.codecov.io/gh/scverse/scanpy/commit/9b08d35f00fc727d0b3c15f15bcb4059cd8055ac?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.84% compared to head [(`554567f`)](https://app.codecov.io/gh/scverse/scanpy/pull/2799?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.84%. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2799 +/- ##; =======================================; Coverage 72.84% 72.84% ; =======================================; Files 111 111 ; Lines 12367 12367 ; =======================================; Hits 9009 9009 ; Misses 3358 3358 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2799#issuecomment-1881589152
https://github.com/scverse/scanpy/pull/2799#issuecomment-1882962300:157,Deployability,update,update,157,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 c410cd123f5487f25c08b421c8d06da50551ff73; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2799: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2799-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2799 on branch 1.9.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2799#issuecomment-1882962300
https://github.com/scverse/scanpy/pull/2799#issuecomment-1882962300:913,Deployability,continuous,continuous,913,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 c410cd123f5487f25c08b421c8d06da50551ff73; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2799: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2799-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2799 on branch 1.9.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2799#issuecomment-1882962300
https://github.com/scverse/scanpy/pull/2799#issuecomment-1882962300:924,Deployability,integrat,integration,924,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 c410cd123f5487f25c08b421c8d06da50551ff73; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2799: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2799-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2799 on branch 1.9.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2799#issuecomment-1882962300
https://github.com/scverse/scanpy/pull/2799#issuecomment-1882962300:924,Integrability,integrat,integration,924,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 c410cd123f5487f25c08b421c8d06da50551ff73; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2799: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2799-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2799 on branch 1.9.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2799#issuecomment-1882962300
https://github.com/scverse/scanpy/pull/2799#issuecomment-1882962300:899,Testability,test,tested,899,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 c410cd123f5487f25c08b421c8d06da50551ff73; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2799: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2799-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2799 on branch 1.9.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2799#issuecomment-1882962300
https://github.com/scverse/scanpy/pull/2801#issuecomment-1882788091:234,Testability,test,tests,234,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2801?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Comparison is base [(`61c6944`)](https://app.codecov.io/gh/scverse/scanpy/commit/61c6944f6d7014dc8ca9e886ce16ff79abedfc49?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.84% compared to head [(`8c4ff13`)](https://app.codecov.io/gh/scverse/scanpy/pull/2801?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.84%. > :exclamation: Current head 8c4ff13 differs from pull request most recent head ecc6337. Consider uploading reports for the commit ecc6337 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2801 +/- ##; =======================================; Coverage 72.84% 72.84% ; =======================================; Files 111 111 ; Lines 12382 12382 ; =======================================; Hits 9020 9020 ; Misses 3362 3362 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2801?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/readwrite.py](https://app.codecov.io/gh/scverse/scanpy/pull/2801?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3JlYWR3cml0ZS5weQ==) | `68.33% <100.00%> (ø)` | |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2801#issuecomment-1882788091
https://github.com/scverse/scanpy/pull/2803#issuecomment-1886074390:252,Testability,test,tests,252,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2803?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Project coverage is 72.84%. Comparing base [(`c410cd1`)](https://app.codecov.io/gh/scverse/scanpy/commit/c410cd123f5487f25c08b421c8d06da50551ff73?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`88d721c`)](https://app.codecov.io/gh/scverse/scanpy/pull/2803?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 76 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2803 +/- ##; =======================================; Coverage 72.84% 72.84% ; =======================================; Files 111 111 ; Lines 12368 12368 ; =======================================; Hits 9009 9009 ; Misses 3359 3359 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2803?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/tools/\_tsne.py](https://app.codecov.io/gh/scverse/scanpy/pull/2803?src=pr&el=tree&filepath=scanpy%2Ftools%2F_tsne.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rvb2xzL190c25lLnB5) | `90.69% <ø> (ø)` | |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2803#issuecomment-1886074390
https://github.com/scverse/scanpy/issues/2804#issuecomment-2006642107:77,Deployability,install,install,77,Thanks for the investigation! @metoru can you try with #2928?. ```shell; pip install git+https://github.com/scverse/scanpy.git@fix-dendro-corr; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2804#issuecomment-2006642107
https://github.com/scverse/scanpy/issues/2804#issuecomment-2012516645:70,Testability,test,test,70,"@THZ34 can you create a reproducer where this happens, so I can add a test?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2804#issuecomment-2012516645
https://github.com/scverse/scanpy/issues/2804#issuecomment-2014432043:270,Availability,error,error,270,"> @THZ34 can you create a reproducer where this happens, so I can add a test?. OK, I've upload the h5ad file to onedrive: https://bioplot-my.sharepoint.com/:u:/g/personal/tanghongzhen_bioplot_onmicrosoft_com/EUbNHPuin5pGuMPrmch6rsQBjHojfikr38EYgZEL4KAZ2A?e=T2YfkO.; The error will reapper in these code:; import anndata; import scanpy as sc; adata = ad.read_h5ad('debug.h5ad'); sc.tl.dendrogram(adata,groupby='leiden')",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2804#issuecomment-2014432043
https://github.com/scverse/scanpy/issues/2804#issuecomment-2014432043:72,Testability,test,test,72,"> @THZ34 can you create a reproducer where this happens, so I can add a test?. OK, I've upload the h5ad file to onedrive: https://bioplot-my.sharepoint.com/:u:/g/personal/tanghongzhen_bioplot_onmicrosoft_com/EUbNHPuin5pGuMPrmch6rsQBjHojfikr38EYgZEL4KAZ2A?e=T2YfkO.; The error will reapper in these code:; import anndata; import scanpy as sc; adata = ad.read_h5ad('debug.h5ad'); sc.tl.dendrogram(adata,groupby='leiden')",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2804#issuecomment-2014432043
https://github.com/scverse/scanpy/pull/2805#issuecomment-1886674471:234,Testability,test,tests,234,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2805?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Comparison is base [(`c410cd1`)](https://app.codecov.io/gh/scverse/scanpy/commit/c410cd123f5487f25c08b421c8d06da50551ff73?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.84% compared to head [(`db26f06`)](https://app.codecov.io/gh/scverse/scanpy/pull/2805?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.70%. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2805 +/- ##; ==========================================; - Coverage 72.84% 72.70% -0.14% ; ==========================================; Files 111 111 ; Lines 12368 12368 ; ==========================================; - Hits 9009 8992 -17 ; - Misses 3359 3376 +17 ; ```. [see 1 file with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2805/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2805#issuecomment-1886674471
https://github.com/scverse/scanpy/pull/2805#issuecomment-1889299384:60,Deployability,release,released,60,"OK, done! https://github.com/theislab/scanpydoc/pull/128 is released and this PR is updated. I’m not touching the `/` shortcut: meta/ctrl+k is advertised in a prominent spot and I don’t want to accidentally swallow a user trying to type `/` somewhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2805#issuecomment-1889299384
https://github.com/scverse/scanpy/pull/2805#issuecomment-1889299384:84,Deployability,update,updated,84,"OK, done! https://github.com/theislab/scanpydoc/pull/128 is released and this PR is updated. I’m not touching the `/` shortcut: meta/ctrl+k is advertised in a prominent spot and I don’t want to accidentally swallow a user trying to type `/` somewhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2805#issuecomment-1889299384
https://github.com/scverse/scanpy/pull/2805#issuecomment-1889665103:344,Usability,simpl,simple,344,"> Are any improvements here reasonably easy to do? I recognize that it's making two libraries talk to each other, and at least one of them can't be totally turned off, so this might be difficult. yes, both things are quite easy, I think. Event listeners can be registered in a way that they don’t capture the event, and toggling the popup is a simple `if (isModalVisible()) removeSearchModal() else showSearchModal()`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2805#issuecomment-1889665103
https://github.com/scverse/scanpy/issues/2806#issuecomment-1892881600:75,Availability,Down,Downgrade,75,I have the same problem. Didn't expect it is due to the anndata package. ; Downgrade anndata to 0.10.2 solve this problem.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2806#issuecomment-1892881600
https://github.com/scverse/scanpy/issues/2806#issuecomment-1893367676:84,Deployability,install,installing,84,"OK, this is indeed fixed in scanpy master and the bugfix branch (1.9.x). Please try installing the current bugfix branch:. ```bash; pip install 'scanpy @ git+https://github.com/scverse/scanpy.git@1.9.x'; ```. We will release a new feature version in 3 weeks, so there will probably be no bugfix release before that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2806#issuecomment-1893367676
https://github.com/scverse/scanpy/issues/2806#issuecomment-1893367676:136,Deployability,install,install,136,"OK, this is indeed fixed in scanpy master and the bugfix branch (1.9.x). Please try installing the current bugfix branch:. ```bash; pip install 'scanpy @ git+https://github.com/scverse/scanpy.git@1.9.x'; ```. We will release a new feature version in 3 weeks, so there will probably be no bugfix release before that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2806#issuecomment-1893367676
https://github.com/scverse/scanpy/issues/2806#issuecomment-1893367676:217,Deployability,release,release,217,"OK, this is indeed fixed in scanpy master and the bugfix branch (1.9.x). Please try installing the current bugfix branch:. ```bash; pip install 'scanpy @ git+https://github.com/scverse/scanpy.git@1.9.x'; ```. We will release a new feature version in 3 weeks, so there will probably be no bugfix release before that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2806#issuecomment-1893367676
https://github.com/scverse/scanpy/issues/2806#issuecomment-1893367676:295,Deployability,release,release,295,"OK, this is indeed fixed in scanpy master and the bugfix branch (1.9.x). Please try installing the current bugfix branch:. ```bash; pip install 'scanpy @ git+https://github.com/scverse/scanpy.git@1.9.x'; ```. We will release a new feature version in 3 weeks, so there will probably be no bugfix release before that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2806#issuecomment-1893367676
https://github.com/scverse/scanpy/pull/2809#issuecomment-1906001725:0,Availability,Error,Error,0,"Error when trying this where `X` is a dask array with sparse chunks:. ```python; result = sc.pp.highly_variable_genes(adata, inplace=False); ```. <details>; <summary> Traceback </summary>. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); File /mnt/workspace/mambaforge/envs/scanpy-dev/lib/python3.11/site-packages/dask/array/reductions.py:363, in partial_reduce(func, x, split_every, keepdims, dtype, name, reduced_meta); 362 try:; --> 363 meta = func(reduced_meta, computing_meta=True); 364 # no meta keyword argument exists for func, and it isn't required. File /mnt/workspace/mambaforge/envs/scanpy-dev/lib/python3.11/site-packages/dask/array/reductions.py:685, in mean_combine(pairs, sum, numel, dtype, axis, computing_meta, **kwargs); 684 ns = deepmap(lambda pair: pair[""n""], pairs) if not computing_meta else pairs; --> 685 n = _concatenate2(ns, axes=axis).sum(axis=axis, **kwargs); 687 if computing_meta:. TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'. During handling of the above exception, another exception occurred:. IndexError Traceback (most recent call last); Cell In[19], line 1; ----> 1 result = sc.pp.highly_variable_genes(adata, inplace=False); 2 result. File /mnt/workspace/mambaforge/envs/scanpy-dev/lib/python3.11/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw); 77 @wraps(fn); 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:; 79 if len(args_all) <= n_positional:; ---> 80 return fn(*args_all, **kw); 82 args_pos: P.args; 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /mnt/workspace/repos/scanpy/scanpy/preprocessing/_highly_variable_genes.py:702, in highly_variable_genes(***failed resolving arguments***); 699 del min_disp, max_disp, min_mean, max_mean, n_top_genes; 701 if batch_key is None:; --> 702 df = _highly_variable_genes_single_batch(; 703 a",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1906001725
https://github.com/scverse/scanpy/pull/2809#issuecomment-1906001725:1415,Integrability,wrap,wrapper,1415,"y:363, in partial_reduce(func, x, split_every, keepdims, dtype, name, reduced_meta); 362 try:; --> 363 meta = func(reduced_meta, computing_meta=True); 364 # no meta keyword argument exists for func, and it isn't required. File /mnt/workspace/mambaforge/envs/scanpy-dev/lib/python3.11/site-packages/dask/array/reductions.py:685, in mean_combine(pairs, sum, numel, dtype, axis, computing_meta, **kwargs); 684 ns = deepmap(lambda pair: pair[""n""], pairs) if not computing_meta else pairs; --> 685 n = _concatenate2(ns, axes=axis).sum(axis=axis, **kwargs); 687 if computing_meta:. TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'. During handling of the above exception, another exception occurred:. IndexError Traceback (most recent call last); Cell In[19], line 1; ----> 1 result = sc.pp.highly_variable_genes(adata, inplace=False); 2 result. File /mnt/workspace/mambaforge/envs/scanpy-dev/lib/python3.11/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw); 77 @wraps(fn); 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:; 79 if len(args_all) <= n_positional:; ---> 80 return fn(*args_all, **kw); 82 args_pos: P.args; 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /mnt/workspace/repos/scanpy/scanpy/preprocessing/_highly_variable_genes.py:702, in highly_variable_genes(***failed resolving arguments***); 699 del min_disp, max_disp, min_mean, max_mean, n_top_genes; 701 if batch_key is None:; --> 702 df = _highly_variable_genes_single_batch(; 703 adata, layer=layer, cutoff=cutoff, n_bins=n_bins, flavor=flavor; 704 ); 705 else:; 706 df = _highly_variable_genes_batched(; 707 adata, batch_key, layer=layer, cutoff=cutoff, n_bins=n_bins, flavor=flavor; 708 ). File /mnt/workspace/repos/scanpy/scanpy/preprocessing/_highly_variable_genes.py:274, in _highly_variable_genes_single_batch(adata, layer, cutoff, n_bins, flavor); 271 else:; 272 X = np.expm1(X); --> 274 mean",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1906001725
https://github.com/scverse/scanpy/pull/2809#issuecomment-1906001725:1468,Integrability,wrap,wraps,1468,"ms, dtype, name, reduced_meta); 362 try:; --> 363 meta = func(reduced_meta, computing_meta=True); 364 # no meta keyword argument exists for func, and it isn't required. File /mnt/workspace/mambaforge/envs/scanpy-dev/lib/python3.11/site-packages/dask/array/reductions.py:685, in mean_combine(pairs, sum, numel, dtype, axis, computing_meta, **kwargs); 684 ns = deepmap(lambda pair: pair[""n""], pairs) if not computing_meta else pairs; --> 685 n = _concatenate2(ns, axes=axis).sum(axis=axis, **kwargs); 687 if computing_meta:. TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'. During handling of the above exception, another exception occurred:. IndexError Traceback (most recent call last); Cell In[19], line 1; ----> 1 result = sc.pp.highly_variable_genes(adata, inplace=False); 2 result. File /mnt/workspace/mambaforge/envs/scanpy-dev/lib/python3.11/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw); 77 @wraps(fn); 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:; 79 if len(args_all) <= n_positional:; ---> 80 return fn(*args_all, **kw); 82 args_pos: P.args; 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /mnt/workspace/repos/scanpy/scanpy/preprocessing/_highly_variable_genes.py:702, in highly_variable_genes(***failed resolving arguments***); 699 del min_disp, max_disp, min_mean, max_mean, n_top_genes; 701 if batch_key is None:; --> 702 df = _highly_variable_genes_single_batch(; 703 adata, layer=layer, cutoff=cutoff, n_bins=n_bins, flavor=flavor; 704 ); 705 else:; 706 df = _highly_variable_genes_batched(; 707 adata, batch_key, layer=layer, cutoff=cutoff, n_bins=n_bins, flavor=flavor; 708 ). File /mnt/workspace/repos/scanpy/scanpy/preprocessing/_highly_variable_genes.py:274, in _highly_variable_genes_single_batch(adata, layer, cutoff, n_bins, flavor); 271 else:; 272 X = np.expm1(X); --> 274 mean, var = _get_mean_var(X); 275 # now actually compute t",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1906001725
https://github.com/scverse/scanpy/pull/2809#issuecomment-1906123122:187,Availability,error,errors,187,"Are we committing to support sparse-in-dask?. I’m defaulting to `ARRAY_TYPES_SUPPORTED`, which marks sparse as xfail. That’s how we treat other dask-capable utils so far. You can see the errors with. ```console; $ pytest -vv --runxfail scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_{subset_inplace_consistency,no_inplace} -k sparse; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-full-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-subset-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-subset-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-full-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-full-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-subset-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-subset-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_su",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1906123122
https://github.com/scverse/scanpy/pull/2809#issuecomment-1906123122:243,Testability,test,tests,243,"Are we committing to support sparse-in-dask?. I’m defaulting to `ARRAY_TYPES_SUPPORTED`, which marks sparse as xfail. That’s how we treat other dask-capable utils so far. You can see the errors with. ```console; $ pytest -vv --runxfail scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_{subset_inplace_consistency,no_inplace} -k sparse; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-full-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-subset-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-subset-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-full-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-full-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-subset-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-subset-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_su",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1906123122
https://github.com/scverse/scanpy/pull/2809#issuecomment-1906123122:372,Testability,test,tests,372,"Are we committing to support sparse-in-dask?. I’m defaulting to `ARRAY_TYPES_SUPPORTED`, which marks sparse as xfail. That’s how we treat other dask-capable utils so far. You can see the errors with. ```console; $ pytest -vv --runxfail scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_{subset_inplace_consistency,no_inplace} -k sparse; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-full-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-subset-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-subset-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-full-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-full-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-subset-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-subset-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_su",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1906123122
https://github.com/scverse/scanpy/pull/2809#issuecomment-1906123122:595,Testability,test,tests,595,"Are we committing to support sparse-in-dask?. I’m defaulting to `ARRAY_TYPES_SUPPORTED`, which marks sparse as xfail. That’s how we treat other dask-capable utils so far. You can see the errors with. ```console; $ pytest -vv --runxfail scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_{subset_inplace_consistency,no_inplace} -k sparse; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-full-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-subset-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-subset-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-full-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-full-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-subset-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-subset-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_su",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1906123122
https://github.com/scverse/scanpy/pull/2809#issuecomment-1906123122:820,Testability,test,tests,820,"Are we committing to support sparse-in-dask?. I’m defaulting to `ARRAY_TYPES_SUPPORTED`, which marks sparse as xfail. That’s how we treat other dask-capable utils so far. You can see the errors with. ```console; $ pytest -vv --runxfail scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_{subset_inplace_consistency,no_inplace} -k sparse; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-full-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-subset-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-subset-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-full-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-full-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-subset-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-subset-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_su",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1906123122
https://github.com/scverse/scanpy/pull/2809#issuecomment-1906123122:1048,Testability,test,tests,1048,"arse-in-dask?. I’m defaulting to `ARRAY_TYPES_SUPPORTED`, which marks sparse as xfail. That’s how we treat other dask-capable utils so far. You can see the errors with. ```console; $ pytest -vv --runxfail scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_{subset_inplace_consistency,no_inplace} -k sparse; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-full-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-subset-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-subset-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-full-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-full-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-subset-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-subset-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inpla",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1906123122
https://github.com/scverse/scanpy/pull/2809#issuecomment-1906123122:1274,Testability,test,tests,1274,"hly_variable_genes.py::test_highly_variable_genes_{subset_inplace_consistency,no_inplace} -k sparse; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-full-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-subset-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-subset-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-full-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-full-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-subset-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-subset-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-full-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_no_inplace[dask_array_sparse-batched]",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1906123122
https://github.com/scverse/scanpy/pull/2809#issuecomment-1906123122:1492,Testability,test,tests,1492,sk_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-subset-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-subset-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-full-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-full-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-subset-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-subset-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-full-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_no_inplace[dask_array_sparse-batched] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_no_inplace[dask_array_sparse-single] - IndexError: Index dimen,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1906123122
https://github.com/scverse/scanpy/pull/2809#issuecomment-1906123122:1715,Testability,test,tests,1715,ger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-subset-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-subset-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-full-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-full-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-subset-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-subset-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-full-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_no_inplace[dask_array_sparse-batched] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_no_inplace[dask_array_sparse-single] - IndexError: Index dimension must be 1 or 2; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1906123122
https://github.com/scverse/scanpy/pull/2809#issuecomment-1906123122:1935,Testability,test,tests,1935,ger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-subset-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-subset-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-full-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-full-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-subset-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-subset-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-full-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_no_inplace[dask_array_sparse-batched] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_no_inplace[dask_array_sparse-single] - IndexError: Index dimension must be 1 or 2; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1906123122
https://github.com/scverse/scanpy/pull/2809#issuecomment-1906123122:2156,Testability,test,tests,2156,ger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-subset-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-subset-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-full-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-full-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-subset-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-subset-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-full-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_no_inplace[dask_array_sparse-batched] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_no_inplace[dask_array_sparse-single] - IndexError: Index dimension must be 1 or 2; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1906123122
https://github.com/scverse/scanpy/pull/2809#issuecomment-1906123122:2349,Testability,test,tests,2349,ger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-subset-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-subset-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-full-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-full-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-subset-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-subset-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-full-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_no_inplace[dask_array_sparse-batched] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_no_inplace[dask_array_sparse-single] - IndexError: Index dimension must be 1 or 2; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1906123122
https://github.com/scverse/scanpy/pull/2809#issuecomment-1910279573:77,Availability,failure,failures,77,"OK, this should be mostly it. Maybe some cleanup, but no major changes. Test failures are all the server for `ebi_expression_atlas` breaking.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1910279573
https://github.com/scverse/scanpy/pull/2809#issuecomment-1910279573:72,Testability,Test,Test,72,"OK, this should be mostly it. Maybe some cleanup, but no major changes. Test failures are all the server for `ebi_expression_atlas` breaking.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1910279573
https://github.com/scverse/scanpy/pull/2809#issuecomment-1929321140:1475,Deployability,integrat,integrated,1475,"> there is still a large amount of changes to the dataframe code here. Not really changes: it’s almost all refactoring, because the code was spaghetti with quite some duplication. I’m doing nothing more than. 1. I introduce helper functions so code gets more readable, e.g. a clean `disp_cut_off = _nth_highest(dispersion_norm, n_top_genes)` instead of a large inline code block that has to be decyphered line by line to figure out that it finds the nth highest value. This is especially necessary for the huge main pile of spaghetti that used to be the `if flavor == ""seurat"":`/`elif flavor == ""cell_ranger"":` branches. I simply put their contents into a `_get_mean_bins` helper and two helpers `_stats_seurat` and `_stats_cell_ranger` (while deduplicating shared code); 2. Making sure pandas indices match up while removing `.to_numpy()`. That way instead of having `.to_numpy()` potentially copy and and convert data in extension arrays, the series are just used directly. Not to mention that three `.to_numpy()` per line make things hard to read.; 3. refactor the 5 cutoff parameters into one value `cutoff` for clarity, less inline code, and better type information (we either have either `n_top_genes: int` or a `_Cutoffs` instance, never both. This way, the type system knows). and that’s it. <ins>potentially</ins> faster, much more maintainable, and almost dask-compatible. After my changes, it should be easier to further refactor things so the seurat_v3 flavor is integrated into the overall structure instead of doing its own thing.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1929321140
https://github.com/scverse/scanpy/pull/2809#issuecomment-1929321140:1475,Integrability,integrat,integrated,1475,"> there is still a large amount of changes to the dataframe code here. Not really changes: it’s almost all refactoring, because the code was spaghetti with quite some duplication. I’m doing nothing more than. 1. I introduce helper functions so code gets more readable, e.g. a clean `disp_cut_off = _nth_highest(dispersion_norm, n_top_genes)` instead of a large inline code block that has to be decyphered line by line to figure out that it finds the nth highest value. This is especially necessary for the huge main pile of spaghetti that used to be the `if flavor == ""seurat"":`/`elif flavor == ""cell_ranger"":` branches. I simply put their contents into a `_get_mean_bins` helper and two helpers `_stats_seurat` and `_stats_cell_ranger` (while deduplicating shared code); 2. Making sure pandas indices match up while removing `.to_numpy()`. That way instead of having `.to_numpy()` potentially copy and and convert data in extension arrays, the series are just used directly. Not to mention that three `.to_numpy()` per line make things hard to read.; 3. refactor the 5 cutoff parameters into one value `cutoff` for clarity, less inline code, and better type information (we either have either `n_top_genes: int` or a `_Cutoffs` instance, never both. This way, the type system knows). and that’s it. <ins>potentially</ins> faster, much more maintainable, and almost dask-compatible. After my changes, it should be easier to further refactor things so the seurat_v3 flavor is integrated into the overall structure instead of doing its own thing.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1929321140
https://github.com/scverse/scanpy/pull/2809#issuecomment-1929321140:107,Modifiability,refactor,refactoring,107,"> there is still a large amount of changes to the dataframe code here. Not really changes: it’s almost all refactoring, because the code was spaghetti with quite some duplication. I’m doing nothing more than. 1. I introduce helper functions so code gets more readable, e.g. a clean `disp_cut_off = _nth_highest(dispersion_norm, n_top_genes)` instead of a large inline code block that has to be decyphered line by line to figure out that it finds the nth highest value. This is especially necessary for the huge main pile of spaghetti that used to be the `if flavor == ""seurat"":`/`elif flavor == ""cell_ranger"":` branches. I simply put their contents into a `_get_mean_bins` helper and two helpers `_stats_seurat` and `_stats_cell_ranger` (while deduplicating shared code); 2. Making sure pandas indices match up while removing `.to_numpy()`. That way instead of having `.to_numpy()` potentially copy and and convert data in extension arrays, the series are just used directly. Not to mention that three `.to_numpy()` per line make things hard to read.; 3. refactor the 5 cutoff parameters into one value `cutoff` for clarity, less inline code, and better type information (we either have either `n_top_genes: int` or a `_Cutoffs` instance, never both. This way, the type system knows). and that’s it. <ins>potentially</ins> faster, much more maintainable, and almost dask-compatible. After my changes, it should be easier to further refactor things so the seurat_v3 flavor is integrated into the overall structure instead of doing its own thing.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1929321140
https://github.com/scverse/scanpy/pull/2809#issuecomment-1929321140:1055,Modifiability,refactor,refactor,1055,"> there is still a large amount of changes to the dataframe code here. Not really changes: it’s almost all refactoring, because the code was spaghetti with quite some duplication. I’m doing nothing more than. 1. I introduce helper functions so code gets more readable, e.g. a clean `disp_cut_off = _nth_highest(dispersion_norm, n_top_genes)` instead of a large inline code block that has to be decyphered line by line to figure out that it finds the nth highest value. This is especially necessary for the huge main pile of spaghetti that used to be the `if flavor == ""seurat"":`/`elif flavor == ""cell_ranger"":` branches. I simply put their contents into a `_get_mean_bins` helper and two helpers `_stats_seurat` and `_stats_cell_ranger` (while deduplicating shared code); 2. Making sure pandas indices match up while removing `.to_numpy()`. That way instead of having `.to_numpy()` potentially copy and and convert data in extension arrays, the series are just used directly. Not to mention that three `.to_numpy()` per line make things hard to read.; 3. refactor the 5 cutoff parameters into one value `cutoff` for clarity, less inline code, and better type information (we either have either `n_top_genes: int` or a `_Cutoffs` instance, never both. This way, the type system knows). and that’s it. <ins>potentially</ins> faster, much more maintainable, and almost dask-compatible. After my changes, it should be easier to further refactor things so the seurat_v3 flavor is integrated into the overall structure instead of doing its own thing.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1929321140
https://github.com/scverse/scanpy/pull/2809#issuecomment-1929321140:1341,Modifiability,maintainab,maintainable,1341,"> there is still a large amount of changes to the dataframe code here. Not really changes: it’s almost all refactoring, because the code was spaghetti with quite some duplication. I’m doing nothing more than. 1. I introduce helper functions so code gets more readable, e.g. a clean `disp_cut_off = _nth_highest(dispersion_norm, n_top_genes)` instead of a large inline code block that has to be decyphered line by line to figure out that it finds the nth highest value. This is especially necessary for the huge main pile of spaghetti that used to be the `if flavor == ""seurat"":`/`elif flavor == ""cell_ranger"":` branches. I simply put their contents into a `_get_mean_bins` helper and two helpers `_stats_seurat` and `_stats_cell_ranger` (while deduplicating shared code); 2. Making sure pandas indices match up while removing `.to_numpy()`. That way instead of having `.to_numpy()` potentially copy and and convert data in extension arrays, the series are just used directly. Not to mention that three `.to_numpy()` per line make things hard to read.; 3. refactor the 5 cutoff parameters into one value `cutoff` for clarity, less inline code, and better type information (we either have either `n_top_genes: int` or a `_Cutoffs` instance, never both. This way, the type system knows). and that’s it. <ins>potentially</ins> faster, much more maintainable, and almost dask-compatible. After my changes, it should be easier to further refactor things so the seurat_v3 flavor is integrated into the overall structure instead of doing its own thing.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1929321140
https://github.com/scverse/scanpy/pull/2809#issuecomment-1929321140:1432,Modifiability,refactor,refactor,1432,"> there is still a large amount of changes to the dataframe code here. Not really changes: it’s almost all refactoring, because the code was spaghetti with quite some duplication. I’m doing nothing more than. 1. I introduce helper functions so code gets more readable, e.g. a clean `disp_cut_off = _nth_highest(dispersion_norm, n_top_genes)` instead of a large inline code block that has to be decyphered line by line to figure out that it finds the nth highest value. This is especially necessary for the huge main pile of spaghetti that used to be the `if flavor == ""seurat"":`/`elif flavor == ""cell_ranger"":` branches. I simply put their contents into a `_get_mean_bins` helper and two helpers `_stats_seurat` and `_stats_cell_ranger` (while deduplicating shared code); 2. Making sure pandas indices match up while removing `.to_numpy()`. That way instead of having `.to_numpy()` potentially copy and and convert data in extension arrays, the series are just used directly. Not to mention that three `.to_numpy()` per line make things hard to read.; 3. refactor the 5 cutoff parameters into one value `cutoff` for clarity, less inline code, and better type information (we either have either `n_top_genes: int` or a `_Cutoffs` instance, never both. This way, the type system knows). and that’s it. <ins>potentially</ins> faster, much more maintainable, and almost dask-compatible. After my changes, it should be easier to further refactor things so the seurat_v3 flavor is integrated into the overall structure instead of doing its own thing.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1929321140
https://github.com/scverse/scanpy/pull/2809#issuecomment-1929321140:623,Usability,simpl,simply,623,"> there is still a large amount of changes to the dataframe code here. Not really changes: it’s almost all refactoring, because the code was spaghetti with quite some duplication. I’m doing nothing more than. 1. I introduce helper functions so code gets more readable, e.g. a clean `disp_cut_off = _nth_highest(dispersion_norm, n_top_genes)` instead of a large inline code block that has to be decyphered line by line to figure out that it finds the nth highest value. This is especially necessary for the huge main pile of spaghetti that used to be the `if flavor == ""seurat"":`/`elif flavor == ""cell_ranger"":` branches. I simply put their contents into a `_get_mean_bins` helper and two helpers `_stats_seurat` and `_stats_cell_ranger` (while deduplicating shared code); 2. Making sure pandas indices match up while removing `.to_numpy()`. That way instead of having `.to_numpy()` potentially copy and and convert data in extension arrays, the series are just used directly. Not to mention that three `.to_numpy()` per line make things hard to read.; 3. refactor the 5 cutoff parameters into one value `cutoff` for clarity, less inline code, and better type information (we either have either `n_top_genes: int` or a `_Cutoffs` instance, never both. This way, the type system knows). and that’s it. <ins>potentially</ins> faster, much more maintainable, and almost dask-compatible. After my changes, it should be easier to further refactor things so the seurat_v3 flavor is integrated into the overall structure instead of doing its own thing.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1929321140
https://github.com/scverse/scanpy/pull/2809#issuecomment-1930104931:627,Deployability,update,update,627,"> I wasn't really expecting this feature PR to also include such a large refactor. It would have been necessary for the Dask Dataframe version. Now I 1. did the work and 2. improved readability, so it would be counter productive to undo it. > I'm still not 100% convinced the behaviour here is exactly the same as before. I have done a few tests, which have been okay, but I haven't tried much parameterization. I'm ~80% convinced the results should be the same. If you have any specific things in mind, you should probably make a PR that adds tests for the properties you think we should preserve. We can then merge that one, update this one, and see if it actually breaks something. I can’t check for speculative differences if I have no idea where those could be. > I would note that the dataframe returned when inplace=False has a different index than it did previously. Yup, now it actually matches instead of discarding the original Index and replacing it with a RangeIndex for no reason. > Apart from the comments, can we get a regression test for ""cell_ranger"" (e.g. generate results with an older version)? I don't think we have one in the test suite. Sure! That’s a concrete thing I can do. I’ll do that on thursday, I did the rest of what you asked today",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1930104931
https://github.com/scverse/scanpy/pull/2809#issuecomment-1930104931:73,Modifiability,refactor,refactor,73,"> I wasn't really expecting this feature PR to also include such a large refactor. It would have been necessary for the Dask Dataframe version. Now I 1. did the work and 2. improved readability, so it would be counter productive to undo it. > I'm still not 100% convinced the behaviour here is exactly the same as before. I have done a few tests, which have been okay, but I haven't tried much parameterization. I'm ~80% convinced the results should be the same. If you have any specific things in mind, you should probably make a PR that adds tests for the properties you think we should preserve. We can then merge that one, update this one, and see if it actually breaks something. I can’t check for speculative differences if I have no idea where those could be. > I would note that the dataframe returned when inplace=False has a different index than it did previously. Yup, now it actually matches instead of discarding the original Index and replacing it with a RangeIndex for no reason. > Apart from the comments, can we get a regression test for ""cell_ranger"" (e.g. generate results with an older version)? I don't think we have one in the test suite. Sure! That’s a concrete thing I can do. I’ll do that on thursday, I did the rest of what you asked today",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1930104931
https://github.com/scverse/scanpy/pull/2809#issuecomment-1930104931:394,Modifiability,parameteriz,parameterization,394,"> I wasn't really expecting this feature PR to also include such a large refactor. It would have been necessary for the Dask Dataframe version. Now I 1. did the work and 2. improved readability, so it would be counter productive to undo it. > I'm still not 100% convinced the behaviour here is exactly the same as before. I have done a few tests, which have been okay, but I haven't tried much parameterization. I'm ~80% convinced the results should be the same. If you have any specific things in mind, you should probably make a PR that adds tests for the properties you think we should preserve. We can then merge that one, update this one, and see if it actually breaks something. I can’t check for speculative differences if I have no idea where those could be. > I would note that the dataframe returned when inplace=False has a different index than it did previously. Yup, now it actually matches instead of discarding the original Index and replacing it with a RangeIndex for no reason. > Apart from the comments, can we get a regression test for ""cell_ranger"" (e.g. generate results with an older version)? I don't think we have one in the test suite. Sure! That’s a concrete thing I can do. I’ll do that on thursday, I did the rest of what you asked today",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1930104931
https://github.com/scverse/scanpy/pull/2809#issuecomment-1930104931:340,Testability,test,tests,340,"> I wasn't really expecting this feature PR to also include such a large refactor. It would have been necessary for the Dask Dataframe version. Now I 1. did the work and 2. improved readability, so it would be counter productive to undo it. > I'm still not 100% convinced the behaviour here is exactly the same as before. I have done a few tests, which have been okay, but I haven't tried much parameterization. I'm ~80% convinced the results should be the same. If you have any specific things in mind, you should probably make a PR that adds tests for the properties you think we should preserve. We can then merge that one, update this one, and see if it actually breaks something. I can’t check for speculative differences if I have no idea where those could be. > I would note that the dataframe returned when inplace=False has a different index than it did previously. Yup, now it actually matches instead of discarding the original Index and replacing it with a RangeIndex for no reason. > Apart from the comments, can we get a regression test for ""cell_ranger"" (e.g. generate results with an older version)? I don't think we have one in the test suite. Sure! That’s a concrete thing I can do. I’ll do that on thursday, I did the rest of what you asked today",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1930104931
https://github.com/scverse/scanpy/pull/2809#issuecomment-1930104931:544,Testability,test,tests,544,"> I wasn't really expecting this feature PR to also include such a large refactor. It would have been necessary for the Dask Dataframe version. Now I 1. did the work and 2. improved readability, so it would be counter productive to undo it. > I'm still not 100% convinced the behaviour here is exactly the same as before. I have done a few tests, which have been okay, but I haven't tried much parameterization. I'm ~80% convinced the results should be the same. If you have any specific things in mind, you should probably make a PR that adds tests for the properties you think we should preserve. We can then merge that one, update this one, and see if it actually breaks something. I can’t check for speculative differences if I have no idea where those could be. > I would note that the dataframe returned when inplace=False has a different index than it did previously. Yup, now it actually matches instead of discarding the original Index and replacing it with a RangeIndex for no reason. > Apart from the comments, can we get a regression test for ""cell_ranger"" (e.g. generate results with an older version)? I don't think we have one in the test suite. Sure! That’s a concrete thing I can do. I’ll do that on thursday, I did the rest of what you asked today",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1930104931
https://github.com/scverse/scanpy/pull/2809#issuecomment-1930104931:1046,Testability,test,test,1046,"> I wasn't really expecting this feature PR to also include such a large refactor. It would have been necessary for the Dask Dataframe version. Now I 1. did the work and 2. improved readability, so it would be counter productive to undo it. > I'm still not 100% convinced the behaviour here is exactly the same as before. I have done a few tests, which have been okay, but I haven't tried much parameterization. I'm ~80% convinced the results should be the same. If you have any specific things in mind, you should probably make a PR that adds tests for the properties you think we should preserve. We can then merge that one, update this one, and see if it actually breaks something. I can’t check for speculative differences if I have no idea where those could be. > I would note that the dataframe returned when inplace=False has a different index than it did previously. Yup, now it actually matches instead of discarding the original Index and replacing it with a RangeIndex for no reason. > Apart from the comments, can we get a regression test for ""cell_ranger"" (e.g. generate results with an older version)? I don't think we have one in the test suite. Sure! That’s a concrete thing I can do. I’ll do that on thursday, I did the rest of what you asked today",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1930104931
https://github.com/scverse/scanpy/pull/2809#issuecomment-1930104931:1149,Testability,test,test,1149,"> I wasn't really expecting this feature PR to also include such a large refactor. It would have been necessary for the Dask Dataframe version. Now I 1. did the work and 2. improved readability, so it would be counter productive to undo it. > I'm still not 100% convinced the behaviour here is exactly the same as before. I have done a few tests, which have been okay, but I haven't tried much parameterization. I'm ~80% convinced the results should be the same. If you have any specific things in mind, you should probably make a PR that adds tests for the properties you think we should preserve. We can then merge that one, update this one, and see if it actually breaks something. I can’t check for speculative differences if I have no idea where those could be. > I would note that the dataframe returned when inplace=False has a different index than it did previously. Yup, now it actually matches instead of discarding the original Index and replacing it with a RangeIndex for no reason. > Apart from the comments, can we get a regression test for ""cell_ranger"" (e.g. generate results with an older version)? I don't think we have one in the test suite. Sure! That’s a concrete thing I can do. I’ll do that on thursday, I did the rest of what you asked today",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1930104931
https://github.com/scverse/scanpy/pull/2809#issuecomment-1930104931:232,Usability,undo,undo,232,"> I wasn't really expecting this feature PR to also include such a large refactor. It would have been necessary for the Dask Dataframe version. Now I 1. did the work and 2. improved readability, so it would be counter productive to undo it. > I'm still not 100% convinced the behaviour here is exactly the same as before. I have done a few tests, which have been okay, but I haven't tried much parameterization. I'm ~80% convinced the results should be the same. If you have any specific things in mind, you should probably make a PR that adds tests for the properties you think we should preserve. We can then merge that one, update this one, and see if it actually breaks something. I can’t check for speculative differences if I have no idea where those could be. > I would note that the dataframe returned when inplace=False has a different index than it did previously. Yup, now it actually matches instead of discarding the original Index and replacing it with a RangeIndex for no reason. > Apart from the comments, can we get a regression test for ""cell_ranger"" (e.g. generate results with an older version)? I don't think we have one in the test suite. Sure! That’s a concrete thing I can do. I’ll do that on thursday, I did the rest of what you asked today",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1930104931
https://github.com/scverse/scanpy/pull/2809#issuecomment-1940849400:26,Testability,test,test,26,"> can we get a regression test for ""cell_ranger"" (e.g. generate results with an older version)? I don't think we have one in the test suite. I’ll do that today if you can give me more info. Usually “regression test” refers to testing specific properties that were broken in a bug and subsequently fixed. What properties exactly are you looking for? Why `cell_ranger` and not `seurat`? Are you implying that we do that already for seurat?. /edit: done in https://github.com/scverse/scanpy/pull/2851. > There are two more lines which aren't covered, but I believe they should be unreachable (both just ValueError that the arg should be ""cell_ranger"" or ""seurat"") so it's fine. yeah, lines like that are more defensive coding. I add them even to internal code to force us to look at everything instead of having a `else: # flavor == ""cell_ranger""` branch or so. > I'm a little concerned about changing the return for inplace=False, in case anyone was relying on that. You mean the fact that the index makes the dataframe now actually useful? I can’t think of a way in which this breaks things in a way that isn’t immediately obvious and welcome. Of course, code can be infinitely weird, but can you think of a scenario?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1940849400
https://github.com/scverse/scanpy/pull/2809#issuecomment-1940849400:129,Testability,test,test,129,"> can we get a regression test for ""cell_ranger"" (e.g. generate results with an older version)? I don't think we have one in the test suite. I’ll do that today if you can give me more info. Usually “regression test” refers to testing specific properties that were broken in a bug and subsequently fixed. What properties exactly are you looking for? Why `cell_ranger` and not `seurat`? Are you implying that we do that already for seurat?. /edit: done in https://github.com/scverse/scanpy/pull/2851. > There are two more lines which aren't covered, but I believe they should be unreachable (both just ValueError that the arg should be ""cell_ranger"" or ""seurat"") so it's fine. yeah, lines like that are more defensive coding. I add them even to internal code to force us to look at everything instead of having a `else: # flavor == ""cell_ranger""` branch or so. > I'm a little concerned about changing the return for inplace=False, in case anyone was relying on that. You mean the fact that the index makes the dataframe now actually useful? I can’t think of a way in which this breaks things in a way that isn’t immediately obvious and welcome. Of course, code can be infinitely weird, but can you think of a scenario?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1940849400
https://github.com/scverse/scanpy/pull/2809#issuecomment-1940849400:210,Testability,test,test,210,"> can we get a regression test for ""cell_ranger"" (e.g. generate results with an older version)? I don't think we have one in the test suite. I’ll do that today if you can give me more info. Usually “regression test” refers to testing specific properties that were broken in a bug and subsequently fixed. What properties exactly are you looking for? Why `cell_ranger` and not `seurat`? Are you implying that we do that already for seurat?. /edit: done in https://github.com/scverse/scanpy/pull/2851. > There are two more lines which aren't covered, but I believe they should be unreachable (both just ValueError that the arg should be ""cell_ranger"" or ""seurat"") so it's fine. yeah, lines like that are more defensive coding. I add them even to internal code to force us to look at everything instead of having a `else: # flavor == ""cell_ranger""` branch or so. > I'm a little concerned about changing the return for inplace=False, in case anyone was relying on that. You mean the fact that the index makes the dataframe now actually useful? I can’t think of a way in which this breaks things in a way that isn’t immediately obvious and welcome. Of course, code can be infinitely weird, but can you think of a scenario?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1940849400
https://github.com/scverse/scanpy/pull/2809#issuecomment-1940849400:226,Testability,test,testing,226,"> can we get a regression test for ""cell_ranger"" (e.g. generate results with an older version)? I don't think we have one in the test suite. I’ll do that today if you can give me more info. Usually “regression test” refers to testing specific properties that were broken in a bug and subsequently fixed. What properties exactly are you looking for? Why `cell_ranger` and not `seurat`? Are you implying that we do that already for seurat?. /edit: done in https://github.com/scverse/scanpy/pull/2851. > There are two more lines which aren't covered, but I believe they should be unreachable (both just ValueError that the arg should be ""cell_ranger"" or ""seurat"") so it's fine. yeah, lines like that are more defensive coding. I add them even to internal code to force us to look at everything instead of having a `else: # flavor == ""cell_ranger""` branch or so. > I'm a little concerned about changing the return for inplace=False, in case anyone was relying on that. You mean the fact that the index makes the dataframe now actually useful? I can’t think of a way in which this breaks things in a way that isn’t immediately obvious and welcome. Of course, code can be infinitely weird, but can you think of a scenario?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1940849400
https://github.com/scverse/scanpy/pull/2809#issuecomment-1945680366:307,Security,access,accessing,307,"> You mean the fact that the index makes the dataframe now actually useful? I can’t think of a way in which this breaks things in a way that isn’t immediately obvious and welcome. Of course, code can be infinitely weird, but can you think of a scenario?. I get that it is more useful, but any code that was accessing it with `.loc` especially if it was relying on unique indices could run into a problem. It's minor, I'd be fine to leave it. Just we may need to revert.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1945680366
https://github.com/scverse/scanpy/pull/2810#issuecomment-1892337785:1672,Testability,test,testing,1672,(https://app.codecov.io/gh/scverse/scanpy/pull/2810?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.70%.; > Report is 1 commits behind head on master. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2810 +/- ##; ==========================================; - Coverage 72.84% 72.70% -0.14% ; ==========================================; Files 111 111 ; Lines 12368 12368 ; ==========================================; - Hits 9009 8992 -17 ; - Misses 3359 3376 +17 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2810?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/experimental/pp/\_highly\_variable\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/2810?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2V4cGVyaW1lbnRhbC9wcC9faGlnaGx5X3ZhcmlhYmxlX2dlbmVzLnB5) | `63.46% <100.00%> (ø)` | |; | [scanpy/testing/\_pytest/fixtures/data.py](https://app.codecov.io/gh/scverse/scanpy/pull/2810?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9maXh0dXJlcy9kYXRhLnB5) | `100.00% <100.00%> (ø)` | |; | [scanpy/preprocessing/\_highly\_variable\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/2810?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX2hpZ2hseV92YXJpYWJsZV9nZW5lcy5weQ==) | `96.17% <90.47%> (ø)` | |. ... and [1 file with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2810/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2810#issuecomment-1892337785
https://github.com/scverse/scanpy/pull/2811#issuecomment-1893455599:1672,Testability,test,testing,1672,(https://app.codecov.io/gh/scverse/scanpy/pull/2811?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.37%.; > Report is 1 commits behind head on master. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2811 +/- ##; ==========================================; - Coverage 72.70% 72.37% -0.34% ; ==========================================; Files 111 111 ; Lines 12368 12368 ; ==========================================; - Hits 8992 8951 -41 ; - Misses 3376 3417 +41 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2811?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/experimental/pp/\_highly\_variable\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/2811?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2V4cGVyaW1lbnRhbC9wcC9faGlnaGx5X3ZhcmlhYmxlX2dlbmVzLnB5) | `63.46% <100.00%> (ø)` | |; | [scanpy/testing/\_pytest/fixtures/data.py](https://app.codecov.io/gh/scverse/scanpy/pull/2811?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9maXh0dXJlcy9kYXRhLnB5) | `100.00% <100.00%> (ø)` | |; | [scanpy/preprocessing/\_highly\_variable\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/2811?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX2hpZ2hseV92YXJpYWJsZV9nZW5lcy5weQ==) | `96.17% <90.47%> (ø)` | |. ... and [1 file with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2811/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2811#issuecomment-1893455599
https://github.com/scverse/scanpy/pull/2811#issuecomment-1893536608:157,Deployability,update,update,157,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 4f4b1c3a655546d981360bcce625d354a4291385; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2811: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2811-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2811 on branch 1.9.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2811#issuecomment-1893536608
https://github.com/scverse/scanpy/pull/2811#issuecomment-1893536608:913,Deployability,continuous,continuous,913,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 4f4b1c3a655546d981360bcce625d354a4291385; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2811: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2811-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2811 on branch 1.9.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2811#issuecomment-1893536608
https://github.com/scverse/scanpy/pull/2811#issuecomment-1893536608:924,Deployability,integrat,integration,924,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 4f4b1c3a655546d981360bcce625d354a4291385; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2811: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2811-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2811 on branch 1.9.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2811#issuecomment-1893536608
https://github.com/scverse/scanpy/pull/2811#issuecomment-1893536608:924,Integrability,integrat,integration,924,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 4f4b1c3a655546d981360bcce625d354a4291385; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2811: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2811-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2811 on branch 1.9.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2811#issuecomment-1893536608
https://github.com/scverse/scanpy/pull/2811#issuecomment-1893536608:899,Testability,test,tested,899,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 4f4b1c3a655546d981360bcce625d354a4291385; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2811: [pre-commit.ci] pre-commit autoupdate'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2811-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2811 on branch 1.9.x ([pre-commit.ci] pre-commit autoupdate)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2811#issuecomment-1893536608
https://github.com/scverse/scanpy/pull/2812#issuecomment-1893321168:405,Availability,error,error-reference,405,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2812?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > :exclamation: No coverage uploaded for pull request base (`1.9.x@518e76a`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2812 +/- ##; ========================================; Coverage ? 71.34% ; ========================================; Files ? 103 ; Lines ? 11632 ; Branches ? 0 ; ========================================; Hits ? 8299 ; Misses ? 3333 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2812#issuecomment-1893321168
https://github.com/scverse/scanpy/pull/2812#issuecomment-1893321168:234,Testability,test,tests,234,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2812?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > :exclamation: No coverage uploaded for pull request base (`1.9.x@518e76a`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2812 +/- ##; ========================================; Coverage ? 71.34% ; ========================================; Files ? 103 ; Lines ? 11632 ; Branches ? 0 ; ========================================; Hits ? 8299 ; Misses ? 3333 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2812#issuecomment-1893321168
https://github.com/scverse/scanpy/pull/2812#issuecomment-1893321168:353,Usability,learn,learn,353,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2812?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > :exclamation: No coverage uploaded for pull request base (`1.9.x@518e76a`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2812 +/- ##; ========================================; Coverage ? 71.34% ; ========================================; Files ? 103 ; Lines ? 11632 ; Branches ? 0 ; ========================================; Hits ? 8299 ; Misses ? 3333 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2812#issuecomment-1893321168
https://github.com/scverse/scanpy/pull/2815#issuecomment-1894255210:120,Deployability,UPDATE,UPDATE,120,"TODOs:. 1. Figure out why some tests are passing when they shouldn't (hence why I pushed the branch, curious about CI). UPDATE: `tol` for `matplotlib.testing.compare.compare_images` is too high for a sparse-ish plot like `rank_genes_groups`. This is somewhat worrying so will need to be amended. Other than that, changed plotting outputs make sense so this should be resolved.; 2. Check with scanpy tutorials to see what needs to be changed there as well, if anything (if needed, the two PRs should be merged in tandem). The following use leiden in some capacity:; a. https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html; b. https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html; c. https://scanpy-tutorials.readthedocs.io/en/latest/spatial/basic-analysis.html; d. https://scanpy-tutorials.readthedocs.io/en/latest/spatial/integration-scanorama.html; 3. Do a large dataset test - check NMI for accuracy of the new default against the old one, check speed to confirm what we're doing makes sense (although this was covered, it seems, in #1053), and scalability",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2815#issuecomment-1894255210
https://github.com/scverse/scanpy/pull/2815#issuecomment-1894255210:847,Deployability,integrat,integration-scanorama,847,"TODOs:. 1. Figure out why some tests are passing when they shouldn't (hence why I pushed the branch, curious about CI). UPDATE: `tol` for `matplotlib.testing.compare.compare_images` is too high for a sparse-ish plot like `rank_genes_groups`. This is somewhat worrying so will need to be amended. Other than that, changed plotting outputs make sense so this should be resolved.; 2. Check with scanpy tutorials to see what needs to be changed there as well, if anything (if needed, the two PRs should be merged in tandem). The following use leiden in some capacity:; a. https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html; b. https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html; c. https://scanpy-tutorials.readthedocs.io/en/latest/spatial/basic-analysis.html; d. https://scanpy-tutorials.readthedocs.io/en/latest/spatial/integration-scanorama.html; 3. Do a large dataset test - check NMI for accuracy of the new default against the old one, check speed to confirm what we're doing makes sense (although this was covered, it seems, in #1053), and scalability",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2815#issuecomment-1894255210
https://github.com/scverse/scanpy/pull/2815#issuecomment-1894255210:847,Integrability,integrat,integration-scanorama,847,"TODOs:. 1. Figure out why some tests are passing when they shouldn't (hence why I pushed the branch, curious about CI). UPDATE: `tol` for `matplotlib.testing.compare.compare_images` is too high for a sparse-ish plot like `rank_genes_groups`. This is somewhat worrying so will need to be amended. Other than that, changed plotting outputs make sense so this should be resolved.; 2. Check with scanpy tutorials to see what needs to be changed there as well, if anything (if needed, the two PRs should be merged in tandem). The following use leiden in some capacity:; a. https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html; b. https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html; c. https://scanpy-tutorials.readthedocs.io/en/latest/spatial/basic-analysis.html; d. https://scanpy-tutorials.readthedocs.io/en/latest/spatial/integration-scanorama.html; 3. Do a large dataset test - check NMI for accuracy of the new default against the old one, check speed to confirm what we're doing makes sense (although this was covered, it seems, in #1053), and scalability",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2815#issuecomment-1894255210
https://github.com/scverse/scanpy/pull/2815#issuecomment-1894255210:1072,Performance,scalab,scalability,1072,"TODOs:. 1. Figure out why some tests are passing when they shouldn't (hence why I pushed the branch, curious about CI). UPDATE: `tol` for `matplotlib.testing.compare.compare_images` is too high for a sparse-ish plot like `rank_genes_groups`. This is somewhat worrying so will need to be amended. Other than that, changed plotting outputs make sense so this should be resolved.; 2. Check with scanpy tutorials to see what needs to be changed there as well, if anything (if needed, the two PRs should be merged in tandem). The following use leiden in some capacity:; a. https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html; b. https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html; c. https://scanpy-tutorials.readthedocs.io/en/latest/spatial/basic-analysis.html; d. https://scanpy-tutorials.readthedocs.io/en/latest/spatial/integration-scanorama.html; 3. Do a large dataset test - check NMI for accuracy of the new default against the old one, check speed to confirm what we're doing makes sense (although this was covered, it seems, in #1053), and scalability",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2815#issuecomment-1894255210
https://github.com/scverse/scanpy/pull/2815#issuecomment-1894255210:31,Testability,test,tests,31,"TODOs:. 1. Figure out why some tests are passing when they shouldn't (hence why I pushed the branch, curious about CI). UPDATE: `tol` for `matplotlib.testing.compare.compare_images` is too high for a sparse-ish plot like `rank_genes_groups`. This is somewhat worrying so will need to be amended. Other than that, changed plotting outputs make sense so this should be resolved.; 2. Check with scanpy tutorials to see what needs to be changed there as well, if anything (if needed, the two PRs should be merged in tandem). The following use leiden in some capacity:; a. https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html; b. https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html; c. https://scanpy-tutorials.readthedocs.io/en/latest/spatial/basic-analysis.html; d. https://scanpy-tutorials.readthedocs.io/en/latest/spatial/integration-scanorama.html; 3. Do a large dataset test - check NMI for accuracy of the new default against the old one, check speed to confirm what we're doing makes sense (although this was covered, it seems, in #1053), and scalability",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2815#issuecomment-1894255210
https://github.com/scverse/scanpy/pull/2815#issuecomment-1894255210:150,Testability,test,testing,150,"TODOs:. 1. Figure out why some tests are passing when they shouldn't (hence why I pushed the branch, curious about CI). UPDATE: `tol` for `matplotlib.testing.compare.compare_images` is too high for a sparse-ish plot like `rank_genes_groups`. This is somewhat worrying so will need to be amended. Other than that, changed plotting outputs make sense so this should be resolved.; 2. Check with scanpy tutorials to see what needs to be changed there as well, if anything (if needed, the two PRs should be merged in tandem). The following use leiden in some capacity:; a. https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html; b. https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html; c. https://scanpy-tutorials.readthedocs.io/en/latest/spatial/basic-analysis.html; d. https://scanpy-tutorials.readthedocs.io/en/latest/spatial/integration-scanorama.html; 3. Do a large dataset test - check NMI for accuracy of the new default against the old one, check speed to confirm what we're doing makes sense (although this was covered, it seems, in #1053), and scalability",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2815#issuecomment-1894255210
https://github.com/scverse/scanpy/pull/2815#issuecomment-1894255210:897,Testability,test,test,897,"TODOs:. 1. Figure out why some tests are passing when they shouldn't (hence why I pushed the branch, curious about CI). UPDATE: `tol` for `matplotlib.testing.compare.compare_images` is too high for a sparse-ish plot like `rank_genes_groups`. This is somewhat worrying so will need to be amended. Other than that, changed plotting outputs make sense so this should be resolved.; 2. Check with scanpy tutorials to see what needs to be changed there as well, if anything (if needed, the two PRs should be merged in tandem). The following use leiden in some capacity:; a. https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html; b. https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html; c. https://scanpy-tutorials.readthedocs.io/en/latest/spatial/basic-analysis.html; d. https://scanpy-tutorials.readthedocs.io/en/latest/spatial/integration-scanorama.html; 3. Do a large dataset test - check NMI for accuracy of the new default against the old one, check speed to confirm what we're doing makes sense (although this was covered, it seems, in #1053), and scalability",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2815#issuecomment-1894255210
https://github.com/scverse/scanpy/pull/2815#issuecomment-1903722027:8,Testability,test,test,8,Failing test looks similar to what happens when I run out of memory locally: https://dev.azure.com/scverse/scanpy/_build/results?buildId=5329&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=a42f7c48-3122-5ff2-641c-e8a7971de511&l=86. and now this again only on the CI: https://github.com/scverse/scanpy/pull/2815#issuecomment-1894530944,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2815#issuecomment-1903722027
https://github.com/scverse/scanpy/pull/2815#issuecomment-1903722027:147,Testability,log,logs,147,Failing test looks similar to what happens when I run out of memory locally: https://dev.azure.com/scverse/scanpy/_build/results?buildId=5329&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=a42f7c48-3122-5ff2-641c-e8a7971de511&l=86. and now this again only on the CI: https://github.com/scverse/scanpy/pull/2815#issuecomment-1894530944,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2815#issuecomment-1903722027
https://github.com/scverse/scanpy/pull/2815#issuecomment-1905756533:124,Availability,error,errors,124,> Failing test looks similar to what happens when I run out of memory locally. I’ve mostly seen these “illegal instruction” errors in a case where something is run on the wrong CPU architecture (e.g. compiled for a newer architecture than supported on that specific runner),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2815#issuecomment-1905756533
https://github.com/scverse/scanpy/pull/2815#issuecomment-1905756533:10,Testability,test,test,10,> Failing test looks similar to what happens when I run out of memory locally. I’ve mostly seen these “illegal instruction” errors in a case where something is run on the wrong CPU architecture (e.g. compiled for a newer architecture than supported on that specific runner),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2815#issuecomment-1905756533
https://github.com/scverse/scanpy/pull/2815#issuecomment-1910351580:205,Energy Efficiency,power,powerful,205,"OK, done, please check out https://github.com/scverse/scanpy/issues/2828. The sister API `sc.pp.louvain` uses `flavor` for this exact use case. It also says about the `'vtraag'` implementation: “Much more powerful than 'igraph', and the default”. I’m not sure why we consider it that much more “powerful” …",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2815#issuecomment-1910351580
https://github.com/scverse/scanpy/pull/2815#issuecomment-1910351580:295,Energy Efficiency,power,powerful,295,"OK, done, please check out https://github.com/scverse/scanpy/issues/2828. The sister API `sc.pp.louvain` uses `flavor` for this exact use case. It also says about the `'vtraag'` implementation: “Much more powerful than 'igraph', and the default”. I’m not sure why we consider it that much more “powerful” …",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2815#issuecomment-1910351580
https://github.com/scverse/scanpy/pull/2815#issuecomment-1952455566:117,Usability,simpl,simply,117,@ivirshup You are right about some of the pre-processing plots. I should have created a separate branch for those. I simply think hte outputs have changed and we never caught it but would be curious to see what you get. It could be my M1,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2815#issuecomment-1952455566
https://github.com/scverse/scanpy/pull/2815#issuecomment-1952548908:119,Availability,Error,Error,119,"@ivirshup I simplified the conditionals a bit and there are only two sets now. One to check for various `{Value/Import}Error`s and another to do the `clustering_kwargs` building. I think this is cleaner and faster since no code will run that doesn't have to. I didn't really see a way to do it with only one set of conditionals without code duplication. There's some code that's just common to both, but that shouldn't be run in the case of one of the `{Value/Import}Error`s .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2815#issuecomment-1952548908
https://github.com/scverse/scanpy/pull/2815#issuecomment-1952548908:467,Availability,Error,Error,467,"@ivirshup I simplified the conditionals a bit and there are only two sets now. One to check for various `{Value/Import}Error`s and another to do the `clustering_kwargs` building. I think this is cleaner and faster since no code will run that doesn't have to. I didn't really see a way to do it with only one set of conditionals without code duplication. There's some code that's just common to both, but that shouldn't be run in the case of one of the `{Value/Import}Error`s .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2815#issuecomment-1952548908
https://github.com/scverse/scanpy/pull/2815#issuecomment-1952548908:12,Usability,simpl,simplified,12,"@ivirshup I simplified the conditionals a bit and there are only two sets now. One to check for various `{Value/Import}Error`s and another to do the `clustering_kwargs` building. I think this is cleaner and faster since no code will run that doesn't have to. I didn't really see a way to do it with only one set of conditionals without code duplication. There's some code that's just common to both, but that shouldn't be run in the case of one of the `{Value/Import}Error`s .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2815#issuecomment-1952548908
https://github.com/scverse/scanpy/pull/2815#issuecomment-1952605321:40,Testability,test,tests,40,About the preprocessing plots:. `scanpy/tests/notebooks/_images_pbmc3k/filter_genes_dispersion/expected.png`. * Text and some points are shifted slightly. I'm not totally sure whether any points are actually in a different place. `scanpy/tests/notebooks/_images_pbmc3k/highest_expr_genes/expected.png`; `scanpy/tests/notebooks/_images_pbmc3k/pca/expected.png`; `scanpy/tests/notebooks/_images_pbmc3k/pca_variance_ratio/expected.png`; `scanpy/tests/notebooks/_images_pbmc3k/scatter_2/expected.png`. * Axis text shifted slightly; * Can probably be reverted if the tests still pass. `scanpy/tests/notebooks/_images_pbmc3k/scatter_1/expected.png`. * y axis moved,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2815#issuecomment-1952605321
https://github.com/scverse/scanpy/pull/2815#issuecomment-1952605321:238,Testability,test,tests,238,About the preprocessing plots:. `scanpy/tests/notebooks/_images_pbmc3k/filter_genes_dispersion/expected.png`. * Text and some points are shifted slightly. I'm not totally sure whether any points are actually in a different place. `scanpy/tests/notebooks/_images_pbmc3k/highest_expr_genes/expected.png`; `scanpy/tests/notebooks/_images_pbmc3k/pca/expected.png`; `scanpy/tests/notebooks/_images_pbmc3k/pca_variance_ratio/expected.png`; `scanpy/tests/notebooks/_images_pbmc3k/scatter_2/expected.png`. * Axis text shifted slightly; * Can probably be reverted if the tests still pass. `scanpy/tests/notebooks/_images_pbmc3k/scatter_1/expected.png`. * y axis moved,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2815#issuecomment-1952605321
https://github.com/scverse/scanpy/pull/2815#issuecomment-1952605321:311,Testability,test,tests,311,About the preprocessing plots:. `scanpy/tests/notebooks/_images_pbmc3k/filter_genes_dispersion/expected.png`. * Text and some points are shifted slightly. I'm not totally sure whether any points are actually in a different place. `scanpy/tests/notebooks/_images_pbmc3k/highest_expr_genes/expected.png`; `scanpy/tests/notebooks/_images_pbmc3k/pca/expected.png`; `scanpy/tests/notebooks/_images_pbmc3k/pca_variance_ratio/expected.png`; `scanpy/tests/notebooks/_images_pbmc3k/scatter_2/expected.png`. * Axis text shifted slightly; * Can probably be reverted if the tests still pass. `scanpy/tests/notebooks/_images_pbmc3k/scatter_1/expected.png`. * y axis moved,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2815#issuecomment-1952605321
https://github.com/scverse/scanpy/pull/2815#issuecomment-1952605321:369,Testability,test,tests,369,About the preprocessing plots:. `scanpy/tests/notebooks/_images_pbmc3k/filter_genes_dispersion/expected.png`. * Text and some points are shifted slightly. I'm not totally sure whether any points are actually in a different place. `scanpy/tests/notebooks/_images_pbmc3k/highest_expr_genes/expected.png`; `scanpy/tests/notebooks/_images_pbmc3k/pca/expected.png`; `scanpy/tests/notebooks/_images_pbmc3k/pca_variance_ratio/expected.png`; `scanpy/tests/notebooks/_images_pbmc3k/scatter_2/expected.png`. * Axis text shifted slightly; * Can probably be reverted if the tests still pass. `scanpy/tests/notebooks/_images_pbmc3k/scatter_1/expected.png`. * y axis moved,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2815#issuecomment-1952605321
https://github.com/scverse/scanpy/pull/2815#issuecomment-1952605321:442,Testability,test,tests,442,About the preprocessing plots:. `scanpy/tests/notebooks/_images_pbmc3k/filter_genes_dispersion/expected.png`. * Text and some points are shifted slightly. I'm not totally sure whether any points are actually in a different place. `scanpy/tests/notebooks/_images_pbmc3k/highest_expr_genes/expected.png`; `scanpy/tests/notebooks/_images_pbmc3k/pca/expected.png`; `scanpy/tests/notebooks/_images_pbmc3k/pca_variance_ratio/expected.png`; `scanpy/tests/notebooks/_images_pbmc3k/scatter_2/expected.png`. * Axis text shifted slightly; * Can probably be reverted if the tests still pass. `scanpy/tests/notebooks/_images_pbmc3k/scatter_1/expected.png`. * y axis moved,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2815#issuecomment-1952605321
https://github.com/scverse/scanpy/pull/2815#issuecomment-1952605321:562,Testability,test,tests,562,About the preprocessing plots:. `scanpy/tests/notebooks/_images_pbmc3k/filter_genes_dispersion/expected.png`. * Text and some points are shifted slightly. I'm not totally sure whether any points are actually in a different place. `scanpy/tests/notebooks/_images_pbmc3k/highest_expr_genes/expected.png`; `scanpy/tests/notebooks/_images_pbmc3k/pca/expected.png`; `scanpy/tests/notebooks/_images_pbmc3k/pca_variance_ratio/expected.png`; `scanpy/tests/notebooks/_images_pbmc3k/scatter_2/expected.png`. * Axis text shifted slightly; * Can probably be reverted if the tests still pass. `scanpy/tests/notebooks/_images_pbmc3k/scatter_1/expected.png`. * y axis moved,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2815#issuecomment-1952605321
https://github.com/scverse/scanpy/pull/2815#issuecomment-1952605321:588,Testability,test,tests,588,About the preprocessing plots:. `scanpy/tests/notebooks/_images_pbmc3k/filter_genes_dispersion/expected.png`. * Text and some points are shifted slightly. I'm not totally sure whether any points are actually in a different place. `scanpy/tests/notebooks/_images_pbmc3k/highest_expr_genes/expected.png`; `scanpy/tests/notebooks/_images_pbmc3k/pca/expected.png`; `scanpy/tests/notebooks/_images_pbmc3k/pca_variance_ratio/expected.png`; `scanpy/tests/notebooks/_images_pbmc3k/scatter_2/expected.png`. * Axis text shifted slightly; * Can probably be reverted if the tests still pass. `scanpy/tests/notebooks/_images_pbmc3k/scatter_1/expected.png`. * y axis moved,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2815#issuecomment-1952605321
https://github.com/scverse/scanpy/pull/2815#issuecomment-1952629319:45,Testability,test,tests,45,"@ivirshup I will revert those, and hopefully tests pass",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2815#issuecomment-1952629319
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895706976:3364,Testability,test,testing,3364,19tYXRyaXhwbG90LnB5) | `96.70% <100.00%> (ø)` | |; | [scanpy/plotting/\_stacked\_violin.py](https://app.codecov.io/gh/scverse/scanpy/pull/2816?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL19zdGFja2VkX3Zpb2xpbi5weQ==) | `84.18% <100.00%> (-0.16%)` | :arrow_down: |; | [scanpy/preprocessing/\_highly\_variable\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/2816?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX2hpZ2hseV92YXJpYWJsZV9nZW5lcy5weQ==) | `95.61% <100.00%> (+0.03%)` | :arrow_up: |; | [scanpy/preprocessing/\_pca.py](https://app.codecov.io/gh/scverse/scanpy/pull/2816?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX3BjYS5weQ==) | `93.25% <100.00%> (+0.11%)` | :arrow_up: |; | [scanpy/testing/\_helpers/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2816?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX2hlbHBlcnMvX19pbml0X18ucHk=) | `100.00% <100.00%> (ø)` | |; | [scanpy/testing/\_pytest/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2816?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9fX2luaXRfXy5weQ==) | `87.87% <100.00%> (+1.67%)` | :arrow_up: |; | [scanpy/testing/\_pytest/params.py](https://app.codecov.io/gh/scverse/scanpy/pull/2816?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9wYXJhbXMucHk=) | `100.00% <100.00%> (ø)` | |; | ... and [2 more](https://app.codecov.io/gh/scverse/scanpy/pull/2816?src=pr&el=tree-more&utm_medium=referral&utm_so,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895706976
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895706976:3661,Testability,test,testing,3661,2xpbi5weQ==) | `84.18% <100.00%> (-0.16%)` | :arrow_down: |; | [scanpy/preprocessing/\_highly\_variable\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/2816?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX2hpZ2hseV92YXJpYWJsZV9nZW5lcy5weQ==) | `95.61% <100.00%> (+0.03%)` | :arrow_up: |; | [scanpy/preprocessing/\_pca.py](https://app.codecov.io/gh/scverse/scanpy/pull/2816?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX3BjYS5weQ==) | `93.25% <100.00%> (+0.11%)` | :arrow_up: |; | [scanpy/testing/\_helpers/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2816?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX2hlbHBlcnMvX19pbml0X18ucHk=) | `100.00% <100.00%> (ø)` | |; | [scanpy/testing/\_pytest/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2816?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9fX2luaXRfXy5weQ==) | `87.87% <100.00%> (+1.67%)` | :arrow_up: |; | [scanpy/testing/\_pytest/params.py](https://app.codecov.io/gh/scverse/scanpy/pull/2816?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9wYXJhbXMucHk=) | `100.00% <100.00%> (ø)` | |; | ... and [2 more](https://app.codecov.io/gh/scverse/scanpy/pull/2816?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | |. ... and [5 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2816/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895706976
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895706976:3972,Testability,test,testing,3972,%> (-0.16%)` | :arrow_down: |; | [scanpy/preprocessing/\_highly\_variable\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/2816?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX2hpZ2hseV92YXJpYWJsZV9nZW5lcy5weQ==) | `95.61% <100.00%> (+0.03%)` | :arrow_up: |; | [scanpy/preprocessing/\_pca.py](https://app.codecov.io/gh/scverse/scanpy/pull/2816?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX3BjYS5weQ==) | `93.25% <100.00%> (+0.11%)` | :arrow_up: |; | [scanpy/testing/\_helpers/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2816?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX2hlbHBlcnMvX19pbml0X18ucHk=) | `100.00% <100.00%> (ø)` | |; | [scanpy/testing/\_pytest/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2816?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9fX2luaXRfXy5weQ==) | `87.87% <100.00%> (+1.67%)` | :arrow_up: |; | [scanpy/testing/\_pytest/params.py](https://app.codecov.io/gh/scverse/scanpy/pull/2816?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rlc3RpbmcvX3B5dGVzdC9wYXJhbXMucHk=) | `100.00% <100.00%> (ø)` | |; | ... and [2 more](https://app.codecov.io/gh/scverse/scanpy/pull/2816?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | |. ... and [5 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2816/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895706976
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:8,Availability,failure,failures,8,"## Test failures on 141eb6a315542317ddab2f7a413a24559c84492f. 252 failed, 650 passed, 59 skipped, 5 xfailed, 1038 warnings, 128 errors in 451.20s (0:07:31). Noting some of the big causes:. ### Expected warnings not thrown. A few times. ### Older versions of pandas do not support `na_action`. Likely caused during [Fix more pandas warnings by flying-sheep · Pull Request #2789 · scverse/scanpy](https://github.com/scverse/scanpy/pull/2789). Which did also bump up the required pandas version to 2.1.3. However, I think we'll want to revert that bump because:. * According to the scientific python versioning specification we're still meant to be on 1.4 ; * More than half of pandas users are still on 1.*; * Bumping pandas up to 2.1.3 actually requires bumping the versions on a number of other dependencies whose current minimums do not work with pandas 2.1.3. ### ufunc equal. Something is happening in a lot of plotting functions with the `equal` ufunc. ### Numba NotImplementedError. During `test_highly_variable_genes_pearson_residuals_general`. ### AnnData private methods used in tests. A lot of private anndata methods are used at test time. But these didn't exist at the time. Not totally sure what the best solution here is. * Vendoring anndata test helpers over here.; * Literally pulling in the file is probably not so bad; * I will investigate to see how many functions are really needed, possible it's just a few one liners (`as_dense_dask_array` is getting hit often); * Make a new package with just the test helpers? Probably too much of a pain. ### ImportError: cannot import name 'check_is_fitted' from 'sklearn.base'. <details>; <summary> Raw test output </summary>. ```python; FAILED scanpy/tests/test_datasets.py::test_krumsiek11 - Failed: DID NOT WARN. No warnings of type (<class 'UserWarning'>,) were emitted.; FAILED scanpy/tests/test_datasets.py::test_toggleswitch - Failed: DID NOT WARN. No warnings of type (<class 'UserWarning'>,) were emitted.; FAILED scanpy/get/get.py::",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:128,Availability,error,errors,128,"## Test failures on 141eb6a315542317ddab2f7a413a24559c84492f. 252 failed, 650 passed, 59 skipped, 5 xfailed, 1038 warnings, 128 errors in 451.20s (0:07:31). Noting some of the big causes:. ### Expected warnings not thrown. A few times. ### Older versions of pandas do not support `na_action`. Likely caused during [Fix more pandas warnings by flying-sheep · Pull Request #2789 · scverse/scanpy](https://github.com/scverse/scanpy/pull/2789). Which did also bump up the required pandas version to 2.1.3. However, I think we'll want to revert that bump because:. * According to the scientific python versioning specification we're still meant to be on 1.4 ; * More than half of pandas users are still on 1.*; * Bumping pandas up to 2.1.3 actually requires bumping the versions on a number of other dependencies whose current minimums do not work with pandas 2.1.3. ### ufunc equal. Something is happening in a lot of plotting functions with the `equal` ufunc. ### Numba NotImplementedError. During `test_highly_variable_genes_pearson_residuals_general`. ### AnnData private methods used in tests. A lot of private anndata methods are used at test time. But these didn't exist at the time. Not totally sure what the best solution here is. * Vendoring anndata test helpers over here.; * Literally pulling in the file is probably not so bad; * I will investigate to see how many functions are really needed, possible it's just a few one liners (`as_dense_dask_array` is getting hit often); * Make a new package with just the test helpers? Probably too much of a pain. ### ImportError: cannot import name 'check_is_fitted' from 'sklearn.base'. <details>; <summary> Raw test output </summary>. ```python; FAILED scanpy/tests/test_datasets.py::test_krumsiek11 - Failed: DID NOT WARN. No warnings of type (<class 'UserWarning'>,) were emitted.; FAILED scanpy/tests/test_datasets.py::test_toggleswitch - Failed: DID NOT WARN. No warnings of type (<class 'UserWarning'>,) were emitted.; FAILED scanpy/get/get.py::",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:42274,Availability,Error,Error,42274,al' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_paga.py::test_paga_pie - ImportError: cannot import name 'gcd' from 'fractions' (/mnt/workspace/mambaforge/envs/anndata-min-deps-test/lib/python...; FAILED scanpy/tests/test_paga.py::test_paga_plots[compare_pca-func6] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-infclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-inftheta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-infclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-inftheta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:42613,Availability,Error,Error,42613,ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-infclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-inftheta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-infclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-inftheta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/tes,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:42759,Availability,Error,Error,42759,nes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-infclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-inftheta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-infclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-inftheta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-noclip-subset,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:43156,Availability,Error,Error,43156,ode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-infclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-inftheta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: I,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:43318,Availability,Error,Error,43318,iles did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-infclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-inftheta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-n,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:43947,Availability,Error,Error,43947,n-inftheta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-noclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_dict-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED sca,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:44117,Availability,Error,Error,44117,plot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-noclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_dict-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_violin_without_raw - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:44497,Availability,Error,Error,44497,2-200n-inftheta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-noclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_dict-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_violin_without_raw - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_paga.py::test_paga_path - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_enumerated_palettes[pca] - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_highly_variable_genes.py::test_high,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:44640,Availability,Error,Error,44640,y_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-noclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_dict-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_violin_without_raw - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_paga.py::test_paga_path - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_enumerated_palettes[pca] - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-float32-100n-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:46230,Availability,Error,Error,46230,id not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_enumerated_palettes[pca] - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-float32-100n-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_embedding_plots.py::test_enumerated_palettes[spatial] - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_embedding_plots.py::test_dimension_broadcasting - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_embedding_plots.py::test_marker_broadcasting - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_compare - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_paga.py::test_paga_positions_reproducible - ImportError: cannot import name 'gcd' from 'fractions' (/mnt/workspace/mambaforge/envs/anndata-min-deps-test/lib/python...; FAILED scanpy/tests/test_embedding_plots.py::test_dimensions_same_as_components - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_tracksplot-fn15] - AssertionErro,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:46380,Availability,Error,Error,46380,or: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-float32-100n-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_embedding_plots.py::test_enumerated_palettes[spatial] - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_embedding_plots.py::test_dimension_broadcasting - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_embedding_plots.py::test_marker_broadcasting - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_compare - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_paga.py::test_paga_positions_reproducible - ImportError: cannot import name 'gcd' from 'fractions' (/mnt/workspace/mambaforge/envs/anndata-min-deps-test/lib/python...; FAILED scanpy/tests/test_embedding_plots.py::test_dimensions_same_as_components - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_tracksplot-fn15] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - A,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:46488,Availability,Error,Error,46488,_genes_pearson_residuals_batch[csr_matrix-float32-100n-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_embedding_plots.py::test_enumerated_palettes[spatial] - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_embedding_plots.py::test_dimension_broadcasting - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_embedding_plots.py::test_marker_broadcasting - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_compare - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_paga.py::test_paga_positions_reproducible - ImportError: cannot import name 'gcd' from 'fractions' (/mnt/workspace/mambaforge/envs/anndata-min-deps-test/lib/python...; FAILED scanpy/tests/test_embedding_plots.py::test_dimensions_same_as_components - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_tracksplot-fn15] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatm,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:47209,Availability,Error,Error,47209,dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_compare - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_paga.py::test_paga_positions_reproducible - ImportError: cannot import name 'gcd' from 'fractions' (/mnt/workspace/mambaforge/envs/anndata-min-deps-test/lib/python...; FAILED scanpy/tests/test_embedding_plots.py::test_dimensions_same_as_components - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_tracksplot-fn15] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - Asser,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:47371,Availability,Error,Error,47371,[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_compare - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_paga.py::test_paga_positions_reproducible - ImportError: cannot import name 'gcd' from 'fractions' (/mnt/workspace/mambaforge/envs/anndata-min-deps-test/lib/python...; FAILED scanpy/tests/test_embedding_plots.py::test_dimensions_same_as_components - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_tracksplot-fn15] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:47511,Availability,Error,Error,47511,r: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_compare - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_paga.py::test_paga_positions_reproducible - ImportError: cannot import name 'gcd' from 'fractions' (/mnt/workspace/mambaforge/envs/anndata-min-deps-test/lib/python...; FAILED scanpy/tests/test_embedding_plots.py::test_dimensions_same_as_components - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_tracksplot-fn15] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not m,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:47661,Availability,Error,Error,47661,not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_paga.py::test_paga_positions_reproducible - ImportError: cannot import name 'gcd' from 'fractions' (/mnt/workspace/mambaforge/envs/anndata-min-deps-test/lib/python...; FAILED scanpy/tests/test_embedding_plots.py::test_dimensions_same_as_components - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_tracksplot-fn15] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Imag,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:47815,Availability,Error,Error,47815, import name 'gcd' from 'fractions' (/mnt/workspace/mambaforge/envs/anndata-min-deps-test/lib/python...; FAILED scanpy/tests/test_embedding_plots.py::test_dimensions_same_as_components - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_tracksplot-fn15] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Im,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:47923,Availability,Error,Error,47923,mbedding_plots.py::test_dimensions_same_as_components - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_tracksplot-fn15] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:48084,Availability,Error,Error,48084, with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_tracksplot-fn15] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files di,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:48199,Availability,Error,Error,48199, AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image fi,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:48357,Availability,Error,Error,48357,gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Ima,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:48464,Availability,Error,Error,48464,roups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Ima,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:48626,Availability,Error,Error,48626,nes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionErro,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:48780,Availability,Error,Error,48780,ps[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[tracksplot-tracksplot] - AssertionError: Error: Image files did,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:48907,Availability,Error,Error,48907,otplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[tracksplot-tracksplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: E,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:49034,Availability,Error,Error,49034,nked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[tracksplot-tracksplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image file,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:49178,Availability,Error,Error,49178,test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[tracksplot-tracksplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:49319,Availability,Error,Error,49319,ed_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[tracksplot-tracksplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_add_outline_vmin_vmax_norm - numpy.core._exceptions._UFuncN,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:49452,Availability,Error,Error,49452,racksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[tracksplot-tracksplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_add_outline_vmin_vmax_norm - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:49599,Availability,Error,Error,49599,plot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[tracksplot-tracksplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_add_outline_vmin_vmax_norm - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_add_outline_vmin_vmax_norm_ref - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signa,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:49732,Availability,Error,Error,49732,roups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[tracksplot-tracksplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_add_outline_vmin_vmax_norm - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_add_outline_vmin_vmax_norm_ref - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_violin - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equa,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:49894,Availability,Error,Error,49894,symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[tracksplot-tracksplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_add_outline_vmin_vmax_norm - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_add_outline_vmin_vmax_norm_ref - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_violin - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_binary_scatter - TypeError: map(),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:50005,Availability,Error,Error,50005,otplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[tracksplot-tracksplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_add_outline_vmin_vmax_norm - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_add_outline_vmin_vmax_norm_ref - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_violin - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_binary_scatter - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_plotting.py::test_color_cycler - TypeError: map() got an unexpe,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:50145,Availability,Error,Error,50145,ups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[tracksplot-tracksplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_add_outline_vmin_vmax_norm - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_add_outline_vmin_vmax_norm_ref - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_violin - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_binary_scatter - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_plotting.py::test_color_cycler - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_plotting.py::test_repeated_colors_w_missing_value - TypeError: ma,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:54899,Availability,ERROR,ERROR,54899,erplots[pca_with_fonts-fn1] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[pca_markers_colors_with_dimensions-fn10] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[umap_with_edges-fn17] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[pca_mask-fn19] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_groups_and_size - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:55068,Availability,ERROR,ERROR,55068,/tests/test_plotting.py::test_scatterplots[pca_markers_colors_with_dimensions-fn10] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[umap_with_edges-fn17] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[pca_mask-fn19] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_groups_and_size - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/te,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:55233,Availability,ERROR,ERROR,55233,th signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[umap_with_edges-fn17] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[pca_mask-fn19] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_groups_and_size - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neig,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:55402,Availability,ERROR,ERROR,55402,c 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[pca_mask-fn19] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_groups_and_size - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/test,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:55571,Availability,ERROR,ERROR,55571,ions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_groups_and_size - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbor,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:55740,Availability,ERROR,ERROR,55740,groups_and_size - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighb,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:55905,Availability,ERROR,ERROR,55905,_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/ne,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:56070,Availability,ERROR,ERROR,56070,g/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanp,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:56235,Availability,ERROR,ERROR,56235,s/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR sca,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:56404,Availability,ERROR,ERROR,56404,ors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanp,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:56569,Availability,ERROR,ERROR,56569,hbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:56738,Availability,ERROR,ERROR,56738,ing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/test,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:56907,Availability,ERROR,ERROR,56907,_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbor,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:57076,Availability,ERROR,ERROR,57076,est/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbor,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:57245,Availability,ERROR,ERROR,57245,kends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighb,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:57410,Availability,ERROR,ERROR,57410,ytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/te,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:57575,Availability,ERROR,ERROR,57575,_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/ne,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:57740,Availability,ERROR,ERROR,57740,ors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanp,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:57905,Availability,ERROR,ERROR,57905,hbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:58074,Availability,ERROR,ERROR,58074,hbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/test,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:58243,Availability,ERROR,ERROR,58243,ing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbor,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:58412,Availability,ERROR,ERROR,58412,g/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighb,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:58577,Availability,ERROR,ERROR,58577,_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/test,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:58746,Availability,ERROR,ERROR,58746,ytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testin,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:58911,Availability,ERROR,ERROR,58911,_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighb,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:59076,Availability,ERROR,ERROR,59076,ors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/te,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:59241,Availability,ERROR,ERROR,59241,hbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/test,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:59410,Availability,ERROR,ERROR,59410,ing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_n,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:59579,Availability,ERROR,ERROR,59579,ors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_m,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:59744,Availability,ERROR,ERROR,59744,sting/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metri,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:59909,Availability,ERROR,ERROR,59909,ing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalizati,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:60078,Availability,ERROR,ERROR,60078,g/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:60243,Availability,ERROR,ERROR,60243,hbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - Impo,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:60404,Availability,ERROR,ERROR,60404,/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - I,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:60571,Availability,ERROR,ERROR,60571,canpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:60732,Availability,ERROR,ERROR,60732,OR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessi,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:60893,Availability,ERROR,ERROR,60893,ROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:61060,Availability,ERROR,ERROR,61060,.; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:61221,Availability,ERROR,ERROR,61221,annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:61378,Availability,ERROR,ERROR,61378,py/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_norm,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:61545,Availability,ERROR,ERROR,61545,can...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:61712,Availability,ERROR,ERROR,61712,; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - Impor,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:61879,Availability,ERROR,ERROR,61879,RROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - Im,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:62040,Availability,ERROR,ERROR,62040,ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - I,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:62211,Availability,ERROR,ERROR,62211,OR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:62368,Availability,ERROR,ERROR,62368,anpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:62535,Availability,ERROR,ERROR,62535,OR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessi,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:62692,Availability,ERROR,ERROR,62692,an...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_r,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:62849,Availability,ERROR,ERROR,62849,os/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tes,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:63016,Availability,ERROR,ERROR,63016,/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_me,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:63183,Availability,ERROR,ERROR,63183,py/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:63354,Availability,ERROR,ERROR,63354,ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metr,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:63513,Availability,ERROR,ERROR,63513,..; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normal,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:63680,Availability,ERROR,ERROR,63680,anpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preproce,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:63851,Availability,ERROR,ERROR,63851,sts/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_norma,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:64008,Availability,ERROR,ERROR,64008,canpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/te,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:64169,Availability,ERROR,ERROR,64169,scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:64340,Availability,ERROR,ERROR,64340,RROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:64501,Availability,ERROR,ERROR,64501,scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_util,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:64668,Availability,ERROR,ERROR,64668,scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - Imp,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:64835,Availability,ERROR,ERROR,64835,ROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportErr,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:65002,Availability,ERROR,ERROR,65002,anpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: ca,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:65161,Availability,ERROR,ERROR,65161,/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:65332,Availability,ERROR,ERROR,65332,scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:65491,Availability,ERROR,ERROR,65491,R scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:65650,Availability,ERROR,ERROR,65650,...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - Im,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:65807,Availability,ERROR,ERROR,65807,pos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:65968,Availability,ERROR,ERROR,65968,space/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:66125,Availability,ERROR,ERROR,66125,canpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_ra,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:66292,Availability,ERROR,ERROR,66292,/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:66451,Availability,ERROR,ERROR,66451,os/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/t,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:66618,Availability,ERROR,ERROR,66618,y/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/t,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:66785,Availability,ERROR,ERROR,66785,nd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_nor,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:66946,Availability,ERROR,ERROR,66946,; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_ut,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:67117,Availability,ERROR,ERROR,67117,/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:67288,Availability,ERROR,ERROR,67288,ests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - Imp,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:67455,Availability,ERROR,ERROR,67455,test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportEr,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:67616,Availability,ERROR,ERROR,67616,y/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.p,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:67773,Availability,ERROR,ERROR,67773,scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalizat,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:67940,Availability,ERROR,ERROR,67940,anpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metric,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:68099,Availability,ERROR,ERROR,68099,ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:68266,Availability,ERROR,ERROR,68266,y/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:68427,Availability,ERROR,ERROR,68427,epos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalizatio,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:68586,Availability,ERROR,ERROR,68586,anpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalizat,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:68757,Availability,ERROR,ERROR,68757,ROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - Imp,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:68924,Availability,ERROR,ERROR,68924, ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportErro,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:69085,Availability,ERROR,ERROR,69085,RROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportErro,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515
