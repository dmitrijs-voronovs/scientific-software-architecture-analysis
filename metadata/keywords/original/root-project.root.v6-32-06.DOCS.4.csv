id,quality_attribute,keyword,matched_word,match_idx,sentence,source,filename,author,repo,version,wiki,url
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:127420,Performance,load,loaded,127420,"wo different use cases having different ways of invoking the; geometry editors. The first one applies when starting with geometry from; scratch and using the builder functionality to create new geometry; objects. In this case, one should use the sequence:. ~~~{.cpp}; root[] TGeoManager *geom = new TGeoManager(""MyGeom"",; ""Test builder"");; root[] geom->Edit(Option_t *option="""");; ~~~. The lines above will create a new TGeoManager class, create an; empty canvas and start the editor in the left-sided editor frame; attached to the canvas. To open the editor in a separate frame one; should provide a non-empty string as option to the `Edit()` method. \image html geometry018.png ""The geometry manager editor"". \anchor GP08b; ### The Geometry Manager Editor. \image html geometry019.png ""Accessing/creating different categories of editable objects"" width=600px. The second use case applies when starting to edit an existing geometry.; Supposing the geometry was loaded into memory, besides the first method; that still applies one can also edit drawn geometry objects. For this,; the menu entry View/Editor of the canvas containing for instance a drawn; volume must be activated. For starting the volume editor one can click; on a volume. The GUI of the TGeoManager class can be started by; clicking on the top-right `40x40` pixels corner of the pad with a drawn; geometry. This is the main entry point for editing the geometry or creating new; objects. Once the interface is created (using one of the methods; described above), several categories can be accessed via a shutter GUI; widget:. - *General.* This allows changing the name/title of the geometry,; setting the top volume, closing the geometry and saving the geometry; in a file. The file name is formed by `geometry_name.C` or `.root`; depending if the geometry need to be saved as a `C` macro or a; `.root` file.; - *Shapes.* The category provides buttons for creation of all; supported shapes. The new shape name is chosen by the interfac",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:131660,Performance,perform,performed,131660," the apply button is; pressed, the changes are applied to the edited shape and drawn. The; ""Undo"" button becomes active after the first modification has been; applied. It allows restoring the initial parameters of the shape. NOTE: In this version the ""Undo"" does not allow restoring an; intermediate state of the parameters that was applied - it will always; restore the parameters at the moment the shape was edited. All material properties changes are undoable. The mixture editor; currently allows adding elements one by one in the mixture composition.; This can be done either by element weight fraction or by number of; atoms. Once an element was added using one method the other method is not; selectable anymore. Summing component fractions up to 1 in the final; mixture is the user responsibility. Adding materials as components of a; mixture is not supported in this version. The elements that were added to the mixture appear in the bottom of the; mixture editor. The operations performed on mixture are not undoable. \anchor GP08d; ### Creation of New Objects. As described above, all geometry object creators are accessible within; the geometry manager editor frame. Generally, if the new object that; needs to be created does not depend on other objects, it will be built; with a set of default parameters. This is the case for all shapes; (except composite shapes) and matrices. For all the other objects the; interface forces the selection of components before creating the object. \anchor GP08e; ### Editing Volumes. Volumes are hierarchical components in the geometry, therefore their; editor is more complex. It provides the following functionalities:. - *General*. This category allows changing the name of the volume and; selecting other shape or medium among existing ones. - *Daughters*. The category allows removing existing daughter nodes or; adding new ones. The button ""Position"" allows editing the; positioning matrix of a given node. \image html geometry022.jpg width=600p",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:130,Safety,detect,detector,130,"\defgroup Geometry The Geometry Package. The %ROOT geometry package is a tool for building, browsing,; navigating and visualizing detector geometries. The code works; standalone with respect to any tracking Monte-Carlo engine; therefore,; it does not contain any constraints related to physics. However, the; navigation features provided by the package are designed to optimize; particle transport through complex geometries, working in correlation; with simulation packages such as GEANT3, GEANT4 and FLUKA. - [Quick Start: Creating the world](\ref GP00); - [Example 1: Creating the World](\ref GP00a); - [Example 2: A Geometrical Hierarchy Look and Feel](\ref GP00b); - [Selecting the System of Units in ROOT](\ref GPUNITS); - [Geometry Creation](\ref GP01); - [The Volume Hierarchy](\ref GP01a); - [Creating and Positioning Volumes](\ref GP01b); - [Making Volumes](\ref GP01ba); - [Example of Volume Creation](\ref GP01bb); - [Positioned Volumes (Nodes)](\ref GP01bc); - [Virtual Containers and Assemblies of Volumes](\ref GP01bd); - [Examples of Volume Positioning](\ref GP01be); - [Overlapping Volumes](\ref GP01bf); - [Replicating Volumes](\ref GP01bg); - [Volume Families](\ref GP01bh); - [Dividing Volumes](\ref GP01bi); - [Volume Assemblies](\ref GP01bj); - [Geometrical Transformations](\ref GP01c); - [Matrix Creation Example](\ref GP01ca); - [Rule for Creation of Transformations](\ref GP01cb); - [Available Geometrical Transformations](\ref GP01cc); - [Ownership of Geometry Objects](\ref GP01d); - [Navigation and Tracking](\ref GP02); - [TGeoNavigator Class](\ref GP02a); - [Initializing the Starting Point](\ref GP02b); - [Initializing the Direction](\ref GP02c); - [Initializing the State](\ref GP02d); - [Checking the Current State](\ref GP02e); - [Saving and Restoring the Current State](\ref GP02f); - [Navigation Queries](\ref GP02g); - [Finding If Current State Is Changed For a New Point](\ref GP02ga); - [Finding the Distance to the Next Boundary](\ref GP02gb); - [Computing th",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:5633,Safety,safe,safely,5633," Let us focus on the biggest pack - it is mandatory to; define one. Consider the simplest geometry that is made of a single box.; Here is an example on how to build it:. \anchor GP00a; ### Example 1: Creating the World. We first need to load the geometry library. This is not needed if one; does ""make map"" in root folder. ~~~{.cpp}; root[] gSystem->Load(""libGeom"");; ~~~. Second, we have to create an instance of the geometry manager class.; This takes care of all the modeller components, performing several tasks; to insure geometry validity and containing the user interface for; building and interacting with the geometry. After its creation, the; geometry manager class can be accessed with the global; `gGeoManager`:. ~~~{.cpp}; root[] new TGeoManager(""world"", ""the simplest geometry"");; ~~~. We want to create a single volume in our geometry, but since any volume; needs to have an associated medium, we will create a dummy one. You can; safely ignore the following lines for the time being, since materials; and media will be explained in detail later on. ~~~{.cpp}; root[] TGeoMaterial *mat = new TGeoMaterial(""Vacuum"",0,0,0);; root[] TGeoMedium *med = new TGeoMedium(""Vacuum"",1,mat);; ~~~. We can finally make our volume having a box shape. Note that the world; volume does not need to be a box - it can be any other shape. Generally,; boxes and tubes are the most recommendable shapes for this purpose due; to their fast navigation algorithms. ~~~{.cpp}; root[] TGeoVolume *top=gGeoManager->MakeBox(""Top"",med,10.,10.,10.);; ~~~. The default units are in centimeters. Now we want to make this volume; our world. We have to do this operation **before** closing the geometry. ~~~{.cpp}; root[] gGeoManager->SetTopVolume(top);; ~~~. This should be enough, but it is not since always after defining some; geometry hierarchy, TGeo needs to build some optimization; structures and perform some checks. Note the messages posted after the; statement is executed. We will describe the corresponding",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:16518,Safety,avoid,avoid,16518,"sic unit system based; on millimeters, nanoseconds and MegaElectronVolts was better suited for the LHC; experiments. All LHC experiments use Geant4 and effectively adopted this; convention for all areas of data processing: simulation, reconstruction and; data analysis. Hence experiments using the %ROOT geometry toolkit to describe; the geometry had two different system of units in the application code. To allow users having the same system of units in the geometry description and the; application it is now possible to choose the system of units at startup of the; application:. ``` {.cpp}; TGeoManager::SetDefaultUnits(xx); xx = kG4Units, kRootUnits; ```. To ensure backwards compatibility %ROOT's default system of units is - as it was before -; based on centimeters, seconds and GigaElectronVolts, ie. the defaults are equivalent to:. ``` {.cpp}; TGeoManager::SetDefaultUnits(kRootUnits);; ```. To avoid confusion between materials described in %ROOT units and materials described; in Geant4 units, this switch should by all means be set once, before any element or; material is constructed. If for whatever reason it is necessary to change the; system of units later, this is feasible disabling the otherwise fatal exception:. ``` {.cpp}; TGeoManager::LockDefaultUnits(kFALSE);; ```. followed later by a corresponding call to again lock the system of units:. ``` {.cpp}; TGeoManager::LockDefaultUnits(kTRUE);; ```. \anchor GP01; ## Geometry Creation. A given geometry can be built in various ways, but one has to follow; some mandatory steps. Even if we might use some terms that will be; explained later, here are few general rules:. - Volumes need media and shapes in order to be created.; - Both containers and contained volumes must be created before linking; them together, and the relative transformation matrix must be; provided.; - Any volume have to be positioned somewhere otherwise it will not be; considered as part of the geometry.; - Visibility or tracking properties of volumes",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:24504,Safety,avoid,avoid,24504,"ry. Nodes have visualization attributes as the volume; has. When undefined by users, painting a node on a pad will take the; corresponding volume attributes. \anchor GP01b; ### Creating and Positioning Volumes. \anchor GP01ba; #### Making Volumes. As mentioned before, volumes are the basic objects used in building the; geometrical hierarchy. They represent objects that are not positioned,; but store all information about the placement of the other volumes they; may contain. Therefore a volume can be replicated several times in the; geometry. As it was explained, in order to create a volume, one has to; put together a shape and a medium, which are already defined. Volumes have to be named by users at creation time. Every different name; may represent a unique volume object, but may also represent more; general a family (class) of volume objects having the same shape type; and medium, but possibly different shape parameters. It is the user's; task to provide different names for different volume families in order; to avoid ambiguities at tracking time. A generic family rather than a single volume is created only in two; cases: when a parametric shape is used or when a division operation is; applied. Each volume in the geometry stores a unique ID corresponding to; its family. In order to ease-up their creation, the manager class is; providing an API that allows making a shape and a volume in a single; step. \anchor GP01bb; #### Example of Volume Creation. ~~~{.cpp}; // Making a volume out of a shape and a medium.; TGeoVolume *vol = new TGeoVolume(""VNAME"",ptrShape,ptrMed);. // Making a volume out of a shape but without a defined medium.; TGeoVolume *vol = new TGeoVolume(""VNAME"",ptrShape);. // Making a volume with a given shape in one step; TGeoVolume *vol = gGeoManager->MakeBox(""VNAME"",ptrMed,dx,dy,dz);; TGeoVolume *vol = gGeoManager->MakeTubs(""VNAME"",ptrMed,rmin,rmax,; dz,phi1,phi2);. // See class TGeoManager for the rest of shapes.; // Making a volume with a given shape",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:26160,Safety,detect,detector,26160," with a given shape in one step; TGeoVolume *vol = gGeoManager->MakeBox(""VNAME"",ptrMed,dx,dy,dz);; TGeoVolume *vol = gGeoManager->MakeTubs(""VNAME"",ptrMed,rmin,rmax,; dz,phi1,phi2);. // See class TGeoManager for the rest of shapes.; // Making a volume with a given shape with a unique prototype; TGeoVolume *vol = gGeoManager->Volume(""VNAME"",""XXXX"",nmed,upar,; npar);. // Where XXXX stands for the first 4 letters of the specific shape; // classes, nmed is the medium number, upar is an Double_t * array; // of the shape parameters and npar is the number of parameters.; // This prototype allows (npar = 0) to define volumes with shape; // defined only at positioning time (volumes defined in this way; // need to be positioned using TGeoManager::Node() method); ~~~. \anchor GP01bc; #### Positioned Volumes (Nodes). Geometrical modeling is a difficult task when the number of different; geometrical objects is 106-108. This is more or less the case for; detector geometries of complex experiments, where a ‘flat' CSG model; description cannot scale with the current CPU performances. This is the; reason why models like GEANT [1] introduced an additional dimension; (depth) in order to reduce the complexity of the problem. This concept; is also preserved by the ROOT modeller and introduces a pure geometrical; constraint between objects (volumes in our case) - containment. This; means in fact that any positioned volume has to be contained by another.; Now what means contained and positioned?. - We will say that a volume `contains` a point if this is inside the; shape associated to the volume. For instance, a volume having a box; shape will contain all points `P=(X,Y,Z)` verifying the conditions:; `Abs(Pi)dXi`. The points on the shape boundaries are considered as; inside the volume. The volume contains a daughter if it contains all; the points contained by the daughter.; - The definition of containment works of course only with points; defined in the local coordinate system of the consid",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:31946,Safety,avoid,avoid,31946,"s, the limitation in proceeding this way is that `D,E,` and; `F` must point to the same medium. If this was not the case, we would; have to define different virtual volumes for each placement: `C`, `C`'; and `C`\"", having the same shape but different media matching the; corresponding containers. This might not happen so often, but when it; does, it forces the creation of several extra virtual volumes. Other; limitation comes from the fact that any container is directly used by; navigation algorithms to optimize tracking. These must geometrically; contain their belongings (positioned volumes) so that these do not; extrude its shape boundaries. Not respecting this rule generally leads; to unpredictable results. Therefore `A` and `B` together must fit into; `C` that has to fit also into `D`, `E`, and `F`. This is not always; straightforward to accomplish, especially when instead of `A` and `B` we; have many more volumes. In order to avoid these problems, one can use for the difficult cases; the class TGeoVolumeAssembly, representing an assembly of volumes.; This behaves like a normal container volume supporting other volumes; positioned inside, but it has neither shape nor medium. It cannot be; used directly as a piece of the geometry, but just as a temporary; structure helping temporary assembling and positioning volumes. If we define now `C` as an assembly containing `A` and `B`, positioning; the assembly into `D,E` and `F` will actually position only `A` and; `B `directly into these volumes, taking into account their combined; transformations `A/B` to `C` and `C` to `D/E/F`. This looks much nicer,; is it? In fact, it is and it is not. Of course, we managed to get rid of; the ""unnecessary"" volume `C` in our geometry, but we end-up with a more; flat structure for `D,E` and `F` (more daughters inside). This can get; much worse when extensively used, as in the case: assemblies of; assemblies. For deciding what to choose between using virtual containers or; assemblies fo",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:36872,Safety,avoid,avoid,36872,"o all overlapping partners.; The answer provided by the modeller to ""Where am I?"" is no longer; deterministic if there is no priority assigned. There are two ways out provided by the modeller in such cases and we; will illustrate them by examples. - Suppose we have 2 crossing tubes that we have to describe. Such a; structure cannot be decomposed in a containment schema. This is a; typical example of simple structure that can be handled by using; composite shapes. What we have to do is to define as shapes the; inner and outer parts of the tubes (tubes having; `Rmin=0`,` Rmax=`inner/outer radius), then to make a composite:; - `C = (Tub1out+Tub2out)-(Tub1in+Tub2in)`; - On the other hand, if we have an EM calorimeter having a honeycomb; structure, Boolean combinations do not help anymore. Here the; problem is that we usually have a very large number of cells that; are naturally belonging to the same container. This result in a very; flat and slow structure for that particular container, which we; would very much want to avoid by introducing additional levels in; depth. We can describe the basic cell as a hexahedron that we can; represent by using a polygon primitive shape. Instead of putting one; by one all cells in the same container, we can define rows of such; elements, fitting in box-shaped containers. Then we can put; row-beside-row inside the container, making life much easier for its; navigation algorithms. The problem is that in order to reproduce the; honeycomb structure out of rows of cells, we have to overlap row; containers. Whoops - we have not obeyed rule No. 2 in positioning.; The way out is to position our rows with a special prototype:. ~~~{.cpp}; ptrCAL->AddNodeOverlap(""ROW"",nRow,matrixRow);; ~~~. This will instruct the modeller that the daughter ROW inside CAL; overlaps with something else. The modeller will check this at closure; time and build a list of possibly overlapping candidates. This option is; equivalent with the option MANY in GEANT3. The m",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:39542,Safety,detect,detector,39542,"-overlapping; nodes as ONLY and the others MANY as in GEANT3, where this concept was; introduced:. 1. The part of a MANY node B extruding its container A will never be; ""seen"" during navigation, as if B was in fact the result of the; intersection of A and B. 2. If we have two nodes A (ONLY) and B (MANY) inside the same container,; all points in the overlapping region of A and B will be designated as; belonging to A. 3. If A an B in the above case were both MANY, points in the overlapping; part will be designated to the one defined first. Both nodes must have; the same medium. 4. The slices of a divided MANY will be as well MANY. One needs to know that navigation inside geometry parts MANY nodes is; much slower. Any overlapping part can be defined based on composite; shapes - might be in some cases a better way out. \anchor GP01bg; #### Replicating Volumes. What can we do if our chamber contains two identical wires instead of; one? What if then we would need 1000 chambers in our detector? Should we; create 2000 wires and 1000 chamber volumes? No, we will just need to; replicate the ones that we have already created. ~~~{.cpp}; chamber->AddNode(wire_co,1,new TGeoTranslation(0.2,0,0));; chamber->AddNode(wire_co,2,new TGeoTranslation(0.2,0,0));; ~~~. The 2 nodes that we have created inside chamber will both point to a; `wire_co` object, but will be completely distinct: `WIRE_CO_1` and; `WIRE_CO_2`. We will want now to place symmetrically 1000 chambers on a; pad, following a pattern of 20 rows and 50 columns. One way to do this; will be to replicate our chamber by positioning it 1000 times in; different positions of the pad. Unfortunately, this is far from being; the optimal way of doing what we want. Imagine that we would like to; find out which of the 1000 chambers is containing a `(x,y,z)` point; defined in the pad reference. You will never have to do that, since the; modeller will take care of it for you, but let's guess what it has to; do. The most simple algorithm ",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:61883,Safety,safe,safety,61883," transformations; are subjected to a caching mechanism due to the sometimes very large; memory requirements of logical graph expansion. The total number of; physical instances of volumes triggers the caching mechanism and the; cache manager is a client of TGeoManager. The manager class also; controls the drawing/checking package (TGeoPainter client). This; is linked with %ROOT graphical libraries loaded on demand in order to; control visualization actions. \anchor GP02; ## Navigation and Tracking. Tracking is the feature allowing the transport of a given particle; knowing its kinematics. A state is determined by any combination of the; position \f$\vec{r}\f$ and direction \f$\vec{n}\f$ with respect to the world; reference frame. The direction \f$\vec{n}\f$ must be a unit vector having as; components the director cosines. The full classification of a given; state will provide the following information: the deepest physical node; containing the position vector, the distance to the closest boundary; along the direction vector, the next physical node after propagating the; current point with this distance and the safety distance to the nearest; boundary. This information allows the propagation of particles inside a; detector geometry by taking into account both geometrical and physical; constraints. We will hereby describe the user interface of `TGeo` to access; tracking functionality. This allows either developing a tracker for; simple navigation within a given geometry, either interfacing to an; external tracking engine such as GEANT. Note that the abstract interface; for external trackers can be found in `$ROOTSYS/vmc` folder and it can; be used to run GEANT3, GEANT4 and FLUKA-based simulations (\*) by using; directly a geometry described with %ROOT. The interface methods related to tracking are incorporated into; TGeoManager class and implemented in the navigator class; TGeoNavigator. In order to be able to start tracking, one has to; define the initial state provid",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:61988,Safety,detect,detector,61988,"s a client of TGeoManager. The manager class also; controls the drawing/checking package (TGeoPainter client). This; is linked with %ROOT graphical libraries loaded on demand in order to; control visualization actions. \anchor GP02; ## Navigation and Tracking. Tracking is the feature allowing the transport of a given particle; knowing its kinematics. A state is determined by any combination of the; position \f$\vec{r}\f$ and direction \f$\vec{n}\f$ with respect to the world; reference frame. The direction \f$\vec{n}\f$ must be a unit vector having as; components the director cosines. The full classification of a given; state will provide the following information: the deepest physical node; containing the position vector, the distance to the closest boundary; along the direction vector, the next physical node after propagating the; current point with this distance and the safety distance to the nearest; boundary. This information allows the propagation of particles inside a; detector geometry by taking into account both geometrical and physical; constraints. We will hereby describe the user interface of `TGeo` to access; tracking functionality. This allows either developing a tracker for; simple navigation within a given geometry, either interfacing to an; external tracking engine such as GEANT. Note that the abstract interface; for external trackers can be found in `$ROOTSYS/vmc` folder and it can; be used to run GEANT3, GEANT4 and FLUKA-based simulations (\*) by using; directly a geometry described with %ROOT. The interface methods related to tracking are incorporated into; TGeoManager class and implemented in the navigator class; TGeoNavigator. In order to be able to start tracking, one has to; define the initial state providing the starting point \f$\vec{r_0}\f$; and direction \f$\vec{n_0}\f$ .; There are several ways of doing that. \anchor GP02a; ### TGeoNavigator Class. One geometry may have several independent navigators to query to; localize points or comput",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:63748,Safety,safe,safety,63748,"ng the starting point \f$\vec{r_0}\f$; and direction \f$\vec{n_0}\f$ .; There are several ways of doing that. \anchor GP02a; ### TGeoNavigator Class. One geometry may have several independent navigators to query to; localize points or compute distances. The geometry manager holds a list; of active navigators accessible via:. ~~~{.cpp}; TObjArray *navigators = gGeoManager->GetListOfNavigators();; ~~~. Upon closing the geometry a default navigator is provided as first one; in this list, but one may add its own via:. ~~~{.cpp}; TGeoNavigator *navig = new TGeoNavigator(gGeoManager);; // Store the index of the user navigator; Int_t inav = gGeoManager->AddNavigator(navig);; // Make its own navigator the active one; gGeoManager->SetCurrentNavigator(inav);; // Switch between navigators; gGeoManager->SetCurrentNavigator(0);; ~~~. A navigator holds several variables describing the current navigation; state: current point position, current direction distance to next; boundary, isotropic safety, pointer to current and next nods as well as; several tracking flags related to volume boundary conditions or other; properties required for track propagation in geometry. Each geometry; query affects these variables, so the only way in testing several; navigation alternatives and remembering the active navigation state is; to use parallel navigation. The following paragraphs will describe the; usage of a single navigator. All setters/getters for navigation state; parameters as well as navigation queries provided by TGeoNavigator; are interfaced by TGeoManager and will act on the current; navigator. \anchor GP02b; ### Initializing the Starting Point. The current point (`x,y,z`) known by the modeller is stored as; `Double_t fCurrentPoint[3]` by the navigator class. This array of the; three coordinates is defined in the current global reference system and; can be retrieved any time:. ~~~{.cpp}; Const Double_t *cpoint = gGeoManager->GetCurrentPoint();; ~~~. Initializing this point can be don",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:77219,Safety,safe,safety,77219,"nt along a straight line.; The starting point and direction for this procedure are the ones; corresponding to the current state. The boundary search is initialized; inside the current volume and the crossed boundary can belong either to; the current node or to one of its daughters. The full prototype of the; method is:. ~~~{.cpp}; TGeoNode *TGeoManager::FindNextBoundary(Double_t step=kBig);; ~~~. In the prototype above, besides the current point and direction that are; supposed already initialized, the only input parameter is `step`. This; represents the maximum step allowed by the tracking algorithm or the; `physical step`. The modeller will search for a boundary crossing only; up to a distance equal to this value. If a boundary is found, a pointer; to the object (node) having it is returned; otherwise the method returns; `NULL`. The computed value for the computed distance can be subsequently; retrieved from the manager class:. ~~~{.cpp}; Double_t snext = gGeoManager->GetStep();; Double_t safety = gGeoManager->GetSafeDistance();; ~~~. According the step value, two use cases are possible:. - `step =` `TGeoShape::kBig ` (default behavior; `kBig = 1030`). In; this case, there is no limitation on the search algorithm, the first; crossed node is returned and the corresponding distance computed. If; the current point is outside geometry and the top node is not; crossed, the corresponding distance will be set to `kBig` and a; `NULL` pointer returned. No additional quantity will be computed.; - `step < kBig`. In this case, the progressive search starting from; the current point will be stopped after a distance equal with the; supplied step. In addition to the distance to the first crossed; boundary, the `safety radius` is also computed. Whenever the; information regarding the maximum required step is known it is; recommended to be provided as input parameter in order to speed-up; the search. In addition to the distance computation, the method sets an additional; flag telli",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:77941,Safety,safe,safety,77941,"to this value. If a boundary is found, a pointer; to the object (node) having it is returned; otherwise the method returns; `NULL`. The computed value for the computed distance can be subsequently; retrieved from the manager class:. ~~~{.cpp}; Double_t snext = gGeoManager->GetStep();; Double_t safety = gGeoManager->GetSafeDistance();; ~~~. According the step value, two use cases are possible:. - `step =` `TGeoShape::kBig ` (default behavior; `kBig = 1030`). In; this case, there is no limitation on the search algorithm, the first; crossed node is returned and the corresponding distance computed. If; the current point is outside geometry and the top node is not; crossed, the corresponding distance will be set to `kBig` and a; `NULL` pointer returned. No additional quantity will be computed.; - `step < kBig`. In this case, the progressive search starting from; the current point will be stopped after a distance equal with the; supplied step. In addition to the distance to the first crossed; boundary, the `safety radius` is also computed. Whenever the; information regarding the maximum required step is known it is; recommended to be provided as input parameter in order to speed-up; the search. In addition to the distance computation, the method sets an additional; flag telling if the current track will enter inside some daughter of the; current volume or it will exit inside its container:. ~~~{.cpp}; Bool_t TGeoManager::IsStepEntering() const;; ~~~. A combined task is to first find the distance to the next boundary and; then extrapolate the current point/direction with this distance making; sure that the boundary was crossed. Finally the goal would be to find; the next state after crossing the boundary. The problem can be solved in; principle using FindNextBoundary, but the boundary crossing can give; unpredictable results due to numerical roundings. The manager class; provides a method that allows this combined task and ensures boundary; crossing. This should be used in",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:79307,Safety,safe,safety,79307,"olume or it will exit inside its container:. ~~~{.cpp}; Bool_t TGeoManager::IsStepEntering() const;; ~~~. A combined task is to first find the distance to the next boundary and; then extrapolate the current point/direction with this distance making; sure that the boundary was crossed. Finally the goal would be to find; the next state after crossing the boundary. The problem can be solved in; principle using FindNextBoundary, but the boundary crossing can give; unpredictable results due to numerical roundings. The manager class; provides a method that allows this combined task and ensures boundary; crossing. This should be used instead of the method `FindNextBoundary()`; whenever the tracking is not imposed in association with an external MC; transport engine (which provide their own algorithms for boundary; crossing). ~~~{.cpp}; TGeoNode *TGeoManager::FindNextBoundaryAndStep(Double_t stepmax,; Bool_t comp_safe=kFALSE);; ~~~. The meaning of the parameters here is the same as for FindNextBoundary,; but the safety value is triggered by an input flag. The output is the; node after the boundary crossing. \anchor GP02gc; #### Computing the Safe Radius. Other important navigation query for tracking is the computation of the; safe distance. This represents the `maximum` step that can be made from; the current point in `any direction` that assures that no boundary will; be crossed. Knowing this value gives additional freedom to the stepping; algorithm to propagate the current track on the corresponding range; `without checking` if the current state has changed. In other words, the; modeller insures that the current state does not change in any point; within the safety radius around the current point. The computation of the safe radius is `automatically` computed any time; when the next boundary is queried within a `limited step:`. ~~~{.cpp}; TGeoNode *crossed = gGeoManager->FindNextBoundary(pstep);; Double_t safety = gGeoManager->GetSafeDistance();; ~~~. Otherwise, the comput",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:79525,Safety,safe,safe,79525,"oint/direction with this distance making; sure that the boundary was crossed. Finally the goal would be to find; the next state after crossing the boundary. The problem can be solved in; principle using FindNextBoundary, but the boundary crossing can give; unpredictable results due to numerical roundings. The manager class; provides a method that allows this combined task and ensures boundary; crossing. This should be used instead of the method `FindNextBoundary()`; whenever the tracking is not imposed in association with an external MC; transport engine (which provide their own algorithms for boundary; crossing). ~~~{.cpp}; TGeoNode *TGeoManager::FindNextBoundaryAndStep(Double_t stepmax,; Bool_t comp_safe=kFALSE);; ~~~. The meaning of the parameters here is the same as for FindNextBoundary,; but the safety value is triggered by an input flag. The output is the; node after the boundary crossing. \anchor GP02gc; #### Computing the Safe Radius. Other important navigation query for tracking is the computation of the; safe distance. This represents the `maximum` step that can be made from; the current point in `any direction` that assures that no boundary will; be crossed. Knowing this value gives additional freedom to the stepping; algorithm to propagate the current track on the corresponding range; `without checking` if the current state has changed. In other words, the; modeller insures that the current state does not change in any point; within the safety radius around the current point. The computation of the safe radius is `automatically` computed any time; when the next boundary is queried within a `limited step:`. ~~~{.cpp}; TGeoNode *crossed = gGeoManager->FindNextBoundary(pstep);; Double_t safety = gGeoManager->GetSafeDistance();; ~~~. Otherwise, the computation of safety can always be forced:. ~~~{.cpp}; Double_t safety = gGeoManager->Safety();; ~~~. \anchor GP02gd; #### Making a Step. The modeller is able to make steps starting from the current point along; ",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:79968,Safety,safe,safety,79968," method `FindNextBoundary()`; whenever the tracking is not imposed in association with an external MC; transport engine (which provide their own algorithms for boundary; crossing). ~~~{.cpp}; TGeoNode *TGeoManager::FindNextBoundaryAndStep(Double_t stepmax,; Bool_t comp_safe=kFALSE);; ~~~. The meaning of the parameters here is the same as for FindNextBoundary,; but the safety value is triggered by an input flag. The output is the; node after the boundary crossing. \anchor GP02gc; #### Computing the Safe Radius. Other important navigation query for tracking is the computation of the; safe distance. This represents the `maximum` step that can be made from; the current point in `any direction` that assures that no boundary will; be crossed. Knowing this value gives additional freedom to the stepping; algorithm to propagate the current track on the corresponding range; `without checking` if the current state has changed. In other words, the; modeller insures that the current state does not change in any point; within the safety radius around the current point. The computation of the safe radius is `automatically` computed any time; when the next boundary is queried within a `limited step:`. ~~~{.cpp}; TGeoNode *crossed = gGeoManager->FindNextBoundary(pstep);; Double_t safety = gGeoManager->GetSafeDistance();; ~~~. Otherwise, the computation of safety can always be forced:. ~~~{.cpp}; Double_t safety = gGeoManager->Safety();; ~~~. \anchor GP02gd; #### Making a Step. The modeller is able to make steps starting from the current point along; the current direction and having the current step length. The new point; and its corresponding state will be automatically computed:. ~~~{.cpp}; TGeoNode *TGeoManager::Step(Bool_t is_geom = kTRUE,; Bool_t cross = kTRUE);; ~~~. We will explain the method above by its use cases. The input flag; `is_geom` allows specifying if the step is limited by geometrical; reasons (a boundary crossing) or is an arbitrary step. The flag cross; can be us",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:80031,Safety,safe,safe,80031,"eir own algorithms for boundary; crossing). ~~~{.cpp}; TGeoNode *TGeoManager::FindNextBoundaryAndStep(Double_t stepmax,; Bool_t comp_safe=kFALSE);; ~~~. The meaning of the parameters here is the same as for FindNextBoundary,; but the safety value is triggered by an input flag. The output is the; node after the boundary crossing. \anchor GP02gc; #### Computing the Safe Radius. Other important navigation query for tracking is the computation of the; safe distance. This represents the `maximum` step that can be made from; the current point in `any direction` that assures that no boundary will; be crossed. Knowing this value gives additional freedom to the stepping; algorithm to propagate the current track on the corresponding range; `without checking` if the current state has changed. In other words, the; modeller insures that the current state does not change in any point; within the safety radius around the current point. The computation of the safe radius is `automatically` computed any time; when the next boundary is queried within a `limited step:`. ~~~{.cpp}; TGeoNode *crossed = gGeoManager->FindNextBoundary(pstep);; Double_t safety = gGeoManager->GetSafeDistance();; ~~~. Otherwise, the computation of safety can always be forced:. ~~~{.cpp}; Double_t safety = gGeoManager->Safety();; ~~~. \anchor GP02gd; #### Making a Step. The modeller is able to make steps starting from the current point along; the current direction and having the current step length. The new point; and its corresponding state will be automatically computed:. ~~~{.cpp}; TGeoNode *TGeoManager::Step(Bool_t is_geom = kTRUE,; Bool_t cross = kTRUE);; ~~~. We will explain the method above by its use cases. The input flag; `is_geom` allows specifying if the step is limited by geometrical; reasons (a boundary crossing) or is an arbitrary step. The flag cross; can be used in case the step is made on a boundary and specifies if user; wants to cross or not the boundary. The returned node represents the new;",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:80220,Safety,safe,safety,80220,"safe=kFALSE);; ~~~. The meaning of the parameters here is the same as for FindNextBoundary,; but the safety value is triggered by an input flag. The output is the; node after the boundary crossing. \anchor GP02gc; #### Computing the Safe Radius. Other important navigation query for tracking is the computation of the; safe distance. This represents the `maximum` step that can be made from; the current point in `any direction` that assures that no boundary will; be crossed. Knowing this value gives additional freedom to the stepping; algorithm to propagate the current track on the corresponding range; `without checking` if the current state has changed. In other words, the; modeller insures that the current state does not change in any point; within the safety radius around the current point. The computation of the safe radius is `automatically` computed any time; when the next boundary is queried within a `limited step:`. ~~~{.cpp}; TGeoNode *crossed = gGeoManager->FindNextBoundary(pstep);; Double_t safety = gGeoManager->GetSafeDistance();; ~~~. Otherwise, the computation of safety can always be forced:. ~~~{.cpp}; Double_t safety = gGeoManager->Safety();; ~~~. \anchor GP02gd; #### Making a Step. The modeller is able to make steps starting from the current point along; the current direction and having the current step length. The new point; and its corresponding state will be automatically computed:. ~~~{.cpp}; TGeoNode *TGeoManager::Step(Bool_t is_geom = kTRUE,; Bool_t cross = kTRUE);; ~~~. We will explain the method above by its use cases. The input flag; `is_geom` allows specifying if the step is limited by geometrical; reasons (a boundary crossing) or is an arbitrary step. The flag cross; can be used in case the step is made on a boundary and specifies if user; wants to cross or not the boundary. The returned node represents the new; current node after the step was made. - Making a geometrically contained step with boundary crossing; (`is_geom=kTRUE`, `cross=kTRU",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:80297,Safety,safe,safety,80297,",; but the safety value is triggered by an input flag. The output is the; node after the boundary crossing. \anchor GP02gc; #### Computing the Safe Radius. Other important navigation query for tracking is the computation of the; safe distance. This represents the `maximum` step that can be made from; the current point in `any direction` that assures that no boundary will; be crossed. Knowing this value gives additional freedom to the stepping; algorithm to propagate the current track on the corresponding range; `without checking` if the current state has changed. In other words, the; modeller insures that the current state does not change in any point; within the safety radius around the current point. The computation of the safe radius is `automatically` computed any time; when the next boundary is queried within a `limited step:`. ~~~{.cpp}; TGeoNode *crossed = gGeoManager->FindNextBoundary(pstep);; Double_t safety = gGeoManager->GetSafeDistance();; ~~~. Otherwise, the computation of safety can always be forced:. ~~~{.cpp}; Double_t safety = gGeoManager->Safety();; ~~~. \anchor GP02gd; #### Making a Step. The modeller is able to make steps starting from the current point along; the current direction and having the current step length. The new point; and its corresponding state will be automatically computed:. ~~~{.cpp}; TGeoNode *TGeoManager::Step(Bool_t is_geom = kTRUE,; Bool_t cross = kTRUE);; ~~~. We will explain the method above by its use cases. The input flag; `is_geom` allows specifying if the step is limited by geometrical; reasons (a boundary crossing) or is an arbitrary step. The flag cross; can be used in case the step is made on a boundary and specifies if user; wants to cross or not the boundary. The returned node represents the new; current node after the step was made. - Making a geometrically contained step with boundary crossing; (`is_geom=kTRUE`, `cross=kTRUE`) - This is the default method; behavior. In this case, the step size is supposed to be ",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:80347,Safety,safe,safety,80347,"put is the; node after the boundary crossing. \anchor GP02gc; #### Computing the Safe Radius. Other important navigation query for tracking is the computation of the; safe distance. This represents the `maximum` step that can be made from; the current point in `any direction` that assures that no boundary will; be crossed. Knowing this value gives additional freedom to the stepping; algorithm to propagate the current track on the corresponding range; `without checking` if the current state has changed. In other words, the; modeller insures that the current state does not change in any point; within the safety radius around the current point. The computation of the safe radius is `automatically` computed any time; when the next boundary is queried within a `limited step:`. ~~~{.cpp}; TGeoNode *crossed = gGeoManager->FindNextBoundary(pstep);; Double_t safety = gGeoManager->GetSafeDistance();; ~~~. Otherwise, the computation of safety can always be forced:. ~~~{.cpp}; Double_t safety = gGeoManager->Safety();; ~~~. \anchor GP02gd; #### Making a Step. The modeller is able to make steps starting from the current point along; the current direction and having the current step length. The new point; and its corresponding state will be automatically computed:. ~~~{.cpp}; TGeoNode *TGeoManager::Step(Bool_t is_geom = kTRUE,; Bool_t cross = kTRUE);; ~~~. We will explain the method above by its use cases. The input flag; `is_geom` allows specifying if the step is limited by geometrical; reasons (a boundary crossing) or is an arbitrary step. The flag cross; can be used in case the step is made on a boundary and specifies if user; wants to cross or not the boundary. The returned node represents the new; current node after the step was made. - Making a geometrically contained step with boundary crossing; (`is_geom=kTRUE`, `cross=kTRUE`) - This is the default method; behavior. In this case, the step size is supposed to be already set; by a previous TGeoManager::FindNextBoundary() cal",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:92299,Safety,detect,detected,92299," behavior is dependent on the track; parameters, which is a highly undesirable effect. *B)* We will call ""overlaps"" only the regions in space contained by; more than one node inside the same container. The owner of such regions; cannot be determined based on hierarchical considerations; therefore; they will be considered as belonging to the node from which the current; track is coming from. When coming from their container, the ownership is totally; unpredictable. Again, the ownership of overlapping regions highly; depends on the current track parameters. We must say that even the overlaps of type *A)* and *B)* are allowed in case; the corresponding nodes are created using; TGeoVolume::AddNodeOverlap() method. Navigation is performed in such; cases by giving priority to the non-overlapping nodes. The modeller has; to perform an additional search through the overlapping candidates.; These are detected automatically during the geometry closing procedure; in order to optimize the algorithm, but we will stress that extensive; usage of this feature leads to a drastic deterioration of performance.; In the following we will focus on the non-declared overlaps of type *A)*; and *B)* since this is the main source of errors during tracking. These; are generally non-intended overlaps due to coding mistakes or bad; geometry design. The checking package is loaded together with the; painter classes and contains an automated overlap checker. \image html geometry008.png ""Overlap checking"". This can be activated both at volume level (checking for illegal; overlaps only one level inside a given volume) and from the geometry; manager level (checking full geometry):. ~~~{.cpp}; myVolume->CheckOverlaps(precision, option);; gGeoManager->CheckOverlaps(precision);; myNode->CheckOverlaps(precision);; ~~~. Here precision represents the desired maximum accepted overlap value in; centimeters (default value is 0.1). This tool checks all possible; significant pairs of candidates inside a given vol",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:94270,Safety,safe,safety,94270," (default value is 0.1). This tool checks all possible; significant pairs of candidates inside a given volume (not declared as; overlapping or division volumes). The check is performed by verifying; the mesh representation of one candidate against the shape of the other.; This sort of check cannot identify all possible overlapping topologies,; but it works for more than 95% and is much faster than the usual; shape-to-shape comparison. For a 100% reliability, one can perform the; check at the level of a single volume by using `option`=""`d`"" or; `option`=""`d<number>`"" to perform overlap checking by sampling the; volume with \<`number`\> random points (default 1 million). This; produces also a picture showing in red the overlapping region and; estimates the volume of the overlaps. An extrusion *A)* is declared in any of the following cases:. - At least one of the vertices of the daughter mesh representation is; outside the mother volume (in fact its shape) and having a safety; distance to the mother greater than the desired value;; - At least one of the mother vertices is contained also by one of its; daughters, in the same conditions. An overlap *B)* is declared if:. - At least one vertex of a positioned volume mesh is contained (having; a safety bigger than the accepted maximum value) by other positioned; volume inside the same container. The check is performed also by; inverting the candidates. The code is highly optimized to avoid checking candidates that are far; away in space by performing a fast check on their bounding boxes. Once; the checking tool is fired-up inside a volume or at top level, the list; of overlaps (visible as Illegal overlaps inside a TBrowser) held; by the manager class will be filled with TGeoOverlap objects; containing a full description of the detected overlaps. The list is; sorted in the decreasing order of the overlapping distance, extrusions; coming first. An overlap object name represents the full description of; the overlap, containing",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:94547,Safety,safe,safety,94547,"; This sort of check cannot identify all possible overlapping topologies,; but it works for more than 95% and is much faster than the usual; shape-to-shape comparison. For a 100% reliability, one can perform the; check at the level of a single volume by using `option`=""`d`"" or; `option`=""`d<number>`"" to perform overlap checking by sampling the; volume with \<`number`\> random points (default 1 million). This; produces also a picture showing in red the overlapping region and; estimates the volume of the overlaps. An extrusion *A)* is declared in any of the following cases:. - At least one of the vertices of the daughter mesh representation is; outside the mother volume (in fact its shape) and having a safety; distance to the mother greater than the desired value;; - At least one of the mother vertices is contained also by one of its; daughters, in the same conditions. An overlap *B)* is declared if:. - At least one vertex of a positioned volume mesh is contained (having; a safety bigger than the accepted maximum value) by other positioned; volume inside the same container. The check is performed also by; inverting the candidates. The code is highly optimized to avoid checking candidates that are far; away in space by performing a fast check on their bounding boxes. Once; the checking tool is fired-up inside a volume or at top level, the list; of overlaps (visible as Illegal overlaps inside a TBrowser) held; by the manager class will be filled with TGeoOverlap objects; containing a full description of the detected overlaps. The list is; sorted in the decreasing order of the overlapping distance, extrusions; coming first. An overlap object name represents the full description of; the overlap, containing both candidate node names and a letter; (x-extrusion, o-overlap) representing the type. Double-clicking an; overlap item in a TBrowser produces a picture of the overlap; containing only the two overlapping nodes (one in blue and one in green); and having the critical ve",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:94739,Safety,avoid,avoid,94739,"eck at the level of a single volume by using `option`=""`d`"" or; `option`=""`d<number>`"" to perform overlap checking by sampling the; volume with \<`number`\> random points (default 1 million). This; produces also a picture showing in red the overlapping region and; estimates the volume of the overlaps. An extrusion *A)* is declared in any of the following cases:. - At least one of the vertices of the daughter mesh representation is; outside the mother volume (in fact its shape) and having a safety; distance to the mother greater than the desired value;; - At least one of the mother vertices is contained also by one of its; daughters, in the same conditions. An overlap *B)* is declared if:. - At least one vertex of a positioned volume mesh is contained (having; a safety bigger than the accepted maximum value) by other positioned; volume inside the same container. The check is performed also by; inverting the candidates. The code is highly optimized to avoid checking candidates that are far; away in space by performing a fast check on their bounding boxes. Once; the checking tool is fired-up inside a volume or at top level, the list; of overlaps (visible as Illegal overlaps inside a TBrowser) held; by the manager class will be filled with TGeoOverlap objects; containing a full description of the detected overlaps. The list is; sorted in the decreasing order of the overlapping distance, extrusions; coming first. An overlap object name represents the full description of; the overlap, containing both candidate node names and a letter; (x-extrusion, o-overlap) representing the type. Double-clicking an; overlap item in a TBrowser produces a picture of the overlap; containing only the two overlapping nodes (one in blue and one in green); and having the critical vertices represented by red points. The picture; can be rotated/zoomed or drawn in X3d as any other view. Calling; gGeoManager->PrintOverlaps() prints the list of overlaps. \anchor GP03b; ### Graphical Checking Method",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:95089,Safety,detect,detected,95089,"oduces also a picture showing in red the overlapping region and; estimates the volume of the overlaps. An extrusion *A)* is declared in any of the following cases:. - At least one of the vertices of the daughter mesh representation is; outside the mother volume (in fact its shape) and having a safety; distance to the mother greater than the desired value;; - At least one of the mother vertices is contained also by one of its; daughters, in the same conditions. An overlap *B)* is declared if:. - At least one vertex of a positioned volume mesh is contained (having; a safety bigger than the accepted maximum value) by other positioned; volume inside the same container. The check is performed also by; inverting the candidates. The code is highly optimized to avoid checking candidates that are far; away in space by performing a fast check on their bounding boxes. Once; the checking tool is fired-up inside a volume or at top level, the list; of overlaps (visible as Illegal overlaps inside a TBrowser) held; by the manager class will be filled with TGeoOverlap objects; containing a full description of the detected overlaps. The list is; sorted in the decreasing order of the overlapping distance, extrusions; coming first. An overlap object name represents the full description of; the overlap, containing both candidate node names and a letter; (x-extrusion, o-overlap) representing the type. Double-clicking an; overlap item in a TBrowser produces a picture of the overlap; containing only the two overlapping nodes (one in blue and one in green); and having the critical vertices represented by red points. The picture; can be rotated/zoomed or drawn in X3d as any other view. Calling; gGeoManager->PrintOverlaps() prints the list of overlaps. \anchor GP03b; ### Graphical Checking Methods. \image html geometry009.png ""Safety computation checking"" width=500px. In order to check a given point, `CheckPoint(x,y,z)` method of; TGeoManager draws the daughters of the volume containing the po",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:106052,Safety,detect,detector,106052,"4ca; #### Clipping Ray-traced Images. A ray-traced view can be `clipped` with any shape known by the modeller.; This means that the region inside the clipping shape is subtracted from; the current drawn geometry (become invisible). In order to activate; clipping, one has to first define the clipping shape(s):. 1. `TGeoShape *clip1, *clip2, ...`; One might switch between several clipping shapes. Note that these; shapes are considered defined in the current `MARS`. Composite shapes; may be used.; 2. `gGeoManager->SetClippingShape(clip1);`; One can activate or deactivate clipping at any time:; `gGeoManager->SetClipping(flag);`; 3. Perform ray-tracing:` gGeoManager->GetTopVolume()->Raytrace();`. One can redo the steps 2-3 as many times as needed. Let us look how the; rootgeom.C example looks clipped with a tube. \image html geometry014.png ""Ray-tracing example with box-clipping"". \anchor GP05; ## Representing Misalignments of the Ideal Geometry. The ideal positioning of a detector does not match its position in the; experimental hall. This generally happens not only for the detector; modules, but also for their components. The accurate knowledge of the; detector real misalignments can be extremely important for getting close; to its designed resolution and the expected tracking efficiency.; `TGeo` offers tools for representing positioning misalignments,; applying them to the ideal geometry and performing navigation under; these conditions. Detector tracking algorithms can then directly query; the geometry for navigation purposes or for retrieving actual; misalignment information. \anchor GP05a; ### Physical Nodes. Physical nodes are the actual ""touchable"" objects in the geometry,; representing actually a path of positioned volumes starting with the; top node: `path=/TOP/A_1/B_4/C_3` , where `A`, `B`, `C` represent names; of volumes. The number of physical nodes is given by the total number of; possible of branches in the geometry hierarchy. In case of detector; geometrie",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:106156,Safety,detect,detector,106156,"wn by the modeller.; This means that the region inside the clipping shape is subtracted from; the current drawn geometry (become invisible). In order to activate; clipping, one has to first define the clipping shape(s):. 1. `TGeoShape *clip1, *clip2, ...`; One might switch between several clipping shapes. Note that these; shapes are considered defined in the current `MARS`. Composite shapes; may be used.; 2. `gGeoManager->SetClippingShape(clip1);`; One can activate or deactivate clipping at any time:; `gGeoManager->SetClipping(flag);`; 3. Perform ray-tracing:` gGeoManager->GetTopVolume()->Raytrace();`. One can redo the steps 2-3 as many times as needed. Let us look how the; rootgeom.C example looks clipped with a tube. \image html geometry014.png ""Ray-tracing example with box-clipping"". \anchor GP05; ## Representing Misalignments of the Ideal Geometry. The ideal positioning of a detector does not match its position in the; experimental hall. This generally happens not only for the detector; modules, but also for their components. The accurate knowledge of the; detector real misalignments can be extremely important for getting close; to its designed resolution and the expected tracking efficiency.; `TGeo` offers tools for representing positioning misalignments,; applying them to the ideal geometry and performing navigation under; these conditions. Detector tracking algorithms can then directly query; the geometry for navigation purposes or for retrieving actual; misalignment information. \anchor GP05a; ### Physical Nodes. Physical nodes are the actual ""touchable"" objects in the geometry,; representing actually a path of positioned volumes starting with the; top node: `path=/TOP/A_1/B_4/C_3` , where `A`, `B`, `C` represent names; of volumes. The number of physical nodes is given by the total number of; possible of branches in the geometry hierarchy. In case of detector; geometries and specially for calorimeters this number can be of the; order 106-109, therefore it is",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:106237,Safety,detect,detector,106237,"nvisible). In order to activate; clipping, one has to first define the clipping shape(s):. 1. `TGeoShape *clip1, *clip2, ...`; One might switch between several clipping shapes. Note that these; shapes are considered defined in the current `MARS`. Composite shapes; may be used.; 2. `gGeoManager->SetClippingShape(clip1);`; One can activate or deactivate clipping at any time:; `gGeoManager->SetClipping(flag);`; 3. Perform ray-tracing:` gGeoManager->GetTopVolume()->Raytrace();`. One can redo the steps 2-3 as many times as needed. Let us look how the; rootgeom.C example looks clipped with a tube. \image html geometry014.png ""Ray-tracing example with box-clipping"". \anchor GP05; ## Representing Misalignments of the Ideal Geometry. The ideal positioning of a detector does not match its position in the; experimental hall. This generally happens not only for the detector; modules, but also for their components. The accurate knowledge of the; detector real misalignments can be extremely important for getting close; to its designed resolution and the expected tracking efficiency.; `TGeo` offers tools for representing positioning misalignments,; applying them to the ideal geometry and performing navigation under; these conditions. Detector tracking algorithms can then directly query; the geometry for navigation purposes or for retrieving actual; misalignment information. \anchor GP05a; ### Physical Nodes. Physical nodes are the actual ""touchable"" objects in the geometry,; representing actually a path of positioned volumes starting with the; top node: `path=/TOP/A_1/B_4/C_3` , where `A`, `B`, `C` represent names; of volumes. The number of physical nodes is given by the total number of; possible of branches in the geometry hierarchy. In case of detector; geometries and specially for calorimeters this number can be of the; order 106-109, therefore it is impossible to create all physical nodes; as objects in memory. In `TGeo`, physical nodes are represented by; the class TGeoPhysic",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:107051,Safety,detect,detector,107051,"happens not only for the detector; modules, but also for their components. The accurate knowledge of the; detector real misalignments can be extremely important for getting close; to its designed resolution and the expected tracking efficiency.; `TGeo` offers tools for representing positioning misalignments,; applying them to the ideal geometry and performing navigation under; these conditions. Detector tracking algorithms can then directly query; the geometry for navigation purposes or for retrieving actual; misalignment information. \anchor GP05a; ### Physical Nodes. Physical nodes are the actual ""touchable"" objects in the geometry,; representing actually a path of positioned volumes starting with the; top node: `path=/TOP/A_1/B_4/C_3` , where `A`, `B`, `C` represent names; of volumes. The number of physical nodes is given by the total number of; possible of branches in the geometry hierarchy. In case of detector; geometries and specially for calorimeters this number can be of the; order 106-109, therefore it is impossible to create all physical nodes; as objects in memory. In `TGeo`, physical nodes are represented by; the class TGeoPhysicalNode and can be created on demand for; alignment purposes:. ~~~{.cpp}; TGeoPhysicalNode(const char* path); ~~~. The knowledge of the path to the objects that need to be misaligned is; essential since there is no other way of identifying them. One can; however create ""symbolic links"" to any complex path to make it more; representable for the object it designates:. ~~~{.cpp}; TGeoPNEntry(const char* unique_name, const char* path); void TGeoPNEntry::SetPhysicalNode(TGeoPhysicalNode *node); ~~~. Such a symbolic link hides the complexity of the path to the align; object and replaces it with a more meaningful name. In addition,; TGeoPNEntry objects are faster to search by name and they may; optionally store an additional user matrix. ~~~{.cpp}; // Creating a symlink object.; TGeoPNEntry *TGeoManager::SetAlignableEntry(const char *uni",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:109531,Safety,avoid,avoid,109531,"e corresponds; to the level 0 in the stored array, while the last node will correspond; to level `n`. For each level, the node, volume and global matrix can be; retrieved using corresponding getters:. ~~~{.cpp}; TGeoHMatrix *GetMatrix(Int_t level=-1) const; TGeoNode *GetNode(Int_t level=-1) const; TGeoShape *GetShape(Int_t level=-1) const; TGeoVolume *GetVolume(Int_t level=-1) const; ~~~. By default the object at level n is retrieved (the align-able object). Once created, a physical node can be misaligned, meaning that its; positioning matrix or even the shape.:. ~~~{.cpp}; void Align(TGeoMatrix* newmat=0, TGeoShape* newshape=0,; Bool_t check=kFALSE); ~~~. The convention used is that newmat represents the new local matrix of; the last node in the branch with respect to its mother volume. The; `Align()` method will actually duplicate the corresponding branch within; the logical hierarchy, creating new volumes and nodes. This is mandatory; in order to avoid problems due to replicated volumes and can create; exhaustive memory consumption if used abusively. Once aligned, a physical node is ready to be tracked. The operation can; be done only after the geometry was closed. Important NOTE: Calling the `Align()` method for a physical node changes; the node pointers for the stored node branch in the active geometry, Due; to this the other defined physical nodes containing elements of this; path will be invalid. Example:. ~~~{.cpp}; TGeoPhysicalNode *pn1 =; gGeoManager->MakePhysicalNode(""/A_1/B_1/C_2"");; TGeoPhysicalNode *pn2 =; gGeoManager->MakePhysicalNode(""/A_1/B_1/C_3"");; ...; pn1->Align(...);; ~~~. The call to `pn1->Align()` will invalidate the pointer to the node `B_1`; in `pn2` object.. The way out is to either call `pn1->Align()` before; the creation of `pn2`, either to use a global method that will correct; all existing physical nodes:. ~~~{.cpp}; void RefreshPhysicalNodes(Bool_t lock = kTRUE); ~~~. The method above will optionally lock the possibility of doing any; ",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:120638,Safety,safe,safe,120638,"ned by the method is the object which shape; boundary will be crossed first. The distance to the next crossing can be; retrieved after the call:. ~~~{.cpp}; Double_t TGeoManager::GetStep(); ~~~. - The main input parameter is `stepmax,` which act as a trigger for; different features. The absolute value of this parameter represents; the step value proposed by the user. The algorithm will never try o; search for boundaries further than this distance. In case no; boundary is found the returned node will be the current one and the; computed step to boundary will be equal to abs (`stepmax`) having; the meaning ""step approved"". The default value for `stepmax` is; TGeoShape::Big with the meaning that boundaries are looked for; without limitation. \image html geometry017.png ""Finding the distance to the next crossed boundary"" width=600px. According the values of the input parameters the method will perform; additional optional tasks:. `|stepmax| < TGeoShape::Big()`. The safe distance in the current volume is also computed. Moving the; particle from its current location with this distance in any direction; is safe in the sense that will never change the current state. `stepmax < 0`. The global matrix for the object that will have the next crossed; boundary is also computed. This can be retrieved for masterlocal point; or vector conversions: TGeoManager::GetNextMatrix(). In case the computation of the normal vector to the next crossed surface; is required, using a negative stepmax value is recommended. In this case; one can subsequently call a method for fast normal computation:. ~~~{.cpp}; Double_t *TGeoManager::FindNormalFast(); ~~~. `path 0`. In case a path to a given physical object is specified, the distance to; its boundary is computed ignoring the rest of the geometry. \anchor GP07c; #### Output Values. TGeoManager::GetStep(): distance to next boundary. TGeoManager::GetSafeDistance(): safe distance (in case it was computed). TGeoManager::IsOnBoundary(): the initial poin",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:120779,Safety,safe,safe,120779,"crossing can be; retrieved after the call:. ~~~{.cpp}; Double_t TGeoManager::GetStep(); ~~~. - The main input parameter is `stepmax,` which act as a trigger for; different features. The absolute value of this parameter represents; the step value proposed by the user. The algorithm will never try o; search for boundaries further than this distance. In case no; boundary is found the returned node will be the current one and the; computed step to boundary will be equal to abs (`stepmax`) having; the meaning ""step approved"". The default value for `stepmax` is; TGeoShape::Big with the meaning that boundaries are looked for; without limitation. \image html geometry017.png ""Finding the distance to the next crossed boundary"" width=600px. According the values of the input parameters the method will perform; additional optional tasks:. `|stepmax| < TGeoShape::Big()`. The safe distance in the current volume is also computed. Moving the; particle from its current location with this distance in any direction; is safe in the sense that will never change the current state. `stepmax < 0`. The global matrix for the object that will have the next crossed; boundary is also computed. This can be retrieved for masterlocal point; or vector conversions: TGeoManager::GetNextMatrix(). In case the computation of the normal vector to the next crossed surface; is required, using a negative stepmax value is recommended. In this case; one can subsequently call a method for fast normal computation:. ~~~{.cpp}; Double_t *TGeoManager::FindNormalFast(); ~~~. `path 0`. In case a path to a given physical object is specified, the distance to; its boundary is computed ignoring the rest of the geometry. \anchor GP07c; #### Output Values. TGeoManager::GetStep(): distance to next boundary. TGeoManager::GetSafeDistance(): safe distance (in case it was computed). TGeoManager::IsOnBoundary(): the initial point `(x,y,z)` was (or was; not) on a boundary within TGeoShape::Tolerance(). The algorithm checks first i",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:121576,Safety,safe,safe,121576,"ional optional tasks:. `|stepmax| < TGeoShape::Big()`. The safe distance in the current volume is also computed. Moving the; particle from its current location with this distance in any direction; is safe in the sense that will never change the current state. `stepmax < 0`. The global matrix for the object that will have the next crossed; boundary is also computed. This can be retrieved for masterlocal point; or vector conversions: TGeoManager::GetNextMatrix(). In case the computation of the normal vector to the next crossed surface; is required, using a negative stepmax value is recommended. In this case; one can subsequently call a method for fast normal computation:. ~~~{.cpp}; Double_t *TGeoManager::FindNormalFast(); ~~~. `path 0`. In case a path to a given physical object is specified, the distance to; its boundary is computed ignoring the rest of the geometry. \anchor GP07c; #### Output Values. TGeoManager::GetStep(): distance to next boundary. TGeoManager::GetSafeDistance(): safe distance (in case it was computed). TGeoManager::IsOnBoundary(): the initial point `(x,y,z)` was (or was; not) on a boundary within TGeoShape::Tolerance(). The algorithm checks first if the computation of safety was required. If; this is the case and the global point coordinates did not change from; the last query, the last computed safety is taken. Otherwise, the method; TGeoManager::Safety () is invoked. A safety value less than; TGeoShape::Tolerance() will set the flag IsOnBoundary to true.; On the other hand, a safety value bigger than the proposed step will; stop the computation of the distance to next boundary, returning the; current geometry location with the meaning that the proposed step is; safe. The next stage is to check if computation of the distance to a give; physical object specified by a path was required. If this is the case,; the modeller changes the state to point to the required object, converts; the current point and direction coordinates to the local frame of th",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:121786,Safety,safe,safety,121786,"ion; is safe in the sense that will never change the current state. `stepmax < 0`. The global matrix for the object that will have the next crossed; boundary is also computed. This can be retrieved for masterlocal point; or vector conversions: TGeoManager::GetNextMatrix(). In case the computation of the normal vector to the next crossed surface; is required, using a negative stepmax value is recommended. In this case; one can subsequently call a method for fast normal computation:. ~~~{.cpp}; Double_t *TGeoManager::FindNormalFast(); ~~~. `path 0`. In case a path to a given physical object is specified, the distance to; its boundary is computed ignoring the rest of the geometry. \anchor GP07c; #### Output Values. TGeoManager::GetStep(): distance to next boundary. TGeoManager::GetSafeDistance(): safe distance (in case it was computed). TGeoManager::IsOnBoundary(): the initial point `(x,y,z)` was (or was; not) on a boundary within TGeoShape::Tolerance(). The algorithm checks first if the computation of safety was required. If; this is the case and the global point coordinates did not change from; the last query, the last computed safety is taken. Otherwise, the method; TGeoManager::Safety () is invoked. A safety value less than; TGeoShape::Tolerance() will set the flag IsOnBoundary to true.; On the other hand, a safety value bigger than the proposed step will; stop the computation of the distance to next boundary, returning the; current geometry location with the meaning that the proposed step is; safe. The next stage is to check if computation of the distance to a give; physical object specified by a path was required. If this is the case,; the modeller changes the state to point to the required object, converts; the current point and direction coordinates to the local frame of this; object and computes the distance to its shape. The node returned is the; one pointed by the input path in case the shape is crossed; otherwise; the returned value is NULL. In case the dis",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:121916,Safety,safe,safety,121916,"ix for the object that will have the next crossed; boundary is also computed. This can be retrieved for masterlocal point; or vector conversions: TGeoManager::GetNextMatrix(). In case the computation of the normal vector to the next crossed surface; is required, using a negative stepmax value is recommended. In this case; one can subsequently call a method for fast normal computation:. ~~~{.cpp}; Double_t *TGeoManager::FindNormalFast(); ~~~. `path 0`. In case a path to a given physical object is specified, the distance to; its boundary is computed ignoring the rest of the geometry. \anchor GP07c; #### Output Values. TGeoManager::GetStep(): distance to next boundary. TGeoManager::GetSafeDistance(): safe distance (in case it was computed). TGeoManager::IsOnBoundary(): the initial point `(x,y,z)` was (or was; not) on a boundary within TGeoShape::Tolerance(). The algorithm checks first if the computation of safety was required. If; this is the case and the global point coordinates did not change from; the last query, the last computed safety is taken. Otherwise, the method; TGeoManager::Safety () is invoked. A safety value less than; TGeoShape::Tolerance() will set the flag IsOnBoundary to true.; On the other hand, a safety value bigger than the proposed step will; stop the computation of the distance to next boundary, returning the; current geometry location with the meaning that the proposed step is; safe. The next stage is to check if computation of the distance to a give; physical object specified by a path was required. If this is the case,; the modeller changes the state to point to the required object, converts; the current point and direction coordinates to the local frame of this; object and computes the distance to its shape. The node returned is the; one pointed by the input path in case the shape is crossed; otherwise; the returned value is NULL. In case the distance to next crossed; boundary is required, the current point has to be physically INSIDE the; sh",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:121993,Safety,safe,safety,121993,"tMatrix(). In case the computation of the normal vector to the next crossed surface; is required, using a negative stepmax value is recommended. In this case; one can subsequently call a method for fast normal computation:. ~~~{.cpp}; Double_t *TGeoManager::FindNormalFast(); ~~~. `path 0`. In case a path to a given physical object is specified, the distance to; its boundary is computed ignoring the rest of the geometry. \anchor GP07c; #### Output Values. TGeoManager::GetStep(): distance to next boundary. TGeoManager::GetSafeDistance(): safe distance (in case it was computed). TGeoManager::IsOnBoundary(): the initial point `(x,y,z)` was (or was; not) on a boundary within TGeoShape::Tolerance(). The algorithm checks first if the computation of safety was required. If; this is the case and the global point coordinates did not change from; the last query, the last computed safety is taken. Otherwise, the method; TGeoManager::Safety () is invoked. A safety value less than; TGeoShape::Tolerance() will set the flag IsOnBoundary to true.; On the other hand, a safety value bigger than the proposed step will; stop the computation of the distance to next boundary, returning the; current geometry location with the meaning that the proposed step is; safe. The next stage is to check if computation of the distance to a give; physical object specified by a path was required. If this is the case,; the modeller changes the state to point to the required object, converts; the current point and direction coordinates to the local frame of this; object and computes the distance to its shape. The node returned is the; one pointed by the input path in case the shape is crossed; otherwise; the returned value is NULL. In case the distance to next crossed; boundary is required, the current point has to be physically INSIDE the; shape pointed by the current volume. This is only insured in case a call; to TGeoManager::FindNode() was performed for the current point.; Therefore, the first step is ",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:122102,Safety,safe,safety,122102,"case; one can subsequently call a method for fast normal computation:. ~~~{.cpp}; Double_t *TGeoManager::FindNormalFast(); ~~~. `path 0`. In case a path to a given physical object is specified, the distance to; its boundary is computed ignoring the rest of the geometry. \anchor GP07c; #### Output Values. TGeoManager::GetStep(): distance to next boundary. TGeoManager::GetSafeDistance(): safe distance (in case it was computed). TGeoManager::IsOnBoundary(): the initial point `(x,y,z)` was (or was; not) on a boundary within TGeoShape::Tolerance(). The algorithm checks first if the computation of safety was required. If; this is the case and the global point coordinates did not change from; the last query, the last computed safety is taken. Otherwise, the method; TGeoManager::Safety () is invoked. A safety value less than; TGeoShape::Tolerance() will set the flag IsOnBoundary to true.; On the other hand, a safety value bigger than the proposed step will; stop the computation of the distance to next boundary, returning the; current geometry location with the meaning that the proposed step is; safe. The next stage is to check if computation of the distance to a give; physical object specified by a path was required. If this is the case,; the modeller changes the state to point to the required object, converts; the current point and direction coordinates to the local frame of this; object and computes the distance to its shape. The node returned is the; one pointed by the input path in case the shape is crossed; otherwise; the returned value is NULL. In case the distance to next crossed; boundary is required, the current point has to be physically INSIDE the; shape pointed by the current volume. This is only insured in case a call; to TGeoManager::FindNode() was performed for the current point.; Therefore, the first step is to convert the global current point and; direction in the local reference frame of the current volume and to; compute the distance to exit its shape from",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:122291,Safety,safe,safe,122291,"case; one can subsequently call a method for fast normal computation:. ~~~{.cpp}; Double_t *TGeoManager::FindNormalFast(); ~~~. `path 0`. In case a path to a given physical object is specified, the distance to; its boundary is computed ignoring the rest of the geometry. \anchor GP07c; #### Output Values. TGeoManager::GetStep(): distance to next boundary. TGeoManager::GetSafeDistance(): safe distance (in case it was computed). TGeoManager::IsOnBoundary(): the initial point `(x,y,z)` was (or was; not) on a boundary within TGeoShape::Tolerance(). The algorithm checks first if the computation of safety was required. If; this is the case and the global point coordinates did not change from; the last query, the last computed safety is taken. Otherwise, the method; TGeoManager::Safety () is invoked. A safety value less than; TGeoShape::Tolerance() will set the flag IsOnBoundary to true.; On the other hand, a safety value bigger than the proposed step will; stop the computation of the distance to next boundary, returning the; current geometry location with the meaning that the proposed step is; safe. The next stage is to check if computation of the distance to a give; physical object specified by a path was required. If this is the case,; the modeller changes the state to point to the required object, converts; the current point and direction coordinates to the local frame of this; object and computes the distance to its shape. The node returned is the; one pointed by the input path in case the shape is crossed; otherwise; the returned value is NULL. In case the distance to next crossed; boundary is required, the current point has to be physically INSIDE the; shape pointed by the current volume. This is only insured in case a call; to TGeoManager::FindNode() was performed for the current point.; Therefore, the first step is to convert the global current point and; direction in the local reference frame of the current volume and to; compute the distance to exit its shape from",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:123311,Safety,safe,safe,123311,"s; safe. The next stage is to check if computation of the distance to a give; physical object specified by a path was required. If this is the case,; the modeller changes the state to point to the required object, converts; the current point and direction coordinates to the local frame of this; object and computes the distance to its shape. The node returned is the; one pointed by the input path in case the shape is crossed; otherwise; the returned value is NULL. In case the distance to next crossed; boundary is required, the current point has to be physically INSIDE the; shape pointed by the current volume. This is only insured in case a call; to TGeoManager::FindNode() was performed for the current point.; Therefore, the first step is to convert the global current point and; direction in the local reference frame of the current volume and to; compute the distance to exit its shape from inside. The returned value; is again compared to the maximum allowed step (the proposed one) and in; case the distance is safe no other action is performed and the proposed; step is approved. In case the boundary is closer, the computed distance; is taken as maximum allowed step. For optimization purposed, for; particles starting very close to the current volume boundary (less than; 0.01 microns) and exiting the algorithm stops here. After computing the distance to exit the current node, the distance to; the daughter of the current volume which is crossed next is computed by; TGeoManager::FindNextDaughterBoundary(). This computes the; distance to all daughter candidates that can be possibly crossed by; using volume voxelization. The algorithm is efficient in average only in; case the number of daughters is greater than 4. For fewer nodes, a; simple loop is performed and the minimum distance (from a point outside; each shape) is taken and compared to the maximum allowed step. The step; value is again updated if `step<stepmax` . A special case is when the current node is declared as p",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:5370,Security,access,accessed,5370,"nalogy with a tree structure). On the other hand, any volume is a small world by itself - what we need; to do is to take it out and to ignore all the rest since it is a; self-contained object. In fact, the modeller can act like this,; considering a given volume as temporary MARS, but we will describe this; feature later on. Let us focus on the biggest pack - it is mandatory to; define one. Consider the simplest geometry that is made of a single box.; Here is an example on how to build it:. \anchor GP00a; ### Example 1: Creating the World. We first need to load the geometry library. This is not needed if one; does ""make map"" in root folder. ~~~{.cpp}; root[] gSystem->Load(""libGeom"");; ~~~. Second, we have to create an instance of the geometry manager class.; This takes care of all the modeller components, performing several tasks; to insure geometry validity and containing the user interface for; building and interacting with the geometry. After its creation, the; geometry manager class can be accessed with the global; `gGeoManager`:. ~~~{.cpp}; root[] new TGeoManager(""world"", ""the simplest geometry"");; ~~~. We want to create a single volume in our geometry, but since any volume; needs to have an associated medium, we will create a dummy one. You can; safely ignore the following lines for the time being, since materials; and media will be explained in detail later on. ~~~{.cpp}; root[] TGeoMaterial *mat = new TGeoMaterial(""Vacuum"",0,0,0);; root[] TGeoMedium *med = new TGeoMedium(""Vacuum"",1,mat);; ~~~. We can finally make our volume having a box shape. Note that the world; volume does not need to be a box - it can be any other shape. Generally,; boxes and tubes are the most recommendable shapes for this purpose due; to their fast navigation algorithms. ~~~{.cpp}; root[] TGeoVolume *top=gGeoManager->MakeBox(""Top"",med,10.,10.,10.);; ~~~. The default units are in centimeters. Now we want to make this volume; our world. We have to do this operation **before** closing the g",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:12968,Security,access,accessed,12968,"ng the; Geometry""). If tracking is performed using `TGeo`, the folder; `Tracks` might contain user-defined tracks that can be; visualized/animated in the geometry context (see section: ""Creating and; Visualizing Tracks""). Since for the time being we are interested more in; the geometrical hierarchy, we will focus on the last two displayed items; `TOP `and `TOP_1`. These are the top volume and the corresponding top; node in the hierarchy. Double clicking on the `TOP` volume will unfold all different volumes; contained by the top volume. In the right panel, we will see all the; volumes contained by `TOP` (if the same is positioned 4 times we will; get 4 identical items). This rule will apply to any clicked volume in; the hierarchy. Note that right clicking a volume item activates the; volume context menu containing several specific methods. We will call; the volume hierarchy developed in this way as the; `logical geometry graph`. The volume objects are nodes inside this graph; and the same volume can be accessed starting from different branches. On the other hand, the real geometrical objects that are seen when; visualizing or tracking the geometry are depicted in the `TOP_1` branch.; These are the nodes of the `physical` `tree` of positioned volumes; represented by TGeoNode objects. This hierarchy is a tree since a; node can have only one parent and several daughters. For a better; understanding of the hierarchy, have a look at TGeoManage. Just close now the `X3D` window and focus at the wire frame picture; drawn in a pad. Activate Options/Event Status. Moving the mouse in the; pad, you will notice that objects are sometimes changing color to red.; Volumes are highlighted in this way whenever the mouse pointer is close; enough to one of its vertices. When this happens, the corresponding; volume is selected and you will see in the bottom right size of the %ROOT; canvas its name, shape type and corresponding path in the physical tree.; Right clicking on the screen when",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:59876,Security,access,accessible,59876,"determinant, inverse. - Scale transformations (TGeoScale class) - represent a scaled; shrinking/enlargement, possibly different on all axes. Data members:; `Double_t fScale[3]`. Not implemented yet.; - Combined transformations - represent a rotation followed by a; translation. Data members:; `Double_t fTranslation[3]`, `TGeoRotation *fRotation`. ~~~{.cpp}; TGeoRotation *rot = new TGeoRotation(""rot"",10,20,30);; TGeoTranslation trans;; ...; TGeoCombiTrans *c1 = new TGeoCombiTrans(trans,rot);; TGeoCombiTrans *c2 = new TGeoCombiTrans(""somename"",10,20,30,rot); ~~~. - General transformations: (TGeoHMatrix class) represent; combined transformations in any order.; - Identity transformation: (TGeoIdentity class) is a generic; identity transformation represented by a singleton class object; `gGeoIdentity`. \anchor GP01d; ### Ownership of Geometry Objects. The class TGeoManager class contains the entire API needed for; building and tracking geometry. It defines a global pointer; `gGeoManager` in order to be fully accessible from external code.; The manager class is the owner of all geometry objects defined in a; session; therefore, users must not try to control their deletion. It; contains lists of media, materials, transformations, shapes and volumes.; A special case is the one of geometrical transformations. When creating; a matrix or a translation, this is by default owned by external objects.; The manager class becomes owner of all transformations used for; positioning volumes. In order to force the ownership for other; transformations, one can use TGeoMatrix::RegisterYourself() method. Do; not be therefore surprised that some transformations cannot be found by; name when creating a composite shape for instance if you did not; register them after creation. Logical nodes (positioned volumes) are created and destroyed by the; TGeoVolume class. Physical nodes and their global transformations; are subjected to a caching mechanism due to the sometimes very large; memory requirem",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:62129,Security,access,access,62129,"s linked with %ROOT graphical libraries loaded on demand in order to; control visualization actions. \anchor GP02; ## Navigation and Tracking. Tracking is the feature allowing the transport of a given particle; knowing its kinematics. A state is determined by any combination of the; position \f$\vec{r}\f$ and direction \f$\vec{n}\f$ with respect to the world; reference frame. The direction \f$\vec{n}\f$ must be a unit vector having as; components the director cosines. The full classification of a given; state will provide the following information: the deepest physical node; containing the position vector, the distance to the closest boundary; along the direction vector, the next physical node after propagating the; current point with this distance and the safety distance to the nearest; boundary. This information allows the propagation of particles inside a; detector geometry by taking into account both geometrical and physical; constraints. We will hereby describe the user interface of `TGeo` to access; tracking functionality. This allows either developing a tracker for; simple navigation within a given geometry, either interfacing to an; external tracking engine such as GEANT. Note that the abstract interface; for external trackers can be found in `$ROOTSYS/vmc` folder and it can; be used to run GEANT3, GEANT4 and FLUKA-based simulations (\*) by using; directly a geometry described with %ROOT. The interface methods related to tracking are incorporated into; TGeoManager class and implemented in the navigator class; TGeoNavigator. In order to be able to start tracking, one has to; define the initial state providing the starting point \f$\vec{r_0}\f$; and direction \f$\vec{n_0}\f$ .; There are several ways of doing that. \anchor GP02a; ### TGeoNavigator Class. One geometry may have several independent navigators to query to; localize points or compute distances. The geometry manager holds a list; of active navigators accessible via:. ~~~{.cpp}; TObjArray *navigators",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:63067,Security,access,accessible,63067,"and physical; constraints. We will hereby describe the user interface of `TGeo` to access; tracking functionality. This allows either developing a tracker for; simple navigation within a given geometry, either interfacing to an; external tracking engine such as GEANT. Note that the abstract interface; for external trackers can be found in `$ROOTSYS/vmc` folder and it can; be used to run GEANT3, GEANT4 and FLUKA-based simulations (\*) by using; directly a geometry described with %ROOT. The interface methods related to tracking are incorporated into; TGeoManager class and implemented in the navigator class; TGeoNavigator. In order to be able to start tracking, one has to; define the initial state providing the starting point \f$\vec{r_0}\f$; and direction \f$\vec{n_0}\f$ .; There are several ways of doing that. \anchor GP02a; ### TGeoNavigator Class. One geometry may have several independent navigators to query to; localize points or compute distances. The geometry manager holds a list; of active navigators accessible via:. ~~~{.cpp}; TObjArray *navigators = gGeoManager->GetListOfNavigators();; ~~~. Upon closing the geometry a default navigator is provided as first one; in this list, but one may add its own via:. ~~~{.cpp}; TGeoNavigator *navig = new TGeoNavigator(gGeoManager);; // Store the index of the user navigator; Int_t inav = gGeoManager->AddNavigator(navig);; // Make its own navigator the active one; gGeoManager->SetCurrentNavigator(inav);; // Switch between navigators; gGeoManager->SetCurrentNavigator(0);; ~~~. A navigator holds several variables describing the current navigation; state: current point position, current direction distance to next; boundary, isotropic safety, pointer to current and next nods as well as; several tracking flags related to volume boundary conditions or other; properties required for track propagation in geometry. Each geometry; query affects these variables, so the only way in testing several; navigation alternatives and rememberin",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:73348,Security,access,access,73348," be done by using the global transformation or; directly the **`TGeoManager`** corresponding interfaces:. ~~~{.cpp}; Double_t *glob_pt = gGeoManager->GetCurrentPoint();; Double_t *glob_dir = gGeoManager->GetCurrentDirection();; Double_t loc_pt[3], loc_dir[3];; // Go from MARS to local coordinates:; gGeoManager->MasterToLocal(glob_pt,loc_pt); // or:; global->MasterToLocal(glob_pt,loc_pt); // will be omitted from now; ~~~. \anchor GP02f; ### Saving and Restoring the Current State. As we already described, saving and restoring modeller states can be; quite useful during tracking and is a feature extensively used by; external tracking engines. We will call this navigation history; management, which in most of the cases can be performed by handling the; state identifiers. For quite big geometries, state indexing is not; possible anymore and will be automatically disabled by the modeller.; Fortunately there is a backup solution working in any condition: the; modeller maintains a stack of states that is internally used by its own; navigation algorithms, but user code is also allowed to access it. This; works on any stack principle by using PUSH and POP calls and user code; is responsible for popping the pushed states in order to keep the stack; clean. ~~~{.cpp}; // push the current state in the stack; Int_t index = gGeoManager->PushPath();; // push state and current point; Int_t index = gGeoManager->PushPoint();; // retrieves the last pushed state (decrements stack index); gGeoManager->PopPath();; // the same but retrieves also the point location; gGeoManager->PopPoint();; // just decrement stack index without changing state; gGeoManager->PopDummy();; // retrieves a state at given index without changing stack index; gGeoManager->PopPath(Int_t index);; ~~~. \anchor GP02g; ### Navigation Queries. After initializing the current state related to a given point and; direction defined in `MARS` `(‘Where am I?')`, one can query for several; geometrical quantities. All the related a",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:88234,Security,access,accessed,88234,"(track);; // or directly; gGeoManager->SetCurrentTrack(track_index);; TVirtualGeoTrack *current = gGeoManager->GetCurrentTrack();; ~~~. One can also look for a track by `user id` or `track index`:. ~~~{.cpp}; ptrTrack = gGeoManager->GetTrackOfId(user_id);; ptrParent = gGeoManager->GetParentTrackOfId(user_id);; ptrTrack = gGeoManager->GetTrack(index);; ~~~. Supposing a particle represented by a primary track decays or interacts,; one should not create new primaries as described before, but rather add; them as secondary:. ~~~{.cpp}; TVirtualGeoTrack *secondary =; ptrTrack->AddTrack(secondId,pdg,secondParticle);; ~~~. At any step made by the current track, one is able to add control points; to either primary or secondary:. ~~~{.cpp}; track->AddPoint(x,y,z,t);; ~~~. After tracks were defined and filled during tracking, one will be able; to browse directly the list of tracks held by the manager class. Any; track can be drawn using its `Draw()` and `Animate()` methods, but there; are also global methods for drawing or animation that can be accessed; from TGeoManager context menu:. ~~~{.cpp}; TGeoManager::DrawTracks(Option_t *option);; TGeoManager::AnimateTracks(Double_t tmin=0.,Double_t tmax=1E-8,; Int_t nframes=200,Option_t *option="""");; ~~~. The drawing/animation time range is a global variable that can be; directly set:. ~~~{.cpp}; gGeoManager->SetTminTmax(tmin, tmax);; // without arguments resets the time range to the maximum value; ~~~. Once set, the time range will be active both for individual or global; track drawing. For animation, this range is divided to the desired; number of frames and will be automatically updated at each frame in; order to get the animation effect. The option provided to all track-drawing methods can trigger different; track selections:. `default: `A track (or all primary tracks) drawn without daughters. `/D:` Track and first level descendents only are drawn. `/*: ` Track and all descendents are drawn. `/Ntype:` All tracks having `name=type",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:89849,Security,access,accessible,89849,"mation effect. The option provided to all track-drawing methods can trigger different; track selections:. `default: `A track (or all primary tracks) drawn without daughters. `/D:` Track and first level descendents only are drawn. `/*: ` Track and all descendents are drawn. `/Ntype:` All tracks having `name=type` are drawn. Generally several options can be concatenated in the same string (E.g.; `""/D /Npion-""`). For animating tracks, additional options can be added:. `/G:`Geometry animate. Generally when drawing or animating tracks, one; has to first perform a normal drawing of the geometry as convenient. The; tracks will be drawn over the geometry. The geometry itself will be; animated (camera moving and rotating in order to ""catch"" the majority of; current track segments.). `/S:`Save all frames in gif format in the current folder. This option; allows creating a movie based on individual frames. \anchor GP03; ## Checking the Geometry. Several checking methods are accessible from the context menu of volume; objects or of the manager class. They generally apply only to the; visible parts of the drawn geometry in order to ease geometry checking,; and their implementation is in the TGeoChecker class. The checking; package contains an overlap checker and several utility methods that; generally have visualization outputs. \anchor GP03a; ### The Overlap Checker. An overlap is any region in the Euclidian space being contained by more; than one positioned volume. Due to the containment scheme used by the; modeller, all points inside a volume have to be also contained by the; mother therefore are overlapping in that sense. This category of; overlaps is ignored due to the fact that any such point is treated as; belonging to the deepest node in the hierarchy. \image html geometry007.png ""Extruding volumes"". A volume containment region is in fact the result of the subtraction of; all daughters. On the other hand, there are two other categories of; overlaps that are considered ill",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:98049,Security,validat,validation,98049,"the main one provides all functionality being; linked with the underlying ROOT visualization system. This library is; dynamically loaded by the plug-in manager only when drawing features are; requested. The geometrical structures that can be visualized are volumes; and volume hierarchies. The main component of the visualization system is volume primitive; painting in a ROOT pad. Starting from this one, several specific options; or subsystems are available, like: X3D viewing using hidden line and; surface removal algorithms, OpenGL viewing\* or ray tracing. The method TGeoManager::GetGeomPainter() loads the painting library in; memory. This is generally not needed since it is called automatically by; TGeoVolume::Draw() as well as by few other methods setting; visualization attributes. \anchor GP04a; ### Drawing Volumes and Hierarchies of Volumes. The first thing one would like to do after building some geometry is to; visualize the volume tree. This provides the fastest validation check; for most common coding or design mistakes. As soon as the geometry is; successfully closed, one should draw it starting from the top-level; volume:. ~~~{.cpp}; //... code for geometry building; root[] gGeoManager->CloseGeometry();; root[] gGeoManager->GetMasterVolume()->Draw();; ~~~. Doing this ensures that the original top-level volume of the geometry is; drawn, even if another volume is currently the geometry `root`. OK, I; suppose you already did that with your simple geometry and immediately; noticed a new ROOT canvas popping-up and having some more or less; strange picture inside. Here are few questions that might come:. **Q:** ""The picture is strangely rotated; where are the coordinate axes?"". **A:** If drawn in a new canvas, any view has some default; viewpoint, center of view and size. One can then perform mouse/keyboard; actions to change them:. - Mouse left-click and drag will rotate the view;. - Some keys can be pressed when the view canvas is selected: J/K; zoom/un-zoom, U",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:104678,Security,validat,validation,104678,"tracing is a quite known drawing technique based on tracking rays; from the eye position through all pixels of a view port device. The; pixel color is derived from the properties of the first crossed surface,; according some illumination model and material optical properties. While; there are currently existing quite sophisticated ray tracing models,; `TGeo` is currently using a very simple approach where the light; source is matching the eye position (no shadows or back-tracing of the; reflected ray). In future we are considering providing a base class in; order to be able to derive more complex models. Due to the fact that the number of rays that have to be tracked matches; the size in pixels of the pad, the time required by this algorithm is; proportional to the pad size. On the other hand, the speed is quite; acceptable for the default ROOT pad size and the images produced by; using this technique have high quality. Since the algorithm is; practically using all navigation features, producing ray-traced pictures; is also a geometry validation check. Ray tracing can be activated at; volume level as the normal `Draw()`. \image html geometry013.jpg ""Ray-traced view in a pad"". ~~~{.cpp}; myVolume->Raytrace(); ~~~. Once ray-tracing a view, this can be zoomed or rotated as a usual one.; Objects on the screen are no longer highlighted when picking the; vertices but the corresponding volumes is still accessible. \anchor GP04ca; #### Clipping Ray-traced Images. A ray-traced view can be `clipped` with any shape known by the modeller.; This means that the region inside the clipping shape is subtracted from; the current drawn geometry (become invisible). In order to activate; clipping, one has to first define the clipping shape(s):. 1. `TGeoShape *clip1, *clip2, ...`; One might switch between several clipping shapes. Note that these; shapes are considered defined in the current `MARS`. Composite shapes; may be used.; 2. `gGeoManager->SetClippingShape(clip1);`; One can activat",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:105046,Security,access,accessible,105046,"rrently using a very simple approach where the light; source is matching the eye position (no shadows or back-tracing of the; reflected ray). In future we are considering providing a base class in; order to be able to derive more complex models. Due to the fact that the number of rays that have to be tracked matches; the size in pixels of the pad, the time required by this algorithm is; proportional to the pad size. On the other hand, the speed is quite; acceptable for the default ROOT pad size and the images produced by; using this technique have high quality. Since the algorithm is; practically using all navigation features, producing ray-traced pictures; is also a geometry validation check. Ray tracing can be activated at; volume level as the normal `Draw()`. \image html geometry013.jpg ""Ray-traced view in a pad"". ~~~{.cpp}; myVolume->Raytrace(); ~~~. Once ray-tracing a view, this can be zoomed or rotated as a usual one.; Objects on the screen are no longer highlighted when picking the; vertices but the corresponding volumes is still accessible. \anchor GP04ca; #### Clipping Ray-traced Images. A ray-traced view can be `clipped` with any shape known by the modeller.; This means that the region inside the clipping shape is subtracted from; the current drawn geometry (become invisible). In order to activate; clipping, one has to first define the clipping shape(s):. 1. `TGeoShape *clip1, *clip2, ...`; One might switch between several clipping shapes. Note that these; shapes are considered defined in the current `MARS`. Composite shapes; may be used.; 2. `gGeoManager->SetClippingShape(clip1);`; One can activate or deactivate clipping at any time:; `gGeoManager->SetClipping(flag);`; 3. Perform ray-tracing:` gGeoManager->GetTopVolume()->Raytrace();`. One can redo the steps 2-3 as many times as needed. Let us look how the; rootgeom.C example looks clipped with a tube. \image html geometry014.png ""Ray-tracing example with box-clipping"". \anchor GP05; ## Representing Misali",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:126220,Security,access,access,126220," the next crossed one, but the physical path (state) AFTER crossing; the boundary is not determined. In order to find out this new state, one; has to propagate the point with a distance slightly bigger that the; computed step value (which is accurate within numerical precision). A; method that performs this task finding the next location is; TGeoManager::Step(), described in ""Making a Step"", but users may; implement more precise methods to insure post-step boundary crossing. \anchor GP08; ## Geometry Graphical User Interface. The geombuilder package allows you to create and edit geometries. The; package provides a library of all GUI classes related to geometry. Each; editable geometry class `TGeoXXX` have a correspondent editor; `TGeoXXXEditor` that provides a graphics user interface allowing to; edit some (or all) parameters of a geometry object. The editable objects; are geometry manager, volumes, nodes, shapes, media, materials and; matrices. The interfaces provide also access to specific functionality; of geometry objects. The editing mechanism is based on ROOT GED; (Graphics Editors) functionality and the library is loaded using the; plug-in mechanism. \anchor GP08a; ### Editing a Geometry. There are two different use cases having different ways of invoking the; geometry editors. The first one applies when starting with geometry from; scratch and using the builder functionality to create new geometry; objects. In this case, one should use the sequence:. ~~~{.cpp}; root[] TGeoManager *geom = new TGeoManager(""MyGeom"",; ""Test builder"");; root[] geom->Edit(Option_t *option="""");; ~~~. The lines above will create a new TGeoManager class, create an; empty canvas and start the editor in the left-sided editor frame; attached to the canvas. To open the editor in a separate frame one; should provide a non-empty string as option to the `Edit()` method. \image html geometry018.png ""The geometry manager editor"". \anchor GP08b; ### The Geometry Manager Editor. \image html geom",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:128013,Security,access,accessed,128013,"ed to the canvas. To open the editor in a separate frame one; should provide a non-empty string as option to the `Edit()` method. \image html geometry018.png ""The geometry manager editor"". \anchor GP08b; ### The Geometry Manager Editor. \image html geometry019.png ""Accessing/creating different categories of editable objects"" width=600px. The second use case applies when starting to edit an existing geometry.; Supposing the geometry was loaded into memory, besides the first method; that still applies one can also edit drawn geometry objects. For this,; the menu entry View/Editor of the canvas containing for instance a drawn; volume must be activated. For starting the volume editor one can click; on a volume. The GUI of the TGeoManager class can be started by; clicking on the top-right `40x40` pixels corner of the pad with a drawn; geometry. This is the main entry point for editing the geometry or creating new; objects. Once the interface is created (using one of the methods; described above), several categories can be accessed via a shutter GUI; widget:. - *General.* This allows changing the name/title of the geometry,; setting the top volume, closing the geometry and saving the geometry; in a file. The file name is formed by `geometry_name.C` or `.root`; depending if the geometry need to be saved as a `C` macro or a; `.root` file.; - *Shapes.* The category provides buttons for creation of all; supported shapes. The new shape name is chosen by the interface, but; can be changed from the shape editor GUI. Existing shapes can be; browsed and edited from the same category.; - *Volumes.* The category allows the creation of a new volume having a; given name, shape and medium. For creating a volume assembly only; the name is relevant. Existing volumes can be browsed or edited from; this category.; - *Materials.* Allows creation of new materials/mixtures or editing; existing ones.; - *Media.* The same for creation/editing of tracking media (materials; having a set of proper",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:131796,Security,access,accessible,131796,"r the first modification has been; applied. It allows restoring the initial parameters of the shape. NOTE: In this version the ""Undo"" does not allow restoring an; intermediate state of the parameters that was applied - it will always; restore the parameters at the moment the shape was edited. All material properties changes are undoable. The mixture editor; currently allows adding elements one by one in the mixture composition.; This can be done either by element weight fraction or by number of; atoms. Once an element was added using one method the other method is not; selectable anymore. Summing component fractions up to 1 in the final; mixture is the user responsibility. Adding materials as components of a; mixture is not supported in this version. The elements that were added to the mixture appear in the bottom of the; mixture editor. The operations performed on mixture are not undoable. \anchor GP08d; ### Creation of New Objects. As described above, all geometry object creators are accessible within; the geometry manager editor frame. Generally, if the new object that; needs to be created does not depend on other objects, it will be built; with a set of default parameters. This is the case for all shapes; (except composite shapes) and matrices. For all the other objects the; interface forces the selection of components before creating the object. \anchor GP08e; ### Editing Volumes. Volumes are hierarchical components in the geometry, therefore their; editor is more complex. It provides the following functionalities:. - *General*. This category allows changing the name of the volume and; selecting other shape or medium among existing ones. - *Daughters*. The category allows removing existing daughter nodes or; adding new ones. The button ""Position"" allows editing the; positioning matrix of a given node. \image html geometry022.jpg width=600px; \image html geometry023.jpg ""Setting volume properties and modifying volume hierarchy"" width=600px. - *Visualization*. Thi",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:133960,Security,validat,validate,133960,"tings. The radio button ""All"" allows viewing all volumes down; to the selected depth. ""Leaves"" will draw only the deepest nodes; that have the selected depth or lower level ones that have no; daughters inside. ""Only"" will allow drawing only the edited; volume. The check button ""Raytrace"" will just draw the current; selection in solid mode using the ray-tracing algorithm provided by; TGeo. \image html geometry024.jpg width=600px; \image html geometry025.jpg ""Volume visualisation settings and division interface for volumes"" width=600px. - *Division*. Allows dividing the edited volume according a given; pattern. The division axes that are allowed are presented in a; radio-button group. The number entries labeled ""From"", ""Step""; and ""Nslices"" correspond to the divisioning parameters on the; selected axis. The range of the division is between `start` and; `start+ndiv*step` values and its validity is checked upon changing; one of the values. NOTE: When changing a value in a number entry by typing a number, press; ENTER at the end to validate. This applies for taking into account and; validation of any number change in the geometry editors. \anchor GP08f; ### How to Create a Valid Geometry with Geometry Editors. 1. Create a new geometry manager and start the editor as described at; the beginning. 2. Create at least one material from the ""Materials"" shutter item; category. Generally, for creating objects, the interface is always in; the TGeoManagerEditor in different categories - one should just; provide a name and requested parameters. 3. Create a shape that will be used for the top volume within the; ""Shapes"" category. For the moment, the shapes that have editors are; Box, Para, Trd1, Trd2, Tube, Tube segment, Cone, Cone segment, Hype,; Pcon, Torus and Sphere. 4. Create a medium from one of the existing materials from the; ""Medium"" category. You will notice that some categories as ""Volume""; and ""Medium"" are inactive at the beginning because at that time there; is no materi",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:134012,Security,validat,validation,134012,"raw only the deepest nodes; that have the selected depth or lower level ones that have no; daughters inside. ""Only"" will allow drawing only the edited; volume. The check button ""Raytrace"" will just draw the current; selection in solid mode using the ray-tracing algorithm provided by; TGeo. \image html geometry024.jpg width=600px; \image html geometry025.jpg ""Volume visualisation settings and division interface for volumes"" width=600px. - *Division*. Allows dividing the edited volume according a given; pattern. The division axes that are allowed are presented in a; radio-button group. The number entries labeled ""From"", ""Step""; and ""Nslices"" correspond to the divisioning parameters on the; selected axis. The range of the division is between `start` and; `start+ndiv*step` values and its validity is checked upon changing; one of the values. NOTE: When changing a value in a number entry by typing a number, press; ENTER at the end to validate. This applies for taking into account and; validation of any number change in the geometry editors. \anchor GP08f; ### How to Create a Valid Geometry with Geometry Editors. 1. Create a new geometry manager and start the editor as described at; the beginning. 2. Create at least one material from the ""Materials"" shutter item; category. Generally, for creating objects, the interface is always in; the TGeoManagerEditor in different categories - one should just; provide a name and requested parameters. 3. Create a shape that will be used for the top volume within the; ""Shapes"" category. For the moment, the shapes that have editors are; Box, Para, Trd1, Trd2, Tube, Tube segment, Cone, Cone segment, Hype,; Pcon, Torus and Sphere. 4. Create a medium from one of the existing materials from the; ""Medium"" category. You will notice that some categories as ""Volume""; and ""Medium"" are inactive at the beginning because at that time there; is no material yet (for making a medium) and no shape (for making a; volume). These categories are dynamically ac",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:136308,Security,access,access,136308,"Trd2, Tube, Tube segment, Cone, Cone segment, Hype,; Pcon, Torus and Sphere. 4. Create a medium from one of the existing materials from the; ""Medium"" category. You will notice that some categories as ""Volume""; and ""Medium"" are inactive at the beginning because at that time there; is no material yet (for making a medium) and no shape (for making a; volume). These categories are dynamically activated once all the; required components are defined. 5. Create a volume from the ""Volumes"" category. You will notice that; contrary to the other editors, the volume editor is opened in a tab, not; transient - this is because it is more complex. 6. Go back to ""General"" category and select the newly created volume; as the top one (you can do it also from the volume category). This is; just for starting. To create some hierarchy, one has to create several; other volumes and the matrices to position them. Once this is done, use; the volume editor interface to:; - add/remove daughters, change shape, edit position of daughters; - change visualization settings; - divide the volume (only if there are no daughters yet). 7. Close the geometry from the ""General"" category. \defgroup Geometry_classes Geometry classes; \ingroup Geometry; \brief The Geometry related classes. Several documents describing these classes are listed below:. - The main geometry class is documented in class TGeoManager.; - [Presentation/article at CHEP'03](http://www.slac.stanford.edu/econf/C0303241/proc/papers/THMT001.PDF); - [Presentation at ROOT 2004](http://www.slac.stanford.edu/BFROOT/www/Computing/Distributed/ROOT2004/files/gheata.ppt); - [Presentation at ROOT 2005](http://indico.cern.ch/getFile.py/access?contribId=s1t14&sessionId=1&resId=1&materialId=0&confId=a055638); - [Presentation at ROOT 2007](http://indico.cern.ch/materialDisplay.py?contribId=35&materialId=slides&confId=13356). See also [the use of the geometry classes in AliROOT package of ALICE](https://alice-offline.web.cern.ch/AliRoot/Manual.html). ",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:12868,Testability,log,logical,12868,"laps` folder is empty but can be filled after; performing a geometry validity check (see section: ""Checking the; Geometry""). If tracking is performed using `TGeo`, the folder; `Tracks` might contain user-defined tracks that can be; visualized/animated in the geometry context (see section: ""Creating and; Visualizing Tracks""). Since for the time being we are interested more in; the geometrical hierarchy, we will focus on the last two displayed items; `TOP `and `TOP_1`. These are the top volume and the corresponding top; node in the hierarchy. Double clicking on the `TOP` volume will unfold all different volumes; contained by the top volume. In the right panel, we will see all the; volumes contained by `TOP` (if the same is positioned 4 times we will; get 4 identical items). This rule will apply to any clicked volume in; the hierarchy. Note that right clicking a volume item activates the; volume context menu containing several specific methods. We will call; the volume hierarchy developed in this way as the; `logical geometry graph`. The volume objects are nodes inside this graph; and the same volume can be accessed starting from different branches. On the other hand, the real geometrical objects that are seen when; visualizing or tracking the geometry are depicted in the `TOP_1` branch.; These are the nodes of the `physical` `tree` of positioned volumes; represented by TGeoNode objects. This hierarchy is a tree since a; node can have only one parent and several daughters. For a better; understanding of the hierarchy, have a look at TGeoManage. Just close now the `X3D` window and focus at the wire frame picture; drawn in a pad. Activate Options/Event Status. Moving the mouse in the; pad, you will notice that objects are sometimes changing color to red.; Volumes are highlighted in this way whenever the mouse pointer is close; enough to one of its vertices. When this happens, the corresponding; volume is selected and you will see in the bottom right size of the %ROOT; can",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:18628,Testability,log,logical,18628,"erties of volumes can be provided both at; build time or after geometry is closed, but global visualization; settings (see section: ""The Drawing Package"") should not be provided; at build time, otherwise the drawing package will be loaded. There is also a list of specific rules:. - Positioned volumes should not extrude their container or intersect; with others within this unless it is specified (see section:; Overlapping Volumes).; - The top volume (containing all geometry trees) must be specified; before closing the geometry and must not be positioned - it; represents the global reference frame.; - After building the full geometry tree, the geometry must be closed; (see the method **`TGeoManager::CloseGeometry()`**). Voxelization; can be redone per volume after this process. The list is much bigger and we will describe in more detail the geometry; creation procedure in the following sections. Provided that geometry was; successfully built and closed, the **`TGeoManager`** class will register; itself to ROOT and the logical/physical structures will become; immediately browsable. \anchor GP01a; ### The Volume Hierarchy. The basic components used for building the logical hierarchy of the; geometry are the positioned volumes called `nodes`. Volumes are fully; defined geometrical objects having a given shape and medium and possibly; containing a list of nodes. Nodes represent just positioned instances of; volumes inside a container volume but users do not directly create them.; They are automatically created as a result of adding one volume inside; other or dividing a volume. The geometrical transformation held by nodes; is always defined with respect to their mother (relative positioning).; Reflection matrices are allowed. A hierarchical element is not fully defined by a node since nodes are; not directly linked to each other, but through volumes (a node points to; a volume, which at its turn points to a list of nodes):. `NodeTop ` ` VolTop ` ` NodeA ` ` VolA ` `...`. O",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:18776,Testability,log,logical,18776,"herwise the drawing package will be loaded. There is also a list of specific rules:. - Positioned volumes should not extrude their container or intersect; with others within this unless it is specified (see section:; Overlapping Volumes).; - The top volume (containing all geometry trees) must be specified; before closing the geometry and must not be positioned - it; represents the global reference frame.; - After building the full geometry tree, the geometry must be closed; (see the method **`TGeoManager::CloseGeometry()`**). Voxelization; can be redone per volume after this process. The list is much bigger and we will describe in more detail the geometry; creation procedure in the following sections. Provided that geometry was; successfully built and closed, the **`TGeoManager`** class will register; itself to ROOT and the logical/physical structures will become; immediately browsable. \anchor GP01a; ### The Volume Hierarchy. The basic components used for building the logical hierarchy of the; geometry are the positioned volumes called `nodes`. Volumes are fully; defined geometrical objects having a given shape and medium and possibly; containing a list of nodes. Nodes represent just positioned instances of; volumes inside a container volume but users do not directly create them.; They are automatically created as a result of adding one volume inside; other or dividing a volume. The geometrical transformation held by nodes; is always defined with respect to their mother (relative positioning).; Reflection matrices are allowed. A hierarchical element is not fully defined by a node since nodes are; not directly linked to each other, but through volumes (a node points to; a volume, which at its turn points to a list of nodes):. `NodeTop ` ` VolTop ` ` NodeA ` ` VolA ` `...`. One can therefore talk about ""the node or volume hierarchy"", but in; fact, an element is made by a pair volume-node. In the line above is; represented just a single branch, but of course from any v",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:20444,Testability,log,logical,20444,"oints to; a volume, which at its turn points to a list of nodes):. `NodeTop ` ` VolTop ` ` NodeA ` ` VolA ` `...`. One can therefore talk about ""the node or volume hierarchy"", but in; fact, an element is made by a pair volume-node. In the line above is; represented just a single branch, but of course from any volume other; branches can also emerge. The index of a node in such a branch (counting; only nodes) is called `depth`. The top node have always `depth=0`. Volumes need to have their daughter nodes defined when the geometry is; closed. They will build additional structures (called `voxels` ) in; order to fasten-up the search algorithms. Finally, nodes can be regarded; as bi-directional links between containers and contained volumes. The structure defined in this way is a graph structure since volumes are; replicable (same volume can become daughter node of several other; volumes), every volume becoming a branch in this graph. Any volume in; the logical graph can become the actual top volume at run time (see; TGeoManager::SetTopVolume()). **All functionalities of the modeller; will behave in this case as if only the corresponding branch starting; from this volume is the active geometry**. \image html geometry005.png ""A geometry hierarchy in memory"" width=600. Nodes are never instantiated directly by users, but created as a result; of volume operations. Adding a volume named A with a given `user id`; inside a volume B will create a node named `A_id.` This will be added to; the list of nodes stored by B. In addition, when applying a division; operation in N slices to a volume A, a list of nodes `B_1`, `B_2`, ... ,; `B_N` is also created. A node `B_i` does not represent a unique object; in the geometry because its container A might be at its turn positioned; as node inside several other volumes. Only when a complete branch of; nodes is fully defined up to the top node in the geometry, a given; path:` /TOP_1/`...`/A_3/B_7` will represent a unique object. Its global; ",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:21603,Testability,log,logical,21603,"rresponding branch starting; from this volume is the active geometry**. \image html geometry005.png ""A geometry hierarchy in memory"" width=600. Nodes are never instantiated directly by users, but created as a result; of volume operations. Adding a volume named A with a given `user id`; inside a volume B will create a node named `A_id.` This will be added to; the list of nodes stored by B. In addition, when applying a division; operation in N slices to a volume A, a list of nodes `B_1`, `B_2`, ... ,; `B_N` is also created. A node `B_i` does not represent a unique object; in the geometry because its container A might be at its turn positioned; as node inside several other volumes. Only when a complete branch of; nodes is fully defined up to the top node in the geometry, a given; path:` /TOP_1/`...`/A_3/B_7` will represent a unique object. Its global; transformation matrix can be computed as the pile-up of all local; transformations in its branch. We will therefore call `logical graph`; the hierarchy defined by nodes and volumes. The expansion of the logical; graph by all possible paths defines a tree structure where all nodes are; unique ""touchable"" objects. We will call this the ""physical tree"".; Unlike the logical graph, the physical tree can become a huge structure; with several millions of nodes in case of complex geometries; therefore,; it is not always a good idea to keep it transient in memory. Since the; logical and physical structures are correlated, the modeller rather; keeps track only of the current branch, updating the current global; matrix at each change of the level in geometry. The current physical; node is not an object that can be asked for at a given moment, but; rather represented by the combination: current node/current global; matrix. However, physical nodes have unique ID's that can be retrieved; for a given modeller state. These can be fed back to the modeller in; order to force a physical node to become current. The advantage of this; comes f",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:21684,Testability,log,logical,21684,"try hierarchy in memory"" width=600. Nodes are never instantiated directly by users, but created as a result; of volume operations. Adding a volume named A with a given `user id`; inside a volume B will create a node named `A_id.` This will be added to; the list of nodes stored by B. In addition, when applying a division; operation in N slices to a volume A, a list of nodes `B_1`, `B_2`, ... ,; `B_N` is also created. A node `B_i` does not represent a unique object; in the geometry because its container A might be at its turn positioned; as node inside several other volumes. Only when a complete branch of; nodes is fully defined up to the top node in the geometry, a given; path:` /TOP_1/`...`/A_3/B_7` will represent a unique object. Its global; transformation matrix can be computed as the pile-up of all local; transformations in its branch. We will therefore call `logical graph`; the hierarchy defined by nodes and volumes. The expansion of the logical; graph by all possible paths defines a tree structure where all nodes are; unique ""touchable"" objects. We will call this the ""physical tree"".; Unlike the logical graph, the physical tree can become a huge structure; with several millions of nodes in case of complex geometries; therefore,; it is not always a good idea to keep it transient in memory. Since the; logical and physical structures are correlated, the modeller rather; keeps track only of the current branch, updating the current global; matrix at each change of the level in geometry. The current physical; node is not an object that can be asked for at a given moment, but; rather represented by the combination: current node/current global; matrix. However, physical nodes have unique ID's that can be retrieved; for a given modeller state. These can be fed back to the modeller in; order to force a physical node to become current. The advantage of this; comes from the fact that all navigation queries check first the current; node; therefore the location of a point in",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:21846,Testability,log,logical,21846,"a node named `A_id.` This will be added to; the list of nodes stored by B. In addition, when applying a division; operation in N slices to a volume A, a list of nodes `B_1`, `B_2`, ... ,; `B_N` is also created. A node `B_i` does not represent a unique object; in the geometry because its container A might be at its turn positioned; as node inside several other volumes. Only when a complete branch of; nodes is fully defined up to the top node in the geometry, a given; path:` /TOP_1/`...`/A_3/B_7` will represent a unique object. Its global; transformation matrix can be computed as the pile-up of all local; transformations in its branch. We will therefore call `logical graph`; the hierarchy defined by nodes and volumes. The expansion of the logical; graph by all possible paths defines a tree structure where all nodes are; unique ""touchable"" objects. We will call this the ""physical tree"".; Unlike the logical graph, the physical tree can become a huge structure; with several millions of nodes in case of complex geometries; therefore,; it is not always a good idea to keep it transient in memory. Since the; logical and physical structures are correlated, the modeller rather; keeps track only of the current branch, updating the current global; matrix at each change of the level in geometry. The current physical; node is not an object that can be asked for at a given moment, but; rather represented by the combination: current node/current global; matrix. However, physical nodes have unique ID's that can be retrieved; for a given modeller state. These can be fed back to the modeller in; order to force a physical node to become current. The advantage of this; comes from the fact that all navigation queries check first the current; node; therefore the location of a point in the geometry can be saved as; a starting state for later use. Nodes can be declared as `overlapping` in case they do overlap with; other nodes inside the same container or extrude this container (see; also ‘Ch",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:22054,Testability,log,logical,22054,"reated. A node `B_i` does not represent a unique object; in the geometry because its container A might be at its turn positioned; as node inside several other volumes. Only when a complete branch of; nodes is fully defined up to the top node in the geometry, a given; path:` /TOP_1/`...`/A_3/B_7` will represent a unique object. Its global; transformation matrix can be computed as the pile-up of all local; transformations in its branch. We will therefore call `logical graph`; the hierarchy defined by nodes and volumes. The expansion of the logical; graph by all possible paths defines a tree structure where all nodes are; unique ""touchable"" objects. We will call this the ""physical tree"".; Unlike the logical graph, the physical tree can become a huge structure; with several millions of nodes in case of complex geometries; therefore,; it is not always a good idea to keep it transient in memory. Since the; logical and physical structures are correlated, the modeller rather; keeps track only of the current branch, updating the current global; matrix at each change of the level in geometry. The current physical; node is not an object that can be asked for at a given moment, but; rather represented by the combination: current node/current global; matrix. However, physical nodes have unique ID's that can be retrieved; for a given modeller state. These can be fed back to the modeller in; order to force a physical node to become current. The advantage of this; comes from the fact that all navigation queries check first the current; node; therefore the location of a point in the geometry can be saved as; a starting state for later use. Nodes can be declared as `overlapping` in case they do overlap with; other nodes inside the same container or extrude this container (see; also ‘Checking the Geometry'). Non-overlapping nodes can be created; with:. ~~~{.cpp}; TGeoVolume::AddNode(TGeoVolume *daughter,Int_t copy_No,; TGeoMatrix *matr);; ~~~. The creation of overlapping nodes can be d",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:29879,Testability,log,logical,29879,"s management is handled by volumes. These build; additional optimization structures upon geometry closure. In order to; have navigation features properly working one has to follow some rules; for building a valid geometry. - The daughter volume(s) must not extrude the mother shape. They are; allowed however to have a common boundaries.; - The volumes positioned in the same container must not overlap with; each other. They may touch on one boundaries or shape vertex. The daughter nodes of a volume can be also removed or replaced with; other nodes:. ~~~{.cpp}; void RemoveNode(TGeoNode* node); TGeoNode*ReplaceNode(TGeoNode* nodeorig, TGeoShape* newshape = 0,; TGeoMatrix* newpos = 0, TGeoMedium* newmed = 0); ~~~. The last method allows replacing an existing daughter of a volume with; another one. Providing only the node to be replaced will just create a; new volume for the node but having exactly the same parameters as the; old one. This helps in case of divisions for decoupling a node from the; logical hierarchy so getting new content/properties. For non-divided; volumes, one can change the shape and/or the position of the daughter. \anchor GP01bd; #### Virtual Containers and Assemblies of Volumes. Virtual containers are volumes that do not represent real objects, but; they are needed for grouping and positioning together other volumes.; Such grouping helps not only geometry creation, but also optimizes; tracking performance; therefore, it is highly recommended. Virtual; volumes need to inherit material/medium properties from the volume they; are placed into in order to be ""invisible"" at tracking time. Let us suppose that we need to group together two volumes `A` and `B`; into a structure and position this into several other volumes `D,E,` and; `F`. What we need to do is to create a virtual container volume `C`; holding `A` and `B`, then position `C` in the other volumes. Note that `C` is a volume having a determined medium. Since it is not a; real volume, we need to ma",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:33274,Testability,test,test,33274,"mbling and positioning volumes. If we define now `C` as an assembly containing `A` and `B`, positioning; the assembly into `D,E` and `F` will actually position only `A` and; `B `directly into these volumes, taking into account their combined; transformations `A/B` to `C` and `C` to `D/E/F`. This looks much nicer,; is it? In fact, it is and it is not. Of course, we managed to get rid of; the ""unnecessary"" volume `C` in our geometry, but we end-up with a more; flat structure for `D,E` and `F` (more daughters inside). This can get; much worse when extensively used, as in the case: assemblies of; assemblies. For deciding what to choose between using virtual containers or; assemblies for a specific case, one can use for both cases, after the; geometry was closed:. ~~~{.cpp}; gGeoManager->SetTopVolume(ptr_D);; gGeoManager->Test();; gGeoManager->RestoreMasterVolume();; ~~~. The `ptr_D` is a pointer to volume `D` containing the interesting; structure. The test will provide the timing for classifying 1 million; random points inside `D`. \anchor GP01be; #### Examples of Volume Positioning. Now let us make a simple volume representing a copper wire. We suppose; that a medium is already created (see TGeoMedium class on how to; create media). We will create a `TUBE` shape for our wire, having `Rmin=0cm`,; `Rmax=0.01cm` and a half-length `dZ=1cm`:. ~~~{.cpp}; TGeoTube *tube = new TGeoTube(""wire_tube"",0,0.01,1);; ~~~. One may omit the name for the shape `wire_tube,` if no retrieving by; name is further needed during geometry building. Different volumes; having different names and materials can share the same shape. Now let's make the volume for our wire:. ~~~{.cpp}; TGeoVolume *wire_co = new TGeoVolume(""WIRE_CO"",tube,ptrCOPPER); //(*); ~~~. (*) Do not bother to delete the media, shapes or volumes that you; have created since all will be automatically cleaned on exit by the; manager class. If we would have taken a look inside `TGeoManager::MakeTube()` method,; we would have been ab",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:60867,Testability,log,logical,60867,"try. It defines a global pointer; `gGeoManager` in order to be fully accessible from external code.; The manager class is the owner of all geometry objects defined in a; session; therefore, users must not try to control their deletion. It; contains lists of media, materials, transformations, shapes and volumes.; A special case is the one of geometrical transformations. When creating; a matrix or a translation, this is by default owned by external objects.; The manager class becomes owner of all transformations used for; positioning volumes. In order to force the ownership for other; transformations, one can use TGeoMatrix::RegisterYourself() method. Do; not be therefore surprised that some transformations cannot be found by; name when creating a composite shape for instance if you did not; register them after creation. Logical nodes (positioned volumes) are created and destroyed by the; TGeoVolume class. Physical nodes and their global transformations; are subjected to a caching mechanism due to the sometimes very large; memory requirements of logical graph expansion. The total number of; physical instances of volumes triggers the caching mechanism and the; cache manager is a client of TGeoManager. The manager class also; controls the drawing/checking package (TGeoPainter client). This; is linked with %ROOT graphical libraries loaded on demand in order to; control visualization actions. \anchor GP02; ## Navigation and Tracking. Tracking is the feature allowing the transport of a given particle; knowing its kinematics. A state is determined by any combination of the; position \f$\vec{r}\f$ and direction \f$\vec{n}\f$ with respect to the world; reference frame. The direction \f$\vec{n}\f$ must be a unit vector having as; components the director cosines. The full classification of a given; state will provide the following information: the deepest physical node; containing the position vector, the distance to the closest boundary; along the direction vector, the next phy",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:63992,Testability,test,testing,63992,"ometry manager holds a list; of active navigators accessible via:. ~~~{.cpp}; TObjArray *navigators = gGeoManager->GetListOfNavigators();; ~~~. Upon closing the geometry a default navigator is provided as first one; in this list, but one may add its own via:. ~~~{.cpp}; TGeoNavigator *navig = new TGeoNavigator(gGeoManager);; // Store the index of the user navigator; Int_t inav = gGeoManager->AddNavigator(navig);; // Make its own navigator the active one; gGeoManager->SetCurrentNavigator(inav);; // Switch between navigators; gGeoManager->SetCurrentNavigator(0);; ~~~. A navigator holds several variables describing the current navigation; state: current point position, current direction distance to next; boundary, isotropic safety, pointer to current and next nods as well as; several tracking flags related to volume boundary conditions or other; properties required for track propagation in geometry. Each geometry; query affects these variables, so the only way in testing several; navigation alternatives and remembering the active navigation state is; to use parallel navigation. The following paragraphs will describe the; usage of a single navigator. All setters/getters for navigation state; parameters as well as navigation queries provided by TGeoNavigator; are interfaced by TGeoManager and will act on the current; navigator. \anchor GP02b; ### Initializing the Starting Point. The current point (`x,y,z`) known by the modeller is stored as; `Double_t fCurrentPoint[3]` by the navigator class. This array of the; three coordinates is defined in the current global reference system and; can be retrieved any time:. ~~~{.cpp}; Const Double_t *cpoint = gGeoManager->GetCurrentPoint();; ~~~. Initializing this point can be done like:. ~~~{.cpp}; gGeoManager->SetCurrentPoint(x,y,z);; // or:; gGeoManager->SetCurrentPoint(Double_t *point[3]);; ~~~. \anchor GP02c; ### Initializing the Direction. In order to move inside geometry starting with the current point, the; modeller needs to k",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:69289,Testability,test,test,69289,"ermediate; `folders` in the path are in fact also nodes ""touched"" by the; current point, but having some ""touched"" containment. The current; path can be retrieved only after the state was initialized and is; useful for getting an idea of the current point location. ~~~{.cpp}; const char *path = gGeoManager->GetPath();; cout << ""Current path is: "" << path << endl;; /A_1/B_34/C_3/D_1; ~~~. - The `current node`, `volume` and `material`. In order to; take decisions on post-step or further stepping actions, one has to; know these. In order to get a pointer to the current node one can; do:. ~~~{.cpp}; TGeoNode *cnode = gGeoManager->GetCurrentNode();; // then:; TGeoVolume *cvol = gGeoManager->GetCurrentVolume();; // or:; cvol = cnode->GetVolume(); // (*); // then:; TGeoMaterial *cmat = cvol->GetMedium()->GetMaterial();; ~~~. (*) Note: If the current point is in fact outside the geometry, the; current node pointer will not be NULL, but pointing to the top node. In order to take decisions in such case one needs always to test:. ~~~{.cpp}; if (gGeoManager->IsOutside()) {; // current point is actually outside; ... // corresponding action; }; ~~~. Specific information related to the current volume/node like ID's or; shape can be then retrieved from the corresponding objects. - Current state `index`. The number of possible different states of; the modeller corresponds to the number of different objects/paths in; the geometry. This has nothing to do with the number of nodes, since; the same node can be found on different branches. In other words,; the number of states corresponds to the number of nodes in the; `expanded geometry tree`. Since unfortunately this expansion from; logical to physical hierarchy cannot be stored on regular basis due; to the large size of the latter, one cannot directly assign state; numbers. If the size of the expansion proves however to be small; enough (less than about 50 million objects), a parallel structure; storing these state indices is built and ",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:69952,Testability,log,logical,69952,"olume(); // (*); // then:; TGeoMaterial *cmat = cvol->GetMedium()->GetMaterial();; ~~~. (*) Note: If the current point is in fact outside the geometry, the; current node pointer will not be NULL, but pointing to the top node. In order to take decisions in such case one needs always to test:. ~~~{.cpp}; if (gGeoManager->IsOutside()) {; // current point is actually outside; ... // corresponding action; }; ~~~. Specific information related to the current volume/node like ID's or; shape can be then retrieved from the corresponding objects. - Current state `index`. The number of possible different states of; the modeller corresponds to the number of different objects/paths in; the geometry. This has nothing to do with the number of nodes, since; the same node can be found on different branches. In other words,; the number of states corresponds to the number of nodes in the; `expanded geometry tree`. Since unfortunately this expansion from; logical to physical hierarchy cannot be stored on regular basis due; to the large size of the latter, one cannot directly assign state; numbers. If the size of the expansion proves however to be small; enough (less than about 50 million objects), a parallel structure; storing these state indices is built and stored in memory. In such; case each state automatically gets an index that can be retrieved; after any state initialization. These indices can prove to be quite; useful for being able to keep track of the navigation history and; force certain states. Let's illustrate how this works with a simple; example:; - Suppose we have a simple geometry with a volume B positioned twice; inside a container A. Then A is positioned twice in a top container; T. The complete list of logical nodes is: `T_1`, `A_1`, `A_2`,; `B_1`, `B_2`. On the other hand we will have more states than; logical nodes:; - `/T_1`- 1 state at level = 0; - `/T_1/A_1,/T_1/A_2`- 2 states at level = 1; - `/T_1/A_1/B_1,/T_1/A_1/B_2,/T_1/A_2/B_1,/T_1/A_2/B_2` - 4 states at; l",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:70734,Testability,log,logical,70734,"nce; the same node can be found on different branches. In other words,; the number of states corresponds to the number of nodes in the; `expanded geometry tree`. Since unfortunately this expansion from; logical to physical hierarchy cannot be stored on regular basis due; to the large size of the latter, one cannot directly assign state; numbers. If the size of the expansion proves however to be small; enough (less than about 50 million objects), a parallel structure; storing these state indices is built and stored in memory. In such; case each state automatically gets an index that can be retrieved; after any state initialization. These indices can prove to be quite; useful for being able to keep track of the navigation history and; force certain states. Let's illustrate how this works with a simple; example:; - Suppose we have a simple geometry with a volume B positioned twice; inside a container A. Then A is positioned twice in a top container; T. The complete list of logical nodes is: `T_1`, `A_1`, `A_2`,; `B_1`, `B_2`. On the other hand we will have more states than; logical nodes:; - `/T_1`- 1 state at level = 0; - `/T_1/A_1,/T_1/A_2`- 2 states at level = 1; - `/T_1/A_1/B_1,/T_1/A_1/B_2,/T_1/A_2/B_1,/T_1/A_2/B_2` - 4 states at; level = 2; - All these states will get automatic numbers, starting with 0; corresponding to the top-level state and ending with an integer; corresponding to Ntotal\_states-1. The mapping from a given logical; node to a state number is generally not possible, as for the node; B\_1 that appears as current node for 2 different states. The; numbering order of states is therefore not important, but it can be; used as in the following lines:. ~~~{.cpp}; gGeoManager->InitTrack(pt,dir); // anything to initialize a state; Int_t istate = gGeoManager->GetCurrentNodeId(); // in fact state Id; {; //... code changing the current state; }; gGeoManager->CdNode(istate); // forces state's re-initialization; ~~~. - Current `global transformation`. This repr",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:70837,Testability,log,logical,70837," cannot be stored on regular basis due; to the large size of the latter, one cannot directly assign state; numbers. If the size of the expansion proves however to be small; enough (less than about 50 million objects), a parallel structure; storing these state indices is built and stored in memory. In such; case each state automatically gets an index that can be retrieved; after any state initialization. These indices can prove to be quite; useful for being able to keep track of the navigation history and; force certain states. Let's illustrate how this works with a simple; example:; - Suppose we have a simple geometry with a volume B positioned twice; inside a container A. Then A is positioned twice in a top container; T. The complete list of logical nodes is: `T_1`, `A_1`, `A_2`,; `B_1`, `B_2`. On the other hand we will have more states than; logical nodes:; - `/T_1`- 1 state at level = 0; - `/T_1/A_1,/T_1/A_2`- 2 states at level = 1; - `/T_1/A_1/B_1,/T_1/A_1/B_2,/T_1/A_2/B_1,/T_1/A_2/B_2` - 4 states at; level = 2; - All these states will get automatic numbers, starting with 0; corresponding to the top-level state and ending with an integer; corresponding to Ntotal\_states-1. The mapping from a given logical; node to a state number is generally not possible, as for the node; B\_1 that appears as current node for 2 different states. The; numbering order of states is therefore not important, but it can be; used as in the following lines:. ~~~{.cpp}; gGeoManager->InitTrack(pt,dir); // anything to initialize a state; Int_t istate = gGeoManager->GetCurrentNodeId(); // in fact state Id; {; //... code changing the current state; }; gGeoManager->CdNode(istate); // forces state's re-initialization; ~~~. - Current `global transformation`. This represents the transformation; from `MARS` to the local reference of the current node, being the; product of all local mother-daughter transformations in the branch.; The global transformation can be referenced or copied:. ~~~{.cpp}; co",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:71202,Testability,log,logical,71202,"lt and stored in memory. In such; case each state automatically gets an index that can be retrieved; after any state initialization. These indices can prove to be quite; useful for being able to keep track of the navigation history and; force certain states. Let's illustrate how this works with a simple; example:; - Suppose we have a simple geometry with a volume B positioned twice; inside a container A. Then A is positioned twice in a top container; T. The complete list of logical nodes is: `T_1`, `A_1`, `A_2`,; `B_1`, `B_2`. On the other hand we will have more states than; logical nodes:; - `/T_1`- 1 state at level = 0; - `/T_1/A_1,/T_1/A_2`- 2 states at level = 1; - `/T_1/A_1/B_1,/T_1/A_1/B_2,/T_1/A_2/B_1,/T_1/A_2/B_2` - 4 states at; level = 2; - All these states will get automatic numbers, starting with 0; corresponding to the top-level state and ending with an integer; corresponding to Ntotal\_states-1. The mapping from a given logical; node to a state number is generally not possible, as for the node; B\_1 that appears as current node for 2 different states. The; numbering order of states is therefore not important, but it can be; used as in the following lines:. ~~~{.cpp}; gGeoManager->InitTrack(pt,dir); // anything to initialize a state; Int_t istate = gGeoManager->GetCurrentNodeId(); // in fact state Id; {; //... code changing the current state; }; gGeoManager->CdNode(istate); // forces state's re-initialization; ~~~. - Current `global transformation`. This represents the transformation; from `MARS` to the local reference of the current node, being the; product of all local mother-daughter transformations in the branch.; The global transformation can be referenced or copied:. ~~~{.cpp}; const TGeoHMatrix *global = gGeoManager->GetCurrentMatrix();; TGeoHMatrix *copy = new TGeoHMatrix(*global);; ~~~. - One often needs to perform `master-to-local` and `local-to-master`; point and vector conversions to get from `MARS` to the local node; coordinates. This can be ",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:108426,Testability,log,logical,108426,"ligned is; essential since there is no other way of identifying them. One can; however create ""symbolic links"" to any complex path to make it more; representable for the object it designates:. ~~~{.cpp}; TGeoPNEntry(const char* unique_name, const char* path); void TGeoPNEntry::SetPhysicalNode(TGeoPhysicalNode *node); ~~~. Such a symbolic link hides the complexity of the path to the align; object and replaces it with a more meaningful name. In addition,; TGeoPNEntry objects are faster to search by name and they may; optionally store an additional user matrix. ~~~{.cpp}; // Creating a symlink object.; TGeoPNEntry *TGeoManager::SetAlignableEntry(const char *unique_n,; const char*path); // Retrieving an existing alignable object.; TGeoPNEntry *TGeoManager::GetAlignableEntry(const char *name); // Retrieving an existing alignable object at a given index.; TGeoPNEntry *GetAlignableEntry(Int_t index); ~~~. Physical nodes store internally the full list of logical nodes; corresponding to the elements from the string path, as well as the; global transformation matrix for each of them. The top node corresponds; to the level 0 in the stored array, while the last node will correspond; to level `n`. For each level, the node, volume and global matrix can be; retrieved using corresponding getters:. ~~~{.cpp}; TGeoHMatrix *GetMatrix(Int_t level=-1) const; TGeoNode *GetNode(Int_t level=-1) const; TGeoShape *GetShape(Int_t level=-1) const; TGeoVolume *GetVolume(Int_t level=-1) const; ~~~. By default the object at level n is retrieved (the align-able object). Once created, a physical node can be misaligned, meaning that its; positioning matrix or even the shape.:. ~~~{.cpp}; void Align(TGeoMatrix* newmat=0, TGeoShape* newshape=0,; Bool_t check=kFALSE); ~~~. The convention used is that newmat represents the new local matrix of; the last node in the branch with respect to its mother volume. The; `Align()` method will actually duplicate the corresponding branch within; the logical hierarchy",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:109449,Testability,log,logical,109449,"l nodes; corresponding to the elements from the string path, as well as the; global transformation matrix for each of them. The top node corresponds; to the level 0 in the stored array, while the last node will correspond; to level `n`. For each level, the node, volume and global matrix can be; retrieved using corresponding getters:. ~~~{.cpp}; TGeoHMatrix *GetMatrix(Int_t level=-1) const; TGeoNode *GetNode(Int_t level=-1) const; TGeoShape *GetShape(Int_t level=-1) const; TGeoVolume *GetVolume(Int_t level=-1) const; ~~~. By default the object at level n is retrieved (the align-able object). Once created, a physical node can be misaligned, meaning that its; positioning matrix or even the shape.:. ~~~{.cpp}; void Align(TGeoMatrix* newmat=0, TGeoShape* newshape=0,; Bool_t check=kFALSE); ~~~. The convention used is that newmat represents the new local matrix of; the last node in the branch with respect to its mother volume. The; `Align()` method will actually duplicate the corresponding branch within; the logical hierarchy, creating new volumes and nodes. This is mandatory; in order to avoid problems due to replicated volumes and can create; exhaustive memory consumption if used abusively. Once aligned, a physical node is ready to be tracked. The operation can; be done only after the geometry was closed. Important NOTE: Calling the `Align()` method for a physical node changes; the node pointers for the stored node branch in the active geometry, Due; to this the other defined physical nodes containing elements of this; path will be invalid. Example:. ~~~{.cpp}; TGeoPhysicalNode *pn1 =; gGeoManager->MakePhysicalNode(""/A_1/B_1/C_2"");; TGeoPhysicalNode *pn2 =; gGeoManager->MakePhysicalNode(""/A_1/B_1/C_3"");; ...; pn1->Align(...);; ~~~. The call to `pn1->Align()` will invalidate the pointer to the node `B_1`; in `pn2` object.. The way out is to either call `pn1->Align()` before; the creation of `pn2`, either to use a global method that will correct; all existing physical node",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:117790,Testability,log,logical,117790," (in our case let us suppose it is `B\_3`). Since a node is just a; positioned volume, we can then get a pointer to the volume, medium or; material objects related to it. ""Deepest"" means that `B\_3` still; contains point `P` (as well as `A\_1` and `TOP\_1`), but none of the; daughters of volume `B` does. After finding out the node containing; the particle, one can check if the geometry state is different compared; to the last located point:. ~~~{.cpp}; Bool_t *TGeoManager::IsSameLocation(); ~~~. The algorithm for finding where a point is located in geometry is; presented in the figure 17-36. It always starts by checking if the last computed modeller state is the; answer. This optimizes the search when continuously tracking a particle.; The main actions performed are:. - moving up and down in the logical node tree while updating the; current node and its global matrix; - converting the global position into the local frame of the current; node/volume; - checking whether the local position lies within the geometrical; shape of the current volume - if this is the case continue the; search downwards for the daughters of the current node, otherwise; search upwards its containers until the top level is reached.; - the number of candidate nodes to be checked at a given level is; minimized by an additional optimization structure: voxels. This is; effective even in case there is only one daughter of the current; volume.; - in case the current node is declared as possibly overlapping, the; method FindInCluster() is invoked. This method checks all different; possibilities within the cluster of overlapping candidates. One of; the candidates is prioritized if one of the following conditions id; fulfilled (in order):; - Is declared as non-overlapping (these are anyway searched first); - Has at least one daughter that contains the current point; - Was already declared as containing the point at a previous step. \image html geometry016.png ""Finding the location of a point in the geom",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:4768,Usability,simpl,simplest,4768," pieces; is not defined by neighbors, but by ""containment"". In other words,; volumes are put one inside another making an in-depth hierarchy. From; outside, the whole thing looks like a big pack that you can open finding; out other smaller packs nicely arranged waiting to be opened at their; turn. The biggest one containing all others defines the ""world"" of the; model. We will often call this ""master reference system (MARS)"". Going; on and opening our packs, we will obviously find out some empty ones,; otherwise, something is very wrong... We will call these leaves (by; analogy with a tree structure). On the other hand, any volume is a small world by itself - what we need; to do is to take it out and to ignore all the rest since it is a; self-contained object. In fact, the modeller can act like this,; considering a given volume as temporary MARS, but we will describe this; feature later on. Let us focus on the biggest pack - it is mandatory to; define one. Consider the simplest geometry that is made of a single box.; Here is an example on how to build it:. \anchor GP00a; ### Example 1: Creating the World. We first need to load the geometry library. This is not needed if one; does ""make map"" in root folder. ~~~{.cpp}; root[] gSystem->Load(""libGeom"");; ~~~. Second, we have to create an instance of the geometry manager class.; This takes care of all the modeller components, performing several tasks; to insure geometry validity and containing the user interface for; building and interacting with the geometry. After its creation, the; geometry manager class can be accessed with the global; `gGeoManager`:. ~~~{.cpp}; root[] new TGeoManager(""world"", ""the simplest geometry"");; ~~~. We want to create a single volume in our geometry, but since any volume; needs to have an associated medium, we will create a dummy one. You can; safely ignore the following lines for the time being, since materials; and media will be explained in detail later on. ~~~{.cpp}; root[] TGeoMaterial *m",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:5460,Usability,simpl,simplest,5460," what we need; to do is to take it out and to ignore all the rest since it is a; self-contained object. In fact, the modeller can act like this,; considering a given volume as temporary MARS, but we will describe this; feature later on. Let us focus on the biggest pack - it is mandatory to; define one. Consider the simplest geometry that is made of a single box.; Here is an example on how to build it:. \anchor GP00a; ### Example 1: Creating the World. We first need to load the geometry library. This is not needed if one; does ""make map"" in root folder. ~~~{.cpp}; root[] gSystem->Load(""libGeom"");; ~~~. Second, we have to create an instance of the geometry manager class.; This takes care of all the modeller components, performing several tasks; to insure geometry validity and containing the user interface for; building and interacting with the geometry. After its creation, the; geometry manager class can be accessed with the global; `gGeoManager`:. ~~~{.cpp}; root[] new TGeoManager(""world"", ""the simplest geometry"");; ~~~. We want to create a single volume in our geometry, but since any volume; needs to have an associated medium, we will create a dummy one. You can; safely ignore the following lines for the time being, since materials; and media will be explained in detail later on. ~~~{.cpp}; root[] TGeoMaterial *mat = new TGeoMaterial(""Vacuum"",0,0,0);; root[] TGeoMedium *med = new TGeoMedium(""Vacuum"",1,mat);; ~~~. We can finally make our volume having a box shape. Note that the world; volume does not need to be a box - it can be any other shape. Generally,; boxes and tubes are the most recommendable shapes for this purpose due; to their fast navigation algorithms. ~~~{.cpp}; root[] TGeoVolume *top=gGeoManager->MakeBox(""Top"",med,10.,10.,10.);; ~~~. The default units are in centimeters. Now we want to make this volume; our world. We have to do this operation **before** closing the geometry. ~~~{.cpp}; root[] gGeoManager->SetTopVolume(top);; ~~~. This should be enough, b",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:6844,Usability,simpl,simple,6844,"acuum"",0,0,0);; root[] TGeoMedium *med = new TGeoMedium(""Vacuum"",1,mat);; ~~~. We can finally make our volume having a box shape. Note that the world; volume does not need to be a box - it can be any other shape. Generally,; boxes and tubes are the most recommendable shapes for this purpose due; to their fast navigation algorithms. ~~~{.cpp}; root[] TGeoVolume *top=gGeoManager->MakeBox(""Top"",med,10.,10.,10.);; ~~~. The default units are in centimeters. Now we want to make this volume; our world. We have to do this operation **before** closing the geometry. ~~~{.cpp}; root[] gGeoManager->SetTopVolume(top);; ~~~. This should be enough, but it is not since always after defining some; geometry hierarchy, TGeo needs to build some optimization; structures and perform some checks. Note the messages posted after the; statement is executed. We will describe the corresponding operations; later. ~~~{.cpp}; root[] gGeoManager->CloseGeometry();; ~~~. Now we are really done with geometry building stage, but we would like; to see our simple world:. ~~~{.cpp}; root[] top->SetLineColor(kMagenta);; root[] gGeoManager->SetTopVisible(); // the TOP is invisible; root[] top->Draw();; ~~~. \anchor GP00b; ### Example 2: A Geometrical Hierarchy Look and Feel. Before going further, let us get a look and feel of interacting with the; modeller. For this, we will use one of the examples illustrating the; geometry package. To get an idea on the geometry structure created in; this example, just look at rootgeom.C. You will; notice that this is a bit more complex that just creating the ""world""; since several other volumes are created and put together in a hierarchy.; The purpose here is just to learn how to interact with a geometry that; is already built, but just few hints on the building steps in this; example might be useful. The geometry here represents the word %ROOT that; is replicated in some symmetric manner. You might for instance ask some; questions after having a first look:. **Q:** ""OK",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:7501,Usability,learn,learn,7501,"on; structures and perform some checks. Note the messages posted after the; statement is executed. We will describe the corresponding operations; later. ~~~{.cpp}; root[] gGeoManager->CloseGeometry();; ~~~. Now we are really done with geometry building stage, but we would like; to see our simple world:. ~~~{.cpp}; root[] top->SetLineColor(kMagenta);; root[] gGeoManager->SetTopVisible(); // the TOP is invisible; root[] top->Draw();; ~~~. \anchor GP00b; ### Example 2: A Geometrical Hierarchy Look and Feel. Before going further, let us get a look and feel of interacting with the; modeller. For this, we will use one of the examples illustrating the; geometry package. To get an idea on the geometry structure created in; this example, just look at rootgeom.C. You will; notice that this is a bit more complex that just creating the ""world""; since several other volumes are created and put together in a hierarchy.; The purpose here is just to learn how to interact with a geometry that; is already built, but just few hints on the building steps in this; example might be useful. The geometry here represents the word %ROOT that; is replicated in some symmetric manner. You might for instance ask some; questions after having a first look:. **Q:** ""OK, I understand the first lines that load the libGeom library and create; a geometry manager object. I also recognize from the previous example the following; lines creating some materials and media, but what about the geometrical transformations below?"". **A:** As explained before, the model that we are trying to create; is a hierarchy of volumes based on ""containment"". This is; accomplished by ""positioning"" some volumes ""inside"" others.; Any volume is an un-positioned object in the sense that it defines only; a ""local frame"" (matching the one of its ""shape""). In order; to fully define the mother-daughter relationship between two volumes one; has to specify how the daughter will be positioned inside. This is; accomplished by defining a",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:9163,Usability,simpl,simple,9163,"ing"" some volumes ""inside"" others.; Any volume is an un-positioned object in the sense that it defines only; a ""local frame"" (matching the one of its ""shape""). In order; to fully define the mother-daughter relationship between two volumes one; has to specify how the daughter will be positioned inside. This is; accomplished by defining a ""local geometrical transformation"" of; the daughter with respect to the mother coordinate system. These; transformations will be subsequently used in the example. **Q:** ""I see the lines defining the top level volume as in the previous example,; but what about the other volumes named REPLICA and ROOT?"". **A:** You will also notice that several other volumes are created; by using lines like:. ~~~{.cpp}; TGeoVolume *someVolume = gGeoManager->MakeXXX(""someName"",; ptrMedium, /* parameters coresponding to XXX ...*/); ~~~. In the method above XXX represent some shape name (Box, Tube,; etc.). This is just a simple way of creating a volume having a given; shape in one-step (see also section: ""Creating and Positioning; Volumes""). As for REPLICA and %ROOT volumes, they are just some; ""virtual volumes"" used for grouping and positioning together other; ""real volumes"". See ""Positioned Volumes (Nodes)"". The same; structure represented by (a real or) a virtual volume can be; ""replicated"" several times in the geometry. **Q:** ""Fine, so probably the real volumes are the ones composing the letters R,; O and T. Why one have to define so many volumes to make an R?"". **A:** Well, in real life some objects have much more complex shapes; that an ""R"". The modeller cannot just know all of them; the idea; is to make a complex object by using elementary building blocks that; have known shapes (called ""primitive shapes""). Gluing these; together in the appropriate way is the user responsibility. **Q:** ""I am getting the global picture but not making much out of it... There; are also a lot of calls to TGeoVolume::AddNode() that I do not understand."". **A:** A vol",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:10725,Usability,simpl,simple,10725,"e have to define so many volumes to make an R?"". **A:** Well, in real life some objects have much more complex shapes; that an ""R"". The modeller cannot just know all of them; the idea; is to make a complex object by using elementary building blocks that; have known shapes (called ""primitive shapes""). Gluing these; together in the appropriate way is the user responsibility. **Q:** ""I am getting the global picture but not making much out of it... There; are also a lot of calls to TGeoVolume::AddNode() that I do not understand."". **A:** A volume is positioned inside another one by using this; method. The relative geometrical transformation as well as a copy number; must be specified. When positioned, a volume becomes a ""node"" of; its container and a new object of the class TGeoNode is; automatically created. This method is therefore the key element for the; creation of a hierarchical link between two volumes. As it will be; described further on in this document, there are few other methods; performing similar actions, but let us keep things simple for the time; being. In addition, notice that there are some visualization-related; calls in the example followed by a final TGeoVolume::Draw() call for; the top volume. These are explained in details in the section; ""Visualization Settings and Attributes"". At this point, you will; probably like to see how this geometry looks like. You just need to run; the example and you will get the following picture that you can rotate; using the mouse; or you can zoom / move it around (see what the Help; menu of the GL window displays). ~~~{.cpp}; % root rootgeom.C; ~~~. \image html geometry001.png width=600px. Now let us browse the hierarchy that was just created. Start a browser; and double-click on the item simple1 representing the; `gGeoManager` object. Note that right click opens the context menu; of the manager class where several global methods are available. ~~~{.cpp}; root[] new TBrowser;; ~~~. \image html geometry002.jpg width=",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:33427,Usability,simpl,simple,33427,"E` and `F` will actually position only `A` and; `B `directly into these volumes, taking into account their combined; transformations `A/B` to `C` and `C` to `D/E/F`. This looks much nicer,; is it? In fact, it is and it is not. Of course, we managed to get rid of; the ""unnecessary"" volume `C` in our geometry, but we end-up with a more; flat structure for `D,E` and `F` (more daughters inside). This can get; much worse when extensively used, as in the case: assemblies of; assemblies. For deciding what to choose between using virtual containers or; assemblies for a specific case, one can use for both cases, after the; geometry was closed:. ~~~{.cpp}; gGeoManager->SetTopVolume(ptr_D);; gGeoManager->Test();; gGeoManager->RestoreMasterVolume();; ~~~. The `ptr_D` is a pointer to volume `D` containing the interesting; structure. The test will provide the timing for classifying 1 million; random points inside `D`. \anchor GP01be; #### Examples of Volume Positioning. Now let us make a simple volume representing a copper wire. We suppose; that a medium is already created (see TGeoMedium class on how to; create media). We will create a `TUBE` shape for our wire, having `Rmin=0cm`,; `Rmax=0.01cm` and a half-length `dZ=1cm`:. ~~~{.cpp}; TGeoTube *tube = new TGeoTube(""wire_tube"",0,0.01,1);; ~~~. One may omit the name for the shape `wire_tube,` if no retrieving by; name is further needed during geometry building. Different volumes; having different names and materials can share the same shape. Now let's make the volume for our wire:. ~~~{.cpp}; TGeoVolume *wire_co = new TGeoVolume(""WIRE_CO"",tube,ptrCOPPER); //(*); ~~~. (*) Do not bother to delete the media, shapes or volumes that you; have created since all will be automatically cleaned on exit by the; manager class. If we would have taken a look inside `TGeoManager::MakeTube()` method,; we would have been able to create our wire with a single line:. ~~~{.cpp}; TGeoVolume *wire_co = gGeoManager->MakeTube(""WIRE_CO"",ptrCOPPER,0,0.01,1",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:35342,Usability,simpl,simplicity,35342,"ave been able to create our wire with a single line:. ~~~{.cpp}; TGeoVolume *wire_co = gGeoManager->MakeTube(""WIRE_CO"",ptrCOPPER,0,0.01,1); //(*); ~~~. (*) The same applies for all primitive shapes, for which there can; be found corresponding `MakeSHAPE()` methods. Their usage is much more; convenient unless a shape has to be shared between more volumes. Let us make now an aluminum wire having the same shape, supposing that; we have created the copper wire with the line above:. ~~~{.cpp}; TGeoVolume *wire_al = new TGeoVolume(""WIRE_AL"",wire_co>GetShape(),; ptrAL);; ~~~. We would like now to position our wire in the middle of a gas chamber.; We need first to define the gas chamber:. ~~~{.cpp}; TGeoVolume *chamber = gGeoManager->MakeTube(""CHAMBER"",ptrGAS,; 0,1,1);; ~~~. Now we can put the wire inside:. ~~~{.cpp}; chamber->AddNode(wire_co,1);; ~~~. If we inspect now the chamber volume in a browser, we will notice that; it has one daughter. Of course, the gas has some container also, but let; us keeps it like that for the sake of simplicity. Since we did not; supply the third argument, the wire will be positioned with an identity; transformation inside the chamber. \anchor GP01bf; #### Overlapping Volumes. Positioning volumes that does not overlap their neighbors nor extrude; their container is sometimes quite strong constraint. Having a limited; set of geometric shapes might force sometimes overlaps. Since; overlapping is contradictory to containment, a point belonging to an; overlapping region will naturally belong to all overlapping partners.; The answer provided by the modeller to ""Where am I?"" is no longer; deterministic if there is no priority assigned. There are two ways out provided by the modeller in such cases and we; will illustrate them by examples. - Suppose we have 2 crossing tubes that we have to describe. Such a; structure cannot be decomposed in a containment schema. This is a; typical example of simple structure that can be handled by using; composite sh",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:36243,Usability,simpl,simple,36243,"e, the gas has some container also, but let; us keeps it like that for the sake of simplicity. Since we did not; supply the third argument, the wire will be positioned with an identity; transformation inside the chamber. \anchor GP01bf; #### Overlapping Volumes. Positioning volumes that does not overlap their neighbors nor extrude; their container is sometimes quite strong constraint. Having a limited; set of geometric shapes might force sometimes overlaps. Since; overlapping is contradictory to containment, a point belonging to an; overlapping region will naturally belong to all overlapping partners.; The answer provided by the modeller to ""Where am I?"" is no longer; deterministic if there is no priority assigned. There are two ways out provided by the modeller in such cases and we; will illustrate them by examples. - Suppose we have 2 crossing tubes that we have to describe. Such a; structure cannot be decomposed in a containment schema. This is a; typical example of simple structure that can be handled by using; composite shapes. What we have to do is to define as shapes the; inner and outer parts of the tubes (tubes having; `Rmin=0`,` Rmax=`inner/outer radius), then to make a composite:; - `C = (Tub1out+Tub2out)-(Tub1in+Tub2in)`; - On the other hand, if we have an EM calorimeter having a honeycomb; structure, Boolean combinations do not help anymore. Here the; problem is that we usually have a very large number of cells that; are naturally belonging to the same container. This result in a very; flat and slow structure for that particular container, which we; would very much want to avoid by introducing additional levels in; depth. We can describe the basic cell as a hexahedron that we can; represent by using a polygon primitive shape. Instead of putting one; by one all cells in the same container, we can define rows of such; elements, fitting in box-shaped containers. Then we can put; row-beside-row inside the container, making life much easier for its; navigatio",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:40532,Usability,simpl,simple,40532,"o, we will just need to; replicate the ones that we have already created. ~~~{.cpp}; chamber->AddNode(wire_co,1,new TGeoTranslation(0.2,0,0));; chamber->AddNode(wire_co,2,new TGeoTranslation(0.2,0,0));; ~~~. The 2 nodes that we have created inside chamber will both point to a; `wire_co` object, but will be completely distinct: `WIRE_CO_1` and; `WIRE_CO_2`. We will want now to place symmetrically 1000 chambers on a; pad, following a pattern of 20 rows and 50 columns. One way to do this; will be to replicate our chamber by positioning it 1000 times in; different positions of the pad. Unfortunately, this is far from being; the optimal way of doing what we want. Imagine that we would like to; find out which of the 1000 chambers is containing a `(x,y,z)` point; defined in the pad reference. You will never have to do that, since the; modeller will take care of it for you, but let's guess what it has to; do. The most simple algorithm will just loop over all daughters, convert; the point from mother to local reference and check if the current; chamber contains the point or not. This might be efficient for pads with; few chambers, but definitely not for 1000. Fortunately the modeller is; smarter than that and creates for each volume some optimization; structures called `voxels` to minimize the penalty having too many; daughters, but if you have 100 pads like this in your geometry you will; anyway lose a lot in your tracking performance. The way out when; volumes can be arranged according to simple patterns is the usage of; divisions. We will describe them in detail later on. Let's think now at; a different situation: instead of 1000 chambers of the same type, we may; have several types of chambers. Let's say all chambers are cylindrical; and have a wire inside, but their dimensions are different. However, we; would like all to be represented by a single volume family, since they; have the same properties. \anchor GP01bh; #### Volume Families. A volume family is represented b",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:41115,Usability,simpl,simple,41115,"o replicate our chamber by positioning it 1000 times in; different positions of the pad. Unfortunately, this is far from being; the optimal way of doing what we want. Imagine that we would like to; find out which of the 1000 chambers is containing a `(x,y,z)` point; defined in the pad reference. You will never have to do that, since the; modeller will take care of it for you, but let's guess what it has to; do. The most simple algorithm will just loop over all daughters, convert; the point from mother to local reference and check if the current; chamber contains the point or not. This might be efficient for pads with; few chambers, but definitely not for 1000. Fortunately the modeller is; smarter than that and creates for each volume some optimization; structures called `voxels` to minimize the penalty having too many; daughters, but if you have 100 pads like this in your geometry you will; anyway lose a lot in your tracking performance. The way out when; volumes can be arranged according to simple patterns is the usage of; divisions. We will describe them in detail later on. Let's think now at; a different situation: instead of 1000 chambers of the same type, we may; have several types of chambers. Let's say all chambers are cylindrical; and have a wire inside, but their dimensions are different. However, we; would like all to be represented by a single volume family, since they; have the same properties. \anchor GP01bh; #### Volume Families. A volume family is represented by the class TGeoVolumeMulti. It; represents a class of volumes having the same shape type and each member; will be identified by the same name and volume ID. Any operation applied; to a TGeoVolumeMulti equally affects all volumes in that family.; The creation of a family is generally not a user task, but can be forced; in particular cases:. ~~~{.cpp}; TGeoManager::Volume(const char *vname,const char *shape, Int_t nmed);; ~~~. Where: `vname` is the family name, `nmed` is the medium number and; `sh",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:44231,Usability,simpl,simplest,44231,"e; used is when we want that a volume positioned inside a container to; match one ore more container limits. Suppose we want to position the; same box inside 2 different volumes and we want the Z size to match the; one of each container:. ~~~{.cpp}; TGeoVolume *container1 = gGeoManager->MakeBox(""C1"",imed,10,10,30);; TGeoVolume *container2 = gGeoManager->MakeBox(""C2"",imed,10,10,20);; TGeoVolume *pvol = gGeoManager->MakeBox(""PVOL"",jmed,3,3,-1);; container1->AddNode(pvol,1);; container2->AddNode(pvol,1);; ~~~. Note that the third parameter of `PVOL` is negative, which does not make; sense as half-length on Z. This is interpreted as: when positioned,; create a box replacing all invalid parameters with the corresponding; dimensions of the container. This is also internally handled by the; **`TGeoVolumeMulti`** class, which does not need to be instantiated by; users. \anchor GP01bi; #### Dividing Volumes. Volumes can be divided according a pattern. The simplest division can be; done along one axis that can be: `X,Y,Z,Phi,Rxy or Rxyz`. Let's take a; simple case: we would like to divide a box in N equal slices along X; coordinate, representing a new volume family. Supposing we already have; created the initial box, this can be done like:. ~~~{.cpp}; TGeoVolume *slicex = box->Divide(""SLICEX"",1,N);; ~~~. Here `SLICEX` is the name of the new family representing all slices and; 1 is the slicing axis. The meaning of the axis index is the following:; for all volumes having shapes like `box`, `trd1`, `trd2`, `trap`,; `gtra `or` para - `1, 2, 3 mean X, Y, Z; for `tube`, `tubs`, `cone`,; `cons - `1 means `Rxy`, 2 means `phi` and 3 means Z; for `pcon` and; `pgon` - 2 means `phi` and 3 means Z; for spheres 1 means `R `and 2; means `phi.`. In fact, the division operation has the same effect as positioning; volumes in a given order inside the divided container - the advantage; being that the navigation in such a structure is much faster. When a; volume is divided, a volume family corres",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:44329,Usability,simpl,simple,44329,"Suppose we want to position the; same box inside 2 different volumes and we want the Z size to match the; one of each container:. ~~~{.cpp}; TGeoVolume *container1 = gGeoManager->MakeBox(""C1"",imed,10,10,30);; TGeoVolume *container2 = gGeoManager->MakeBox(""C2"",imed,10,10,20);; TGeoVolume *pvol = gGeoManager->MakeBox(""PVOL"",jmed,3,3,-1);; container1->AddNode(pvol,1);; container2->AddNode(pvol,1);; ~~~. Note that the third parameter of `PVOL` is negative, which does not make; sense as half-length on Z. This is interpreted as: when positioned,; create a box replacing all invalid parameters with the corresponding; dimensions of the container. This is also internally handled by the; **`TGeoVolumeMulti`** class, which does not need to be instantiated by; users. \anchor GP01bi; #### Dividing Volumes. Volumes can be divided according a pattern. The simplest division can be; done along one axis that can be: `X,Y,Z,Phi,Rxy or Rxyz`. Let's take a; simple case: we would like to divide a box in N equal slices along X; coordinate, representing a new volume family. Supposing we already have; created the initial box, this can be done like:. ~~~{.cpp}; TGeoVolume *slicex = box->Divide(""SLICEX"",1,N);; ~~~. Here `SLICEX` is the name of the new family representing all slices and; 1 is the slicing axis. The meaning of the axis index is the following:; for all volumes having shapes like `box`, `trd1`, `trd2`, `trap`,; `gtra `or` para - `1, 2, 3 mean X, Y, Z; for `tube`, `tubs`, `cone`,; `cons - `1 means `Rxy`, 2 means `phi` and 3 means Z; for `pcon` and; `pgon` - 2 means `phi` and 3 means Z; for spheres 1 means `R `and 2; means `phi.`. In fact, the division operation has the same effect as positioning; volumes in a given order inside the divided container - the advantage; being that the navigation in such a structure is much faster. When a; volume is divided, a volume family corresponding to the slices is; created. In case all slices can be represented by a single shape, only; one volume ",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:48584,Usability,simpl,simply,48584,"e). Divides `MOTHER` into `NDIV` divisions called `NAME` along axis `IAXIS`; starting at coordinate value `START` and having size `STEP`. The created; volumes will have tracking media `ID=NUMED` (if `NUMED=0` -\> same media; as `MOTHER`). The behavior of the division operation can be triggered using `OPTION`; (case insensitive):. - `N`divide all range in `NDIV` cells (same effect as `STEP<=0`); (GSDVN in G3); - `NX`divide range starting with `START` in `NDIV` cells (GSDVN2 in; G3); - `S`divide all range with given `STEP`; `NDIV` is computed and; divisions will be centered in full range (same effect as `NDIV<=0`); (GSDVS, GSDVT in G3); - `SX`same as `DVS`, but from `START` position (GSDVS2, GSDVT2 in G3). \anchor GP01bj; #### Volume Assemblies. In general, geometry contains structures of positioned volumes that have; to be grouped and handled together, for different possible reasons. One; of these is that the structure has to be replicated in several parts of; the geometry, or it may simply happen that they really represent a; single object, too complex to be described by a primitive shape. Usually handling structures like these can be easily done by positioning; all components in the same container volume, then positioning the; container itself. However, there are many practical cases when defining; such a container is not straightforward or even possible without; generating overlaps with the rest of the geometry. There are few ways; out of this:. - Defining the container for the structure as ""overlapping"" (see also; ""Overlapping Volumes""); - Representing the container as a composite shape - the Boolean union; of all components (see also ""Composite Shapes""); - Using an assembly volume - this will be described in the following. The first two approaches have the disadvantage of penalizing the; navigation performance with a factor increasing more than linear of the; number of components in the structure. The best solution is the third; one because it uses all volume-rel",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:51139,Usability,simpl,simple,51139,", so a TGeoVolumeAssembly does not need to have a; medium. Due to the self-containment of assemblies, they are very; practical to use when a container is hard to define due to possible; overlaps during positioning. For instance, it is very easy creating; honeycomb structures. A very useful example for creating and using; assemblies can be found at: assembly.C. Creation of an assembly is very easy: one has just to create a; TGeoVolumeAssembly object and position the components inside as; for any volume:. ~~~{.cpp}; TGeoVolume *vol = new TGeoVolumeAssembly(name);; vol->AddNode(vdaughter1, cpy1, matrix1);; vol->AddNode(vdaughter2, cpy2, matrix2);; ~~~. Note that components cannot be declared as ""overlapping"" and that a; component can be an assembly volume. For existing flat volume; structures, one can define assemblies to force a hierarchical structure; therefore optimizing the performance. Usage of assemblies does NOT imply; penalties in performance, but in some cases, it can be observed that it; is not as performing as bounding the structure in a container volume; with a simple shape. Choosing a normal container is therefore; recommended whenever possible. \image html geometry006.png ""Assemblies of volumes"" width=600px. \anchor GP01c; ### Geometrical Transformations. All geometrical transformations handled by the modeller are provided as; a built-in package. This was designed to minimize memory requirements; and optimize performance of point/vector master-to-local and; local-to-master computation. We need to have in mind that a; transformation in **`TGeo`** has two major use-cases. The first one is; for defining the placement of a volume with respect to its container; reference frame. This frame will be called 'master' and the frame of the; positioned volume - 'local'. If `T` is a transformation used for; positioning volume daughters, then: `MASTER = T * LOCAL`. Therefore `T `is used to perform a local to master conversion, while; `T-1` for a master to local conversi",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:52756,Usability,simpl,simple,52756,"cement of a volume with respect to its container; reference frame. This frame will be called 'master' and the frame of the; positioned volume - 'local'. If `T` is a transformation used for; positioning volume daughters, then: `MASTER = T * LOCAL`. Therefore `T `is used to perform a local to master conversion, while; `T-1` for a master to local conversion. The second use case is the; computation of the global transformation of a given object in the; geometry. Since the geometry is built as 'volumes-inside-volumes', the; global transformation represents the pile-up of all local; transformations in the corresponding branch. Once a given object in the; hierarchy becomes the current one, the conversion from master to local; coordinates or the other way around can be done from the manager class. A general homogenous transformation is defined as a 4x4 matrix embedding; a rotation, a translation and a scale. The advantage of this description; is that each basic transformation can be represented as a homogenous; matrix, composition being performed as simple matrix multiplication. Rotation:. \f[; \left|\begin{array}{cccc}; r_{11} & r_{12} & r_{13} & 0 \\; r_{21} & r_{22} & r_{23} & 0 \\; r_{31} & r_{32} & r_{33} & 0 \\; 0 & 0 & 0 & 1; \end{array}; \right|; \f]. Translation:. \f[; \left|\begin{array}{cccc}; 1 & 0 & 0 & 0 \\; 0 & 1 & 0 & 0 \\; 0 & 0 & 1 & 0 \\; t_x & t_y & t_z & 1; \end{array}; \right|; \f]. Scale:. \f[; \left|\begin{array}{cccc}; s_x & 0 & 0 & 0 \\; 0 & s_y & 0 & 0 \\; 0 & 0 & s_z & 0 \\; 0 & 0 & 0 & 1; \end{array}; \right|; \f]. Inverse rotation:. \f[; \left|\begin{array}{cccc}; r_{11} & r_{21} & r_{31} & 0 \\; r_{12} & r_{22} & r_{32} & 0 \\; r_{13} & r_{23} & r_{33} & 0 \\; 0 & 0 & 0 & 1; \end{array}; \right|; \f]. Inverse translation:. \f[; \left|\begin{array}{cccc}; 1 & 0 & 0 & 0 \\; 0 & 1 & 0 & 0 \\; 0 & 0 & 1 & 0 \\; -t_x & -t_y & -t_z & 1; \end{array}; \right|; \f]. Inverse scale:. \f[; \left|\begin{array}{cccc}; \frac{1}{s_x} & 0 & 0 & 0 \\; 0 & \frac",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:62206,Usability,simpl,simple,62206,"igation and Tracking. Tracking is the feature allowing the transport of a given particle; knowing its kinematics. A state is determined by any combination of the; position \f$\vec{r}\f$ and direction \f$\vec{n}\f$ with respect to the world; reference frame. The direction \f$\vec{n}\f$ must be a unit vector having as; components the director cosines. The full classification of a given; state will provide the following information: the deepest physical node; containing the position vector, the distance to the closest boundary; along the direction vector, the next physical node after propagating the; current point with this distance and the safety distance to the nearest; boundary. This information allows the propagation of particles inside a; detector geometry by taking into account both geometrical and physical; constraints. We will hereby describe the user interface of `TGeo` to access; tracking functionality. This allows either developing a tracker for; simple navigation within a given geometry, either interfacing to an; external tracking engine such as GEANT. Note that the abstract interface; for external trackers can be found in `$ROOTSYS/vmc` folder and it can; be used to run GEANT3, GEANT4 and FLUKA-based simulations (\*) by using; directly a geometry described with %ROOT. The interface methods related to tracking are incorporated into; TGeoManager class and implemented in the navigator class; TGeoNavigator. In order to be able to start tracking, one has to; define the initial state providing the starting point \f$\vec{r_0}\f$; and direction \f$\vec{n_0}\f$ .; There are several ways of doing that. \anchor GP02a; ### TGeoNavigator Class. One geometry may have several independent navigators to query to; localize points or compute distances. The geometry manager holds a list; of active navigators accessible via:. ~~~{.cpp}; TObjArray *navigators = gGeoManager->GetListOfNavigators();; ~~~. Upon closing the geometry a default navigator is provided as first one; in t",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:65874,Usability,simpl,simple,65874,"P02c; ### Initializing the Direction. In order to move inside geometry starting with the current point, the; modeller needs to know the current direction `(nx,ny,nz)`. This; direction is stored as `Double_t fCurrentDirection[3]` by the navigator; and it represents a direction in the global frame. It can be retrieved; with:. ~~~{.cpp}; Const Double_t *cdir = gGeoManager->GetCurrentDirection();; ~~~. The direction can be initialized in a similar manner as the current; point:. ~~~{.cpp}; gGeoManager->SetCurrentDirection(nx,ny,nz);; // or:; gGeoManager->SetCurrentDirection(Double_t *dir);; ~~~. \anchor GP02d; ### Initializing the State. Setting the initial point and direction is not enough for initializing; tracking. The modeller needs to find out where the initial point is; located in the geometrical hierarchy. Due to the containment based; architecture of the model, this is the deepest positioned object; containing the point. For illustrating this, imagine that we have a; simple structure with a top volume `A` and another one `B `positioned; inside. Since `A `is a top volume, its associated node `A_1` will define; `MARS` and our simple hierarchy of nodes (positioned volumes) will be:; `/A_1/B_1`. Suppose now that the initial point is contained by `B_1`.; This implies by default that the point is also contained by `A_1`, since; `B_1` have to be fully contained by this. After searching the point; location, the modeller will consider that the point is located inside; `B_1`, which will be considered as the representative object (node) for; the current state. This is stored as: `TGeoNode *TGeoNavigator::%fCurrentNode`; and can be asked from the manager class; only after the `'Where am I?'` was completed:. ~~~{.cpp}; TGeoNode *current = gGeoManager->GetCurrentNode();; ~~~. In order to find the location of the current point inside the hierarchy; of nodes, after setting this point it is mandatory to call the; `‘Where am I?'` method:. ~~~{.cpp}; gGeoManager->FindNode();; ~~~. ",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:66034,Usability,simpl,simple,66034,"rrent direction `(nx,ny,nz)`. This; direction is stored as `Double_t fCurrentDirection[3]` by the navigator; and it represents a direction in the global frame. It can be retrieved; with:. ~~~{.cpp}; Const Double_t *cdir = gGeoManager->GetCurrentDirection();; ~~~. The direction can be initialized in a similar manner as the current; point:. ~~~{.cpp}; gGeoManager->SetCurrentDirection(nx,ny,nz);; // or:; gGeoManager->SetCurrentDirection(Double_t *dir);; ~~~. \anchor GP02d; ### Initializing the State. Setting the initial point and direction is not enough for initializing; tracking. The modeller needs to find out where the initial point is; located in the geometrical hierarchy. Due to the containment based; architecture of the model, this is the deepest positioned object; containing the point. For illustrating this, imagine that we have a; simple structure with a top volume `A` and another one `B `positioned; inside. Since `A `is a top volume, its associated node `A_1` will define; `MARS` and our simple hierarchy of nodes (positioned volumes) will be:; `/A_1/B_1`. Suppose now that the initial point is contained by `B_1`.; This implies by default that the point is also contained by `A_1`, since; `B_1` have to be fully contained by this. After searching the point; location, the modeller will consider that the point is located inside; `B_1`, which will be considered as the representative object (node) for; the current state. This is stored as: `TGeoNode *TGeoNavigator::%fCurrentNode`; and can be asked from the manager class; only after the `'Where am I?'` was completed:. ~~~{.cpp}; TGeoNode *current = gGeoManager->GetCurrentNode();; ~~~. In order to find the location of the current point inside the hierarchy; of nodes, after setting this point it is mandatory to call the; `‘Where am I?'` method:. ~~~{.cpp}; gGeoManager->FindNode();; ~~~. In order to have more flexibility, there are in fact several alternative; ways of initializing a modeller state:. ~~~{.cpp}; // Setting th",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:70553,Usability,simpl,simple,70553,"sible different states of; the modeller corresponds to the number of different objects/paths in; the geometry. This has nothing to do with the number of nodes, since; the same node can be found on different branches. In other words,; the number of states corresponds to the number of nodes in the; `expanded geometry tree`. Since unfortunately this expansion from; logical to physical hierarchy cannot be stored on regular basis due; to the large size of the latter, one cannot directly assign state; numbers. If the size of the expansion proves however to be small; enough (less than about 50 million objects), a parallel structure; storing these state indices is built and stored in memory. In such; case each state automatically gets an index that can be retrieved; after any state initialization. These indices can prove to be quite; useful for being able to keep track of the navigation history and; force certain states. Let's illustrate how this works with a simple; example:; - Suppose we have a simple geometry with a volume B positioned twice; inside a container A. Then A is positioned twice in a top container; T. The complete list of logical nodes is: `T_1`, `A_1`, `A_2`,; `B_1`, `B_2`. On the other hand we will have more states than; logical nodes:; - `/T_1`- 1 state at level = 0; - `/T_1/A_1,/T_1/A_2`- 2 states at level = 1; - `/T_1/A_1/B_1,/T_1/A_1/B_2,/T_1/A_2/B_1,/T_1/A_2/B_2` - 4 states at; level = 2; - All these states will get automatic numbers, starting with 0; corresponding to the top-level state and ending with an integer; corresponding to Ntotal\_states-1. The mapping from a given logical; node to a state number is generally not possible, as for the node; B\_1 that appears as current node for 2 different states. The; numbering order of states is therefore not important, but it can be; used as in the following lines:. ~~~{.cpp}; gGeoManager->InitTrack(pt,dir); // anything to initialize a state; Int_t istate = gGeoManager->GetCurrentNodeId(); // in fact state Id",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:70591,Usability,simpl,simple,70591,"sible different states of; the modeller corresponds to the number of different objects/paths in; the geometry. This has nothing to do with the number of nodes, since; the same node can be found on different branches. In other words,; the number of states corresponds to the number of nodes in the; `expanded geometry tree`. Since unfortunately this expansion from; logical to physical hierarchy cannot be stored on regular basis due; to the large size of the latter, one cannot directly assign state; numbers. If the size of the expansion proves however to be small; enough (less than about 50 million objects), a parallel structure; storing these state indices is built and stored in memory. In such; case each state automatically gets an index that can be retrieved; after any state initialization. These indices can prove to be quite; useful for being able to keep track of the navigation history and; force certain states. Let's illustrate how this works with a simple; example:; - Suppose we have a simple geometry with a volume B positioned twice; inside a container A. Then A is positioned twice in a top container; T. The complete list of logical nodes is: `T_1`, `A_1`, `A_2`,; `B_1`, `B_2`. On the other hand we will have more states than; logical nodes:; - `/T_1`- 1 state at level = 0; - `/T_1/A_1,/T_1/A_2`- 2 states at level = 1; - `/T_1/A_1/B_1,/T_1/A_1/B_2,/T_1/A_2/B_1,/T_1/A_2/B_2` - 4 states at; level = 2; - All these states will get automatic numbers, starting with 0; corresponding to the top-level state and ending with an integer; corresponding to Ntotal\_states-1. The mapping from a given logical; node to a state number is generally not possible, as for the node; B\_1 that appears as current node for 2 different states. The; numbering order of states is therefore not important, but it can be; used as in the following lines:. ~~~{.cpp}; gGeoManager->InitTrack(pt,dir); // anything to initialize a state; Int_t istate = gGeoManager->GetCurrentNodeId(); // in fact state Id",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:98536,Usability,simpl,simple,98536," removal algorithms, OpenGL viewing\* or ray tracing. The method TGeoManager::GetGeomPainter() loads the painting library in; memory. This is generally not needed since it is called automatically by; TGeoVolume::Draw() as well as by few other methods setting; visualization attributes. \anchor GP04a; ### Drawing Volumes and Hierarchies of Volumes. The first thing one would like to do after building some geometry is to; visualize the volume tree. This provides the fastest validation check; for most common coding or design mistakes. As soon as the geometry is; successfully closed, one should draw it starting from the top-level; volume:. ~~~{.cpp}; //... code for geometry building; root[] gGeoManager->CloseGeometry();; root[] gGeoManager->GetMasterVolume()->Draw();; ~~~. Doing this ensures that the original top-level volume of the geometry is; drawn, even if another volume is currently the geometry `root`. OK, I; suppose you already did that with your simple geometry and immediately; noticed a new ROOT canvas popping-up and having some more or less; strange picture inside. Here are few questions that might come:. **Q:** ""The picture is strangely rotated; where are the coordinate axes?"". **A:** If drawn in a new canvas, any view has some default; viewpoint, center of view and size. One can then perform mouse/keyboard; actions to change them:. - Mouse left-click and drag will rotate the view;. - Some keys can be pressed when the view canvas is selected: J/K; zoom/un-zoom, U/I move up/down, L/H move left/right. The coordinate axes; display as well as changing top or side viewpoints can be activated from; the **`TView`** context menu: right-click on the picture when no object; is selected;. **Q:** ""Every line is black! I cannot figure out what is what..."". **A:** Volumes can have different colors (those known by %ROOT of; course). Think at using them after each volume creation:; `myvolume->SetLineColor(Int_t color);` otherwise everything is by; default black. **Q:** ""The to",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:104014,Usability,simpl,simple,104014,"el put a; limitation on the maximum applied depth. Combined with visibility; settings per volume, these can tune quite well what should appear on the; screen. However, there are situations when users want to see a volume; branch displayed down to the maximum depth, keeping at the same time a; limitation or even suppressing others. In order to accomplish that, one; should use the volume attribute: ""Visible daughters"". By default, all; daughters of all volumes are displayed if there is no limitation related; with their level depth with respect to the top drawn volume. \anchor GP04c; ### Ray Tracing. Ray tracing is a quite known drawing technique based on tracking rays; from the eye position through all pixels of a view port device. The; pixel color is derived from the properties of the first crossed surface,; according some illumination model and material optical properties. While; there are currently existing quite sophisticated ray tracing models,; `TGeo` is currently using a very simple approach where the light; source is matching the eye position (no shadows or back-tracing of the; reflected ray). In future we are considering providing a base class in; order to be able to derive more complex models. Due to the fact that the number of rays that have to be tracked matches; the size in pixels of the pad, the time required by this algorithm is; proportional to the pad size. On the other hand, the speed is quite; acceptable for the default ROOT pad size and the images produced by; using this technique have high quality. Since the algorithm is; practically using all navigation features, producing ray-traced pictures; is also a geometry validation check. Ray tracing can be activated at; volume level as the normal `Draw()`. \image html geometry013.jpg ""Ray-traced view in a pad"". ~~~{.cpp}; myVolume->Raytrace(); ~~~. Once ray-tracing a view, this can be zoomed or rotated as a usual one.; Objects on the screen are no longer highlighted when picking the; vertices but the corr",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:124043,Usability,simpl,simple,124043,"eference frame of the current volume and to; compute the distance to exit its shape from inside. The returned value; is again compared to the maximum allowed step (the proposed one) and in; case the distance is safe no other action is performed and the proposed; step is approved. In case the boundary is closer, the computed distance; is taken as maximum allowed step. For optimization purposed, for; particles starting very close to the current volume boundary (less than; 0.01 microns) and exiting the algorithm stops here. After computing the distance to exit the current node, the distance to; the daughter of the current volume which is crossed next is computed by; TGeoManager::FindNextDaughterBoundary(). This computes the; distance to all daughter candidates that can be possibly crossed by; using volume voxelization. The algorithm is efficient in average only in; case the number of daughters is greater than 4. For fewer nodes, a; simple loop is performed and the minimum distance (from a point outside; each shape) is taken and compared to the maximum allowed step. The step; value is again updated if `step<stepmax` . A special case is when the current node is declared as possibly; overlapping with something else. If this is the case, the distance is; computed for all possibly overlapping candidates, taking into account; the overlapping priorities (see also: "" Overlapping volumes ""). The global matrix describing the next crossed physical node is; systematically computed in case the value of the proposed step is; negative. In this case, one can subsequently call; TGeoManager::ComputeNormalFast() to get the normal vector to the; crossed surface, after propagating the current point with the; TGeoManager::GetStep() value. This propagation can be done like:. ~~~{.cpp}; Double_t *current_point = gGeoManager->GetCurrentPoint();; Double_t *current_dir = gGeoManager->GetCurrentDirection();; for (Int_t i=0; i<3; i++); current_point[i] += step * current_dir[I];; ~~~. Note: The met",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:131125,Usability,undo,undoable,131125,"nsient; frames will not delete, but just hide existing opened editors for later; reuse. Their lifetime is determined by the canvas to which the manager; editor is attached to, since these will be destroyed together. \image html geometry021.png ""Editors for shapes, materials, media, matrices"" width=600px. For most editors, the functionalities Apply and Undo are provided. For shapes, changing any of the shape parameters will activate the; ""Apply"" button only if the check button ""Delayed draw"" is checked,; otherwise the changes are immediately applied. Once the apply button is; pressed, the changes are applied to the edited shape and drawn. The; ""Undo"" button becomes active after the first modification has been; applied. It allows restoring the initial parameters of the shape. NOTE: In this version the ""Undo"" does not allow restoring an; intermediate state of the parameters that was applied - it will always; restore the parameters at the moment the shape was edited. All material properties changes are undoable. The mixture editor; currently allows adding elements one by one in the mixture composition.; This can be done either by element weight fraction or by number of; atoms. Once an element was added using one method the other method is not; selectable anymore. Summing component fractions up to 1 in the final; mixture is the user responsibility. Adding materials as components of a; mixture is not supported in this version. The elements that were added to the mixture appear in the bottom of the; mixture editor. The operations performed on mixture are not undoable. \anchor GP08d; ### Creation of New Objects. As described above, all geometry object creators are accessible within; the geometry manager editor frame. Generally, if the new object that; needs to be created does not depend on other objects, it will be built; with a set of default parameters. This is the case for all shapes; (except composite shapes) and matrices. For all the other objects the; interface forces",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:131689,Usability,undo,undoable,131689," the apply button is; pressed, the changes are applied to the edited shape and drawn. The; ""Undo"" button becomes active after the first modification has been; applied. It allows restoring the initial parameters of the shape. NOTE: In this version the ""Undo"" does not allow restoring an; intermediate state of the parameters that was applied - it will always; restore the parameters at the moment the shape was edited. All material properties changes are undoable. The mixture editor; currently allows adding elements one by one in the mixture composition.; This can be done either by element weight fraction or by number of; atoms. Once an element was added using one method the other method is not; selectable anymore. Summing component fractions up to 1 in the final; mixture is the user responsibility. Adding materials as components of a; mixture is not supported in this version. The elements that were added to the mixture appear in the bottom of the; mixture editor. The operations performed on mixture are not undoable. \anchor GP08d; ### Creation of New Objects. As described above, all geometry object creators are accessible within; the geometry manager editor frame. Generally, if the new object that; needs to be created does not depend on other objects, it will be built; with a set of default parameters. This is the case for all shapes; (except composite shapes) and matrices. For all the other objects the; interface forces the selection of components before creating the object. \anchor GP08e; ### Editing Volumes. Volumes are hierarchical components in the geometry, therefore their; editor is more complex. It provides the following functionalities:. - *General*. This category allows changing the name of the volume and; selecting other shape or medium among existing ones. - *Daughters*. The category allows removing existing daughter nodes or; adding new ones. The button ""Position"" allows editing the; positioning matrix of a given node. \image html geometry022.jpg width=600p",MatchSource.DOCS,geom/geom/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md:1612,Energy Efficiency,charge,charge,1612,"efore creating the volume; itself, so we will describe the bits and pieces needed for making the; geometry before moving to an architectural point of view. As far as materials are concerned, they represent the physical; properties of the solid from which a volume is made. Materials are just; a support for the data that has to be provided to the tracking engine; that uses this geometry package. Due to this fact, the; TGeoMaterial class is more like a thin data structure needed for; building the corresponding native materials of the Monte-Carlo tracking; code that uses TGeo. \anchor GM00a; ### Elements, Materials and Mixtures. In order to make easier material and mixture creation, one can use the; pre-built table of elements owned by TGeoManager class:. ~~~{.cpp}; TGeoElementTable *table = gGeoManager->GetElementTable();; TGeoElement *element1 = table->GetElement(Int_t Z);; TGeoElement *element2 = table->FindElement(""Copper"");; ~~~. Materials made of single elements can be defined by their atomic mass; (`A`), charge (`Z`) and density (`rho`). One can also create a material; by specifying the element that it is made of. Optionally the radiation; and absorption lengths can be also provided; otherwise they can be; computed on-demand [`G3`]. The class representing them is; TGeoMaterial:. ~~~{.cpp}; TGeoMaterial(const char *name,Double_t a,Double_t z,; Double_t density, Double_t radlen=0,Double_t intlen=0);; TGeoMaterial(const char *name, TGeoElement *elem,; Double_t density);; TGeoMaterial(const char* name, Double_t a, Double_t z,; Double_t rho,; TGeoMaterial::EGeoMaterialState state,; Double_t temperature = STP_temperature,; Double_t pressure = STP_pressure); ~~~. Any material or derived class is automatically indexed after creation.; The assigned index is corresponding to the last entry in the list of; materials owned by TGeoManager class. This can be changed using; the `TGeoMaterial::SetIndex()` method, however it is not; recommended while using the geometry package in",MatchSource.DOCS,geom/geom/doc/materials.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md:4225,Energy Efficiency,charge,charge,4225,"oring Cerenkov; properties. Another hook for material shading properties is currently; not in use. Mixtures are materials made of several elements. They are; represented by the class TGeoMixture, deriving from; TGeoMaterial and defined by their number of components and the; density:. ~~~{.cpp}; TGeoMixture(const char *name,Int_t nel,Double_t rho);; ~~~. Elements have to be further defined one by one:. ~~~{.cpp}; void TGeoMixture::DefineElement(Int_t iel,Double_t a,Double_t z,; Double_t weigth);; void TGeoMixture::DefineElement(Int_t iel, TGeoElement *elem,; Double_t weight);; void TGeoMixture::DefineElement(Int_t iel, Int_t z, Int_t natoms);; ~~~. or:. ~~~{.cpp}; void AddElement(TGeoMaterial* mat, Double_t weight);; void AddElement(TGeoElement* elem, Double_t weight);; void AddElement(TGeoElement* elem, Int_t natoms);; void AddElement(Double_t a, Double_t z, Double_t weight); ~~~. - `iel:` index of the element` [0,nel-1]`; - `a` and `z:` the atomic mass and charge; - `weight:` proportion by mass of the elements; - `natoms`: number of atoms of the element in the molecule making the; mixture. The radiation length is automatically computed when all elements are; defined. Since tracking MC provide several other ways to create; materials/mixtures, the materials classes are likely to evolve as the; interfaces to these engines are being developed. Generally in the; process of tracking material properties are not enough and more specific; media properties have to be defined. These highly depend on the MC; performing tracking and sometimes allow the definition of different; media properties (e.g. energy or range cuts) for the same material. \anchor GM00b; ### Radionuclides. A new class TGeoElementRN was introduced in this version to; provide support for radioactive nuclides and their decays. A database of; 3162 radionuclides can be loaded on demand via the table of elements; (TGeoElementTable class). One can make then materials/mixtures; based on these radionuclides and use ",MatchSource.DOCS,geom/geom/doc/materials.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md:4868,Energy Efficiency,energy,energy,4868,"nt_t natoms);; ~~~. or:. ~~~{.cpp}; void AddElement(TGeoMaterial* mat, Double_t weight);; void AddElement(TGeoElement* elem, Double_t weight);; void AddElement(TGeoElement* elem, Int_t natoms);; void AddElement(Double_t a, Double_t z, Double_t weight); ~~~. - `iel:` index of the element` [0,nel-1]`; - `a` and `z:` the atomic mass and charge; - `weight:` proportion by mass of the elements; - `natoms`: number of atoms of the element in the molecule making the; mixture. The radiation length is automatically computed when all elements are; defined. Since tracking MC provide several other ways to create; materials/mixtures, the materials classes are likely to evolve as the; interfaces to these engines are being developed. Generally in the; process of tracking material properties are not enough and more specific; media properties have to be defined. These highly depend on the MC; performing tracking and sometimes allow the definition of different; media properties (e.g. energy or range cuts) for the same material. \anchor GM00b; ### Radionuclides. A new class TGeoElementRN was introduced in this version to; provide support for radioactive nuclides and their decays. A database of; 3162 radionuclides can be loaded on demand via the table of elements; (TGeoElementTable class). One can make then materials/mixtures; based on these radionuclides and use them in a geometry. ~~~{.cpp}; root[] TGeoManager *geom = new TGeoManager(""geom"",""radionuclides"");; root[] TGeoElementTable *table = geom->GetElementTable();; root[] TGeoElementRN *c14 = table->GetElementRN(14,6); // A,Z; root[] c14->Print();; 6-C-014 ENDF=60140; A=14; Z=6; Iso=0; Level=0[MeV]; Dmass=3.0199[MeV];; Hlife=1.81e+11[s] J/P=0+; Abund=0; Htox=5.8e-10; Itox=5.8e-10; Stat=0; Decay modes:; BetaMinus Diso: 0 BR: 100.000% Qval: 0.1565; ~~~. One can make materials or mixtures from radionuclides:. ~~~{.cpp}; root[] TGeoMaterial *mat = new TGeoMaterial(""C14"", c14, 2.0);; ~~~. The following properties of radionuclides can be cu",MatchSource.DOCS,geom/geom/doc/materials.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md:5967,Energy Efficiency,charge,charge,5967,"ntroduced in this version to; provide support for radioactive nuclides and their decays. A database of; 3162 radionuclides can be loaded on demand via the table of elements; (TGeoElementTable class). One can make then materials/mixtures; based on these radionuclides and use them in a geometry. ~~~{.cpp}; root[] TGeoManager *geom = new TGeoManager(""geom"",""radionuclides"");; root[] TGeoElementTable *table = geom->GetElementTable();; root[] TGeoElementRN *c14 = table->GetElementRN(14,6); // A,Z; root[] c14->Print();; 6-C-014 ENDF=60140; A=14; Z=6; Iso=0; Level=0[MeV]; Dmass=3.0199[MeV];; Hlife=1.81e+11[s] J/P=0+; Abund=0; Htox=5.8e-10; Itox=5.8e-10; Stat=0; Decay modes:; BetaMinus Diso: 0 BR: 100.000% Qval: 0.1565; ~~~. One can make materials or mixtures from radionuclides:. ~~~{.cpp}; root[] TGeoMaterial *mat = new TGeoMaterial(""C14"", c14, 2.0);; ~~~. The following properties of radionuclides can be currently accessed via; getters in the TGeoElementRN class:. Atomic number and charge (from the base class TGeoElement). - Isomeric number (`ISO`); - ENDF code - following the convention: `ENDF=10000*Z+100*A+ISO`; - Isomeric energy level [`MeV`]; - Mass excess [`MeV`]; - Half life [`s`]; - Spin/Parity - can be retrieved with: `TGeoElementRN::GetTitle()`; - Hynalation and ingestion toxicities; - List of decays - `TGeoElementRN::GetDecays()`. The radioactive decays of a radionuclide are represented by the class; TGeoDecayChannel and they are stored in a TObjArray. Decay; provides:. - Decay mode; - Variation of isomeric number; - `Q` value for the decay [`GeV`]; - Parent element; - Daughter element. Radionuclides are linked one to each other via their decays, until the; last element in the decay chain which must be stable. One can iterate; decay chains using the iterator TGeoElemIter:. ~~~{.cpp}; root[] TGeoElemIter next(c14);; root[] TGeoElementRN *elem;; root[] while ((elem=next())) next.Print();; 6-C-014 (100% BetaMinus) T1/2=1.81e+11; 7-N-014 stable; ~~~. To create a radio",MatchSource.DOCS,geom/geom/doc/materials.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md:6113,Energy Efficiency,energy,energy,6113,"class). One can make then materials/mixtures; based on these radionuclides and use them in a geometry. ~~~{.cpp}; root[] TGeoManager *geom = new TGeoManager(""geom"",""radionuclides"");; root[] TGeoElementTable *table = geom->GetElementTable();; root[] TGeoElementRN *c14 = table->GetElementRN(14,6); // A,Z; root[] c14->Print();; 6-C-014 ENDF=60140; A=14; Z=6; Iso=0; Level=0[MeV]; Dmass=3.0199[MeV];; Hlife=1.81e+11[s] J/P=0+; Abund=0; Htox=5.8e-10; Itox=5.8e-10; Stat=0; Decay modes:; BetaMinus Diso: 0 BR: 100.000% Qval: 0.1565; ~~~. One can make materials or mixtures from radionuclides:. ~~~{.cpp}; root[] TGeoMaterial *mat = new TGeoMaterial(""C14"", c14, 2.0);; ~~~. The following properties of radionuclides can be currently accessed via; getters in the TGeoElementRN class:. Atomic number and charge (from the base class TGeoElement). - Isomeric number (`ISO`); - ENDF code - following the convention: `ENDF=10000*Z+100*A+ISO`; - Isomeric energy level [`MeV`]; - Mass excess [`MeV`]; - Half life [`s`]; - Spin/Parity - can be retrieved with: `TGeoElementRN::GetTitle()`; - Hynalation and ingestion toxicities; - List of decays - `TGeoElementRN::GetDecays()`. The radioactive decays of a radionuclide are represented by the class; TGeoDecayChannel and they are stored in a TObjArray. Decay; provides:. - Decay mode; - Variation of isomeric number; - `Q` value for the decay [`GeV`]; - Parent element; - Daughter element. Radionuclides are linked one to each other via their decays, until the; last element in the decay chain which must be stable. One can iterate; decay chains using the iterator TGeoElemIter:. ~~~{.cpp}; root[] TGeoElemIter next(c14);; root[] TGeoElementRN *elem;; root[] while ((elem=next())) next.Print();; 6-C-014 (100% BetaMinus) T1/2=1.81e+11; 7-N-014 stable; ~~~. To create a radioactive material based on a radionuclide, one should; use the constructor:. ~~~{.cpp}; TGeoMaterial(const char *name, TGeoElement *elem, Double_t density); ~~~. To create a radioactive mixture,",MatchSource.DOCS,geom/geom/doc/materials.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md:2587,Integrability,interface,interfaced,2587,"erials made of single elements can be defined by their atomic mass; (`A`), charge (`Z`) and density (`rho`). One can also create a material; by specifying the element that it is made of. Optionally the radiation; and absorption lengths can be also provided; otherwise they can be; computed on-demand [`G3`]. The class representing them is; TGeoMaterial:. ~~~{.cpp}; TGeoMaterial(const char *name,Double_t a,Double_t z,; Double_t density, Double_t radlen=0,Double_t intlen=0);; TGeoMaterial(const char *name, TGeoElement *elem,; Double_t density);; TGeoMaterial(const char* name, Double_t a, Double_t z,; Double_t rho,; TGeoMaterial::EGeoMaterialState state,; Double_t temperature = STP_temperature,; Double_t pressure = STP_pressure); ~~~. Any material or derived class is automatically indexed after creation.; The assigned index is corresponding to the last entry in the list of; materials owned by TGeoManager class. This can be changed using; the `TGeoMaterial::SetIndex()` method, however it is not; recommended while using the geometry package interfaced with a transport; MC. Radiation and absorption lengths can be set using:. ~~~{.cpp}; TGeoMaterial::SetRadLen(Double_t radlen, Double_t intlen);; ~~~. - `radlen:` radiation length. If `radlen<=0` the value is computed; using GSMATE algorithm in GEANT3; - `intlen:` absorption length. Material state, temperature and pressure can be changed via setters.; Another material property is transparency. It can be defined and used; while viewing the geometry with OpenGL. ~~~{.cpp}; void SetTransparency (Char_t transparency = 0); ~~~. - `transparency:` between 0 (opaque default) to 100 (fully; transparent). One can attach to a material a user-defined object storing Cerenkov; properties. Another hook for material shading properties is currently; not in use. Mixtures are materials made of several elements. They are; represented by the class TGeoMixture, deriving from; TGeoMaterial and defined by their number of components and the; density:. ",MatchSource.DOCS,geom/geom/doc/materials.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md:4567,Integrability,interface,interfaces,4567," density:. ~~~{.cpp}; TGeoMixture(const char *name,Int_t nel,Double_t rho);; ~~~. Elements have to be further defined one by one:. ~~~{.cpp}; void TGeoMixture::DefineElement(Int_t iel,Double_t a,Double_t z,; Double_t weigth);; void TGeoMixture::DefineElement(Int_t iel, TGeoElement *elem,; Double_t weight);; void TGeoMixture::DefineElement(Int_t iel, Int_t z, Int_t natoms);; ~~~. or:. ~~~{.cpp}; void AddElement(TGeoMaterial* mat, Double_t weight);; void AddElement(TGeoElement* elem, Double_t weight);; void AddElement(TGeoElement* elem, Int_t natoms);; void AddElement(Double_t a, Double_t z, Double_t weight); ~~~. - `iel:` index of the element` [0,nel-1]`; - `a` and `z:` the atomic mass and charge; - `weight:` proportion by mass of the elements; - `natoms`: number of atoms of the element in the molecule making the; mixture. The radiation length is automatically computed when all elements are; defined. Since tracking MC provide several other ways to create; materials/mixtures, the materials classes are likely to evolve as the; interfaces to these engines are being developed. Generally in the; process of tracking material properties are not enough and more specific; media properties have to be defined. These highly depend on the MC; performing tracking and sometimes allow the definition of different; media properties (e.g. energy or range cuts) for the same material. \anchor GM00b; ### Radionuclides. A new class TGeoElementRN was introduced in this version to; provide support for radioactive nuclides and their decays. A database of; 3162 radionuclides can be loaded on demand via the table of elements; (TGeoElementTable class). One can make then materials/mixtures; based on these radionuclides and use them in a geometry. ~~~{.cpp}; root[] TGeoManager *geom = new TGeoManager(""geom"",""radionuclides"");; root[] TGeoElementTable *table = geom->GetElementTable();; root[] TGeoElementRN *c14 = table->GetElementRN(14,6); // A,Z; root[] c14->Print();; 6-C-014 ENDF=60140; A=14; Z=6;",MatchSource.DOCS,geom/geom/doc/materials.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md:4758,Integrability,depend,depend,4758,"ment *elem,; Double_t weight);; void TGeoMixture::DefineElement(Int_t iel, Int_t z, Int_t natoms);; ~~~. or:. ~~~{.cpp}; void AddElement(TGeoMaterial* mat, Double_t weight);; void AddElement(TGeoElement* elem, Double_t weight);; void AddElement(TGeoElement* elem, Int_t natoms);; void AddElement(Double_t a, Double_t z, Double_t weight); ~~~. - `iel:` index of the element` [0,nel-1]`; - `a` and `z:` the atomic mass and charge; - `weight:` proportion by mass of the elements; - `natoms`: number of atoms of the element in the molecule making the; mixture. The radiation length is automatically computed when all elements are; defined. Since tracking MC provide several other ways to create; materials/mixtures, the materials classes are likely to evolve as the; interfaces to these engines are being developed. Generally in the; process of tracking material properties are not enough and more specific; media properties have to be defined. These highly depend on the MC; performing tracking and sometimes allow the definition of different; media properties (e.g. energy or range cuts) for the same material. \anchor GM00b; ### Radionuclides. A new class TGeoElementRN was introduced in this version to; provide support for radioactive nuclides and their decays. A database of; 3162 radionuclides can be loaded on demand via the table of elements; (TGeoElementTable class). One can make then materials/mixtures; based on these radionuclides and use them in a geometry. ~~~{.cpp}; root[] TGeoManager *geom = new TGeoManager(""geom"",""radionuclides"");; root[] TGeoElementTable *table = geom->GetElementTable();; root[] TGeoElementRN *c14 = table->GetElementRN(14,6); // A,Z; root[] c14->Print();; 6-C-014 ENDF=60140; A=14; Z=6; Iso=0; Level=0[MeV]; Dmass=3.0199[MeV];; Hlife=1.81e+11[s] J/P=0+; Abund=0; Htox=5.8e-10; Itox=5.8e-10; Stat=0; Decay modes:; BetaMinus Diso: 0 BR: 100.000% Qval: 0.1565; ~~~. One can make materials or mixtures from radionuclides:. ~~~{.cpp}; root[] TGeoMaterial *mat = new TGe",MatchSource.DOCS,geom/geom/doc/materials.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md:8045,Integrability,depend,depending,8045,"hould; use the constructor:. ~~~{.cpp}; TGeoMaterial(const char *name, TGeoElement *elem, Double_t density); ~~~. To create a radioactive mixture, one can use radionuclides as well as; stable elements:. ~~~{.cpp}; TGeoMixture(const char *name, Int_t nelements, Double_t density);; TGeoMixture::AddElement(TGeoElement *elem,; Double_t weight_fraction);; ~~~. Once defined, one can retrieve the time evolution for the radioactive; materials/mixtures by using one of the next two methods:. #### Method 1. ~~~{.cpp}; TGeoMaterial::FillMaterialEvolution(TObjArray *population, Double_t precision=0.001); ~~~. To use this method, one has to provide an empty TObjArray object; that will be filled with all elements coming from the decay chain of the; initial radionuclides contained by the material/mixture. The precision; represent the cumulative branching ratio for which decay products are; still considered. \image html geometry003.png width=600px. The population list may contain stable elements as well as; radionuclides, depending on the initial elements. To test if an element; is a radionuclide:. ~~~{.cpp}; Bool_t TGeoElement::IsRadioNuclide() const; ~~~. All radionuclides in the output population list have attached objects; that represent the time evolution of their fraction of nuclei with; respect to the top radionuclide in the decay chain. These objects; (Bateman solutions) can be retrieved and drawn:. ~~~{.cpp}; TGeoBatemanSol *TGeoElementRN::Ratio();; void TGeoBatemanSol::Draw();; ~~~. #### Method 2. Another method allows to create the evolution of a given radioactive; material/mixture at a given moment in time:. ~~~{.cpp}; TGeoMaterial::DecayMaterial(Double_t time, Double_t precision=0.001); ~~~. The method will create the mixture that result from the decay of a; initial material/mixture at time, while all resulting elements having a; fractional weight less than precision are excluded. A demo macro for radioactive material features is; `$ROOTSYS/tutorials/geom/RadioNuclides.",MatchSource.DOCS,geom/geom/doc/materials.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md:9897,Integrability,interface,interface,9897,"ethod 2. Another method allows to create the evolution of a given radioactive; material/mixture at a given moment in time:. ~~~{.cpp}; TGeoMaterial::DecayMaterial(Double_t time, Double_t precision=0.001); ~~~. The method will create the mixture that result from the decay of a; initial material/mixture at time, while all resulting elements having a; fractional weight less than precision are excluded. A demo macro for radioactive material features is; `$ROOTSYS/tutorials/geom/RadioNuclides.C` It demonstrates also the decay; of a mixture made of radionuclides. \image html geometry004.png width=600px. \anchor GM00c; ### Tracking Media. The class TGeoMedium describes tracking media properties. This has; a pointer to a material and the additional data members representing the; properties related to tracking. ~~~{.cpp}; TGeoMedium(const char *name,Int_t numed,TGeoMaterial *mat,; Double_t *params=0);; ~~~. - `name:` name assigned to the medium; - `mat:` pointer to a material; - `params:` array of additional parameters. Another constructor allows effectively defining tracking parameters in; GEANT3 style:. ~~~{.cpp}; TGeoMedium(const char *name,Int_t numed,Int_t imat,Int_t ifield,; Double_t fieldm,Double_t tmaxfd,Double_t stemax,; Double_t deemax,Double_t epsil,Double_t stmin);; ~~~. This constructor is reserved for creating tracking media from the VMC; interface [...]:. - `numed:` user-defined medium index; - `imat:` unique ID of the material; - `others:` see G3 documentation. Looking at our simple world example, one can see that for creating; volumes one needs to create tracking media before. The way to proceed; for those not interested in performing tracking with external MC's is to; define and use only one `dummy tracking medium` as in the example (or a; `NULL` pointer). \anchor GM00d; ### User Interface for Handling Materials and Media. The TGeoManager class contains the API for accessing and handling; defined materials:. ~~~{.cpp}; TGeoManager::GetMaterial(name);; ~~~. ",MatchSource.DOCS,geom/geom/doc/materials.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md:4552,Modifiability,evolve,evolve,4552," density:. ~~~{.cpp}; TGeoMixture(const char *name,Int_t nel,Double_t rho);; ~~~. Elements have to be further defined one by one:. ~~~{.cpp}; void TGeoMixture::DefineElement(Int_t iel,Double_t a,Double_t z,; Double_t weigth);; void TGeoMixture::DefineElement(Int_t iel, TGeoElement *elem,; Double_t weight);; void TGeoMixture::DefineElement(Int_t iel, Int_t z, Int_t natoms);; ~~~. or:. ~~~{.cpp}; void AddElement(TGeoMaterial* mat, Double_t weight);; void AddElement(TGeoElement* elem, Double_t weight);; void AddElement(TGeoElement* elem, Int_t natoms);; void AddElement(Double_t a, Double_t z, Double_t weight); ~~~. - `iel:` index of the element` [0,nel-1]`; - `a` and `z:` the atomic mass and charge; - `weight:` proportion by mass of the elements; - `natoms`: number of atoms of the element in the molecule making the; mixture. The radiation length is automatically computed when all elements are; defined. Since tracking MC provide several other ways to create; materials/mixtures, the materials classes are likely to evolve as the; interfaces to these engines are being developed. Generally in the; process of tracking material properties are not enough and more specific; media properties have to be defined. These highly depend on the MC; performing tracking and sometimes allow the definition of different; media properties (e.g. energy or range cuts) for the same material. \anchor GM00b; ### Radionuclides. A new class TGeoElementRN was introduced in this version to; provide support for radioactive nuclides and their decays. A database of; 3162 radionuclides can be loaded on demand via the table of elements; (TGeoElementTable class). One can make then materials/mixtures; based on these radionuclides and use them in a geometry. ~~~{.cpp}; root[] TGeoManager *geom = new TGeoManager(""geom"",""radionuclides"");; root[] TGeoElementTable *table = geom->GetElementTable();; root[] TGeoElementRN *c14 = table->GetElementRN(14,6); // A,Z; root[] c14->Print();; 6-C-014 ENDF=60140; A=14; Z=6;",MatchSource.DOCS,geom/geom/doc/materials.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md:4776,Performance,perform,performing,4776,"ment *elem,; Double_t weight);; void TGeoMixture::DefineElement(Int_t iel, Int_t z, Int_t natoms);; ~~~. or:. ~~~{.cpp}; void AddElement(TGeoMaterial* mat, Double_t weight);; void AddElement(TGeoElement* elem, Double_t weight);; void AddElement(TGeoElement* elem, Int_t natoms);; void AddElement(Double_t a, Double_t z, Double_t weight); ~~~. - `iel:` index of the element` [0,nel-1]`; - `a` and `z:` the atomic mass and charge; - `weight:` proportion by mass of the elements; - `natoms`: number of atoms of the element in the molecule making the; mixture. The radiation length is automatically computed when all elements are; defined. Since tracking MC provide several other ways to create; materials/mixtures, the materials classes are likely to evolve as the; interfaces to these engines are being developed. Generally in the; process of tracking material properties are not enough and more specific; media properties have to be defined. These highly depend on the MC; performing tracking and sometimes allow the definition of different; media properties (e.g. energy or range cuts) for the same material. \anchor GM00b; ### Radionuclides. A new class TGeoElementRN was introduced in this version to; provide support for radioactive nuclides and their decays. A database of; 3162 radionuclides can be loaded on demand via the table of elements; (TGeoElementTable class). One can make then materials/mixtures; based on these radionuclides and use them in a geometry. ~~~{.cpp}; root[] TGeoManager *geom = new TGeoManager(""geom"",""radionuclides"");; root[] TGeoElementTable *table = geom->GetElementTable();; root[] TGeoElementRN *c14 = table->GetElementRN(14,6); // A,Z; root[] c14->Print();; 6-C-014 ENDF=60140; A=14; Z=6; Iso=0; Level=0[MeV]; Dmass=3.0199[MeV];; Hlife=1.81e+11[s] J/P=0+; Abund=0; Htox=5.8e-10; Itox=5.8e-10; Stat=0; Decay modes:; BetaMinus Diso: 0 BR: 100.000% Qval: 0.1565; ~~~. One can make materials or mixtures from radionuclides:. ~~~{.cpp}; root[] TGeoMaterial *mat = new TGe",MatchSource.DOCS,geom/geom/doc/materials.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md:5108,Performance,load,loaded,5108,"z, Double_t weight); ~~~. - `iel:` index of the element` [0,nel-1]`; - `a` and `z:` the atomic mass and charge; - `weight:` proportion by mass of the elements; - `natoms`: number of atoms of the element in the molecule making the; mixture. The radiation length is automatically computed when all elements are; defined. Since tracking MC provide several other ways to create; materials/mixtures, the materials classes are likely to evolve as the; interfaces to these engines are being developed. Generally in the; process of tracking material properties are not enough and more specific; media properties have to be defined. These highly depend on the MC; performing tracking and sometimes allow the definition of different; media properties (e.g. energy or range cuts) for the same material. \anchor GM00b; ### Radionuclides. A new class TGeoElementRN was introduced in this version to; provide support for radioactive nuclides and their decays. A database of; 3162 radionuclides can be loaded on demand via the table of elements; (TGeoElementTable class). One can make then materials/mixtures; based on these radionuclides and use them in a geometry. ~~~{.cpp}; root[] TGeoManager *geom = new TGeoManager(""geom"",""radionuclides"");; root[] TGeoElementTable *table = geom->GetElementTable();; root[] TGeoElementRN *c14 = table->GetElementRN(14,6); // A,Z; root[] c14->Print();; 6-C-014 ENDF=60140; A=14; Z=6; Iso=0; Level=0[MeV]; Dmass=3.0199[MeV];; Hlife=1.81e+11[s] J/P=0+; Abund=0; Htox=5.8e-10; Itox=5.8e-10; Stat=0; Decay modes:; BetaMinus Diso: 0 BR: 100.000% Qval: 0.1565; ~~~. One can make materials or mixtures from radionuclides:. ~~~{.cpp}; root[] TGeoMaterial *mat = new TGeoMaterial(""C14"", c14, 2.0);; ~~~. The following properties of radionuclides can be currently accessed via; getters in the TGeoElementRN class:. Atomic number and charge (from the base class TGeoElement). - Isomeric number (`ISO`); - ENDF code - following the convention: `ENDF=10000*Z+100*A+ISO`; - Isomeric energy le",MatchSource.DOCS,geom/geom/doc/materials.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md:10191,Performance,perform,performing,10191,"ethod 2. Another method allows to create the evolution of a given radioactive; material/mixture at a given moment in time:. ~~~{.cpp}; TGeoMaterial::DecayMaterial(Double_t time, Double_t precision=0.001); ~~~. The method will create the mixture that result from the decay of a; initial material/mixture at time, while all resulting elements having a; fractional weight less than precision are excluded. A demo macro for radioactive material features is; `$ROOTSYS/tutorials/geom/RadioNuclides.C` It demonstrates also the decay; of a mixture made of radionuclides. \image html geometry004.png width=600px. \anchor GM00c; ### Tracking Media. The class TGeoMedium describes tracking media properties. This has; a pointer to a material and the additional data members representing the; properties related to tracking. ~~~{.cpp}; TGeoMedium(const char *name,Int_t numed,TGeoMaterial *mat,; Double_t *params=0);; ~~~. - `name:` name assigned to the medium; - `mat:` pointer to a material; - `params:` array of additional parameters. Another constructor allows effectively defining tracking parameters in; GEANT3 style:. ~~~{.cpp}; TGeoMedium(const char *name,Int_t numed,Int_t imat,Int_t ifield,; Double_t fieldm,Double_t tmaxfd,Double_t stemax,; Double_t deemax,Double_t epsil,Double_t stmin);; ~~~. This constructor is reserved for creating tracking media from the VMC; interface [...]:. - `numed:` user-defined medium index; - `imat:` unique ID of the material; - `others:` see G3 documentation. Looking at our simple world example, one can see that for creating; volumes one needs to create tracking media before. The way to proceed; for those not interested in performing tracking with external MC's is to; define and use only one `dummy tracking medium` as in the example (or a; `NULL` pointer). \anchor GM00d; ### User Interface for Handling Materials and Media. The TGeoManager class contains the API for accessing and handling; defined materials:. ~~~{.cpp}; TGeoManager::GetMaterial(name);; ~~~. ",MatchSource.DOCS,geom/geom/doc/materials.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md:5898,Security,access,accessed,5898," the same material. \anchor GM00b; ### Radionuclides. A new class TGeoElementRN was introduced in this version to; provide support for radioactive nuclides and their decays. A database of; 3162 radionuclides can be loaded on demand via the table of elements; (TGeoElementTable class). One can make then materials/mixtures; based on these radionuclides and use them in a geometry. ~~~{.cpp}; root[] TGeoManager *geom = new TGeoManager(""geom"",""radionuclides"");; root[] TGeoElementTable *table = geom->GetElementTable();; root[] TGeoElementRN *c14 = table->GetElementRN(14,6); // A,Z; root[] c14->Print();; 6-C-014 ENDF=60140; A=14; Z=6; Iso=0; Level=0[MeV]; Dmass=3.0199[MeV];; Hlife=1.81e+11[s] J/P=0+; Abund=0; Htox=5.8e-10; Itox=5.8e-10; Stat=0; Decay modes:; BetaMinus Diso: 0 BR: 100.000% Qval: 0.1565; ~~~. One can make materials or mixtures from radionuclides:. ~~~{.cpp}; root[] TGeoMaterial *mat = new TGeoMaterial(""C14"", c14, 2.0);; ~~~. The following properties of radionuclides can be currently accessed via; getters in the TGeoElementRN class:. Atomic number and charge (from the base class TGeoElement). - Isomeric number (`ISO`); - ENDF code - following the convention: `ENDF=10000*Z+100*A+ISO`; - Isomeric energy level [`MeV`]; - Mass excess [`MeV`]; - Half life [`s`]; - Spin/Parity - can be retrieved with: `TGeoElementRN::GetTitle()`; - Hynalation and ingestion toxicities; - List of decays - `TGeoElementRN::GetDecays()`. The radioactive decays of a radionuclide are represented by the class; TGeoDecayChannel and they are stored in a TObjArray. Decay; provides:. - Decay mode; - Variation of isomeric number; - `Q` value for the decay [`GeV`]; - Parent element; - Daughter element. Radionuclides are linked one to each other via their decays, until the; last element in the decay chain which must be stable. One can iterate; decay chains using the iterator TGeoElemIter:. ~~~{.cpp}; root[] TGeoElemIter next(c14);; root[] TGeoElementRN *elem;; root[] while ((elem=next())) next.Pri",MatchSource.DOCS,geom/geom/doc/materials.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md:10438,Security,access,accessing,10438,"ethod 2. Another method allows to create the evolution of a given radioactive; material/mixture at a given moment in time:. ~~~{.cpp}; TGeoMaterial::DecayMaterial(Double_t time, Double_t precision=0.001); ~~~. The method will create the mixture that result from the decay of a; initial material/mixture at time, while all resulting elements having a; fractional weight less than precision are excluded. A demo macro for radioactive material features is; `$ROOTSYS/tutorials/geom/RadioNuclides.C` It demonstrates also the decay; of a mixture made of radionuclides. \image html geometry004.png width=600px. \anchor GM00c; ### Tracking Media. The class TGeoMedium describes tracking media properties. This has; a pointer to a material and the additional data members representing the; properties related to tracking. ~~~{.cpp}; TGeoMedium(const char *name,Int_t numed,TGeoMaterial *mat,; Double_t *params=0);; ~~~. - `name:` name assigned to the medium; - `mat:` pointer to a material; - `params:` array of additional parameters. Another constructor allows effectively defining tracking parameters in; GEANT3 style:. ~~~{.cpp}; TGeoMedium(const char *name,Int_t numed,Int_t imat,Int_t ifield,; Double_t fieldm,Double_t tmaxfd,Double_t stemax,; Double_t deemax,Double_t epsil,Double_t stmin);; ~~~. This constructor is reserved for creating tracking media from the VMC; interface [...]:. - `numed:` user-defined medium index; - `imat:` unique ID of the material; - `others:` see G3 documentation. Looking at our simple world example, one can see that for creating; volumes one needs to create tracking media before. The way to proceed; for those not interested in performing tracking with external MC's is to; define and use only one `dummy tracking medium` as in the example (or a; `NULL` pointer). \anchor GM00d; ### User Interface for Handling Materials and Media. The TGeoManager class contains the API for accessing and handling; defined materials:. ~~~{.cpp}; TGeoManager::GetMaterial(name);; ~~~. ",MatchSource.DOCS,geom/geom/doc/materials.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md:8083,Testability,test,test,8083,"lement *elem, Double_t density); ~~~. To create a radioactive mixture, one can use radionuclides as well as; stable elements:. ~~~{.cpp}; TGeoMixture(const char *name, Int_t nelements, Double_t density);; TGeoMixture::AddElement(TGeoElement *elem,; Double_t weight_fraction);; ~~~. Once defined, one can retrieve the time evolution for the radioactive; materials/mixtures by using one of the next two methods:. #### Method 1. ~~~{.cpp}; TGeoMaterial::FillMaterialEvolution(TObjArray *population, Double_t precision=0.001); ~~~. To use this method, one has to provide an empty TObjArray object; that will be filled with all elements coming from the decay chain of the; initial radionuclides contained by the material/mixture. The precision; represent the cumulative branching ratio for which decay products are; still considered. \image html geometry003.png width=600px. The population list may contain stable elements as well as; radionuclides, depending on the initial elements. To test if an element; is a radionuclide:. ~~~{.cpp}; Bool_t TGeoElement::IsRadioNuclide() const; ~~~. All radionuclides in the output population list have attached objects; that represent the time evolution of their fraction of nuclei with; respect to the top radionuclide in the decay chain. These objects; (Bateman solutions) can be retrieved and drawn:. ~~~{.cpp}; TGeoBatemanSol *TGeoElementRN::Ratio();; void TGeoBatemanSol::Draw();; ~~~. #### Method 2. Another method allows to create the evolution of a given radioactive; material/mixture at a given moment in time:. ~~~{.cpp}; TGeoMaterial::DecayMaterial(Double_t time, Double_t precision=0.001); ~~~. The method will create the mixture that result from the decay of a; initial material/mixture at time, while all resulting elements having a; fractional weight less than precision are excluded. A demo macro for radioactive material features is; `$ROOTSYS/tutorials/geom/RadioNuclides.C` It demonstrates also the decay; of a mixture made of radionuclides. \image",MatchSource.DOCS,geom/geom/doc/materials.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md:10039,Usability,simpl,simple,10039,"ethod 2. Another method allows to create the evolution of a given radioactive; material/mixture at a given moment in time:. ~~~{.cpp}; TGeoMaterial::DecayMaterial(Double_t time, Double_t precision=0.001); ~~~. The method will create the mixture that result from the decay of a; initial material/mixture at time, while all resulting elements having a; fractional weight less than precision are excluded. A demo macro for radioactive material features is; `$ROOTSYS/tutorials/geom/RadioNuclides.C` It demonstrates also the decay; of a mixture made of radionuclides. \image html geometry004.png width=600px. \anchor GM00c; ### Tracking Media. The class TGeoMedium describes tracking media properties. This has; a pointer to a material and the additional data members representing the; properties related to tracking. ~~~{.cpp}; TGeoMedium(const char *name,Int_t numed,TGeoMaterial *mat,; Double_t *params=0);; ~~~. - `name:` name assigned to the medium; - `mat:` pointer to a material; - `params:` array of additional parameters. Another constructor allows effectively defining tracking parameters in; GEANT3 style:. ~~~{.cpp}; TGeoMedium(const char *name,Int_t numed,Int_t imat,Int_t ifield,; Double_t fieldm,Double_t tmaxfd,Double_t stemax,; Double_t deemax,Double_t epsil,Double_t stmin);; ~~~. This constructor is reserved for creating tracking media from the VMC; interface [...]:. - `numed:` user-defined medium index; - `imat:` unique ID of the material; - `others:` see G3 documentation. Looking at our simple world example, one can see that for creating; volumes one needs to create tracking media before. The way to proceed; for those not interested in performing tracking with external MC's is to; define and use only one `dummy tracking medium` as in the example (or a; `NULL` pointer). \anchor GM00d; ### User Interface for Handling Materials and Media. The TGeoManager class contains the API for accessing and handling; defined materials:. ~~~{.cpp}; TGeoManager::GetMaterial(name);; ~~~. ",MatchSource.DOCS,geom/geom/doc/materials.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/shapes.md:10027,Availability,error,error,10027,"tive first 4 letters of the corresponding class name; (e.g. ""`tubs`"" will match **`TGeoTubeSeg`**, ""`bbox`"" will match; **`TGeoBBox`**); - `nmed:` the medium number. This will create a special volume that will not be directly used in the; geometry, but whenever positioned will require a list of actual; parameters for the current shape that will be created in this process.; Such volumes having shape parameters known only when used have to be; positioned only with **`TGeoManager::Node()` method (see ‘Creating and; Positioning Volumes').**. Other case when shape parameterizations are quite useful is scaling; geometry structures. Imagine that we would like to enlarge/shrink a; detector structure on one or more axes. This happens quite often in real; life and is handled by ""fitting mother"" parameters. This is accomplished; by defining shapes with one or more invalid (negative) parameters. For; instance, defining a box having `dx=10.`, `dy=10.`, and `dz=-1` will not; generate an error but will be interpreted in a different way: A special; volume **`TGeoVolumeMulti`** will be created. Whenever positioned inside; a mother volume, this will create a normal **`TGeoVolume`** object; having as shape a box with `dz` fitting the corresponding `dz `of the; mother shape. Generally, this type of parameterization is used when; positioning volumes in containers having a matching shape, but it works; also for most reasonable combinations. \defgroup Tubes Tubes; \ingroup Shapes_classes; Tubes have Z as their symmetry axis. \defgroup Cones Cones; \ingroup Shapes_classes; Conical tube classes. \defgroup Trapezoids Trapezoids; \ingroup Shapes_classes; In general, we will call trapezoidal shapes having 8 vertices and up to; 6 trapezoid faces. Besides that, two of the opposite faces are parallel; to XY plane and are positioned at ` dZ`. Since general trapezoids are; seldom used in detector geometry descriptions, there are several; primitives implemented in the modeller for particular cases. ",MatchSource.DOCS,geom/geom/doc/shapes.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/shapes.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/shapes.md:1953,Modifiability,inherit,inheritance,1953,"tor to the crossed shape; surface, given a starting local point and an ongoing direction. All the features above are globally managed by the modeller in order to; provide navigation functionality. In addition to those, shapes have also; to implement additional specific abstract methods:. - Computation of the minimal box bounding the shape, given that this; box have to be aligned with the local coordinates;; - Algorithms for dividing the shape along a given axis. The modeller currently provides a set of 20 basic shapes, which we will; call `primitives`. It also provides a special class allowing the; creation of shapes as a result of Boolean operations between primitives.; These are called `composite shapes` and the composition operation can be; recursive (combined composites). This allows the creation of a quite; large number of different shape topologies and combinations. You can; have a look and run the tutorial: geodemo.C. \image html geom_primitive_shapes.png Primitive Shapes - the general inheritance scheme. Shapes are named objects and all primitives have constructors like:. ~~~ {.cpp}; TGeoXXX(const char *name,<type> param1,<type> param2, ...);; TGeoXXX(<type> param1,<type> param2, ...);; ~~~. Naming shape primitive is mandatory only for the primitives used in; Boolean composites (see ""Composite Shapes""). For the sake of simplicity,; we will describe only the constructors in the second form. \anchor SHAPES01; ### Primitive Shapes. - Boxes: TGeoBBox class; - Parallelepiped: TGeoPara class; - Trapezoids: TGeoTrd1, TGeoTrd2 classes; - General Trapezoid: TGeoTrap class; - Twisted Trapezoid: TGeoGtra class; - Arbitrary 8 vertices shapes: TGeoArb8 class; - Tubes: TGeoTube class; - Tube Segments: TGeoTubeSeg class; - Cut Tubes: TGeoCtub class; - Elliptical Tubes: TGeoEltu class; - Hyperboloids: TGeoHype class; - Cones: TGeoCone class; - Cone Segments: TGeoConeSeg class; - Sphere: TGeoSphere class; - Torus: TGeoTorus class; - Paraboloid: TGeoParaboloid class; - Polyco",MatchSource.DOCS,geom/geom/doc/shapes.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/shapes.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/shapes.md:8487,Modifiability,parameteriz,parameterizations,8487,"`Rxy`, `Phi`, `Rxyz`. A given shape cannot be divided; however on any axis. The general rule is that that divisions are; possible on whatever axis that produces still known shapes as slices.; The division of shapes are performed by the call `TGeoShape::Divide()`,; but this operation can be done only via `TGeoVolume::Divide()` method.; In other words, the algorithm for dividing a specific shape is known by; the shape object, but is always invoked in a generic way from the volume; level. Details on how to do that can be found in the paragraph ‘Dividing; volumes'. One can see how all division options are interpreted and which; their result inside specific shape classes is. \anchor SHAPES05; ### Parametric Shapes. Shapes generally have a set of parameters that is well defined at build; time. In fact, when the final geometrical hierarchy is assembled and the; geometry is closed, all constituent shapes `MUST`**have well defined and; valid parameters. In order to ease-up geometry creation, some; parameterizations are however allowed. For instance let's suppose that we need to define several volumes having; exactly the same properties but different sizes. A way to do this would; be to create as many different volumes and shapes. The modeller allows; however the definition of a single volume having undefined shape; parameters. ~~~ {.cpp}; TGeoManager::Volume(const char *name,const char *shape,Int_t nmed);; ~~~. - `name:` the name of the newly created volume;; - `shape:`the type of the associated shape. This has to contain the; case-insensitive first 4 letters of the corresponding class name; (e.g. ""`tubs`"" will match **`TGeoTubeSeg`**, ""`bbox`"" will match; **`TGeoBBox`**); - `nmed:` the medium number. This will create a special volume that will not be directly used in the; geometry, but whenever positioned will require a list of actual; parameters for the current shape that will be created in this process.; Such volumes having shape parameters known only when used have to be",MatchSource.DOCS,geom/geom/doc/shapes.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/shapes.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/shapes.md:9605,Modifiability,parameteriz,parameterizations,9605," but different sizes. A way to do this would; be to create as many different volumes and shapes. The modeller allows; however the definition of a single volume having undefined shape; parameters. ~~~ {.cpp}; TGeoManager::Volume(const char *name,const char *shape,Int_t nmed);; ~~~. - `name:` the name of the newly created volume;; - `shape:`the type of the associated shape. This has to contain the; case-insensitive first 4 letters of the corresponding class name; (e.g. ""`tubs`"" will match **`TGeoTubeSeg`**, ""`bbox`"" will match; **`TGeoBBox`**); - `nmed:` the medium number. This will create a special volume that will not be directly used in the; geometry, but whenever positioned will require a list of actual; parameters for the current shape that will be created in this process.; Such volumes having shape parameters known only when used have to be; positioned only with **`TGeoManager::Node()` method (see ‘Creating and; Positioning Volumes').**. Other case when shape parameterizations are quite useful is scaling; geometry structures. Imagine that we would like to enlarge/shrink a; detector structure on one or more axes. This happens quite often in real; life and is handled by ""fitting mother"" parameters. This is accomplished; by defining shapes with one or more invalid (negative) parameters. For; instance, defining a box having `dx=10.`, `dy=10.`, and `dz=-1` will not; generate an error but will be interpreted in a different way: A special; volume **`TGeoVolumeMulti`** will be created. Whenever positioned inside; a mother volume, this will create a normal **`TGeoVolume`** object; having as shape a box with `dz` fitting the corresponding `dz `of the; mother shape. Generally, this type of parameterization is used when; positioning volumes in containers having a matching shape, but it works; also for most reasonable combinations. \defgroup Tubes Tubes; \ingroup Shapes_classes; Tubes have Z as their symmetry axis. \defgroup Cones Cones; \ingroup Shapes_classes; Conical tube",MatchSource.DOCS,geom/geom/doc/shapes.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/shapes.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/shapes.md:10339,Modifiability,parameteriz,parameterization,10339,"tive first 4 letters of the corresponding class name; (e.g. ""`tubs`"" will match **`TGeoTubeSeg`**, ""`bbox`"" will match; **`TGeoBBox`**); - `nmed:` the medium number. This will create a special volume that will not be directly used in the; geometry, but whenever positioned will require a list of actual; parameters for the current shape that will be created in this process.; Such volumes having shape parameters known only when used have to be; positioned only with **`TGeoManager::Node()` method (see ‘Creating and; Positioning Volumes').**. Other case when shape parameterizations are quite useful is scaling; geometry structures. Imagine that we would like to enlarge/shrink a; detector structure on one or more axes. This happens quite often in real; life and is handled by ""fitting mother"" parameters. This is accomplished; by defining shapes with one or more invalid (negative) parameters. For; instance, defining a box having `dx=10.`, `dy=10.`, and `dz=-1` will not; generate an error but will be interpreted in a different way: A special; volume **`TGeoVolumeMulti`** will be created. Whenever positioned inside; a mother volume, this will create a normal **`TGeoVolume`** object; having as shape a box with `dz` fitting the corresponding `dz `of the; mother shape. Generally, this type of parameterization is used when; positioning volumes in containers having a matching shape, but it works; also for most reasonable combinations. \defgroup Tubes Tubes; \ingroup Shapes_classes; Tubes have Z as their symmetry axis. \defgroup Cones Cones; \ingroup Shapes_classes; Conical tube classes. \defgroup Trapezoids Trapezoids; \ingroup Shapes_classes; In general, we will call trapezoidal shapes having 8 vertices and up to; 6 trapezoid faces. Besides that, two of the opposite faces are parallel; to XY plane and are positioned at ` dZ`. Since general trapezoids are; seldom used in detector geometry descriptions, there are several; primitives implemented in the modeller for particular cases. ",MatchSource.DOCS,geom/geom/doc/shapes.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/shapes.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/shapes.md:3790,Performance,perform,performed,3790,"egments: TGeoConeSeg class; - Sphere: TGeoSphere class; - Torus: TGeoTorus class; - Paraboloid: TGeoParaboloid class; - Polycone: TGeoPcon class; - Polygon: TGeoPgon class; - Polygonal extrusion: TGeoXtru class; - Half Spaces: TGeoHalfSpace class; - Composite Shapes: TGeoCompositeShape class. \anchor SHAPES02; ### Navigation Methods Performed By Shapes. Shapes are named objects and register themselves to the `manager class`; at creation time. This is responsible for their final deletion. Shapes; can be created without name if their retrieval by name is no needed.; Generally shapes are objects that are useful only at geometry creation; stage. The pointer to a shape is in fact needed only when referring to a; given volume and it is always accessible at that level. Several volumes; may reference a single shape; therefore its deletion is not possible; once volumes were defined based on it. The navigation features related for instance to tracking particles are; performed in the following way: Each shape implement its specific; algorithms for all required tasks in its local reference system. Note; that the manager class handles global queries related to geometry.; However, shape-related queries might be sometimes useful:. ~~~ {.cpp}; Bool_t TGeoShape::Contains(Double_t *point[3]);; ~~~. The method above returns `kTRUE` if the point \*point is actually inside; the shape. The point has to be defined in the local shape reference. For; instance, for a box having `DX,DY` and `DZ `half-lengths a point will be; considered inside if:. `-DX <= point[0] <= DX`. `-DY <= point[1] <= DY`. `-DZ <= point[2] <= DZ`. ~~~ {.cpp}; Double_t TGeoShape::DistFromInside(Double_t *point[3],; Double_t *dir[3], Int_t iact,Double_t step,Double_t *safe);; ~~~. The method computes the distance to exiting a shape from a given point; `inside`, along a given direction. This direction is given by its; director cosines with respect to the local shape coordinate system. This; method provides additional info",MatchSource.DOCS,geom/geom/doc/shapes.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/shapes.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/shapes.md:7702,Performance,perform,performed,7702,"an be created; stand-alone:. ~~~ {.cpp}; TGeoBBox *box = new TGeoBBox(""s_box"",halfX,halfY,halfZ); // named; TGeoTube *tub = new TGeoTube(rmin,rmax,halfZ); // no name; //... (See all specific shape constructors); ~~~. Sometimes it is much easier to create a volume having a given shape in; one step, since shapes are not directly linked in the geometrical tree; but volumes are:. ~~~ {.cpp}; TGeoVolume *vol_box = gGeoManager->MakeBox(""BOX_VOL"",pmed,halfX,; halfY,halfZ);; TGeoVolume *vol_tub = gGeoManager->MakeTube(""TUB_VOL"",pmed,rmin,; rmax,halfZ);; // ...(See MakeXXX() utilities in TGeoManager class); ~~~. \anchor SHAPES04; ### Dividing Shapes. Shapes can generally be divided along a given axis. Supported axes are:; `X`, `Y`, `Z`, `Rxy`, `Phi`, `Rxyz`. A given shape cannot be divided; however on any axis. The general rule is that that divisions are; possible on whatever axis that produces still known shapes as slices.; The division of shapes are performed by the call `TGeoShape::Divide()`,; but this operation can be done only via `TGeoVolume::Divide()` method.; In other words, the algorithm for dividing a specific shape is known by; the shape object, but is always invoked in a generic way from the volume; level. Details on how to do that can be found in the paragraph ‘Dividing; volumes'. One can see how all division options are interpreted and which; their result inside specific shape classes is. \anchor SHAPES05; ### Parametric Shapes. Shapes generally have a set of parameters that is well defined at build; time. In fact, when the final geometrical hierarchy is assembled and the; geometry is closed, all constituent shapes `MUST`**have well defined and; valid parameters. In order to ease-up geometry creation, some; parameterizations are however allowed. For instance let's suppose that we need to define several volumes having; exactly the same properties but different sizes. A way to do this would; be to create as many different volumes and shapes. The modeller allows; h",MatchSource.DOCS,geom/geom/doc/shapes.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/shapes.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/shapes.md:886,Safety,safe,safe,886,"\defgroup Shapes_classes Shapes; \ingroup Geometry; \brief Shapes are geometrical objects that provide the basic modeling functionality. - [Primitive Shapes](\ref SHAPES01); - [Navigation Methods Performed By Shapes](\ref SHAPES02); - [Creating Shapes](\ref SHAPES03); - [Dividing Shapes](\ref SHAPES04); - [Parametric Shapes](\ref SHAPES05). The ""shapes"" provide the definition of the `local` coordinate; system of the volume. Any volume must have a shape. Any shape recognized; by the modeller has to derive from the base **`TGeoShape`** class,; providing methods for:. - Finding out if a point defined in their local frame is contained or; not by the shape;; - Computing the distance to enter/exit the shape from a local point,; given a known direction;; - Computing the maximum distance in any direction from a local point; that does NOT result in a boundary crossing of the shape (safe; distance);; - Computing the cosines of the normal vector to the crossed shape; surface, given a starting local point and an ongoing direction. All the features above are globally managed by the modeller in order to; provide navigation functionality. In addition to those, shapes have also; to implement additional specific abstract methods:. - Computation of the minimal box bounding the shape, given that this; box have to be aligned with the local coordinates;; - Algorithms for dividing the shape along a given axis. The modeller currently provides a set of 20 basic shapes, which we will; call `primitives`. It also provides a special class allowing the; creation of shapes as a result of Boolean operations between primitives.; These are called `composite shapes` and the composition operation can be; recursive (combined composites). This allows the creation of a quite; large number of different shape topologies and combinations. You can; have a look and run the tutorial: geodemo.C. \image html geom_primitive_shapes.png Primitive Shapes - the general inheritance scheme. Shapes are named objects and",MatchSource.DOCS,geom/geom/doc/shapes.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/shapes.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/shapes.md:4562,Safety,safe,safe,4562,"only when referring to a; given volume and it is always accessible at that level. Several volumes; may reference a single shape; therefore its deletion is not possible; once volumes were defined based on it. The navigation features related for instance to tracking particles are; performed in the following way: Each shape implement its specific; algorithms for all required tasks in its local reference system. Note; that the manager class handles global queries related to geometry.; However, shape-related queries might be sometimes useful:. ~~~ {.cpp}; Bool_t TGeoShape::Contains(Double_t *point[3]);; ~~~. The method above returns `kTRUE` if the point \*point is actually inside; the shape. The point has to be defined in the local shape reference. For; instance, for a box having `DX,DY` and `DZ `half-lengths a point will be; considered inside if:. `-DX <= point[0] <= DX`. `-DY <= point[1] <= DY`. `-DZ <= point[2] <= DZ`. ~~~ {.cpp}; Double_t TGeoShape::DistFromInside(Double_t *point[3],; Double_t *dir[3], Int_t iact,Double_t step,Double_t *safe);; ~~~. The method computes the distance to exiting a shape from a given point; `inside`, along a given direction. This direction is given by its; director cosines with respect to the local shape coordinate system. This; method provides additional information according the value of `iact`; input parameter:. - `iact = 0`computes only safe distance and fill it at the location; given by SAFE;; - `iact = 1`a proposed STEP is supplied. The safe distance is computed; first. If this is bigger than STEP than the proposed step is; approved and returned by the method since it does not cross the; shape boundaries. Otherwise, the distance to exiting the shape is; computed and returned;; - `iact = 2`computes both safe distance and distance to exiting,; ignoring the proposed step;; - `iact > 2`computes only the distance to exiting, ignoring anything; else. ~~~ {.cpp}; Double_t TGeoShape::DistFromOutside(Double_t *point[3],; Double_t *dir[3],Int",MatchSource.DOCS,geom/geom/doc/shapes.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/shapes.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/shapes.md:4902,Safety,safe,safe,4902,"anager class handles global queries related to geometry.; However, shape-related queries might be sometimes useful:. ~~~ {.cpp}; Bool_t TGeoShape::Contains(Double_t *point[3]);; ~~~. The method above returns `kTRUE` if the point \*point is actually inside; the shape. The point has to be defined in the local shape reference. For; instance, for a box having `DX,DY` and `DZ `half-lengths a point will be; considered inside if:. `-DX <= point[0] <= DX`. `-DY <= point[1] <= DY`. `-DZ <= point[2] <= DZ`. ~~~ {.cpp}; Double_t TGeoShape::DistFromInside(Double_t *point[3],; Double_t *dir[3], Int_t iact,Double_t step,Double_t *safe);; ~~~. The method computes the distance to exiting a shape from a given point; `inside`, along a given direction. This direction is given by its; director cosines with respect to the local shape coordinate system. This; method provides additional information according the value of `iact`; input parameter:. - `iact = 0`computes only safe distance and fill it at the location; given by SAFE;; - `iact = 1`a proposed STEP is supplied. The safe distance is computed; first. If this is bigger than STEP than the proposed step is; approved and returned by the method since it does not cross the; shape boundaries. Otherwise, the distance to exiting the shape is; computed and returned;; - `iact = 2`computes both safe distance and distance to exiting,; ignoring the proposed step;; - `iact > 2`computes only the distance to exiting, ignoring anything; else. ~~~ {.cpp}; Double_t TGeoShape::DistFromOutside(Double_t *point[3],; Double_t *dir[3],Int_t iact,Double_t step,Double_t *safe);; ~~~. This method computes the distance to entering a shape from a given point; `outside`. It acts in the same way as the previous method. ~~~ {.cpp}; Double_t TGeoShape::Safety(Double_t *point[3],Bool_t inside);; ~~~. This computes the maximum shift of a point in any direction that does; not change its `inside/outside `state (does not cross shape boundaries).; The state of the point h",MatchSource.DOCS,geom/geom/doc/shapes.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/shapes.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/shapes.md:5006,Safety,safe,safe,5006,"ueries might be sometimes useful:. ~~~ {.cpp}; Bool_t TGeoShape::Contains(Double_t *point[3]);; ~~~. The method above returns `kTRUE` if the point \*point is actually inside; the shape. The point has to be defined in the local shape reference. For; instance, for a box having `DX,DY` and `DZ `half-lengths a point will be; considered inside if:. `-DX <= point[0] <= DX`. `-DY <= point[1] <= DY`. `-DZ <= point[2] <= DZ`. ~~~ {.cpp}; Double_t TGeoShape::DistFromInside(Double_t *point[3],; Double_t *dir[3], Int_t iact,Double_t step,Double_t *safe);; ~~~. The method computes the distance to exiting a shape from a given point; `inside`, along a given direction. This direction is given by its; director cosines with respect to the local shape coordinate system. This; method provides additional information according the value of `iact`; input parameter:. - `iact = 0`computes only safe distance and fill it at the location; given by SAFE;; - `iact = 1`a proposed STEP is supplied. The safe distance is computed; first. If this is bigger than STEP than the proposed step is; approved and returned by the method since it does not cross the; shape boundaries. Otherwise, the distance to exiting the shape is; computed and returned;; - `iact = 2`computes both safe distance and distance to exiting,; ignoring the proposed step;; - `iact > 2`computes only the distance to exiting, ignoring anything; else. ~~~ {.cpp}; Double_t TGeoShape::DistFromOutside(Double_t *point[3],; Double_t *dir[3],Int_t iact,Double_t step,Double_t *safe);; ~~~. This method computes the distance to entering a shape from a given point; `outside`. It acts in the same way as the previous method. ~~~ {.cpp}; Double_t TGeoShape::Safety(Double_t *point[3],Bool_t inside);; ~~~. This computes the maximum shift of a point in any direction that does; not change its `inside/outside `state (does not cross shape boundaries).; The state of the point has to be properly supplied. ~~~ {.cpp}; Double_t *TGeoShape::ComputeNormal(Double_",MatchSource.DOCS,geom/geom/doc/shapes.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/shapes.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/shapes.md:5277,Safety,safe,safe,5277,",DY` and `DZ `half-lengths a point will be; considered inside if:. `-DX <= point[0] <= DX`. `-DY <= point[1] <= DY`. `-DZ <= point[2] <= DZ`. ~~~ {.cpp}; Double_t TGeoShape::DistFromInside(Double_t *point[3],; Double_t *dir[3], Int_t iact,Double_t step,Double_t *safe);; ~~~. The method computes the distance to exiting a shape from a given point; `inside`, along a given direction. This direction is given by its; director cosines with respect to the local shape coordinate system. This; method provides additional information according the value of `iact`; input parameter:. - `iact = 0`computes only safe distance and fill it at the location; given by SAFE;; - `iact = 1`a proposed STEP is supplied. The safe distance is computed; first. If this is bigger than STEP than the proposed step is; approved and returned by the method since it does not cross the; shape boundaries. Otherwise, the distance to exiting the shape is; computed and returned;; - `iact = 2`computes both safe distance and distance to exiting,; ignoring the proposed step;; - `iact > 2`computes only the distance to exiting, ignoring anything; else. ~~~ {.cpp}; Double_t TGeoShape::DistFromOutside(Double_t *point[3],; Double_t *dir[3],Int_t iact,Double_t step,Double_t *safe);; ~~~. This method computes the distance to entering a shape from a given point; `outside`. It acts in the same way as the previous method. ~~~ {.cpp}; Double_t TGeoShape::Safety(Double_t *point[3],Bool_t inside);; ~~~. This computes the maximum shift of a point in any direction that does; not change its `inside/outside `state (does not cross shape boundaries).; The state of the point has to be properly supplied. ~~~ {.cpp}; Double_t *TGeoShape::ComputeNormal(Double_t *point[3],; Double_t *dir[3],Double_t *norm[3]);; ~~~. The method above computes the director cosines of normal to the crossed; shape surface from a given point towards direction. This is filled into; the `norm` array, supplied by the user. The normal vector is always; chosen ",MatchSource.DOCS,geom/geom/doc/shapes.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/shapes.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/shapes.md:5543,Safety,safe,safe,5543,"ble_t *point[3],; Double_t *dir[3], Int_t iact,Double_t step,Double_t *safe);; ~~~. The method computes the distance to exiting a shape from a given point; `inside`, along a given direction. This direction is given by its; director cosines with respect to the local shape coordinate system. This; method provides additional information according the value of `iact`; input parameter:. - `iact = 0`computes only safe distance and fill it at the location; given by SAFE;; - `iact = 1`a proposed STEP is supplied. The safe distance is computed; first. If this is bigger than STEP than the proposed step is; approved and returned by the method since it does not cross the; shape boundaries. Otherwise, the distance to exiting the shape is; computed and returned;; - `iact = 2`computes both safe distance and distance to exiting,; ignoring the proposed step;; - `iact > 2`computes only the distance to exiting, ignoring anything; else. ~~~ {.cpp}; Double_t TGeoShape::DistFromOutside(Double_t *point[3],; Double_t *dir[3],Int_t iact,Double_t step,Double_t *safe);; ~~~. This method computes the distance to entering a shape from a given point; `outside`. It acts in the same way as the previous method. ~~~ {.cpp}; Double_t TGeoShape::Safety(Double_t *point[3],Bool_t inside);; ~~~. This computes the maximum shift of a point in any direction that does; not change its `inside/outside `state (does not cross shape boundaries).; The state of the point has to be properly supplied. ~~~ {.cpp}; Double_t *TGeoShape::ComputeNormal(Double_t *point[3],; Double_t *dir[3],Double_t *norm[3]);; ~~~. The method above computes the director cosines of normal to the crossed; shape surface from a given point towards direction. This is filled into; the `norm` array, supplied by the user. The normal vector is always; chosen such that its dot product with the direction is positive defined. \anchor SHAPES03; ### Creating Shapes. Shape objects embeds only the minimum set of parameters that are fully; describing a val",MatchSource.DOCS,geom/geom/doc/shapes.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/shapes.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/shapes.md:9721,Safety,detect,detector,9721,"shapes. The modeller allows; however the definition of a single volume having undefined shape; parameters. ~~~ {.cpp}; TGeoManager::Volume(const char *name,const char *shape,Int_t nmed);; ~~~. - `name:` the name of the newly created volume;; - `shape:`the type of the associated shape. This has to contain the; case-insensitive first 4 letters of the corresponding class name; (e.g. ""`tubs`"" will match **`TGeoTubeSeg`**, ""`bbox`"" will match; **`TGeoBBox`**); - `nmed:` the medium number. This will create a special volume that will not be directly used in the; geometry, but whenever positioned will require a list of actual; parameters for the current shape that will be created in this process.; Such volumes having shape parameters known only when used have to be; positioned only with **`TGeoManager::Node()` method (see ‘Creating and; Positioning Volumes').**. Other case when shape parameterizations are quite useful is scaling; geometry structures. Imagine that we would like to enlarge/shrink a; detector structure on one or more axes. This happens quite often in real; life and is handled by ""fitting mother"" parameters. This is accomplished; by defining shapes with one or more invalid (negative) parameters. For; instance, defining a box having `dx=10.`, `dy=10.`, and `dz=-1` will not; generate an error but will be interpreted in a different way: A special; volume **`TGeoVolumeMulti`** will be created. Whenever positioned inside; a mother volume, this will create a normal **`TGeoVolume`** object; having as shape a box with `dz` fitting the corresponding `dz `of the; mother shape. Generally, this type of parameterization is used when; positioning volumes in containers having a matching shape, but it works; also for most reasonable combinations. \defgroup Tubes Tubes; \ingroup Shapes_classes; Tubes have Z as their symmetry axis. \defgroup Cones Cones; \ingroup Shapes_classes; Conical tube classes. \defgroup Trapezoids Trapezoids; \ingroup Shapes_classes; In general, we will c",MatchSource.DOCS,geom/geom/doc/shapes.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/shapes.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/shapes.md:10927,Safety,detect,detector,10927,"tive first 4 letters of the corresponding class name; (e.g. ""`tubs`"" will match **`TGeoTubeSeg`**, ""`bbox`"" will match; **`TGeoBBox`**); - `nmed:` the medium number. This will create a special volume that will not be directly used in the; geometry, but whenever positioned will require a list of actual; parameters for the current shape that will be created in this process.; Such volumes having shape parameters known only when used have to be; positioned only with **`TGeoManager::Node()` method (see ‘Creating and; Positioning Volumes').**. Other case when shape parameterizations are quite useful is scaling; geometry structures. Imagine that we would like to enlarge/shrink a; detector structure on one or more axes. This happens quite often in real; life and is handled by ""fitting mother"" parameters. This is accomplished; by defining shapes with one or more invalid (negative) parameters. For; instance, defining a box having `dx=10.`, `dy=10.`, and `dz=-1` will not; generate an error but will be interpreted in a different way: A special; volume **`TGeoVolumeMulti`** will be created. Whenever positioned inside; a mother volume, this will create a normal **`TGeoVolume`** object; having as shape a box with `dz` fitting the corresponding `dz `of the; mother shape. Generally, this type of parameterization is used when; positioning volumes in containers having a matching shape, but it works; also for most reasonable combinations. \defgroup Tubes Tubes; \ingroup Shapes_classes; Tubes have Z as their symmetry axis. \defgroup Cones Cones; \ingroup Shapes_classes; Conical tube classes. \defgroup Trapezoids Trapezoids; \ingroup Shapes_classes; In general, we will call trapezoidal shapes having 8 vertices and up to; 6 trapezoid faces. Besides that, two of the opposite faces are parallel; to XY plane and are positioned at ` dZ`. Since general trapezoids are; seldom used in detector geometry descriptions, there are several; primitives implemented in the modeller for particular cases. ",MatchSource.DOCS,geom/geom/doc/shapes.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/shapes.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/shapes.md:3566,Security,access,accessible,3566,"GeoTrap class; - Twisted Trapezoid: TGeoGtra class; - Arbitrary 8 vertices shapes: TGeoArb8 class; - Tubes: TGeoTube class; - Tube Segments: TGeoTubeSeg class; - Cut Tubes: TGeoCtub class; - Elliptical Tubes: TGeoEltu class; - Hyperboloids: TGeoHype class; - Cones: TGeoCone class; - Cone Segments: TGeoConeSeg class; - Sphere: TGeoSphere class; - Torus: TGeoTorus class; - Paraboloid: TGeoParaboloid class; - Polycone: TGeoPcon class; - Polygon: TGeoPgon class; - Polygonal extrusion: TGeoXtru class; - Half Spaces: TGeoHalfSpace class; - Composite Shapes: TGeoCompositeShape class. \anchor SHAPES02; ### Navigation Methods Performed By Shapes. Shapes are named objects and register themselves to the `manager class`; at creation time. This is responsible for their final deletion. Shapes; can be created without name if their retrieval by name is no needed.; Generally shapes are objects that are useful only at geometry creation; stage. The pointer to a shape is in fact needed only when referring to a; given volume and it is always accessible at that level. Several volumes; may reference a single shape; therefore its deletion is not possible; once volumes were defined based on it. The navigation features related for instance to tracking particles are; performed in the following way: Each shape implement its specific; algorithms for all required tasks in its local reference system. Note; that the manager class handles global queries related to geometry.; However, shape-related queries might be sometimes useful:. ~~~ {.cpp}; Bool_t TGeoShape::Contains(Double_t *point[3]);; ~~~. The method above returns `kTRUE` if the point \*point is actually inside; the shape. The point has to be defined in the local shape reference. For; instance, for a box having `DX,DY` and `DZ `half-lengths a point will be; considered inside if:. `-DX <= point[0] <= DX`. `-DY <= point[1] <= DY`. `-DZ <= point[2] <= DZ`. ~~~ {.cpp}; Double_t TGeoShape::DistFromInside(Double_t *point[3],; Double_t *dir[3], Int",MatchSource.DOCS,geom/geom/doc/shapes.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/shapes.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/shapes.md:2294,Usability,simpl,simplicity,2294,"igned with the local coordinates;; - Algorithms for dividing the shape along a given axis. The modeller currently provides a set of 20 basic shapes, which we will; call `primitives`. It also provides a special class allowing the; creation of shapes as a result of Boolean operations between primitives.; These are called `composite shapes` and the composition operation can be; recursive (combined composites). This allows the creation of a quite; large number of different shape topologies and combinations. You can; have a look and run the tutorial: geodemo.C. \image html geom_primitive_shapes.png Primitive Shapes - the general inheritance scheme. Shapes are named objects and all primitives have constructors like:. ~~~ {.cpp}; TGeoXXX(const char *name,<type> param1,<type> param2, ...);; TGeoXXX(<type> param1,<type> param2, ...);; ~~~. Naming shape primitive is mandatory only for the primitives used in; Boolean composites (see ""Composite Shapes""). For the sake of simplicity,; we will describe only the constructors in the second form. \anchor SHAPES01; ### Primitive Shapes. - Boxes: TGeoBBox class; - Parallelepiped: TGeoPara class; - Trapezoids: TGeoTrd1, TGeoTrd2 classes; - General Trapezoid: TGeoTrap class; - Twisted Trapezoid: TGeoGtra class; - Arbitrary 8 vertices shapes: TGeoArb8 class; - Tubes: TGeoTube class; - Tube Segments: TGeoTubeSeg class; - Cut Tubes: TGeoCtub class; - Elliptical Tubes: TGeoEltu class; - Hyperboloids: TGeoHype class; - Cones: TGeoCone class; - Cone Segments: TGeoConeSeg class; - Sphere: TGeoSphere class; - Torus: TGeoTorus class; - Paraboloid: TGeoParaboloid class; - Polycone: TGeoPcon class; - Polygon: TGeoPgon class; - Polygonal extrusion: TGeoXtru class; - Half Spaces: TGeoHalfSpace class; - Composite Shapes: TGeoCompositeShape class. \anchor SHAPES02; ### Navigation Methods Performed By Shapes. Shapes are named objects and register themselves to the `manager class`; at creation time. This is responsible for their final deletion. Shapes; c",MatchSource.DOCS,geom/geom/doc/shapes.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/shapes.md
https://github.com/root-project/root/tree/v6-32-06/geom/geom/inc/bvh/v2/README.md:25,Integrability,rout,routines,25,"These headers, providing routines to construct and navigate; bounding volume hierarchies, have been copied from https://github.com/madmann91/bvh; commit 66e445b92f68801a6dd8ef94. Minor changes have been subsequently been applied to achieve compilation with C++17:. - inclusion of alternative span, when std::span is not found; - replacement of C++20 defaulted comparison operators with actual implementation; - old-style struct construction for objects of type ""Reinsertion""; - use of std::inner_product instead of std::transform_reduce (gcc 8.5 had problems). This is needed since ROOT should compile with C++17.; ",MatchSource.DOCS,geom/geom/inc/bvh/v2/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/inc/bvh/v2/README.md
https://github.com/root-project/root/tree/v6-32-06/geom/geombuilder/doc/index.md:228,Security,access,access,228,"\defgroup Geometry_builder Geometry builder; \ingroup Geometry; \brief The Geometry builder related classes. Some documents describing these classes are listed below:. - [Presentation, May 2006](http://indico.cern.ch/getFile.py/access?contribId=3&resId=1&materialId=slides&confId=3028). ",MatchSource.DOCS,geom/geombuilder/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geombuilder/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/graf2d/asimage/doc/index.md:32,Integrability,interface,interface,32,"\defgroup asimage libAfterImage interface; \ingroup Graphics2D; \brief Classes interfacing to libAfterImage. - [libAfterImage Imaging Library.](http://www.afterstep.org/afterimage/index.php); - Several tutorials demonstrate how to use images in ROOT:; - rose_image.C shows how to draw an image in a pad.; - galaxy_image.C illustrates the TASImage class and an image editor.; - img2pad.C shows how to insert images in a pad.; - imgconv.C shows how to save an image in various formats: .png, .gif, .xpm and tiff.; - pad2png.C create a canvas and save as png.",MatchSource.DOCS,graf2d/asimage/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf2d/asimage/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/graf2d/doc/v600/index.md:4280,Availability,error,error,4280,"les' sizes as there is; at least two axis per histogram and that there is often 1000th; histograms in a single file.; So we choose to follow the same mechanism as for the `SetMaxDigits`; static method. The new function is: `SetExponentOffset`.; Example:. ``` {.cpp}; ...; TGaxis::SetMaxDigits(2);; TGaxis::SetExponentOffset(-0.01, 0.01, ""y""); // X and Y offset for Y axis; TGaxis::SetExponentOffset(-0.05, 0.01, ""x""); // Y and Y offset for X axis; ...; hist->Draw();; ```. - `TGaxis::SetMaxDigits()` was not acitve on standalone `TGaxis`. ### TLegend. - The line attribute of objects in the legend were not taken into; account with the option ""e"".; - In case of automatic computation of the legend items' size, the; text size was wrong if the font precision was set to 3.; - Improve the spacing between lines. Due to the way the vertical; text centring is done (bounding based) the spacing between lines; may appeared irregular in some cases.; - The error bar in the legend (option ""E"") didn't have the line; attributes when drawn alone (without option ""L""). ### TPie. - New drawing option ""SC"" to draw the labels with the slices' colors. ### TLine. - Add `SetNDC`. ### TMathText. - TMathText's purpose is to write mathematical equations, exactly as; TeX would do it. The syntax is the same as the TeX's one. Author:; Yue Shi Lai (MIT)) \; Example:. ``` {.cpp}; {; TMathText l;; l.SetTextAlign(23);; l.SetTextSize(0.06);; l.DrawMathText(0.50, 1.000, ""\\prod_{j\\ge0} \\left(\\sum_{k\\ge0} a_{jk}z^k\\right) = \\sum_{n\\ge0} z^n \\left(\\sum_{k_0,k_1,\\ldots\\ge0\\atop k_0+k_1+\\cdots=n} a_{0k_0}a_{1k_1} \\cdots \\right)"");; l.DrawMathText(0.50, 0.800, ""W_{\\delta_1\\rho_1\\sigma_2}^{3\\beta} = U_{\\delta_1\\rho_1\\sigma_2}^{3\\beta} + {1\\over 8\\pi^2} \\int_{\\alpha_1}^{\\alpha_2} d\\alpha_2^\\prime \\left[ {U_{\\delta_1\\rho_1}^{2\\beta} - \\alpha_2^\\prime U_{\\rho_1\\sigma_2}^{1\\beta} \\over U_{\\rho_1\\sigma_2}^{0\\beta}} \\right]"");; l.DrawMathText(0.50, 0.600, ""d\\Gamma = {1\\over 2m",MatchSource.DOCS,graf2d/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf2d/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/graf2d/doc/v600/index.md:8203,Availability,avail,available,8203,"ompatibility; between `TLatex`, `TMathText` and `TTexDump`.; - Some operators like `#minus`, `#plus`, `#mp`, `#hbar` etc ...; ignored the color defined by the operator `#color`.; - With the Cocoa backend on Mac the text string were a bit too large; compared to the TTF rendering. ### TPave. - Implement `SetX1()` etc ... for `TPave` and inherited classes to make sure the; NDC coordinates are also defined. ### TLinearGradient and TRadialGradient. - Two new classes to support color gradient: `TLinearGradient` and `TRadialGradient`.; Both classes inherit from `TColor` and can be used the same way as ROOT's; standard colors in `TAttFill` (`SetFillColor(newColorIndex)`).; Gradient fill can be created using either RGBA values directly, or from; color indices (colors from the ROOT's color table).; - TRadialGradient supports a simple radial gradient (center + radius); and an ""extended"" radial gradient (starting/ending points + two radii).; - The new gradient fill option is available either with OpenGL (""gl-in-pad""); or with a Cocoa backend (OS X only).; - Please note, at the moment, a color gradient can not be saved; in a ROOT file or a pdf/ps file. It can be saved as an image (png/jpg etc.).; - There are several demos in the tutorials/cocoa and tutorials/gl sub-directories; explaining how to use these new classes:; * grad.C; * grad2.C; * radialgradients.C. ![TRadialGradient example](ellipses.png ""TEllipse objects with a radial gradient fill""). ![TLinearGradient example](lingrad.png ""Two histograms with a linear gradient fill and transparency""). ![Gradient example](mixgrad.png ""TPie with a radial fill + a linear gradient fill as a background""). ### TGCocoa and TGQuartz. - Correct font metrics for greek and math symbols are implemented now.; - Added support for linear and radial color gradients (see the notes above).; - ""GL-in-pad"" implemented for Cocoa backend.; - Keyboard event handling is more ""X11-like"" now.; - Multi-display setup is supported now.; - Transparent pads (col",MatchSource.DOCS,graf2d/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf2d/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/graf2d/doc/v600/index.md:3073,Energy Efficiency,power,power,3073,"Label. It doesn't use anymore the `TGX11` function `RequestString`.; Now the text appears directly as it will show and it is possible to; enter several text string. The input is not block in the `RequestString` event loop.; - The toolbar methods now work without XOR mode (useful for OpenGL()).; - A new ""vertex compression"" algorithm added to deal with complex histograms; (thousands/millions of bins - polygons with thousands/millions of vertices) -; optimization/fix for X11 crashes. ### TGaxis and TAxis. - The time axis behavior should now be correct along time zone and; summer saving time. A fix has been done with the of Philippe Gras; (CEA Saclay. IRFU/SEDI) and Julian Sitarek (IFAE). Time axis; transported from a time zone to an other in a ROOT file are correct; too. A new example test have been introduced to test the time axis; (timeonaxis3.C); - In some case the format use to build the axis labels was incorrect.; (cf: Jira report ROOT-5635).; - New static function to change the position of the ""power of 10""; near the axis. A static function is used instead of data members; in `TAxis` in order to keep the `TAxis` class small. Adding two; floating point numbers in that class (in fact in `TAttAxis`) would; have a none negligible effect on the Root files' sizes as there is; at least two axis per histogram and that there is often 1000th; histograms in a single file.; So we choose to follow the same mechanism as for the `SetMaxDigits`; static method. The new function is: `SetExponentOffset`.; Example:. ``` {.cpp}; ...; TGaxis::SetMaxDigits(2);; TGaxis::SetExponentOffset(-0.01, 0.01, ""y""); // X and Y offset for Y axis; TGaxis::SetExponentOffset(-0.05, 0.01, ""x""); // Y and Y offset for X axis; ...; hist->Draw();; ```. - `TGaxis::SetMaxDigits()` was not acitve on standalone `TGaxis`. ### TLegend. - The line attribute of objects in the legend were not taken into; account with the option ""e"".; - In case of automatic computation of the legend items' size, the; text size was ",MatchSource.DOCS,graf2d/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf2d/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/graf2d/doc/v600/index.md:624,Integrability,interface,interface,624,"## 2D Graphics Libraries. ### TASImage. - In some cases dashed lines with a line width greater than ""1"" were; not drawn.; - The `TLatex` symbol `#tilde`, was misplaced.; - In `TASImage::DrawtText`, `TTF::SetTextSize` was called with a rounded; value (to pixel). This cause some misplacements of character in TLatex; formulae. ### TPDF and TPostScript. - Parenthesis can be used in PDF and PS file names.; - In PDF files, italic greek characters were not correct for non null; text angle. ### TImageDump; - Fix a `TBox` clipping issue. ### TSVG; - Some markers did not show in Google-Chrome. ### New class TTeXDump: Graphics interface to TeX. This class allow to generate `PGF/TikZ` vector graphics output; which can be included in TeX and LaTeX documents. `PGF` is a TeX macro package for generating graphics. It is platform; and format-independent and works together with the most important TeX; backend drivers, including pdftex and dvips. It comes with a; user-friedly syntax layer called `TikZ`. To generate a such file it is enough to do:. ```; gStyle->SetPaperSize(10.,10.);; hpx->Draw();; gPad->Print(""hpx.tex"");; ```. Then, the generated file (<tt>hpx.tex</tt>) can be included in a; LaTeX document (`simple.tex`) in the following way:. ```; \documentclass{article}; \usepackage{tikz}; \usetikzlibrary{patterns}; \title{A simple LaTeX example}; \date{July 2013}; \begin{document}; \maketitle; The following image as been generated using the TTeXDump class:; \par; \input{hpx.tex}; \end{document}; ```. Note the two directive needed at the top of the LaTeX file:. ```; \usepackage{tikz}; \usetikzlibrary{patterns}; ```. Then including the picture in the document is done with the; `\input` directive. The command `pdflatex simple.tex` will generate the corresponding pdf; file `simple.pdf`. ### X11 fonts. - A coverity fix in `Rotated.cxx` had a side effect on rotated text; drawn with X11 fonts. ### TCanvas and TPad. - `TPad::SaveAs` produces named macros in .C files.; - Change the way the s",MatchSource.DOCS,graf2d/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf2d/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/graf2d/doc/v600/index.md:7562,Modifiability,inherit,inherited,7562,"ed. Therefore, as histograms' titles, axis; titles, labels etc ... are drawn using `TLatex`, the `TMathText`; syntax can be used for them also.; - Fix a very old bug (in `TTF.cxx` since the beginning). With the; following code the spaces between ""text"" and \#lambda were ignored. ``` {.cpp}; TLatex t; t.DrawLatex( 0.1,0.1,""text \#Lambda"" ); ```. - Implement `#backslash`.; - Implement `DrawLatexNDC`.; - Implement `#minus` and `#plus` typographically better than the; standard `""-""` and `""+""`.; - Make sure all greek and math symbols are printed correctly by `TTexDump`.; - Implement dummy operators `#mbox` and `#hbox` to improve the compatibility; between `TLatex`, `TMathText` and `TTexDump`.; - Some operators like `#minus`, `#plus`, `#mp`, `#hbar` etc ...; ignored the color defined by the operator `#color`.; - With the Cocoa backend on Mac the text string were a bit too large; compared to the TTF rendering. ### TPave. - Implement `SetX1()` etc ... for `TPave` and inherited classes to make sure the; NDC coordinates are also defined. ### TLinearGradient and TRadialGradient. - Two new classes to support color gradient: `TLinearGradient` and `TRadialGradient`.; Both classes inherit from `TColor` and can be used the same way as ROOT's; standard colors in `TAttFill` (`SetFillColor(newColorIndex)`).; Gradient fill can be created using either RGBA values directly, or from; color indices (colors from the ROOT's color table).; - TRadialGradient supports a simple radial gradient (center + radius); and an ""extended"" radial gradient (starting/ending points + two radii).; - The new gradient fill option is available either with OpenGL (""gl-in-pad""); or with a Cocoa backend (OS X only).; - Please note, at the moment, a color gradient can not be saved; in a ROOT file or a pdf/ps file. It can be saved as an image (png/jpg etc.).; - There are several demos in the tutorials/cocoa and tutorials/gl sub-directories; explaining how to use these new classes:; * grad.C; * grad2.C; * radialgradie",MatchSource.DOCS,graf2d/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf2d/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/graf2d/doc/v600/index.md:7773,Modifiability,inherit,inherit,7773,"etween ""text"" and \#lambda were ignored. ``` {.cpp}; TLatex t; t.DrawLatex( 0.1,0.1,""text \#Lambda"" ); ```. - Implement `#backslash`.; - Implement `DrawLatexNDC`.; - Implement `#minus` and `#plus` typographically better than the; standard `""-""` and `""+""`.; - Make sure all greek and math symbols are printed correctly by `TTexDump`.; - Implement dummy operators `#mbox` and `#hbox` to improve the compatibility; between `TLatex`, `TMathText` and `TTexDump`.; - Some operators like `#minus`, `#plus`, `#mp`, `#hbar` etc ...; ignored the color defined by the operator `#color`.; - With the Cocoa backend on Mac the text string were a bit too large; compared to the TTF rendering. ### TPave. - Implement `SetX1()` etc ... for `TPave` and inherited classes to make sure the; NDC coordinates are also defined. ### TLinearGradient and TRadialGradient. - Two new classes to support color gradient: `TLinearGradient` and `TRadialGradient`.; Both classes inherit from `TColor` and can be used the same way as ROOT's; standard colors in `TAttFill` (`SetFillColor(newColorIndex)`).; Gradient fill can be created using either RGBA values directly, or from; color indices (colors from the ROOT's color table).; - TRadialGradient supports a simple radial gradient (center + radius); and an ""extended"" radial gradient (starting/ending points + two radii).; - The new gradient fill option is available either with OpenGL (""gl-in-pad""); or with a Cocoa backend (OS X only).; - Please note, at the moment, a color gradient can not be saved; in a ROOT file or a pdf/ps file. It can be saved as an image (png/jpg etc.).; - There are several demos in the tutorials/cocoa and tutorials/gl sub-directories; explaining how to use these new classes:; * grad.C; * grad2.C; * radialgradients.C. ![TRadialGradient example](ellipses.png ""TEllipse objects with a radial gradient fill""). ![TLinearGradient example](lingrad.png ""Two histograms with a linear gradient fill and transparency""). ![Gradient example](mixgrad.png ""TPie wit",MatchSource.DOCS,graf2d/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf2d/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/graf2d/doc/v600/index.md:8104,Modifiability,extend,extended,8104," all greek and math symbols are printed correctly by `TTexDump`.; - Implement dummy operators `#mbox` and `#hbox` to improve the compatibility; between `TLatex`, `TMathText` and `TTexDump`.; - Some operators like `#minus`, `#plus`, `#mp`, `#hbar` etc ...; ignored the color defined by the operator `#color`.; - With the Cocoa backend on Mac the text string were a bit too large; compared to the TTF rendering. ### TPave. - Implement `SetX1()` etc ... for `TPave` and inherited classes to make sure the; NDC coordinates are also defined. ### TLinearGradient and TRadialGradient. - Two new classes to support color gradient: `TLinearGradient` and `TRadialGradient`.; Both classes inherit from `TColor` and can be used the same way as ROOT's; standard colors in `TAttFill` (`SetFillColor(newColorIndex)`).; Gradient fill can be created using either RGBA values directly, or from; color indices (colors from the ROOT's color table).; - TRadialGradient supports a simple radial gradient (center + radius); and an ""extended"" radial gradient (starting/ending points + two radii).; - The new gradient fill option is available either with OpenGL (""gl-in-pad""); or with a Cocoa backend (OS X only).; - Please note, at the moment, a color gradient can not be saved; in a ROOT file or a pdf/ps file. It can be saved as an image (png/jpg etc.).; - There are several demos in the tutorials/cocoa and tutorials/gl sub-directories; explaining how to use these new classes:; * grad.C; * grad2.C; * radialgradients.C. ![TRadialGradient example](ellipses.png ""TEllipse objects with a radial gradient fill""). ![TLinearGradient example](lingrad.png ""Two histograms with a linear gradient fill and transparency""). ![Gradient example](mixgrad.png ""TPie with a radial fill + a linear gradient fill as a background""). ### TGCocoa and TGQuartz. - Correct font metrics for greek and math symbols are implemented now.; - Added support for linear and radial color gradients (see the notes above).; - ""GL-in-pad"" implemented for C",MatchSource.DOCS,graf2d/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf2d/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/graf2d/doc/v600/index.md:2512,Performance,optimiz,optimization,2512,"TTeXDump class:; \par; \input{hpx.tex}; \end{document}; ```. Note the two directive needed at the top of the LaTeX file:. ```; \usepackage{tikz}; \usetikzlibrary{patterns}; ```. Then including the picture in the document is done with the; `\input` directive. The command `pdflatex simple.tex` will generate the corresponding pdf; file `simple.pdf`. ### X11 fonts. - A coverity fix in `Rotated.cxx` had a side effect on rotated text; drawn with X11 fonts. ### TCanvas and TPad. - `TPad::SaveAs` produces named macros in .C files.; - Change the way the string input is done in the Pad toolbar for text; and Pave Label. It doesn't use anymore the `TGX11` function `RequestString`.; Now the text appears directly as it will show and it is possible to; enter several text string. The input is not block in the `RequestString` event loop.; - The toolbar methods now work without XOR mode (useful for OpenGL()).; - A new ""vertex compression"" algorithm added to deal with complex histograms; (thousands/millions of bins - polygons with thousands/millions of vertices) -; optimization/fix for X11 crashes. ### TGaxis and TAxis. - The time axis behavior should now be correct along time zone and; summer saving time. A fix has been done with the of Philippe Gras; (CEA Saclay. IRFU/SEDI) and Julian Sitarek (IFAE). Time axis; transported from a time zone to an other in a ROOT file are correct; too. A new example test have been introduced to test the time axis; (timeonaxis3.C); - In some case the format use to build the axis labels was incorrect.; (cf: Jira report ROOT-5635).; - New static function to change the position of the ""power of 10""; near the axis. A static function is used instead of data members; in `TAxis` in order to keep the `TAxis` class small. Adding two; floating point numbers in that class (in fact in `TAttAxis`) would; have a none negligible effect on the Root files' sizes as there is; at least two axis per histogram and that there is often 1000th; histograms in a single file.; S",MatchSource.DOCS,graf2d/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf2d/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/graf2d/doc/v600/index.md:2853,Testability,test,test,2853,"text; drawn with X11 fonts. ### TCanvas and TPad. - `TPad::SaveAs` produces named macros in .C files.; - Change the way the string input is done in the Pad toolbar for text; and Pave Label. It doesn't use anymore the `TGX11` function `RequestString`.; Now the text appears directly as it will show and it is possible to; enter several text string. The input is not block in the `RequestString` event loop.; - The toolbar methods now work without XOR mode (useful for OpenGL()).; - A new ""vertex compression"" algorithm added to deal with complex histograms; (thousands/millions of bins - polygons with thousands/millions of vertices) -; optimization/fix for X11 crashes. ### TGaxis and TAxis. - The time axis behavior should now be correct along time zone and; summer saving time. A fix has been done with the of Philippe Gras; (CEA Saclay. IRFU/SEDI) and Julian Sitarek (IFAE). Time axis; transported from a time zone to an other in a ROOT file are correct; too. A new example test have been introduced to test the time axis; (timeonaxis3.C); - In some case the format use to build the axis labels was incorrect.; (cf: Jira report ROOT-5635).; - New static function to change the position of the ""power of 10""; near the axis. A static function is used instead of data members; in `TAxis` in order to keep the `TAxis` class small. Adding two; floating point numbers in that class (in fact in `TAttAxis`) would; have a none negligible effect on the Root files' sizes as there is; at least two axis per histogram and that there is often 1000th; histograms in a single file.; So we choose to follow the same mechanism as for the `SetMaxDigits`; static method. The new function is: `SetExponentOffset`.; Example:. ``` {.cpp}; ...; TGaxis::SetMaxDigits(2);; TGaxis::SetExponentOffset(-0.01, 0.01, ""y""); // X and Y offset for Y axis; TGaxis::SetExponentOffset(-0.05, 0.01, ""x""); // Y and Y offset for X axis; ...; hist->Draw();; ```. - `TGaxis::SetMaxDigits()` was not acitve on standalone `TGaxis`. ### TLeg",MatchSource.DOCS,graf2d/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf2d/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/graf2d/doc/v600/index.md:2882,Testability,test,test,2882,"text; drawn with X11 fonts. ### TCanvas and TPad. - `TPad::SaveAs` produces named macros in .C files.; - Change the way the string input is done in the Pad toolbar for text; and Pave Label. It doesn't use anymore the `TGX11` function `RequestString`.; Now the text appears directly as it will show and it is possible to; enter several text string. The input is not block in the `RequestString` event loop.; - The toolbar methods now work without XOR mode (useful for OpenGL()).; - A new ""vertex compression"" algorithm added to deal with complex histograms; (thousands/millions of bins - polygons with thousands/millions of vertices) -; optimization/fix for X11 crashes. ### TGaxis and TAxis. - The time axis behavior should now be correct along time zone and; summer saving time. A fix has been done with the of Philippe Gras; (CEA Saclay. IRFU/SEDI) and Julian Sitarek (IFAE). Time axis; transported from a time zone to an other in a ROOT file are correct; too. A new example test have been introduced to test the time axis; (timeonaxis3.C); - In some case the format use to build the axis labels was incorrect.; (cf: Jira report ROOT-5635).; - New static function to change the position of the ""power of 10""; near the axis. A static function is used instead of data members; in `TAxis` in order to keep the `TAxis` class small. Adding two; floating point numbers in that class (in fact in `TAttAxis`) would; have a none negligible effect on the Root files' sizes as there is; at least two axis per histogram and that there is often 1000th; histograms in a single file.; So we choose to follow the same mechanism as for the `SetMaxDigits`; static method. The new function is: `SetExponentOffset`.; Example:. ``` {.cpp}; ...; TGaxis::SetMaxDigits(2);; TGaxis::SetExponentOffset(-0.01, 0.01, ""y""); // X and Y offset for Y axis; TGaxis::SetExponentOffset(-0.05, 0.01, ""x""); // Y and Y offset for X axis; ...; hist->Draw();; ```. - `TGaxis::SetMaxDigits()` was not acitve on standalone `TGaxis`. ### TLeg",MatchSource.DOCS,graf2d/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf2d/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/graf2d/doc/v600/index.md:1209,Usability,simpl,simple,1209,"awtText`, `TTF::SetTextSize` was called with a rounded; value (to pixel). This cause some misplacements of character in TLatex; formulae. ### TPDF and TPostScript. - Parenthesis can be used in PDF and PS file names.; - In PDF files, italic greek characters were not correct for non null; text angle. ### TImageDump; - Fix a `TBox` clipping issue. ### TSVG; - Some markers did not show in Google-Chrome. ### New class TTeXDump: Graphics interface to TeX. This class allow to generate `PGF/TikZ` vector graphics output; which can be included in TeX and LaTeX documents. `PGF` is a TeX macro package for generating graphics. It is platform; and format-independent and works together with the most important TeX; backend drivers, including pdftex and dvips. It comes with a; user-friedly syntax layer called `TikZ`. To generate a such file it is enough to do:. ```; gStyle->SetPaperSize(10.,10.);; hpx->Draw();; gPad->Print(""hpx.tex"");; ```. Then, the generated file (<tt>hpx.tex</tt>) can be included in a; LaTeX document (`simple.tex`) in the following way:. ```; \documentclass{article}; \usepackage{tikz}; \usetikzlibrary{patterns}; \title{A simple LaTeX example}; \date{July 2013}; \begin{document}; \maketitle; The following image as been generated using the TTeXDump class:; \par; \input{hpx.tex}; \end{document}; ```. Note the two directive needed at the top of the LaTeX file:. ```; \usepackage{tikz}; \usetikzlibrary{patterns}; ```. Then including the picture in the document is done with the; `\input` directive. The command `pdflatex simple.tex` will generate the corresponding pdf; file `simple.pdf`. ### X11 fonts. - A coverity fix in `Rotated.cxx` had a side effect on rotated text; drawn with X11 fonts. ### TCanvas and TPad. - `TPad::SaveAs` produces named macros in .C files.; - Change the way the string input is done in the Pad toolbar for text; and Pave Label. It doesn't use anymore the `TGX11` function `RequestString`.; Now the text appears directly as it will show and it is poss",MatchSource.DOCS,graf2d/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf2d/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/graf2d/doc/v600/index.md:1330,Usability,simpl,simple,1330,"is can be used in PDF and PS file names.; - In PDF files, italic greek characters were not correct for non null; text angle. ### TImageDump; - Fix a `TBox` clipping issue. ### TSVG; - Some markers did not show in Google-Chrome. ### New class TTeXDump: Graphics interface to TeX. This class allow to generate `PGF/TikZ` vector graphics output; which can be included in TeX and LaTeX documents. `PGF` is a TeX macro package for generating graphics. It is platform; and format-independent and works together with the most important TeX; backend drivers, including pdftex and dvips. It comes with a; user-friedly syntax layer called `TikZ`. To generate a such file it is enough to do:. ```; gStyle->SetPaperSize(10.,10.);; hpx->Draw();; gPad->Print(""hpx.tex"");; ```. Then, the generated file (<tt>hpx.tex</tt>) can be included in a; LaTeX document (`simple.tex`) in the following way:. ```; \documentclass{article}; \usepackage{tikz}; \usetikzlibrary{patterns}; \title{A simple LaTeX example}; \date{July 2013}; \begin{document}; \maketitle; The following image as been generated using the TTeXDump class:; \par; \input{hpx.tex}; \end{document}; ```. Note the two directive needed at the top of the LaTeX file:. ```; \usepackage{tikz}; \usetikzlibrary{patterns}; ```. Then including the picture in the document is done with the; `\input` directive. The command `pdflatex simple.tex` will generate the corresponding pdf; file `simple.pdf`. ### X11 fonts. - A coverity fix in `Rotated.cxx` had a side effect on rotated text; drawn with X11 fonts. ### TCanvas and TPad. - `TPad::SaveAs` produces named macros in .C files.; - Change the way the string input is done in the Pad toolbar for text; and Pave Label. It doesn't use anymore the `TGX11` function `RequestString`.; Now the text appears directly as it will show and it is possible to; enter several text string. The input is not block in the `RequestString` event loop.; - The toolbar methods now work without XOR mode (useful for OpenGL()).; - A new """,MatchSource.DOCS,graf2d/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf2d/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/graf2d/doc/v600/index.md:1730,Usability,simpl,simple,1730,"luded in TeX and LaTeX documents. `PGF` is a TeX macro package for generating graphics. It is platform; and format-independent and works together with the most important TeX; backend drivers, including pdftex and dvips. It comes with a; user-friedly syntax layer called `TikZ`. To generate a such file it is enough to do:. ```; gStyle->SetPaperSize(10.,10.);; hpx->Draw();; gPad->Print(""hpx.tex"");; ```. Then, the generated file (<tt>hpx.tex</tt>) can be included in a; LaTeX document (`simple.tex`) in the following way:. ```; \documentclass{article}; \usepackage{tikz}; \usetikzlibrary{patterns}; \title{A simple LaTeX example}; \date{July 2013}; \begin{document}; \maketitle; The following image as been generated using the TTeXDump class:; \par; \input{hpx.tex}; \end{document}; ```. Note the two directive needed at the top of the LaTeX file:. ```; \usepackage{tikz}; \usetikzlibrary{patterns}; ```. Then including the picture in the document is done with the; `\input` directive. The command `pdflatex simple.tex` will generate the corresponding pdf; file `simple.pdf`. ### X11 fonts. - A coverity fix in `Rotated.cxx` had a side effect on rotated text; drawn with X11 fonts. ### TCanvas and TPad. - `TPad::SaveAs` produces named macros in .C files.; - Change the way the string input is done in the Pad toolbar for text; and Pave Label. It doesn't use anymore the `TGX11` function `RequestString`.; Now the text appears directly as it will show and it is possible to; enter several text string. The input is not block in the `RequestString` event loop.; - The toolbar methods now work without XOR mode (useful for OpenGL()).; - A new ""vertex compression"" algorithm added to deal with complex histograms; (thousands/millions of bins - polygons with thousands/millions of vertices) -; optimization/fix for X11 crashes. ### TGaxis and TAxis. - The time axis behavior should now be correct along time zone and; summer saving time. A fix has been done with the of Philippe Gras; (CEA Saclay. IRFU/S",MatchSource.DOCS,graf2d/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf2d/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/graf2d/doc/v600/index.md:1785,Usability,simpl,simple,1785," a TeX macro package for generating graphics. It is platform; and format-independent and works together with the most important TeX; backend drivers, including pdftex and dvips. It comes with a; user-friedly syntax layer called `TikZ`. To generate a such file it is enough to do:. ```; gStyle->SetPaperSize(10.,10.);; hpx->Draw();; gPad->Print(""hpx.tex"");; ```. Then, the generated file (<tt>hpx.tex</tt>) can be included in a; LaTeX document (`simple.tex`) in the following way:. ```; \documentclass{article}; \usepackage{tikz}; \usetikzlibrary{patterns}; \title{A simple LaTeX example}; \date{July 2013}; \begin{document}; \maketitle; The following image as been generated using the TTeXDump class:; \par; \input{hpx.tex}; \end{document}; ```. Note the two directive needed at the top of the LaTeX file:. ```; \usepackage{tikz}; \usetikzlibrary{patterns}; ```. Then including the picture in the document is done with the; `\input` directive. The command `pdflatex simple.tex` will generate the corresponding pdf; file `simple.pdf`. ### X11 fonts. - A coverity fix in `Rotated.cxx` had a side effect on rotated text; drawn with X11 fonts. ### TCanvas and TPad. - `TPad::SaveAs` produces named macros in .C files.; - Change the way the string input is done in the Pad toolbar for text; and Pave Label. It doesn't use anymore the `TGX11` function `RequestString`.; Now the text appears directly as it will show and it is possible to; enter several text string. The input is not block in the `RequestString` event loop.; - The toolbar methods now work without XOR mode (useful for OpenGL()).; - A new ""vertex compression"" algorithm added to deal with complex histograms; (thousands/millions of bins - polygons with thousands/millions of vertices) -; optimization/fix for X11 crashes. ### TGaxis and TAxis. - The time axis behavior should now be correct along time zone and; summer saving time. A fix has been done with the of Philippe Gras; (CEA Saclay. IRFU/SEDI) and Julian Sitarek (IFAE). Time axis; ",MatchSource.DOCS,graf2d/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf2d/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/graf2d/doc/v600/index.md:8054,Usability,simpl,simple,8054," all greek and math symbols are printed correctly by `TTexDump`.; - Implement dummy operators `#mbox` and `#hbox` to improve the compatibility; between `TLatex`, `TMathText` and `TTexDump`.; - Some operators like `#minus`, `#plus`, `#mp`, `#hbar` etc ...; ignored the color defined by the operator `#color`.; - With the Cocoa backend on Mac the text string were a bit too large; compared to the TTF rendering. ### TPave. - Implement `SetX1()` etc ... for `TPave` and inherited classes to make sure the; NDC coordinates are also defined. ### TLinearGradient and TRadialGradient. - Two new classes to support color gradient: `TLinearGradient` and `TRadialGradient`.; Both classes inherit from `TColor` and can be used the same way as ROOT's; standard colors in `TAttFill` (`SetFillColor(newColorIndex)`).; Gradient fill can be created using either RGBA values directly, or from; color indices (colors from the ROOT's color table).; - TRadialGradient supports a simple radial gradient (center + radius); and an ""extended"" radial gradient (starting/ending points + two radii).; - The new gradient fill option is available either with OpenGL (""gl-in-pad""); or with a Cocoa backend (OS X only).; - Please note, at the moment, a color gradient can not be saved; in a ROOT file or a pdf/ps file. It can be saved as an image (png/jpg etc.).; - There are several demos in the tutorials/cocoa and tutorials/gl sub-directories; explaining how to use these new classes:; * grad.C; * grad2.C; * radialgradients.C. ![TRadialGradient example](ellipses.png ""TEllipse objects with a radial gradient fill""). ![TLinearGradient example](lingrad.png ""Two histograms with a linear gradient fill and transparency""). ![Gradient example](mixgrad.png ""TPie with a radial fill + a linear gradient fill as a background""). ### TGCocoa and TGQuartz. - Correct font metrics for greek and math symbols are implemented now.; - Added support for linear and radial color gradients (see the notes above).; - ""GL-in-pad"" implemented for C",MatchSource.DOCS,graf2d/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf2d/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/graf2d/doc/v602/index.md:325,Integrability,interface,interface,325,"## 2D Graphics Libraries. ### TLegend. - Due to the way the vertical text centring is done (bounding based) the; spacing between lines may appeared irregular in some cases. This was; previously fixed. But in case the text size of legend's items is smaller; than the line spacing some misalignment appeared. ### TLatex. - The interface to TMathText did not work when the size was set in pixel; (precision 3). ### TTeXDump. - The marker definition is now inside the picture definition. Being outside; produced some side effect on the picture positioning. (cf Jira Report 6470). ### Typographically correct minus sign. - Negative values as well as negative exponents were typeset with a hyphen; instead of a real minus sign in axis labels and statistics numbers. Now is the; TLatex `#minus` sign is used instead, which improve the appearance of the plots; and make them even better for publications.",MatchSource.DOCS,graf2d/doc/v602/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf2d/doc/v602/index.md
https://github.com/root-project/root/tree/v6-32-06/graf2d/gpad/doc/index.md:1024,Modifiability,inherit,inheritance,1024,"\defgroup Graphics Graphics; \brief The graphics related classes; \defgroup Graphics2D 2D Graphics; \ingroup Graphics; \brief The 2D graphics related classes; \defgroup gpad Graphics pad; \ingroup Graphics2D; \brief The TPad related classes. TPad and TPad's related classes' usages are illustrated by the following examples:. - [The Graphics Pad.](https://root.cern/doc/master/classTPad.html); - [How to Draw objects.](https://root-forum.cern.ch/t/how-to-draw-objects/28249); - [How to Pick objects.](https://root-forum.cern.ch/t/how-to-pick-objects/28251); - [Dividing a canvas with no margins between pads.](https://root.cern/doc/master/zones_8C.html); - [Using transparent pads.](https://root.cern/doc/master/transpad_8C.html). \defgroup GraphicsAtt Graphics attributes; \ingroup Graphics; \brief The graphics attributes related classes. Graphics attributes, are parameters that affect the way; [graphics primitives](https://root.cern.ch/basic-graphics-primitives) are displayed. A ROOT object get graphics attributes by inheritance from the `TAttXXX` classes. For example, lines can be dotted or dashed, fat or thin, blue or orange. If; an object inherits form the class TAttLine it will get these attributes.; Areas might be filled with one color or with a multicolor pattern. If; an object inherits form the class TAttFill it will get these attribute.; Text can appear with an angle, displayed in different fonts, colors, and sizes.; If an object inherits form the class TAttText it will get these attribute. ",MatchSource.DOCS,graf2d/gpad/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf2d/gpad/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/graf2d/gpad/doc/index.md:1151,Modifiability,inherit,inherits,1151,"\defgroup Graphics Graphics; \brief The graphics related classes; \defgroup Graphics2D 2D Graphics; \ingroup Graphics; \brief The 2D graphics related classes; \defgroup gpad Graphics pad; \ingroup Graphics2D; \brief The TPad related classes. TPad and TPad's related classes' usages are illustrated by the following examples:. - [The Graphics Pad.](https://root.cern/doc/master/classTPad.html); - [How to Draw objects.](https://root-forum.cern.ch/t/how-to-draw-objects/28249); - [How to Pick objects.](https://root-forum.cern.ch/t/how-to-pick-objects/28251); - [Dividing a canvas with no margins between pads.](https://root.cern/doc/master/zones_8C.html); - [Using transparent pads.](https://root.cern/doc/master/transpad_8C.html). \defgroup GraphicsAtt Graphics attributes; \ingroup Graphics; \brief The graphics attributes related classes. Graphics attributes, are parameters that affect the way; [graphics primitives](https://root.cern.ch/basic-graphics-primitives) are displayed. A ROOT object get graphics attributes by inheritance from the `TAttXXX` classes. For example, lines can be dotted or dashed, fat or thin, blue or orange. If; an object inherits form the class TAttLine it will get these attributes.; Areas might be filled with one color or with a multicolor pattern. If; an object inherits form the class TAttFill it will get these attribute.; Text can appear with an angle, displayed in different fonts, colors, and sizes.; If an object inherits form the class TAttText it will get these attribute. ",MatchSource.DOCS,graf2d/gpad/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf2d/gpad/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/graf2d/gpad/doc/index.md:1296,Modifiability,inherit,inherits,1296,"\defgroup Graphics Graphics; \brief The graphics related classes; \defgroup Graphics2D 2D Graphics; \ingroup Graphics; \brief The 2D graphics related classes; \defgroup gpad Graphics pad; \ingroup Graphics2D; \brief The TPad related classes. TPad and TPad's related classes' usages are illustrated by the following examples:. - [The Graphics Pad.](https://root.cern/doc/master/classTPad.html); - [How to Draw objects.](https://root-forum.cern.ch/t/how-to-draw-objects/28249); - [How to Pick objects.](https://root-forum.cern.ch/t/how-to-pick-objects/28251); - [Dividing a canvas with no margins between pads.](https://root.cern/doc/master/zones_8C.html); - [Using transparent pads.](https://root.cern/doc/master/transpad_8C.html). \defgroup GraphicsAtt Graphics attributes; \ingroup Graphics; \brief The graphics attributes related classes. Graphics attributes, are parameters that affect the way; [graphics primitives](https://root.cern.ch/basic-graphics-primitives) are displayed. A ROOT object get graphics attributes by inheritance from the `TAttXXX` classes. For example, lines can be dotted or dashed, fat or thin, blue or orange. If; an object inherits form the class TAttLine it will get these attributes.; Areas might be filled with one color or with a multicolor pattern. If; an object inherits form the class TAttFill it will get these attribute.; Text can appear with an angle, displayed in different fonts, colors, and sizes.; If an object inherits form the class TAttText it will get these attribute. ",MatchSource.DOCS,graf2d/gpad/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf2d/gpad/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/graf2d/gpad/doc/index.md:1453,Modifiability,inherit,inherits,1453,"\defgroup Graphics Graphics; \brief The graphics related classes; \defgroup Graphics2D 2D Graphics; \ingroup Graphics; \brief The 2D graphics related classes; \defgroup gpad Graphics pad; \ingroup Graphics2D; \brief The TPad related classes. TPad and TPad's related classes' usages are illustrated by the following examples:. - [The Graphics Pad.](https://root.cern/doc/master/classTPad.html); - [How to Draw objects.](https://root-forum.cern.ch/t/how-to-draw-objects/28249); - [How to Pick objects.](https://root-forum.cern.ch/t/how-to-pick-objects/28251); - [Dividing a canvas with no margins between pads.](https://root.cern/doc/master/zones_8C.html); - [Using transparent pads.](https://root.cern/doc/master/transpad_8C.html). \defgroup GraphicsAtt Graphics attributes; \ingroup Graphics; \brief The graphics attributes related classes. Graphics attributes, are parameters that affect the way; [graphics primitives](https://root.cern.ch/basic-graphics-primitives) are displayed. A ROOT object get graphics attributes by inheritance from the `TAttXXX` classes. For example, lines can be dotted or dashed, fat or thin, blue or orange. If; an object inherits form the class TAttLine it will get these attributes.; Areas might be filled with one color or with a multicolor pattern. If; an object inherits form the class TAttFill it will get these attribute.; Text can appear with an angle, displayed in different fonts, colors, and sizes.; If an object inherits form the class TAttText it will get these attribute. ",MatchSource.DOCS,graf2d/gpad/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf2d/gpad/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/graf2d/gviz/doc/index.md:24,Integrability,interface,interface,24,\defgroup gviz graphviz interface; \ingroup Graphics2D; \brief Interface to the graphing package `graphviz`. - graphstruct.C is an example of the graphviz interface classes usage. ,MatchSource.DOCS,graf2d/gviz/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf2d/gviz/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/graf2d/gviz/doc/index.md:155,Integrability,interface,interface,155,\defgroup gviz graphviz interface; \ingroup Graphics2D; \brief Interface to the graphing package `graphviz`. - graphstruct.C is an example of the graphviz interface classes usage. ,MatchSource.DOCS,graf2d/gviz/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf2d/gviz/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/graf2d/postscript/doc/index.md:309,Security,access,accessible,309,"\defgroup PS Graphics file output; \ingroup Graphics2D; \brief Interfaces to various file output formats. These classes are the backends allowing to generate PS, PDF, LaTeX, SVG and all kinds; of binary files. They are used when the methods `TPad::SaveAS` or `TPad::Print`; are invoked. This methods are also accessible interactively from the `File` menu; of a `TCanvas` window. - psview.C is an example showing how to display PS, EPS, PDF files in canvas. ",MatchSource.DOCS,graf2d/postscript/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf2d/postscript/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/graf3d/doc/v600/index.md:561,Deployability,update,updated,561,". ## 3D Graphics Libraries. ### Gl in Pad. - Transparency is now implemented for ""GL in Pad"" (`gStyle->SetCanvasPreferGL(1)`).; - Introduce the flag `CanvasPreferGL` in `rootrc.in`. So OpenGL can be use by; default. The default value for this flag is 0 (no OpenGL).; - Fix size issues with the FTGL text.; - Make `TMathText` work with FTGL; - Linear and radial color gradients are implemented for ""GL in Pad""; (only a simple radial color gradient),; see also the notes about TLinearGradient and TRadialGradient classes.; - ""GL in Pad"" and gl hist painters were updated to support Retina displays; (OS X + Cocoa).; ",MatchSource.DOCS,graf3d/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf3d/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/graf3d/doc/v600/index.md:418,Usability,simpl,simple,418,". ## 3D Graphics Libraries. ### Gl in Pad. - Transparency is now implemented for ""GL in Pad"" (`gStyle->SetCanvasPreferGL(1)`).; - Introduce the flag `CanvasPreferGL` in `rootrc.in`. So OpenGL can be use by; default. The default value for this flag is 0 (no OpenGL).; - Fix size issues with the FTGL text.; - Make `TMathText` work with FTGL; - Linear and radial color gradients are implemented for ""GL in Pad""; (only a simple radial color gradient),; see also the notes about TLinearGradient and TRadialGradient classes.; - ""GL in Pad"" and gl hist painters were updated to support Retina displays; (OS X + Cocoa).; ",MatchSource.DOCS,graf3d/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf3d/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/graf3d/eve/doc/index.md:407,Performance,perform,perform,407,"\defgroup Graphics3D 3D Graphics; \ingroup Graphics; \brief The 3D graphics related classes; \defgroup TEve Event Display; \ingroup Graphics3D; \brief The Event Display classes. Eve is a ROOT module based on experiment-independent part of the; ALICE event display developed in cooperation between ALICE offline; project and ROOT during the last two years. It has been used in; ALICE for more than a year to perform high-level event; visualization, debugging of simulation and reconstruction code as; well as for raw-data visualization. Papers describing Eve (older ones still using the old name - Reve):. - [EVE - Event Visualization Environment of the ROOT framework]; (http://pos.sissa.it//archive/conferences/070/103/ACAT08_103.pdf); presented at ACAT 2008. - [Event Visualization Environment of the ALICE experiment]; (http://indico.cern.ch/contributionDisplay.py?contribId=25&confId=13356); presented at ROOT Workshop 2007. - [Raw-data display and visual reconstruction validation in ALICE]; (http://indico.cern.ch/contributionDisplay.py?contribId=442&sessionId=23&confId=3580); presented at CHEP 2007. Eve is built on top of ROOT's GUI, GL and GED infrastructure and; delivers the following main features:. - Base-classes for representation of visual objects that can; be presented in list-tree views, object-editors and rendered; via OpenGL (TEveElement and sub-classes). - Application manager class TEveManager for top-level; management of elements, GUI components, geometries and events;. - Classes for presentation of full TGeo geometries; (TEveGeoNode and TEveGeoTopNode) as well as of; simplifed geometries via extraction of shape-data; (TEveGeoShape). \image html eve_cmsgeo.png ""CMS geometry"". - Classes for presentation of trajectories or tracks; (TEveTrack, TEveTrackPropagator) and hits or; clusters (TEvePointSet, TEvePointSetArray). \image html eve_alice3d.png ""A simulated ALICE pp@14TeV event in 3D"". - Base-classes for presentation of raw-data or digits; (TEveDigitSet, TEveQuadS",MatchSource.DOCS,graf3d/eve/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf3d/eve/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/graf3d/eve/doc/index.md:975,Security,validat,validation,975,"\defgroup Graphics3D 3D Graphics; \ingroup Graphics; \brief The 3D graphics related classes; \defgroup TEve Event Display; \ingroup Graphics3D; \brief The Event Display classes. Eve is a ROOT module based on experiment-independent part of the; ALICE event display developed in cooperation between ALICE offline; project and ROOT during the last two years. It has been used in; ALICE for more than a year to perform high-level event; visualization, debugging of simulation and reconstruction code as; well as for raw-data visualization. Papers describing Eve (older ones still using the old name - Reve):. - [EVE - Event Visualization Environment of the ROOT framework]; (http://pos.sissa.it//archive/conferences/070/103/ACAT08_103.pdf); presented at ACAT 2008. - [Event Visualization Environment of the ALICE experiment]; (http://indico.cern.ch/contributionDisplay.py?contribId=25&confId=13356); presented at ROOT Workshop 2007. - [Raw-data display and visual reconstruction validation in ALICE]; (http://indico.cern.ch/contributionDisplay.py?contribId=442&sessionId=23&confId=3580); presented at CHEP 2007. Eve is built on top of ROOT's GUI, GL and GED infrastructure and; delivers the following main features:. - Base-classes for representation of visual objects that can; be presented in list-tree views, object-editors and rendered; via OpenGL (TEveElement and sub-classes). - Application manager class TEveManager for top-level; management of elements, GUI components, geometries and events;. - Classes for presentation of full TGeo geometries; (TEveGeoNode and TEveGeoTopNode) as well as of; simplifed geometries via extraction of shape-data; (TEveGeoShape). \image html eve_cmsgeo.png ""CMS geometry"". - Classes for presentation of trajectories or tracks; (TEveTrack, TEveTrackPropagator) and hits or; clusters (TEvePointSet, TEvePointSetArray). \image html eve_alice3d.png ""A simulated ALICE pp@14TeV event in 3D"". - Base-classes for presentation of raw-data or digits; (TEveDigitSet, TEveQuadS",MatchSource.DOCS,graf3d/eve/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf3d/eve/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/graf3d/eve/doc/index.md:1598,Usability,simpl,simplifed,1598,"g the old name - Reve):. - [EVE - Event Visualization Environment of the ROOT framework]; (http://pos.sissa.it//archive/conferences/070/103/ACAT08_103.pdf); presented at ACAT 2008. - [Event Visualization Environment of the ALICE experiment]; (http://indico.cern.ch/contributionDisplay.py?contribId=25&confId=13356); presented at ROOT Workshop 2007. - [Raw-data display and visual reconstruction validation in ALICE]; (http://indico.cern.ch/contributionDisplay.py?contribId=442&sessionId=23&confId=3580); presented at CHEP 2007. Eve is built on top of ROOT's GUI, GL and GED infrastructure and; delivers the following main features:. - Base-classes for representation of visual objects that can; be presented in list-tree views, object-editors and rendered; via OpenGL (TEveElement and sub-classes). - Application manager class TEveManager for top-level; management of elements, GUI components, geometries and events;. - Classes for presentation of full TGeo geometries; (TEveGeoNode and TEveGeoTopNode) as well as of; simplifed geometries via extraction of shape-data; (TEveGeoShape). \image html eve_cmsgeo.png ""CMS geometry"". - Classes for presentation of trajectories or tracks; (TEveTrack, TEveTrackPropagator) and hits or; clusters (TEvePointSet, TEvePointSetArray). \image html eve_alice3d.png ""A simulated ALICE pp@14TeV event in 3D"". - Base-classes for presentation of raw-data or digits; (TEveDigitSet, TEveQuadSet and; TEveBoxSet). A collection of objects can be assigned; common signal-to-color mapping (TEveRGBAPelette) and; surrounding frame (TEveFrameBox). \image html eve_quadset.png ""Hexagonal and rectangular digits"". - Base-classes for 2D projections with dynamically controllable; fish-eye magnification of the vertex region; (TEveProjectionManager and; TEveProjection). Tracks, points and geometries can be; projected automatically. R-phi and Rho-z projections are; currently supported. \image html eve_aliceproj.png ""A r-phi projection with fish-eye transformation of a simulated ",MatchSource.DOCS,graf3d/eve/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf3d/eve/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/graf3d/gl/doc/index.md:135,Integrability,interface,interface,135,"\defgroup opengl OpenGL rendering; \ingroup Graphics3D; \brief OpenGL rendering and utility classes. The GL module incapsulates ROOT's interface to the OpenGL rendering; engine and provides the following functionality:. - management of system-resources;; - frequently used utility classes;; - base-classes for shapes, scenes and viewers;; - concrete implementations of shapes needed by TGeo package;; - concrete implementations of scenes and viewers including the GUI components;; - specialized plot-painters for GL rendering of TH2, TH3, TF2 and TF3 object as well as parametric surfaces. Papers describing OpenGL in ROOT:; - [ROOT 3D graphics](http://indico.cern.ch/contributionDisplay.py?contribId=93&sessionId=4&confId=048), presented at CHEP 2006.; - [3D graphics with OpenGL: recent improvements and plans](http://indico.cern.ch/contributionDisplay.py?contribId=23&confId=13356), presented at ROOT Workshop 2007; - [Next generation of OpenGL support in ROOT](http://indico.cern.ch/contributionDisplay.py?contribId=445&sessionId=28&confId=3580), presented at CHEP 2007.; ",MatchSource.DOCS,graf3d/gl/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf3d/gl/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/gui/cefdisplay/Readme.md:3869,Availability,down,download-dir,3869," --config Release --target libcef_dll_wrapper; ~~~. 5. Before compiling ROOT, `set CEF_ROOT=C:\Soft\cef` variable. ## Using plain CEF in ROOT batch mode on Linux. Default CEF builds, provided by [https://cef-builds.spotifycdn.com/index.html](https://cef-builds.spotifycdn.com/index.html), do; not include support of Ozone framework, which the only support headless mode in CEF. To run ROOT in headless (or batch) made with such CEF distribution,; one can use `Xvfb` server. Most simple way is to use `xvfb-run` utility like:. ~~~; $ xvfb-run --server-args='-screen 0, 1024x768x16' root.exe -l --web=cef $ROOTSYS/tutorials/rcanvas/rline.cxx -q; ~~~. Or run `Xvfb` before starting ROOT:. ~~~; $ Xvfb :99 &; $ export DISPLAY=:99; $ root.exe -l --web=cef $ROOTSYS/tutorials/rcanvas/rline.cxx -q; ~~~. ## Compile CEF with ozone support. Since March 2019 one can compile [CEF without X11](https://bitbucket.org/chromiumembedded/cef/issues/2296/), but such builds not provided.; Therefore to be able to use real headless mode in CEF, one should compile it from sources.; On [CEF build tutorial](https://bitbucket.org/chromiumembedded/cef/wiki/AutomatedBuildSetup.md) one can find complete compilation documentation.; Several Ubuntu distributions are supported by CEF, all others may require extra work. Once all depndencies are installed,; CEF with ozone support can be compiled with following commands:. ~~~; $ export GN_DEFINES=""is_official_build=true use_sysroot=true use_allocator=none symbol_level=1 is_cfi=false use_thin_lto=false use_ozone=true""; $ python automate-git.py --download-dir=/home/user/cef --branch=4638 --minimal-distrib --client-distrib --force-clean --x64-build --build-target=cefsimple; ~~~. With little luck one get prepared tarballs in `/home/user/cef/chromium/src/cef/binary_distrib`.; Just install it in the same way as described before in this document.; ROOT will automatically detect that CEF build with `ozone` support and will use it for both interactive and headless modes. ",MatchSource.DOCS,gui/cefdisplay/Readme.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/cefdisplay/Readme.md
https://github.com/root-project/root/tree/v6-32-06/gui/cefdisplay/Readme.md:19,Deployability,install,installation,19,"\page cefpage ROOT installation with CEF. ## Compilation with CEF support. See details about [Chromium Embedded Framework](https://bitbucket.org/chromiumembedded/cef). 1. Current code tested with CEF3 branch 5845, Chromium 116 (August 2023); Some older CEF versions (like 95 or 107) may also be supported. 2. Download binary code from [https://cef-builds.spotifycdn.com/index.html](https://cef-builds.spotifycdn.com/index.html); and unpack it in directory without spaces and special symbols:. ~~~; $ mkdir /d/cef; $ cd /d/cef/; $ wget https://cef-builds.spotifycdn.com/cef_binary_107.1.11%2Bg26c0b5e%2Bchromium-107.0.5304.110_linux64_minimal.tar.bz2; $ tar xjf cef_binary_107.1.11+g26c0b5e+chromium-107.0.5304.110_linux64_minimal.tar.bz2; ~~~. 3 Install prerequisites - see comments in package `CMakeLists.txt`.; For the linux these are: `build-essential`, `libgtk3.0-dev`. 4. Compile CEF to produce `libcef_dll_wrapper`:. ~~~; $ cd /d/cef/cef_binary_107.1.11+g26c0b5e+chromium-107.0.5304.110_linux64_minimal; $ mkdir build; $ cd build; $ cmake ..; $ make -j libcef_dll_wrapper; ~~~. 5. Set CEF_ROOT variable to unpacked directory:. ~~~; $ export CEF_ROOT=/d/cef/cef_binary_107.1.11+g26c0b5e+chromium-107.0.5304.110_linux64_minimal; ~~~. 6. When configure ROOT compilation with `cmake -Dwebgui=ON -Dcefweb=ON ...`, CEF_ROOT shell variable should be set appropriately.; During compilation library `$ROOTSYS/lib/libROOTCefDisplay.so` and executable `$ROOTSYS/bin/cef_main`; should be created. Also check that several files like `icudtl.dat`, `v8_context_snapshot_blob.bin`, `snapshot_blob.bin`; copied into ROOT library directory. 7. Run ROOT with `--web=cef` argument to use CEF web display like:. ~~~; $ root --web=cef $ROOTSYS/tutorials/rcanvas/rh2.cxx; ~~~. ## Compile libcef_dll_wrapper on Windows. 1. Download binary win32 build like https://cef-builds.spotifycdn.com/cef_binary_95.7.12%2Bg99c4ac0%2Bchromium-95.0.4638.54_windows32.tar.bz2. 2. Extract in directory without spaces like `C:\Soft\cef",MatchSource.DOCS,gui/cefdisplay/Readme.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/cefdisplay/Readme.md
https://github.com/root-project/root/tree/v6-32-06/gui/cefdisplay/Readme.md:3616,Deployability,install,installed,3616," --config Release --target libcef_dll_wrapper; ~~~. 5. Before compiling ROOT, `set CEF_ROOT=C:\Soft\cef` variable. ## Using plain CEF in ROOT batch mode on Linux. Default CEF builds, provided by [https://cef-builds.spotifycdn.com/index.html](https://cef-builds.spotifycdn.com/index.html), do; not include support of Ozone framework, which the only support headless mode in CEF. To run ROOT in headless (or batch) made with such CEF distribution,; one can use `Xvfb` server. Most simple way is to use `xvfb-run` utility like:. ~~~; $ xvfb-run --server-args='-screen 0, 1024x768x16' root.exe -l --web=cef $ROOTSYS/tutorials/rcanvas/rline.cxx -q; ~~~. Or run `Xvfb` before starting ROOT:. ~~~; $ Xvfb :99 &; $ export DISPLAY=:99; $ root.exe -l --web=cef $ROOTSYS/tutorials/rcanvas/rline.cxx -q; ~~~. ## Compile CEF with ozone support. Since March 2019 one can compile [CEF without X11](https://bitbucket.org/chromiumembedded/cef/issues/2296/), but such builds not provided.; Therefore to be able to use real headless mode in CEF, one should compile it from sources.; On [CEF build tutorial](https://bitbucket.org/chromiumembedded/cef/wiki/AutomatedBuildSetup.md) one can find complete compilation documentation.; Several Ubuntu distributions are supported by CEF, all others may require extra work. Once all depndencies are installed,; CEF with ozone support can be compiled with following commands:. ~~~; $ export GN_DEFINES=""is_official_build=true use_sysroot=true use_allocator=none symbol_level=1 is_cfi=false use_thin_lto=false use_ozone=true""; $ python automate-git.py --download-dir=/home/user/cef --branch=4638 --minimal-distrib --client-distrib --force-clean --x64-build --build-target=cefsimple; ~~~. With little luck one get prepared tarballs in `/home/user/cef/chromium/src/cef/binary_distrib`.; Just install it in the same way as described before in this document.; ROOT will automatically detect that CEF build with `ozone` support and will use it for both interactive and headless modes. ",MatchSource.DOCS,gui/cefdisplay/Readme.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/cefdisplay/Readme.md
https://github.com/root-project/root/tree/v6-32-06/gui/cefdisplay/Readme.md:4105,Deployability,install,install,4105," --config Release --target libcef_dll_wrapper; ~~~. 5. Before compiling ROOT, `set CEF_ROOT=C:\Soft\cef` variable. ## Using plain CEF in ROOT batch mode on Linux. Default CEF builds, provided by [https://cef-builds.spotifycdn.com/index.html](https://cef-builds.spotifycdn.com/index.html), do; not include support of Ozone framework, which the only support headless mode in CEF. To run ROOT in headless (or batch) made with such CEF distribution,; one can use `Xvfb` server. Most simple way is to use `xvfb-run` utility like:. ~~~; $ xvfb-run --server-args='-screen 0, 1024x768x16' root.exe -l --web=cef $ROOTSYS/tutorials/rcanvas/rline.cxx -q; ~~~. Or run `Xvfb` before starting ROOT:. ~~~; $ Xvfb :99 &; $ export DISPLAY=:99; $ root.exe -l --web=cef $ROOTSYS/tutorials/rcanvas/rline.cxx -q; ~~~. ## Compile CEF with ozone support. Since March 2019 one can compile [CEF without X11](https://bitbucket.org/chromiumembedded/cef/issues/2296/), but such builds not provided.; Therefore to be able to use real headless mode in CEF, one should compile it from sources.; On [CEF build tutorial](https://bitbucket.org/chromiumembedded/cef/wiki/AutomatedBuildSetup.md) one can find complete compilation documentation.; Several Ubuntu distributions are supported by CEF, all others may require extra work. Once all depndencies are installed,; CEF with ozone support can be compiled with following commands:. ~~~; $ export GN_DEFINES=""is_official_build=true use_sysroot=true use_allocator=none symbol_level=1 is_cfi=false use_thin_lto=false use_ozone=true""; $ python automate-git.py --download-dir=/home/user/cef --branch=4638 --minimal-distrib --client-distrib --force-clean --x64-build --build-target=cefsimple; ~~~. With little luck one get prepared tarballs in `/home/user/cef/chromium/src/cef/binary_distrib`.; Just install it in the same way as described before in this document.; ROOT will automatically detect that CEF build with `ozone` support and will use it for both interactive and headless modes. ",MatchSource.DOCS,gui/cefdisplay/Readme.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/cefdisplay/Readme.md
https://github.com/root-project/root/tree/v6-32-06/gui/cefdisplay/Readme.md:1100,Modifiability,variab,variable,1100,"ed Framework](https://bitbucket.org/chromiumembedded/cef). 1. Current code tested with CEF3 branch 5845, Chromium 116 (August 2023); Some older CEF versions (like 95 or 107) may also be supported. 2. Download binary code from [https://cef-builds.spotifycdn.com/index.html](https://cef-builds.spotifycdn.com/index.html); and unpack it in directory without spaces and special symbols:. ~~~; $ mkdir /d/cef; $ cd /d/cef/; $ wget https://cef-builds.spotifycdn.com/cef_binary_107.1.11%2Bg26c0b5e%2Bchromium-107.0.5304.110_linux64_minimal.tar.bz2; $ tar xjf cef_binary_107.1.11+g26c0b5e+chromium-107.0.5304.110_linux64_minimal.tar.bz2; ~~~. 3 Install prerequisites - see comments in package `CMakeLists.txt`.; For the linux these are: `build-essential`, `libgtk3.0-dev`. 4. Compile CEF to produce `libcef_dll_wrapper`:. ~~~; $ cd /d/cef/cef_binary_107.1.11+g26c0b5e+chromium-107.0.5304.110_linux64_minimal; $ mkdir build; $ cd build; $ cmake ..; $ make -j libcef_dll_wrapper; ~~~. 5. Set CEF_ROOT variable to unpacked directory:. ~~~; $ export CEF_ROOT=/d/cef/cef_binary_107.1.11+g26c0b5e+chromium-107.0.5304.110_linux64_minimal; ~~~. 6. When configure ROOT compilation with `cmake -Dwebgui=ON -Dcefweb=ON ...`, CEF_ROOT shell variable should be set appropriately.; During compilation library `$ROOTSYS/lib/libROOTCefDisplay.so` and executable `$ROOTSYS/bin/cef_main`; should be created. Also check that several files like `icudtl.dat`, `v8_context_snapshot_blob.bin`, `snapshot_blob.bin`; copied into ROOT library directory. 7. Run ROOT with `--web=cef` argument to use CEF web display like:. ~~~; $ root --web=cef $ROOTSYS/tutorials/rcanvas/rh2.cxx; ~~~. ## Compile libcef_dll_wrapper on Windows. 1. Download binary win32 build like https://cef-builds.spotifycdn.com/cef_binary_95.7.12%2Bg99c4ac0%2Bchromium-95.0.4638.54_windows32.tar.bz2. 2. Extract in directory without spaces like `C:\Soft\cef`. 3. Modify `cmake/cef_variables.cmake` to set dynamic linking, replace ""/MT"" by ""/MD"" in approx line 389. ",MatchSource.DOCS,gui/cefdisplay/Readme.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/cefdisplay/Readme.md
https://github.com/root-project/root/tree/v6-32-06/gui/cefdisplay/Readme.md:1246,Modifiability,config,configure,1246,"or 107) may also be supported. 2. Download binary code from [https://cef-builds.spotifycdn.com/index.html](https://cef-builds.spotifycdn.com/index.html); and unpack it in directory without spaces and special symbols:. ~~~; $ mkdir /d/cef; $ cd /d/cef/; $ wget https://cef-builds.spotifycdn.com/cef_binary_107.1.11%2Bg26c0b5e%2Bchromium-107.0.5304.110_linux64_minimal.tar.bz2; $ tar xjf cef_binary_107.1.11+g26c0b5e+chromium-107.0.5304.110_linux64_minimal.tar.bz2; ~~~. 3 Install prerequisites - see comments in package `CMakeLists.txt`.; For the linux these are: `build-essential`, `libgtk3.0-dev`. 4. Compile CEF to produce `libcef_dll_wrapper`:. ~~~; $ cd /d/cef/cef_binary_107.1.11+g26c0b5e+chromium-107.0.5304.110_linux64_minimal; $ mkdir build; $ cd build; $ cmake ..; $ make -j libcef_dll_wrapper; ~~~. 5. Set CEF_ROOT variable to unpacked directory:. ~~~; $ export CEF_ROOT=/d/cef/cef_binary_107.1.11+g26c0b5e+chromium-107.0.5304.110_linux64_minimal; ~~~. 6. When configure ROOT compilation with `cmake -Dwebgui=ON -Dcefweb=ON ...`, CEF_ROOT shell variable should be set appropriately.; During compilation library `$ROOTSYS/lib/libROOTCefDisplay.so` and executable `$ROOTSYS/bin/cef_main`; should be created. Also check that several files like `icudtl.dat`, `v8_context_snapshot_blob.bin`, `snapshot_blob.bin`; copied into ROOT library directory. 7. Run ROOT with `--web=cef` argument to use CEF web display like:. ~~~; $ root --web=cef $ROOTSYS/tutorials/rcanvas/rh2.cxx; ~~~. ## Compile libcef_dll_wrapper on Windows. 1. Download binary win32 build like https://cef-builds.spotifycdn.com/cef_binary_95.7.12%2Bg99c4ac0%2Bchromium-95.0.4638.54_windows32.tar.bz2. 2. Extract in directory without spaces like `C:\Soft\cef`. 3. Modify `cmake/cef_variables.cmake` to set dynamic linking, replace ""/MT"" by ""/MD"" in approx line 389. 4. Start ""x86 Native tools Command Prompt for VS 2019"". Do:; ~~~; $ cd C:\Soft\cef; $ mkdir build; $ cd build; $ cmake -G""Visual Studio 16 2019"" -A Win32 -Thost=x64 .",MatchSource.DOCS,gui/cefdisplay/Readme.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/cefdisplay/Readme.md
https://github.com/root-project/root/tree/v6-32-06/gui/cefdisplay/Readme.md:1330,Modifiability,variab,variable,1330,"ps://cef-builds.spotifycdn.com/index.html](https://cef-builds.spotifycdn.com/index.html); and unpack it in directory without spaces and special symbols:. ~~~; $ mkdir /d/cef; $ cd /d/cef/; $ wget https://cef-builds.spotifycdn.com/cef_binary_107.1.11%2Bg26c0b5e%2Bchromium-107.0.5304.110_linux64_minimal.tar.bz2; $ tar xjf cef_binary_107.1.11+g26c0b5e+chromium-107.0.5304.110_linux64_minimal.tar.bz2; ~~~. 3 Install prerequisites - see comments in package `CMakeLists.txt`.; For the linux these are: `build-essential`, `libgtk3.0-dev`. 4. Compile CEF to produce `libcef_dll_wrapper`:. ~~~; $ cd /d/cef/cef_binary_107.1.11+g26c0b5e+chromium-107.0.5304.110_linux64_minimal; $ mkdir build; $ cd build; $ cmake ..; $ make -j libcef_dll_wrapper; ~~~. 5. Set CEF_ROOT variable to unpacked directory:. ~~~; $ export CEF_ROOT=/d/cef/cef_binary_107.1.11+g26c0b5e+chromium-107.0.5304.110_linux64_minimal; ~~~. 6. When configure ROOT compilation with `cmake -Dwebgui=ON -Dcefweb=ON ...`, CEF_ROOT shell variable should be set appropriately.; During compilation library `$ROOTSYS/lib/libROOTCefDisplay.so` and executable `$ROOTSYS/bin/cef_main`; should be created. Also check that several files like `icudtl.dat`, `v8_context_snapshot_blob.bin`, `snapshot_blob.bin`; copied into ROOT library directory. 7. Run ROOT with `--web=cef` argument to use CEF web display like:. ~~~; $ root --web=cef $ROOTSYS/tutorials/rcanvas/rh2.cxx; ~~~. ## Compile libcef_dll_wrapper on Windows. 1. Download binary win32 build like https://cef-builds.spotifycdn.com/cef_binary_95.7.12%2Bg99c4ac0%2Bchromium-95.0.4638.54_windows32.tar.bz2. 2. Extract in directory without spaces like `C:\Soft\cef`. 3. Modify `cmake/cef_variables.cmake` to set dynamic linking, replace ""/MT"" by ""/MD"" in approx line 389. 4. Start ""x86 Native tools Command Prompt for VS 2019"". Do:; ~~~; $ cd C:\Soft\cef; $ mkdir build; $ cd build; $ cmake -G""Visual Studio 16 2019"" -A Win32 -Thost=x64 ..; $ cmake --build . --config Release --target libcef_dll_wrapper",MatchSource.DOCS,gui/cefdisplay/Readme.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/cefdisplay/Readme.md
https://github.com/root-project/root/tree/v6-32-06/gui/cefdisplay/Readme.md:2298,Modifiability,config,config,2298,"OOT shell variable should be set appropriately.; During compilation library `$ROOTSYS/lib/libROOTCefDisplay.so` and executable `$ROOTSYS/bin/cef_main`; should be created. Also check that several files like `icudtl.dat`, `v8_context_snapshot_blob.bin`, `snapshot_blob.bin`; copied into ROOT library directory. 7. Run ROOT with `--web=cef` argument to use CEF web display like:. ~~~; $ root --web=cef $ROOTSYS/tutorials/rcanvas/rh2.cxx; ~~~. ## Compile libcef_dll_wrapper on Windows. 1. Download binary win32 build like https://cef-builds.spotifycdn.com/cef_binary_95.7.12%2Bg99c4ac0%2Bchromium-95.0.4638.54_windows32.tar.bz2. 2. Extract in directory without spaces like `C:\Soft\cef`. 3. Modify `cmake/cef_variables.cmake` to set dynamic linking, replace ""/MT"" by ""/MD"" in approx line 389. 4. Start ""x86 Native tools Command Prompt for VS 2019"". Do:; ~~~; $ cd C:\Soft\cef; $ mkdir build; $ cd build; $ cmake -G""Visual Studio 16 2019"" -A Win32 -Thost=x64 ..; $ cmake --build . --config Release --target libcef_dll_wrapper; ~~~. 5. Before compiling ROOT, `set CEF_ROOT=C:\Soft\cef` variable. ## Using plain CEF in ROOT batch mode on Linux. Default CEF builds, provided by [https://cef-builds.spotifycdn.com/index.html](https://cef-builds.spotifycdn.com/index.html), do; not include support of Ozone framework, which the only support headless mode in CEF. To run ROOT in headless (or batch) made with such CEF distribution,; one can use `Xvfb` server. Most simple way is to use `xvfb-run` utility like:. ~~~; $ xvfb-run --server-args='-screen 0, 1024x768x16' root.exe -l --web=cef $ROOTSYS/tutorials/rcanvas/rline.cxx -q; ~~~. Or run `Xvfb` before starting ROOT:. ~~~; $ Xvfb :99 &; $ export DISPLAY=:99; $ root.exe -l --web=cef $ROOTSYS/tutorials/rcanvas/rline.cxx -q; ~~~. ## Compile CEF with ozone support. Since March 2019 one can compile [CEF without X11](https://bitbucket.org/chromiumembedded/cef/issues/2296/), but such builds not provided.; Therefore to be able to use real headless mode in CEF,",MatchSource.DOCS,gui/cefdisplay/Readme.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/cefdisplay/Readme.md
https://github.com/root-project/root/tree/v6-32-06/gui/cefdisplay/Readme.md:2400,Modifiability,variab,variable,2400,"pilation library `$ROOTSYS/lib/libROOTCefDisplay.so` and executable `$ROOTSYS/bin/cef_main`; should be created. Also check that several files like `icudtl.dat`, `v8_context_snapshot_blob.bin`, `snapshot_blob.bin`; copied into ROOT library directory. 7. Run ROOT with `--web=cef` argument to use CEF web display like:. ~~~; $ root --web=cef $ROOTSYS/tutorials/rcanvas/rh2.cxx; ~~~. ## Compile libcef_dll_wrapper on Windows. 1. Download binary win32 build like https://cef-builds.spotifycdn.com/cef_binary_95.7.12%2Bg99c4ac0%2Bchromium-95.0.4638.54_windows32.tar.bz2. 2. Extract in directory without spaces like `C:\Soft\cef`. 3. Modify `cmake/cef_variables.cmake` to set dynamic linking, replace ""/MT"" by ""/MD"" in approx line 389. 4. Start ""x86 Native tools Command Prompt for VS 2019"". Do:; ~~~; $ cd C:\Soft\cef; $ mkdir build; $ cd build; $ cmake -G""Visual Studio 16 2019"" -A Win32 -Thost=x64 ..; $ cmake --build . --config Release --target libcef_dll_wrapper; ~~~. 5. Before compiling ROOT, `set CEF_ROOT=C:\Soft\cef` variable. ## Using plain CEF in ROOT batch mode on Linux. Default CEF builds, provided by [https://cef-builds.spotifycdn.com/index.html](https://cef-builds.spotifycdn.com/index.html), do; not include support of Ozone framework, which the only support headless mode in CEF. To run ROOT in headless (or batch) made with such CEF distribution,; one can use `Xvfb` server. Most simple way is to use `xvfb-run` utility like:. ~~~; $ xvfb-run --server-args='-screen 0, 1024x768x16' root.exe -l --web=cef $ROOTSYS/tutorials/rcanvas/rline.cxx -q; ~~~. Or run `Xvfb` before starting ROOT:. ~~~; $ Xvfb :99 &; $ export DISPLAY=:99; $ root.exe -l --web=cef $ROOTSYS/tutorials/rcanvas/rline.cxx -q; ~~~. ## Compile CEF with ozone support. Since March 2019 one can compile [CEF without X11](https://bitbucket.org/chromiumembedded/cef/issues/2296/), but such builds not provided.; Therefore to be able to use real headless mode in CEF, one should compile it from sources.; On [CEF build tutori",MatchSource.DOCS,gui/cefdisplay/Readme.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/cefdisplay/Readme.md
https://github.com/root-project/root/tree/v6-32-06/gui/cefdisplay/Readme.md:4195,Safety,detect,detect,4195," --config Release --target libcef_dll_wrapper; ~~~. 5. Before compiling ROOT, `set CEF_ROOT=C:\Soft\cef` variable. ## Using plain CEF in ROOT batch mode on Linux. Default CEF builds, provided by [https://cef-builds.spotifycdn.com/index.html](https://cef-builds.spotifycdn.com/index.html), do; not include support of Ozone framework, which the only support headless mode in CEF. To run ROOT in headless (or batch) made with such CEF distribution,; one can use `Xvfb` server. Most simple way is to use `xvfb-run` utility like:. ~~~; $ xvfb-run --server-args='-screen 0, 1024x768x16' root.exe -l --web=cef $ROOTSYS/tutorials/rcanvas/rline.cxx -q; ~~~. Or run `Xvfb` before starting ROOT:. ~~~; $ Xvfb :99 &; $ export DISPLAY=:99; $ root.exe -l --web=cef $ROOTSYS/tutorials/rcanvas/rline.cxx -q; ~~~. ## Compile CEF with ozone support. Since March 2019 one can compile [CEF without X11](https://bitbucket.org/chromiumembedded/cef/issues/2296/), but such builds not provided.; Therefore to be able to use real headless mode in CEF, one should compile it from sources.; On [CEF build tutorial](https://bitbucket.org/chromiumembedded/cef/wiki/AutomatedBuildSetup.md) one can find complete compilation documentation.; Several Ubuntu distributions are supported by CEF, all others may require extra work. Once all depndencies are installed,; CEF with ozone support can be compiled with following commands:. ~~~; $ export GN_DEFINES=""is_official_build=true use_sysroot=true use_allocator=none symbol_level=1 is_cfi=false use_thin_lto=false use_ozone=true""; $ python automate-git.py --download-dir=/home/user/cef --branch=4638 --minimal-distrib --client-distrib --force-clean --x64-build --build-target=cefsimple; ~~~. With little luck one get prepared tarballs in `/home/user/cef/chromium/src/cef/binary_distrib`.; Just install it in the same way as described before in this document.; ROOT will automatically detect that CEF build with `ozone` support and will use it for both interactive and headless modes. ",MatchSource.DOCS,gui/cefdisplay/Readme.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/cefdisplay/Readme.md
https://github.com/root-project/root/tree/v6-32-06/gui/cefdisplay/Readme.md:184,Testability,test,tested,184,"\page cefpage ROOT installation with CEF. ## Compilation with CEF support. See details about [Chromium Embedded Framework](https://bitbucket.org/chromiumembedded/cef). 1. Current code tested with CEF3 branch 5845, Chromium 116 (August 2023); Some older CEF versions (like 95 or 107) may also be supported. 2. Download binary code from [https://cef-builds.spotifycdn.com/index.html](https://cef-builds.spotifycdn.com/index.html); and unpack it in directory without spaces and special symbols:. ~~~; $ mkdir /d/cef; $ cd /d/cef/; $ wget https://cef-builds.spotifycdn.com/cef_binary_107.1.11%2Bg26c0b5e%2Bchromium-107.0.5304.110_linux64_minimal.tar.bz2; $ tar xjf cef_binary_107.1.11+g26c0b5e+chromium-107.0.5304.110_linux64_minimal.tar.bz2; ~~~. 3 Install prerequisites - see comments in package `CMakeLists.txt`.; For the linux these are: `build-essential`, `libgtk3.0-dev`. 4. Compile CEF to produce `libcef_dll_wrapper`:. ~~~; $ cd /d/cef/cef_binary_107.1.11+g26c0b5e+chromium-107.0.5304.110_linux64_minimal; $ mkdir build; $ cd build; $ cmake ..; $ make -j libcef_dll_wrapper; ~~~. 5. Set CEF_ROOT variable to unpacked directory:. ~~~; $ export CEF_ROOT=/d/cef/cef_binary_107.1.11+g26c0b5e+chromium-107.0.5304.110_linux64_minimal; ~~~. 6. When configure ROOT compilation with `cmake -Dwebgui=ON -Dcefweb=ON ...`, CEF_ROOT shell variable should be set appropriately.; During compilation library `$ROOTSYS/lib/libROOTCefDisplay.so` and executable `$ROOTSYS/bin/cef_main`; should be created. Also check that several files like `icudtl.dat`, `v8_context_snapshot_blob.bin`, `snapshot_blob.bin`; copied into ROOT library directory. 7. Run ROOT with `--web=cef` argument to use CEF web display like:. ~~~; $ root --web=cef $ROOTSYS/tutorials/rcanvas/rh2.cxx; ~~~. ## Compile libcef_dll_wrapper on Windows. 1. Download binary win32 build like https://cef-builds.spotifycdn.com/cef_binary_95.7.12%2Bg99c4ac0%2Bchromium-95.0.4638.54_windows32.tar.bz2. 2. Extract in directory without spaces like `C:\Soft\cef",MatchSource.DOCS,gui/cefdisplay/Readme.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/cefdisplay/Readme.md
https://github.com/root-project/root/tree/v6-32-06/gui/cefdisplay/Readme.md:2774,Usability,simpl,simple,2774,"indows. 1. Download binary win32 build like https://cef-builds.spotifycdn.com/cef_binary_95.7.12%2Bg99c4ac0%2Bchromium-95.0.4638.54_windows32.tar.bz2. 2. Extract in directory without spaces like `C:\Soft\cef`. 3. Modify `cmake/cef_variables.cmake` to set dynamic linking, replace ""/MT"" by ""/MD"" in approx line 389. 4. Start ""x86 Native tools Command Prompt for VS 2019"". Do:; ~~~; $ cd C:\Soft\cef; $ mkdir build; $ cd build; $ cmake -G""Visual Studio 16 2019"" -A Win32 -Thost=x64 ..; $ cmake --build . --config Release --target libcef_dll_wrapper; ~~~. 5. Before compiling ROOT, `set CEF_ROOT=C:\Soft\cef` variable. ## Using plain CEF in ROOT batch mode on Linux. Default CEF builds, provided by [https://cef-builds.spotifycdn.com/index.html](https://cef-builds.spotifycdn.com/index.html), do; not include support of Ozone framework, which the only support headless mode in CEF. To run ROOT in headless (or batch) made with such CEF distribution,; one can use `Xvfb` server. Most simple way is to use `xvfb-run` utility like:. ~~~; $ xvfb-run --server-args='-screen 0, 1024x768x16' root.exe -l --web=cef $ROOTSYS/tutorials/rcanvas/rline.cxx -q; ~~~. Or run `Xvfb` before starting ROOT:. ~~~; $ Xvfb :99 &; $ export DISPLAY=:99; $ root.exe -l --web=cef $ROOTSYS/tutorials/rcanvas/rline.cxx -q; ~~~. ## Compile CEF with ozone support. Since March 2019 one can compile [CEF without X11](https://bitbucket.org/chromiumembedded/cef/issues/2296/), but such builds not provided.; Therefore to be able to use real headless mode in CEF, one should compile it from sources.; On [CEF build tutorial](https://bitbucket.org/chromiumembedded/cef/wiki/AutomatedBuildSetup.md) one can find complete compilation documentation.; Several Ubuntu distributions are supported by CEF, all others may require extra work. Once all depndencies are installed,; CEF with ozone support can be compiled with following commands:. ~~~; $ export GN_DEFINES=""is_official_build=true use_sysroot=true use_allocator=none symbol_level=1 i",MatchSource.DOCS,gui/cefdisplay/Readme.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/cefdisplay/Readme.md
https://github.com/root-project/root/tree/v6-32-06/gui/doc/index.md:139,Integrability,interface,interface,139,\defgroup gui GUI; \brief Graphical User Interface. The ROOT GUI classes support an extensive and rich set of widgets. The widget classes; interface to the underlying graphics system via a single abstract class making the ROOT GUI; fully cross-platform. \defgroup webwidgets Web Widgets; \brief A Graphical User Interface based on WEB technology; ,MatchSource.DOCS,gui/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/gui/doc/v600/index.md:220,Modifiability,extend,extended,220,"## GUI Libraries. ### Attributes editors. - The transparency sliders change the transparency only for the currently edited object. ### Object editing on canvas. - The ""move opaque"" way to edit object on canvas, has been extended to all kind of objects.; - When in move opaque mode, a canvas can show guide lines to place object relatively to each other. A new resource in `etc/system.rootrc` allows to turn the feature on or off: `Canvas.ShowGuideLines`.; - For a fine adjustment at the pixel level, the arrow keys can be used to move object on pad.; - The zoom on axis and on 2D histogram has been improved. A shaded area is shown instead of simple lines. Also it is possible to zoom a 2D histogram with a shaded rectangle. ### Saving Files; - When saving files from a canvas, the default file type is now .pdf instead of .ps, since pdf is probably becoming more popular than ps.; - In the ""File Save Dialog"", there is now a default file name and its extension (if a specific one is selected), and the name is highlighted, so when the user types something, only the file name is changed.; - The default file type can be changed with a new `Canvas.SaveAsDefaultType` option in `etc/system.rootrc` (default being pdf). ### ROOT browser and pad editor; - The Pad Editor is now embedded in the left tab of the browser instead of inside the canvas itself, so the layout of the canvas remains untouched when opening the editor. ",MatchSource.DOCS,gui/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/gui/doc/v600/index.md:300,Usability,guid,guide,300,"## GUI Libraries. ### Attributes editors. - The transparency sliders change the transparency only for the currently edited object. ### Object editing on canvas. - The ""move opaque"" way to edit object on canvas, has been extended to all kind of objects.; - When in move opaque mode, a canvas can show guide lines to place object relatively to each other. A new resource in `etc/system.rootrc` allows to turn the feature on or off: `Canvas.ShowGuideLines`.; - For a fine adjustment at the pixel level, the arrow keys can be used to move object on pad.; - The zoom on axis and on 2D histogram has been improved. A shaded area is shown instead of simple lines. Also it is possible to zoom a 2D histogram with a shaded rectangle. ### Saving Files; - When saving files from a canvas, the default file type is now .pdf instead of .ps, since pdf is probably becoming more popular than ps.; - In the ""File Save Dialog"", there is now a default file name and its extension (if a specific one is selected), and the name is highlighted, so when the user types something, only the file name is changed.; - The default file type can be changed with a new `Canvas.SaveAsDefaultType` option in `etc/system.rootrc` (default being pdf). ### ROOT browser and pad editor; - The Pad Editor is now embedded in the left tab of the browser instead of inside the canvas itself, so the layout of the canvas remains untouched when opening the editor. ",MatchSource.DOCS,gui/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/gui/doc/v600/index.md:643,Usability,simpl,simple,643,"## GUI Libraries. ### Attributes editors. - The transparency sliders change the transparency only for the currently edited object. ### Object editing on canvas. - The ""move opaque"" way to edit object on canvas, has been extended to all kind of objects.; - When in move opaque mode, a canvas can show guide lines to place object relatively to each other. A new resource in `etc/system.rootrc` allows to turn the feature on or off: `Canvas.ShowGuideLines`.; - For a fine adjustment at the pixel level, the arrow keys can be used to move object on pad.; - The zoom on axis and on 2D histogram has been improved. A shaded area is shown instead of simple lines. Also it is possible to zoom a 2D histogram with a shaded rectangle. ### Saving Files; - When saving files from a canvas, the default file type is now .pdf instead of .ps, since pdf is probably becoming more popular than ps.; - In the ""File Save Dialog"", there is now a default file name and its extension (if a specific one is selected), and the name is highlighted, so when the user types something, only the file name is changed.; - The default file type can be changed with a new `Canvas.SaveAsDefaultType` option in `etc/system.rootrc` (default being pdf). ### ROOT browser and pad editor; - The Pad Editor is now embedded in the left tab of the browser instead of inside the canvas itself, so the layout of the canvas remains untouched when opening the editor. ",MatchSource.DOCS,gui/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/gui/fitpanel/doc/index.md:1697,Availability,error,error,1697,"s not; prevent users from interacting with other windows. Its first prototype; is a singleton application. When the Fit Panel is activated, users can; select an object for fitting in the usual way, i.e. by left-mouse; click on it. If the selected object is suitable for fitting, the fit; panel is connected with this object and users can perform fits by; setting different parameters and options. ### Function Choice and Settings. *‘Predefined' combo box* - contains a list of predefined functions in; ROOT. You have a choice of several polynomials, a Gaussian, a Landau,; and an Exponential function. The default one is Gaussian. *‘Operation' radio button group* defines the selected operational mode; between functions:. *Nop* - no operation (default);. *Add* - addition;. *Conv* - convolution (will be implemented in the future). Users can enter the function expression into the text entry field; below the ‘Predefined' combo box. The entered string is checked after; the Enter key was pressed and an error message shows up, if the; function string is not accepted. ‘*Set Parameters*' button opens a dialog for parameters settings,; which will be explained later. ### Fitter Settings. *‘Method' combo box* currently provides only two fit model choices:; Chi-square and Binned Likelihood. The default one is Chi-square. The; Binned Likelihood is recommended for bins with low statistics. *‘Linear Fit' check button* sets the use of Linear fitter when is; selected. Otherwise the minimization is done by Minuit, i.e. fit; option ""`F`"" is applied. The Linear fitter can be selected only for; functions linear in parameters (for example - `polN)`. *‘Robust' number entry* sets the robust value when fitting graphs. *‘No Chi-square' check button* switch On/Off the fit option ""`C`"" -; do not calculate Chi-square (for Linear fitter). *‘Integral' check button* switch On/Off the option ""`I`"" - use; integral of function instead of value in bin center. *‘Best Errors'* sets On/Off the option ""`E`"" - bette",MatchSource.DOCS,gui/fitpanel/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/fitpanel/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/gui/fitpanel/doc/index.md:2373,Availability,robust,robust,2373,"ected operational mode; between functions:. *Nop* - no operation (default);. *Add* - addition;. *Conv* - convolution (will be implemented in the future). Users can enter the function expression into the text entry field; below the ‘Predefined' combo box. The entered string is checked after; the Enter key was pressed and an error message shows up, if the; function string is not accepted. ‘*Set Parameters*' button opens a dialog for parameters settings,; which will be explained later. ### Fitter Settings. *‘Method' combo box* currently provides only two fit model choices:; Chi-square and Binned Likelihood. The default one is Chi-square. The; Binned Likelihood is recommended for bins with low statistics. *‘Linear Fit' check button* sets the use of Linear fitter when is; selected. Otherwise the minimization is done by Minuit, i.e. fit; option ""`F`"" is applied. The Linear fitter can be selected only for; functions linear in parameters (for example - `polN)`. *‘Robust' number entry* sets the robust value when fitting graphs. *‘No Chi-square' check button* switch On/Off the fit option ""`C`"" -; do not calculate Chi-square (for Linear fitter). *‘Integral' check button* switch On/Off the option ""`I`"" - use; integral of function instead of value in bin center. *‘Best Errors'* sets On/Off the option ""`E`"" - better errors; estimation by using Minos technique. *‘All weights = 1'* sets On/Off the option ""`W`""- all weights set to 1; excluding empty bins; error bars ignored. *‘Empty bins, weights=1'* sets On/Off the option ""`WW`"" - all weights; equal to 1 including empty bins; error bars ignored. *‘Use range'* sets On/Off the option ""`R`"" - fit only data within the; specified function range. Sliders settings are used if this option is; set to On. Users can change the function range values by pressing the; left mouse button near to the left/right slider edges. It is possible; to change both values simultaneously by pressing the left mouse button; near to the slider center and moving i",MatchSource.DOCS,gui/fitpanel/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/fitpanel/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/gui/fitpanel/doc/index.md:2696,Availability,error,errors,2696,"and an error message shows up, if the; function string is not accepted. ‘*Set Parameters*' button opens a dialog for parameters settings,; which will be explained later. ### Fitter Settings. *‘Method' combo box* currently provides only two fit model choices:; Chi-square and Binned Likelihood. The default one is Chi-square. The; Binned Likelihood is recommended for bins with low statistics. *‘Linear Fit' check button* sets the use of Linear fitter when is; selected. Otherwise the minimization is done by Minuit, i.e. fit; option ""`F`"" is applied. The Linear fitter can be selected only for; functions linear in parameters (for example - `polN)`. *‘Robust' number entry* sets the robust value when fitting graphs. *‘No Chi-square' check button* switch On/Off the fit option ""`C`"" -; do not calculate Chi-square (for Linear fitter). *‘Integral' check button* switch On/Off the option ""`I`"" - use; integral of function instead of value in bin center. *‘Best Errors'* sets On/Off the option ""`E`"" - better errors; estimation by using Minos technique. *‘All weights = 1'* sets On/Off the option ""`W`""- all weights set to 1; excluding empty bins; error bars ignored. *‘Empty bins, weights=1'* sets On/Off the option ""`WW`"" - all weights; equal to 1 including empty bins; error bars ignored. *‘Use range'* sets On/Off the option ""`R`"" - fit only data within the; specified function range. Sliders settings are used if this option is; set to On. Users can change the function range values by pressing the; left mouse button near to the left/right slider edges. It is possible; to change both values simultaneously by pressing the left mouse button; near to the slider center and moving it to a new position. *‘Improve fit results'* sets On/Off the option ""`M`""- after minimum is; found, search for a new one. *‘Add to list'* sets On/Off the option ""`+`""- add function to the list; without deleting the previous one. When fitting a histogram, the; function is attached to the histogram's list of functions.",MatchSource.DOCS,gui/fitpanel/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/fitpanel/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/gui/fitpanel/doc/index.md:2835,Availability,error,error,2835,"ialog for parameters settings,; which will be explained later. ### Fitter Settings. *‘Method' combo box* currently provides only two fit model choices:; Chi-square and Binned Likelihood. The default one is Chi-square. The; Binned Likelihood is recommended for bins with low statistics. *‘Linear Fit' check button* sets the use of Linear fitter when is; selected. Otherwise the minimization is done by Minuit, i.e. fit; option ""`F`"" is applied. The Linear fitter can be selected only for; functions linear in parameters (for example - `polN)`. *‘Robust' number entry* sets the robust value when fitting graphs. *‘No Chi-square' check button* switch On/Off the fit option ""`C`"" -; do not calculate Chi-square (for Linear fitter). *‘Integral' check button* switch On/Off the option ""`I`"" - use; integral of function instead of value in bin center. *‘Best Errors'* sets On/Off the option ""`E`"" - better errors; estimation by using Minos technique. *‘All weights = 1'* sets On/Off the option ""`W`""- all weights set to 1; excluding empty bins; error bars ignored. *‘Empty bins, weights=1'* sets On/Off the option ""`WW`"" - all weights; equal to 1 including empty bins; error bars ignored. *‘Use range'* sets On/Off the option ""`R`"" - fit only data within the; specified function range. Sliders settings are used if this option is; set to On. Users can change the function range values by pressing the; left mouse button near to the left/right slider edges. It is possible; to change both values simultaneously by pressing the left mouse button; near to the slider center and moving it to a new position. *‘Improve fit results'* sets On/Off the option ""`M`""- after minimum is; found, search for a new one. *‘Add to list'* sets On/Off the option ""`+`""- add function to the list; without deleting the previous one. When fitting a histogram, the; function is attached to the histogram's list of functions. By default,; the previously fitted function is deleted and replaced with the most; recent one, so the lis",MatchSource.DOCS,gui/fitpanel/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/fitpanel/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/gui/fitpanel/doc/index.md:2959,Availability,error,error,2959,"ides only two fit model choices:; Chi-square and Binned Likelihood. The default one is Chi-square. The; Binned Likelihood is recommended for bins with low statistics. *‘Linear Fit' check button* sets the use of Linear fitter when is; selected. Otherwise the minimization is done by Minuit, i.e. fit; option ""`F`"" is applied. The Linear fitter can be selected only for; functions linear in parameters (for example - `polN)`. *‘Robust' number entry* sets the robust value when fitting graphs. *‘No Chi-square' check button* switch On/Off the fit option ""`C`"" -; do not calculate Chi-square (for Linear fitter). *‘Integral' check button* switch On/Off the option ""`I`"" - use; integral of function instead of value in bin center. *‘Best Errors'* sets On/Off the option ""`E`"" - better errors; estimation by using Minos technique. *‘All weights = 1'* sets On/Off the option ""`W`""- all weights set to 1; excluding empty bins; error bars ignored. *‘Empty bins, weights=1'* sets On/Off the option ""`WW`"" - all weights; equal to 1 including empty bins; error bars ignored. *‘Use range'* sets On/Off the option ""`R`"" - fit only data within the; specified function range. Sliders settings are used if this option is; set to On. Users can change the function range values by pressing the; left mouse button near to the left/right slider edges. It is possible; to change both values simultaneously by pressing the left mouse button; near to the slider center and moving it to a new position. *‘Improve fit results'* sets On/Off the option ""`M`""- after minimum is; found, search for a new one. *‘Add to list'* sets On/Off the option ""`+`""- add function to the list; without deleting the previous one. When fitting a histogram, the; function is attached to the histogram's list of functions. By default,; the previously fitted function is deleted and replaced with the most; recent one, so the list only contains one function. Setting this; option to On will add the newly fitted function to the existing list; of fu",MatchSource.DOCS,gui/fitpanel/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/fitpanel/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/gui/fitpanel/doc/index.md:6163,Availability,toler,tolerance,6163," *‘No drawing'* sets On/Off the option ""`0`""- do not draw the fit; results. *‘Do not store/draw'* sets On/Off option ""`N`""- do not store the; function and do not draw it. ### Advances Options. The advance option button is enabled only after having performed the fit and provides; additional drawing options that can be used after having done the fit. These new drawing tools,; which can be selected by the ""Advanced Drawing Tool"" panel that pops up when clicking the ""Advanced"" button, are:. * *Contour*: to plot the confidence contour of two chosen parameters. One can select the number of points to draw the contour; (more points might require more time to compute it), the parameters and the desired confidence level . * *Scan* : to plot a scan of the minimization function (likelihood or chi-squared) around the minimum as function of the chosen parameter. * *Conf Interval* : to plot the confidence interval of the fitted function as a filled coloured band around its central value.; One can select the desired confidence level for the band to be plotted. ### Print Options. This set of options specifies the amount of feedback printed on the; root command line after performed fits. *‘Verbose'* - prints fit results after each iteration. *‘Quiet'* - no fit information is printed. *‘Default'* - between Verbose and Quiet. ### Command Buttons. *Fit button* - performs a fit taking different option settings via the; Fit Panel interface. *Reset* - sets the GUI elements and related fit settings to the; default ones. *Close* - closes the Fit panel window. ### Minimization Options. With this tab one can select specific options for minimization. These include. * The minimizer library ( *Minuit*, *Minuit2*, *Fumili*, *GSL*, *Genetics* ); * The method (algorithm) for minimization. For example for Minuit one can choose between (*Migrad*, *Simplex* or *Scan*); * Error definition; * Minimization tolerance; * Number of iterations/function calls; * Print Level: (*Default*, *Verbose* or *Quiet*). ",MatchSource.DOCS,gui/fitpanel/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/fitpanel/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/gui/fitpanel/doc/index.md:81,Integrability,interface,interface,81,"\defgroup fitpanel ROOT Fit Panel; \ingroup gui; \brief Classes forming the user interface of the Fit Panel in ROOT. ## The Fit Panel. \image html fitpanel.png. To display the Fit Panel right click on a histogram to pop up the; context menu, and then select the menu entry Fit Panel. By design, this user interface is planned to contain two tabs:; ""General"" and ""Minimization"". Currently, the ""General"" tab provides; user interface elements for setting the fit function, fit method and; different fit, draw, print options.; The ""Minimization tab"" provides the option to set the Minimizer to use in the fit and; its specific options. The fit panel is a modeless dialog, i.e. when opened, it does not; prevent users from interacting with other windows. Its first prototype; is a singleton application. When the Fit Panel is activated, users can; select an object for fitting in the usual way, i.e. by left-mouse; click on it. If the selected object is suitable for fitting, the fit; panel is connected with this object and users can perform fits by; setting different parameters and options. ### Function Choice and Settings. *‘Predefined' combo box* - contains a list of predefined functions in; ROOT. You have a choice of several polynomials, a Gaussian, a Landau,; and an Exponential function. The default one is Gaussian. *‘Operation' radio button group* defines the selected operational mode; between functions:. *Nop* - no operation (default);. *Add* - addition;. *Conv* - convolution (will be implemented in the future). Users can enter the function expression into the text entry field; below the ‘Predefined' combo box. The entered string is checked after; the Enter key was pressed and an error message shows up, if the; function string is not accepted. ‘*Set Parameters*' button opens a dialog for parameters settings,; which will be explained later. ### Fitter Settings. *‘Method' combo box* currently provides only two fit model choices:; Chi-square and Binned Likelihood. The default one i",MatchSource.DOCS,gui/fitpanel/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/fitpanel/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/gui/fitpanel/doc/index.md:305,Integrability,interface,interface,305,"\defgroup fitpanel ROOT Fit Panel; \ingroup gui; \brief Classes forming the user interface of the Fit Panel in ROOT. ## The Fit Panel. \image html fitpanel.png. To display the Fit Panel right click on a histogram to pop up the; context menu, and then select the menu entry Fit Panel. By design, this user interface is planned to contain two tabs:; ""General"" and ""Minimization"". Currently, the ""General"" tab provides; user interface elements for setting the fit function, fit method and; different fit, draw, print options.; The ""Minimization tab"" provides the option to set the Minimizer to use in the fit and; its specific options. The fit panel is a modeless dialog, i.e. when opened, it does not; prevent users from interacting with other windows. Its first prototype; is a singleton application. When the Fit Panel is activated, users can; select an object for fitting in the usual way, i.e. by left-mouse; click on it. If the selected object is suitable for fitting, the fit; panel is connected with this object and users can perform fits by; setting different parameters and options. ### Function Choice and Settings. *‘Predefined' combo box* - contains a list of predefined functions in; ROOT. You have a choice of several polynomials, a Gaussian, a Landau,; and an Exponential function. The default one is Gaussian. *‘Operation' radio button group* defines the selected operational mode; between functions:. *Nop* - no operation (default);. *Add* - addition;. *Conv* - convolution (will be implemented in the future). Users can enter the function expression into the text entry field; below the ‘Predefined' combo box. The entered string is checked after; the Enter key was pressed and an error message shows up, if the; function string is not accepted. ‘*Set Parameters*' button opens a dialog for parameters settings,; which will be explained later. ### Fitter Settings. *‘Method' combo box* currently provides only two fit model choices:; Chi-square and Binned Likelihood. The default one i",MatchSource.DOCS,gui/fitpanel/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/fitpanel/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/gui/fitpanel/doc/index.md:422,Integrability,interface,interface,422,"\defgroup fitpanel ROOT Fit Panel; \ingroup gui; \brief Classes forming the user interface of the Fit Panel in ROOT. ## The Fit Panel. \image html fitpanel.png. To display the Fit Panel right click on a histogram to pop up the; context menu, and then select the menu entry Fit Panel. By design, this user interface is planned to contain two tabs:; ""General"" and ""Minimization"". Currently, the ""General"" tab provides; user interface elements for setting the fit function, fit method and; different fit, draw, print options.; The ""Minimization tab"" provides the option to set the Minimizer to use in the fit and; its specific options. The fit panel is a modeless dialog, i.e. when opened, it does not; prevent users from interacting with other windows. Its first prototype; is a singleton application. When the Fit Panel is activated, users can; select an object for fitting in the usual way, i.e. by left-mouse; click on it. If the selected object is suitable for fitting, the fit; panel is connected with this object and users can perform fits by; setting different parameters and options. ### Function Choice and Settings. *‘Predefined' combo box* - contains a list of predefined functions in; ROOT. You have a choice of several polynomials, a Gaussian, a Landau,; and an Exponential function. The default one is Gaussian. *‘Operation' radio button group* defines the selected operational mode; between functions:. *Nop* - no operation (default);. *Add* - addition;. *Conv* - convolution (will be implemented in the future). Users can enter the function expression into the text entry field; below the ‘Predefined' combo box. The entered string is checked after; the Enter key was pressed and an error message shows up, if the; function string is not accepted. ‘*Set Parameters*' button opens a dialog for parameters settings,; which will be explained later. ### Fitter Settings. *‘Method' combo box* currently provides only two fit model choices:; Chi-square and Binned Likelihood. The default one i",MatchSource.DOCS,gui/fitpanel/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/fitpanel/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/gui/fitpanel/doc/index.md:1703,Integrability,message,message,1703,"s not; prevent users from interacting with other windows. Its first prototype; is a singleton application. When the Fit Panel is activated, users can; select an object for fitting in the usual way, i.e. by left-mouse; click on it. If the selected object is suitable for fitting, the fit; panel is connected with this object and users can perform fits by; setting different parameters and options. ### Function Choice and Settings. *‘Predefined' combo box* - contains a list of predefined functions in; ROOT. You have a choice of several polynomials, a Gaussian, a Landau,; and an Exponential function. The default one is Gaussian. *‘Operation' radio button group* defines the selected operational mode; between functions:. *Nop* - no operation (default);. *Add* - addition;. *Conv* - convolution (will be implemented in the future). Users can enter the function expression into the text entry field; below the ‘Predefined' combo box. The entered string is checked after; the Enter key was pressed and an error message shows up, if the; function string is not accepted. ‘*Set Parameters*' button opens a dialog for parameters settings,; which will be explained later. ### Fitter Settings. *‘Method' combo box* currently provides only two fit model choices:; Chi-square and Binned Likelihood. The default one is Chi-square. The; Binned Likelihood is recommended for bins with low statistics. *‘Linear Fit' check button* sets the use of Linear fitter when is; selected. Otherwise the minimization is done by Minuit, i.e. fit; option ""`F`"" is applied. The Linear fitter can be selected only for; functions linear in parameters (for example - `polN)`. *‘Robust' number entry* sets the robust value when fitting graphs. *‘No Chi-square' check button* switch On/Off the fit option ""`C`"" -; do not calculate Chi-square (for Linear fitter). *‘Integral' check button* switch On/Off the option ""`I`"" - use; integral of function instead of value in bin center. *‘Best Errors'* sets On/Off the option ""`E`"" - bette",MatchSource.DOCS,gui/fitpanel/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/fitpanel/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/gui/fitpanel/doc/index.md:5694,Integrability,interface,interface,5694," *‘No drawing'* sets On/Off the option ""`0`""- do not draw the fit; results. *‘Do not store/draw'* sets On/Off option ""`N`""- do not store the; function and do not draw it. ### Advances Options. The advance option button is enabled only after having performed the fit and provides; additional drawing options that can be used after having done the fit. These new drawing tools,; which can be selected by the ""Advanced Drawing Tool"" panel that pops up when clicking the ""Advanced"" button, are:. * *Contour*: to plot the confidence contour of two chosen parameters. One can select the number of points to draw the contour; (more points might require more time to compute it), the parameters and the desired confidence level . * *Scan* : to plot a scan of the minimization function (likelihood or chi-squared) around the minimum as function of the chosen parameter. * *Conf Interval* : to plot the confidence interval of the fitted function as a filled coloured band around its central value.; One can select the desired confidence level for the band to be plotted. ### Print Options. This set of options specifies the amount of feedback printed on the; root command line after performed fits. *‘Verbose'* - prints fit results after each iteration. *‘Quiet'* - no fit information is printed. *‘Default'* - between Verbose and Quiet. ### Command Buttons. *Fit button* - performs a fit taking different option settings via the; Fit Panel interface. *Reset* - sets the GUI elements and related fit settings to the; default ones. *Close* - closes the Fit panel window. ### Minimization Options. With this tab one can select specific options for minimization. These include. * The minimizer library ( *Minuit*, *Minuit2*, *Fumili*, *GSL*, *Genetics* ); * The method (algorithm) for minimization. For example for Minuit one can choose between (*Migrad*, *Simplex* or *Scan*); * Error definition; * Minimization tolerance; * Number of iterations/function calls; * Print Level: (*Default*, *Verbose* or *Quiet*). ",MatchSource.DOCS,gui/fitpanel/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/fitpanel/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/gui/fitpanel/doc/index.md:1031,Performance,perform,perform,1031,"oup fitpanel ROOT Fit Panel; \ingroup gui; \brief Classes forming the user interface of the Fit Panel in ROOT. ## The Fit Panel. \image html fitpanel.png. To display the Fit Panel right click on a histogram to pop up the; context menu, and then select the menu entry Fit Panel. By design, this user interface is planned to contain two tabs:; ""General"" and ""Minimization"". Currently, the ""General"" tab provides; user interface elements for setting the fit function, fit method and; different fit, draw, print options.; The ""Minimization tab"" provides the option to set the Minimizer to use in the fit and; its specific options. The fit panel is a modeless dialog, i.e. when opened, it does not; prevent users from interacting with other windows. Its first prototype; is a singleton application. When the Fit Panel is activated, users can; select an object for fitting in the usual way, i.e. by left-mouse; click on it. If the selected object is suitable for fitting, the fit; panel is connected with this object and users can perform fits by; setting different parameters and options. ### Function Choice and Settings. *‘Predefined' combo box* - contains a list of predefined functions in; ROOT. You have a choice of several polynomials, a Gaussian, a Landau,; and an Exponential function. The default one is Gaussian. *‘Operation' radio button group* defines the selected operational mode; between functions:. *Nop* - no operation (default);. *Add* - addition;. *Conv* - convolution (will be implemented in the future). Users can enter the function expression into the text entry field; below the ‘Predefined' combo box. The entered string is checked after; the Enter key was pressed and an error message shows up, if the; function string is not accepted. ‘*Set Parameters*' button opens a dialog for parameters settings,; which will be explained later. ### Fitter Settings. *‘Method' combo box* currently provides only two fit model choices:; Chi-square and Binned Likelihood. The default one is Chi",MatchSource.DOCS,gui/fitpanel/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/fitpanel/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/gui/fitpanel/doc/index.md:4511,Performance,perform,performed,4511,"""`+`""- add function to the list; without deleting the previous one. When fitting a histogram, the; function is attached to the histogram's list of functions. By default,; the previously fitted function is deleted and replaced with the most; recent one, so the list only contains one function. Setting this; option to On will add the newly fitted function to the existing list; of functions for the histogram. Note that the fitted functions are; saved with the histogram when it is written to a ROOT file. By; default, the function is drawn on the pad displaying the histogram. ### Draw Options. *‘SAME'* sets On/Off function drawing on the same pad. When a fit is; executed, the image of the function is drawn on the current pad. *‘No drawing'* sets On/Off the option ""`0`""- do not draw the fit; results. *‘Do not store/draw'* sets On/Off option ""`N`""- do not store the; function and do not draw it. ### Advances Options. The advance option button is enabled only after having performed the fit and provides; additional drawing options that can be used after having done the fit. These new drawing tools,; which can be selected by the ""Advanced Drawing Tool"" panel that pops up when clicking the ""Advanced"" button, are:. * *Contour*: to plot the confidence contour of two chosen parameters. One can select the number of points to draw the contour; (more points might require more time to compute it), the parameters and the desired confidence level . * *Scan* : to plot a scan of the minimization function (likelihood or chi-squared) around the minimum as function of the chosen parameter. * *Conf Interval* : to plot the confidence interval of the fitted function as a filled coloured band around its central value.; One can select the desired confidence level for the band to be plotted. ### Print Options. This set of options specifies the amount of feedback printed on the; root command line after performed fits. *‘Verbose'* - prints fit results after each iteration. *‘Quiet'* - no fit informat",MatchSource.DOCS,gui/fitpanel/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/fitpanel/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/gui/fitpanel/doc/index.md:5436,Performance,perform,performed,5436," *‘No drawing'* sets On/Off the option ""`0`""- do not draw the fit; results. *‘Do not store/draw'* sets On/Off option ""`N`""- do not store the; function and do not draw it. ### Advances Options. The advance option button is enabled only after having performed the fit and provides; additional drawing options that can be used after having done the fit. These new drawing tools,; which can be selected by the ""Advanced Drawing Tool"" panel that pops up when clicking the ""Advanced"" button, are:. * *Contour*: to plot the confidence contour of two chosen parameters. One can select the number of points to draw the contour; (more points might require more time to compute it), the parameters and the desired confidence level . * *Scan* : to plot a scan of the minimization function (likelihood or chi-squared) around the minimum as function of the chosen parameter. * *Conf Interval* : to plot the confidence interval of the fitted function as a filled coloured band around its central value.; One can select the desired confidence level for the band to be plotted. ### Print Options. This set of options specifies the amount of feedback printed on the; root command line after performed fits. *‘Verbose'* - prints fit results after each iteration. *‘Quiet'* - no fit information is printed. *‘Default'* - between Verbose and Quiet. ### Command Buttons. *Fit button* - performs a fit taking different option settings via the; Fit Panel interface. *Reset* - sets the GUI elements and related fit settings to the; default ones. *Close* - closes the Fit panel window. ### Minimization Options. With this tab one can select specific options for minimization. These include. * The minimizer library ( *Minuit*, *Minuit2*, *Fumili*, *GSL*, *Genetics* ); * The method (algorithm) for minimization. For example for Minuit one can choose between (*Migrad*, *Simplex* or *Scan*); * Error definition; * Minimization tolerance; * Number of iterations/function calls; * Print Level: (*Default*, *Verbose* or *Quiet*). ",MatchSource.DOCS,gui/fitpanel/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/fitpanel/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/gui/fitpanel/doc/index.md:5627,Performance,perform,performs,5627," *‘No drawing'* sets On/Off the option ""`0`""- do not draw the fit; results. *‘Do not store/draw'* sets On/Off option ""`N`""- do not store the; function and do not draw it. ### Advances Options. The advance option button is enabled only after having performed the fit and provides; additional drawing options that can be used after having done the fit. These new drawing tools,; which can be selected by the ""Advanced Drawing Tool"" panel that pops up when clicking the ""Advanced"" button, are:. * *Contour*: to plot the confidence contour of two chosen parameters. One can select the number of points to draw the contour; (more points might require more time to compute it), the parameters and the desired confidence level . * *Scan* : to plot a scan of the minimization function (likelihood or chi-squared) around the minimum as function of the chosen parameter. * *Conf Interval* : to plot the confidence interval of the fitted function as a filled coloured band around its central value.; One can select the desired confidence level for the band to be plotted. ### Print Options. This set of options specifies the amount of feedback printed on the; root command line after performed fits. *‘Verbose'* - prints fit results after each iteration. *‘Quiet'* - no fit information is printed. *‘Default'* - between Verbose and Quiet. ### Command Buttons. *Fit button* - performs a fit taking different option settings via the; Fit Panel interface. *Reset* - sets the GUI elements and related fit settings to the; default ones. *Close* - closes the Fit panel window. ### Minimization Options. With this tab one can select specific options for minimization. These include. * The minimizer library ( *Minuit*, *Minuit2*, *Fumili*, *GSL*, *Genetics* ); * The method (algorithm) for minimization. For example for Minuit one can choose between (*Migrad*, *Simplex* or *Scan*); * Error definition; * Minimization tolerance; * Number of iterations/function calls; * Print Level: (*Default*, *Verbose* or *Quiet*). ",MatchSource.DOCS,gui/fitpanel/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/fitpanel/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/gui/fitpanel/doc/index.md:5387,Usability,feedback,feedback,5387," *‘No drawing'* sets On/Off the option ""`0`""- do not draw the fit; results. *‘Do not store/draw'* sets On/Off option ""`N`""- do not store the; function and do not draw it. ### Advances Options. The advance option button is enabled only after having performed the fit and provides; additional drawing options that can be used after having done the fit. These new drawing tools,; which can be selected by the ""Advanced Drawing Tool"" panel that pops up when clicking the ""Advanced"" button, are:. * *Contour*: to plot the confidence contour of two chosen parameters. One can select the number of points to draw the contour; (more points might require more time to compute it), the parameters and the desired confidence level . * *Scan* : to plot a scan of the minimization function (likelihood or chi-squared) around the minimum as function of the chosen parameter. * *Conf Interval* : to plot the confidence interval of the fitted function as a filled coloured band around its central value.; One can select the desired confidence level for the band to be plotted. ### Print Options. This set of options specifies the amount of feedback printed on the; root command line after performed fits. *‘Verbose'* - prints fit results after each iteration. *‘Quiet'* - no fit information is printed. *‘Default'* - between Verbose and Quiet. ### Command Buttons. *Fit button* - performs a fit taking different option settings via the; Fit Panel interface. *Reset* - sets the GUI elements and related fit settings to the; default ones. *Close* - closes the Fit panel window. ### Minimization Options. With this tab one can select specific options for minimization. These include. * The minimizer library ( *Minuit*, *Minuit2*, *Fumili*, *GSL*, *Genetics* ); * The method (algorithm) for minimization. For example for Minuit one can choose between (*Migrad*, *Simplex* or *Scan*); * Error definition; * Minimization tolerance; * Number of iterations/function calls; * Print Level: (*Default*, *Verbose* or *Quiet*). ",MatchSource.DOCS,gui/fitpanel/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/fitpanel/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/gui/ged/doc/index.md:6150,Availability,avail,available,6150,"elected object, executed from method **`TGedEditor::SetModel()`**.; When a new object of a different class is selected, the unneeded; GED-frames are cached in memory for potential reuse. The frames are; deleted automatically when the editor is closed. Note: A deep cleanup is assumed for all frames put into the editor. This; implies:. - do not share the layout-hints among GUI components;. - do not delete child widgets in the destructor as this is done; automatically. #### Using Several Tabs. Sometimes you might need to use several tabs to organize properly your; class-editor. Each editor tab is a resource shared among all the; class-editors. Tabs must be created from the constructor of your; editor-class by using the method:. ``` {.cpp}; TGVerticalFrame* TGedFrame::CreateEditorTabSubFrame(const Text_t *name),; ```. It returns a pointer to a new tab container frame ready for use in your; class. If you need to hide/show this frame depending on the object's; status, you should store it in a data member. See for examples:; **`TH1Editor`**, **`TH2Editor`**. #### Base-Class Editors Control. Full control over base-class editors can be achieved by re-implementing; virtual method void `TGedFrame::ActivateBaseClassEditors(TClass` `*cl)`.; It is called during each compound editor rebuild and the default; implementation simply offers all base-classes to the publishing; mechanism. To prevent inclusion of a base-class into the compound editor, call:. ``` {.cpp}; void TGedEditor::ExcludeClassEditor(TClass* class, Bool_t recurse); ```. Pointer to the compound GED-editor is available in **`TGedFrame`**‘s; data-member:. ``` {.cpp}; TGedEditor *fGedEditor; ```. Ordering of base-class editor frames follows the order of the classes in; the class hierarchy. This order can be changed by modifying the value of; **`TGedFrame`**'s data member `Int_t fPriority`. The default value is; 50; smaller values move the frame towards to the top. This priority; should be set in the editor constructor.; ",MatchSource.DOCS,gui/ged/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/ged/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/gui/ged/doc/index.md:921,Energy Efficiency,reduce,reduced,921,"\defgroup ged ROOT Graphics Editor; \ingroup gui; \brief Classes forming the Graphics Editor (GED) of ROOT and the basic classes of so-called object editors. ## The ROOT Graphics Editor (GED). Everything drawn in a ROOT canvas is an object. There are classes for; all objects, and they fall into hierarchies. In addition, the ROOT has; fully cross-platform GUI classes and provides all standard components; for an application environment with common ‘look and feel'. The; object-oriented, event-driven programming model supports the modern; signals/slots communication mechanism. It handles user interface actions; and allows total independence of interacting objects and classes. This; mechanism uses the ROOT dictionary information and the Cling the C++; Interpreter to connect signals to slots methods. Therefore, all necessary elements for an object-oriented editor design; are in place. The editor complexity can be reduced by splitting it into; discrete units of so-called *`object`* *`editors`*. Any object editor; provides an object specific GUI. The main purpose of the ROOT graphics; editor is the organization of the object editors' appearance and the; task sequence between them. ### Object Editors. Every object editor follows a simple naming convention: to have as a; name the object class name concatenated with ‘*`Editor`*' (e.g. for; **`TGraph`** objects the object editor is **`TGraphEditor`**). Thanks to; the signals/slots communication mechanism and to the method; `DistancetoPrimitive()` that computes a ‘‘distance'' to an object from; the mouse position, it was possible to implement a signal method of the; canvas that says which is the selected object and to which pad it; belongs. Having this information the graphics editor loads the; corresponding object editor and the user interface is ready for use.; This way after a click on ‘axis'—the axis editor is active; a click on a; ‘pad' activates the pad editor, etc. The algorithm in use is simple and is based on the object-",MatchSource.DOCS,gui/ged/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/ged/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/gui/ged/doc/index.md:2925,Energy Efficiency,reduce,reduced,2925,"The algorithm in use is simple and is based on the object-oriented; relationship and communication. When the user activates the editor,; according to the selected object **`<obj>`** in the canvas it looks for; a class name **`<obj>Editor`**. For that reason, the correct naming is; very important. If a class with this name is found, the editor verifies; that this class derives from the base editor class **`TGedFrame`**. If; all checks are satisfied, the editor makes an instance of the object; editor. Then, it scans all object base classes searching the; corresponding object editors. When it finds one, it makes an instance of; the base class editor too. Once the object editor is in place, it sets the user interface elements; according to the object's status. After that, it is ready to interact; with the object following the user actions. The graphics editor gives an intuitive way to edit objects in a canvas; with immediate feedback. Complexity of some object editors is reduced by; hiding GUI elements and revealing them only on users' requests. An object in the canvas is selected by clicking on it with the left; mouse button. Its name is displayed on the top of the editor frame in; red color. If the editor frame needs more space than the canvas window,; a vertical scroll bar appears for easy navigation. \image html ged.png width=800px. **Histogram, pad and axis editors**. ### Editor Design Elements. The next rules describe the path to follow when creating your own object; editor that will be recognized and loaded by the graphics editor in; ROOT, i.e. it will be included as a part of it. (a) Derive the code of your object editor from the base editor class; **`TGedFrame`**. (b) Keep the correct naming convention: the name of the object editor; should be the object class name concatenated with the word `‘Editor'`. (c) Provide a default constructor. (d) Use the signals/slots communication mechanism for event processing. (e) Implement the virtual method `SetModel(TObject *ob",MatchSource.DOCS,gui/ged/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/ged/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/gui/ged/doc/index.md:596,Integrability,interface,interface,596,"\defgroup ged ROOT Graphics Editor; \ingroup gui; \brief Classes forming the Graphics Editor (GED) of ROOT and the basic classes of so-called object editors. ## The ROOT Graphics Editor (GED). Everything drawn in a ROOT canvas is an object. There are classes for; all objects, and they fall into hierarchies. In addition, the ROOT has; fully cross-platform GUI classes and provides all standard components; for an application environment with common ‘look and feel'. The; object-oriented, event-driven programming model supports the modern; signals/slots communication mechanism. It handles user interface actions; and allows total independence of interacting objects and classes. This; mechanism uses the ROOT dictionary information and the Cling the C++; Interpreter to connect signals to slots methods. Therefore, all necessary elements for an object-oriented editor design; are in place. The editor complexity can be reduced by splitting it into; discrete units of so-called *`object`* *`editors`*. Any object editor; provides an object specific GUI. The main purpose of the ROOT graphics; editor is the organization of the object editors' appearance and the; task sequence between them. ### Object Editors. Every object editor follows a simple naming convention: to have as a; name the object class name concatenated with ‘*`Editor`*' (e.g. for; **`TGraph`** objects the object editor is **`TGraphEditor`**). Thanks to; the signals/slots communication mechanism and to the method; `DistancetoPrimitive()` that computes a ‘‘distance'' to an object from; the mouse position, it was possible to implement a signal method of the; canvas that says which is the selected object and to which pad it; belongs. Having this information the graphics editor loads the; corresponding object editor and the user interface is ready for use.; This way after a click on ‘axis'—the axis editor is active; a click on a; ‘pad' activates the pad editor, etc. The algorithm in use is simple and is based on the object-",MatchSource.DOCS,gui/ged/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/ged/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/gui/ged/doc/index.md:1803,Integrability,interface,interface,1803," to connect signals to slots methods. Therefore, all necessary elements for an object-oriented editor design; are in place. The editor complexity can be reduced by splitting it into; discrete units of so-called *`object`* *`editors`*. Any object editor; provides an object specific GUI. The main purpose of the ROOT graphics; editor is the organization of the object editors' appearance and the; task sequence between them. ### Object Editors. Every object editor follows a simple naming convention: to have as a; name the object class name concatenated with ‘*`Editor`*' (e.g. for; **`TGraph`** objects the object editor is **`TGraphEditor`**). Thanks to; the signals/slots communication mechanism and to the method; `DistancetoPrimitive()` that computes a ‘‘distance'' to an object from; the mouse position, it was possible to implement a signal method of the; canvas that says which is the selected object and to which pad it; belongs. Having this information the graphics editor loads the; corresponding object editor and the user interface is ready for use.; This way after a click on ‘axis'—the axis editor is active; a click on a; ‘pad' activates the pad editor, etc. The algorithm in use is simple and is based on the object-oriented; relationship and communication. When the user activates the editor,; according to the selected object **`<obj>`** in the canvas it looks for; a class name **`<obj>Editor`**. For that reason, the correct naming is; very important. If a class with this name is found, the editor verifies; that this class derives from the base editor class **`TGedFrame`**. If; all checks are satisfied, the editor makes an instance of the object; editor. Then, it scans all object base classes searching the; corresponding object editors. When it finds one, it makes an instance of; the base class editor too. Once the object editor is in place, it sets the user interface elements; according to the object's status. After that, it is ready to interact; with the object follo",MatchSource.DOCS,gui/ged/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/ged/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/gui/ged/doc/index.md:2656,Integrability,interface,interface,2656,"s the selected object and to which pad it; belongs. Having this information the graphics editor loads the; corresponding object editor and the user interface is ready for use.; This way after a click on ‘axis'—the axis editor is active; a click on a; ‘pad' activates the pad editor, etc. The algorithm in use is simple and is based on the object-oriented; relationship and communication. When the user activates the editor,; according to the selected object **`<obj>`** in the canvas it looks for; a class name **`<obj>Editor`**. For that reason, the correct naming is; very important. If a class with this name is found, the editor verifies; that this class derives from the base editor class **`TGedFrame`**. If; all checks are satisfied, the editor makes an instance of the object; editor. Then, it scans all object base classes searching the; corresponding object editors. When it finds one, it makes an instance of; the base class editor too. Once the object editor is in place, it sets the user interface elements; according to the object's status. After that, it is ready to interact; with the object following the user actions. The graphics editor gives an intuitive way to edit objects in a canvas; with immediate feedback. Complexity of some object editors is reduced by; hiding GUI elements and revealing them only on users' requests. An object in the canvas is selected by clicking on it with the left; mouse button. Its name is displayed on the top of the editor frame in; red color. If the editor frame needs more space than the canvas window,; a vertical scroll bar appears for easy navigation. \image html ged.png width=800px. **Histogram, pad and axis editors**. ### Editor Design Elements. The next rules describe the path to follow when creating your own object; editor that will be recognized and loaded by the graphics editor in; ROOT, i.e. it will be included as a part of it. (a) Derive the code of your object editor from the base editor class; **`TGedFrame`**. (b) Keep the co",MatchSource.DOCS,gui/ged/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/ged/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/gui/ged/doc/index.md:5509,Integrability,depend,depending,5509,"ng traversal of class hierarchy of the; selected object, executed from method **`TGedEditor::SetModel()`**.; When a new object of a different class is selected, the unneeded; GED-frames are cached in memory for potential reuse. The frames are; deleted automatically when the editor is closed. Note: A deep cleanup is assumed for all frames put into the editor. This; implies:. - do not share the layout-hints among GUI components;. - do not delete child widgets in the destructor as this is done; automatically. #### Using Several Tabs. Sometimes you might need to use several tabs to organize properly your; class-editor. Each editor tab is a resource shared among all the; class-editors. Tabs must be created from the constructor of your; editor-class by using the method:. ``` {.cpp}; TGVerticalFrame* TGedFrame::CreateEditorTabSubFrame(const Text_t *name),; ```. It returns a pointer to a new tab container frame ready for use in your; class. If you need to hide/show this frame depending on the object's; status, you should store it in a data member. See for examples:; **`TH1Editor`**, **`TH2Editor`**. #### Base-Class Editors Control. Full control over base-class editors can be achieved by re-implementing; virtual method void `TGedFrame::ActivateBaseClassEditors(TClass` `*cl)`.; It is called during each compound editor rebuild and the default; implementation simply offers all base-classes to the publishing; mechanism. To prevent inclusion of a base-class into the compound editor, call:. ``` {.cpp}; void TGedEditor::ExcludeClassEditor(TClass* class, Bool_t recurse); ```. Pointer to the compound GED-editor is available in **`TGedFrame`**‘s; data-member:. ``` {.cpp}; TGedEditor *fGedEditor; ```. Ordering of base-class editor frames follows the order of the classes in; the class hierarchy. This order can be changed by modifying the value of; **`TGedFrame`**'s data member `Int_t fPriority`. The default value is; 50; smaller values move the frame towards to the top. This priority; sh",MatchSource.DOCS,gui/ged/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/ged/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/gui/ged/doc/index.md:1751,Performance,load,loads,1751," to connect signals to slots methods. Therefore, all necessary elements for an object-oriented editor design; are in place. The editor complexity can be reduced by splitting it into; discrete units of so-called *`object`* *`editors`*. Any object editor; provides an object specific GUI. The main purpose of the ROOT graphics; editor is the organization of the object editors' appearance and the; task sequence between them. ### Object Editors. Every object editor follows a simple naming convention: to have as a; name the object class name concatenated with ‘*`Editor`*' (e.g. for; **`TGraph`** objects the object editor is **`TGraphEditor`**). Thanks to; the signals/slots communication mechanism and to the method; `DistancetoPrimitive()` that computes a ‘‘distance'' to an object from; the mouse position, it was possible to implement a signal method of the; canvas that says which is the selected object and to which pad it; belongs. Having this information the graphics editor loads the; corresponding object editor and the user interface is ready for use.; This way after a click on ‘axis'—the axis editor is active; a click on a; ‘pad' activates the pad editor, etc. The algorithm in use is simple and is based on the object-oriented; relationship and communication. When the user activates the editor,; according to the selected object **`<obj>`** in the canvas it looks for; a class name **`<obj>Editor`**. For that reason, the correct naming is; very important. If a class with this name is found, the editor verifies; that this class derives from the base editor class **`TGedFrame`**. If; all checks are satisfied, the editor makes an instance of the object; editor. Then, it scans all object base classes searching the; corresponding object editors. When it finds one, it makes an instance of; the base class editor too. Once the object editor is in place, it sets the user interface elements; according to the object's status. After that, it is ready to interact; with the object follo",MatchSource.DOCS,gui/ged/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/ged/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/gui/ged/doc/index.md:3472,Performance,load,loaded,3472,"; editor. Then, it scans all object base classes searching the; corresponding object editors. When it finds one, it makes an instance of; the base class editor too. Once the object editor is in place, it sets the user interface elements; according to the object's status. After that, it is ready to interact; with the object following the user actions. The graphics editor gives an intuitive way to edit objects in a canvas; with immediate feedback. Complexity of some object editors is reduced by; hiding GUI elements and revealing them only on users' requests. An object in the canvas is selected by clicking on it with the left; mouse button. Its name is displayed on the top of the editor frame in; red color. If the editor frame needs more space than the canvas window,; a vertical scroll bar appears for easy navigation. \image html ged.png width=800px. **Histogram, pad and axis editors**. ### Editor Design Elements. The next rules describe the path to follow when creating your own object; editor that will be recognized and loaded by the graphics editor in; ROOT, i.e. it will be included as a part of it. (a) Derive the code of your object editor from the base editor class; **`TGedFrame`**. (b) Keep the correct naming convention: the name of the object editor; should be the object class name concatenated with the word `‘Editor'`. (c) Provide a default constructor. (d) Use the signals/slots communication mechanism for event processing. (e) Implement the virtual method `SetModel(TObject *obj)` where all; widgets are set with the current object's attributes. This method is; called when the editor receives a signal from the canvas saying that an; object is the selected. (f) Implement all necessary slots and connect them to appropriate; signals that GUI widgets send out. The GUI classes in ROOT are developed; to emit signals whenever they change a state that others might be; interested. As we noted already, the signals/slots communication; mechanism allows total independence of",MatchSource.DOCS,gui/ged/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/ged/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/gui/ged/doc/index.md:4716,Performance,cache,cached,4716,"the object editor; should be the object class name concatenated with the word `‘Editor'`. (c) Provide a default constructor. (d) Use the signals/slots communication mechanism for event processing. (e) Implement the virtual method `SetModel(TObject *obj)` where all; widgets are set with the current object's attributes. This method is; called when the editor receives a signal from the canvas saying that an; object is the selected. (f) Implement all necessary slots and connect them to appropriate; signals that GUI widgets send out. The GUI classes in ROOT are developed; to emit signals whenever they change a state that others might be; interested. As we noted already, the signals/slots communication; mechanism allows total independence of the interacting classes. #### Creation and Destruction. GED-frames are constructed during traversal of class hierarchy of the; selected object, executed from method **`TGedEditor::SetModel()`**.; When a new object of a different class is selected, the unneeded; GED-frames are cached in memory for potential reuse. The frames are; deleted automatically when the editor is closed. Note: A deep cleanup is assumed for all frames put into the editor. This; implies:. - do not share the layout-hints among GUI components;. - do not delete child widgets in the destructor as this is done; automatically. #### Using Several Tabs. Sometimes you might need to use several tabs to organize properly your; class-editor. Each editor tab is a resource shared among all the; class-editors. Tabs must be created from the constructor of your; editor-class by using the method:. ``` {.cpp}; TGVerticalFrame* TGedFrame::CreateEditorTabSubFrame(const Text_t *name),; ```. It returns a pointer to a new tab container frame ready for use in your; class. If you need to hide/show this frame depending on the object's; status, you should store it in a data member. See for examples:; **`TH1Editor`**, **`TH2Editor`**. #### Base-Class Editors Control. Full control over base-cl",MatchSource.DOCS,gui/ged/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/ged/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/gui/ged/doc/index.md:1242,Usability,simpl,simple,1242,"and they fall into hierarchies. In addition, the ROOT has; fully cross-platform GUI classes and provides all standard components; for an application environment with common ‘look and feel'. The; object-oriented, event-driven programming model supports the modern; signals/slots communication mechanism. It handles user interface actions; and allows total independence of interacting objects and classes. This; mechanism uses the ROOT dictionary information and the Cling the C++; Interpreter to connect signals to slots methods. Therefore, all necessary elements for an object-oriented editor design; are in place. The editor complexity can be reduced by splitting it into; discrete units of so-called *`object`* *`editors`*. Any object editor; provides an object specific GUI. The main purpose of the ROOT graphics; editor is the organization of the object editors' appearance and the; task sequence between them. ### Object Editors. Every object editor follows a simple naming convention: to have as a; name the object class name concatenated with ‘*`Editor`*' (e.g. for; **`TGraph`** objects the object editor is **`TGraphEditor`**). Thanks to; the signals/slots communication mechanism and to the method; `DistancetoPrimitive()` that computes a ‘‘distance'' to an object from; the mouse position, it was possible to implement a signal method of the; canvas that says which is the selected object and to which pad it; belongs. Having this information the graphics editor loads the; corresponding object editor and the user interface is ready for use.; This way after a click on ‘axis'—the axis editor is active; a click on a; ‘pad' activates the pad editor, etc. The algorithm in use is simple and is based on the object-oriented; relationship and communication. When the user activates the editor,; according to the selected object **`<obj>`** in the canvas it looks for; a class name **`<obj>Editor`**. For that reason, the correct naming is; very important. If a class with this name is found, ",MatchSource.DOCS,gui/ged/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/ged/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/gui/ged/doc/index.md:1967,Usability,simpl,simple,1967,"editors`*. Any object editor; provides an object specific GUI. The main purpose of the ROOT graphics; editor is the organization of the object editors' appearance and the; task sequence between them. ### Object Editors. Every object editor follows a simple naming convention: to have as a; name the object class name concatenated with ‘*`Editor`*' (e.g. for; **`TGraph`** objects the object editor is **`TGraphEditor`**). Thanks to; the signals/slots communication mechanism and to the method; `DistancetoPrimitive()` that computes a ‘‘distance'' to an object from; the mouse position, it was possible to implement a signal method of the; canvas that says which is the selected object and to which pad it; belongs. Having this information the graphics editor loads the; corresponding object editor and the user interface is ready for use.; This way after a click on ‘axis'—the axis editor is active; a click on a; ‘pad' activates the pad editor, etc. The algorithm in use is simple and is based on the object-oriented; relationship and communication. When the user activates the editor,; according to the selected object **`<obj>`** in the canvas it looks for; a class name **`<obj>Editor`**. For that reason, the correct naming is; very important. If a class with this name is found, the editor verifies; that this class derives from the base editor class **`TGedFrame`**. If; all checks are satisfied, the editor makes an instance of the object; editor. Then, it scans all object base classes searching the; corresponding object editors. When it finds one, it makes an instance of; the base class editor too. Once the object editor is in place, it sets the user interface elements; according to the object's status. After that, it is ready to interact; with the object following the user actions. The graphics editor gives an intuitive way to edit objects in a canvas; with immediate feedback. Complexity of some object editors is reduced by; hiding GUI elements and revealing them only on users' r",MatchSource.DOCS,gui/ged/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/ged/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/gui/ged/doc/index.md:2820,Usability,intuit,intuitive,2820,"ay after a click on ‘axis'—the axis editor is active; a click on a; ‘pad' activates the pad editor, etc. The algorithm in use is simple and is based on the object-oriented; relationship and communication. When the user activates the editor,; according to the selected object **`<obj>`** in the canvas it looks for; a class name **`<obj>Editor`**. For that reason, the correct naming is; very important. If a class with this name is found, the editor verifies; that this class derives from the base editor class **`TGedFrame`**. If; all checks are satisfied, the editor makes an instance of the object; editor. Then, it scans all object base classes searching the; corresponding object editors. When it finds one, it makes an instance of; the base class editor too. Once the object editor is in place, it sets the user interface elements; according to the object's status. After that, it is ready to interact; with the object following the user actions. The graphics editor gives an intuitive way to edit objects in a canvas; with immediate feedback. Complexity of some object editors is reduced by; hiding GUI elements and revealing them only on users' requests. An object in the canvas is selected by clicking on it with the left; mouse button. Its name is displayed on the top of the editor frame in; red color. If the editor frame needs more space than the canvas window,; a vertical scroll bar appears for easy navigation. \image html ged.png width=800px. **Histogram, pad and axis editors**. ### Editor Design Elements. The next rules describe the path to follow when creating your own object; editor that will be recognized and loaded by the graphics editor in; ROOT, i.e. it will be included as a part of it. (a) Derive the code of your object editor from the base editor class; **`TGedFrame`**. (b) Keep the correct naming convention: the name of the object editor; should be the object class name concatenated with the word `‘Editor'`. (c) Provide a default constructor. (d) Use the signals/s",MatchSource.DOCS,gui/ged/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/ged/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/gui/ged/doc/index.md:2878,Usability,feedback,feedback,2878,"ay after a click on ‘axis'—the axis editor is active; a click on a; ‘pad' activates the pad editor, etc. The algorithm in use is simple and is based on the object-oriented; relationship and communication. When the user activates the editor,; according to the selected object **`<obj>`** in the canvas it looks for; a class name **`<obj>Editor`**. For that reason, the correct naming is; very important. If a class with this name is found, the editor verifies; that this class derives from the base editor class **`TGedFrame`**. If; all checks are satisfied, the editor makes an instance of the object; editor. Then, it scans all object base classes searching the; corresponding object editors. When it finds one, it makes an instance of; the base class editor too. Once the object editor is in place, it sets the user interface elements; according to the object's status. After that, it is ready to interact; with the object following the user actions. The graphics editor gives an intuitive way to edit objects in a canvas; with immediate feedback. Complexity of some object editors is reduced by; hiding GUI elements and revealing them only on users' requests. An object in the canvas is selected by clicking on it with the left; mouse button. Its name is displayed on the top of the editor frame in; red color. If the editor frame needs more space than the canvas window,; a vertical scroll bar appears for easy navigation. \image html ged.png width=800px. **Histogram, pad and axis editors**. ### Editor Design Elements. The next rules describe the path to follow when creating your own object; editor that will be recognized and loaded by the graphics editor in; ROOT, i.e. it will be included as a part of it. (a) Derive the code of your object editor from the base editor class; **`TGedFrame`**. (b) Keep the correct naming convention: the name of the object editor; should be the object class name concatenated with the word `‘Editor'`. (c) Provide a default constructor. (d) Use the signals/s",MatchSource.DOCS,gui/ged/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/ged/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/gui/ged/doc/index.md:5896,Usability,simpl,simply,5896,"elected object, executed from method **`TGedEditor::SetModel()`**.; When a new object of a different class is selected, the unneeded; GED-frames are cached in memory for potential reuse. The frames are; deleted automatically when the editor is closed. Note: A deep cleanup is assumed for all frames put into the editor. This; implies:. - do not share the layout-hints among GUI components;. - do not delete child widgets in the destructor as this is done; automatically. #### Using Several Tabs. Sometimes you might need to use several tabs to organize properly your; class-editor. Each editor tab is a resource shared among all the; class-editors. Tabs must be created from the constructor of your; editor-class by using the method:. ``` {.cpp}; TGVerticalFrame* TGedFrame::CreateEditorTabSubFrame(const Text_t *name),; ```. It returns a pointer to a new tab container frame ready for use in your; class. If you need to hide/show this frame depending on the object's; status, you should store it in a data member. See for examples:; **`TH1Editor`**, **`TH2Editor`**. #### Base-Class Editors Control. Full control over base-class editors can be achieved by re-implementing; virtual method void `TGedFrame::ActivateBaseClassEditors(TClass` `*cl)`.; It is called during each compound editor rebuild and the default; implementation simply offers all base-classes to the publishing; mechanism. To prevent inclusion of a base-class into the compound editor, call:. ``` {.cpp}; void TGedEditor::ExcludeClassEditor(TClass* class, Bool_t recurse); ```. Pointer to the compound GED-editor is available in **`TGedFrame`**‘s; data-member:. ``` {.cpp}; TGedEditor *fGedEditor; ```. Ordering of base-class editor frames follows the order of the classes in; the class hierarchy. This order can be changed by modifying the value of; **`TGedFrame`**'s data member `Int_t fPriority`. The default value is; 50; smaller values move the frame towards to the top. This priority; should be set in the editor constructor.; ",MatchSource.DOCS,gui/ged/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/ged/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/gui/guihtml/doc/index.md:63,Usability,simpl,simple,63,\defgroup guihtml HTML visualizer; \ingroup gui; \brief A very simple HTML browser.; ,MatchSource.DOCS,gui/guihtml/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/guihtml/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/gui/recorder/doc/index.md:137,Integrability,interface,interface,137,"\defgroup guirecorder Events recorder; \ingroup gui; \brief The event recorder. ## ROOT EVENT RECORDING SYSTEM. TRecorder class provides interface for recording and replaying; events in ROOT.; Recorded events are:. - Commands typed by user in commandline ('new TCanvas'); - GUI events (mouse movement, button clicks, ...). All the recorded events from one session are stored in one TFile; and can be replayed again anytime. ### Recording. 1] To start recording; ```; TRecorder r(const char *filename, ""NEW""); TRecorder r(const char *filename, ""RECREATE""); ```; or:; ```; TRecorder *recorder = new TRecorder;; recorder->Start(const char *filename, ...); ```; - `filename`: Name of ROOT file in which to save recorded events. 2] To stop recording; ```; recorder->Stop(); ```. IMPORTANT:; State capturing is part of recording. It means that if you want to; record events for some object (window), creation of this object; must be also recorded. #### Example:. ```; t = new TRecorder(); // Create a new recorder; t->Start(""logfile.root""); // ! Start recording first. c = new TCanvas(); // ! Then, create an object; c->Dump(); // Work with that object. t->Stop(); // Stop recording; ```. It is strongly recommended to start recording with empty ROOT; environment, at least with no previously created ROOT GUI.; This ensures that only events for well known windows are stored.; Events for windows, which were not created during recording,; cannot be replayed. ### Replaying. 1] To start replaying; ```; TRecorder r(const char *filename); TRecorder r(const char *filename, ""READ""); ```; or:; ```; TRecorder *recorder = new TRecorder;; recorder->Replay(const char *filename,; Bool_t showMouseCursor = kTRUE);; ```; - `filename`: A name of file with recorded events previously created with TRecorder::Start. - `showMouseCursor`: If kTRUE, mouse cursor is replayed as well.; In that case it is not recommended to use mouse; during replaying. In general, it is not recommended to use mouse to change positions; a",MatchSource.DOCS,gui/recorder/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/recorder/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/gui/recorder/doc/index.md:1019,Testability,log,logfile,1019,"\defgroup guirecorder Events recorder; \ingroup gui; \brief The event recorder. ## ROOT EVENT RECORDING SYSTEM. TRecorder class provides interface for recording and replaying; events in ROOT.; Recorded events are:. - Commands typed by user in commandline ('new TCanvas'); - GUI events (mouse movement, button clicks, ...). All the recorded events from one session are stored in one TFile; and can be replayed again anytime. ### Recording. 1] To start recording; ```; TRecorder r(const char *filename, ""NEW""); TRecorder r(const char *filename, ""RECREATE""); ```; or:; ```; TRecorder *recorder = new TRecorder;; recorder->Start(const char *filename, ...); ```; - `filename`: Name of ROOT file in which to save recorded events. 2] To stop recording; ```; recorder->Stop(); ```. IMPORTANT:; State capturing is part of recording. It means that if you want to; record events for some object (window), creation of this object; must be also recorded. #### Example:. ```; t = new TRecorder(); // Create a new recorder; t->Start(""logfile.root""); // ! Start recording first. c = new TCanvas(); // ! Then, create an object; c->Dump(); // Work with that object. t->Stop(); // Stop recording; ```. It is strongly recommended to start recording with empty ROOT; environment, at least with no previously created ROOT GUI.; This ensures that only events for well known windows are stored.; Events for windows, which were not created during recording,; cannot be replayed. ### Replaying. 1] To start replaying; ```; TRecorder r(const char *filename); TRecorder r(const char *filename, ""READ""); ```; or:; ```; TRecorder *recorder = new TRecorder;; recorder->Replay(const char *filename,; Bool_t showMouseCursor = kTRUE);; ```; - `filename`: A name of file with recorded events previously created with TRecorder::Start. - `showMouseCursor`: If kTRUE, mouse cursor is replayed as well.; In that case it is not recommended to use mouse; during replaying. In general, it is not recommended to use mouse to change positions; a",MatchSource.DOCS,gui/recorder/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/recorder/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/gui/recorder/doc/index.md:2283,Usability,pause,pause,2283,"""); ```; or:; ```; TRecorder *recorder = new TRecorder;; recorder->Start(const char *filename, ...); ```; - `filename`: Name of ROOT file in which to save recorded events. 2] To stop recording; ```; recorder->Stop(); ```. IMPORTANT:; State capturing is part of recording. It means that if you want to; record events for some object (window), creation of this object; must be also recorded. #### Example:. ```; t = new TRecorder(); // Create a new recorder; t->Start(""logfile.root""); // ! Start recording first. c = new TCanvas(); // ! Then, create an object; c->Dump(); // Work with that object. t->Stop(); // Stop recording; ```. It is strongly recommended to start recording with empty ROOT; environment, at least with no previously created ROOT GUI.; This ensures that only events for well known windows are stored.; Events for windows, which were not created during recording,; cannot be replayed. ### Replaying. 1] To start replaying; ```; TRecorder r(const char *filename); TRecorder r(const char *filename, ""READ""); ```; or:; ```; TRecorder *recorder = new TRecorder;; recorder->Replay(const char *filename,; Bool_t showMouseCursor = kTRUE);; ```; - `filename`: A name of file with recorded events previously created with TRecorder::Start. - `showMouseCursor`: If kTRUE, mouse cursor is replayed as well.; In that case it is not recommended to use mouse; during replaying. In general, it is not recommended to use mouse to change positions; and states of ROOT windows during replaying. IMPORTANT:; The state of ROOT environment before replaying of some events; must be exactly the same as before recording them.; Therefore it is strongly recommended to start both recording; and replaying with empty ROOT environment. 2] To pause replaying; ```; recorder->Pause(); ```; Replaying is stopped until `recorder->Resume()` is called. 3] To resume paused replaying; ```; recorder->Resume(); ```; Resumes previously stopped replaying. 4] To stop replaying before its end; ```; recorder->Stop(); ```; ",MatchSource.DOCS,gui/recorder/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/recorder/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/gui/recorder/doc/index.md:2394,Usability,resume,resume,2394,"""); ```; or:; ```; TRecorder *recorder = new TRecorder;; recorder->Start(const char *filename, ...); ```; - `filename`: Name of ROOT file in which to save recorded events. 2] To stop recording; ```; recorder->Stop(); ```. IMPORTANT:; State capturing is part of recording. It means that if you want to; record events for some object (window), creation of this object; must be also recorded. #### Example:. ```; t = new TRecorder(); // Create a new recorder; t->Start(""logfile.root""); // ! Start recording first. c = new TCanvas(); // ! Then, create an object; c->Dump(); // Work with that object. t->Stop(); // Stop recording; ```. It is strongly recommended to start recording with empty ROOT; environment, at least with no previously created ROOT GUI.; This ensures that only events for well known windows are stored.; Events for windows, which were not created during recording,; cannot be replayed. ### Replaying. 1] To start replaying; ```; TRecorder r(const char *filename); TRecorder r(const char *filename, ""READ""); ```; or:; ```; TRecorder *recorder = new TRecorder;; recorder->Replay(const char *filename,; Bool_t showMouseCursor = kTRUE);; ```; - `filename`: A name of file with recorded events previously created with TRecorder::Start. - `showMouseCursor`: If kTRUE, mouse cursor is replayed as well.; In that case it is not recommended to use mouse; during replaying. In general, it is not recommended to use mouse to change positions; and states of ROOT windows during replaying. IMPORTANT:; The state of ROOT environment before replaying of some events; must be exactly the same as before recording them.; Therefore it is strongly recommended to start both recording; and replaying with empty ROOT environment. 2] To pause replaying; ```; recorder->Pause(); ```; Replaying is stopped until `recorder->Resume()` is called. 3] To resume paused replaying; ```; recorder->Resume(); ```; Resumes previously stopped replaying. 4] To stop replaying before its end; ```; recorder->Stop(); ```; ",MatchSource.DOCS,gui/recorder/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/recorder/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/gui/recorder/doc/index.md:2401,Usability,pause,paused,2401,"""); ```; or:; ```; TRecorder *recorder = new TRecorder;; recorder->Start(const char *filename, ...); ```; - `filename`: Name of ROOT file in which to save recorded events. 2] To stop recording; ```; recorder->Stop(); ```. IMPORTANT:; State capturing is part of recording. It means that if you want to; record events for some object (window), creation of this object; must be also recorded. #### Example:. ```; t = new TRecorder(); // Create a new recorder; t->Start(""logfile.root""); // ! Start recording first. c = new TCanvas(); // ! Then, create an object; c->Dump(); // Work with that object. t->Stop(); // Stop recording; ```. It is strongly recommended to start recording with empty ROOT; environment, at least with no previously created ROOT GUI.; This ensures that only events for well known windows are stored.; Events for windows, which were not created during recording,; cannot be replayed. ### Replaying. 1] To start replaying; ```; TRecorder r(const char *filename); TRecorder r(const char *filename, ""READ""); ```; or:; ```; TRecorder *recorder = new TRecorder;; recorder->Replay(const char *filename,; Bool_t showMouseCursor = kTRUE);; ```; - `filename`: A name of file with recorded events previously created with TRecorder::Start. - `showMouseCursor`: If kTRUE, mouse cursor is replayed as well.; In that case it is not recommended to use mouse; during replaying. In general, it is not recommended to use mouse to change positions; and states of ROOT windows during replaying. IMPORTANT:; The state of ROOT environment before replaying of some events; must be exactly the same as before recording them.; Therefore it is strongly recommended to start both recording; and replaying with empty ROOT environment. 2] To pause replaying; ```; recorder->Pause(); ```; Replaying is stopped until `recorder->Resume()` is called. 3] To resume paused replaying; ```; recorder->Resume(); ```; Resumes previously stopped replaying. 4] To stop replaying before its end; ```; recorder->Stop(); ```; ",MatchSource.DOCS,gui/recorder/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/recorder/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/gui/webgui6/doc/index.md:478,Performance,perform,performed,478,"\defgroup webgui6 ROOT 6 Web Display; \ingroup webdisplay; \brief To display %ROOT 6 canvases in the web browser. This group contains TWebCanvas class which provides web-based TCanvasImp; and allows display of **%ROOT 6 TCanvas** in the web browser. This is fully reimplements TVirtualX and TVirtualPadPainter classes,; supporting majority of existing ROOT classes. Implementation does not; provide some interactive features - like custom mouse events handling.; Object changes performed in the browser (histogram color change); are not reflected in the C++ objects -; WebGui provides READ-ONLY display capability. ",MatchSource.DOCS,gui/webgui6/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/webgui6/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md:3602,Availability,error,errors,3602,"; {; TH1D * histo1D = new TH1D (""histo1D"","""",2,0.,4.) ;; histo1D->SetBinContent( 1,1.) ;; histo1D->SetBinContent( 2,2.) ;; TCanvas * canvas = new TCanvas () ;; canvas->Divide(2,1) ;; canvas->cd(1) ; gStyle->SetOptStat(""nemruoi"") ; histo1D->DrawClone() ;; canvas->cd(2) ; gStyle->SetOptStat(""nemruoI"") ; histo1D->DrawClone() ;; }; ```; - `TH1` was drawn improperly in ""Logx"" mode if ""X"" axis starts at; negative values. The following macro illustrades this problem. ``` {.cpp}; {; TCanvas *c1 = new TCanvas(""c1"", ""c1"",0,0,1200,700);; int n = 100;; Float_t d = 0.5;; TH1F *h1 = new TH1F(""h1"", ""x_min = - d"", n, -d, 100-d);; h1->Fill(1, 1); h1->Fill(3, 3); h1->Fill(5, 5); h1->Fill(7, 7);. TH1F *h2 = new TH1F(""h2"", ""x_min = +d"", n, d, 100+d);; h2->Fill(1, 1); h2->Fill(3, 3); h2->Fill(5, 5); h2->Fill(7, 7);. c1->Divide(1, 2);; c1->cd(1); gPad->SetLogx(); h1->Draw(); // upper picture; c1->cd(2); gPad->SetLogx(); h2->Draw(); // lower picture; h1->GetXaxis()->SetMoreLogLabels();; h2->GetXaxis()->SetMoreLogLabels();; c1_1->SetGridx();; c1_2->SetGridx();; }; ```; - In `PaintStat2` the temporary string used to paint the fit parameters; was too small and in some cases the errors where truncated. The size; of the string is now the same as in `PaintStat`.; - Display the bin error for 2D histograms in the status bar.; - New option `CANDLE` to draw 2D histograms as Candle-PLot (Box-PLot).; A Candle plot (also known as a ""box-and whisker plot"" or simply ""box plot""); is a convenient way to describe graphically a data distribution (D) with; only the five numbers. It was invented in 1977 by John Tukey. With the option CANDLEX five numbers are:. 1. The minimum value of the distribution D (bottom dashed line).; 2. The lower quartile (Q1): 25% of the data points in D are less than; Q1 (bottom of the box).; 3. The median (M): 50% of the data points in D are less than M; (thick line segment inside the box).; 4. The upper quartile (Q3): 75% of the data points in D are less; than Q3 (top of the box).",MatchSource.DOCS,hist/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md:3704,Availability,error,error,3704,"tStat(""nemruoI"") ; histo1D->DrawClone() ;; }; ```; - `TH1` was drawn improperly in ""Logx"" mode if ""X"" axis starts at; negative values. The following macro illustrades this problem. ``` {.cpp}; {; TCanvas *c1 = new TCanvas(""c1"", ""c1"",0,0,1200,700);; int n = 100;; Float_t d = 0.5;; TH1F *h1 = new TH1F(""h1"", ""x_min = - d"", n, -d, 100-d);; h1->Fill(1, 1); h1->Fill(3, 3); h1->Fill(5, 5); h1->Fill(7, 7);. TH1F *h2 = new TH1F(""h2"", ""x_min = +d"", n, d, 100+d);; h2->Fill(1, 1); h2->Fill(3, 3); h2->Fill(5, 5); h2->Fill(7, 7);. c1->Divide(1, 2);; c1->cd(1); gPad->SetLogx(); h1->Draw(); // upper picture; c1->cd(2); gPad->SetLogx(); h2->Draw(); // lower picture; h1->GetXaxis()->SetMoreLogLabels();; h2->GetXaxis()->SetMoreLogLabels();; c1_1->SetGridx();; c1_2->SetGridx();; }; ```; - In `PaintStat2` the temporary string used to paint the fit parameters; was too small and in some cases the errors where truncated. The size; of the string is now the same as in `PaintStat`.; - Display the bin error for 2D histograms in the status bar.; - New option `CANDLE` to draw 2D histograms as Candle-PLot (Box-PLot).; A Candle plot (also known as a ""box-and whisker plot"" or simply ""box plot""); is a convenient way to describe graphically a data distribution (D) with; only the five numbers. It was invented in 1977 by John Tukey. With the option CANDLEX five numbers are:. 1. The minimum value of the distribution D (bottom dashed line).; 2. The lower quartile (Q1): 25% of the data points in D are less than; Q1 (bottom of the box).; 3. The median (M): 50% of the data points in D are less than M; (thick line segment inside the box).; 4. The upper quartile (Q3): 75% of the data points in D are less; than Q3 (top of the box).; 5. The maximum value of the distribution D (top dashed line). The mean value of the distribution D is also represented as a circle. In this implementation a TH2 is considered as a collection of TH1 along; X (option `CANDLE` or `CANDLEX`) or Y (option `CANDLEY`).; Each TH1 is repres",MatchSource.DOCS,hist/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md:8200,Availability,error,errors,8200,"ists still in ROOT 6.0 but it has no effect.; One should use now the new function `TH1::SetCanExtend(..)` passing the axis (using the appropriate enumeration), which needs to be extended.; In addition to extend each axis individually, the function can be used also to enable/disable extension for all axes.; For example `TH1::SetCanExtend(TH1::kXaxis)` will make extendable only the X axis; `TH1::SetCanExtend(TH1::kAllAxes)` will; make extendable all the axes (this is the same functionality of the previous function `SetBit(TH1::kCanRebin)` and; `TH1::SetCanExtend(TH1::kNoAxis)` will remove the extendable functionality to all the axes (equivalent to the old `ResetBit(TH1::kCanRebin)`).; The functionality of `TestBit(TH1::kCanRebin)` is now replaced by `TH1::CanExtendAllAxis()`. - An histogram filled with weights different than one has now automatically the sum of the weight squared stored inside, without the need to call anymore; `TH1::Sumw2()`. As a consequences an histogram filled with weights will always draw the errors by default. If one desire to continue having the histogram drawn; without the errors, one should use the `hist` option: `h.Draw(""hist"")`.; If, for memory reason, one does not want to remove the internal array storing the bin errors (the bin sum of weight square), one can use the function `TH1::Sumw2(false)`. - The copy constructor is not anymore public for TH1. Before (in 5.34) this code was allowed by the compiler, although giving undefined behavior: now not anymore:. ``` {.cpp}; TH1D h1;; TH1 h2(h1);; ```; Now this code is not allowed anymore. It will give a compilation error.; The copy constructor of the derived classes (`TH1D` in this example) should instead be used.; This applies also for `TH2` and `TH3`.; In case you want to copy histograms using the TH1 interface, you can use either `TObject::Clone`, which uses the I/O system and can be unconvenient in some cases (e.g. in a multi-threaded; environment) or `TH1::Copy` which is public since some o",MatchSource.DOCS,hist/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md:8285,Availability,error,errors,8285,".)` passing the axis (using the appropriate enumeration), which needs to be extended.; In addition to extend each axis individually, the function can be used also to enable/disable extension for all axes.; For example `TH1::SetCanExtend(TH1::kXaxis)` will make extendable only the X axis; `TH1::SetCanExtend(TH1::kAllAxes)` will; make extendable all the axes (this is the same functionality of the previous function `SetBit(TH1::kCanRebin)` and; `TH1::SetCanExtend(TH1::kNoAxis)` will remove the extendable functionality to all the axes (equivalent to the old `ResetBit(TH1::kCanRebin)`).; The functionality of `TestBit(TH1::kCanRebin)` is now replaced by `TH1::CanExtendAllAxis()`. - An histogram filled with weights different than one has now automatically the sum of the weight squared stored inside, without the need to call anymore; `TH1::Sumw2()`. As a consequences an histogram filled with weights will always draw the errors by default. If one desire to continue having the histogram drawn; without the errors, one should use the `hist` option: `h.Draw(""hist"")`.; If, for memory reason, one does not want to remove the internal array storing the bin errors (the bin sum of weight square), one can use the function `TH1::Sumw2(false)`. - The copy constructor is not anymore public for TH1. Before (in 5.34) this code was allowed by the compiler, although giving undefined behavior: now not anymore:. ``` {.cpp}; TH1D h1;; TH1 h2(h1);; ```; Now this code is not allowed anymore. It will give a compilation error.; The copy constructor of the derived classes (`TH1D` in this example) should instead be used.; This applies also for `TH2` and `TH3`.; In case you want to copy histograms using the TH1 interface, you can use either `TObject::Clone`, which uses the I/O system and can be unconvenient in some cases (e.g. in a multi-threaded; environment) or `TH1::Copy` which is public since some of the latest 5.34 revisions together with `TClass::New` as following:. ``` {.cpp}; TH1 * h2 = (TH1*) ",MatchSource.DOCS,hist/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md:8432,Availability,error,errors,8432,"d also to enable/disable extension for all axes.; For example `TH1::SetCanExtend(TH1::kXaxis)` will make extendable only the X axis; `TH1::SetCanExtend(TH1::kAllAxes)` will; make extendable all the axes (this is the same functionality of the previous function `SetBit(TH1::kCanRebin)` and; `TH1::SetCanExtend(TH1::kNoAxis)` will remove the extendable functionality to all the axes (equivalent to the old `ResetBit(TH1::kCanRebin)`).; The functionality of `TestBit(TH1::kCanRebin)` is now replaced by `TH1::CanExtendAllAxis()`. - An histogram filled with weights different than one has now automatically the sum of the weight squared stored inside, without the need to call anymore; `TH1::Sumw2()`. As a consequences an histogram filled with weights will always draw the errors by default. If one desire to continue having the histogram drawn; without the errors, one should use the `hist` option: `h.Draw(""hist"")`.; If, for memory reason, one does not want to remove the internal array storing the bin errors (the bin sum of weight square), one can use the function `TH1::Sumw2(false)`. - The copy constructor is not anymore public for TH1. Before (in 5.34) this code was allowed by the compiler, although giving undefined behavior: now not anymore:. ``` {.cpp}; TH1D h1;; TH1 h2(h1);; ```; Now this code is not allowed anymore. It will give a compilation error.; The copy constructor of the derived classes (`TH1D` in this example) should instead be used.; This applies also for `TH2` and `TH3`.; In case you want to copy histograms using the TH1 interface, you can use either `TObject::Clone`, which uses the I/O system and can be unconvenient in some cases (e.g. in a multi-threaded; environment) or `TH1::Copy` which is public since some of the latest 5.34 revisions together with `TClass::New` as following:. ``` {.cpp}; TH1 * h2 = (TH1*) h1->IsA()->New();; h1->Copy(*h2);; ```; Note that `TH1::Copy` does not copy the attached list of functions, while `TH1::Clone()` does a deep copy also of th",MatchSource.DOCS,hist/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md:8786,Availability,error,error,8786,"dable functionality to all the axes (equivalent to the old `ResetBit(TH1::kCanRebin)`).; The functionality of `TestBit(TH1::kCanRebin)` is now replaced by `TH1::CanExtendAllAxis()`. - An histogram filled with weights different than one has now automatically the sum of the weight squared stored inside, without the need to call anymore; `TH1::Sumw2()`. As a consequences an histogram filled with weights will always draw the errors by default. If one desire to continue having the histogram drawn; without the errors, one should use the `hist` option: `h.Draw(""hist"")`.; If, for memory reason, one does not want to remove the internal array storing the bin errors (the bin sum of weight square), one can use the function `TH1::Sumw2(false)`. - The copy constructor is not anymore public for TH1. Before (in 5.34) this code was allowed by the compiler, although giving undefined behavior: now not anymore:. ``` {.cpp}; TH1D h1;; TH1 h2(h1);; ```; Now this code is not allowed anymore. It will give a compilation error.; The copy constructor of the derived classes (`TH1D` in this example) should instead be used.; This applies also for `TH2` and `TH3`.; In case you want to copy histograms using the TH1 interface, you can use either `TObject::Clone`, which uses the I/O system and can be unconvenient in some cases (e.g. in a multi-threaded; environment) or `TH1::Copy` which is public since some of the latest 5.34 revisions together with `TClass::New` as following:. ``` {.cpp}; TH1 * h2 = (TH1*) h1->IsA()->New();; h1->Copy(*h2);; ```; Note that `TH1::Copy` does not copy the attached list of functions, while `TH1::Clone()` does a deep copy also of the contained functions. - Add new method `TH1::GetNCells` to retrieve the total number of bins of an histogram including underflow and overflows. This is the product of all the bins in each dimension. - The methods `GetCellContent`, `GetCellError` and `SetCellContent` and `SetCellError` have been deprecated. Get/SetBinContent and Get/SetBinErro",MatchSource.DOCS,hist/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md:10297,Availability,error,error,10297,"` does not copy the attached list of functions, while `TH1::Clone()` does a deep copy also of the contained functions. - Add new method `TH1::GetNCells` to retrieve the total number of bins of an histogram including underflow and overflows. This is the product of all the bins in each dimension. - The methods `GetCellContent`, `GetCellError` and `SetCellContent` and `SetCellError` have been deprecated. Get/SetBinContent and Get/SetBinError should be instead used and they have exactly the; same functionality. - The following code should produce a plot. It did not. ``` {.cpp}; TH1F* h=new TH1F(""hist"", ""histogram"", 10, 0, 3);; h->FillRandom(""gaus"");; h->Draw(""same"");; ```; - Make sure histograms having quotes in title are properly saved in .C files. ### TH2, TH3. - Add new functions `TH2::QuantilesX` and `TH2::QuantilesY` to return in a 1D histogram the projected quantiles distribution along; the other Y or X axis. The return histogram will have as bin error an approximate error on the quantile assuming a normal distribution of the; bin contents in the other axis. - Update Projection methods of both TH2 and TH3 to not return a null; pointer when an histogram with the same name already existed and it; was not compatible. Now just set the new correct binning on the; previously existing histogram. ### TGraph. - `TGraph::Draw()` needed at least the option `AL` to draw the graph; axis even when there was no active canvas or when the active canvas; did not have any axis defined. This was counter-intuitive. Now if; `TGraph::Draw()` is invoked without parameter and if there is no; axis defined in the current canvas, the option `ALP` is automatically; set.; - Change `SavePrimtive()` to improve speed compilation on generated macros. ### TGraph2D. - When `GetX(YZ)axis` were called on a `TGraph2D`, the frame limit and; plotting options were changed.; - Modify the `Clear` function in order to be able to reuse a; `TGraph2D` after a `Clear` is performed.; - In `GetHistogram()` the low",MatchSource.DOCS,hist/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md:10318,Availability,error,error,10318,"` does not copy the attached list of functions, while `TH1::Clone()` does a deep copy also of the contained functions. - Add new method `TH1::GetNCells` to retrieve the total number of bins of an histogram including underflow and overflows. This is the product of all the bins in each dimension. - The methods `GetCellContent`, `GetCellError` and `SetCellContent` and `SetCellError` have been deprecated. Get/SetBinContent and Get/SetBinError should be instead used and they have exactly the; same functionality. - The following code should produce a plot. It did not. ``` {.cpp}; TH1F* h=new TH1F(""hist"", ""histogram"", 10, 0, 3);; h->FillRandom(""gaus"");; h->Draw(""same"");; ```; - Make sure histograms having quotes in title are properly saved in .C files. ### TH2, TH3. - Add new functions `TH2::QuantilesX` and `TH2::QuantilesY` to return in a 1D histogram the projected quantiles distribution along; the other Y or X axis. The return histogram will have as bin error an approximate error on the quantile assuming a normal distribution of the; bin contents in the other axis. - Update Projection methods of both TH2 and TH3 to not return a null; pointer when an histogram with the same name already existed and it; was not compatible. Now just set the new correct binning on the; previously existing histogram. ### TGraph. - `TGraph::Draw()` needed at least the option `AL` to draw the graph; axis even when there was no active canvas or when the active canvas; did not have any axis defined. This was counter-intuitive. Now if; `TGraph::Draw()` is invoked without parameter and if there is no; axis defined in the current canvas, the option `ALP` is automatically; set.; - Change `SavePrimtive()` to improve speed compilation on generated macros. ### TGraph2D. - When `GetX(YZ)axis` were called on a `TGraph2D`, the frame limit and; plotting options were changed.; - Modify the `Clear` function in order to be able to reuse a; `TGraph2D` after a `Clear` is performed.; - In `GetHistogram()` the low",MatchSource.DOCS,hist/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md:12760,Availability,error,error,12760,"ll; be added with the option it had in `multigraph`.; - The option ""A"" in the `Draw()` was not cleaning properly the; current pad.; - Implement this option `pads`. This option is equivalent to the one in; `THStack`. It allows to draw all the `TGraphs` in separated pads. ### THStack. - By default the background of the histograms is erased before drawing the; histograms. The new option `noclear` avoid this behaviour. This is useful; when drawing a `THStack` on top of an other plot. If the patterns used to; draw the histograms in the stack are transparents, then the plot behind; will be visible. ### TH2Poly. - Implement a simple version of ""Scale"". ### TF1. - Change `TF1::Integral(double a, double b, double * params = 0, double eps = 1.E-12)` to; `TF1::Integral(doubnle a, double b, double epsrel=1.E-12)`. One should use `TF1::SetParameters` to; set the function parameters before computing the integral. - Add a new function `TF1::IntegralOneDim(Double_t a, Double_t b, Double_t epsrel, Double_t epsabs, Double_t &err)`; that returns as last argument the error in the integration. `TF1::Integral` is implemented using `Tf1::IntegralOneDim`. - The one-dim and multi-dim integral functions are now implemented using the `ROOT::Math::IntegratorOneDim` and `ROOT::Math::IntegratorMultiDim`; classes. This allows to change the integration algorithm used in `TF1` using the static methods of the classes; `ROOT::Math::IntegratorOneDimOptions` and `ROOT::Math::IntegratorMultiDimOptions`. The default algorithm used are; `ROOT::Math::IntegratorOneDimOptions::DefaultIntegratorType()` and `ROOT::Math::IntegratorMultiDimOptions::DefaultIntegratorType()`.; For example, if ROOT has been built with mathmore the default one-dim integration type is the GSL AdaptiveSingular integration algorithm. - Implement the possibility to save a `TF1` as C code indenpant from; ROOT. It is enough to save the function as a "".cc"" file. \; Example:. ``` {.cpp}; root [0] TF1 *f1 = new TF1(""f1"",""x*x"",-10,10); root [1",MatchSource.DOCS,hist/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md:12773,Deployability,integrat,integration,12773,"ll; be added with the option it had in `multigraph`.; - The option ""A"" in the `Draw()` was not cleaning properly the; current pad.; - Implement this option `pads`. This option is equivalent to the one in; `THStack`. It allows to draw all the `TGraphs` in separated pads. ### THStack. - By default the background of the histograms is erased before drawing the; histograms. The new option `noclear` avoid this behaviour. This is useful; when drawing a `THStack` on top of an other plot. If the patterns used to; draw the histograms in the stack are transparents, then the plot behind; will be visible. ### TH2Poly. - Implement a simple version of ""Scale"". ### TF1. - Change `TF1::Integral(double a, double b, double * params = 0, double eps = 1.E-12)` to; `TF1::Integral(doubnle a, double b, double epsrel=1.E-12)`. One should use `TF1::SetParameters` to; set the function parameters before computing the integral. - Add a new function `TF1::IntegralOneDim(Double_t a, Double_t b, Double_t epsrel, Double_t epsabs, Double_t &err)`; that returns as last argument the error in the integration. `TF1::Integral` is implemented using `Tf1::IntegralOneDim`. - The one-dim and multi-dim integral functions are now implemented using the `ROOT::Math::IntegratorOneDim` and `ROOT::Math::IntegratorMultiDim`; classes. This allows to change the integration algorithm used in `TF1` using the static methods of the classes; `ROOT::Math::IntegratorOneDimOptions` and `ROOT::Math::IntegratorMultiDimOptions`. The default algorithm used are; `ROOT::Math::IntegratorOneDimOptions::DefaultIntegratorType()` and `ROOT::Math::IntegratorMultiDimOptions::DefaultIntegratorType()`.; For example, if ROOT has been built with mathmore the default one-dim integration type is the GSL AdaptiveSingular integration algorithm. - Implement the possibility to save a `TF1` as C code indenpant from; ROOT. It is enough to save the function as a "".cc"" file. \; Example:. ``` {.cpp}; root [0] TF1 *f1 = new TF1(""f1"",""x*x"",-10,10); root [1",MatchSource.DOCS,hist/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md:13027,Deployability,integrat,integration,13027,"avoid this behaviour. This is useful; when drawing a `THStack` on top of an other plot. If the patterns used to; draw the histograms in the stack are transparents, then the plot behind; will be visible. ### TH2Poly. - Implement a simple version of ""Scale"". ### TF1. - Change `TF1::Integral(double a, double b, double * params = 0, double eps = 1.E-12)` to; `TF1::Integral(doubnle a, double b, double epsrel=1.E-12)`. One should use `TF1::SetParameters` to; set the function parameters before computing the integral. - Add a new function `TF1::IntegralOneDim(Double_t a, Double_t b, Double_t epsrel, Double_t epsabs, Double_t &err)`; that returns as last argument the error in the integration. `TF1::Integral` is implemented using `Tf1::IntegralOneDim`. - The one-dim and multi-dim integral functions are now implemented using the `ROOT::Math::IntegratorOneDim` and `ROOT::Math::IntegratorMultiDim`; classes. This allows to change the integration algorithm used in `TF1` using the static methods of the classes; `ROOT::Math::IntegratorOneDimOptions` and `ROOT::Math::IntegratorMultiDimOptions`. The default algorithm used are; `ROOT::Math::IntegratorOneDimOptions::DefaultIntegratorType()` and `ROOT::Math::IntegratorMultiDimOptions::DefaultIntegratorType()`.; For example, if ROOT has been built with mathmore the default one-dim integration type is the GSL AdaptiveSingular integration algorithm. - Implement the possibility to save a `TF1` as C code indenpant from; ROOT. It is enough to save the function as a "".cc"" file. \; Example:. ``` {.cpp}; root [0] TF1 *f1 = new TF1(""f1"",""x*x"",-10,10); root [1] f1->SaveAs(""f1.cc"");; Info in <TF1::SaveAs>: cc file: f1.cc has been generated; root [2] .x f1.cc(9.); (double)8.10019368181367980e+01; ```. ### TF2, TF3. - Implement `TF2::GetMinimumXY` and `TF3::GetMinimumXYZ` using the `ROOT::Math::Minimizer` class instead of `TFitter`. The methods return now the function value at the minimum. - Implement also a `TF2::GetMaximumXY` and `TF3::GetMaximumXYZ",MatchSource.DOCS,hist/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md:13423,Deployability,integrat,integration,13423,"ts, then the plot behind; will be visible. ### TH2Poly. - Implement a simple version of ""Scale"". ### TF1. - Change `TF1::Integral(double a, double b, double * params = 0, double eps = 1.E-12)` to; `TF1::Integral(doubnle a, double b, double epsrel=1.E-12)`. One should use `TF1::SetParameters` to; set the function parameters before computing the integral. - Add a new function `TF1::IntegralOneDim(Double_t a, Double_t b, Double_t epsrel, Double_t epsabs, Double_t &err)`; that returns as last argument the error in the integration. `TF1::Integral` is implemented using `Tf1::IntegralOneDim`. - The one-dim and multi-dim integral functions are now implemented using the `ROOT::Math::IntegratorOneDim` and `ROOT::Math::IntegratorMultiDim`; classes. This allows to change the integration algorithm used in `TF1` using the static methods of the classes; `ROOT::Math::IntegratorOneDimOptions` and `ROOT::Math::IntegratorMultiDimOptions`. The default algorithm used are; `ROOT::Math::IntegratorOneDimOptions::DefaultIntegratorType()` and `ROOT::Math::IntegratorMultiDimOptions::DefaultIntegratorType()`.; For example, if ROOT has been built with mathmore the default one-dim integration type is the GSL AdaptiveSingular integration algorithm. - Implement the possibility to save a `TF1` as C code indenpant from; ROOT. It is enough to save the function as a "".cc"" file. \; Example:. ``` {.cpp}; root [0] TF1 *f1 = new TF1(""f1"",""x*x"",-10,10); root [1] f1->SaveAs(""f1.cc"");; Info in <TF1::SaveAs>: cc file: f1.cc has been generated; root [2] .x f1.cc(9.); (double)8.10019368181367980e+01; ```. ### TF2, TF3. - Implement `TF2::GetMinimumXY` and `TF3::GetMinimumXYZ` using the `ROOT::Math::Minimizer` class instead of `TFitter`. The methods return now the function value at the minimum. - Implement also a `TF2::GetMaximumXY` and `TF3::GetMaximumXYZ`. - Remove some ambigous `Integral` functions. ### TFractionFitter, TBinomialFitter. - Change to use the `ROOT::Math::Fitter` instead of the `TFitter` class.; ",MatchSource.DOCS,hist/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md:13468,Deployability,integrat,integration,13468,"ts, then the plot behind; will be visible. ### TH2Poly. - Implement a simple version of ""Scale"". ### TF1. - Change `TF1::Integral(double a, double b, double * params = 0, double eps = 1.E-12)` to; `TF1::Integral(doubnle a, double b, double epsrel=1.E-12)`. One should use `TF1::SetParameters` to; set the function parameters before computing the integral. - Add a new function `TF1::IntegralOneDim(Double_t a, Double_t b, Double_t epsrel, Double_t epsabs, Double_t &err)`; that returns as last argument the error in the integration. `TF1::Integral` is implemented using `Tf1::IntegralOneDim`. - The one-dim and multi-dim integral functions are now implemented using the `ROOT::Math::IntegratorOneDim` and `ROOT::Math::IntegratorMultiDim`; classes. This allows to change the integration algorithm used in `TF1` using the static methods of the classes; `ROOT::Math::IntegratorOneDimOptions` and `ROOT::Math::IntegratorMultiDimOptions`. The default algorithm used are; `ROOT::Math::IntegratorOneDimOptions::DefaultIntegratorType()` and `ROOT::Math::IntegratorMultiDimOptions::DefaultIntegratorType()`.; For example, if ROOT has been built with mathmore the default one-dim integration type is the GSL AdaptiveSingular integration algorithm. - Implement the possibility to save a `TF1` as C code indenpant from; ROOT. It is enough to save the function as a "".cc"" file. \; Example:. ``` {.cpp}; root [0] TF1 *f1 = new TF1(""f1"",""x*x"",-10,10); root [1] f1->SaveAs(""f1.cc"");; Info in <TF1::SaveAs>: cc file: f1.cc has been generated; root [2] .x f1.cc(9.); (double)8.10019368181367980e+01; ```. ### TF2, TF3. - Implement `TF2::GetMinimumXY` and `TF3::GetMinimumXYZ` using the `ROOT::Math::Minimizer` class instead of `TFitter`. The methods return now the function value at the minimum. - Implement also a `TF2::GetMaximumXY` and `TF3::GetMaximumXYZ`. - Remove some ambigous `Integral` functions. ### TFractionFitter, TBinomialFitter. - Change to use the `ROOT::Math::Fitter` instead of the `TFitter` class.; ",MatchSource.DOCS,hist/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md:8978,Integrability,interface,interface,8978,"e has now automatically the sum of the weight squared stored inside, without the need to call anymore; `TH1::Sumw2()`. As a consequences an histogram filled with weights will always draw the errors by default. If one desire to continue having the histogram drawn; without the errors, one should use the `hist` option: `h.Draw(""hist"")`.; If, for memory reason, one does not want to remove the internal array storing the bin errors (the bin sum of weight square), one can use the function `TH1::Sumw2(false)`. - The copy constructor is not anymore public for TH1. Before (in 5.34) this code was allowed by the compiler, although giving undefined behavior: now not anymore:. ``` {.cpp}; TH1D h1;; TH1 h2(h1);; ```; Now this code is not allowed anymore. It will give a compilation error.; The copy constructor of the derived classes (`TH1D` in this example) should instead be used.; This applies also for `TH2` and `TH3`.; In case you want to copy histograms using the TH1 interface, you can use either `TObject::Clone`, which uses the I/O system and can be unconvenient in some cases (e.g. in a multi-threaded; environment) or `TH1::Copy` which is public since some of the latest 5.34 revisions together with `TClass::New` as following:. ``` {.cpp}; TH1 * h2 = (TH1*) h1->IsA()->New();; h1->Copy(*h2);; ```; Note that `TH1::Copy` does not copy the attached list of functions, while `TH1::Clone()` does a deep copy also of the contained functions. - Add new method `TH1::GetNCells` to retrieve the total number of bins of an histogram including underflow and overflows. This is the product of all the bins in each dimension. - The methods `GetCellContent`, `GetCellError` and `SetCellContent` and `SetCellError` have been deprecated. Get/SetBinContent and Get/SetBinError should be instead used and they have exactly the; same functionality. - The following code should produce a plot. It did not. ``` {.cpp}; TH1F* h=new TH1F(""hist"", ""histogram"", 10, 0, 3);; h->FillRandom(""gaus"");; h->Draw(""same"");; ```",MatchSource.DOCS,hist/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md:12773,Integrability,integrat,integration,12773,"ll; be added with the option it had in `multigraph`.; - The option ""A"" in the `Draw()` was not cleaning properly the; current pad.; - Implement this option `pads`. This option is equivalent to the one in; `THStack`. It allows to draw all the `TGraphs` in separated pads. ### THStack. - By default the background of the histograms is erased before drawing the; histograms. The new option `noclear` avoid this behaviour. This is useful; when drawing a `THStack` on top of an other plot. If the patterns used to; draw the histograms in the stack are transparents, then the plot behind; will be visible. ### TH2Poly. - Implement a simple version of ""Scale"". ### TF1. - Change `TF1::Integral(double a, double b, double * params = 0, double eps = 1.E-12)` to; `TF1::Integral(doubnle a, double b, double epsrel=1.E-12)`. One should use `TF1::SetParameters` to; set the function parameters before computing the integral. - Add a new function `TF1::IntegralOneDim(Double_t a, Double_t b, Double_t epsrel, Double_t epsabs, Double_t &err)`; that returns as last argument the error in the integration. `TF1::Integral` is implemented using `Tf1::IntegralOneDim`. - The one-dim and multi-dim integral functions are now implemented using the `ROOT::Math::IntegratorOneDim` and `ROOT::Math::IntegratorMultiDim`; classes. This allows to change the integration algorithm used in `TF1` using the static methods of the classes; `ROOT::Math::IntegratorOneDimOptions` and `ROOT::Math::IntegratorMultiDimOptions`. The default algorithm used are; `ROOT::Math::IntegratorOneDimOptions::DefaultIntegratorType()` and `ROOT::Math::IntegratorMultiDimOptions::DefaultIntegratorType()`.; For example, if ROOT has been built with mathmore the default one-dim integration type is the GSL AdaptiveSingular integration algorithm. - Implement the possibility to save a `TF1` as C code indenpant from; ROOT. It is enough to save the function as a "".cc"" file. \; Example:. ``` {.cpp}; root [0] TF1 *f1 = new TF1(""f1"",""x*x"",-10,10); root [1",MatchSource.DOCS,hist/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md:13027,Integrability,integrat,integration,13027,"avoid this behaviour. This is useful; when drawing a `THStack` on top of an other plot. If the patterns used to; draw the histograms in the stack are transparents, then the plot behind; will be visible. ### TH2Poly. - Implement a simple version of ""Scale"". ### TF1. - Change `TF1::Integral(double a, double b, double * params = 0, double eps = 1.E-12)` to; `TF1::Integral(doubnle a, double b, double epsrel=1.E-12)`. One should use `TF1::SetParameters` to; set the function parameters before computing the integral. - Add a new function `TF1::IntegralOneDim(Double_t a, Double_t b, Double_t epsrel, Double_t epsabs, Double_t &err)`; that returns as last argument the error in the integration. `TF1::Integral` is implemented using `Tf1::IntegralOneDim`. - The one-dim and multi-dim integral functions are now implemented using the `ROOT::Math::IntegratorOneDim` and `ROOT::Math::IntegratorMultiDim`; classes. This allows to change the integration algorithm used in `TF1` using the static methods of the classes; `ROOT::Math::IntegratorOneDimOptions` and `ROOT::Math::IntegratorMultiDimOptions`. The default algorithm used are; `ROOT::Math::IntegratorOneDimOptions::DefaultIntegratorType()` and `ROOT::Math::IntegratorMultiDimOptions::DefaultIntegratorType()`.; For example, if ROOT has been built with mathmore the default one-dim integration type is the GSL AdaptiveSingular integration algorithm. - Implement the possibility to save a `TF1` as C code indenpant from; ROOT. It is enough to save the function as a "".cc"" file. \; Example:. ``` {.cpp}; root [0] TF1 *f1 = new TF1(""f1"",""x*x"",-10,10); root [1] f1->SaveAs(""f1.cc"");; Info in <TF1::SaveAs>: cc file: f1.cc has been generated; root [2] .x f1.cc(9.); (double)8.10019368181367980e+01; ```. ### TF2, TF3. - Implement `TF2::GetMinimumXY` and `TF3::GetMinimumXYZ` using the `ROOT::Math::Minimizer` class instead of `TFitter`. The methods return now the function value at the minimum. - Implement also a `TF2::GetMaximumXY` and `TF3::GetMaximumXYZ",MatchSource.DOCS,hist/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md:13423,Integrability,integrat,integration,13423,"ts, then the plot behind; will be visible. ### TH2Poly. - Implement a simple version of ""Scale"". ### TF1. - Change `TF1::Integral(double a, double b, double * params = 0, double eps = 1.E-12)` to; `TF1::Integral(doubnle a, double b, double epsrel=1.E-12)`. One should use `TF1::SetParameters` to; set the function parameters before computing the integral. - Add a new function `TF1::IntegralOneDim(Double_t a, Double_t b, Double_t epsrel, Double_t epsabs, Double_t &err)`; that returns as last argument the error in the integration. `TF1::Integral` is implemented using `Tf1::IntegralOneDim`. - The one-dim and multi-dim integral functions are now implemented using the `ROOT::Math::IntegratorOneDim` and `ROOT::Math::IntegratorMultiDim`; classes. This allows to change the integration algorithm used in `TF1` using the static methods of the classes; `ROOT::Math::IntegratorOneDimOptions` and `ROOT::Math::IntegratorMultiDimOptions`. The default algorithm used are; `ROOT::Math::IntegratorOneDimOptions::DefaultIntegratorType()` and `ROOT::Math::IntegratorMultiDimOptions::DefaultIntegratorType()`.; For example, if ROOT has been built with mathmore the default one-dim integration type is the GSL AdaptiveSingular integration algorithm. - Implement the possibility to save a `TF1` as C code indenpant from; ROOT. It is enough to save the function as a "".cc"" file. \; Example:. ``` {.cpp}; root [0] TF1 *f1 = new TF1(""f1"",""x*x"",-10,10); root [1] f1->SaveAs(""f1.cc"");; Info in <TF1::SaveAs>: cc file: f1.cc has been generated; root [2] .x f1.cc(9.); (double)8.10019368181367980e+01; ```. ### TF2, TF3. - Implement `TF2::GetMinimumXY` and `TF3::GetMinimumXYZ` using the `ROOT::Math::Minimizer` class instead of `TFitter`. The methods return now the function value at the minimum. - Implement also a `TF2::GetMaximumXY` and `TF3::GetMaximumXYZ`. - Remove some ambigous `Integral` functions. ### TFractionFitter, TBinomialFitter. - Change to use the `ROOT::Math::Fitter` instead of the `TFitter` class.; ",MatchSource.DOCS,hist/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md:13468,Integrability,integrat,integration,13468,"ts, then the plot behind; will be visible. ### TH2Poly. - Implement a simple version of ""Scale"". ### TF1. - Change `TF1::Integral(double a, double b, double * params = 0, double eps = 1.E-12)` to; `TF1::Integral(doubnle a, double b, double epsrel=1.E-12)`. One should use `TF1::SetParameters` to; set the function parameters before computing the integral. - Add a new function `TF1::IntegralOneDim(Double_t a, Double_t b, Double_t epsrel, Double_t epsabs, Double_t &err)`; that returns as last argument the error in the integration. `TF1::Integral` is implemented using `Tf1::IntegralOneDim`. - The one-dim and multi-dim integral functions are now implemented using the `ROOT::Math::IntegratorOneDim` and `ROOT::Math::IntegratorMultiDim`; classes. This allows to change the integration algorithm used in `TF1` using the static methods of the classes; `ROOT::Math::IntegratorOneDimOptions` and `ROOT::Math::IntegratorMultiDimOptions`. The default algorithm used are; `ROOT::Math::IntegratorOneDimOptions::DefaultIntegratorType()` and `ROOT::Math::IntegratorMultiDimOptions::DefaultIntegratorType()`.; For example, if ROOT has been built with mathmore the default one-dim integration type is the GSL AdaptiveSingular integration algorithm. - Implement the possibility to save a `TF1` as C code indenpant from; ROOT. It is enough to save the function as a "".cc"" file. \; Example:. ``` {.cpp}; root [0] TF1 *f1 = new TF1(""f1"",""x*x"",-10,10); root [1] f1->SaveAs(""f1.cc"");; Info in <TF1::SaveAs>: cc file: f1.cc has been generated; root [2] .x f1.cc(9.); (double)8.10019368181367980e+01; ```. ### TF2, TF3. - Implement `TF2::GetMinimumXY` and `TF3::GetMinimumXYZ` using the `ROOT::Math::Minimizer` class instead of `TFitter`. The methods return now the function value at the minimum. - Implement also a `TF2::GetMaximumXY` and `TF3::GetMaximumXYZ`. - Remove some ambigous `Integral` functions. ### TFractionFitter, TBinomialFitter. - Change to use the `ROOT::Math::Fitter` instead of the `TFitter` class.; ",MatchSource.DOCS,hist/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md:7117,Modifiability,extend,extend,7117,"ntent(3,3.);. c->cd(2); gPad->DrawFrame(4.,0., 10.,5.);; histo2->Draw(""same"");; }; ```; - In `TGraph2DPainter::PaintLevels` the colour levels used to paint; the triangles did not match the minimum and maximum set by the; user on the `TGraph2D`. This problem was reported; [here](http://root.cern.ch/phpBB3/viewtopic.php?f=3&t=16937&p=72314#p72314). ### TPaletteAxis. - The histogram Z axis title is now painted along the palette axis. ### TAxis. - The Axis has a new public bit `TAxis::kCanExtend`, which control the axis extensions (for example in case of time axis) and used to; replace the old bit `TH1::kCanRebin` (see below).; Note that this bit is automatically set when the axis has labels associated to each bin. In this case the axis becomes alphanumeric and; there is no more relation to the observed quantities. Note that when an axis is alphanumeric the mean and the rms of the histograms are not anymore; coputed and they are set to zero. ### TH1. - The bit `TH1::kCanRebin` used to extend the histogram axes is now deprecated. The bit exists still in ROOT 6.0 but it has no effect.; One should use now the new function `TH1::SetCanExtend(..)` passing the axis (using the appropriate enumeration), which needs to be extended.; In addition to extend each axis individually, the function can be used also to enable/disable extension for all axes.; For example `TH1::SetCanExtend(TH1::kXaxis)` will make extendable only the X axis; `TH1::SetCanExtend(TH1::kAllAxes)` will; make extendable all the axes (this is the same functionality of the previous function `SetBit(TH1::kCanRebin)` and; `TH1::SetCanExtend(TH1::kNoAxis)` will remove the extendable functionality to all the axes (equivalent to the old `ResetBit(TH1::kCanRebin)`).; The functionality of `TestBit(TH1::kCanRebin)` is now replaced by `TH1::CanExtendAllAxis()`. - An histogram filled with weights different than one has now automatically the sum of the weight squared stored inside, without the need to call anymore; `TH1::Sum",MatchSource.DOCS,hist/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md:7350,Modifiability,extend,extended,7350," and maximum set by the; user on the `TGraph2D`. This problem was reported; [here](http://root.cern.ch/phpBB3/viewtopic.php?f=3&t=16937&p=72314#p72314). ### TPaletteAxis. - The histogram Z axis title is now painted along the palette axis. ### TAxis. - The Axis has a new public bit `TAxis::kCanExtend`, which control the axis extensions (for example in case of time axis) and used to; replace the old bit `TH1::kCanRebin` (see below).; Note that this bit is automatically set when the axis has labels associated to each bin. In this case the axis becomes alphanumeric and; there is no more relation to the observed quantities. Note that when an axis is alphanumeric the mean and the rms of the histograms are not anymore; coputed and they are set to zero. ### TH1. - The bit `TH1::kCanRebin` used to extend the histogram axes is now deprecated. The bit exists still in ROOT 6.0 but it has no effect.; One should use now the new function `TH1::SetCanExtend(..)` passing the axis (using the appropriate enumeration), which needs to be extended.; In addition to extend each axis individually, the function can be used also to enable/disable extension for all axes.; For example `TH1::SetCanExtend(TH1::kXaxis)` will make extendable only the X axis; `TH1::SetCanExtend(TH1::kAllAxes)` will; make extendable all the axes (this is the same functionality of the previous function `SetBit(TH1::kCanRebin)` and; `TH1::SetCanExtend(TH1::kNoAxis)` will remove the extendable functionality to all the axes (equivalent to the old `ResetBit(TH1::kCanRebin)`).; The functionality of `TestBit(TH1::kCanRebin)` is now replaced by `TH1::CanExtendAllAxis()`. - An histogram filled with weights different than one has now automatically the sum of the weight squared stored inside, without the need to call anymore; `TH1::Sumw2()`. As a consequences an histogram filled with weights will always draw the errors by default. If one desire to continue having the histogram drawn; without the errors, one should use the `hist",MatchSource.DOCS,hist/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md:7376,Modifiability,extend,extend,7376,"h/phpBB3/viewtopic.php?f=3&t=16937&p=72314#p72314). ### TPaletteAxis. - The histogram Z axis title is now painted along the palette axis. ### TAxis. - The Axis has a new public bit `TAxis::kCanExtend`, which control the axis extensions (for example in case of time axis) and used to; replace the old bit `TH1::kCanRebin` (see below).; Note that this bit is automatically set when the axis has labels associated to each bin. In this case the axis becomes alphanumeric and; there is no more relation to the observed quantities. Note that when an axis is alphanumeric the mean and the rms of the histograms are not anymore; coputed and they are set to zero. ### TH1. - The bit `TH1::kCanRebin` used to extend the histogram axes is now deprecated. The bit exists still in ROOT 6.0 but it has no effect.; One should use now the new function `TH1::SetCanExtend(..)` passing the axis (using the appropriate enumeration), which needs to be extended.; In addition to extend each axis individually, the function can be used also to enable/disable extension for all axes.; For example `TH1::SetCanExtend(TH1::kXaxis)` will make extendable only the X axis; `TH1::SetCanExtend(TH1::kAllAxes)` will; make extendable all the axes (this is the same functionality of the previous function `SetBit(TH1::kCanRebin)` and; `TH1::SetCanExtend(TH1::kNoAxis)` will remove the extendable functionality to all the axes (equivalent to the old `ResetBit(TH1::kCanRebin)`).; The functionality of `TestBit(TH1::kCanRebin)` is now replaced by `TH1::CanExtendAllAxis()`. - An histogram filled with weights different than one has now automatically the sum of the weight squared stored inside, without the need to call anymore; `TH1::Sumw2()`. As a consequences an histogram filled with weights will always draw the errors by default. If one desire to continue having the histogram drawn; without the errors, one should use the `hist` option: `h.Draw(""hist"")`.; If, for memory reason, one does not want to remove the internal array sto",MatchSource.DOCS,hist/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md:7535,Modifiability,extend,extendable,7535,"case of time axis) and used to; replace the old bit `TH1::kCanRebin` (see below).; Note that this bit is automatically set when the axis has labels associated to each bin. In this case the axis becomes alphanumeric and; there is no more relation to the observed quantities. Note that when an axis is alphanumeric the mean and the rms of the histograms are not anymore; coputed and they are set to zero. ### TH1. - The bit `TH1::kCanRebin` used to extend the histogram axes is now deprecated. The bit exists still in ROOT 6.0 but it has no effect.; One should use now the new function `TH1::SetCanExtend(..)` passing the axis (using the appropriate enumeration), which needs to be extended.; In addition to extend each axis individually, the function can be used also to enable/disable extension for all axes.; For example `TH1::SetCanExtend(TH1::kXaxis)` will make extendable only the X axis; `TH1::SetCanExtend(TH1::kAllAxes)` will; make extendable all the axes (this is the same functionality of the previous function `SetBit(TH1::kCanRebin)` and; `TH1::SetCanExtend(TH1::kNoAxis)` will remove the extendable functionality to all the axes (equivalent to the old `ResetBit(TH1::kCanRebin)`).; The functionality of `TestBit(TH1::kCanRebin)` is now replaced by `TH1::CanExtendAllAxis()`. - An histogram filled with weights different than one has now automatically the sum of the weight squared stored inside, without the need to call anymore; `TH1::Sumw2()`. As a consequences an histogram filled with weights will always draw the errors by default. If one desire to continue having the histogram drawn; without the errors, one should use the `hist` option: `h.Draw(""hist"")`.; If, for memory reason, one does not want to remove the internal array storing the bin errors (the bin sum of weight square), one can use the function `TH1::Sumw2(false)`. - The copy constructor is not anymore public for TH1. Before (in 5.34) this code was allowed by the compiler, although giving undefined behavior: now not",MatchSource.DOCS,hist/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md:7609,Modifiability,extend,extendable,7609,"case of time axis) and used to; replace the old bit `TH1::kCanRebin` (see below).; Note that this bit is automatically set when the axis has labels associated to each bin. In this case the axis becomes alphanumeric and; there is no more relation to the observed quantities. Note that when an axis is alphanumeric the mean and the rms of the histograms are not anymore; coputed and they are set to zero. ### TH1. - The bit `TH1::kCanRebin` used to extend the histogram axes is now deprecated. The bit exists still in ROOT 6.0 but it has no effect.; One should use now the new function `TH1::SetCanExtend(..)` passing the axis (using the appropriate enumeration), which needs to be extended.; In addition to extend each axis individually, the function can be used also to enable/disable extension for all axes.; For example `TH1::SetCanExtend(TH1::kXaxis)` will make extendable only the X axis; `TH1::SetCanExtend(TH1::kAllAxes)` will; make extendable all the axes (this is the same functionality of the previous function `SetBit(TH1::kCanRebin)` and; `TH1::SetCanExtend(TH1::kNoAxis)` will remove the extendable functionality to all the axes (equivalent to the old `ResetBit(TH1::kCanRebin)`).; The functionality of `TestBit(TH1::kCanRebin)` is now replaced by `TH1::CanExtendAllAxis()`. - An histogram filled with weights different than one has now automatically the sum of the weight squared stored inside, without the need to call anymore; `TH1::Sumw2()`. As a consequences an histogram filled with weights will always draw the errors by default. If one desire to continue having the histogram drawn; without the errors, one should use the `hist` option: `h.Draw(""hist"")`.; If, for memory reason, one does not want to remove the internal array storing the bin errors (the bin sum of weight square), one can use the function `TH1::Sumw2(false)`. - The copy constructor is not anymore public for TH1. Before (in 5.34) this code was allowed by the compiler, although giving undefined behavior: now not",MatchSource.DOCS,hist/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md:7770,Modifiability,extend,extendable,7770,"case of time axis) and used to; replace the old bit `TH1::kCanRebin` (see below).; Note that this bit is automatically set when the axis has labels associated to each bin. In this case the axis becomes alphanumeric and; there is no more relation to the observed quantities. Note that when an axis is alphanumeric the mean and the rms of the histograms are not anymore; coputed and they are set to zero. ### TH1. - The bit `TH1::kCanRebin` used to extend the histogram axes is now deprecated. The bit exists still in ROOT 6.0 but it has no effect.; One should use now the new function `TH1::SetCanExtend(..)` passing the axis (using the appropriate enumeration), which needs to be extended.; In addition to extend each axis individually, the function can be used also to enable/disable extension for all axes.; For example `TH1::SetCanExtend(TH1::kXaxis)` will make extendable only the X axis; `TH1::SetCanExtend(TH1::kAllAxes)` will; make extendable all the axes (this is the same functionality of the previous function `SetBit(TH1::kCanRebin)` and; `TH1::SetCanExtend(TH1::kNoAxis)` will remove the extendable functionality to all the axes (equivalent to the old `ResetBit(TH1::kCanRebin)`).; The functionality of `TestBit(TH1::kCanRebin)` is now replaced by `TH1::CanExtendAllAxis()`. - An histogram filled with weights different than one has now automatically the sum of the weight squared stored inside, without the need to call anymore; `TH1::Sumw2()`. As a consequences an histogram filled with weights will always draw the errors by default. If one desire to continue having the histogram drawn; without the errors, one should use the `hist` option: `h.Draw(""hist"")`.; If, for memory reason, one does not want to remove the internal array storing the bin errors (the bin sum of weight square), one can use the function `TH1::Sumw2(false)`. - The copy constructor is not anymore public for TH1. Before (in 5.34) this code was allowed by the compiler, although giving undefined behavior: now not",MatchSource.DOCS,hist/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md:9101,Performance,multi-thread,multi-threaded,9101,"nces an histogram filled with weights will always draw the errors by default. If one desire to continue having the histogram drawn; without the errors, one should use the `hist` option: `h.Draw(""hist"")`.; If, for memory reason, one does not want to remove the internal array storing the bin errors (the bin sum of weight square), one can use the function `TH1::Sumw2(false)`. - The copy constructor is not anymore public for TH1. Before (in 5.34) this code was allowed by the compiler, although giving undefined behavior: now not anymore:. ``` {.cpp}; TH1D h1;; TH1 h2(h1);; ```; Now this code is not allowed anymore. It will give a compilation error.; The copy constructor of the derived classes (`TH1D` in this example) should instead be used.; This applies also for `TH2` and `TH3`.; In case you want to copy histograms using the TH1 interface, you can use either `TObject::Clone`, which uses the I/O system and can be unconvenient in some cases (e.g. in a multi-threaded; environment) or `TH1::Copy` which is public since some of the latest 5.34 revisions together with `TClass::New` as following:. ``` {.cpp}; TH1 * h2 = (TH1*) h1->IsA()->New();; h1->Copy(*h2);; ```; Note that `TH1::Copy` does not copy the attached list of functions, while `TH1::Clone()` does a deep copy also of the contained functions. - Add new method `TH1::GetNCells` to retrieve the total number of bins of an histogram including underflow and overflows. This is the product of all the bins in each dimension. - The methods `GetCellContent`, `GetCellError` and `SetCellContent` and `SetCellError` have been deprecated. Get/SetBinContent and Get/SetBinError should be instead used and they have exactly the; same functionality. - The following code should produce a plot. It did not. ``` {.cpp}; TH1F* h=new TH1F(""hist"", ""histogram"", 10, 0, 3);; h->FillRandom(""gaus"");; h->Draw(""same"");; ```; - Make sure histograms having quotes in title are properly saved in .C files. ### TH2, TH3. - Add new functions `TH2::QuantilesX` ",MatchSource.DOCS,hist/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md:11293,Performance,perform,performed,11293,"X axis. The return histogram will have as bin error an approximate error on the quantile assuming a normal distribution of the; bin contents in the other axis. - Update Projection methods of both TH2 and TH3 to not return a null; pointer when an histogram with the same name already existed and it; was not compatible. Now just set the new correct binning on the; previously existing histogram. ### TGraph. - `TGraph::Draw()` needed at least the option `AL` to draw the graph; axis even when there was no active canvas or when the active canvas; did not have any axis defined. This was counter-intuitive. Now if; `TGraph::Draw()` is invoked without parameter and if there is no; axis defined in the current canvas, the option `ALP` is automatically; set.; - Change `SavePrimtive()` to improve speed compilation on generated macros. ### TGraph2D. - When `GetX(YZ)axis` were called on a `TGraph2D`, the frame limit and; plotting options were changed.; - Modify the `Clear` function in order to be able to reuse a; `TGraph2D` after a `Clear` is performed.; - In `GetHistogram()` the lower and higher axis limits are always; different.; - Protection added to avoid a Seg Fault on `.q` when `SetHistogram()`; is called on a `TGraph2D`. ### TMultiGraph. - In `TMultiGraph::Add(TMultiGraph *multigraph, Option_t *chopt)`; If `chopt` is defined all the graphs in `multigraph` will be added; with the `chopt` option. If `chopt` is undefined each graph will; be added with the option it had in `multigraph`.; - The option ""A"" in the `Draw()` was not cleaning properly the; current pad.; - Implement this option `pads`. This option is equivalent to the one in; `THStack`. It allows to draw all the `TGraphs` in separated pads. ### THStack. - By default the background of the histograms is erased before drawing the; histograms. The new option `noclear` avoid this behaviour. This is useful; when drawing a `THStack` on top of an other plot. If the patterns used to; draw the histograms in the stack are transpar",MatchSource.DOCS,hist/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md:11406,Safety,avoid,avoid,11406,"axis. - Update Projection methods of both TH2 and TH3 to not return a null; pointer when an histogram with the same name already existed and it; was not compatible. Now just set the new correct binning on the; previously existing histogram. ### TGraph. - `TGraph::Draw()` needed at least the option `AL` to draw the graph; axis even when there was no active canvas or when the active canvas; did not have any axis defined. This was counter-intuitive. Now if; `TGraph::Draw()` is invoked without parameter and if there is no; axis defined in the current canvas, the option `ALP` is automatically; set.; - Change `SavePrimtive()` to improve speed compilation on generated macros. ### TGraph2D. - When `GetX(YZ)axis` were called on a `TGraph2D`, the frame limit and; plotting options were changed.; - Modify the `Clear` function in order to be able to reuse a; `TGraph2D` after a `Clear` is performed.; - In `GetHistogram()` the lower and higher axis limits are always; different.; - Protection added to avoid a Seg Fault on `.q` when `SetHistogram()`; is called on a `TGraph2D`. ### TMultiGraph. - In `TMultiGraph::Add(TMultiGraph *multigraph, Option_t *chopt)`; If `chopt` is defined all the graphs in `multigraph` will be added; with the `chopt` option. If `chopt` is undefined each graph will; be added with the option it had in `multigraph`.; - The option ""A"" in the `Draw()` was not cleaning properly the; current pad.; - Implement this option `pads`. This option is equivalent to the one in; `THStack`. It allows to draw all the `TGraphs` in separated pads. ### THStack. - By default the background of the histograms is erased before drawing the; histograms. The new option `noclear` avoid this behaviour. This is useful; when drawing a `THStack` on top of an other plot. If the patterns used to; draw the histograms in the stack are transparents, then the plot behind; will be visible. ### TH2Poly. - Implement a simple version of ""Scale"". ### TF1. - Change `TF1::Integral(double a, double b, dou",MatchSource.DOCS,hist/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md:12093,Safety,avoid,avoid,12093,"aph2D. - When `GetX(YZ)axis` were called on a `TGraph2D`, the frame limit and; plotting options were changed.; - Modify the `Clear` function in order to be able to reuse a; `TGraph2D` after a `Clear` is performed.; - In `GetHistogram()` the lower and higher axis limits are always; different.; - Protection added to avoid a Seg Fault on `.q` when `SetHistogram()`; is called on a `TGraph2D`. ### TMultiGraph. - In `TMultiGraph::Add(TMultiGraph *multigraph, Option_t *chopt)`; If `chopt` is defined all the graphs in `multigraph` will be added; with the `chopt` option. If `chopt` is undefined each graph will; be added with the option it had in `multigraph`.; - The option ""A"" in the `Draw()` was not cleaning properly the; current pad.; - Implement this option `pads`. This option is equivalent to the one in; `THStack`. It allows to draw all the `TGraphs` in separated pads. ### THStack. - By default the background of the histograms is erased before drawing the; histograms. The new option `noclear` avoid this behaviour. This is useful; when drawing a `THStack` on top of an other plot. If the patterns used to; draw the histograms in the stack are transparents, then the plot behind; will be visible. ### TH2Poly. - Implement a simple version of ""Scale"". ### TF1. - Change `TF1::Integral(double a, double b, double * params = 0, double eps = 1.E-12)` to; `TF1::Integral(doubnle a, double b, double epsrel=1.E-12)`. One should use `TF1::SetParameters` to; set the function parameters before computing the integral. - Add a new function `TF1::IntegralOneDim(Double_t a, Double_t b, Double_t epsrel, Double_t epsabs, Double_t &err)`; that returns as last argument the error in the integration. `TF1::Integral` is implemented using `Tf1::IntegralOneDim`. - The one-dim and multi-dim integral functions are now implemented using the `ROOT::Math::IntegratorOneDim` and `ROOT::Math::IntegratorMultiDim`; classes. This allows to change the integration algorithm used in `TF1` using the static methods of ",MatchSource.DOCS,hist/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md:3877,Usability,simpl,simply,3877,"}; {; TCanvas *c1 = new TCanvas(""c1"", ""c1"",0,0,1200,700);; int n = 100;; Float_t d = 0.5;; TH1F *h1 = new TH1F(""h1"", ""x_min = - d"", n, -d, 100-d);; h1->Fill(1, 1); h1->Fill(3, 3); h1->Fill(5, 5); h1->Fill(7, 7);. TH1F *h2 = new TH1F(""h2"", ""x_min = +d"", n, d, 100+d);; h2->Fill(1, 1); h2->Fill(3, 3); h2->Fill(5, 5); h2->Fill(7, 7);. c1->Divide(1, 2);; c1->cd(1); gPad->SetLogx(); h1->Draw(); // upper picture; c1->cd(2); gPad->SetLogx(); h2->Draw(); // lower picture; h1->GetXaxis()->SetMoreLogLabels();; h2->GetXaxis()->SetMoreLogLabels();; c1_1->SetGridx();; c1_2->SetGridx();; }; ```; - In `PaintStat2` the temporary string used to paint the fit parameters; was too small and in some cases the errors where truncated. The size; of the string is now the same as in `PaintStat`.; - Display the bin error for 2D histograms in the status bar.; - New option `CANDLE` to draw 2D histograms as Candle-PLot (Box-PLot).; A Candle plot (also known as a ""box-and whisker plot"" or simply ""box plot""); is a convenient way to describe graphically a data distribution (D) with; only the five numbers. It was invented in 1977 by John Tukey. With the option CANDLEX five numbers are:. 1. The minimum value of the distribution D (bottom dashed line).; 2. The lower quartile (Q1): 25% of the data points in D are less than; Q1 (bottom of the box).; 3. The median (M): 50% of the data points in D are less than M; (thick line segment inside the box).; 4. The upper quartile (Q3): 75% of the data points in D are less; than Q3 (top of the box).; 5. The maximum value of the distribution D (top dashed line). The mean value of the distribution D is also represented as a circle. In this implementation a TH2 is considered as a collection of TH1 along; X (option `CANDLE` or `CANDLEX`) or Y (option `CANDLEY`).; Each TH1 is represented as a candle plot. Example:. ``` {.cpp}; {; TH2F *hcandle = new TH2F(""hcandle"",""Option CANDLE example "",40,-4,4,40,-20,20);; Float_t px, py;; for (Int_t i = 0; i < 25000; i++) {; gRandom",MatchSource.DOCS,hist/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md:10845,Usability,intuit,intuitive,10845,"lity. - The following code should produce a plot. It did not. ``` {.cpp}; TH1F* h=new TH1F(""hist"", ""histogram"", 10, 0, 3);; h->FillRandom(""gaus"");; h->Draw(""same"");; ```; - Make sure histograms having quotes in title are properly saved in .C files. ### TH2, TH3. - Add new functions `TH2::QuantilesX` and `TH2::QuantilesY` to return in a 1D histogram the projected quantiles distribution along; the other Y or X axis. The return histogram will have as bin error an approximate error on the quantile assuming a normal distribution of the; bin contents in the other axis. - Update Projection methods of both TH2 and TH3 to not return a null; pointer when an histogram with the same name already existed and it; was not compatible. Now just set the new correct binning on the; previously existing histogram. ### TGraph. - `TGraph::Draw()` needed at least the option `AL` to draw the graph; axis even when there was no active canvas or when the active canvas; did not have any axis defined. This was counter-intuitive. Now if; `TGraph::Draw()` is invoked without parameter and if there is no; axis defined in the current canvas, the option `ALP` is automatically; set.; - Change `SavePrimtive()` to improve speed compilation on generated macros. ### TGraph2D. - When `GetX(YZ)axis` were called on a `TGraph2D`, the frame limit and; plotting options were changed.; - Modify the `Clear` function in order to be able to reuse a; `TGraph2D` after a `Clear` is performed.; - In `GetHistogram()` the lower and higher axis limits are always; different.; - Protection added to avoid a Seg Fault on `.q` when `SetHistogram()`; is called on a `TGraph2D`. ### TMultiGraph. - In `TMultiGraph::Add(TMultiGraph *multigraph, Option_t *chopt)`; If `chopt` is defined all the graphs in `multigraph` will be added; with the `chopt` option. If `chopt` is undefined each graph will; be added with the option it had in `multigraph`.; - The option ""A"" in the `Draw()` was not cleaning properly the; current pad.; - Implement t",MatchSource.DOCS,hist/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md:12323,Usability,simpl,simple,12323,"he lower and higher axis limits are always; different.; - Protection added to avoid a Seg Fault on `.q` when `SetHistogram()`; is called on a `TGraph2D`. ### TMultiGraph. - In `TMultiGraph::Add(TMultiGraph *multigraph, Option_t *chopt)`; If `chopt` is defined all the graphs in `multigraph` will be added; with the `chopt` option. If `chopt` is undefined each graph will; be added with the option it had in `multigraph`.; - The option ""A"" in the `Draw()` was not cleaning properly the; current pad.; - Implement this option `pads`. This option is equivalent to the one in; `THStack`. It allows to draw all the `TGraphs` in separated pads. ### THStack. - By default the background of the histograms is erased before drawing the; histograms. The new option `noclear` avoid this behaviour. This is useful; when drawing a `THStack` on top of an other plot. If the patterns used to; draw the histograms in the stack are transparents, then the plot behind; will be visible. ### TH2Poly. - Implement a simple version of ""Scale"". ### TF1. - Change `TF1::Integral(double a, double b, double * params = 0, double eps = 1.E-12)` to; `TF1::Integral(doubnle a, double b, double epsrel=1.E-12)`. One should use `TF1::SetParameters` to; set the function parameters before computing the integral. - Add a new function `TF1::IntegralOneDim(Double_t a, Double_t b, Double_t epsrel, Double_t epsabs, Double_t &err)`; that returns as last argument the error in the integration. `TF1::Integral` is implemented using `Tf1::IntegralOneDim`. - The one-dim and multi-dim integral functions are now implemented using the `ROOT::Math::IntegratorOneDim` and `ROOT::Math::IntegratorMultiDim`; classes. This allows to change the integration algorithm used in `TF1` using the static methods of the classes; `ROOT::Math::IntegratorOneDimOptions` and `ROOT::Math::IntegratorMultiDimOptions`. The default algorithm used are; `ROOT::Math::IntegratorOneDimOptions::DefaultIntegratorType()` and `ROOT::Math::IntegratorMultiDimOptions::Def",MatchSource.DOCS,hist/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/hist/doc/v602/index.md:722,Security,hash,hashed,722,"; ## Histogram Libraries. ### THistPainter. - Implement the option `FUNC` for 2D histograms in the same way; it is implmented for 1D. Ie: when the option `FUNC` specified; only the functions attached to the histogram are drawn.; - New drawing option `VIOLIN`for 2D histograms from Davide Gerbaudo; (davide.gerbaudo@gmail.com).; A violin plot is a box plot that also encodes the pdf information at each point.; Quartiles and mean are also represented at each point, with a marker and two lines. In this implementation a TH2 is considered as a collection of TH1 along; X (option <tt>VIOLIN</tt> or <tt>VIOLINX</tt>) or Y (option <tt>VIOLINY</tt>). A solid fill style is recommended for this plot (as opposed to a hollow or; hashed style). Example:. ``` {.cpp}; {; Int_t nx(6), ny(40);; Double_t xmin(0.0), xmax(+6.0), ymin(0.0), ymax(+4.0);; TH2F* hviolin = new TH2F(""hviolin"", ""Option VIOLIN example"", nx, xmin, xmax, ny, ymin, ymax);; TF1 f1(""f1"", ""gaus"", +0,0 +4.0);; Double_t x,y;; for (Int_t iBin=1; iBin<hviolin->GetNbinsX(); ++iBin) {; Double_t xc = hviolin->GetXaxis()->GetBinCenter(iBin);; f1.SetParameters(1, 2.0+TMath::Sin(1.0+xc), 0.2+0.1*(xc-xmin)/xmax);; for(Int_t i=0; i<10000; ++i){; x = xc;; y = f1.GetRandom();; hviolin->Fill(x, y);; }; }; hviolin->SetFillColor(kGray);; hviolin->SetMarkerStyle(20);; hviolin->SetMarkerSize(0.5);; hviolin->Draw(""VIOLIN"");; c1->Update();; return c1;; }; ```; ![Violin plot example](violin.png ""Violin plot example""); ",MatchSource.DOCS,hist/doc/v602/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v602/index.md
https://github.com/root-project/root/tree/v6-32-06/hist/hbook/doc/index.md:38,Integrability,interface,interface,38,This directory contains all the hbook interface classes. See:. - [How to convert Hbook/PAW files to ROOT](https://root-forum.cern.ch/t/how-to-convert-hbook-paw-files-to-root/); - [The Chapter about the Histogram classes in the Users Guide](ftp://root.cern.ch/root/doc/3Histograms.pdf); - [The Chapter about Fitting Histogram in the Users Guide](ftp://root.cern.ch/root/doc/5FittingHistograms.pdf); - [How to use the Histogram classes](https://root.cern/manual/histograms/); - [How to Merge files with histograms and Trees](https://root.cern/manual/storing_root_objects/#merging-root-files-with-hadd); - [How to Fit Histograms](https://root.cern/manual/fitting/); - [How to Fit find peaks in histograms](https://root.cern/doc/master/peaks_8C.html); ,MatchSource.DOCS,hist/hbook/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/hbook/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/hist/histpainter/doc/index.md:310,Availability,error,errors,310,\defgroup Histpainter Histograms and graphs painting classes.; \ingroup HistPainting. The histograms and graphs plotting options are described in details in the THistPainter and TGraphPainter classes.; Some related tutorials:. - graph.C: Using and drawing a simple TGraph.; - graph2derrorsfit.C: TGraph2D with errors drawing.; - h1draw.C: Drawing Options for 1D Histograms.; - hbars.C: Demo of option bar with histograms.; - hsimple.C: Simple drawing of a 1D Histograms.; - hsum.C: Filling several histograms and some graphics options.; - surfaces.C: Drawing a TH2 as a 2-D surface. Some related HowTos:; - [How to Draw objects ?](https://root-forum.cern.ch/t/how-to-draw-objects/28249); - [How to change the position of the statistics box on histogram plot ?](https://root-forum.cern.ch/t/how-to-change-the-position-of-the-statistics-box-on-histogram-plot/28262); - [How to draw several TGraph in one common axis system ?](https://root-forum.cern.ch/t/how-to-draw-several-tgraph-in-one-common-axis-system/28261); ,MatchSource.DOCS,hist/histpainter/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/histpainter/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/hist/histpainter/doc/index.md:258,Usability,simpl,simple,258,\defgroup Histpainter Histograms and graphs painting classes.; \ingroup HistPainting. The histograms and graphs plotting options are described in details in the THistPainter and TGraphPainter classes.; Some related tutorials:. - graph.C: Using and drawing a simple TGraph.; - graph2derrorsfit.C: TGraph2D with errors drawing.; - h1draw.C: Drawing Options for 1D Histograms.; - hbars.C: Demo of option bar with histograms.; - hsimple.C: Simple drawing of a 1D Histograms.; - hsum.C: Filling several histograms and some graphics options.; - surfaces.C: Drawing a TH2 as a 2-D surface. Some related HowTos:; - [How to Draw objects ?](https://root-forum.cern.ch/t/how-to-draw-objects/28249); - [How to change the position of the statistics box on histogram plot ?](https://root-forum.cern.ch/t/how-to-change-the-position-of-the-statistics-box-on-histogram-plot/28262); - [How to draw several TGraph in one common axis system ?](https://root-forum.cern.ch/t/how-to-draw-several-tgraph-in-one-common-axis-system/28261); ,MatchSource.DOCS,hist/histpainter/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/histpainter/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/hist/unfold/doc/index.md:91,Safety,detect,detector,91,\defgroup Unfold TUnfold classes; \ingroup Hist. An algorithm to unfold distributions from detector to truth level. \author Stefan Schmitt DESY. ,MatchSource.DOCS,hist/unfold/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/unfold/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/README.md:1292,Deployability,release,release,1292,"M compiler; infrastructure. Cling implements the [read-eval-print loop; (REPL)](http://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop); concept, in order to leverage rapid application development. Implemented as a; small extension to LLVM and Clang, the interpreter reuses their strengths such; as the praised concise and expressive compiler diagnostics. See also [cling's web page.](https://rawcdn.githack.com/root-project/cling/d59d27ad61f2f3a78cd46e652cd9fb8adb893565/www/index.html). Please note that some of the resources are rather old and most of the stated; limitations are outdated.; * [talks](www/docs/talks); * http://blog.coldflake.com/posts/2012-08-09-On-the-fly-C++.html; * http://solarianprogrammer.com/2012/08/14/cling-cpp-11-interpreter/; * https://www.youtube.com/watch?v=f9Xfh8pv3Fs; * https://www.youtube.com/watch?v=BrjV1ZgYbbA; * https://www.youtube.com/watch?v=wZZdDhf2wDw; * https://www.youtube.com/watch?v=eoIuqLNvzFs. Installation; ------------; ### Release Notes; See our [release notes](docs/ReleaseNotes.md) to find what's new. ### Binaries; Our nightly binary snapshots are currently unavailable. ### Building from Source. ```bash; git clone https://github.com/root-project/llvm-project.git; cd llvm-project; git checkout cling-latest; cd ..; git clone https://github.com/root-project/cling.git; mkdir cling-build && cd cling-build; cmake -DLLVM_EXTERNAL_PROJECTS=cling -DLLVM_EXTERNAL_CLING_SOURCE_DIR=../cling/ -DLLVM_ENABLE_PROJECTS=""clang"" -DLLVM_TARGETS_TO_BUILD=""host;NVPTX"" -DCMAKE_BUILD_TYPE=Release ../llvm-project/llvm; cmake --build . --target cling; ```. See also the instructions [on the webpage](https://root.cern/cling/cling_build_instructions/). Usage; -----; Assuming we're in the build folder:; ```bash; ./bin/cling '#include <stdio.h>' 'printf(""Hello World!\n"")'; ```. To get started run:; ```bash; ./bin/cling --help; ```; or; ```bash; ./bin/cling; [cling]$ .help; ```. Jupyter; -------; Cling comes with a [Jupyter](http://jupyter.org) k",MatchSource.DOCS,interpreter/cling/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/README.md:2310,Deployability,install,install,2310,") to find what's new. ### Binaries; Our nightly binary snapshots are currently unavailable. ### Building from Source. ```bash; git clone https://github.com/root-project/llvm-project.git; cd llvm-project; git checkout cling-latest; cd ..; git clone https://github.com/root-project/cling.git; mkdir cling-build && cd cling-build; cmake -DLLVM_EXTERNAL_PROJECTS=cling -DLLVM_EXTERNAL_CLING_SOURCE_DIR=../cling/ -DLLVM_ENABLE_PROJECTS=""clang"" -DLLVM_TARGETS_TO_BUILD=""host;NVPTX"" -DCMAKE_BUILD_TYPE=Release ../llvm-project/llvm; cmake --build . --target cling; ```. See also the instructions [on the webpage](https://root.cern/cling/cling_build_instructions/). Usage; -----; Assuming we're in the build folder:; ```bash; ./bin/cling '#include <stdio.h>' 'printf(""Hello World!\n"")'; ```. To get started run:; ```bash; ./bin/cling --help; ```; or; ```bash; ./bin/cling; [cling]$ .help; ```. Jupyter; -------; Cling comes with a [Jupyter](http://jupyter.org) kernel. After building cling,; install Jupyter and cling's kernel by following the README.md in; [tools/Jupyter](tools/Jupyter). Make sure cling is in your PATH when you start jupyter!. Citing Cling; ------------; ```latex; % Peer-Reviewed Publication; %; % 19th International Conference on Computing in High Energy and Nuclear Physics (CHEP); % 21-25 May, 2012, New York, USA; %; @inproceedings{Cling,; author = {Vassilev,V. and Canal,Ph. and Naumann,A. and Moneta,L. and Russo,P.},; title = {{Cling} -- The New Interactive Interpreter for {ROOT} 6}},; journal = {Journal of Physics: Conference Series},; year = 2012,; month = {dec},; volume = {396},; number = {5},; pages = {052071},; doi = {10.1088/1742-6596/396/5/052071},; url = {https://iopscience.iop.org/article/10.1088/1742-6596/396/5/052071/pdf},; publisher = {{IOP} Publishing}; }; ```. Developers' Corner; ==================; [Cling's latest doxygen documentation](http://cling.web.cern.ch/cling/doxygen/). Contributions; -------------; Every contribution is considered a donation and it",MatchSource.DOCS,interpreter/cling/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/README.md:3739,Deployability,release,release,3739,"h. and Naumann,A. and Moneta,L. and Russo,P.},; title = {{Cling} -- The New Interactive Interpreter for {ROOT} 6}},; journal = {Journal of Physics: Conference Series},; year = 2012,; month = {dec},; volume = {396},; number = {5},; pages = {052071},; doi = {10.1088/1742-6596/396/5/052071},; url = {https://iopscience.iop.org/article/10.1088/1742-6596/396/5/052071/pdf},; publisher = {{IOP} Publishing}; }; ```. Developers' Corner; ==================; [Cling's latest doxygen documentation](http://cling.web.cern.ch/cling/doxygen/). Contributions; -------------; Every contribution is considered a donation and its copyright and any other; related rights become exclusive ownership of the person who merged the code or; in any other case the main developers of the ""Cling Project"". We warmly welcome external contributions to the Cling! By providing code,; you agree to transfer your copyright on the code to the ""Cling project"".; Of course you will be duly credited and your name will appear on the; contributors page, the release notes, and in the [CREDITS file](CREDITS.txt); shipped with every binary and source distribution. The copyright transfer is; necessary for us to be able to effectively defend the project in case of; litigation. License; -------; Please see our [LICENSE](LICENSE.TXT). Releases; --------; Our release steps to follow when cutting a new release:; 1. Update [release notes](docs/ReleaseNotes.md); 2. Remove `~dev` suffix from [VERSION](VERSION); 3. Add a new entry in the news section of our [website](www/news.html); 4. Commit the changes.; 5. `git tag -a v0.x -m ""Tagging release v0.x""`; 6. Tag `cling-patches` of `clang.git`:; `git tag -a cling-v0.x -m ""Tagging clang for cling v0.x""`; 7. Create a draft release in github and copy the contents of the release notes.; 8. Wait for green builds.; 9. Upload binaries to github (Travis should do this automatically).; 10. Publish the tag and announce it on the mailing list.; 11. Increment the current version and append `~d",MatchSource.DOCS,interpreter/cling/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/README.md:4039,Deployability,release,release,4039," Naumann,A. and Moneta,L. and Russo,P.},; title = {{Cling} -- The New Interactive Interpreter for {ROOT} 6}},; journal = {Journal of Physics: Conference Series},; year = 2012,; month = {dec},; volume = {396},; number = {5},; pages = {052071},; doi = {10.1088/1742-6596/396/5/052071},; url = {https://iopscience.iop.org/article/10.1088/1742-6596/396/5/052071/pdf},; publisher = {{IOP} Publishing}; }; ```. Developers' Corner; ==================; [Cling's latest doxygen documentation](http://cling.web.cern.ch/cling/doxygen/). Contributions; -------------; Every contribution is considered a donation and its copyright and any other; related rights become exclusive ownership of the person who merged the code or; in any other case the main developers of the ""Cling Project"". We warmly welcome external contributions to the Cling! By providing code,; you agree to transfer your copyright on the code to the ""Cling project"".; Of course you will be duly credited and your name will appear on the; contributors page, the release notes, and in the [CREDITS file](CREDITS.txt); shipped with every binary and source distribution. The copyright transfer is; necessary for us to be able to effectively defend the project in case of; litigation. License; -------; Please see our [LICENSE](LICENSE.TXT). Releases; --------; Our release steps to follow when cutting a new release:; 1. Update [release notes](docs/ReleaseNotes.md); 2. Remove `~dev` suffix from [VERSION](VERSION); 3. Add a new entry in the news section of our [website](www/news.html); 4. Commit the changes.; 5. `git tag -a v0.x -m ""Tagging release v0.x""`; 6. Tag `cling-patches` of `clang.git`:; `git tag -a cling-v0.x -m ""Tagging clang for cling v0.x""`; 7. Create a draft release in github and copy the contents of the release notes.; 8. Wait for green builds.; 9. Upload binaries to github (Travis should do this automatically).; 10. Publish the tag and announce it on the mailing list.; 11. Increment the current version and append `~dev`.; ",MatchSource.DOCS,interpreter/cling/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/README.md:4082,Deployability,release,release,4082," Naumann,A. and Moneta,L. and Russo,P.},; title = {{Cling} -- The New Interactive Interpreter for {ROOT} 6}},; journal = {Journal of Physics: Conference Series},; year = 2012,; month = {dec},; volume = {396},; number = {5},; pages = {052071},; doi = {10.1088/1742-6596/396/5/052071},; url = {https://iopscience.iop.org/article/10.1088/1742-6596/396/5/052071/pdf},; publisher = {{IOP} Publishing}; }; ```. Developers' Corner; ==================; [Cling's latest doxygen documentation](http://cling.web.cern.ch/cling/doxygen/). Contributions; -------------; Every contribution is considered a donation and its copyright and any other; related rights become exclusive ownership of the person who merged the code or; in any other case the main developers of the ""Cling Project"". We warmly welcome external contributions to the Cling! By providing code,; you agree to transfer your copyright on the code to the ""Cling project"".; Of course you will be duly credited and your name will appear on the; contributors page, the release notes, and in the [CREDITS file](CREDITS.txt); shipped with every binary and source distribution. The copyright transfer is; necessary for us to be able to effectively defend the project in case of; litigation. License; -------; Please see our [LICENSE](LICENSE.TXT). Releases; --------; Our release steps to follow when cutting a new release:; 1. Update [release notes](docs/ReleaseNotes.md); 2. Remove `~dev` suffix from [VERSION](VERSION); 3. Add a new entry in the news section of our [website](www/news.html); 4. Commit the changes.; 5. `git tag -a v0.x -m ""Tagging release v0.x""`; 6. Tag `cling-patches` of `clang.git`:; `git tag -a cling-v0.x -m ""Tagging clang for cling v0.x""`; 7. Create a draft release in github and copy the contents of the release notes.; 8. Wait for green builds.; 9. Upload binaries to github (Travis should do this automatically).; 10. Publish the tag and announce it on the mailing list.; 11. Increment the current version and append `~dev`.; ",MatchSource.DOCS,interpreter/cling/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/README.md:4103,Deployability,release,release,4103," Naumann,A. and Moneta,L. and Russo,P.},; title = {{Cling} -- The New Interactive Interpreter for {ROOT} 6}},; journal = {Journal of Physics: Conference Series},; year = 2012,; month = {dec},; volume = {396},; number = {5},; pages = {052071},; doi = {10.1088/1742-6596/396/5/052071},; url = {https://iopscience.iop.org/article/10.1088/1742-6596/396/5/052071/pdf},; publisher = {{IOP} Publishing}; }; ```. Developers' Corner; ==================; [Cling's latest doxygen documentation](http://cling.web.cern.ch/cling/doxygen/). Contributions; -------------; Every contribution is considered a donation and its copyright and any other; related rights become exclusive ownership of the person who merged the code or; in any other case the main developers of the ""Cling Project"". We warmly welcome external contributions to the Cling! By providing code,; you agree to transfer your copyright on the code to the ""Cling project"".; Of course you will be duly credited and your name will appear on the; contributors page, the release notes, and in the [CREDITS file](CREDITS.txt); shipped with every binary and source distribution. The copyright transfer is; necessary for us to be able to effectively defend the project in case of; litigation. License; -------; Please see our [LICENSE](LICENSE.TXT). Releases; --------; Our release steps to follow when cutting a new release:; 1. Update [release notes](docs/ReleaseNotes.md); 2. Remove `~dev` suffix from [VERSION](VERSION); 3. Add a new entry in the news section of our [website](www/news.html); 4. Commit the changes.; 5. `git tag -a v0.x -m ""Tagging release v0.x""`; 6. Tag `cling-patches` of `clang.git`:; `git tag -a cling-v0.x -m ""Tagging clang for cling v0.x""`; 7. Create a draft release in github and copy the contents of the release notes.; 8. Wait for green builds.; 9. Upload binaries to github (Travis should do this automatically).; 10. Publish the tag and announce it on the mailing list.; 11. Increment the current version and append `~dev`.; ",MatchSource.DOCS,interpreter/cling/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/README.md:4318,Deployability,release,release,4318," Naumann,A. and Moneta,L. and Russo,P.},; title = {{Cling} -- The New Interactive Interpreter for {ROOT} 6}},; journal = {Journal of Physics: Conference Series},; year = 2012,; month = {dec},; volume = {396},; number = {5},; pages = {052071},; doi = {10.1088/1742-6596/396/5/052071},; url = {https://iopscience.iop.org/article/10.1088/1742-6596/396/5/052071/pdf},; publisher = {{IOP} Publishing}; }; ```. Developers' Corner; ==================; [Cling's latest doxygen documentation](http://cling.web.cern.ch/cling/doxygen/). Contributions; -------------; Every contribution is considered a donation and its copyright and any other; related rights become exclusive ownership of the person who merged the code or; in any other case the main developers of the ""Cling Project"". We warmly welcome external contributions to the Cling! By providing code,; you agree to transfer your copyright on the code to the ""Cling project"".; Of course you will be duly credited and your name will appear on the; contributors page, the release notes, and in the [CREDITS file](CREDITS.txt); shipped with every binary and source distribution. The copyright transfer is; necessary for us to be able to effectively defend the project in case of; litigation. License; -------; Please see our [LICENSE](LICENSE.TXT). Releases; --------; Our release steps to follow when cutting a new release:; 1. Update [release notes](docs/ReleaseNotes.md); 2. Remove `~dev` suffix from [VERSION](VERSION); 3. Add a new entry in the news section of our [website](www/news.html); 4. Commit the changes.; 5. `git tag -a v0.x -m ""Tagging release v0.x""`; 6. Tag `cling-patches` of `clang.git`:; `git tag -a cling-v0.x -m ""Tagging clang for cling v0.x""`; 7. Create a draft release in github and copy the contents of the release notes.; 8. Wait for green builds.; 9. Upload binaries to github (Travis should do this automatically).; 10. Publish the tag and announce it on the mailing list.; 11. Increment the current version and append `~dev`.; ",MatchSource.DOCS,interpreter/cling/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/README.md:4348,Deployability,patch,patches,4348," Naumann,A. and Moneta,L. and Russo,P.},; title = {{Cling} -- The New Interactive Interpreter for {ROOT} 6}},; journal = {Journal of Physics: Conference Series},; year = 2012,; month = {dec},; volume = {396},; number = {5},; pages = {052071},; doi = {10.1088/1742-6596/396/5/052071},; url = {https://iopscience.iop.org/article/10.1088/1742-6596/396/5/052071/pdf},; publisher = {{IOP} Publishing}; }; ```. Developers' Corner; ==================; [Cling's latest doxygen documentation](http://cling.web.cern.ch/cling/doxygen/). Contributions; -------------; Every contribution is considered a donation and its copyright and any other; related rights become exclusive ownership of the person who merged the code or; in any other case the main developers of the ""Cling Project"". We warmly welcome external contributions to the Cling! By providing code,; you agree to transfer your copyright on the code to the ""Cling project"".; Of course you will be duly credited and your name will appear on the; contributors page, the release notes, and in the [CREDITS file](CREDITS.txt); shipped with every binary and source distribution. The copyright transfer is; necessary for us to be able to effectively defend the project in case of; litigation. License; -------; Please see our [LICENSE](LICENSE.TXT). Releases; --------; Our release steps to follow when cutting a new release:; 1. Update [release notes](docs/ReleaseNotes.md); 2. Remove `~dev` suffix from [VERSION](VERSION); 3. Add a new entry in the news section of our [website](www/news.html); 4. Commit the changes.; 5. `git tag -a v0.x -m ""Tagging release v0.x""`; 6. Tag `cling-patches` of `clang.git`:; `git tag -a cling-v0.x -m ""Tagging clang for cling v0.x""`; 7. Create a draft release in github and copy the contents of the release notes.; 8. Wait for green builds.; 9. Upload binaries to github (Travis should do this automatically).; 10. Publish the tag and announce it on the mailing list.; 11. Increment the current version and append `~dev`.; ",MatchSource.DOCS,interpreter/cling/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/README.md:4451,Deployability,release,release,4451," Naumann,A. and Moneta,L. and Russo,P.},; title = {{Cling} -- The New Interactive Interpreter for {ROOT} 6}},; journal = {Journal of Physics: Conference Series},; year = 2012,; month = {dec},; volume = {396},; number = {5},; pages = {052071},; doi = {10.1088/1742-6596/396/5/052071},; url = {https://iopscience.iop.org/article/10.1088/1742-6596/396/5/052071/pdf},; publisher = {{IOP} Publishing}; }; ```. Developers' Corner; ==================; [Cling's latest doxygen documentation](http://cling.web.cern.ch/cling/doxygen/). Contributions; -------------; Every contribution is considered a donation and its copyright and any other; related rights become exclusive ownership of the person who merged the code or; in any other case the main developers of the ""Cling Project"". We warmly welcome external contributions to the Cling! By providing code,; you agree to transfer your copyright on the code to the ""Cling project"".; Of course you will be duly credited and your name will appear on the; contributors page, the release notes, and in the [CREDITS file](CREDITS.txt); shipped with every binary and source distribution. The copyright transfer is; necessary for us to be able to effectively defend the project in case of; litigation. License; -------; Please see our [LICENSE](LICENSE.TXT). Releases; --------; Our release steps to follow when cutting a new release:; 1. Update [release notes](docs/ReleaseNotes.md); 2. Remove `~dev` suffix from [VERSION](VERSION); 3. Add a new entry in the news section of our [website](www/news.html); 4. Commit the changes.; 5. `git tag -a v0.x -m ""Tagging release v0.x""`; 6. Tag `cling-patches` of `clang.git`:; `git tag -a cling-v0.x -m ""Tagging clang for cling v0.x""`; 7. Create a draft release in github and copy the contents of the release notes.; 8. Wait for green builds.; 9. Upload binaries to github (Travis should do this automatically).; 10. Publish the tag and announce it on the mailing list.; 11. Increment the current version and append `~dev`.; ",MatchSource.DOCS,interpreter/cling/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/README.md:4498,Deployability,release,release,4498," Naumann,A. and Moneta,L. and Russo,P.},; title = {{Cling} -- The New Interactive Interpreter for {ROOT} 6}},; journal = {Journal of Physics: Conference Series},; year = 2012,; month = {dec},; volume = {396},; number = {5},; pages = {052071},; doi = {10.1088/1742-6596/396/5/052071},; url = {https://iopscience.iop.org/article/10.1088/1742-6596/396/5/052071/pdf},; publisher = {{IOP} Publishing}; }; ```. Developers' Corner; ==================; [Cling's latest doxygen documentation](http://cling.web.cern.ch/cling/doxygen/). Contributions; -------------; Every contribution is considered a donation and its copyright and any other; related rights become exclusive ownership of the person who merged the code or; in any other case the main developers of the ""Cling Project"". We warmly welcome external contributions to the Cling! By providing code,; you agree to transfer your copyright on the code to the ""Cling project"".; Of course you will be duly credited and your name will appear on the; contributors page, the release notes, and in the [CREDITS file](CREDITS.txt); shipped with every binary and source distribution. The copyright transfer is; necessary for us to be able to effectively defend the project in case of; litigation. License; -------; Please see our [LICENSE](LICENSE.TXT). Releases; --------; Our release steps to follow when cutting a new release:; 1. Update [release notes](docs/ReleaseNotes.md); 2. Remove `~dev` suffix from [VERSION](VERSION); 3. Add a new entry in the news section of our [website](www/news.html); 4. Commit the changes.; 5. `git tag -a v0.x -m ""Tagging release v0.x""`; 6. Tag `cling-patches` of `clang.git`:; `git tag -a cling-v0.x -m ""Tagging clang for cling v0.x""`; 7. Create a draft release in github and copy the contents of the release notes.; 8. Wait for green builds.; 9. Upload binaries to github (Travis should do this automatically).; 10. Publish the tag and announce it on the mailing list.; 11. Increment the current version and append `~dev`.; ",MatchSource.DOCS,interpreter/cling/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/README.md:4526,Energy Efficiency,green,green,4526," Naumann,A. and Moneta,L. and Russo,P.},; title = {{Cling} -- The New Interactive Interpreter for {ROOT} 6}},; journal = {Journal of Physics: Conference Series},; year = 2012,; month = {dec},; volume = {396},; number = {5},; pages = {052071},; doi = {10.1088/1742-6596/396/5/052071},; url = {https://iopscience.iop.org/article/10.1088/1742-6596/396/5/052071/pdf},; publisher = {{IOP} Publishing}; }; ```. Developers' Corner; ==================; [Cling's latest doxygen documentation](http://cling.web.cern.ch/cling/doxygen/). Contributions; -------------; Every contribution is considered a donation and its copyright and any other; related rights become exclusive ownership of the person who merged the code or; in any other case the main developers of the ""Cling Project"". We warmly welcome external contributions to the Cling! By providing code,; you agree to transfer your copyright on the code to the ""Cling project"".; Of course you will be duly credited and your name will appear on the; contributors page, the release notes, and in the [CREDITS file](CREDITS.txt); shipped with every binary and source distribution. The copyright transfer is; necessary for us to be able to effectively defend the project in case of; litigation. License; -------; Please see our [LICENSE](LICENSE.TXT). Releases; --------; Our release steps to follow when cutting a new release:; 1. Update [release notes](docs/ReleaseNotes.md); 2. Remove `~dev` suffix from [VERSION](VERSION); 3. Add a new entry in the news section of our [website](www/news.html); 4. Commit the changes.; 5. `git tag -a v0.x -m ""Tagging release v0.x""`; 6. Tag `cling-patches` of `clang.git`:; `git tag -a cling-v0.x -m ""Tagging clang for cling v0.x""`; 7. Create a draft release in github and copy the contents of the release notes.; 8. Wait for green builds.; 9. Upload binaries to github (Travis should do this automatically).; 10. Publish the tag and announce it on the mailing list.; 11. Increment the current version and append `~dev`.; ",MatchSource.DOCS,interpreter/cling/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/ReleaseNotes.md:1515,Availability,avail,available,1515,"mprovements from the previous release and new feature work. Note that if you are reading this file from a git checkout or the main Cling; web page, this document applies to the *next* release, not the current one. What's New in Cling 1.2?; ========================. Some of the major new features and improvements to Cling are listed; here. Generic improvements to Cling as a whole or to its underlying; infrastructure are described first. External Dependencies; ---------------------; * Upgrade to LLVM r0000000. Major New Features; ------------------; * A major new feature. Misc; ----; * A misc feature. Experimental Features; ---------------------; * An experimental feature. Jupyter; -------; * A Jupyter feature. Fixed Bugs; ----------; [ROOT-XXXX](https://sft.its.cern.ch/jira/browse/ROOT-XXXX). <!---Get release bugs; git log v1.1..master | grep -i ""fix"" | grep '#' | sed -E 's,.*\#([0-9]*).*,\[\1\]\(https://github.com/root-project/cling/issues/\1\),g' | sort; --->; <!---Standard MarkDown doesn't support neither variables nor <base>; [ROOT-XXX](https://sft.its.cern.ch/jira/browse/ROOT-XXX); --->. <!---Additional Information; ----------------------; A wide variety of additional information is available on the; [Cling web page](http://root.cern/cling). The web page contains versions of; the API documentation which are up-to-date with the git version of the source; code. You can access versions of these documents specific to this release by; going into the “clang/docs/” directory in the Cling source tree. If you have any questions or comments about Cling, please feel free to contact; us via the mailing list.--->. Special Kudos; =============; This release wouldn't have happened without the efforts of our contributors,; listed in the form of Firstname Lastname (#contributions):. FirstName LastName (#commits). <!---Find contributor list for this release; git log --pretty=format:""%an"" v1.1...master | sort | uniq -c | sort -rn |\; sed -E 's,^ *([0-9]+) (.*)$,\2 \(\1\),'; --->; ",MatchSource.DOCS,interpreter/cling/docs/ReleaseNotes.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/ReleaseNotes.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/ReleaseNotes.md:55,Deployability,release,release,55,"Introduction; ============. This document contains the release notes for the interactive C++ interpreter; Cling, release 1.2. Cling is built on top of [Clang](http://clang.llvm.org) and; [LLVM](http://llvm.org>) compiler infrastructure. Here we; describe the status of Cling in some detail, including major; improvements from the previous release and new feature work. Note that if you are reading this file from a git checkout or the main Cling; web page, this document applies to the *next* release, not the current one. What's New in Cling 1.2?; ========================. Some of the major new features and improvements to Cling are listed; here. Generic improvements to Cling as a whole or to its underlying; infrastructure are described first. External Dependencies; ---------------------; * Upgrade to LLVM r0000000. Major New Features; ------------------; * A major new feature. Misc; ----; * A misc feature. Experimental Features; ---------------------; * An experimental feature. Jupyter; -------; * A Jupyter feature. Fixed Bugs; ----------; [ROOT-XXXX](https://sft.its.cern.ch/jira/browse/ROOT-XXXX). <!---Get release bugs; git log v1.1..master | grep -i ""fix"" | grep '#' | sed -E 's,.*\#([0-9]*).*,\[\1\]\(https://github.com/root-project/cling/issues/\1\),g' | sort; --->; <!---Standard MarkDown doesn't support neither variables nor <base>; [ROOT-XXX](https://sft.its.cern.ch/jira/browse/ROOT-XXX); --->. <!---Additional Information; ----------------------; A wide variety of additional information is available on the; [Cling web page](http://root.cern/cling). The web page contains versions of; the API documentation which are up-to-date with the git version of the source; code. You can access versions of these documents specific to this release by; going into the “clang/docs/” directory in the Cling source tree. If you have any questions or comments about Cling, please feel free to contact; us via the mailing list.--->. Special Kudos; =============; This release wouldn't have ha",MatchSource.DOCS,interpreter/cling/docs/ReleaseNotes.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/ReleaseNotes.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/ReleaseNotes.md:113,Deployability,release,release,113,"Introduction; ============. This document contains the release notes for the interactive C++ interpreter; Cling, release 1.2. Cling is built on top of [Clang](http://clang.llvm.org) and; [LLVM](http://llvm.org>) compiler infrastructure. Here we; describe the status of Cling in some detail, including major; improvements from the previous release and new feature work. Note that if you are reading this file from a git checkout or the main Cling; web page, this document applies to the *next* release, not the current one. What's New in Cling 1.2?; ========================. Some of the major new features and improvements to Cling are listed; here. Generic improvements to Cling as a whole or to its underlying; infrastructure are described first. External Dependencies; ---------------------; * Upgrade to LLVM r0000000. Major New Features; ------------------; * A major new feature. Misc; ----; * A misc feature. Experimental Features; ---------------------; * An experimental feature. Jupyter; -------; * A Jupyter feature. Fixed Bugs; ----------; [ROOT-XXXX](https://sft.its.cern.ch/jira/browse/ROOT-XXXX). <!---Get release bugs; git log v1.1..master | grep -i ""fix"" | grep '#' | sed -E 's,.*\#([0-9]*).*,\[\1\]\(https://github.com/root-project/cling/issues/\1\),g' | sort; --->; <!---Standard MarkDown doesn't support neither variables nor <base>; [ROOT-XXX](https://sft.its.cern.ch/jira/browse/ROOT-XXX); --->. <!---Additional Information; ----------------------; A wide variety of additional information is available on the; [Cling web page](http://root.cern/cling). The web page contains versions of; the API documentation which are up-to-date with the git version of the source; code. You can access versions of these documents specific to this release by; going into the “clang/docs/” directory in the Cling source tree. If you have any questions or comments about Cling, please feel free to contact; us via the mailing list.--->. Special Kudos; =============; This release wouldn't have ha",MatchSource.DOCS,interpreter/cling/docs/ReleaseNotes.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/ReleaseNotes.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/ReleaseNotes.md:339,Deployability,release,release,339,"Introduction; ============. This document contains the release notes for the interactive C++ interpreter; Cling, release 1.2. Cling is built on top of [Clang](http://clang.llvm.org) and; [LLVM](http://llvm.org>) compiler infrastructure. Here we; describe the status of Cling in some detail, including major; improvements from the previous release and new feature work. Note that if you are reading this file from a git checkout or the main Cling; web page, this document applies to the *next* release, not the current one. What's New in Cling 1.2?; ========================. Some of the major new features and improvements to Cling are listed; here. Generic improvements to Cling as a whole or to its underlying; infrastructure are described first. External Dependencies; ---------------------; * Upgrade to LLVM r0000000. Major New Features; ------------------; * A major new feature. Misc; ----; * A misc feature. Experimental Features; ---------------------; * An experimental feature. Jupyter; -------; * A Jupyter feature. Fixed Bugs; ----------; [ROOT-XXXX](https://sft.its.cern.ch/jira/browse/ROOT-XXXX). <!---Get release bugs; git log v1.1..master | grep -i ""fix"" | grep '#' | sed -E 's,.*\#([0-9]*).*,\[\1\]\(https://github.com/root-project/cling/issues/\1\),g' | sort; --->; <!---Standard MarkDown doesn't support neither variables nor <base>; [ROOT-XXX](https://sft.its.cern.ch/jira/browse/ROOT-XXX); --->. <!---Additional Information; ----------------------; A wide variety of additional information is available on the; [Cling web page](http://root.cern/cling). The web page contains versions of; the API documentation which are up-to-date with the git version of the source; code. You can access versions of these documents specific to this release by; going into the “clang/docs/” directory in the Cling source tree. If you have any questions or comments about Cling, please feel free to contact; us via the mailing list.--->. Special Kudos; =============; This release wouldn't have ha",MatchSource.DOCS,interpreter/cling/docs/ReleaseNotes.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/ReleaseNotes.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/ReleaseNotes.md:493,Deployability,release,release,493,"Introduction; ============. This document contains the release notes for the interactive C++ interpreter; Cling, release 1.2. Cling is built on top of [Clang](http://clang.llvm.org) and; [LLVM](http://llvm.org>) compiler infrastructure. Here we; describe the status of Cling in some detail, including major; improvements from the previous release and new feature work. Note that if you are reading this file from a git checkout or the main Cling; web page, this document applies to the *next* release, not the current one. What's New in Cling 1.2?; ========================. Some of the major new features and improvements to Cling are listed; here. Generic improvements to Cling as a whole or to its underlying; infrastructure are described first. External Dependencies; ---------------------; * Upgrade to LLVM r0000000. Major New Features; ------------------; * A major new feature. Misc; ----; * A misc feature. Experimental Features; ---------------------; * An experimental feature. Jupyter; -------; * A Jupyter feature. Fixed Bugs; ----------; [ROOT-XXXX](https://sft.its.cern.ch/jira/browse/ROOT-XXXX). <!---Get release bugs; git log v1.1..master | grep -i ""fix"" | grep '#' | sed -E 's,.*\#([0-9]*).*,\[\1\]\(https://github.com/root-project/cling/issues/\1\),g' | sort; --->; <!---Standard MarkDown doesn't support neither variables nor <base>; [ROOT-XXX](https://sft.its.cern.ch/jira/browse/ROOT-XXX); --->. <!---Additional Information; ----------------------; A wide variety of additional information is available on the; [Cling web page](http://root.cern/cling). The web page contains versions of; the API documentation which are up-to-date with the git version of the source; code. You can access versions of these documents specific to this release by; going into the “clang/docs/” directory in the Cling source tree. If you have any questions or comments about Cling, please feel free to contact; us via the mailing list.--->. Special Kudos; =============; This release wouldn't have ha",MatchSource.DOCS,interpreter/cling/docs/ReleaseNotes.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/ReleaseNotes.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/ReleaseNotes.md:1121,Deployability,release,release,1121,"ing is built on top of [Clang](http://clang.llvm.org) and; [LLVM](http://llvm.org>) compiler infrastructure. Here we; describe the status of Cling in some detail, including major; improvements from the previous release and new feature work. Note that if you are reading this file from a git checkout or the main Cling; web page, this document applies to the *next* release, not the current one. What's New in Cling 1.2?; ========================. Some of the major new features and improvements to Cling are listed; here. Generic improvements to Cling as a whole or to its underlying; infrastructure are described first. External Dependencies; ---------------------; * Upgrade to LLVM r0000000. Major New Features; ------------------; * A major new feature. Misc; ----; * A misc feature. Experimental Features; ---------------------; * An experimental feature. Jupyter; -------; * A Jupyter feature. Fixed Bugs; ----------; [ROOT-XXXX](https://sft.its.cern.ch/jira/browse/ROOT-XXXX). <!---Get release bugs; git log v1.1..master | grep -i ""fix"" | grep '#' | sed -E 's,.*\#([0-9]*).*,\[\1\]\(https://github.com/root-project/cling/issues/\1\),g' | sort; --->; <!---Standard MarkDown doesn't support neither variables nor <base>; [ROOT-XXX](https://sft.its.cern.ch/jira/browse/ROOT-XXX); --->. <!---Additional Information; ----------------------; A wide variety of additional information is available on the; [Cling web page](http://root.cern/cling). The web page contains versions of; the API documentation which are up-to-date with the git version of the source; code. You can access versions of these documents specific to this release by; going into the “clang/docs/” directory in the Cling source tree. If you have any questions or comments about Cling, please feel free to contact; us via the mailing list.--->. Special Kudos; =============; This release wouldn't have happened without the efforts of our contributors,; listed in the form of Firstname Lastname (#contributions):. FirstName LastName ",MatchSource.DOCS,interpreter/cling/docs/ReleaseNotes.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/ReleaseNotes.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/ReleaseNotes.md:1755,Deployability,release,release,1755,"mprovements from the previous release and new feature work. Note that if you are reading this file from a git checkout or the main Cling; web page, this document applies to the *next* release, not the current one. What's New in Cling 1.2?; ========================. Some of the major new features and improvements to Cling are listed; here. Generic improvements to Cling as a whole or to its underlying; infrastructure are described first. External Dependencies; ---------------------; * Upgrade to LLVM r0000000. Major New Features; ------------------; * A major new feature. Misc; ----; * A misc feature. Experimental Features; ---------------------; * An experimental feature. Jupyter; -------; * A Jupyter feature. Fixed Bugs; ----------; [ROOT-XXXX](https://sft.its.cern.ch/jira/browse/ROOT-XXXX). <!---Get release bugs; git log v1.1..master | grep -i ""fix"" | grep '#' | sed -E 's,.*\#([0-9]*).*,\[\1\]\(https://github.com/root-project/cling/issues/\1\),g' | sort; --->; <!---Standard MarkDown doesn't support neither variables nor <base>; [ROOT-XXX](https://sft.its.cern.ch/jira/browse/ROOT-XXX); --->. <!---Additional Information; ----------------------; A wide variety of additional information is available on the; [Cling web page](http://root.cern/cling). The web page contains versions of; the API documentation which are up-to-date with the git version of the source; code. You can access versions of these documents specific to this release by; going into the “clang/docs/” directory in the Cling source tree. If you have any questions or comments about Cling, please feel free to contact; us via the mailing list.--->. Special Kudos; =============; This release wouldn't have happened without the efforts of our contributors,; listed in the form of Firstname Lastname (#contributions):. FirstName LastName (#commits). <!---Find contributor list for this release; git log --pretty=format:""%an"" v1.1...master | sort | uniq -c | sort -rn |\; sed -E 's,^ *([0-9]+) (.*)$,\2 \(\1\),'; --->; ",MatchSource.DOCS,interpreter/cling/docs/ReleaseNotes.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/ReleaseNotes.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/ReleaseNotes.md:1977,Deployability,release,release,1977,"mprovements from the previous release and new feature work. Note that if you are reading this file from a git checkout or the main Cling; web page, this document applies to the *next* release, not the current one. What's New in Cling 1.2?; ========================. Some of the major new features and improvements to Cling are listed; here. Generic improvements to Cling as a whole or to its underlying; infrastructure are described first. External Dependencies; ---------------------; * Upgrade to LLVM r0000000. Major New Features; ------------------; * A major new feature. Misc; ----; * A misc feature. Experimental Features; ---------------------; * An experimental feature. Jupyter; -------; * A Jupyter feature. Fixed Bugs; ----------; [ROOT-XXXX](https://sft.its.cern.ch/jira/browse/ROOT-XXXX). <!---Get release bugs; git log v1.1..master | grep -i ""fix"" | grep '#' | sed -E 's,.*\#([0-9]*).*,\[\1\]\(https://github.com/root-project/cling/issues/\1\),g' | sort; --->; <!---Standard MarkDown doesn't support neither variables nor <base>; [ROOT-XXX](https://sft.its.cern.ch/jira/browse/ROOT-XXX); --->. <!---Additional Information; ----------------------; A wide variety of additional information is available on the; [Cling web page](http://root.cern/cling). The web page contains versions of; the API documentation which are up-to-date with the git version of the source; code. You can access versions of these documents specific to this release by; going into the “clang/docs/” directory in the Cling source tree. If you have any questions or comments about Cling, please feel free to contact; us via the mailing list.--->. Special Kudos; =============; This release wouldn't have happened without the efforts of our contributors,; listed in the form of Firstname Lastname (#contributions):. FirstName LastName (#commits). <!---Find contributor list for this release; git log --pretty=format:""%an"" v1.1...master | sort | uniq -c | sort -rn |\; sed -E 's,^ *([0-9]+) (.*)$,\2 \(\1\),'; --->; ",MatchSource.DOCS,interpreter/cling/docs/ReleaseNotes.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/ReleaseNotes.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/ReleaseNotes.md:2177,Deployability,release,release,2177,"mprovements from the previous release and new feature work. Note that if you are reading this file from a git checkout or the main Cling; web page, this document applies to the *next* release, not the current one. What's New in Cling 1.2?; ========================. Some of the major new features and improvements to Cling are listed; here. Generic improvements to Cling as a whole or to its underlying; infrastructure are described first. External Dependencies; ---------------------; * Upgrade to LLVM r0000000. Major New Features; ------------------; * A major new feature. Misc; ----; * A misc feature. Experimental Features; ---------------------; * An experimental feature. Jupyter; -------; * A Jupyter feature. Fixed Bugs; ----------; [ROOT-XXXX](https://sft.its.cern.ch/jira/browse/ROOT-XXXX). <!---Get release bugs; git log v1.1..master | grep -i ""fix"" | grep '#' | sed -E 's,.*\#([0-9]*).*,\[\1\]\(https://github.com/root-project/cling/issues/\1\),g' | sort; --->; <!---Standard MarkDown doesn't support neither variables nor <base>; [ROOT-XXX](https://sft.its.cern.ch/jira/browse/ROOT-XXX); --->. <!---Additional Information; ----------------------; A wide variety of additional information is available on the; [Cling web page](http://root.cern/cling). The web page contains versions of; the API documentation which are up-to-date with the git version of the source; code. You can access versions of these documents specific to this release by; going into the “clang/docs/” directory in the Cling source tree. If you have any questions or comments about Cling, please feel free to contact; us via the mailing list.--->. Special Kudos; =============; This release wouldn't have happened without the efforts of our contributors,; listed in the form of Firstname Lastname (#contributions):. FirstName LastName (#commits). <!---Find contributor list for this release; git log --pretty=format:""%an"" v1.1...master | sort | uniq -c | sort -rn |\; sed -E 's,^ *([0-9]+) (.*)$,\2 \(\1\),'; --->; ",MatchSource.DOCS,interpreter/cling/docs/ReleaseNotes.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/ReleaseNotes.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/ReleaseNotes.md:1332,Modifiability,variab,variables,1332,"r; improvements from the previous release and new feature work. Note that if you are reading this file from a git checkout or the main Cling; web page, this document applies to the *next* release, not the current one. What's New in Cling 1.2?; ========================. Some of the major new features and improvements to Cling are listed; here. Generic improvements to Cling as a whole or to its underlying; infrastructure are described first. External Dependencies; ---------------------; * Upgrade to LLVM r0000000. Major New Features; ------------------; * A major new feature. Misc; ----; * A misc feature. Experimental Features; ---------------------; * An experimental feature. Jupyter; -------; * A Jupyter feature. Fixed Bugs; ----------; [ROOT-XXXX](https://sft.its.cern.ch/jira/browse/ROOT-XXXX). <!---Get release bugs; git log v1.1..master | grep -i ""fix"" | grep '#' | sed -E 's,.*\#([0-9]*).*,\[\1\]\(https://github.com/root-project/cling/issues/\1\),g' | sort; --->; <!---Standard MarkDown doesn't support neither variables nor <base>; [ROOT-XXX](https://sft.its.cern.ch/jira/browse/ROOT-XXX); --->. <!---Additional Information; ----------------------; A wide variety of additional information is available on the; [Cling web page](http://root.cern/cling). The web page contains versions of; the API documentation which are up-to-date with the git version of the source; code. You can access versions of these documents specific to this release by; going into the “clang/docs/” directory in the Cling source tree. If you have any questions or comments about Cling, please feel free to contact; us via the mailing list.--->. Special Kudos; =============; This release wouldn't have happened without the efforts of our contributors,; listed in the form of Firstname Lastname (#contributions):. FirstName LastName (#commits). <!---Find contributor list for this release; git log --pretty=format:""%an"" v1.1...master | sort | uniq -c | sort -rn |\; sed -E 's,^ *([0-9]+) (.*)$,\2 \(\1\),'; --",MatchSource.DOCS,interpreter/cling/docs/ReleaseNotes.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/ReleaseNotes.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/ReleaseNotes.md:1703,Security,access,access,1703,"mprovements from the previous release and new feature work. Note that if you are reading this file from a git checkout or the main Cling; web page, this document applies to the *next* release, not the current one. What's New in Cling 1.2?; ========================. Some of the major new features and improvements to Cling are listed; here. Generic improvements to Cling as a whole or to its underlying; infrastructure are described first. External Dependencies; ---------------------; * Upgrade to LLVM r0000000. Major New Features; ------------------; * A major new feature. Misc; ----; * A misc feature. Experimental Features; ---------------------; * An experimental feature. Jupyter; -------; * A Jupyter feature. Fixed Bugs; ----------; [ROOT-XXXX](https://sft.its.cern.ch/jira/browse/ROOT-XXXX). <!---Get release bugs; git log v1.1..master | grep -i ""fix"" | grep '#' | sed -E 's,.*\#([0-9]*).*,\[\1\]\(https://github.com/root-project/cling/issues/\1\),g' | sort; --->; <!---Standard MarkDown doesn't support neither variables nor <base>; [ROOT-XXX](https://sft.its.cern.ch/jira/browse/ROOT-XXX); --->. <!---Additional Information; ----------------------; A wide variety of additional information is available on the; [Cling web page](http://root.cern/cling). The web page contains versions of; the API documentation which are up-to-date with the git version of the source; code. You can access versions of these documents specific to this release by; going into the “clang/docs/” directory in the Cling source tree. If you have any questions or comments about Cling, please feel free to contact; us via the mailing list.--->. Special Kudos; =============; This release wouldn't have happened without the efforts of our contributors,; listed in the form of Firstname Lastname (#contributions):. FirstName LastName (#commits). <!---Find contributor list for this release; git log --pretty=format:""%an"" v1.1...master | sort | uniq -c | sort -rn |\; sed -E 's,^ *([0-9]+) (.*)$,\2 \(\1\),'; --->; ",MatchSource.DOCS,interpreter/cling/docs/ReleaseNotes.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/ReleaseNotes.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/ReleaseNotes.md:1139,Testability,log,log,1139,"ing is built on top of [Clang](http://clang.llvm.org) and; [LLVM](http://llvm.org>) compiler infrastructure. Here we; describe the status of Cling in some detail, including major; improvements from the previous release and new feature work. Note that if you are reading this file from a git checkout or the main Cling; web page, this document applies to the *next* release, not the current one. What's New in Cling 1.2?; ========================. Some of the major new features and improvements to Cling are listed; here. Generic improvements to Cling as a whole or to its underlying; infrastructure are described first. External Dependencies; ---------------------; * Upgrade to LLVM r0000000. Major New Features; ------------------; * A major new feature. Misc; ----; * A misc feature. Experimental Features; ---------------------; * An experimental feature. Jupyter; -------; * A Jupyter feature. Fixed Bugs; ----------; [ROOT-XXXX](https://sft.its.cern.ch/jira/browse/ROOT-XXXX). <!---Get release bugs; git log v1.1..master | grep -i ""fix"" | grep '#' | sed -E 's,.*\#([0-9]*).*,\[\1\]\(https://github.com/root-project/cling/issues/\1\),g' | sort; --->; <!---Standard MarkDown doesn't support neither variables nor <base>; [ROOT-XXX](https://sft.its.cern.ch/jira/browse/ROOT-XXX); --->. <!---Additional Information; ----------------------; A wide variety of additional information is available on the; [Cling web page](http://root.cern/cling). The web page contains versions of; the API documentation which are up-to-date with the git version of the source; code. You can access versions of these documents specific to this release by; going into the “clang/docs/” directory in the Cling source tree. If you have any questions or comments about Cling, please feel free to contact; us via the mailing list.--->. Special Kudos; =============; This release wouldn't have happened without the efforts of our contributors,; listed in the form of Firstname Lastname (#contributions):. FirstName LastName ",MatchSource.DOCS,interpreter/cling/docs/ReleaseNotes.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/ReleaseNotes.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/ReleaseNotes.md:2190,Testability,log,log,2190,"mprovements from the previous release and new feature work. Note that if you are reading this file from a git checkout or the main Cling; web page, this document applies to the *next* release, not the current one. What's New in Cling 1.2?; ========================. Some of the major new features and improvements to Cling are listed; here. Generic improvements to Cling as a whole or to its underlying; infrastructure are described first. External Dependencies; ---------------------; * Upgrade to LLVM r0000000. Major New Features; ------------------; * A major new feature. Misc; ----; * A misc feature. Experimental Features; ---------------------; * An experimental feature. Jupyter; -------; * A Jupyter feature. Fixed Bugs; ----------; [ROOT-XXXX](https://sft.its.cern.ch/jira/browse/ROOT-XXXX). <!---Get release bugs; git log v1.1..master | grep -i ""fix"" | grep '#' | sed -E 's,.*\#([0-9]*).*,\[\1\]\(https://github.com/root-project/cling/issues/\1\),g' | sort; --->; <!---Standard MarkDown doesn't support neither variables nor <base>; [ROOT-XXX](https://sft.its.cern.ch/jira/browse/ROOT-XXX); --->. <!---Additional Information; ----------------------; A wide variety of additional information is available on the; [Cling web page](http://root.cern/cling). The web page contains versions of; the API documentation which are up-to-date with the git version of the source; code. You can access versions of these documents specific to this release by; going into the “clang/docs/” directory in the Cling source tree. If you have any questions or comments about Cling, please feel free to contact; us via the mailing list.--->. Special Kudos; =============; This release wouldn't have happened without the efforts of our contributors,; listed in the form of Firstname Lastname (#contributions):. FirstName LastName (#commits). <!---Find contributor list for this release; git log --pretty=format:""%an"" v1.1...master | sort | uniq -c | sort -rn |\; sed -E 's,^ *([0-9]+) (.*)$,\2 \(\1\),'; --->; ",MatchSource.DOCS,interpreter/cling/docs/ReleaseNotes.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/ReleaseNotes.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/.github/ISSUE_TEMPLATE/bug_report.md:486,Usability,clear,clear,486,"---; name: Bug report; about: Create a report to get an issue fixed; title: ''; labels: bug; ---. - [ ] Checked for duplicates; <!--; Please search in; * https://github.com/root-project/cling/issues; * and meta issues - https://github.com/root-project/cling/issues/406 and https://github.com/root-project/cling/issues/407; for existing reports of your issue. If you find one, you are very welcome to add details to the existing report, for instance.; -->. ### Describe the bug; <!--; A clear and concise description of what the wrong behavior is.; -->. ### Expected behavior; <!--; A clear and concise description of what you expected to happen.; -->. ### To Reproduce; <!--; Steps to reproduce the behavior:; 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves.; 2. Don't forget to attach the required input files!; 3. How to run your code and / or build it.; -->. ### Setup; <!--; 1. Cling version; 2. Operating system; 3. How you obtained Cling, such as with cpt.py (also mention flags) / you built it yourself.; -->. ### Additional context; <!--; Add any other context about the problem here.; -->; ",MatchSource.DOCS,interpreter/cling/.github/ISSUE_TEMPLATE/bug_report.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/.github/ISSUE_TEMPLATE/bug_report.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/.github/ISSUE_TEMPLATE/bug_report.md:584,Usability,clear,clear,584,"---; name: Bug report; about: Create a report to get an issue fixed; title: ''; labels: bug; ---. - [ ] Checked for duplicates; <!--; Please search in; * https://github.com/root-project/cling/issues; * and meta issues - https://github.com/root-project/cling/issues/406 and https://github.com/root-project/cling/issues/407; for existing reports of your issue. If you find one, you are very welcome to add details to the existing report, for instance.; -->. ### Describe the bug; <!--; A clear and concise description of what the wrong behavior is.; -->. ### Expected behavior; <!--; A clear and concise description of what you expected to happen.; -->. ### To Reproduce; <!--; Steps to reproduce the behavior:; 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves.; 2. Don't forget to attach the required input files!; 3. How to run your code and / or build it.; -->. ### Setup; <!--; 1. Cling version; 2. Operating system; 3. How you obtained Cling, such as with cpt.py (also mention flags) / you built it yourself.; -->. ### Additional context; <!--; Add any other context about the problem here.; -->; ",MatchSource.DOCS,interpreter/cling/.github/ISSUE_TEMPLATE/bug_report.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/.github/ISSUE_TEMPLATE/bug_report.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/.github/ISSUE_TEMPLATE/feature_request.md:181,Usability,clear,clear,181,"---; name: Feature request; about: Propose a new feature for Cling; title: ''; labels: new feature; ---. ### Is your feature request related to a problem? Please describe.; <!--; A clear and concise description of what the problem is. E.g ""I always have to [...] when I want to [...]""; -->. ### Describe the solution you'd like; <!--; A clear and concise description of what you want to happen.; -->. ### Describe alternatives you've considered; <!--; Can you think of alternative solutions or features?; -->. ### Additional context; <!--; Add any other context or screenshots about the feature requested here.; -->; ",MatchSource.DOCS,interpreter/cling/.github/ISSUE_TEMPLATE/feature_request.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/.github/ISSUE_TEMPLATE/feature_request.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/.github/ISSUE_TEMPLATE/feature_request.md:337,Usability,clear,clear,337,"---; name: Feature request; about: Propose a new feature for Cling; title: ''; labels: new feature; ---. ### Is your feature request related to a problem? Please describe.; <!--; A clear and concise description of what the problem is. E.g ""I always have to [...] when I want to [...]""; -->. ### Describe the solution you'd like; <!--; A clear and concise description of what you want to happen.; -->. ### Describe alternatives you've considered; <!--; Can you think of alternative solutions or features?; -->. ### Additional context; <!--; Add any other context or screenshots about the feature requested here.; -->; ",MatchSource.DOCS,interpreter/cling/.github/ISSUE_TEMPLATE/feature_request.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/.github/ISSUE_TEMPLATE/feature_request.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/demo/README.md:288,Deployability,configurat,configuration,288,"### Example project using cling as library. This example project uses cling as an external library.; It compiles code and calls it, moving values from the compiled part to the; interpreted part and back. It showcases how to use cling as a library, and shows how to set up a simple; CMake configuration that uses cling. ### How to build. After installing cling (say into /where/cling/is/installed), configure this; project using CMake like this:; ```bash; cmake -Dcling_DIR=/cling-install-dir/lib/cmake/cling /cling-source-dir/tools/cling/tools/demo; make && ./cling-demo; ```; ",MatchSource.DOCS,interpreter/cling/tools/demo/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/demo/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/demo/README.md:343,Deployability,install,installing,343,"### Example project using cling as library. This example project uses cling as an external library.; It compiles code and calls it, moving values from the compiled part to the; interpreted part and back. It showcases how to use cling as a library, and shows how to set up a simple; CMake configuration that uses cling. ### How to build. After installing cling (say into /where/cling/is/installed), configure this; project using CMake like this:; ```bash; cmake -Dcling_DIR=/cling-install-dir/lib/cmake/cling /cling-source-dir/tools/cling/tools/demo; make && ./cling-demo; ```; ",MatchSource.DOCS,interpreter/cling/tools/demo/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/demo/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/demo/README.md:386,Deployability,install,installed,386,"### Example project using cling as library. This example project uses cling as an external library.; It compiles code and calls it, moving values from the compiled part to the; interpreted part and back. It showcases how to use cling as a library, and shows how to set up a simple; CMake configuration that uses cling. ### How to build. After installing cling (say into /where/cling/is/installed), configure this; project using CMake like this:; ```bash; cmake -Dcling_DIR=/cling-install-dir/lib/cmake/cling /cling-source-dir/tools/cling/tools/demo; make && ./cling-demo; ```; ",MatchSource.DOCS,interpreter/cling/tools/demo/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/demo/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/demo/README.md:480,Deployability,install,install-dir,480,"### Example project using cling as library. This example project uses cling as an external library.; It compiles code and calls it, moving values from the compiled part to the; interpreted part and back. It showcases how to use cling as a library, and shows how to set up a simple; CMake configuration that uses cling. ### How to build. After installing cling (say into /where/cling/is/installed), configure this; project using CMake like this:; ```bash; cmake -Dcling_DIR=/cling-install-dir/lib/cmake/cling /cling-source-dir/tools/cling/tools/demo; make && ./cling-demo; ```; ",MatchSource.DOCS,interpreter/cling/tools/demo/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/demo/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/demo/README.md:288,Modifiability,config,configuration,288,"### Example project using cling as library. This example project uses cling as an external library.; It compiles code and calls it, moving values from the compiled part to the; interpreted part and back. It showcases how to use cling as a library, and shows how to set up a simple; CMake configuration that uses cling. ### How to build. After installing cling (say into /where/cling/is/installed), configure this; project using CMake like this:; ```bash; cmake -Dcling_DIR=/cling-install-dir/lib/cmake/cling /cling-source-dir/tools/cling/tools/demo; make && ./cling-demo; ```; ",MatchSource.DOCS,interpreter/cling/tools/demo/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/demo/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/demo/README.md:398,Modifiability,config,configure,398,"### Example project using cling as library. This example project uses cling as an external library.; It compiles code and calls it, moving values from the compiled part to the; interpreted part and back. It showcases how to use cling as a library, and shows how to set up a simple; CMake configuration that uses cling. ### How to build. After installing cling (say into /where/cling/is/installed), configure this; project using CMake like this:; ```bash; cmake -Dcling_DIR=/cling-install-dir/lib/cmake/cling /cling-source-dir/tools/cling/tools/demo; make && ./cling-demo; ```; ",MatchSource.DOCS,interpreter/cling/tools/demo/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/demo/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/demo/README.md:274,Usability,simpl,simple,274,"### Example project using cling as library. This example project uses cling as an external library.; It compiles code and calls it, moving values from the compiled part to the; interpreted part and back. It showcases how to use cling as a library, and shows how to set up a simple; CMake configuration that uses cling. ### How to build. After installing cling (say into /where/cling/is/installed), configure this; project using CMake like this:; ```bash; cmake -Dcling_DIR=/cling-install-dir/lib/cmake/cling /cling-source-dir/tools/cling/tools/demo; make && ./cling-demo; ```; ",MatchSource.DOCS,interpreter/cling/tools/demo/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/demo/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/Jupyter/README.md:92,Deployability,install,install,92,# Cling Kernel. C++ Kernel for Jupyter with Cling. Requires ipykernel ≥ 4.0. ## Install. To install the kernel with sources in src/tools/cling:. export PATH=/cling-install-prefix/bin:$PATH; cd /cling-install-prefix/share/cling/Jupyter/kernel. pip install -e .; # or: pip3 install -e . # register the kernelspec for C++17/C++1z/C++14/C++11:; # the user can install whichever kernel(s) they; # wish:; jupyter-kernelspec install [--user] cling-cpp17; jupyter-kernelspec install [--user] cling-cpp1z; jupyter-kernelspec install [--user] cling-cpp14; jupyter-kernelspec install [--user] cling-cpp11. To run it:. jupyter-notebook; # or: jupyter notebook; ,MatchSource.DOCS,interpreter/cling/tools/Jupyter/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/Jupyter/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/Jupyter/README.md:164,Deployability,install,install-prefix,164,# Cling Kernel. C++ Kernel for Jupyter with Cling. Requires ipykernel ≥ 4.0. ## Install. To install the kernel with sources in src/tools/cling:. export PATH=/cling-install-prefix/bin:$PATH; cd /cling-install-prefix/share/cling/Jupyter/kernel. pip install -e .; # or: pip3 install -e . # register the kernelspec for C++17/C++1z/C++14/C++11:; # the user can install whichever kernel(s) they; # wish:; jupyter-kernelspec install [--user] cling-cpp17; jupyter-kernelspec install [--user] cling-cpp1z; jupyter-kernelspec install [--user] cling-cpp14; jupyter-kernelspec install [--user] cling-cpp11. To run it:. jupyter-notebook; # or: jupyter notebook; ,MatchSource.DOCS,interpreter/cling/tools/Jupyter/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/Jupyter/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/Jupyter/README.md:200,Deployability,install,install-prefix,200,# Cling Kernel. C++ Kernel for Jupyter with Cling. Requires ipykernel ≥ 4.0. ## Install. To install the kernel with sources in src/tools/cling:. export PATH=/cling-install-prefix/bin:$PATH; cd /cling-install-prefix/share/cling/Jupyter/kernel. pip install -e .; # or: pip3 install -e . # register the kernelspec for C++17/C++1z/C++14/C++11:; # the user can install whichever kernel(s) they; # wish:; jupyter-kernelspec install [--user] cling-cpp17; jupyter-kernelspec install [--user] cling-cpp1z; jupyter-kernelspec install [--user] cling-cpp14; jupyter-kernelspec install [--user] cling-cpp11. To run it:. jupyter-notebook; # or: jupyter notebook; ,MatchSource.DOCS,interpreter/cling/tools/Jupyter/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/Jupyter/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/Jupyter/README.md:247,Deployability,install,install,247,# Cling Kernel. C++ Kernel for Jupyter with Cling. Requires ipykernel ≥ 4.0. ## Install. To install the kernel with sources in src/tools/cling:. export PATH=/cling-install-prefix/bin:$PATH; cd /cling-install-prefix/share/cling/Jupyter/kernel. pip install -e .; # or: pip3 install -e . # register the kernelspec for C++17/C++1z/C++14/C++11:; # the user can install whichever kernel(s) they; # wish:; jupyter-kernelspec install [--user] cling-cpp17; jupyter-kernelspec install [--user] cling-cpp1z; jupyter-kernelspec install [--user] cling-cpp14; jupyter-kernelspec install [--user] cling-cpp11. To run it:. jupyter-notebook; # or: jupyter notebook; ,MatchSource.DOCS,interpreter/cling/tools/Jupyter/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/Jupyter/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/Jupyter/README.md:272,Deployability,install,install,272,# Cling Kernel. C++ Kernel for Jupyter with Cling. Requires ipykernel ≥ 4.0. ## Install. To install the kernel with sources in src/tools/cling:. export PATH=/cling-install-prefix/bin:$PATH; cd /cling-install-prefix/share/cling/Jupyter/kernel. pip install -e .; # or: pip3 install -e . # register the kernelspec for C++17/C++1z/C++14/C++11:; # the user can install whichever kernel(s) they; # wish:; jupyter-kernelspec install [--user] cling-cpp17; jupyter-kernelspec install [--user] cling-cpp1z; jupyter-kernelspec install [--user] cling-cpp14; jupyter-kernelspec install [--user] cling-cpp11. To run it:. jupyter-notebook; # or: jupyter notebook; ,MatchSource.DOCS,interpreter/cling/tools/Jupyter/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/Jupyter/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/Jupyter/README.md:356,Deployability,install,install,356,# Cling Kernel. C++ Kernel for Jupyter with Cling. Requires ipykernel ≥ 4.0. ## Install. To install the kernel with sources in src/tools/cling:. export PATH=/cling-install-prefix/bin:$PATH; cd /cling-install-prefix/share/cling/Jupyter/kernel. pip install -e .; # or: pip3 install -e . # register the kernelspec for C++17/C++1z/C++14/C++11:; # the user can install whichever kernel(s) they; # wish:; jupyter-kernelspec install [--user] cling-cpp17; jupyter-kernelspec install [--user] cling-cpp1z; jupyter-kernelspec install [--user] cling-cpp14; jupyter-kernelspec install [--user] cling-cpp11. To run it:. jupyter-notebook; # or: jupyter notebook; ,MatchSource.DOCS,interpreter/cling/tools/Jupyter/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/Jupyter/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/Jupyter/README.md:418,Deployability,install,install,418,# Cling Kernel. C++ Kernel for Jupyter with Cling. Requires ipykernel ≥ 4.0. ## Install. To install the kernel with sources in src/tools/cling:. export PATH=/cling-install-prefix/bin:$PATH; cd /cling-install-prefix/share/cling/Jupyter/kernel. pip install -e .; # or: pip3 install -e . # register the kernelspec for C++17/C++1z/C++14/C++11:; # the user can install whichever kernel(s) they; # wish:; jupyter-kernelspec install [--user] cling-cpp17; jupyter-kernelspec install [--user] cling-cpp1z; jupyter-kernelspec install [--user] cling-cpp14; jupyter-kernelspec install [--user] cling-cpp11. To run it:. jupyter-notebook; # or: jupyter notebook; ,MatchSource.DOCS,interpreter/cling/tools/Jupyter/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/Jupyter/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/Jupyter/README.md:467,Deployability,install,install,467,# Cling Kernel. C++ Kernel for Jupyter with Cling. Requires ipykernel ≥ 4.0. ## Install. To install the kernel with sources in src/tools/cling:. export PATH=/cling-install-prefix/bin:$PATH; cd /cling-install-prefix/share/cling/Jupyter/kernel. pip install -e .; # or: pip3 install -e . # register the kernelspec for C++17/C++1z/C++14/C++11:; # the user can install whichever kernel(s) they; # wish:; jupyter-kernelspec install [--user] cling-cpp17; jupyter-kernelspec install [--user] cling-cpp1z; jupyter-kernelspec install [--user] cling-cpp14; jupyter-kernelspec install [--user] cling-cpp11. To run it:. jupyter-notebook; # or: jupyter notebook; ,MatchSource.DOCS,interpreter/cling/tools/Jupyter/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/Jupyter/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/Jupyter/README.md:516,Deployability,install,install,516,# Cling Kernel. C++ Kernel for Jupyter with Cling. Requires ipykernel ≥ 4.0. ## Install. To install the kernel with sources in src/tools/cling:. export PATH=/cling-install-prefix/bin:$PATH; cd /cling-install-prefix/share/cling/Jupyter/kernel. pip install -e .; # or: pip3 install -e . # register the kernelspec for C++17/C++1z/C++14/C++11:; # the user can install whichever kernel(s) they; # wish:; jupyter-kernelspec install [--user] cling-cpp17; jupyter-kernelspec install [--user] cling-cpp1z; jupyter-kernelspec install [--user] cling-cpp14; jupyter-kernelspec install [--user] cling-cpp11. To run it:. jupyter-notebook; # or: jupyter notebook; ,MatchSource.DOCS,interpreter/cling/tools/Jupyter/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/Jupyter/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/Jupyter/README.md:565,Deployability,install,install,565,# Cling Kernel. C++ Kernel for Jupyter with Cling. Requires ipykernel ≥ 4.0. ## Install. To install the kernel with sources in src/tools/cling:. export PATH=/cling-install-prefix/bin:$PATH; cd /cling-install-prefix/share/cling/Jupyter/kernel. pip install -e .; # or: pip3 install -e . # register the kernelspec for C++17/C++1z/C++14/C++11:; # the user can install whichever kernel(s) they; # wish:; jupyter-kernelspec install [--user] cling-cpp17; jupyter-kernelspec install [--user] cling-cpp1z; jupyter-kernelspec install [--user] cling-cpp14; jupyter-kernelspec install [--user] cling-cpp11. To run it:. jupyter-notebook; # or: jupyter notebook; ,MatchSource.DOCS,interpreter/cling/tools/Jupyter/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/Jupyter/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:1818,Availability,error,error,1818," installers*; * Distros based on Red Hat Linux (Fedora/Scientific Linux CERN) - *RPM packages*; * Mac OS X - *Apple Disk Images*; * Virtually any UNIX-like platform which supports Bash - *Tarballs*. ### Requirements; Before using this tool, make sure you have the required packages installed on; your system. Detailed information on what and how to install is provided below,; but the recommended (and much easier) way is to use the following command which; performs the required checks automatically and displays useful suggestions too; specific to your platform.; ```sh; cd tools/packaging/; ./cpt.py --check-requirements; ```; or; ```sh; cd tools/packaging/; ./cpt.py -c; ```; Regardless of the platform and operating system, make sure to call the cpt script; with Python 3.; CPT uses some features and modules which are not a part of older versions of Python.; The same holds true for the versions of GCC/Clang you have on your machine. Older; compilers do not support c++11 features and thus you can expect a build error if you; choose not to update them. All pre-compiled binaries of Python ship with built-in support for SSL. However if; the Python on your system was compiled by you manually, chances are that it doesn't; have SSL support. This is very likely if you had performed a minimal installation; of Scientific Linux CERN which doesn't include OpenSSL development package. In such; a case, you should install ```openssl-devel```, re-compile Python and ```configure```; will automatically link against the required libraries and produce a binary with SSL; support. #### Ubuntu/Debian; On Debian, Ubuntu, Linux Mint, CrunchBang, or any other distro based on Debian; which supports APT package manager, you can install all the required packages by:; ```sh; sudo apt-get update; sudo apt-get install git g++ debhelper devscripts gnupg python; ```; You are not required to do this manually since CPT can do this for you automatically. ###### Setting up:; Make sure GnuPG is properly set up",MatchSource.DOCS,interpreter/cling/tools/packaging/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:4104,Availability,error,errors,4104,"; configure GnuPG to not ask for the passphrase while signing the Debian package. The [Ubuntu Packaging Guide] contains a quick guide on creating a GPG key on an; Ubuntu system. To test if you have successfully set up your GnuPG key, use the following command:; ```sh; gpg --fingerprint; ```; Again, all these checks are performed by default when you launch CPT with ```-c``` option.; [Ubuntu Packaging Guide]:http://packaging.ubuntu.com/html/getting-set-up.html#create-your-gpg-key. #### Windows; CPT is meant to be executed on cmd.exe prompt. Make sure you have set the; environment properly before continuing.; Below is a list of required packages for Windows (Win32-x86):. [MSYS Git] for Windows. [Python] for Windows. Microsoft Visual Studio 11 (2012), with Microsoft Visual C++ 2012. [MSYS Git]:http://msysgit.github.io/; [Python]:https://www.python.org/. ###### Setting Up:; Unlike other UNIX-like platforms, Windows requires you to follow some rules.; Do not ignore this section unless you want CPT to fail mid-way with wierd; errors. You should require these instructions only once. * While installing the packages make sure the executable is in a path that; doesn't contain spaces. For example, you should install Python in a path like. ```sh; C:\Python27; ```; rather than. ```sh; C:\Program Files (x86)\Python 2.7; ```; * Path to all the required executables should be present in the Windows; **PATH** environment variable.; * In case of MSYS Git, choose the option ""Run Git from Windows; Command Prompt"" during installation. A good way to check if everything is detected properly by the script is to; run the following command:; ```sh; cd tools/packaging/; ./cpt.py --check-requirements; ```. #### Red Hat Linux (Fedora/Scientific Linux CERN); This section applies to all distros based on Red Hat Linux like Fedora, and; Scientific Linux CERN (SLC). Apparently, you can build RPM packages in any; distro regardless of the package manager it uses. This has been tested on; Fedora, SLC, Ub",MatchSource.DOCS,interpreter/cling/tools/packaging/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:166,Deployability,install,installer,166,"Cling Packaging Tool (CPT); ==========================. The Cling Packaging Tool is a command-line utility written in Python to build; Cling from source and generate installer bundles for a wide range of platforms. Cling maintains its own vendor clones of LLVM and Clang (part of ROOT's trunk); on which it is based. This tool is the easiest way to build Cling for your favorite; platorm and bundle it into an installer. If you want to manually compile Cling; from source, go through the [README] of Cling or the build instructions [here]. [README]:https://github.com/root-project/cling/blob/master/README.md; [here]:https://root.cern/cling/cling_build_instructions/. Below is a list of platforms currently supported by CPT:; * Ubuntu and distros based on Debian - *DEB packages*; * Windows - *NSIS installers*; * Distros based on Red Hat Linux (Fedora/Scientific Linux CERN) - *RPM packages*; * Mac OS X - *Apple Disk Images*; * Virtually any UNIX-like platform which supports Bash - *Tarballs*. ### Requirements; Before using this tool, make sure you have the required packages installed on; your system. Detailed information on what and how to install is provided below,; but the recommended (and much easier) way is to use the following command which; performs the required checks automatically and displays useful suggestions too; specific to your platform.; ```sh; cd tools/packaging/; ./cpt.py --check-requirements; ```; or; ```sh; cd tools/packaging/; ./cpt.py -c; ```; Regardless of the platform and operating system, make sure to call the cpt script; with Python 3.; CPT uses some features and modules which are not a part of older versions of Python.; The same holds true for the versions of GCC/Clang you have on your machine. Older; compilers do not support c++11 features and thus you can expect a build error if you; choose not to update them. All pre-compiled binaries of Python ship with built-in support for SSL. However if; the Python on your system was compiled by you manually, ch",MatchSource.DOCS,interpreter/cling/tools/packaging/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:410,Deployability,install,installer,410,"Cling Packaging Tool (CPT); ==========================. The Cling Packaging Tool is a command-line utility written in Python to build; Cling from source and generate installer bundles for a wide range of platforms. Cling maintains its own vendor clones of LLVM and Clang (part of ROOT's trunk); on which it is based. This tool is the easiest way to build Cling for your favorite; platorm and bundle it into an installer. If you want to manually compile Cling; from source, go through the [README] of Cling or the build instructions [here]. [README]:https://github.com/root-project/cling/blob/master/README.md; [here]:https://root.cern/cling/cling_build_instructions/. Below is a list of platforms currently supported by CPT:; * Ubuntu and distros based on Debian - *DEB packages*; * Windows - *NSIS installers*; * Distros based on Red Hat Linux (Fedora/Scientific Linux CERN) - *RPM packages*; * Mac OS X - *Apple Disk Images*; * Virtually any UNIX-like platform which supports Bash - *Tarballs*. ### Requirements; Before using this tool, make sure you have the required packages installed on; your system. Detailed information on what and how to install is provided below,; but the recommended (and much easier) way is to use the following command which; performs the required checks automatically and displays useful suggestions too; specific to your platform.; ```sh; cd tools/packaging/; ./cpt.py --check-requirements; ```; or; ```sh; cd tools/packaging/; ./cpt.py -c; ```; Regardless of the platform and operating system, make sure to call the cpt script; with Python 3.; CPT uses some features and modules which are not a part of older versions of Python.; The same holds true for the versions of GCC/Clang you have on your machine. Older; compilers do not support c++11 features and thus you can expect a build error if you; choose not to update them. All pre-compiled binaries of Python ship with built-in support for SSL. However if; the Python on your system was compiled by you manually, ch",MatchSource.DOCS,interpreter/cling/tools/packaging/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:799,Deployability,install,installers,799,"Cling Packaging Tool (CPT); ==========================. The Cling Packaging Tool is a command-line utility written in Python to build; Cling from source and generate installer bundles for a wide range of platforms. Cling maintains its own vendor clones of LLVM and Clang (part of ROOT's trunk); on which it is based. This tool is the easiest way to build Cling for your favorite; platorm and bundle it into an installer. If you want to manually compile Cling; from source, go through the [README] of Cling or the build instructions [here]. [README]:https://github.com/root-project/cling/blob/master/README.md; [here]:https://root.cern/cling/cling_build_instructions/. Below is a list of platforms currently supported by CPT:; * Ubuntu and distros based on Debian - *DEB packages*; * Windows - *NSIS installers*; * Distros based on Red Hat Linux (Fedora/Scientific Linux CERN) - *RPM packages*; * Mac OS X - *Apple Disk Images*; * Virtually any UNIX-like platform which supports Bash - *Tarballs*. ### Requirements; Before using this tool, make sure you have the required packages installed on; your system. Detailed information on what and how to install is provided below,; but the recommended (and much easier) way is to use the following command which; performs the required checks automatically and displays useful suggestions too; specific to your platform.; ```sh; cd tools/packaging/; ./cpt.py --check-requirements; ```; or; ```sh; cd tools/packaging/; ./cpt.py -c; ```; Regardless of the platform and operating system, make sure to call the cpt script; with Python 3.; CPT uses some features and modules which are not a part of older versions of Python.; The same holds true for the versions of GCC/Clang you have on your machine. Older; compilers do not support c++11 features and thus you can expect a build error if you; choose not to update them. All pre-compiled binaries of Python ship with built-in support for SSL. However if; the Python on your system was compiled by you manually, ch",MatchSource.DOCS,interpreter/cling/tools/packaging/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:1080,Deployability,install,installed,1080,"===. The Cling Packaging Tool is a command-line utility written in Python to build; Cling from source and generate installer bundles for a wide range of platforms. Cling maintains its own vendor clones of LLVM and Clang (part of ROOT's trunk); on which it is based. This tool is the easiest way to build Cling for your favorite; platorm and bundle it into an installer. If you want to manually compile Cling; from source, go through the [README] of Cling or the build instructions [here]. [README]:https://github.com/root-project/cling/blob/master/README.md; [here]:https://root.cern/cling/cling_build_instructions/. Below is a list of platforms currently supported by CPT:; * Ubuntu and distros based on Debian - *DEB packages*; * Windows - *NSIS installers*; * Distros based on Red Hat Linux (Fedora/Scientific Linux CERN) - *RPM packages*; * Mac OS X - *Apple Disk Images*; * Virtually any UNIX-like platform which supports Bash - *Tarballs*. ### Requirements; Before using this tool, make sure you have the required packages installed on; your system. Detailed information on what and how to install is provided below,; but the recommended (and much easier) way is to use the following command which; performs the required checks automatically and displays useful suggestions too; specific to your platform.; ```sh; cd tools/packaging/; ./cpt.py --check-requirements; ```; or; ```sh; cd tools/packaging/; ./cpt.py -c; ```; Regardless of the platform and operating system, make sure to call the cpt script; with Python 3.; CPT uses some features and modules which are not a part of older versions of Python.; The same holds true for the versions of GCC/Clang you have on your machine. Older; compilers do not support c++11 features and thus you can expect a build error if you; choose not to update them. All pre-compiled binaries of Python ship with built-in support for SSL. However if; the Python on your system was compiled by you manually, chances are that it doesn't; have SSL support. This ",MatchSource.DOCS,interpreter/cling/tools/packaging/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:1147,Deployability,install,install,1147," own vendor clones of LLVM and Clang (part of ROOT's trunk); on which it is based. This tool is the easiest way to build Cling for your favorite; platorm and bundle it into an installer. If you want to manually compile Cling; from source, go through the [README] of Cling or the build instructions [here]. [README]:https://github.com/root-project/cling/blob/master/README.md; [here]:https://root.cern/cling/cling_build_instructions/. Below is a list of platforms currently supported by CPT:; * Ubuntu and distros based on Debian - *DEB packages*; * Windows - *NSIS installers*; * Distros based on Red Hat Linux (Fedora/Scientific Linux CERN) - *RPM packages*; * Mac OS X - *Apple Disk Images*; * Virtually any UNIX-like platform which supports Bash - *Tarballs*. ### Requirements; Before using this tool, make sure you have the required packages installed on; your system. Detailed information on what and how to install is provided below,; but the recommended (and much easier) way is to use the following command which; performs the required checks automatically and displays useful suggestions too; specific to your platform.; ```sh; cd tools/packaging/; ./cpt.py --check-requirements; ```; or; ```sh; cd tools/packaging/; ./cpt.py -c; ```; Regardless of the platform and operating system, make sure to call the cpt script; with Python 3.; CPT uses some features and modules which are not a part of older versions of Python.; The same holds true for the versions of GCC/Clang you have on your machine. Older; compilers do not support c++11 features and thus you can expect a build error if you; choose not to update them. All pre-compiled binaries of Python ship with built-in support for SSL. However if; the Python on your system was compiled by you manually, chances are that it doesn't; have SSL support. This is very likely if you had performed a minimal installation; of Scientific Linux CERN which doesn't include OpenSSL development package. In such; a case, you should install ```openssl-",MatchSource.DOCS,interpreter/cling/tools/packaging/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:1846,Deployability,update,update,1846," installers*; * Distros based on Red Hat Linux (Fedora/Scientific Linux CERN) - *RPM packages*; * Mac OS X - *Apple Disk Images*; * Virtually any UNIX-like platform which supports Bash - *Tarballs*. ### Requirements; Before using this tool, make sure you have the required packages installed on; your system. Detailed information on what and how to install is provided below,; but the recommended (and much easier) way is to use the following command which; performs the required checks automatically and displays useful suggestions too; specific to your platform.; ```sh; cd tools/packaging/; ./cpt.py --check-requirements; ```; or; ```sh; cd tools/packaging/; ./cpt.py -c; ```; Regardless of the platform and operating system, make sure to call the cpt script; with Python 3.; CPT uses some features and modules which are not a part of older versions of Python.; The same holds true for the versions of GCC/Clang you have on your machine. Older; compilers do not support c++11 features and thus you can expect a build error if you; choose not to update them. All pre-compiled binaries of Python ship with built-in support for SSL. However if; the Python on your system was compiled by you manually, chances are that it doesn't; have SSL support. This is very likely if you had performed a minimal installation; of Scientific Linux CERN which doesn't include OpenSSL development package. In such; a case, you should install ```openssl-devel```, re-compile Python and ```configure```; will automatically link against the required libraries and produce a binary with SSL; support. #### Ubuntu/Debian; On Debian, Ubuntu, Linux Mint, CrunchBang, or any other distro based on Debian; which supports APT package manager, you can install all the required packages by:; ```sh; sudo apt-get update; sudo apt-get install git g++ debhelper devscripts gnupg python; ```; You are not required to do this manually since CPT can do this for you automatically. ###### Setting up:; Make sure GnuPG is properly set up",MatchSource.DOCS,interpreter/cling/tools/packaging/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:2097,Deployability,install,installation,2097," information on what and how to install is provided below,; but the recommended (and much easier) way is to use the following command which; performs the required checks automatically and displays useful suggestions too; specific to your platform.; ```sh; cd tools/packaging/; ./cpt.py --check-requirements; ```; or; ```sh; cd tools/packaging/; ./cpt.py -c; ```; Regardless of the platform and operating system, make sure to call the cpt script; with Python 3.; CPT uses some features and modules which are not a part of older versions of Python.; The same holds true for the versions of GCC/Clang you have on your machine. Older; compilers do not support c++11 features and thus you can expect a build error if you; choose not to update them. All pre-compiled binaries of Python ship with built-in support for SSL. However if; the Python on your system was compiled by you manually, chances are that it doesn't; have SSL support. This is very likely if you had performed a minimal installation; of Scientific Linux CERN which doesn't include OpenSSL development package. In such; a case, you should install ```openssl-devel```, re-compile Python and ```configure```; will automatically link against the required libraries and produce a binary with SSL; support. #### Ubuntu/Debian; On Debian, Ubuntu, Linux Mint, CrunchBang, or any other distro based on Debian; which supports APT package manager, you can install all the required packages by:; ```sh; sudo apt-get update; sudo apt-get install git g++ debhelper devscripts gnupg python; ```; You are not required to do this manually since CPT can do this for you automatically. ###### Setting up:; Make sure GnuPG is properly set up with your correct fingerprint. These; credentials are needed to sign the Debian package and create Debian changelogs.; On a build machine (Electric Commander), make sure the fingerprint is of the; user who is supposed to sign the official uploads. You might also want to; configure GnuPG to not ask for the passphrase",MatchSource.DOCS,interpreter/cling/tools/packaging/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:2215,Deployability,install,install,2215,"cks automatically and displays useful suggestions too; specific to your platform.; ```sh; cd tools/packaging/; ./cpt.py --check-requirements; ```; or; ```sh; cd tools/packaging/; ./cpt.py -c; ```; Regardless of the platform and operating system, make sure to call the cpt script; with Python 3.; CPT uses some features and modules which are not a part of older versions of Python.; The same holds true for the versions of GCC/Clang you have on your machine. Older; compilers do not support c++11 features and thus you can expect a build error if you; choose not to update them. All pre-compiled binaries of Python ship with built-in support for SSL. However if; the Python on your system was compiled by you manually, chances are that it doesn't; have SSL support. This is very likely if you had performed a minimal installation; of Scientific Linux CERN which doesn't include OpenSSL development package. In such; a case, you should install ```openssl-devel```, re-compile Python and ```configure```; will automatically link against the required libraries and produce a binary with SSL; support. #### Ubuntu/Debian; On Debian, Ubuntu, Linux Mint, CrunchBang, or any other distro based on Debian; which supports APT package manager, you can install all the required packages by:; ```sh; sudo apt-get update; sudo apt-get install git g++ debhelper devscripts gnupg python; ```; You are not required to do this manually since CPT can do this for you automatically. ###### Setting up:; Make sure GnuPG is properly set up with your correct fingerprint. These; credentials are needed to sign the Debian package and create Debian changelogs.; On a build machine (Electric Commander), make sure the fingerprint is of the; user who is supposed to sign the official uploads. You might also want to; configure GnuPG to not ask for the passphrase while signing the Debian package. The [Ubuntu Packaging Guide] contains a quick guide on creating a GPG key on an; Ubuntu system. To test if you have successfully se",MatchSource.DOCS,interpreter/cling/tools/packaging/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:2522,Deployability,install,install,2522," with Python 3.; CPT uses some features and modules which are not a part of older versions of Python.; The same holds true for the versions of GCC/Clang you have on your machine. Older; compilers do not support c++11 features and thus you can expect a build error if you; choose not to update them. All pre-compiled binaries of Python ship with built-in support for SSL. However if; the Python on your system was compiled by you manually, chances are that it doesn't; have SSL support. This is very likely if you had performed a minimal installation; of Scientific Linux CERN which doesn't include OpenSSL development package. In such; a case, you should install ```openssl-devel```, re-compile Python and ```configure```; will automatically link against the required libraries and produce a binary with SSL; support. #### Ubuntu/Debian; On Debian, Ubuntu, Linux Mint, CrunchBang, or any other distro based on Debian; which supports APT package manager, you can install all the required packages by:; ```sh; sudo apt-get update; sudo apt-get install git g++ debhelper devscripts gnupg python; ```; You are not required to do this manually since CPT can do this for you automatically. ###### Setting up:; Make sure GnuPG is properly set up with your correct fingerprint. These; credentials are needed to sign the Debian package and create Debian changelogs.; On a build machine (Electric Commander), make sure the fingerprint is of the; user who is supposed to sign the official uploads. You might also want to; configure GnuPG to not ask for the passphrase while signing the Debian package. The [Ubuntu Packaging Guide] contains a quick guide on creating a GPG key on an; Ubuntu system. To test if you have successfully set up your GnuPG key, use the following command:; ```sh; gpg --fingerprint; ```; Again, all these checks are performed by default when you launch CPT with ```-c``` option.; [Ubuntu Packaging Guide]:http://packaging.ubuntu.com/html/getting-set-up.html#create-your-gpg-key. #### Wi",MatchSource.DOCS,interpreter/cling/tools/packaging/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:2581,Deployability,update,update,2581," with Python 3.; CPT uses some features and modules which are not a part of older versions of Python.; The same holds true for the versions of GCC/Clang you have on your machine. Older; compilers do not support c++11 features and thus you can expect a build error if you; choose not to update them. All pre-compiled binaries of Python ship with built-in support for SSL. However if; the Python on your system was compiled by you manually, chances are that it doesn't; have SSL support. This is very likely if you had performed a minimal installation; of Scientific Linux CERN which doesn't include OpenSSL development package. In such; a case, you should install ```openssl-devel```, re-compile Python and ```configure```; will automatically link against the required libraries and produce a binary with SSL; support. #### Ubuntu/Debian; On Debian, Ubuntu, Linux Mint, CrunchBang, or any other distro based on Debian; which supports APT package manager, you can install all the required packages by:; ```sh; sudo apt-get update; sudo apt-get install git g++ debhelper devscripts gnupg python; ```; You are not required to do this manually since CPT can do this for you automatically. ###### Setting up:; Make sure GnuPG is properly set up with your correct fingerprint. These; credentials are needed to sign the Debian package and create Debian changelogs.; On a build machine (Electric Commander), make sure the fingerprint is of the; user who is supposed to sign the official uploads. You might also want to; configure GnuPG to not ask for the passphrase while signing the Debian package. The [Ubuntu Packaging Guide] contains a quick guide on creating a GPG key on an; Ubuntu system. To test if you have successfully set up your GnuPG key, use the following command:; ```sh; gpg --fingerprint; ```; Again, all these checks are performed by default when you launch CPT with ```-c``` option.; [Ubuntu Packaging Guide]:http://packaging.ubuntu.com/html/getting-set-up.html#create-your-gpg-key. #### Wi",MatchSource.DOCS,interpreter/cling/tools/packaging/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:2602,Deployability,install,install,2602," with Python 3.; CPT uses some features and modules which are not a part of older versions of Python.; The same holds true for the versions of GCC/Clang you have on your machine. Older; compilers do not support c++11 features and thus you can expect a build error if you; choose not to update them. All pre-compiled binaries of Python ship with built-in support for SSL. However if; the Python on your system was compiled by you manually, chances are that it doesn't; have SSL support. This is very likely if you had performed a minimal installation; of Scientific Linux CERN which doesn't include OpenSSL development package. In such; a case, you should install ```openssl-devel```, re-compile Python and ```configure```; will automatically link against the required libraries and produce a binary with SSL; support. #### Ubuntu/Debian; On Debian, Ubuntu, Linux Mint, CrunchBang, or any other distro based on Debian; which supports APT package manager, you can install all the required packages by:; ```sh; sudo apt-get update; sudo apt-get install git g++ debhelper devscripts gnupg python; ```; You are not required to do this manually since CPT can do this for you automatically. ###### Setting up:; Make sure GnuPG is properly set up with your correct fingerprint. These; credentials are needed to sign the Debian package and create Debian changelogs.; On a build machine (Electric Commander), make sure the fingerprint is of the; user who is supposed to sign the official uploads. You might also want to; configure GnuPG to not ask for the passphrase while signing the Debian package. The [Ubuntu Packaging Guide] contains a quick guide on creating a GPG key on an; Ubuntu system. To test if you have successfully set up your GnuPG key, use the following command:; ```sh; gpg --fingerprint; ```; Again, all these checks are performed by default when you launch CPT with ```-c``` option.; [Ubuntu Packaging Guide]:http://packaging.ubuntu.com/html/getting-set-up.html#create-your-gpg-key. #### Wi",MatchSource.DOCS,interpreter/cling/tools/packaging/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:4169,Deployability,install,installing,4169,"ting a GPG key on an; Ubuntu system. To test if you have successfully set up your GnuPG key, use the following command:; ```sh; gpg --fingerprint; ```; Again, all these checks are performed by default when you launch CPT with ```-c``` option.; [Ubuntu Packaging Guide]:http://packaging.ubuntu.com/html/getting-set-up.html#create-your-gpg-key. #### Windows; CPT is meant to be executed on cmd.exe prompt. Make sure you have set the; environment properly before continuing.; Below is a list of required packages for Windows (Win32-x86):. [MSYS Git] for Windows. [Python] for Windows. Microsoft Visual Studio 11 (2012), with Microsoft Visual C++ 2012. [MSYS Git]:http://msysgit.github.io/; [Python]:https://www.python.org/. ###### Setting Up:; Unlike other UNIX-like platforms, Windows requires you to follow some rules.; Do not ignore this section unless you want CPT to fail mid-way with wierd; errors. You should require these instructions only once. * While installing the packages make sure the executable is in a path that; doesn't contain spaces. For example, you should install Python in a path like. ```sh; C:\Python27; ```; rather than. ```sh; C:\Program Files (x86)\Python 2.7; ```; * Path to all the required executables should be present in the Windows; **PATH** environment variable.; * In case of MSYS Git, choose the option ""Run Git from Windows; Command Prompt"" during installation. A good way to check if everything is detected properly by the script is to; run the following command:; ```sh; cd tools/packaging/; ./cpt.py --check-requirements; ```. #### Red Hat Linux (Fedora/Scientific Linux CERN); This section applies to all distros based on Red Hat Linux like Fedora, and; Scientific Linux CERN (SLC). Apparently, you can build RPM packages in any; distro regardless of the package manager it uses. This has been tested on; Fedora, SLC, Ubuntu, and CrunchBang. If you are interested, you can test it; on your favourite platform and email me the results. Depending on the package m",MatchSource.DOCS,interpreter/cling/tools/packaging/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:4285,Deployability,install,install,4285,"your GnuPG key, use the following command:; ```sh; gpg --fingerprint; ```; Again, all these checks are performed by default when you launch CPT with ```-c``` option.; [Ubuntu Packaging Guide]:http://packaging.ubuntu.com/html/getting-set-up.html#create-your-gpg-key. #### Windows; CPT is meant to be executed on cmd.exe prompt. Make sure you have set the; environment properly before continuing.; Below is a list of required packages for Windows (Win32-x86):. [MSYS Git] for Windows. [Python] for Windows. Microsoft Visual Studio 11 (2012), with Microsoft Visual C++ 2012. [MSYS Git]:http://msysgit.github.io/; [Python]:https://www.python.org/. ###### Setting Up:; Unlike other UNIX-like platforms, Windows requires you to follow some rules.; Do not ignore this section unless you want CPT to fail mid-way with wierd; errors. You should require these instructions only once. * While installing the packages make sure the executable is in a path that; doesn't contain spaces. For example, you should install Python in a path like. ```sh; C:\Python27; ```; rather than. ```sh; C:\Program Files (x86)\Python 2.7; ```; * Path to all the required executables should be present in the Windows; **PATH** environment variable.; * In case of MSYS Git, choose the option ""Run Git from Windows; Command Prompt"" during installation. A good way to check if everything is detected properly by the script is to; run the following command:; ```sh; cd tools/packaging/; ./cpt.py --check-requirements; ```. #### Red Hat Linux (Fedora/Scientific Linux CERN); This section applies to all distros based on Red Hat Linux like Fedora, and; Scientific Linux CERN (SLC). Apparently, you can build RPM packages in any; distro regardless of the package manager it uses. This has been tested on; Fedora, SLC, Ubuntu, and CrunchBang. If you are interested, you can test it; on your favourite platform and email me the results. Depending on the package manager of your distro, you can install the; packages required by CPT to build ",MatchSource.DOCS,interpreter/cling/tools/packaging/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:4593,Deployability,install,installation,4593,"## Windows; CPT is meant to be executed on cmd.exe prompt. Make sure you have set the; environment properly before continuing.; Below is a list of required packages for Windows (Win32-x86):. [MSYS Git] for Windows. [Python] for Windows. Microsoft Visual Studio 11 (2012), with Microsoft Visual C++ 2012. [MSYS Git]:http://msysgit.github.io/; [Python]:https://www.python.org/. ###### Setting Up:; Unlike other UNIX-like platforms, Windows requires you to follow some rules.; Do not ignore this section unless you want CPT to fail mid-way with wierd; errors. You should require these instructions only once. * While installing the packages make sure the executable is in a path that; doesn't contain spaces. For example, you should install Python in a path like. ```sh; C:\Python27; ```; rather than. ```sh; C:\Program Files (x86)\Python 2.7; ```; * Path to all the required executables should be present in the Windows; **PATH** environment variable.; * In case of MSYS Git, choose the option ""Run Git from Windows; Command Prompt"" during installation. A good way to check if everything is detected properly by the script is to; run the following command:; ```sh; cd tools/packaging/; ./cpt.py --check-requirements; ```. #### Red Hat Linux (Fedora/Scientific Linux CERN); This section applies to all distros based on Red Hat Linux like Fedora, and; Scientific Linux CERN (SLC). Apparently, you can build RPM packages in any; distro regardless of the package manager it uses. This has been tested on; Fedora, SLC, Ubuntu, and CrunchBang. If you are interested, you can test it; on your favourite platform and email me the results. Depending on the package manager of your distro, you can install the; packages required by CPT to build RPM bundles. For a Red Hat based distro; (which uses ```yum``` package manager), you can use the following command; (also performed automatically by CPT):; ```sh; sudo yum update; sudo yum install git gcc gcc-c++ rpm-build python; ```. #### Mac OS X; Mac OS X provide",MatchSource.DOCS,interpreter/cling/tools/packaging/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:5241,Deployability,install,install,5241,"n't contain spaces. For example, you should install Python in a path like. ```sh; C:\Python27; ```; rather than. ```sh; C:\Program Files (x86)\Python 2.7; ```; * Path to all the required executables should be present in the Windows; **PATH** environment variable.; * In case of MSYS Git, choose the option ""Run Git from Windows; Command Prompt"" during installation. A good way to check if everything is detected properly by the script is to; run the following command:; ```sh; cd tools/packaging/; ./cpt.py --check-requirements; ```. #### Red Hat Linux (Fedora/Scientific Linux CERN); This section applies to all distros based on Red Hat Linux like Fedora, and; Scientific Linux CERN (SLC). Apparently, you can build RPM packages in any; distro regardless of the package manager it uses. This has been tested on; Fedora, SLC, Ubuntu, and CrunchBang. If you are interested, you can test it; on your favourite platform and email me the results. Depending on the package manager of your distro, you can install the; packages required by CPT to build RPM bundles. For a Red Hat based distro; (which uses ```yum``` package manager), you can use the following command; (also performed automatically by CPT):; ```sh; sudo yum update; sudo yum install git gcc gcc-c++ rpm-build python; ```. #### Mac OS X; Mac OS X provides a sane environement for CPT to build Apple Disk Images; (DMG Installers). On older versions of Mac OS, you need to update XCode to; get the latest version of Clang supporting c++11 features. A great package; manager for Mac OS X is [Macports]. It is recommended that you use the; packages provided by Macports for running CPT (or any other tool if that; is the case) rather than the ones which come pre-installed with Mac OS.; Assuming that you have Macports installed on your Mac, you can use the; following command to install the requisite packages (also done automatically; by CPT):; [Macports]:http://www.macports.org/; ```sh; sudo port -v selfupdate; sudo port install git g++ pyt",MatchSource.DOCS,interpreter/cling/tools/packaging/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:5460,Deployability,update,update,5460,"all the required executables should be present in the Windows; **PATH** environment variable.; * In case of MSYS Git, choose the option ""Run Git from Windows; Command Prompt"" during installation. A good way to check if everything is detected properly by the script is to; run the following command:; ```sh; cd tools/packaging/; ./cpt.py --check-requirements; ```. #### Red Hat Linux (Fedora/Scientific Linux CERN); This section applies to all distros based on Red Hat Linux like Fedora, and; Scientific Linux CERN (SLC). Apparently, you can build RPM packages in any; distro regardless of the package manager it uses. This has been tested on; Fedora, SLC, Ubuntu, and CrunchBang. If you are interested, you can test it; on your favourite platform and email me the results. Depending on the package manager of your distro, you can install the; packages required by CPT to build RPM bundles. For a Red Hat based distro; (which uses ```yum``` package manager), you can use the following command; (also performed automatically by CPT):; ```sh; sudo yum update; sudo yum install git gcc gcc-c++ rpm-build python; ```. #### Mac OS X; Mac OS X provides a sane environement for CPT to build Apple Disk Images; (DMG Installers). On older versions of Mac OS, you need to update XCode to; get the latest version of Clang supporting c++11 features. A great package; manager for Mac OS X is [Macports]. It is recommended that you use the; packages provided by Macports for running CPT (or any other tool if that; is the case) rather than the ones which come pre-installed with Mac OS.; Assuming that you have Macports installed on your Mac, you can use the; following command to install the requisite packages (also done automatically; by CPT):; [Macports]:http://www.macports.org/; ```sh; sudo port -v selfupdate; sudo port install git g++ python; ```. ### Usage; ```sh; cd tools/packaging/; ```. ```; usage: cpt.py [-h] [-c] [--current-dev CURRENT_DEV]; [--last-stable LAST_STABLE] [--tarball-tag TARBALL_TAG]; [",MatchSource.DOCS,interpreter/cling/tools/packaging/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:5477,Deployability,install,install,5477,"all the required executables should be present in the Windows; **PATH** environment variable.; * In case of MSYS Git, choose the option ""Run Git from Windows; Command Prompt"" during installation. A good way to check if everything is detected properly by the script is to; run the following command:; ```sh; cd tools/packaging/; ./cpt.py --check-requirements; ```. #### Red Hat Linux (Fedora/Scientific Linux CERN); This section applies to all distros based on Red Hat Linux like Fedora, and; Scientific Linux CERN (SLC). Apparently, you can build RPM packages in any; distro regardless of the package manager it uses. This has been tested on; Fedora, SLC, Ubuntu, and CrunchBang. If you are interested, you can test it; on your favourite platform and email me the results. Depending on the package manager of your distro, you can install the; packages required by CPT to build RPM bundles. For a Red Hat based distro; (which uses ```yum``` package manager), you can use the following command; (also performed automatically by CPT):; ```sh; sudo yum update; sudo yum install git gcc gcc-c++ rpm-build python; ```. #### Mac OS X; Mac OS X provides a sane environement for CPT to build Apple Disk Images; (DMG Installers). On older versions of Mac OS, you need to update XCode to; get the latest version of Clang supporting c++11 features. A great package; manager for Mac OS X is [Macports]. It is recommended that you use the; packages provided by Macports for running CPT (or any other tool if that; is the case) rather than the ones which come pre-installed with Mac OS.; Assuming that you have Macports installed on your Mac, you can use the; following command to install the requisite packages (also done automatically; by CPT):; [Macports]:http://www.macports.org/; ```sh; sudo port -v selfupdate; sudo port install git g++ python; ```. ### Usage; ```sh; cd tools/packaging/; ```. ```; usage: cpt.py [-h] [-c] [--current-dev CURRENT_DEV]; [--last-stable LAST_STABLE] [--tarball-tag TARBALL_TAG]; [",MatchSource.DOCS,interpreter/cling/tools/packaging/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:5672,Deployability,update,update,5672,"he following command:; ```sh; cd tools/packaging/; ./cpt.py --check-requirements; ```. #### Red Hat Linux (Fedora/Scientific Linux CERN); This section applies to all distros based on Red Hat Linux like Fedora, and; Scientific Linux CERN (SLC). Apparently, you can build RPM packages in any; distro regardless of the package manager it uses. This has been tested on; Fedora, SLC, Ubuntu, and CrunchBang. If you are interested, you can test it; on your favourite platform and email me the results. Depending on the package manager of your distro, you can install the; packages required by CPT to build RPM bundles. For a Red Hat based distro; (which uses ```yum``` package manager), you can use the following command; (also performed automatically by CPT):; ```sh; sudo yum update; sudo yum install git gcc gcc-c++ rpm-build python; ```. #### Mac OS X; Mac OS X provides a sane environement for CPT to build Apple Disk Images; (DMG Installers). On older versions of Mac OS, you need to update XCode to; get the latest version of Clang supporting c++11 features. A great package; manager for Mac OS X is [Macports]. It is recommended that you use the; packages provided by Macports for running CPT (or any other tool if that; is the case) rather than the ones which come pre-installed with Mac OS.; Assuming that you have Macports installed on your Mac, you can use the; following command to install the requisite packages (also done automatically; by CPT):; [Macports]:http://www.macports.org/; ```sh; sudo port -v selfupdate; sudo port install git g++ python; ```. ### Usage; ```sh; cd tools/packaging/; ```. ```; usage: cpt.py [-h] [-c] [--current-dev CURRENT_DEV]; [--last-stable LAST_STABLE] [--tarball-tag TARBALL_TAG]; [--deb-tag DEB_TAG] [--rpm-tag RPM_TAG] [--nsis-tag NSIS_TAG]; [--dmg-tag DMG_TAG] [--with-llvm-url WITH_LLVM_URL]; [--with-clang-url WITH_CLANG_URL]; [--with-cling-url WITH_CLING_URL] [--no-test]; [--create-dev-env CREATE_DEV_ENV] [--with-workdir WITH_WORKDIR]; [--make-proper ",MatchSource.DOCS,interpreter/cling/tools/packaging/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:5960,Deployability,install,installed,5960,"edora, and; Scientific Linux CERN (SLC). Apparently, you can build RPM packages in any; distro regardless of the package manager it uses. This has been tested on; Fedora, SLC, Ubuntu, and CrunchBang. If you are interested, you can test it; on your favourite platform and email me the results. Depending on the package manager of your distro, you can install the; packages required by CPT to build RPM bundles. For a Red Hat based distro; (which uses ```yum``` package manager), you can use the following command; (also performed automatically by CPT):; ```sh; sudo yum update; sudo yum install git gcc gcc-c++ rpm-build python; ```. #### Mac OS X; Mac OS X provides a sane environement for CPT to build Apple Disk Images; (DMG Installers). On older versions of Mac OS, you need to update XCode to; get the latest version of Clang supporting c++11 features. A great package; manager for Mac OS X is [Macports]. It is recommended that you use the; packages provided by Macports for running CPT (or any other tool if that; is the case) rather than the ones which come pre-installed with Mac OS.; Assuming that you have Macports installed on your Mac, you can use the; following command to install the requisite packages (also done automatically; by CPT):; [Macports]:http://www.macports.org/; ```sh; sudo port -v selfupdate; sudo port install git g++ python; ```. ### Usage; ```sh; cd tools/packaging/; ```. ```; usage: cpt.py [-h] [-c] [--current-dev CURRENT_DEV]; [--last-stable LAST_STABLE] [--tarball-tag TARBALL_TAG]; [--deb-tag DEB_TAG] [--rpm-tag RPM_TAG] [--nsis-tag NSIS_TAG]; [--dmg-tag DMG_TAG] [--with-llvm-url WITH_LLVM_URL]; [--with-clang-url WITH_CLANG_URL]; [--with-cling-url WITH_CLING_URL] [--no-test]; [--create-dev-env CREATE_DEV_ENV] [--with-workdir WITH_WORKDIR]; [--make-proper MAKE_PROPER]. Cling Packaging Tool. optional arguments:; -h, --help show this help message and exit; -c, --check-requirements; Check if packages required by the script are installed; --current-dev CURRE",MatchSource.DOCS,interpreter/cling/tools/packaging/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:6016,Deployability,install,installed,6016," and CrunchBang. If you are interested, you can test it; on your favourite platform and email me the results. Depending on the package manager of your distro, you can install the; packages required by CPT to build RPM bundles. For a Red Hat based distro; (which uses ```yum``` package manager), you can use the following command; (also performed automatically by CPT):; ```sh; sudo yum update; sudo yum install git gcc gcc-c++ rpm-build python; ```. #### Mac OS X; Mac OS X provides a sane environement for CPT to build Apple Disk Images; (DMG Installers). On older versions of Mac OS, you need to update XCode to; get the latest version of Clang supporting c++11 features. A great package; manager for Mac OS X is [Macports]. It is recommended that you use the; packages provided by Macports for running CPT (or any other tool if that; is the case) rather than the ones which come pre-installed with Mac OS.; Assuming that you have Macports installed on your Mac, you can use the; following command to install the requisite packages (also done automatically; by CPT):; [Macports]:http://www.macports.org/; ```sh; sudo port -v selfupdate; sudo port install git g++ python; ```. ### Usage; ```sh; cd tools/packaging/; ```. ```; usage: cpt.py [-h] [-c] [--current-dev CURRENT_DEV]; [--last-stable LAST_STABLE] [--tarball-tag TARBALL_TAG]; [--deb-tag DEB_TAG] [--rpm-tag RPM_TAG] [--nsis-tag NSIS_TAG]; [--dmg-tag DMG_TAG] [--with-llvm-url WITH_LLVM_URL]; [--with-clang-url WITH_CLANG_URL]; [--with-cling-url WITH_CLING_URL] [--no-test]; [--create-dev-env CREATE_DEV_ENV] [--with-workdir WITH_WORKDIR]; [--make-proper MAKE_PROPER]. Cling Packaging Tool. optional arguments:; -h, --help show this help message and exit; -c, --check-requirements; Check if packages required by the script are installed; --current-dev CURRENT_DEV; Package the latest development snapshot in one of; these formats: tar | deb | nsis | rpm | dmg | pkg; --last-stable LAST_STABLE; Package the last stable snapshot in one of the",MatchSource.DOCS,interpreter/cling/tools/packaging/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:6077,Deployability,install,install,6077," and CrunchBang. If you are interested, you can test it; on your favourite platform and email me the results. Depending on the package manager of your distro, you can install the; packages required by CPT to build RPM bundles. For a Red Hat based distro; (which uses ```yum``` package manager), you can use the following command; (also performed automatically by CPT):; ```sh; sudo yum update; sudo yum install git gcc gcc-c++ rpm-build python; ```. #### Mac OS X; Mac OS X provides a sane environement for CPT to build Apple Disk Images; (DMG Installers). On older versions of Mac OS, you need to update XCode to; get the latest version of Clang supporting c++11 features. A great package; manager for Mac OS X is [Macports]. It is recommended that you use the; packages provided by Macports for running CPT (or any other tool if that; is the case) rather than the ones which come pre-installed with Mac OS.; Assuming that you have Macports installed on your Mac, you can use the; following command to install the requisite packages (also done automatically; by CPT):; [Macports]:http://www.macports.org/; ```sh; sudo port -v selfupdate; sudo port install git g++ python; ```. ### Usage; ```sh; cd tools/packaging/; ```. ```; usage: cpt.py [-h] [-c] [--current-dev CURRENT_DEV]; [--last-stable LAST_STABLE] [--tarball-tag TARBALL_TAG]; [--deb-tag DEB_TAG] [--rpm-tag RPM_TAG] [--nsis-tag NSIS_TAG]; [--dmg-tag DMG_TAG] [--with-llvm-url WITH_LLVM_URL]; [--with-clang-url WITH_CLANG_URL]; [--with-cling-url WITH_CLING_URL] [--no-test]; [--create-dev-env CREATE_DEV_ENV] [--with-workdir WITH_WORKDIR]; [--make-proper MAKE_PROPER]. Cling Packaging Tool. optional arguments:; -h, --help show this help message and exit; -c, --check-requirements; Check if packages required by the script are installed; --current-dev CURRENT_DEV; Package the latest development snapshot in one of; these formats: tar | deb | nsis | rpm | dmg | pkg; --last-stable LAST_STABLE; Package the last stable snapshot in one of the",MatchSource.DOCS,interpreter/cling/tools/packaging/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:6223,Deployability,install,install,6223,"ger of your distro, you can install the; packages required by CPT to build RPM bundles. For a Red Hat based distro; (which uses ```yum``` package manager), you can use the following command; (also performed automatically by CPT):; ```sh; sudo yum update; sudo yum install git gcc gcc-c++ rpm-build python; ```. #### Mac OS X; Mac OS X provides a sane environement for CPT to build Apple Disk Images; (DMG Installers). On older versions of Mac OS, you need to update XCode to; get the latest version of Clang supporting c++11 features. A great package; manager for Mac OS X is [Macports]. It is recommended that you use the; packages provided by Macports for running CPT (or any other tool if that; is the case) rather than the ones which come pre-installed with Mac OS.; Assuming that you have Macports installed on your Mac, you can use the; following command to install the requisite packages (also done automatically; by CPT):; [Macports]:http://www.macports.org/; ```sh; sudo port -v selfupdate; sudo port install git g++ python; ```. ### Usage; ```sh; cd tools/packaging/; ```. ```; usage: cpt.py [-h] [-c] [--current-dev CURRENT_DEV]; [--last-stable LAST_STABLE] [--tarball-tag TARBALL_TAG]; [--deb-tag DEB_TAG] [--rpm-tag RPM_TAG] [--nsis-tag NSIS_TAG]; [--dmg-tag DMG_TAG] [--with-llvm-url WITH_LLVM_URL]; [--with-clang-url WITH_CLANG_URL]; [--with-cling-url WITH_CLING_URL] [--no-test]; [--create-dev-env CREATE_DEV_ENV] [--with-workdir WITH_WORKDIR]; [--make-proper MAKE_PROPER]. Cling Packaging Tool. optional arguments:; -h, --help show this help message and exit; -c, --check-requirements; Check if packages required by the script are installed; --current-dev CURRENT_DEV; Package the latest development snapshot in one of; these formats: tar | deb | nsis | rpm | dmg | pkg; --last-stable LAST_STABLE; Package the last stable snapshot in one of these; formats: tar | deb | nsis | rpm | dmg | pkg; --tarball-tag TARBALL_TAG; Package the snapshot of a given tag in a tarball; (.tar.bz2); -",MatchSource.DOCS,interpreter/cling/tools/packaging/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:6861,Deployability,install,installed,6861,"talled with Mac OS.; Assuming that you have Macports installed on your Mac, you can use the; following command to install the requisite packages (also done automatically; by CPT):; [Macports]:http://www.macports.org/; ```sh; sudo port -v selfupdate; sudo port install git g++ python; ```. ### Usage; ```sh; cd tools/packaging/; ```. ```; usage: cpt.py [-h] [-c] [--current-dev CURRENT_DEV]; [--last-stable LAST_STABLE] [--tarball-tag TARBALL_TAG]; [--deb-tag DEB_TAG] [--rpm-tag RPM_TAG] [--nsis-tag NSIS_TAG]; [--dmg-tag DMG_TAG] [--with-llvm-url WITH_LLVM_URL]; [--with-clang-url WITH_CLANG_URL]; [--with-cling-url WITH_CLING_URL] [--no-test]; [--create-dev-env CREATE_DEV_ENV] [--with-workdir WITH_WORKDIR]; [--make-proper MAKE_PROPER]. Cling Packaging Tool. optional arguments:; -h, --help show this help message and exit; -c, --check-requirements; Check if packages required by the script are installed; --current-dev CURRENT_DEV; Package the latest development snapshot in one of; these formats: tar | deb | nsis | rpm | dmg | pkg; --last-stable LAST_STABLE; Package the last stable snapshot in one of these; formats: tar | deb | nsis | rpm | dmg | pkg; --tarball-tag TARBALL_TAG; Package the snapshot of a given tag in a tarball; (.tar.bz2); --deb-tag DEB_TAG Package the snapshot of a given tag in a Debian; package (.deb); --rpm-tag RPM_TAG Package the snapshot of a given tag in an RPM package; (.rpm); --nsis-tag NSIS_TAG Package the snapshot of a given tag in an NSIS; installer (.exe); --dmg-tag DMG_TAG Package the snapshot of a given tag in a DMG package; (.dmg); --with-llvm-url WITH_LLVM_URL; Specify an alternate URL of LLVM repo; --with-clang-url WITH_CLANG_URL; Specify an alternate URL of Clang repo; --with-cling-url WITH_CLING_URL; Specify an alternate URL of Cling repo; --no-test Do not run test suite of Cling; --create-dev-env CREATE_DEV_ENV; Set up a release/debug environment; --with-workdir WITH_WORKDIR; Specify an alternate working directory for CPT; --make-proper MAK",MatchSource.DOCS,interpreter/cling/tools/packaging/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:7444,Deployability,install,installer,7444,"-deb-tag DEB_TAG] [--rpm-tag RPM_TAG] [--nsis-tag NSIS_TAG]; [--dmg-tag DMG_TAG] [--with-llvm-url WITH_LLVM_URL]; [--with-clang-url WITH_CLANG_URL]; [--with-cling-url WITH_CLING_URL] [--no-test]; [--create-dev-env CREATE_DEV_ENV] [--with-workdir WITH_WORKDIR]; [--make-proper MAKE_PROPER]. Cling Packaging Tool. optional arguments:; -h, --help show this help message and exit; -c, --check-requirements; Check if packages required by the script are installed; --current-dev CURRENT_DEV; Package the latest development snapshot in one of; these formats: tar | deb | nsis | rpm | dmg | pkg; --last-stable LAST_STABLE; Package the last stable snapshot in one of these; formats: tar | deb | nsis | rpm | dmg | pkg; --tarball-tag TARBALL_TAG; Package the snapshot of a given tag in a tarball; (.tar.bz2); --deb-tag DEB_TAG Package the snapshot of a given tag in a Debian; package (.deb); --rpm-tag RPM_TAG Package the snapshot of a given tag in an RPM package; (.rpm); --nsis-tag NSIS_TAG Package the snapshot of a given tag in an NSIS; installer (.exe); --dmg-tag DMG_TAG Package the snapshot of a given tag in a DMG package; (.dmg); --with-llvm-url WITH_LLVM_URL; Specify an alternate URL of LLVM repo; --with-clang-url WITH_CLANG_URL; Specify an alternate URL of Clang repo; --with-cling-url WITH_CLING_URL; Specify an alternate URL of Cling repo; --no-test Do not run test suite of Cling; --create-dev-env CREATE_DEV_ENV; Set up a release/debug environment; --with-workdir WITH_WORKDIR; Specify an alternate working directory for CPT; --make-proper MAKE_PROPER; Internal option to support calls from build system. ```; If you want CPT to build a package by detecting your platform automatically,; use the value 'pkg'.; ```sh; ./cpt.py --current-dev=pkg; ```; or; ```sh; ./cpt.py --last-stable=pkg; ```; ### Overriding Default Variables; There are a select number of variables which can be set to make CPT work; differently. This eliminates the need to manually edit the script.; You can overrride varia",MatchSource.DOCS,interpreter/cling/tools/packaging/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:7842,Deployability,release,release,7842,"and exit; -c, --check-requirements; Check if packages required by the script are installed; --current-dev CURRENT_DEV; Package the latest development snapshot in one of; these formats: tar | deb | nsis | rpm | dmg | pkg; --last-stable LAST_STABLE; Package the last stable snapshot in one of these; formats: tar | deb | nsis | rpm | dmg | pkg; --tarball-tag TARBALL_TAG; Package the snapshot of a given tag in a tarball; (.tar.bz2); --deb-tag DEB_TAG Package the snapshot of a given tag in a Debian; package (.deb); --rpm-tag RPM_TAG Package the snapshot of a given tag in an RPM package; (.rpm); --nsis-tag NSIS_TAG Package the snapshot of a given tag in an NSIS; installer (.exe); --dmg-tag DMG_TAG Package the snapshot of a given tag in a DMG package; (.dmg); --with-llvm-url WITH_LLVM_URL; Specify an alternate URL of LLVM repo; --with-clang-url WITH_CLANG_URL; Specify an alternate URL of Clang repo; --with-cling-url WITH_CLING_URL; Specify an alternate URL of Cling repo; --no-test Do not run test suite of Cling; --create-dev-env CREATE_DEV_ENV; Set up a release/debug environment; --with-workdir WITH_WORKDIR; Specify an alternate working directory for CPT; --make-proper MAKE_PROPER; Internal option to support calls from build system. ```; If you want CPT to build a package by detecting your platform automatically,; use the value 'pkg'.; ```sh; ./cpt.py --current-dev=pkg; ```; or; ```sh; ./cpt.py --last-stable=pkg; ```; ### Overriding Default Variables; There are a select number of variables which can be set to make CPT work; differently. This eliminates the need to manually edit the script.; You can overrride variables by using the following syntax:; ```$ ./cpt.py --with-cling-url=""http://github.com/ani07nov/cling"" --current-dev=tar```. List of variables in CPT which can be overridden:; - **CLING_GIT_URL**; * Specify the URL of the Git repository of Cling to be used by CPT; * **Default value:** ""http://root.cern.ch/git/cling.git""; * **Usage:** ```./cpt.py --with-cling-url=""h",MatchSource.DOCS,interpreter/cling/tools/packaging/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:9416,Deployability,install,installed,9416,"t number of variables which can be set to make CPT work; differently. This eliminates the need to manually edit the script.; You can overrride variables by using the following syntax:; ```$ ./cpt.py --with-cling-url=""http://github.com/ani07nov/cling"" --current-dev=tar```. List of variables in CPT which can be overridden:; - **CLING_GIT_URL**; * Specify the URL of the Git repository of Cling to be used by CPT; * **Default value:** ""http://root.cern.ch/git/cling.git""; * **Usage:** ```./cpt.py --with-cling-url=""http://github.com/ani07nov/cling"" --last-stable=deb```. - **CLANG_GIT_URL**; * Specify the URL of the Git repository of Clang to be used by CPT; * **Default value:** ""http://root.cern.ch/git/clang.git""; * **Usage:** ```./cpt.py --with-clang-url=""http://github.com/ani07nov/clang"" --last-stable=tar```. - **LLVM_GIT_URL**; * Specify the URL of the Git repository of LLVM to be used by CPT; * **Default value:** ""http://root.cern.ch/git/llvm.git""; * **Usage:** ```./cpt.py --with-llvm-url=""http://github.com/ani07nov/llvm"" --current-dev=tar```. - **workdir**; * Specify the working directory of CPT. All sources will be cloned, built; and installed here. The produced packages will also be found here.; * **Default value:** ""~/ec/build""; * **Usage:** ```./cpt.py --with-workdir=""/ec/build"" --current-dev=deb```. Authors; =======; Cling Packaging Tool was developed during Google Summer of Code 2014,; by Anirudha Bose under the mentorship of Vassil Vassilev. Please post all bug reports and feature requests in the Github issue tracker; of this repository. Alternatively you can directly email me in this address:; ani07nov@gmail.com. License; =======; Cling Packaging Tool is a part of Cling project and released under the same; license terms of Cling. You can choose to license it under the University of; Illinois Open Source License or the GNU Lesser General Public License. See; [LICENSE.TXT] for details. [LICENSE.TXT]:https://github.com/root-project/cling/blob/master/LICENSE.TXT; ",MatchSource.DOCS,interpreter/cling/tools/packaging/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:9982,Deployability,release,released,9982,"t number of variables which can be set to make CPT work; differently. This eliminates the need to manually edit the script.; You can overrride variables by using the following syntax:; ```$ ./cpt.py --with-cling-url=""http://github.com/ani07nov/cling"" --current-dev=tar```. List of variables in CPT which can be overridden:; - **CLING_GIT_URL**; * Specify the URL of the Git repository of Cling to be used by CPT; * **Default value:** ""http://root.cern.ch/git/cling.git""; * **Usage:** ```./cpt.py --with-cling-url=""http://github.com/ani07nov/cling"" --last-stable=deb```. - **CLANG_GIT_URL**; * Specify the URL of the Git repository of Clang to be used by CPT; * **Default value:** ""http://root.cern.ch/git/clang.git""; * **Usage:** ```./cpt.py --with-clang-url=""http://github.com/ani07nov/clang"" --last-stable=tar```. - **LLVM_GIT_URL**; * Specify the URL of the Git repository of LLVM to be used by CPT; * **Default value:** ""http://root.cern.ch/git/llvm.git""; * **Usage:** ```./cpt.py --with-llvm-url=""http://github.com/ani07nov/llvm"" --current-dev=tar```. - **workdir**; * Specify the working directory of CPT. All sources will be cloned, built; and installed here. The produced packages will also be found here.; * **Default value:** ""~/ec/build""; * **Usage:** ```./cpt.py --with-workdir=""/ec/build"" --current-dev=deb```. Authors; =======; Cling Packaging Tool was developed during Google Summer of Code 2014,; by Anirudha Bose under the mentorship of Vassil Vassilev. Please post all bug reports and feature requests in the Github issue tracker; of this repository. Alternatively you can directly email me in this address:; ani07nov@gmail.com. License; =======; Cling Packaging Tool is a part of Cling project and released under the same; license terms of Cling. You can choose to license it under the University of; Illinois Open Source License or the GNU Lesser General Public License. See; [LICENSE.TXT] for details. [LICENSE.TXT]:https://github.com/root-project/cling/blob/master/LICENSE.TXT; ",MatchSource.DOCS,interpreter/cling/tools/packaging/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:6772,Integrability,message,message,6772,"talled with Mac OS.; Assuming that you have Macports installed on your Mac, you can use the; following command to install the requisite packages (also done automatically; by CPT):; [Macports]:http://www.macports.org/; ```sh; sudo port -v selfupdate; sudo port install git g++ python; ```. ### Usage; ```sh; cd tools/packaging/; ```. ```; usage: cpt.py [-h] [-c] [--current-dev CURRENT_DEV]; [--last-stable LAST_STABLE] [--tarball-tag TARBALL_TAG]; [--deb-tag DEB_TAG] [--rpm-tag RPM_TAG] [--nsis-tag NSIS_TAG]; [--dmg-tag DMG_TAG] [--with-llvm-url WITH_LLVM_URL]; [--with-clang-url WITH_CLANG_URL]; [--with-cling-url WITH_CLING_URL] [--no-test]; [--create-dev-env CREATE_DEV_ENV] [--with-workdir WITH_WORKDIR]; [--make-proper MAKE_PROPER]. Cling Packaging Tool. optional arguments:; -h, --help show this help message and exit; -c, --check-requirements; Check if packages required by the script are installed; --current-dev CURRENT_DEV; Package the latest development snapshot in one of; these formats: tar | deb | nsis | rpm | dmg | pkg; --last-stable LAST_STABLE; Package the last stable snapshot in one of these; formats: tar | deb | nsis | rpm | dmg | pkg; --tarball-tag TARBALL_TAG; Package the snapshot of a given tag in a tarball; (.tar.bz2); --deb-tag DEB_TAG Package the snapshot of a given tag in a Debian; package (.deb); --rpm-tag RPM_TAG Package the snapshot of a given tag in an RPM package; (.rpm); --nsis-tag NSIS_TAG Package the snapshot of a given tag in an NSIS; installer (.exe); --dmg-tag DMG_TAG Package the snapshot of a given tag in a DMG package; (.dmg); --with-llvm-url WITH_LLVM_URL; Specify an alternate URL of LLVM repo; --with-clang-url WITH_CLANG_URL; Specify an alternate URL of Clang repo; --with-cling-url WITH_CLING_URL; Specify an alternate URL of Cling repo; --no-test Do not run test suite of Cling; --create-dev-env CREATE_DEV_ENV; Set up a release/debug environment; --with-workdir WITH_WORKDIR; Specify an alternate working directory for CPT; --make-proper MAK",MatchSource.DOCS,interpreter/cling/tools/packaging/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:2269,Modifiability,config,configure,2269,"cks automatically and displays useful suggestions too; specific to your platform.; ```sh; cd tools/packaging/; ./cpt.py --check-requirements; ```; or; ```sh; cd tools/packaging/; ./cpt.py -c; ```; Regardless of the platform and operating system, make sure to call the cpt script; with Python 3.; CPT uses some features and modules which are not a part of older versions of Python.; The same holds true for the versions of GCC/Clang you have on your machine. Older; compilers do not support c++11 features and thus you can expect a build error if you; choose not to update them. All pre-compiled binaries of Python ship with built-in support for SSL. However if; the Python on your system was compiled by you manually, chances are that it doesn't; have SSL support. This is very likely if you had performed a minimal installation; of Scientific Linux CERN which doesn't include OpenSSL development package. In such; a case, you should install ```openssl-devel```, re-compile Python and ```configure```; will automatically link against the required libraries and produce a binary with SSL; support. #### Ubuntu/Debian; On Debian, Ubuntu, Linux Mint, CrunchBang, or any other distro based on Debian; which supports APT package manager, you can install all the required packages by:; ```sh; sudo apt-get update; sudo apt-get install git g++ debhelper devscripts gnupg python; ```; You are not required to do this manually since CPT can do this for you automatically. ###### Setting up:; Make sure GnuPG is properly set up with your correct fingerprint. These; credentials are needed to sign the Debian package and create Debian changelogs.; On a build machine (Electric Commander), make sure the fingerprint is of the; user who is supposed to sign the official uploads. You might also want to; configure GnuPG to not ask for the passphrase while signing the Debian package. The [Ubuntu Packaging Guide] contains a quick guide on creating a GPG key on an; Ubuntu system. To test if you have successfully se",MatchSource.DOCS,interpreter/cling/tools/packaging/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:3071,Modifiability,config,configure,3071,"nstallation; of Scientific Linux CERN which doesn't include OpenSSL development package. In such; a case, you should install ```openssl-devel```, re-compile Python and ```configure```; will automatically link against the required libraries and produce a binary with SSL; support. #### Ubuntu/Debian; On Debian, Ubuntu, Linux Mint, CrunchBang, or any other distro based on Debian; which supports APT package manager, you can install all the required packages by:; ```sh; sudo apt-get update; sudo apt-get install git g++ debhelper devscripts gnupg python; ```; You are not required to do this manually since CPT can do this for you automatically. ###### Setting up:; Make sure GnuPG is properly set up with your correct fingerprint. These; credentials are needed to sign the Debian package and create Debian changelogs.; On a build machine (Electric Commander), make sure the fingerprint is of the; user who is supposed to sign the official uploads. You might also want to; configure GnuPG to not ask for the passphrase while signing the Debian package. The [Ubuntu Packaging Guide] contains a quick guide on creating a GPG key on an; Ubuntu system. To test if you have successfully set up your GnuPG key, use the following command:; ```sh; gpg --fingerprint; ```; Again, all these checks are performed by default when you launch CPT with ```-c``` option.; [Ubuntu Packaging Guide]:http://packaging.ubuntu.com/html/getting-set-up.html#create-your-gpg-key. #### Windows; CPT is meant to be executed on cmd.exe prompt. Make sure you have set the; environment properly before continuing.; Below is a list of required packages for Windows (Win32-x86):. [MSYS Git] for Windows. [Python] for Windows. Microsoft Visual Studio 11 (2012), with Microsoft Visual C++ 2012. [MSYS Git]:http://msysgit.github.io/; [Python]:https://www.python.org/. ###### Setting Up:; Unlike other UNIX-like platforms, Windows requires you to follow some rules.; Do not ignore this section unless you want CPT to fail mid-way with w",MatchSource.DOCS,interpreter/cling/tools/packaging/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:4495,Modifiability,variab,variable,4495,"ion.; [Ubuntu Packaging Guide]:http://packaging.ubuntu.com/html/getting-set-up.html#create-your-gpg-key. #### Windows; CPT is meant to be executed on cmd.exe prompt. Make sure you have set the; environment properly before continuing.; Below is a list of required packages for Windows (Win32-x86):. [MSYS Git] for Windows. [Python] for Windows. Microsoft Visual Studio 11 (2012), with Microsoft Visual C++ 2012. [MSYS Git]:http://msysgit.github.io/; [Python]:https://www.python.org/. ###### Setting Up:; Unlike other UNIX-like platforms, Windows requires you to follow some rules.; Do not ignore this section unless you want CPT to fail mid-way with wierd; errors. You should require these instructions only once. * While installing the packages make sure the executable is in a path that; doesn't contain spaces. For example, you should install Python in a path like. ```sh; C:\Python27; ```; rather than. ```sh; C:\Program Files (x86)\Python 2.7; ```; * Path to all the required executables should be present in the Windows; **PATH** environment variable.; * In case of MSYS Git, choose the option ""Run Git from Windows; Command Prompt"" during installation. A good way to check if everything is detected properly by the script is to; run the following command:; ```sh; cd tools/packaging/; ./cpt.py --check-requirements; ```. #### Red Hat Linux (Fedora/Scientific Linux CERN); This section applies to all distros based on Red Hat Linux like Fedora, and; Scientific Linux CERN (SLC). Apparently, you can build RPM packages in any; distro regardless of the package manager it uses. This has been tested on; Fedora, SLC, Ubuntu, and CrunchBang. If you are interested, you can test it; on your favourite platform and email me the results. Depending on the package manager of your distro, you can install the; packages required by CPT to build RPM bundles. For a Red Hat based distro; (which uses ```yum``` package manager), you can use the following command; (also performed automatically by CPT):; ```sh",MatchSource.DOCS,interpreter/cling/tools/packaging/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:8277,Modifiability,variab,variables,8277,"n tag in a Debian; package (.deb); --rpm-tag RPM_TAG Package the snapshot of a given tag in an RPM package; (.rpm); --nsis-tag NSIS_TAG Package the snapshot of a given tag in an NSIS; installer (.exe); --dmg-tag DMG_TAG Package the snapshot of a given tag in a DMG package; (.dmg); --with-llvm-url WITH_LLVM_URL; Specify an alternate URL of LLVM repo; --with-clang-url WITH_CLANG_URL; Specify an alternate URL of Clang repo; --with-cling-url WITH_CLING_URL; Specify an alternate URL of Cling repo; --no-test Do not run test suite of Cling; --create-dev-env CREATE_DEV_ENV; Set up a release/debug environment; --with-workdir WITH_WORKDIR; Specify an alternate working directory for CPT; --make-proper MAKE_PROPER; Internal option to support calls from build system. ```; If you want CPT to build a package by detecting your platform automatically,; use the value 'pkg'.; ```sh; ./cpt.py --current-dev=pkg; ```; or; ```sh; ./cpt.py --last-stable=pkg; ```; ### Overriding Default Variables; There are a select number of variables which can be set to make CPT work; differently. This eliminates the need to manually edit the script.; You can overrride variables by using the following syntax:; ```$ ./cpt.py --with-cling-url=""http://github.com/ani07nov/cling"" --current-dev=tar```. List of variables in CPT which can be overridden:; - **CLING_GIT_URL**; * Specify the URL of the Git repository of Cling to be used by CPT; * **Default value:** ""http://root.cern.ch/git/cling.git""; * **Usage:** ```./cpt.py --with-cling-url=""http://github.com/ani07nov/cling"" --last-stable=deb```. - **CLANG_GIT_URL**; * Specify the URL of the Git repository of Clang to be used by CPT; * **Default value:** ""http://root.cern.ch/git/clang.git""; * **Usage:** ```./cpt.py --with-clang-url=""http://github.com/ani07nov/clang"" --last-stable=tar```. - **LLVM_GIT_URL**; * Specify the URL of the Git repository of LLVM to be used by CPT; * **Default value:** ""http://root.cern.ch/git/llvm.git""; * **Usage:** ```./cpt.py --with-llvm",MatchSource.DOCS,interpreter/cling/tools/packaging/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:8408,Modifiability,variab,variables,8408,"given tag in an NSIS; installer (.exe); --dmg-tag DMG_TAG Package the snapshot of a given tag in a DMG package; (.dmg); --with-llvm-url WITH_LLVM_URL; Specify an alternate URL of LLVM repo; --with-clang-url WITH_CLANG_URL; Specify an alternate URL of Clang repo; --with-cling-url WITH_CLING_URL; Specify an alternate URL of Cling repo; --no-test Do not run test suite of Cling; --create-dev-env CREATE_DEV_ENV; Set up a release/debug environment; --with-workdir WITH_WORKDIR; Specify an alternate working directory for CPT; --make-proper MAKE_PROPER; Internal option to support calls from build system. ```; If you want CPT to build a package by detecting your platform automatically,; use the value 'pkg'.; ```sh; ./cpt.py --current-dev=pkg; ```; or; ```sh; ./cpt.py --last-stable=pkg; ```; ### Overriding Default Variables; There are a select number of variables which can be set to make CPT work; differently. This eliminates the need to manually edit the script.; You can overrride variables by using the following syntax:; ```$ ./cpt.py --with-cling-url=""http://github.com/ani07nov/cling"" --current-dev=tar```. List of variables in CPT which can be overridden:; - **CLING_GIT_URL**; * Specify the URL of the Git repository of Cling to be used by CPT; * **Default value:** ""http://root.cern.ch/git/cling.git""; * **Usage:** ```./cpt.py --with-cling-url=""http://github.com/ani07nov/cling"" --last-stable=deb```. - **CLANG_GIT_URL**; * Specify the URL of the Git repository of Clang to be used by CPT; * **Default value:** ""http://root.cern.ch/git/clang.git""; * **Usage:** ```./cpt.py --with-clang-url=""http://github.com/ani07nov/clang"" --last-stable=tar```. - **LLVM_GIT_URL**; * Specify the URL of the Git repository of LLVM to be used by CPT; * **Default value:** ""http://root.cern.ch/git/llvm.git""; * **Usage:** ```./cpt.py --with-llvm-url=""http://github.com/ani07nov/llvm"" --current-dev=tar```. - **workdir**; * Specify the working directory of CPT. All sources will be cloned, built; and instal",MatchSource.DOCS,interpreter/cling/tools/packaging/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:8546,Modifiability,variab,variables,8546,"-url WITH_CLANG_URL; Specify an alternate URL of Clang repo; --with-cling-url WITH_CLING_URL; Specify an alternate URL of Cling repo; --no-test Do not run test suite of Cling; --create-dev-env CREATE_DEV_ENV; Set up a release/debug environment; --with-workdir WITH_WORKDIR; Specify an alternate working directory for CPT; --make-proper MAKE_PROPER; Internal option to support calls from build system. ```; If you want CPT to build a package by detecting your platform automatically,; use the value 'pkg'.; ```sh; ./cpt.py --current-dev=pkg; ```; or; ```sh; ./cpt.py --last-stable=pkg; ```; ### Overriding Default Variables; There are a select number of variables which can be set to make CPT work; differently. This eliminates the need to manually edit the script.; You can overrride variables by using the following syntax:; ```$ ./cpt.py --with-cling-url=""http://github.com/ani07nov/cling"" --current-dev=tar```. List of variables in CPT which can be overridden:; - **CLING_GIT_URL**; * Specify the URL of the Git repository of Cling to be used by CPT; * **Default value:** ""http://root.cern.ch/git/cling.git""; * **Usage:** ```./cpt.py --with-cling-url=""http://github.com/ani07nov/cling"" --last-stable=deb```. - **CLANG_GIT_URL**; * Specify the URL of the Git repository of Clang to be used by CPT; * **Default value:** ""http://root.cern.ch/git/clang.git""; * **Usage:** ```./cpt.py --with-clang-url=""http://github.com/ani07nov/clang"" --last-stable=tar```. - **LLVM_GIT_URL**; * Specify the URL of the Git repository of LLVM to be used by CPT; * **Default value:** ""http://root.cern.ch/git/llvm.git""; * **Usage:** ```./cpt.py --with-llvm-url=""http://github.com/ani07nov/llvm"" --current-dev=tar```. - **workdir**; * Specify the working directory of CPT. All sources will be cloned, built; and installed here. The produced packages will also be found here.; * **Default value:** ""~/ec/build""; * **Usage:** ```./cpt.py --with-workdir=""/ec/build"" --current-dev=deb```. Authors; =======; Cling Packaging To",MatchSource.DOCS,interpreter/cling/tools/packaging/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:1256,Performance,perform,performs,1256," own vendor clones of LLVM and Clang (part of ROOT's trunk); on which it is based. This tool is the easiest way to build Cling for your favorite; platorm and bundle it into an installer. If you want to manually compile Cling; from source, go through the [README] of Cling or the build instructions [here]. [README]:https://github.com/root-project/cling/blob/master/README.md; [here]:https://root.cern/cling/cling_build_instructions/. Below is a list of platforms currently supported by CPT:; * Ubuntu and distros based on Debian - *DEB packages*; * Windows - *NSIS installers*; * Distros based on Red Hat Linux (Fedora/Scientific Linux CERN) - *RPM packages*; * Mac OS X - *Apple Disk Images*; * Virtually any UNIX-like platform which supports Bash - *Tarballs*. ### Requirements; Before using this tool, make sure you have the required packages installed on; your system. Detailed information on what and how to install is provided below,; but the recommended (and much easier) way is to use the following command which; performs the required checks automatically and displays useful suggestions too; specific to your platform.; ```sh; cd tools/packaging/; ./cpt.py --check-requirements; ```; or; ```sh; cd tools/packaging/; ./cpt.py -c; ```; Regardless of the platform and operating system, make sure to call the cpt script; with Python 3.; CPT uses some features and modules which are not a part of older versions of Python.; The same holds true for the versions of GCC/Clang you have on your machine. Older; compilers do not support c++11 features and thus you can expect a build error if you; choose not to update them. All pre-compiled binaries of Python ship with built-in support for SSL. However if; the Python on your system was compiled by you manually, chances are that it doesn't; have SSL support. This is very likely if you had performed a minimal installation; of Scientific Linux CERN which doesn't include OpenSSL development package. In such; a case, you should install ```openssl-",MatchSource.DOCS,interpreter/cling/tools/packaging/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:2077,Performance,perform,performed,2077," information on what and how to install is provided below,; but the recommended (and much easier) way is to use the following command which; performs the required checks automatically and displays useful suggestions too; specific to your platform.; ```sh; cd tools/packaging/; ./cpt.py --check-requirements; ```; or; ```sh; cd tools/packaging/; ./cpt.py -c; ```; Regardless of the platform and operating system, make sure to call the cpt script; with Python 3.; CPT uses some features and modules which are not a part of older versions of Python.; The same holds true for the versions of GCC/Clang you have on your machine. Older; compilers do not support c++11 features and thus you can expect a build error if you; choose not to update them. All pre-compiled binaries of Python ship with built-in support for SSL. However if; the Python on your system was compiled by you manually, chances are that it doesn't; have SSL support. This is very likely if you had performed a minimal installation; of Scientific Linux CERN which doesn't include OpenSSL development package. In such; a case, you should install ```openssl-devel```, re-compile Python and ```configure```; will automatically link against the required libraries and produce a binary with SSL; support. #### Ubuntu/Debian; On Debian, Ubuntu, Linux Mint, CrunchBang, or any other distro based on Debian; which supports APT package manager, you can install all the required packages by:; ```sh; sudo apt-get update; sudo apt-get install git g++ debhelper devscripts gnupg python; ```; You are not required to do this manually since CPT can do this for you automatically. ###### Setting up:; Make sure GnuPG is properly set up with your correct fingerprint. These; credentials are needed to sign the Debian package and create Debian changelogs.; On a build machine (Electric Commander), make sure the fingerprint is of the; user who is supposed to sign the official uploads. You might also want to; configure GnuPG to not ask for the passphrase",MatchSource.DOCS,interpreter/cling/tools/packaging/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:3390,Performance,perform,performed,3390," a binary with SSL; support. #### Ubuntu/Debian; On Debian, Ubuntu, Linux Mint, CrunchBang, or any other distro based on Debian; which supports APT package manager, you can install all the required packages by:; ```sh; sudo apt-get update; sudo apt-get install git g++ debhelper devscripts gnupg python; ```; You are not required to do this manually since CPT can do this for you automatically. ###### Setting up:; Make sure GnuPG is properly set up with your correct fingerprint. These; credentials are needed to sign the Debian package and create Debian changelogs.; On a build machine (Electric Commander), make sure the fingerprint is of the; user who is supposed to sign the official uploads. You might also want to; configure GnuPG to not ask for the passphrase while signing the Debian package. The [Ubuntu Packaging Guide] contains a quick guide on creating a GPG key on an; Ubuntu system. To test if you have successfully set up your GnuPG key, use the following command:; ```sh; gpg --fingerprint; ```; Again, all these checks are performed by default when you launch CPT with ```-c``` option.; [Ubuntu Packaging Guide]:http://packaging.ubuntu.com/html/getting-set-up.html#create-your-gpg-key. #### Windows; CPT is meant to be executed on cmd.exe prompt. Make sure you have set the; environment properly before continuing.; Below is a list of required packages for Windows (Win32-x86):. [MSYS Git] for Windows. [Python] for Windows. Microsoft Visual Studio 11 (2012), with Microsoft Visual C++ 2012. [MSYS Git]:http://msysgit.github.io/; [Python]:https://www.python.org/. ###### Setting Up:; Unlike other UNIX-like platforms, Windows requires you to follow some rules.; Do not ignore this section unless you want CPT to fail mid-way with wierd; errors. You should require these instructions only once. * While installing the packages make sure the executable is in a path that; doesn't contain spaces. For example, you should install Python in a path like. ```sh; C:\Python27; ```; rather t",MatchSource.DOCS,interpreter/cling/tools/packaging/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:5410,Performance,perform,performed,5410,"all the required executables should be present in the Windows; **PATH** environment variable.; * In case of MSYS Git, choose the option ""Run Git from Windows; Command Prompt"" during installation. A good way to check if everything is detected properly by the script is to; run the following command:; ```sh; cd tools/packaging/; ./cpt.py --check-requirements; ```. #### Red Hat Linux (Fedora/Scientific Linux CERN); This section applies to all distros based on Red Hat Linux like Fedora, and; Scientific Linux CERN (SLC). Apparently, you can build RPM packages in any; distro regardless of the package manager it uses. This has been tested on; Fedora, SLC, Ubuntu, and CrunchBang. If you are interested, you can test it; on your favourite platform and email me the results. Depending on the package manager of your distro, you can install the; packages required by CPT to build RPM bundles. For a Red Hat based distro; (which uses ```yum``` package manager), you can use the following command; (also performed automatically by CPT):; ```sh; sudo yum update; sudo yum install git gcc gcc-c++ rpm-build python; ```. #### Mac OS X; Mac OS X provides a sane environement for CPT to build Apple Disk Images; (DMG Installers). On older versions of Mac OS, you need to update XCode to; get the latest version of Clang supporting c++11 features. A great package; manager for Mac OS X is [Macports]. It is recommended that you use the; packages provided by Macports for running CPT (or any other tool if that; is the case) rather than the ones which come pre-installed with Mac OS.; Assuming that you have Macports installed on your Mac, you can use the; following command to install the requisite packages (also done automatically; by CPT):; [Macports]:http://www.macports.org/; ```sh; sudo port -v selfupdate; sudo port install git g++ python; ```. ### Usage; ```sh; cd tools/packaging/; ```. ```; usage: cpt.py [-h] [-c] [--current-dev CURRENT_DEV]; [--last-stable LAST_STABLE] [--tarball-tag TARBALL_TAG]; [",MatchSource.DOCS,interpreter/cling/tools/packaging/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:4644,Safety,detect,detected,4644,"tinuing.; Below is a list of required packages for Windows (Win32-x86):. [MSYS Git] for Windows. [Python] for Windows. Microsoft Visual Studio 11 (2012), with Microsoft Visual C++ 2012. [MSYS Git]:http://msysgit.github.io/; [Python]:https://www.python.org/. ###### Setting Up:; Unlike other UNIX-like platforms, Windows requires you to follow some rules.; Do not ignore this section unless you want CPT to fail mid-way with wierd; errors. You should require these instructions only once. * While installing the packages make sure the executable is in a path that; doesn't contain spaces. For example, you should install Python in a path like. ```sh; C:\Python27; ```; rather than. ```sh; C:\Program Files (x86)\Python 2.7; ```; * Path to all the required executables should be present in the Windows; **PATH** environment variable.; * In case of MSYS Git, choose the option ""Run Git from Windows; Command Prompt"" during installation. A good way to check if everything is detected properly by the script is to; run the following command:; ```sh; cd tools/packaging/; ./cpt.py --check-requirements; ```. #### Red Hat Linux (Fedora/Scientific Linux CERN); This section applies to all distros based on Red Hat Linux like Fedora, and; Scientific Linux CERN (SLC). Apparently, you can build RPM packages in any; distro regardless of the package manager it uses. This has been tested on; Fedora, SLC, Ubuntu, and CrunchBang. If you are interested, you can test it; on your favourite platform and email me the results. Depending on the package manager of your distro, you can install the; packages required by CPT to build RPM bundles. For a Red Hat based distro; (which uses ```yum``` package manager), you can use the following command; (also performed automatically by CPT):; ```sh; sudo yum update; sudo yum install git gcc gcc-c++ rpm-build python; ```. #### Mac OS X; Mac OS X provides a sane environement for CPT to build Apple Disk Images; (DMG Installers). On older versions of Mac OS, you need to u",MatchSource.DOCS,interpreter/cling/tools/packaging/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:8068,Safety,detect,detecting,8068,"; formats: tar | deb | nsis | rpm | dmg | pkg; --tarball-tag TARBALL_TAG; Package the snapshot of a given tag in a tarball; (.tar.bz2); --deb-tag DEB_TAG Package the snapshot of a given tag in a Debian; package (.deb); --rpm-tag RPM_TAG Package the snapshot of a given tag in an RPM package; (.rpm); --nsis-tag NSIS_TAG Package the snapshot of a given tag in an NSIS; installer (.exe); --dmg-tag DMG_TAG Package the snapshot of a given tag in a DMG package; (.dmg); --with-llvm-url WITH_LLVM_URL; Specify an alternate URL of LLVM repo; --with-clang-url WITH_CLANG_URL; Specify an alternate URL of Clang repo; --with-cling-url WITH_CLING_URL; Specify an alternate URL of Cling repo; --no-test Do not run test suite of Cling; --create-dev-env CREATE_DEV_ENV; Set up a release/debug environment; --with-workdir WITH_WORKDIR; Specify an alternate working directory for CPT; --make-proper MAKE_PROPER; Internal option to support calls from build system. ```; If you want CPT to build a package by detecting your platform automatically,; use the value 'pkg'.; ```sh; ./cpt.py --current-dev=pkg; ```; or; ```sh; ./cpt.py --last-stable=pkg; ```; ### Overriding Default Variables; There are a select number of variables which can be set to make CPT work; differently. This eliminates the need to manually edit the script.; You can overrride variables by using the following syntax:; ```$ ./cpt.py --with-cling-url=""http://github.com/ani07nov/cling"" --current-dev=tar```. List of variables in CPT which can be overridden:; - **CLING_GIT_URL**; * Specify the URL of the Git repository of Cling to be used by CPT; * **Default value:** ""http://root.cern.ch/git/cling.git""; * **Usage:** ```./cpt.py --with-cling-url=""http://github.com/ani07nov/cling"" --last-stable=deb```. - **CLANG_GIT_URL**; * Specify the URL of the Git repository of Clang to be used by CPT; * **Default value:** ""http://root.cern.ch/git/clang.git""; * **Usage:** ```./cpt.py --with-clang-url=""http://github.com/ani07nov/clang"" --last-stable=tar",MatchSource.DOCS,interpreter/cling/tools/packaging/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:3250,Testability,test,test,3250," a binary with SSL; support. #### Ubuntu/Debian; On Debian, Ubuntu, Linux Mint, CrunchBang, or any other distro based on Debian; which supports APT package manager, you can install all the required packages by:; ```sh; sudo apt-get update; sudo apt-get install git g++ debhelper devscripts gnupg python; ```; You are not required to do this manually since CPT can do this for you automatically. ###### Setting up:; Make sure GnuPG is properly set up with your correct fingerprint. These; credentials are needed to sign the Debian package and create Debian changelogs.; On a build machine (Electric Commander), make sure the fingerprint is of the; user who is supposed to sign the official uploads. You might also want to; configure GnuPG to not ask for the passphrase while signing the Debian package. The [Ubuntu Packaging Guide] contains a quick guide on creating a GPG key on an; Ubuntu system. To test if you have successfully set up your GnuPG key, use the following command:; ```sh; gpg --fingerprint; ```; Again, all these checks are performed by default when you launch CPT with ```-c``` option.; [Ubuntu Packaging Guide]:http://packaging.ubuntu.com/html/getting-set-up.html#create-your-gpg-key. #### Windows; CPT is meant to be executed on cmd.exe prompt. Make sure you have set the; environment properly before continuing.; Below is a list of required packages for Windows (Win32-x86):. [MSYS Git] for Windows. [Python] for Windows. Microsoft Visual Studio 11 (2012), with Microsoft Visual C++ 2012. [MSYS Git]:http://msysgit.github.io/; [Python]:https://www.python.org/. ###### Setting Up:; Unlike other UNIX-like platforms, Windows requires you to follow some rules.; Do not ignore this section unless you want CPT to fail mid-way with wierd; errors. You should require these instructions only once. * While installing the packages make sure the executable is in a path that; doesn't contain spaces. For example, you should install Python in a path like. ```sh; C:\Python27; ```; rather t",MatchSource.DOCS,interpreter/cling/tools/packaging/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:5043,Testability,test,tested,5043,"ess you want CPT to fail mid-way with wierd; errors. You should require these instructions only once. * While installing the packages make sure the executable is in a path that; doesn't contain spaces. For example, you should install Python in a path like. ```sh; C:\Python27; ```; rather than. ```sh; C:\Program Files (x86)\Python 2.7; ```; * Path to all the required executables should be present in the Windows; **PATH** environment variable.; * In case of MSYS Git, choose the option ""Run Git from Windows; Command Prompt"" during installation. A good way to check if everything is detected properly by the script is to; run the following command:; ```sh; cd tools/packaging/; ./cpt.py --check-requirements; ```. #### Red Hat Linux (Fedora/Scientific Linux CERN); This section applies to all distros based on Red Hat Linux like Fedora, and; Scientific Linux CERN (SLC). Apparently, you can build RPM packages in any; distro regardless of the package manager it uses. This has been tested on; Fedora, SLC, Ubuntu, and CrunchBang. If you are interested, you can test it; on your favourite platform and email me the results. Depending on the package manager of your distro, you can install the; packages required by CPT to build RPM bundles. For a Red Hat based distro; (which uses ```yum``` package manager), you can use the following command; (also performed automatically by CPT):; ```sh; sudo yum update; sudo yum install git gcc gcc-c++ rpm-build python; ```. #### Mac OS X; Mac OS X provides a sane environement for CPT to build Apple Disk Images; (DMG Installers). On older versions of Mac OS, you need to update XCode to; get the latest version of Clang supporting c++11 features. A great package; manager for Mac OS X is [Macports]. It is recommended that you use the; packages provided by Macports for running CPT (or any other tool if that; is the case) rather than the ones which come pre-installed with Mac OS.; Assuming that you have Macports installed on your Mac, you can use the; fol",MatchSource.DOCS,interpreter/cling/tools/packaging/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:5122,Testability,test,test,5122," instructions only once. * While installing the packages make sure the executable is in a path that; doesn't contain spaces. For example, you should install Python in a path like. ```sh; C:\Python27; ```; rather than. ```sh; C:\Program Files (x86)\Python 2.7; ```; * Path to all the required executables should be present in the Windows; **PATH** environment variable.; * In case of MSYS Git, choose the option ""Run Git from Windows; Command Prompt"" during installation. A good way to check if everything is detected properly by the script is to; run the following command:; ```sh; cd tools/packaging/; ./cpt.py --check-requirements; ```. #### Red Hat Linux (Fedora/Scientific Linux CERN); This section applies to all distros based on Red Hat Linux like Fedora, and; Scientific Linux CERN (SLC). Apparently, you can build RPM packages in any; distro regardless of the package manager it uses. This has been tested on; Fedora, SLC, Ubuntu, and CrunchBang. If you are interested, you can test it; on your favourite platform and email me the results. Depending on the package manager of your distro, you can install the; packages required by CPT to build RPM bundles. For a Red Hat based distro; (which uses ```yum``` package manager), you can use the following command; (also performed automatically by CPT):; ```sh; sudo yum update; sudo yum install git gcc gcc-c++ rpm-build python; ```. #### Mac OS X; Mac OS X provides a sane environement for CPT to build Apple Disk Images; (DMG Installers). On older versions of Mac OS, you need to update XCode to; get the latest version of Clang supporting c++11 features. A great package; manager for Mac OS X is [Macports]. It is recommended that you use the; packages provided by Macports for running CPT (or any other tool if that; is the case) rather than the ones which come pre-installed with Mac OS.; Assuming that you have Macports installed on your Mac, you can use the; following command to install the requisite packages (also done automatically; by ",MatchSource.DOCS,interpreter/cling/tools/packaging/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:6602,Testability,test,test,6602,"ild python; ```. #### Mac OS X; Mac OS X provides a sane environement for CPT to build Apple Disk Images; (DMG Installers). On older versions of Mac OS, you need to update XCode to; get the latest version of Clang supporting c++11 features. A great package; manager for Mac OS X is [Macports]. It is recommended that you use the; packages provided by Macports for running CPT (or any other tool if that; is the case) rather than the ones which come pre-installed with Mac OS.; Assuming that you have Macports installed on your Mac, you can use the; following command to install the requisite packages (also done automatically; by CPT):; [Macports]:http://www.macports.org/; ```sh; sudo port -v selfupdate; sudo port install git g++ python; ```. ### Usage; ```sh; cd tools/packaging/; ```. ```; usage: cpt.py [-h] [-c] [--current-dev CURRENT_DEV]; [--last-stable LAST_STABLE] [--tarball-tag TARBALL_TAG]; [--deb-tag DEB_TAG] [--rpm-tag RPM_TAG] [--nsis-tag NSIS_TAG]; [--dmg-tag DMG_TAG] [--with-llvm-url WITH_LLVM_URL]; [--with-clang-url WITH_CLANG_URL]; [--with-cling-url WITH_CLING_URL] [--no-test]; [--create-dev-env CREATE_DEV_ENV] [--with-workdir WITH_WORKDIR]; [--make-proper MAKE_PROPER]. Cling Packaging Tool. optional arguments:; -h, --help show this help message and exit; -c, --check-requirements; Check if packages required by the script are installed; --current-dev CURRENT_DEV; Package the latest development snapshot in one of; these formats: tar | deb | nsis | rpm | dmg | pkg; --last-stable LAST_STABLE; Package the last stable snapshot in one of these; formats: tar | deb | nsis | rpm | dmg | pkg; --tarball-tag TARBALL_TAG; Package the snapshot of a given tag in a tarball; (.tar.bz2); --deb-tag DEB_TAG Package the snapshot of a given tag in a Debian; package (.deb); --rpm-tag RPM_TAG Package the snapshot of a given tag in an RPM package; (.rpm); --nsis-tag NSIS_TAG Package the snapshot of a given tag in an NSIS; installer (.exe); --dmg-tag DMG_TAG Package the snapshot of a g",MatchSource.DOCS,interpreter/cling/tools/packaging/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:7763,Testability,test,test,7763,"and exit; -c, --check-requirements; Check if packages required by the script are installed; --current-dev CURRENT_DEV; Package the latest development snapshot in one of; these formats: tar | deb | nsis | rpm | dmg | pkg; --last-stable LAST_STABLE; Package the last stable snapshot in one of these; formats: tar | deb | nsis | rpm | dmg | pkg; --tarball-tag TARBALL_TAG; Package the snapshot of a given tag in a tarball; (.tar.bz2); --deb-tag DEB_TAG Package the snapshot of a given tag in a Debian; package (.deb); --rpm-tag RPM_TAG Package the snapshot of a given tag in an RPM package; (.rpm); --nsis-tag NSIS_TAG Package the snapshot of a given tag in an NSIS; installer (.exe); --dmg-tag DMG_TAG Package the snapshot of a given tag in a DMG package; (.dmg); --with-llvm-url WITH_LLVM_URL; Specify an alternate URL of LLVM repo; --with-clang-url WITH_CLANG_URL; Specify an alternate URL of Clang repo; --with-cling-url WITH_CLING_URL; Specify an alternate URL of Cling repo; --no-test Do not run test suite of Cling; --create-dev-env CREATE_DEV_ENV; Set up a release/debug environment; --with-workdir WITH_WORKDIR; Specify an alternate working directory for CPT; --make-proper MAKE_PROPER; Internal option to support calls from build system. ```; If you want CPT to build a package by detecting your platform automatically,; use the value 'pkg'.; ```sh; ./cpt.py --current-dev=pkg; ```; or; ```sh; ./cpt.py --last-stable=pkg; ```; ### Overriding Default Variables; There are a select number of variables which can be set to make CPT work; differently. This eliminates the need to manually edit the script.; You can overrride variables by using the following syntax:; ```$ ./cpt.py --with-cling-url=""http://github.com/ani07nov/cling"" --current-dev=tar```. List of variables in CPT which can be overridden:; - **CLING_GIT_URL**; * Specify the URL of the Git repository of Cling to be used by CPT; * **Default value:** ""http://root.cern.ch/git/cling.git""; * **Usage:** ```./cpt.py --with-cling-url=""h",MatchSource.DOCS,interpreter/cling/tools/packaging/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:7779,Testability,test,test,7779,"and exit; -c, --check-requirements; Check if packages required by the script are installed; --current-dev CURRENT_DEV; Package the latest development snapshot in one of; these formats: tar | deb | nsis | rpm | dmg | pkg; --last-stable LAST_STABLE; Package the last stable snapshot in one of these; formats: tar | deb | nsis | rpm | dmg | pkg; --tarball-tag TARBALL_TAG; Package the snapshot of a given tag in a tarball; (.tar.bz2); --deb-tag DEB_TAG Package the snapshot of a given tag in a Debian; package (.deb); --rpm-tag RPM_TAG Package the snapshot of a given tag in an RPM package; (.rpm); --nsis-tag NSIS_TAG Package the snapshot of a given tag in an NSIS; installer (.exe); --dmg-tag DMG_TAG Package the snapshot of a given tag in a DMG package; (.dmg); --with-llvm-url WITH_LLVM_URL; Specify an alternate URL of LLVM repo; --with-clang-url WITH_CLANG_URL; Specify an alternate URL of Clang repo; --with-cling-url WITH_CLING_URL; Specify an alternate URL of Cling repo; --no-test Do not run test suite of Cling; --create-dev-env CREATE_DEV_ENV; Set up a release/debug environment; --with-workdir WITH_WORKDIR; Specify an alternate working directory for CPT; --make-proper MAKE_PROPER; Internal option to support calls from build system. ```; If you want CPT to build a package by detecting your platform automatically,; use the value 'pkg'.; ```sh; ./cpt.py --current-dev=pkg; ```; or; ```sh; ./cpt.py --last-stable=pkg; ```; ### Overriding Default Variables; There are a select number of variables which can be set to make CPT work; differently. This eliminates the need to manually edit the script.; You can overrride variables by using the following syntax:; ```$ ./cpt.py --with-cling-url=""http://github.com/ani07nov/cling"" --current-dev=tar```. List of variables in CPT which can be overridden:; - **CLING_GIT_URL**; * Specify the URL of the Git repository of Cling to be used by CPT; * **Default value:** ""http://root.cern.ch/git/cling.git""; * **Usage:** ```./cpt.py --with-cling-url=""h",MatchSource.DOCS,interpreter/cling/tools/packaging/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:3197,Usability,guid,guide,3197,"case, you should install ```openssl-devel```, re-compile Python and ```configure```; will automatically link against the required libraries and produce a binary with SSL; support. #### Ubuntu/Debian; On Debian, Ubuntu, Linux Mint, CrunchBang, or any other distro based on Debian; which supports APT package manager, you can install all the required packages by:; ```sh; sudo apt-get update; sudo apt-get install git g++ debhelper devscripts gnupg python; ```; You are not required to do this manually since CPT can do this for you automatically. ###### Setting up:; Make sure GnuPG is properly set up with your correct fingerprint. These; credentials are needed to sign the Debian package and create Debian changelogs.; On a build machine (Electric Commander), make sure the fingerprint is of the; user who is supposed to sign the official uploads. You might also want to; configure GnuPG to not ask for the passphrase while signing the Debian package. The [Ubuntu Packaging Guide] contains a quick guide on creating a GPG key on an; Ubuntu system. To test if you have successfully set up your GnuPG key, use the following command:; ```sh; gpg --fingerprint; ```; Again, all these checks are performed by default when you launch CPT with ```-c``` option.; [Ubuntu Packaging Guide]:http://packaging.ubuntu.com/html/getting-set-up.html#create-your-gpg-key. #### Windows; CPT is meant to be executed on cmd.exe prompt. Make sure you have set the; environment properly before continuing.; Below is a list of required packages for Windows (Win32-x86):. [MSYS Git] for Windows. [Python] for Windows. Microsoft Visual Studio 11 (2012), with Microsoft Visual C++ 2012. [MSYS Git]:http://msysgit.github.io/; [Python]:https://www.python.org/. ###### Setting Up:; Unlike other UNIX-like platforms, Windows requires you to follow some rules.; Do not ignore this section unless you want CPT to fail mid-way with wierd; errors. You should require these instructions only once. * While installing the packages make ",MatchSource.DOCS,interpreter/cling/tools/packaging/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:16975,Availability,failure,failure,16975,"lso block the refactoring:. ```c++; Customer* kGlobalCustomer;. void GetCustomer(Customer *c) {; c->name = ...;; c->account_id = ...;; kGlobalCustomer = c;; }; ```. To identify a candidate function for refactoring, we need to do the following:. * Find a function with a non-const pointer or reference parameter. * Find the definition of that function. * Prove that the function completely overwrites the pointee on all paths; before returning. * Prove that the function reads the pointee only after overwriting it. * Prove that the function does not persist the pointer in a data structure; that is live after the function returns. There are also requirements that all usage sites of the candidate function must; satisfy, for example, that function arguments do not alias, that users are not; taking the address of the function, and so on. Let's consider verifying usage; site conditions to be a separate static analysis problem. ### Lattice design. To analyze the function body we can use a lattice which consists of normal; states and failure states. A normal state describes program points where we are; sure that no behaviors that block the refactoring have occurred. Normal states; keep track of all parameter's member fields that are known to be overwritten on; every path from function entry to the corresponding program point. Failure; states accumulate observed violations (unsafe reads and pointer escapes) that; block the refactoring. In the partial order of the lattice failure states compare greater than normal; states, which guarantees that they ""win"" when joined with normal states. Order; between failure states is determined by inclusion relation on the set of; accumulated violations (lattice's `⩽` is `⊆` on the set of violations). Order; between normal states is determined by reversed inclusion relation on the set of; overwritten parameter's member fields (lattice's `⩽` is `⊇` on the set of; overwritten fields). ![Lattice for data flow analysis that identifies output paramete",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:17420,Availability,failure,failure,17420,"e that the function does not persist the pointer in a data structure; that is live after the function returns. There are also requirements that all usage sites of the candidate function must; satisfy, for example, that function arguments do not alias, that users are not; taking the address of the function, and so on. Let's consider verifying usage; site conditions to be a separate static analysis problem. ### Lattice design. To analyze the function body we can use a lattice which consists of normal; states and failure states. A normal state describes program points where we are; sure that no behaviors that block the refactoring have occurred. Normal states; keep track of all parameter's member fields that are known to be overwritten on; every path from function entry to the corresponding program point. Failure; states accumulate observed violations (unsafe reads and pointer escapes) that; block the refactoring. In the partial order of the lattice failure states compare greater than normal; states, which guarantees that they ""win"" when joined with normal states. Order; between failure states is determined by inclusion relation on the set of; accumulated violations (lattice's `⩽` is `⊆` on the set of violations). Order; between normal states is determined by reversed inclusion relation on the set of; overwritten parameter's member fields (lattice's `⩽` is `⊇` on the set of; overwritten fields). ![Lattice for data flow analysis that identifies output parameters](DataFlowAnalysisIntroImages/OutputParameterIdentificationLattice.svg). To determine whether a statement reads or writes a field we can implement; symbolic evaluation of `DeclRefExpr`s, `LValueToRValue` casts, pointer; dereference operator and `MemberExpr`s. ### Using data flow results to identify output parameters. Let's take a look at how we use data flow analysis to identify an output; parameter. The refactoring can be safely done when the data flow algorithm; computes a normal state with all of the fields pro",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:17552,Availability,failure,failure,17552," sites of the candidate function must; satisfy, for example, that function arguments do not alias, that users are not; taking the address of the function, and so on. Let's consider verifying usage; site conditions to be a separate static analysis problem. ### Lattice design. To analyze the function body we can use a lattice which consists of normal; states and failure states. A normal state describes program points where we are; sure that no behaviors that block the refactoring have occurred. Normal states; keep track of all parameter's member fields that are known to be overwritten on; every path from function entry to the corresponding program point. Failure; states accumulate observed violations (unsafe reads and pointer escapes) that; block the refactoring. In the partial order of the lattice failure states compare greater than normal; states, which guarantees that they ""win"" when joined with normal states. Order; between failure states is determined by inclusion relation on the set of; accumulated violations (lattice's `⩽` is `⊆` on the set of violations). Order; between normal states is determined by reversed inclusion relation on the set of; overwritten parameter's member fields (lattice's `⩽` is `⊇` on the set of; overwritten fields). ![Lattice for data flow analysis that identifies output parameters](DataFlowAnalysisIntroImages/OutputParameterIdentificationLattice.svg). To determine whether a statement reads or writes a field we can implement; symbolic evaluation of `DeclRefExpr`s, `LValueToRValue` casts, pointer; dereference operator and `MemberExpr`s. ### Using data flow results to identify output parameters. Let's take a look at how we use data flow analysis to identify an output; parameter. The refactoring can be safely done when the data flow algorithm; computes a normal state with all of the fields proven to be overwritten in the; exit basic block of the function. ```c++; struct Customer {; int account_id;; std::string name;; };. void GetCustomer(Custo",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:19290,Availability,failure,failure,19290," data flow analysis to identify an output; parameter. The refactoring can be safely done when the data flow algorithm; computes a normal state with all of the fields proven to be overwritten in the; exit basic block of the function. ```c++; struct Customer {; int account_id;; std::string name;; };. void GetCustomer(Customer* c) {; // Overwritten: {}; c->account_id = ...; // Overwritten: {c->account_id}; if (...) {; c->name = ...; // Overwritten: {c->account_id, c->name}; } else {; c->name = ...; // Overwritten: {c->account_id, c->name}; }; // Overwritten: {c->account_id, c->name}; }; ```. When the data flow algorithm computes a normal state, but not all fields are; proven to be overwritten we can't perform the refactoring. ```c++; void target(bool b, Customer* c) {; // Overwritten: {}; if (b) {; c->account_id = 42; // Overwritten: {c->account_id}; } else {; c->name = ""Konrad""; // Overwritten: {c->name}; }; // Overwritten: {}; }; ```. Similarly, when the data flow algorithm computes a failure state, we also can't; perform the refactoring. ```c++; Customer* kGlobalCustomer;. void GetCustomer(Customer* c) {; // Overwritten: {}; c->account_id = ...; // Overwritten: {c->account_id}; if (...) {; print(c->name); // Unsafe read; } else {; kGlobalCustomer = c; // Pointer escape; }; // Unsafe read, Pointer escape; }; ```. ## Example: finding dead stores. Let's say we want to find redundant stores, because they indicate potential; bugs. ```c++; x = GetX();; x = GetY();; ```. The first store to `x` is never read, probably there is a bug. The implementation of dead store analysis is very similar to output parameter; analysis: we need to track stores and loads, and find stores that were never; read. [Liveness analysis](https://en.wikipedia.org/wiki/Live_variable_analysis) is a; generalization of this idea, which is often used to answer many related; questions, for example:. * finding dead stores,; * finding uninitialized variables,; * finding a good point to deallocate memory,; *",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:19684,Availability,redundant,redundant,19684,"if (...) {; c->name = ...; // Overwritten: {c->account_id, c->name}; } else {; c->name = ...; // Overwritten: {c->account_id, c->name}; }; // Overwritten: {c->account_id, c->name}; }; ```. When the data flow algorithm computes a normal state, but not all fields are; proven to be overwritten we can't perform the refactoring. ```c++; void target(bool b, Customer* c) {; // Overwritten: {}; if (b) {; c->account_id = 42; // Overwritten: {c->account_id}; } else {; c->name = ""Konrad""; // Overwritten: {c->name}; }; // Overwritten: {}; }; ```. Similarly, when the data flow algorithm computes a failure state, we also can't; perform the refactoring. ```c++; Customer* kGlobalCustomer;. void GetCustomer(Customer* c) {; // Overwritten: {}; c->account_id = ...; // Overwritten: {c->account_id}; if (...) {; print(c->name); // Unsafe read; } else {; kGlobalCustomer = c; // Pointer escape; }; // Unsafe read, Pointer escape; }; ```. ## Example: finding dead stores. Let's say we want to find redundant stores, because they indicate potential; bugs. ```c++; x = GetX();; x = GetY();; ```. The first store to `x` is never read, probably there is a bug. The implementation of dead store analysis is very similar to output parameter; analysis: we need to track stores and loads, and find stores that were never; read. [Liveness analysis](https://en.wikipedia.org/wiki/Live_variable_analysis) is a; generalization of this idea, which is often used to answer many related; questions, for example:. * finding dead stores,; * finding uninitialized variables,; * finding a good point to deallocate memory,; * finding out if it would be safe to move an object. ## Example: definitive initialization. Definitive initialization proves that variables are known to be initialized when; read. If we find a variable which is read when not initialized then we generate; a warning. ```c++; void Init() {; int x; // x is uninitialized; if (cond()) {; x = 10; // x is initialized; } else {; x = 20; // x is initialized; }; prin",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:25825,Availability,redundant,redundant,25825," refuse to refactor code that mixes borrowed pointer values; and unique ownership. In the following code, `GetPtr()` returns a borrowed; pointer, which is assigned to `pi`. Then, `pi` is used to hold a uniquely-owned; pointer. We don't distinguish between these two assignments, and we want each; assignment to be paired with a corresponding sink; otherwise, we transition the; pointer to a `Conflicting` state, like in this example. ```c++; void ConflictingOwnership() {; int *pi; // pi is Compatible; pi = GetPtr(); // pi is Defined; Borrow(pi); // pi is Defined. pi = new int; // pi is Conflicting; Borrow(pi);; delete pi;; // pi is Conflicting; }; ```. We could still handle this case by finding a maximal range in the code where; `pi` could be in the Compatible state, and only refactoring that part. ```c++; void ConflictingOwnership() {; int *pi;; pi = GetPtr();; Borrow(pi);. std::unique_ptr<int> pi_unique = std::make_unique<int>();; Borrow(pi_unique.get());; }; ```. ## Example: finding redundant branch conditions. In the code below `b1` should not be checked in both the outer and inner ""if""; statements. It is likely there is a bug in this code. ```c++; int F(bool b1, bool b2) {; if (b1) {; f();; if (b1 && b2) { // Check `b1` again -- unnecessary!; g();; }; }; }; ```. A checker that finds this pattern syntactically is already implemented in; ClangTidy using AST matchers (`bugprone-redundant-branch-condition`). To implement it using the data flow analysis framework, we can produce a warning; if any part of the branch condition is implied by the flow condition. ```c++; int F(bool b1, bool b2) {; // Flow condition: true.; if (b1) {; // Flow condition: b1.; f();; if (b1 && b2) { // `b1` is implied by the flow condition.; g();; }; }; }; ```. One way to check this implication is to use a SAT solver. Without a SAT solver,; we could keep the flow condition in the CNF form and then it would be easy to; check the implication. ## Example: finding unchecked `std::optional` unwraps. C",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:26227,Availability,redundant,redundant-branch-condition,26227,"se, we transition the; pointer to a `Conflicting` state, like in this example. ```c++; void ConflictingOwnership() {; int *pi; // pi is Compatible; pi = GetPtr(); // pi is Defined; Borrow(pi); // pi is Defined. pi = new int; // pi is Conflicting; Borrow(pi);; delete pi;; // pi is Conflicting; }; ```. We could still handle this case by finding a maximal range in the code where; `pi` could be in the Compatible state, and only refactoring that part. ```c++; void ConflictingOwnership() {; int *pi;; pi = GetPtr();; Borrow(pi);. std::unique_ptr<int> pi_unique = std::make_unique<int>();; Borrow(pi_unique.get());; }; ```. ## Example: finding redundant branch conditions. In the code below `b1` should not be checked in both the outer and inner ""if""; statements. It is likely there is a bug in this code. ```c++; int F(bool b1, bool b2) {; if (b1) {; f();; if (b1 && b2) { // Check `b1` again -- unnecessary!; g();; }; }; }; ```. A checker that finds this pattern syntactically is already implemented in; ClangTidy using AST matchers (`bugprone-redundant-branch-condition`). To implement it using the data flow analysis framework, we can produce a warning; if any part of the branch condition is implied by the flow condition. ```c++; int F(bool b1, bool b2) {; // Flow condition: true.; if (b1) {; // Flow condition: b1.; f();; if (b1 && b2) { // `b1` is implied by the flow condition.; g();; }; }; }; ```. One way to check this implication is to use a SAT solver. Without a SAT solver,; we could keep the flow condition in the CNF form and then it would be easy to; check the implication. ## Example: finding unchecked `std::optional` unwraps. Calling `optional::value()` is only valid if `optional::has_value()` is true. We; want to show that when `x.value()` is executed, the flow condition implies; `x.has_value()`. In the example below `x.value()` is accessed safely because it is guarded by the; `x.has_value()` check. ```c++; void Example(std::optional<int> &x) {; if (x.has_value()) {; use(x.v",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:29043,Availability,avail,available,29043,"de is invisible to the compiler because the flag can be turned on at any; moment. We could make a tool that deletes experiment flags. The user tells us which flag; they want to delete, and we assume that the it's value is a given constant. For example, the user could use the tool to remove `example_flag` from this; code:. ```c++; DEFINE_FLAG(std::string, example_flag, """", ""A sample flag."");. void Example() {; bool x = GetFlag(FLAGS_example_flag).empty();; f();; if (x) {; g();; } else {; h();; }; }; ```. The tool would simplify the code to:. ```c++; void Example() {; f();; g();; }; ```. We can solve this problem with a classic constant propagation lattice combined; with symbolic evaluation. ## Example: finding inefficient usages of associative containers. Real-world code often accidentally performs repeated lookups in associative; containers:. ```c++; map<int, Employee> xs;; xs[42]->name = ""..."";; xs[42]->title = ""..."";; ```. To find the above inefficiency we can use the available expressions analysis to; understand that `m[42]` is evaluated twice. ```c++; map<int, Employee> xs;; Employee &e = xs[42];; e->name = ""..."";; e->title = ""..."";; ```. We can also track the `m.contains()` check in the flow condition to find; redundant checks, like in the example below. ```c++; std::map<int, Employee> xs;; if (!xs.contains(42)) {; xs.insert({42, someEmployee});; }; ```. ## Example: refactoring types that implicitly convert to each other. Refactoring one strong type to another is difficult, but the compiler can help:; once you refactor one reference to the type, the compiler will flag other places; where this information flows with type mismatch errors. Unfortunately this; strategy does not work when you are refactoring types that implicitly convert to; each other, for example, replacing `int32_t` with `int64_t`. Imagine that we want to change user IDs from 32 to 64-bit integers. In other; words, we need to find all integers tainted with user IDs. We can use data flow; analysis ",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:29293,Availability,redundant,redundant,29293,"nstant. For example, the user could use the tool to remove `example_flag` from this; code:. ```c++; DEFINE_FLAG(std::string, example_flag, """", ""A sample flag."");. void Example() {; bool x = GetFlag(FLAGS_example_flag).empty();; f();; if (x) {; g();; } else {; h();; }; }; ```. The tool would simplify the code to:. ```c++; void Example() {; f();; g();; }; ```. We can solve this problem with a classic constant propagation lattice combined; with symbolic evaluation. ## Example: finding inefficient usages of associative containers. Real-world code often accidentally performs repeated lookups in associative; containers:. ```c++; map<int, Employee> xs;; xs[42]->name = ""..."";; xs[42]->title = ""..."";; ```. To find the above inefficiency we can use the available expressions analysis to; understand that `m[42]` is evaluated twice. ```c++; map<int, Employee> xs;; Employee &e = xs[42];; e->name = ""..."";; e->title = ""..."";; ```. We can also track the `m.contains()` check in the flow condition to find; redundant checks, like in the example below. ```c++; std::map<int, Employee> xs;; if (!xs.contains(42)) {; xs.insert({42, someEmployee});; }; ```. ## Example: refactoring types that implicitly convert to each other. Refactoring one strong type to another is difficult, but the compiler can help:; once you refactor one reference to the type, the compiler will flag other places; where this information flows with type mismatch errors. Unfortunately this; strategy does not work when you are refactoring types that implicitly convert to; each other, for example, replacing `int32_t` with `int64_t`. Imagine that we want to change user IDs from 32 to 64-bit integers. In other; words, we need to find all integers tainted with user IDs. We can use data flow; analysis to implement taint analysis. ```c++; void UseUser(int32_t user_id) {; int32_t id = user_id;; // Variable `id` is tainted with a user ID.; ...; }; ```. Taint analysis is very well suited to this problem because the program rarely; br",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:29720,Availability,error,errors,29720,"++; DEFINE_FLAG(std::string, example_flag, """", ""A sample flag."");. void Example() {; bool x = GetFlag(FLAGS_example_flag).empty();; f();; if (x) {; g();; } else {; h();; }; }; ```. The tool would simplify the code to:. ```c++; void Example() {; f();; g();; }; ```. We can solve this problem with a classic constant propagation lattice combined; with symbolic evaluation. ## Example: finding inefficient usages of associative containers. Real-world code often accidentally performs repeated lookups in associative; containers:. ```c++; map<int, Employee> xs;; xs[42]->name = ""..."";; xs[42]->title = ""..."";; ```. To find the above inefficiency we can use the available expressions analysis to; understand that `m[42]` is evaluated twice. ```c++; map<int, Employee> xs;; Employee &e = xs[42];; e->name = ""..."";; e->title = ""..."";; ```. We can also track the `m.contains()` check in the flow condition to find; redundant checks, like in the example below. ```c++; std::map<int, Employee> xs;; if (!xs.contains(42)) {; xs.insert({42, someEmployee});; }; ```. ## Example: refactoring types that implicitly convert to each other. Refactoring one strong type to another is difficult, but the compiler can help:; once you refactor one reference to the type, the compiler will flag other places; where this information flows with type mismatch errors. Unfortunately this; strategy does not work when you are refactoring types that implicitly convert to; each other, for example, replacing `int32_t` with `int64_t`. Imagine that we want to change user IDs from 32 to 64-bit integers. In other; words, we need to find all integers tainted with user IDs. We can use data flow; analysis to implement taint analysis. ```c++; void UseUser(int32_t user_id) {; int32_t id = user_id;; // Variable `id` is tainted with a user ID.; ...; }; ```. Taint analysis is very well suited to this problem because the program rarely; branches on user IDs, and almost certainly does not perform any computation; (like arithmetic).; ",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:22208,Deployability,release,release,22208,"ice element could also capture the source locations of the branches that; lead us to the corresponding program point. Diagnostics would use this; information to show a sample buggy code path to the user. ## Example: refactoring raw pointers to `unique_ptr`. Modern idiomatic C++ uses smart pointers to express memory ownership, however in; pre-C++11 code one can often find raw pointers that own heap memory blocks. Imagine that we would like to refactor raw pointers that own memory to; `unique_ptr`. There are multiple ways to design a data flow analysis for this; problem; let's look at one way to do it. For example, we would like to refactor the following code that uses raw; pointers:. ```c++; void UniqueOwnership1() {; int *pi = new int;; if (...) {; Borrow(pi);; delete pi;; } else {; TakeOwnership(pi);; }; }; ```. into code that uses `unique_ptr`:. ```c++; void UniqueOwnership1() {; auto pi = std::make_unique<int>();; if (...) {; Borrow(pi.get());; } else {; TakeOwnership(pi.release());; }; }; ```. This problem can be solved with a lattice in form of map from value declarations; to pointer states:. ![Lattice that identifies candidates for unique_ptr refactoring](DataFlowAnalysisIntroImages/UniquePtrLattice.svg). We can perform the refactoring if at the exit of a function `pi` is; `Compatible`. ```c++; void UniqueOwnership1() {; int *pi; // pi is Compatible; pi = new int; // pi is Defined; if (...) {; Borrow(pi); // pi is Defined; delete pi; // pi is Compatible; } else {; TakeOwnership(pi); // pi is Compatible; }; // pi is Compatible; }; ```. Let's look at an example where the raw pointer owns two different memory blocks:. ```c++; void UniqueOwnership2() {; int *pi = new int; // pi is Defined; Borrow(pi);; delete pi; // pi is Compatible; if (smth) {; pi = new int; // pi is Defined; Borrow(pi);; delete pi; // pi is Compatible; }; // pi is Compatible; }; ```. It can be refactored to use `unique_ptr` like this:. ```c++; void UniqueOwnership2() {; auto pi = make_unique<int",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:24268,Deployability,release,release,24268," pi = make_unique<int>();; Borrow(pi);; if (smth) {; pi = make_unique<int>();; Borrow(pi);; }; }; ```. In the following example, the raw pointer is used to access the heap object; after the ownership has been transferred. ```c++; void UniqueOwnership3() {; int *pi = new int; // pi is Defined; if (...) {; Borrow(pi);; delete pi; // pi is Compatible; } else {; vector<unique_ptr<int>> v = {std::unique_ptr(pi)}; // pi is Compatible; print(*pi);; use(v);; }; // pi is Compatible; }; ```. We can refactor this code to use `unique_ptr`, however we would have to; introduce a non-owning pointer variable, since we can't use the moved-from; `unique_ptr` to access the object:. ```c++; void UniqueOwnership3() {; std::unique_ptr<int> pi = std::make_unique<int>();; if (...) {; Borrow(pi);; } else {; int *pi_non_owning = pi.get();; vector<unique_ptr<int>> v = {std::move(pi)};; print(*pi_non_owning);; use(v);; }; }; ```. If the original code didn't call `delete` at the very end of the function, then; our refactoring may change the point at which we run the destructor and release; memory. Specifically, if there is some user code after `delete`, then extending; the lifetime of the object until the end of the function may hold locks for; longer than necessary, introduce memory overhead etc. One solution is to always replace `delete` with a call to `reset()`, and then; perform another analysis that removes unnecessary `reset()` calls. ```c++; void AddedMemoryOverhead() {; HugeObject *ho = new HugeObject();; use(ho);; delete ho; // Release the large amount of memory quickly.; LongRunningFunction();; }; ```. This analysis will refuse to refactor code that mixes borrowed pointer values; and unique ownership. In the following code, `GetPtr()` returns a borrowed; pointer, which is assigned to `pi`. Then, `pi` is used to hold a uniquely-owned; pointer. We don't distinguish between these two assignments, and we want each; assignment to be paired with a corresponding sink; otherwise, we transitio",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:27890,Deployability,A/B,A/B,27890,"l::has_value()` is true. We; want to show that when `x.value()` is executed, the flow condition implies; `x.has_value()`. In the example below `x.value()` is accessed safely because it is guarded by the; `x.has_value()` check. ```c++; void Example(std::optional<int> &x) {; if (x.has_value()) {; use(x.value());; }; }; ```. While entering the if branch we deduce that `x.has_value()` is implied by the; flow condition. ```c++; void Example(std::optional<int> x) {; // Flow condition: true.; if (x.has_value()) {; // Flow condition: x.has_value() == true.; use(x.value());; }; // Flow condition: true.; }; ```. We also need to prove that `x` is not modified between check and value access.; The modification of `x` may be very subtle:. ```c++; void F(std::optional<int> &x);. void Example(std::optional<int> &x) {; if (x.has_value()) {; // Flow condition: x.has_value() == true.; unknown_function(x); // may change x.; // Flow condition: true.; use(x.value());; }; }; ```. ## Example: finding dead code behind A/B experiment flags. Finding dead code is a classic application of data flow analysis. Unused flags for A/B experiment hide dead code. However, this flavor of dead; code is invisible to the compiler because the flag can be turned on at any; moment. We could make a tool that deletes experiment flags. The user tells us which flag; they want to delete, and we assume that the it's value is a given constant. For example, the user could use the tool to remove `example_flag` from this; code:. ```c++; DEFINE_FLAG(std::string, example_flag, """", ""A sample flag."");. void Example() {; bool x = GetFlag(FLAGS_example_flag).empty();; f();; if (x) {; g();; } else {; h();; }; }; ```. The tool would simplify the code to:. ```c++; void Example() {; f();; g();; }; ```. We can solve this problem with a classic constant propagation lattice combined; with symbolic evaluation. ## Example: finding inefficient usages of associative containers. Real-world code often accidentally performs repeated lookup",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:27995,Deployability,A/B,A/B,27995,". In the example below `x.value()` is accessed safely because it is guarded by the; `x.has_value()` check. ```c++; void Example(std::optional<int> &x) {; if (x.has_value()) {; use(x.value());; }; }; ```. While entering the if branch we deduce that `x.has_value()` is implied by the; flow condition. ```c++; void Example(std::optional<int> x) {; // Flow condition: true.; if (x.has_value()) {; // Flow condition: x.has_value() == true.; use(x.value());; }; // Flow condition: true.; }; ```. We also need to prove that `x` is not modified between check and value access.; The modification of `x` may be very subtle:. ```c++; void F(std::optional<int> &x);. void Example(std::optional<int> &x) {; if (x.has_value()) {; // Flow condition: x.has_value() == true.; unknown_function(x); // may change x.; // Flow condition: true.; use(x.value());; }; }; ```. ## Example: finding dead code behind A/B experiment flags. Finding dead code is a classic application of data flow analysis. Unused flags for A/B experiment hide dead code. However, this flavor of dead; code is invisible to the compiler because the flag can be turned on at any; moment. We could make a tool that deletes experiment flags. The user tells us which flag; they want to delete, and we assume that the it's value is a given constant. For example, the user could use the tool to remove `example_flag` from this; code:. ```c++; DEFINE_FLAG(std::string, example_flag, """", ""A sample flag."");. void Example() {; bool x = GetFlag(FLAGS_example_flag).empty();; f();; if (x) {; g();; } else {; h();; }; }; ```. The tool would simplify the code to:. ```c++; void Example() {; f();; g();; }; ```. We can solve this problem with a classic constant propagation lattice combined; with symbolic evaluation. ## Example: finding inefficient usages of associative containers. Real-world code often accidentally performs repeated lookups in associative; containers:. ```c++; map<int, Employee> xs;; xs[42]->name = ""..."";; xs[42]->title = ""..."";; ```. To f",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:3740,Energy Efficiency,efficient,efficiently,3740,"hat `x` can only have one value. When control flow from; the ""then"" and ""else"" branches joins, `x` can have either value. Abstract algebra provides a nice formalism that models this kind of structure,; namely, a lattice. A join-semilattice is a partially ordered set, in which every; two elements have a least upper bound (called a *join*). ```; join(a, b) ⩾ a and join(a, b) ⩾ b and join(x, x) = x; ```. For this problem we will use the lattice of subsets of integers, with set; inclusion relation as ordering and set union as a join. Lattices are often represented visually as Hasse diagrams. Here is a Hasse; diagram for our lattice that tracks subsets of integers:. ![Hasse diagram for a lattice of integer sets](DataFlowAnalysisIntroImages/IntegerSetsInfiniteLattice.svg). Computing the join in the lattice corresponds to finding the lowest common; ancestor (LCA) between two nodes in its Hasse diagram. There is a vast amount of; literature on efficiently implementing LCA queries for a DAG, however Efficient; Implementation of Lattice Operations (1989); ([CiteSeerX](https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.106.4911),; [doi](https://doi.org/10.1145%2F59287.59293)) describes a scheme that; particularly well-suited for programmatic implementation. ### Too much information and ""top"" values. Let's try to find the possible sets of values of `x` in a function that modifies; `x` in a loop:. ```c++; void ExampleOfInfiniteSets() {; int x = 0; // x is {0}; while (condition()) {; x += 1; // x is {0; 1; 2; …}; }; print(x); // x is {0; 1; 2; …}; }; ```. We have an issue: `x` can have any value greater than zero; that's an infinite; set of values, if the program operated on mathematical integers. In C++ `int` is; limited by `INT_MAX` so technically we have a set `{0; 1; …; INT_MAX}` which is; still really big. To make our analysis practical to compute, we have to limit the amount of; information that we track. In this case, we can, for example, arbitrarily limit; the size o",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:240,Modifiability,refactor,refactoring,240,"# Data flow analysis: an informal introduction. ## Abstract. This document introduces data flow analysis in an informal way. The goal is to; give the reader an intuitive understanding of how it works, and show how it; applies to a range of refactoring and bug finding problems. Data flow analysis is a well-established technique; it is described in many; papers, books, and videos. If you would like a more formal, or a more thorough; explanation of the concepts mentioned in this document, please refer to the; following resources:. * [The Lattice article in Wikipedia](https://en.wikipedia.org/wiki/Lattice_\(order\)).; * Videos on the PacketPrep YouTube channel that introduce lattices and the; necessary background information:; [#20](https://www.youtube.com/watch?v=73j_FXBXGm8),; [#21](https://www.youtube.com/watch?v=b5sDjo9tfE8),; [#22](https://www.youtube.com/watch?v=saOG7Uooeho),; [#23](https://www.youtube.com/watch?v=3EAYX-wZH0g),; [#24](https://www.youtube.com/watch?v=KRkHwQtW6Cc),; [#25](https://www.youtube.com/watch?v=7Gwzsc4rAgw).; * [Introduction to Dataflow Analysis](https://www.youtube.com/watch?v=OROXJ9-wUQE); * [Introduction to abstract interpretation](http://www.cs.tau.ac.il/~msagiv/courses/asv/absint-1.pdf).; * [Introduction to symbolic execution](https://www.cs.umd.edu/~mwh/se-tutorial/symbolic-exec.pdf).; * [Static Program Analysis by Anders Møller and Michael I. Schwartzbach](https://cs.au.dk/~amoeller/spa/).; * [EXE: automatically generating inputs of death](https://css.csail.mit.edu/6.858/2020/readings/exe.pdf); (a paper that successfully applies symbolic execution to real-world; software). ## Data flow analysis. ### The purpose of data flow analysis. Data flow analysis is a static analysis technique that proves facts about a; program or its fragment. It can make conclusions about all paths through the; program, while taking control flow into account and scaling to large programs.; The basic idea is propagating facts about the program through the edges",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:2247,Modifiability,variab,variable,2247,"sint-1.pdf).; * [Introduction to symbolic execution](https://www.cs.umd.edu/~mwh/se-tutorial/symbolic-exec.pdf).; * [Static Program Analysis by Anders Møller and Michael I. Schwartzbach](https://cs.au.dk/~amoeller/spa/).; * [EXE: automatically generating inputs of death](https://css.csail.mit.edu/6.858/2020/readings/exe.pdf); (a paper that successfully applies symbolic execution to real-world; software). ## Data flow analysis. ### The purpose of data flow analysis. Data flow analysis is a static analysis technique that proves facts about a; program or its fragment. It can make conclusions about all paths through the; program, while taking control flow into account and scaling to large programs.; The basic idea is propagating facts about the program through the edges of the; control flow graph (CFG) until a fixpoint is reached. ### Sample problem and an ad-hoc solution. We would like to explain data flow analysis while discussing an example. Let's; imagine that we want to track possible values of an integer variable in our; program. Here is how a human could annotate the code:. ```c++; void Example(int n) {; int x = 0;; // x is {0}; if (n > 0) {; x = 5;; // x is {5}; } else {; x = 42;; // x is {42}; }; // x is {5; 42}; print(x);; }; ```. We use sets of integers to represent possible values of `x`. Local variables; have unambiguous values between statements, so we annotate program points; between statements with sets of possible values. Here is how we arrived at these annotations. Assigning a constant to `x` allows; us to make a conclusion that `x` can only have one value. When control flow from; the ""then"" and ""else"" branches joins, `x` can have either value. Abstract algebra provides a nice formalism that models this kind of structure,; namely, a lattice. A join-semilattice is a partially ordered set, in which every; two elements have a least upper bound (called a *join*). ```; join(a, b) ⩾ a and join(a, b) ⩾ b and join(x, x) = x; ```. For this problem we will use th",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:2549,Modifiability,variab,variables,2549,"al-world; software). ## Data flow analysis. ### The purpose of data flow analysis. Data flow analysis is a static analysis technique that proves facts about a; program or its fragment. It can make conclusions about all paths through the; program, while taking control flow into account and scaling to large programs.; The basic idea is propagating facts about the program through the edges of the; control flow graph (CFG) until a fixpoint is reached. ### Sample problem and an ad-hoc solution. We would like to explain data flow analysis while discussing an example. Let's; imagine that we want to track possible values of an integer variable in our; program. Here is how a human could annotate the code:. ```c++; void Example(int n) {; int x = 0;; // x is {0}; if (n > 0) {; x = 5;; // x is {5}; } else {; x = 42;; // x is {42}; }; // x is {5; 42}; print(x);; }; ```. We use sets of integers to represent possible values of `x`. Local variables; have unambiguous values between statements, so we annotate program points; between statements with sets of possible values. Here is how we arrived at these annotations. Assigning a constant to `x` allows; us to make a conclusion that `x` can only have one value. When control flow from; the ""then"" and ""else"" branches joins, `x` can have either value. Abstract algebra provides a nice formalism that models this kind of structure,; namely, a lattice. A join-semilattice is a partially ordered set, in which every; two elements have a least upper bound (called a *join*). ```; join(a, b) ⩾ a and join(a, b) ⩾ b and join(x, x) = x; ```. For this problem we will use the lattice of subsets of integers, with set; inclusion relation as ordering and set union as a join. Lattices are often represented visually as Hasse diagrams. Here is a Hasse; diagram for our lattice that tracks subsets of integers:. ![Hasse diagram for a lattice of integer sets](DataFlowAnalysisIntroImages/IntegerSetsInfiniteLattice.svg). Computing the join in the lattice corresponds",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:5750,Modifiability,variab,variables,5750,"ample, arbitrarily limit; the size of sets to 3 elements. If at a certain program point `x` has more than; 3 possible values, we stop tracking specific values at that program point.; Instead, we denote possible values of `x` with the symbol `⊤` (pronounced ""top""; according to a convention in abstract algebra). ```c++; void ExampleOfTopWithALoop() {; int x = 0; // x is {0}; while (condition()) {; x += 1; // x is ⊤; }; print(x); // x is ⊤; }; ```. The statement ""at this program point, `x`'s possible values are `⊤`"" is; understood as ""at this program point `x` can have any value because we have too; much information, or the information is conflicting"". Note that we can get more than 3 possible values even without a loop:. ```c++; void ExampleOfTopWithoutLoops(int n) {; int x = 0; // x is {0}; switch(n) {; case 0: x = 1; break; // x is {1}; case 1: x = 9; break; // x is {9}; case 2: x = 7; break; // x is {7}; default: x = 3; break; // x is {3}; }; // x is ⊤; }; ```. ### Uninitialized variables and ""bottom"" values. When `x` is declared but not initialized, it has no possible values. We; represent this fact symbolically as `⊥` (pronounced ""bottom""). ```c++; void ExampleOfBottom() {; int x; // x is ⊥; x = 42; // x is {42}; print(x);; }; ```. Note that using values read from uninitialized variables is undefined behaviour; in C++. Generally, compilers and static analysis tools can assume undefined; behavior does not happen. We must model uninitialized variables only when we are; implementing a checker that specifically is trying to find uninitialized reads.; In this example we show how to model uninitialized variables only to demonstrate; the concept of ""bottom"", and how it applies to possible value analysis. We; describe an analysis that finds uninitialized reads in a section below. ### A practical lattice that tracks sets of concrete values. Taking into account all corner cases covered above, we can put together a; lattice that we can use in practice to track possible value",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:6057,Modifiability,variab,variables,6057,"act algebra). ```c++; void ExampleOfTopWithALoop() {; int x = 0; // x is {0}; while (condition()) {; x += 1; // x is ⊤; }; print(x); // x is ⊤; }; ```. The statement ""at this program point, `x`'s possible values are `⊤`"" is; understood as ""at this program point `x` can have any value because we have too; much information, or the information is conflicting"". Note that we can get more than 3 possible values even without a loop:. ```c++; void ExampleOfTopWithoutLoops(int n) {; int x = 0; // x is {0}; switch(n) {; case 0: x = 1; break; // x is {1}; case 1: x = 9; break; // x is {9}; case 2: x = 7; break; // x is {7}; default: x = 3; break; // x is {3}; }; // x is ⊤; }; ```. ### Uninitialized variables and ""bottom"" values. When `x` is declared but not initialized, it has no possible values. We; represent this fact symbolically as `⊥` (pronounced ""bottom""). ```c++; void ExampleOfBottom() {; int x; // x is ⊥; x = 42; // x is {42}; print(x);; }; ```. Note that using values read from uninitialized variables is undefined behaviour; in C++. Generally, compilers and static analysis tools can assume undefined; behavior does not happen. We must model uninitialized variables only when we are; implementing a checker that specifically is trying to find uninitialized reads.; In this example we show how to model uninitialized variables only to demonstrate; the concept of ""bottom"", and how it applies to possible value analysis. We; describe an analysis that finds uninitialized reads in a section below. ### A practical lattice that tracks sets of concrete values. Taking into account all corner cases covered above, we can put together a; lattice that we can use in practice to track possible values of integer; variables. This lattice represents sets of integers with 1, 2, or 3 elements, as; well as top and bottom. Here is a Hasse diagram for it:. ![Hasse diagram for a lattice of integer sets](DataFlowAnalysisIntroImages/IntegerSetsFiniteLattice.svg). ### Formalization. Let's consider a sli",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:6222,Modifiability,variab,variables,6222,"ues are `⊤`"" is; understood as ""at this program point `x` can have any value because we have too; much information, or the information is conflicting"". Note that we can get more than 3 possible values even without a loop:. ```c++; void ExampleOfTopWithoutLoops(int n) {; int x = 0; // x is {0}; switch(n) {; case 0: x = 1; break; // x is {1}; case 1: x = 9; break; // x is {9}; case 2: x = 7; break; // x is {7}; default: x = 3; break; // x is {3}; }; // x is ⊤; }; ```. ### Uninitialized variables and ""bottom"" values. When `x` is declared but not initialized, it has no possible values. We; represent this fact symbolically as `⊥` (pronounced ""bottom""). ```c++; void ExampleOfBottom() {; int x; // x is ⊥; x = 42; // x is {42}; print(x);; }; ```. Note that using values read from uninitialized variables is undefined behaviour; in C++. Generally, compilers and static analysis tools can assume undefined; behavior does not happen. We must model uninitialized variables only when we are; implementing a checker that specifically is trying to find uninitialized reads.; In this example we show how to model uninitialized variables only to demonstrate; the concept of ""bottom"", and how it applies to possible value analysis. We; describe an analysis that finds uninitialized reads in a section below. ### A practical lattice that tracks sets of concrete values. Taking into account all corner cases covered above, we can put together a; lattice that we can use in practice to track possible values of integer; variables. This lattice represents sets of integers with 1, 2, or 3 elements, as; well as top and bottom. Here is a Hasse diagram for it:. ![Hasse diagram for a lattice of integer sets](DataFlowAnalysisIntroImages/IntegerSetsFiniteLattice.svg). ### Formalization. Let's consider a slightly more complex example, and think about how we can; compute the sets of possible values algorithmically. ```c++; void Example(int n) {; int x; // x is ⊥; if (n > 0) {; if (n == 42) {; x = 44; // x is {44",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:6382,Modifiability,variab,variables,6382,"ting"". Note that we can get more than 3 possible values even without a loop:. ```c++; void ExampleOfTopWithoutLoops(int n) {; int x = 0; // x is {0}; switch(n) {; case 0: x = 1; break; // x is {1}; case 1: x = 9; break; // x is {9}; case 2: x = 7; break; // x is {7}; default: x = 3; break; // x is {3}; }; // x is ⊤; }; ```. ### Uninitialized variables and ""bottom"" values. When `x` is declared but not initialized, it has no possible values. We; represent this fact symbolically as `⊥` (pronounced ""bottom""). ```c++; void ExampleOfBottom() {; int x; // x is ⊥; x = 42; // x is {42}; print(x);; }; ```. Note that using values read from uninitialized variables is undefined behaviour; in C++. Generally, compilers and static analysis tools can assume undefined; behavior does not happen. We must model uninitialized variables only when we are; implementing a checker that specifically is trying to find uninitialized reads.; In this example we show how to model uninitialized variables only to demonstrate; the concept of ""bottom"", and how it applies to possible value analysis. We; describe an analysis that finds uninitialized reads in a section below. ### A practical lattice that tracks sets of concrete values. Taking into account all corner cases covered above, we can put together a; lattice that we can use in practice to track possible values of integer; variables. This lattice represents sets of integers with 1, 2, or 3 elements, as; well as top and bottom. Here is a Hasse diagram for it:. ![Hasse diagram for a lattice of integer sets](DataFlowAnalysisIntroImages/IntegerSetsFiniteLattice.svg). ### Formalization. Let's consider a slightly more complex example, and think about how we can; compute the sets of possible values algorithmically. ```c++; void Example(int n) {; int x; // x is ⊥; if (n > 0) {; if (n == 42) {; x = 44; // x is {44}; } else {; x = 5; // x is {5}; }; print(x); // x is {44; 5}; } else {; x = n; // x is ⊤; }; print(x); // x is ⊤; }; ```. As humans, we understan",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:6770,Modifiability,variab,variables,6770,"x is {3}; }; // x is ⊤; }; ```. ### Uninitialized variables and ""bottom"" values. When `x` is declared but not initialized, it has no possible values. We; represent this fact symbolically as `⊥` (pronounced ""bottom""). ```c++; void ExampleOfBottom() {; int x; // x is ⊥; x = 42; // x is {42}; print(x);; }; ```. Note that using values read from uninitialized variables is undefined behaviour; in C++. Generally, compilers and static analysis tools can assume undefined; behavior does not happen. We must model uninitialized variables only when we are; implementing a checker that specifically is trying to find uninitialized reads.; In this example we show how to model uninitialized variables only to demonstrate; the concept of ""bottom"", and how it applies to possible value analysis. We; describe an analysis that finds uninitialized reads in a section below. ### A practical lattice that tracks sets of concrete values. Taking into account all corner cases covered above, we can put together a; lattice that we can use in practice to track possible values of integer; variables. This lattice represents sets of integers with 1, 2, or 3 elements, as; well as top and bottom. Here is a Hasse diagram for it:. ![Hasse diagram for a lattice of integer sets](DataFlowAnalysisIntroImages/IntegerSetsFiniteLattice.svg). ### Formalization. Let's consider a slightly more complex example, and think about how we can; compute the sets of possible values algorithmically. ```c++; void Example(int n) {; int x; // x is ⊥; if (n > 0) {; if (n == 42) {; x = 44; // x is {44}; } else {; x = 5; // x is {5}; }; print(x); // x is {44; 5}; } else {; x = n; // x is ⊤; }; print(x); // x is ⊤; }; ```. As humans, we understand the control flow from the program text. We used our; understanding of control flow to find program points where two flows join.; Formally, control flow is represented by a CFG (control flow graph):. ![CFG for the code above](DataFlowAnalysisIntroImages/CFGExample.svg). We can compute sets of",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:11179,Modifiability,variab,variable,11179,"e; keep propagating information through the CFG until the computed sets of values; stop changing. If the lattice has a finite height and transfer functions are monotonic the; algorithm is guaranteed to terminate. Each iteration of the algorithm can; change computed values only to larger values from the lattice. In the worst; case, all computed values become `⊤`, which is not very useful, but at least the; analysis terminates at that point, because it can't change any of the values. Fixpoint iteration can be optimised by only reprocessing basic blocks which had; one of their inputs changed on the previous iteration. This is typically; implemented using a worklist queue. With this optimisation the time complexity; becomes `O(m * |L|)`, where `m` is the number of basic blocks in the CFG and; `|L|` is the size of lattice used by the analysis. ## Symbolic execution: a very short informal introduction. ### Symbolic values. In the previous example where we tried to figure out what values a variable can; have, the analysis had to be seeded with a concrete value. What if there are no; assignments of concrete values in the program? We can still deduce some; interesting information by representing unknown input values symbolically, and; computing results as symbolic expressions:. ```c++; void PrintAbs(int x) {; int result;; if (x >= 0) {; result = x; // result is {x}; } else {; result = -x; // result is {-x}; }; print(result); // result is {x; -x}; }; ```. We can't say what specific value gets printed, but we know that it is either `x`; or `-x`. Dataflow analysis is an instance of abstract interpretation, and does not dictate; how exactly the lattice and transfer functions should be designed, beyond the; necessary conditions for the analysis to converge. Nevertheless, we can use; symbolic execution ideas to guide our design of the lattice and transfer; functions: lattice values can be symbolic expressions, and transfer functions; can construct more complex symbolic expressions",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:12950,Modifiability,enhance,enhance,12950,"o guide our design of the lattice and transfer; functions: lattice values can be symbolic expressions, and transfer functions; can construct more complex symbolic expressions from symbolic expressions that; represent arguments. See [this StackOverflow; discussion](https://cstheory.stackexchange.com/questions/19708/symbolic-execution-is-a-case-of-abstract-interpretation); for a further comparison of abstract interpretation and symbolic execution. ### Flow condition. A human can say about the previous example that the function returns `x` when; `x >= 0`, and `-x` when `x < 0`. We can make this conclusion programmatically by; tracking a flow condition. A flow condition is a predicate written in terms of; the program state that is true at a specific program point regardless of the; execution path that led to this statement. For example, the flow condition for; the program point right before evaluating `result = x` is `x >= 0`. If we enhance the lattice to be a set of pairs of values and predicates, the; dataflow analysis computes the following values:. ```c++; void PrintAbs(int x) {; int result;; if (x >= 0) {; // Flow condition: x >= 0.; result = x; // result is {x if x >= 0}; } else {; // Flow condition: x < 0.; result = -x; // result is {-x if x < 0}; }; print(result); // result is {x if x >= 0; -x if x < 0}; }; ```. Of course, in a program with loops, symbolic expressions for flow conditions can; grow unbounded. A practical static analysis system must control this growth to; keep the symbolic representations manageable and ensure that the data flow; analysis terminates. For example, it can use a constraint solver to prune; impossible flow conditions, and/or it can abstract them, losing precision, after; their symbolic representations grow beyond some threshold. This is similar to; how we had to limit the sizes of computed sets of possible values to 3 elements. ### Symbolic pointers. This approach proves to be particularly useful for modeling pointer values,; since w",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:14856,Modifiability,refactor,refactor,14856,"ble values to 3 elements. ### Symbolic pointers. This approach proves to be particularly useful for modeling pointer values,; since we don't care about specific addresses but just want to give a unique; identifier to a memory location. ```c++; void ExampleOfSymbolicPointers(bool b) {; int x = 0; // x is {0}; int* ptr = &x; // x is {0} ptr is {&x}; if (b) {; *ptr = 42; // x is {42} ptr is {&x}; }; print(x); // x is {0; 42} ptr is {&x}; }; ```. ## Example: finding output parameters. Let's explore how data flow analysis can help with a problem that is hard to; solve with other tools in Clang. ### Problem description. Output parameters are function parameters of pointer or reference type whose; pointee is completely overwritten by the function, and not read before it is; overwritten. They are common in pre-C++11 code due to the absence of move; semantics. In modern C++ output parameters are non-idiomatic, and return values; are used instead. Imagine that we would like to refactor output parameters to return values to; modernize old code. The first step is to identify refactoring candidates through; static analysis. For example, in the following code snippet the pointer `c` is an output; parameter:. ```c++; struct Customer {; int account_id;; std::string name;; }. void GetCustomer(Customer *c) {; c->account_id = ...;; if (...) {; c->name = ...;; } else {; c->name = ...;; }; }; ```. We would like to refactor this code into:. ```c++; Customer GetCustomer() {; Customer c;; c.account_id = ...;; if (...) {; c.name = ...;; } else {; c.name = ...;; }; return c;; }; ```. However, in the function below the parameter `c` is not an output parameter; because its field `name` is not overwritten on every path through the function. ```c++; void GetCustomer(Customer *c) {; c->account_id = ...;; if (...) {; c->name = ...;; }; }; ```. The code also cannot read the value of the parameter before overwriting it:. ```c++; void GetCustomer(Customer *c) {; use(c->account_id);; c->name = ...;; c",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:14954,Modifiability,refactor,refactoring,14954," useful for modeling pointer values,; since we don't care about specific addresses but just want to give a unique; identifier to a memory location. ```c++; void ExampleOfSymbolicPointers(bool b) {; int x = 0; // x is {0}; int* ptr = &x; // x is {0} ptr is {&x}; if (b) {; *ptr = 42; // x is {42} ptr is {&x}; }; print(x); // x is {0; 42} ptr is {&x}; }; ```. ## Example: finding output parameters. Let's explore how data flow analysis can help with a problem that is hard to; solve with other tools in Clang. ### Problem description. Output parameters are function parameters of pointer or reference type whose; pointee is completely overwritten by the function, and not read before it is; overwritten. They are common in pre-C++11 code due to the absence of move; semantics. In modern C++ output parameters are non-idiomatic, and return values; are used instead. Imagine that we would like to refactor output parameters to return values to; modernize old code. The first step is to identify refactoring candidates through; static analysis. For example, in the following code snippet the pointer `c` is an output; parameter:. ```c++; struct Customer {; int account_id;; std::string name;; }. void GetCustomer(Customer *c) {; c->account_id = ...;; if (...) {; c->name = ...;; } else {; c->name = ...;; }; }; ```. We would like to refactor this code into:. ```c++; Customer GetCustomer() {; Customer c;; c.account_id = ...;; if (...) {; c.name = ...;; } else {; c.name = ...;; }; return c;; }; ```. However, in the function below the parameter `c` is not an output parameter; because its field `name` is not overwritten on every path through the function. ```c++; void GetCustomer(Customer *c) {; c->account_id = ...;; if (...) {; c->name = ...;; }; }; ```. The code also cannot read the value of the parameter before overwriting it:. ```c++; void GetCustomer(Customer *c) {; use(c->account_id);; c->name = ...;; c->account_id = ...;; }; ```. Functions that escape the pointer also block the refactoring",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:15291,Modifiability,refactor,refactor,15291,"; 42} ptr is {&x}; }; ```. ## Example: finding output parameters. Let's explore how data flow analysis can help with a problem that is hard to; solve with other tools in Clang. ### Problem description. Output parameters are function parameters of pointer or reference type whose; pointee is completely overwritten by the function, and not read before it is; overwritten. They are common in pre-C++11 code due to the absence of move; semantics. In modern C++ output parameters are non-idiomatic, and return values; are used instead. Imagine that we would like to refactor output parameters to return values to; modernize old code. The first step is to identify refactoring candidates through; static analysis. For example, in the following code snippet the pointer `c` is an output; parameter:. ```c++; struct Customer {; int account_id;; std::string name;; }. void GetCustomer(Customer *c) {; c->account_id = ...;; if (...) {; c->name = ...;; } else {; c->name = ...;; }; }; ```. We would like to refactor this code into:. ```c++; Customer GetCustomer() {; Customer c;; c.account_id = ...;; if (...) {; c.name = ...;; } else {; c.name = ...;; }; return c;; }; ```. However, in the function below the parameter `c` is not an output parameter; because its field `name` is not overwritten on every path through the function. ```c++; void GetCustomer(Customer *c) {; c->account_id = ...;; if (...) {; c->name = ...;; }; }; ```. The code also cannot read the value of the parameter before overwriting it:. ```c++; void GetCustomer(Customer *c) {; use(c->account_id);; c->name = ...;; c->account_id = ...;; }; ```. Functions that escape the pointer also block the refactoring:. ```c++; Customer* kGlobalCustomer;. void GetCustomer(Customer *c) {; c->name = ...;; c->account_id = ...;; kGlobalCustomer = c;; }; ```. To identify a candidate function for refactoring, we need to do the following:. * Find a function with a non-const pointer or reference parameter. * Find the definition of that function. * Pro",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:15952,Modifiability,refactor,refactoring,15952," step is to identify refactoring candidates through; static analysis. For example, in the following code snippet the pointer `c` is an output; parameter:. ```c++; struct Customer {; int account_id;; std::string name;; }. void GetCustomer(Customer *c) {; c->account_id = ...;; if (...) {; c->name = ...;; } else {; c->name = ...;; }; }; ```. We would like to refactor this code into:. ```c++; Customer GetCustomer() {; Customer c;; c.account_id = ...;; if (...) {; c.name = ...;; } else {; c.name = ...;; }; return c;; }; ```. However, in the function below the parameter `c` is not an output parameter; because its field `name` is not overwritten on every path through the function. ```c++; void GetCustomer(Customer *c) {; c->account_id = ...;; if (...) {; c->name = ...;; }; }; ```. The code also cannot read the value of the parameter before overwriting it:. ```c++; void GetCustomer(Customer *c) {; use(c->account_id);; c->name = ...;; c->account_id = ...;; }; ```. Functions that escape the pointer also block the refactoring:. ```c++; Customer* kGlobalCustomer;. void GetCustomer(Customer *c) {; c->name = ...;; c->account_id = ...;; kGlobalCustomer = c;; }; ```. To identify a candidate function for refactoring, we need to do the following:. * Find a function with a non-const pointer or reference parameter. * Find the definition of that function. * Prove that the function completely overwrites the pointee on all paths; before returning. * Prove that the function reads the pointee only after overwriting it. * Prove that the function does not persist the pointer in a data structure; that is live after the function returns. There are also requirements that all usage sites of the candidate function must; satisfy, for example, that function arguments do not alias, that users are not; taking the address of the function, and so on. Let's consider verifying usage; site conditions to be a separate static analysis problem. ### Lattice design. To analyze the function body we can use a latt",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:16140,Modifiability,refactor,refactoring,16140,"g name;; }. void GetCustomer(Customer *c) {; c->account_id = ...;; if (...) {; c->name = ...;; } else {; c->name = ...;; }; }; ```. We would like to refactor this code into:. ```c++; Customer GetCustomer() {; Customer c;; c.account_id = ...;; if (...) {; c.name = ...;; } else {; c.name = ...;; }; return c;; }; ```. However, in the function below the parameter `c` is not an output parameter; because its field `name` is not overwritten on every path through the function. ```c++; void GetCustomer(Customer *c) {; c->account_id = ...;; if (...) {; c->name = ...;; }; }; ```. The code also cannot read the value of the parameter before overwriting it:. ```c++; void GetCustomer(Customer *c) {; use(c->account_id);; c->name = ...;; c->account_id = ...;; }; ```. Functions that escape the pointer also block the refactoring:. ```c++; Customer* kGlobalCustomer;. void GetCustomer(Customer *c) {; c->name = ...;; c->account_id = ...;; kGlobalCustomer = c;; }; ```. To identify a candidate function for refactoring, we need to do the following:. * Find a function with a non-const pointer or reference parameter. * Find the definition of that function. * Prove that the function completely overwrites the pointee on all paths; before returning. * Prove that the function reads the pointee only after overwriting it. * Prove that the function does not persist the pointer in a data structure; that is live after the function returns. There are also requirements that all usage sites of the candidate function must; satisfy, for example, that function arguments do not alias, that users are not; taking the address of the function, and so on. Let's consider verifying usage; site conditions to be a separate static analysis problem. ### Lattice design. To analyze the function body we can use a lattice which consists of normal; states and failure states. A normal state describes program points where we are; sure that no behaviors that block the refactoring have occurred. Normal states; keep track of all",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:17083,Modifiability,refactor,refactoring,17083,"; c->account_id = ...;; kGlobalCustomer = c;; }; ```. To identify a candidate function for refactoring, we need to do the following:. * Find a function with a non-const pointer or reference parameter. * Find the definition of that function. * Prove that the function completely overwrites the pointee on all paths; before returning. * Prove that the function reads the pointee only after overwriting it. * Prove that the function does not persist the pointer in a data structure; that is live after the function returns. There are also requirements that all usage sites of the candidate function must; satisfy, for example, that function arguments do not alias, that users are not; taking the address of the function, and so on. Let's consider verifying usage; site conditions to be a separate static analysis problem. ### Lattice design. To analyze the function body we can use a lattice which consists of normal; states and failure states. A normal state describes program points where we are; sure that no behaviors that block the refactoring have occurred. Normal states; keep track of all parameter's member fields that are known to be overwritten on; every path from function entry to the corresponding program point. Failure; states accumulate observed violations (unsafe reads and pointer escapes) that; block the refactoring. In the partial order of the lattice failure states compare greater than normal; states, which guarantees that they ""win"" when joined with normal states. Order; between failure states is determined by inclusion relation on the set of; accumulated violations (lattice's `⩽` is `⊆` on the set of violations). Order; between normal states is determined by reversed inclusion relation on the set of; overwritten parameter's member fields (lattice's `⩽` is `⊇` on the set of; overwritten fields). ![Lattice for data flow analysis that identifies output parameters](DataFlowAnalysisIntroImages/OutputParameterIdentificationLattice.svg). To determine whether a statement rea",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:17371,Modifiability,refactor,refactoring,17371,"overwrites the pointee on all paths; before returning. * Prove that the function reads the pointee only after overwriting it. * Prove that the function does not persist the pointer in a data structure; that is live after the function returns. There are also requirements that all usage sites of the candidate function must; satisfy, for example, that function arguments do not alias, that users are not; taking the address of the function, and so on. Let's consider verifying usage; site conditions to be a separate static analysis problem. ### Lattice design. To analyze the function body we can use a lattice which consists of normal; states and failure states. A normal state describes program points where we are; sure that no behaviors that block the refactoring have occurred. Normal states; keep track of all parameter's member fields that are known to be overwritten on; every path from function entry to the corresponding program point. Failure; states accumulate observed violations (unsafe reads and pointer escapes) that; block the refactoring. In the partial order of the lattice failure states compare greater than normal; states, which guarantees that they ""win"" when joined with normal states. Order; between failure states is determined by inclusion relation on the set of; accumulated violations (lattice's `⩽` is `⊆` on the set of violations). Order; between normal states is determined by reversed inclusion relation on the set of; overwritten parameter's member fields (lattice's `⩽` is `⊇` on the set of; overwritten fields). ![Lattice for data flow analysis that identifies output parameters](DataFlowAnalysisIntroImages/OutputParameterIdentificationLattice.svg). To determine whether a statement reads or writes a field we can implement; symbolic evaluation of `DeclRefExpr`s, `LValueToRValue` casts, pointer; dereference operator and `MemberExpr`s. ### Using data flow results to identify output parameters. Let's take a look at how we use data flow analysis to identify an ou",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:18349,Modifiability,refactor,refactoring,18349,"s compare greater than normal; states, which guarantees that they ""win"" when joined with normal states. Order; between failure states is determined by inclusion relation on the set of; accumulated violations (lattice's `⩽` is `⊆` on the set of violations). Order; between normal states is determined by reversed inclusion relation on the set of; overwritten parameter's member fields (lattice's `⩽` is `⊇` on the set of; overwritten fields). ![Lattice for data flow analysis that identifies output parameters](DataFlowAnalysisIntroImages/OutputParameterIdentificationLattice.svg). To determine whether a statement reads or writes a field we can implement; symbolic evaluation of `DeclRefExpr`s, `LValueToRValue` casts, pointer; dereference operator and `MemberExpr`s. ### Using data flow results to identify output parameters. Let's take a look at how we use data flow analysis to identify an output; parameter. The refactoring can be safely done when the data flow algorithm; computes a normal state with all of the fields proven to be overwritten in the; exit basic block of the function. ```c++; struct Customer {; int account_id;; std::string name;; };. void GetCustomer(Customer* c) {; // Overwritten: {}; c->account_id = ...; // Overwritten: {c->account_id}; if (...) {; c->name = ...; // Overwritten: {c->account_id, c->name}; } else {; c->name = ...; // Overwritten: {c->account_id, c->name}; }; // Overwritten: {c->account_id, c->name}; }; ```. When the data flow algorithm computes a normal state, but not all fields are; proven to be overwritten we can't perform the refactoring. ```c++; void target(bool b, Customer* c) {; // Overwritten: {}; if (b) {; c->account_id = 42; // Overwritten: {c->account_id}; } else {; c->name = ""Konrad""; // Overwritten: {c->name}; }; // Overwritten: {}; }; ```. Similarly, when the data flow algorithm computes a failure state, we also can't; perform the refactoring. ```c++; Customer* kGlobalCustomer;. void GetCustomer(Customer* c) {; // Overwritten: {}; ",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:19011,Modifiability,refactor,refactoring,19011,"lysisIntroImages/OutputParameterIdentificationLattice.svg). To determine whether a statement reads or writes a field we can implement; symbolic evaluation of `DeclRefExpr`s, `LValueToRValue` casts, pointer; dereference operator and `MemberExpr`s. ### Using data flow results to identify output parameters. Let's take a look at how we use data flow analysis to identify an output; parameter. The refactoring can be safely done when the data flow algorithm; computes a normal state with all of the fields proven to be overwritten in the; exit basic block of the function. ```c++; struct Customer {; int account_id;; std::string name;; };. void GetCustomer(Customer* c) {; // Overwritten: {}; c->account_id = ...; // Overwritten: {c->account_id}; if (...) {; c->name = ...; // Overwritten: {c->account_id, c->name}; } else {; c->name = ...; // Overwritten: {c->account_id, c->name}; }; // Overwritten: {c->account_id, c->name}; }; ```. When the data flow algorithm computes a normal state, but not all fields are; proven to be overwritten we can't perform the refactoring. ```c++; void target(bool b, Customer* c) {; // Overwritten: {}; if (b) {; c->account_id = 42; // Overwritten: {c->account_id}; } else {; c->name = ""Konrad""; // Overwritten: {c->name}; }; // Overwritten: {}; }; ```. Similarly, when the data flow algorithm computes a failure state, we also can't; perform the refactoring. ```c++; Customer* kGlobalCustomer;. void GetCustomer(Customer* c) {; // Overwritten: {}; c->account_id = ...; // Overwritten: {c->account_id}; if (...) {; print(c->name); // Unsafe read; } else {; kGlobalCustomer = c; // Pointer escape; }; // Unsafe read, Pointer escape; }; ```. ## Example: finding dead stores. Let's say we want to find redundant stores, because they indicate potential; bugs. ```c++; x = GetX();; x = GetY();; ```. The first store to `x` is never read, probably there is a bug. The implementation of dead store analysis is very similar to output parameter; analysis: we need to track stores",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:19332,Modifiability,refactor,refactoring,19332," data flow analysis to identify an output; parameter. The refactoring can be safely done when the data flow algorithm; computes a normal state with all of the fields proven to be overwritten in the; exit basic block of the function. ```c++; struct Customer {; int account_id;; std::string name;; };. void GetCustomer(Customer* c) {; // Overwritten: {}; c->account_id = ...; // Overwritten: {c->account_id}; if (...) {; c->name = ...; // Overwritten: {c->account_id, c->name}; } else {; c->name = ...; // Overwritten: {c->account_id, c->name}; }; // Overwritten: {c->account_id, c->name}; }; ```. When the data flow algorithm computes a normal state, but not all fields are; proven to be overwritten we can't perform the refactoring. ```c++; void target(bool b, Customer* c) {; // Overwritten: {}; if (b) {; c->account_id = 42; // Overwritten: {c->account_id}; } else {; c->name = ""Konrad""; // Overwritten: {c->name}; }; // Overwritten: {}; }; ```. Similarly, when the data flow algorithm computes a failure state, we also can't; perform the refactoring. ```c++; Customer* kGlobalCustomer;. void GetCustomer(Customer* c) {; // Overwritten: {}; c->account_id = ...; // Overwritten: {c->account_id}; if (...) {; print(c->name); // Unsafe read; } else {; kGlobalCustomer = c; // Pointer escape; }; // Unsafe read, Pointer escape; }; ```. ## Example: finding dead stores. Let's say we want to find redundant stores, because they indicate potential; bugs. ```c++; x = GetX();; x = GetY();; ```. The first store to `x` is never read, probably there is a bug. The implementation of dead store analysis is very similar to output parameter; analysis: we need to track stores and loads, and find stores that were never; read. [Liveness analysis](https://en.wikipedia.org/wiki/Live_variable_analysis) is a; generalization of this idea, which is often used to answer many related; questions, for example:. * finding dead stores,; * finding uninitialized variables,; * finding a good point to deallocate memory,; *",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:20232,Modifiability,variab,variables,20232,"a flow algorithm computes a failure state, we also can't; perform the refactoring. ```c++; Customer* kGlobalCustomer;. void GetCustomer(Customer* c) {; // Overwritten: {}; c->account_id = ...; // Overwritten: {c->account_id}; if (...) {; print(c->name); // Unsafe read; } else {; kGlobalCustomer = c; // Pointer escape; }; // Unsafe read, Pointer escape; }; ```. ## Example: finding dead stores. Let's say we want to find redundant stores, because they indicate potential; bugs. ```c++; x = GetX();; x = GetY();; ```. The first store to `x` is never read, probably there is a bug. The implementation of dead store analysis is very similar to output parameter; analysis: we need to track stores and loads, and find stores that were never; read. [Liveness analysis](https://en.wikipedia.org/wiki/Live_variable_analysis) is a; generalization of this idea, which is often used to answer many related; questions, for example:. * finding dead stores,; * finding uninitialized variables,; * finding a good point to deallocate memory,; * finding out if it would be safe to move an object. ## Example: definitive initialization. Definitive initialization proves that variables are known to be initialized when; read. If we find a variable which is read when not initialized then we generate; a warning. ```c++; void Init() {; int x; // x is uninitialized; if (cond()) {; x = 10; // x is initialized; } else {; x = 20; // x is initialized; }; print(x); // x is initialized; }; ```. ```c++; void Uninit() {; int x; // x is uninitialized; if (cond()) {; x = 10; // x is initialized; }; print(x); // x is maybe uninitialized, x is being read, report a bug.; }; ```. For this purpose we can use lattice in a form of a mapping from variable; declarations to initialization states; each initialization state is represented; by the following lattice:. ![Lattice for definitive initialization analysis](DataFlowAnalysisIntroImages/DefinitiveInitializationLattice.svg). A lattice element could also capture the source lo",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:20420,Modifiability,variab,variables,20420,"ten: {}; c->account_id = ...; // Overwritten: {c->account_id}; if (...) {; print(c->name); // Unsafe read; } else {; kGlobalCustomer = c; // Pointer escape; }; // Unsafe read, Pointer escape; }; ```. ## Example: finding dead stores. Let's say we want to find redundant stores, because they indicate potential; bugs. ```c++; x = GetX();; x = GetY();; ```. The first store to `x` is never read, probably there is a bug. The implementation of dead store analysis is very similar to output parameter; analysis: we need to track stores and loads, and find stores that were never; read. [Liveness analysis](https://en.wikipedia.org/wiki/Live_variable_analysis) is a; generalization of this idea, which is often used to answer many related; questions, for example:. * finding dead stores,; * finding uninitialized variables,; * finding a good point to deallocate memory,; * finding out if it would be safe to move an object. ## Example: definitive initialization. Definitive initialization proves that variables are known to be initialized when; read. If we find a variable which is read when not initialized then we generate; a warning. ```c++; void Init() {; int x; // x is uninitialized; if (cond()) {; x = 10; // x is initialized; } else {; x = 20; // x is initialized; }; print(x); // x is initialized; }; ```. ```c++; void Uninit() {; int x; // x is uninitialized; if (cond()) {; x = 10; // x is initialized; }; print(x); // x is maybe uninitialized, x is being read, report a bug.; }; ```. For this purpose we can use lattice in a form of a mapping from variable; declarations to initialization states; each initialization state is represented; by the following lattice:. ![Lattice for definitive initialization analysis](DataFlowAnalysisIntroImages/DefinitiveInitializationLattice.svg). A lattice element could also capture the source locations of the branches that; lead us to the corresponding program point. Diagnostics would use this; information to show a sample buggy code path to the user. ##",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:20483,Modifiability,variab,variable,20483,"e); // Unsafe read; } else {; kGlobalCustomer = c; // Pointer escape; }; // Unsafe read, Pointer escape; }; ```. ## Example: finding dead stores. Let's say we want to find redundant stores, because they indicate potential; bugs. ```c++; x = GetX();; x = GetY();; ```. The first store to `x` is never read, probably there is a bug. The implementation of dead store analysis is very similar to output parameter; analysis: we need to track stores and loads, and find stores that were never; read. [Liveness analysis](https://en.wikipedia.org/wiki/Live_variable_analysis) is a; generalization of this idea, which is often used to answer many related; questions, for example:. * finding dead stores,; * finding uninitialized variables,; * finding a good point to deallocate memory,; * finding out if it would be safe to move an object. ## Example: definitive initialization. Definitive initialization proves that variables are known to be initialized when; read. If we find a variable which is read when not initialized then we generate; a warning. ```c++; void Init() {; int x; // x is uninitialized; if (cond()) {; x = 10; // x is initialized; } else {; x = 20; // x is initialized; }; print(x); // x is initialized; }; ```. ```c++; void Uninit() {; int x; // x is uninitialized; if (cond()) {; x = 10; // x is initialized; }; print(x); // x is maybe uninitialized, x is being read, report a bug.; }; ```. For this purpose we can use lattice in a form of a mapping from variable; declarations to initialization states; each initialization state is represented; by the following lattice:. ![Lattice for definitive initialization analysis](DataFlowAnalysisIntroImages/DefinitiveInitializationLattice.svg). A lattice element could also capture the source locations of the branches that; lead us to the corresponding program point. Diagnostics would use this; information to show a sample buggy code path to the user. ## Example: refactoring raw pointers to `unique_ptr`. Modern idiomatic C++ uses smart poi",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:20979,Modifiability,variab,variable,20979," [Liveness analysis](https://en.wikipedia.org/wiki/Live_variable_analysis) is a; generalization of this idea, which is often used to answer many related; questions, for example:. * finding dead stores,; * finding uninitialized variables,; * finding a good point to deallocate memory,; * finding out if it would be safe to move an object. ## Example: definitive initialization. Definitive initialization proves that variables are known to be initialized when; read. If we find a variable which is read when not initialized then we generate; a warning. ```c++; void Init() {; int x; // x is uninitialized; if (cond()) {; x = 10; // x is initialized; } else {; x = 20; // x is initialized; }; print(x); // x is initialized; }; ```. ```c++; void Uninit() {; int x; // x is uninitialized; if (cond()) {; x = 10; // x is initialized; }; print(x); // x is maybe uninitialized, x is being read, report a bug.; }; ```. For this purpose we can use lattice in a form of a mapping from variable; declarations to initialization states; each initialization state is represented; by the following lattice:. ![Lattice for definitive initialization analysis](DataFlowAnalysisIntroImages/DefinitiveInitializationLattice.svg). A lattice element could also capture the source locations of the branches that; lead us to the corresponding program point. Diagnostics would use this; information to show a sample buggy code path to the user. ## Example: refactoring raw pointers to `unique_ptr`. Modern idiomatic C++ uses smart pointers to express memory ownership, however in; pre-C++11 code one can often find raw pointers that own heap memory blocks. Imagine that we would like to refactor raw pointers that own memory to; `unique_ptr`. There are multiple ways to design a data flow analysis for this; problem; let's look at one way to do it. For example, we would like to refactor the following code that uses raw; pointers:. ```c++; void UniqueOwnership1() {; int *pi = new int;; if (...) {; Borrow(pi);; delete pi;; } ",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:21435,Modifiability,refactor,refactoring,21435,"tialized when; read. If we find a variable which is read when not initialized then we generate; a warning. ```c++; void Init() {; int x; // x is uninitialized; if (cond()) {; x = 10; // x is initialized; } else {; x = 20; // x is initialized; }; print(x); // x is initialized; }; ```. ```c++; void Uninit() {; int x; // x is uninitialized; if (cond()) {; x = 10; // x is initialized; }; print(x); // x is maybe uninitialized, x is being read, report a bug.; }; ```. For this purpose we can use lattice in a form of a mapping from variable; declarations to initialization states; each initialization state is represented; by the following lattice:. ![Lattice for definitive initialization analysis](DataFlowAnalysisIntroImages/DefinitiveInitializationLattice.svg). A lattice element could also capture the source locations of the branches that; lead us to the corresponding program point. Diagnostics would use this; information to show a sample buggy code path to the user. ## Example: refactoring raw pointers to `unique_ptr`. Modern idiomatic C++ uses smart pointers to express memory ownership, however in; pre-C++11 code one can often find raw pointers that own heap memory blocks. Imagine that we would like to refactor raw pointers that own memory to; `unique_ptr`. There are multiple ways to design a data flow analysis for this; problem; let's look at one way to do it. For example, we would like to refactor the following code that uses raw; pointers:. ```c++; void UniqueOwnership1() {; int *pi = new int;; if (...) {; Borrow(pi);; delete pi;; } else {; TakeOwnership(pi);; }; }; ```. into code that uses `unique_ptr`:. ```c++; void UniqueOwnership1() {; auto pi = std::make_unique<int>();; if (...) {; Borrow(pi.get());; } else {; TakeOwnership(pi.release());; }; }; ```. This problem can be solved with a lattice in form of map from value declarations; to pointer states:. ![Lattice that identifies candidates for unique_ptr refactoring](DataFlowAnalysisIntroImages/UniquePtrLattice.svg).",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:21665,Modifiability,refactor,refactor,21665,"s initialized; }; print(x); // x is initialized; }; ```. ```c++; void Uninit() {; int x; // x is uninitialized; if (cond()) {; x = 10; // x is initialized; }; print(x); // x is maybe uninitialized, x is being read, report a bug.; }; ```. For this purpose we can use lattice in a form of a mapping from variable; declarations to initialization states; each initialization state is represented; by the following lattice:. ![Lattice for definitive initialization analysis](DataFlowAnalysisIntroImages/DefinitiveInitializationLattice.svg). A lattice element could also capture the source locations of the branches that; lead us to the corresponding program point. Diagnostics would use this; information to show a sample buggy code path to the user. ## Example: refactoring raw pointers to `unique_ptr`. Modern idiomatic C++ uses smart pointers to express memory ownership, however in; pre-C++11 code one can often find raw pointers that own heap memory blocks. Imagine that we would like to refactor raw pointers that own memory to; `unique_ptr`. There are multiple ways to design a data flow analysis for this; problem; let's look at one way to do it. For example, we would like to refactor the following code that uses raw; pointers:. ```c++; void UniqueOwnership1() {; int *pi = new int;; if (...) {; Borrow(pi);; delete pi;; } else {; TakeOwnership(pi);; }; }; ```. into code that uses `unique_ptr`:. ```c++; void UniqueOwnership1() {; auto pi = std::make_unique<int>();; if (...) {; Borrow(pi.get());; } else {; TakeOwnership(pi.release());; }; }; ```. This problem can be solved with a lattice in form of map from value declarations; to pointer states:. ![Lattice that identifies candidates for unique_ptr refactoring](DataFlowAnalysisIntroImages/UniquePtrLattice.svg). We can perform the refactoring if at the exit of a function `pi` is; `Compatible`. ```c++; void UniqueOwnership1() {; int *pi; // pi is Compatible; pi = new int; // pi is Defined; if (...) {; Borrow(pi); // pi is Defined; delet",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:21857,Modifiability,refactor,refactor,21857,"lized, x is being read, report a bug.; }; ```. For this purpose we can use lattice in a form of a mapping from variable; declarations to initialization states; each initialization state is represented; by the following lattice:. ![Lattice for definitive initialization analysis](DataFlowAnalysisIntroImages/DefinitiveInitializationLattice.svg). A lattice element could also capture the source locations of the branches that; lead us to the corresponding program point. Diagnostics would use this; information to show a sample buggy code path to the user. ## Example: refactoring raw pointers to `unique_ptr`. Modern idiomatic C++ uses smart pointers to express memory ownership, however in; pre-C++11 code one can often find raw pointers that own heap memory blocks. Imagine that we would like to refactor raw pointers that own memory to; `unique_ptr`. There are multiple ways to design a data flow analysis for this; problem; let's look at one way to do it. For example, we would like to refactor the following code that uses raw; pointers:. ```c++; void UniqueOwnership1() {; int *pi = new int;; if (...) {; Borrow(pi);; delete pi;; } else {; TakeOwnership(pi);; }; }; ```. into code that uses `unique_ptr`:. ```c++; void UniqueOwnership1() {; auto pi = std::make_unique<int>();; if (...) {; Borrow(pi.get());; } else {; TakeOwnership(pi.release());; }; }; ```. This problem can be solved with a lattice in form of map from value declarations; to pointer states:. ![Lattice that identifies candidates for unique_ptr refactoring](DataFlowAnalysisIntroImages/UniquePtrLattice.svg). We can perform the refactoring if at the exit of a function `pi` is; `Compatible`. ```c++; void UniqueOwnership1() {; int *pi; // pi is Compatible; pi = new int; // pi is Defined; if (...) {; Borrow(pi); // pi is Defined; delete pi; // pi is Compatible; } else {; TakeOwnership(pi); // pi is Compatible; }; // pi is Compatible; }; ```. Let's look at an example where the raw pointer owns two different memory blocks:. ",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:22386,Modifiability,refactor,refactoring,22386,"ample buggy code path to the user. ## Example: refactoring raw pointers to `unique_ptr`. Modern idiomatic C++ uses smart pointers to express memory ownership, however in; pre-C++11 code one can often find raw pointers that own heap memory blocks. Imagine that we would like to refactor raw pointers that own memory to; `unique_ptr`. There are multiple ways to design a data flow analysis for this; problem; let's look at one way to do it. For example, we would like to refactor the following code that uses raw; pointers:. ```c++; void UniqueOwnership1() {; int *pi = new int;; if (...) {; Borrow(pi);; delete pi;; } else {; TakeOwnership(pi);; }; }; ```. into code that uses `unique_ptr`:. ```c++; void UniqueOwnership1() {; auto pi = std::make_unique<int>();; if (...) {; Borrow(pi.get());; } else {; TakeOwnership(pi.release());; }; }; ```. This problem can be solved with a lattice in form of map from value declarations; to pointer states:. ![Lattice that identifies candidates for unique_ptr refactoring](DataFlowAnalysisIntroImages/UniquePtrLattice.svg). We can perform the refactoring if at the exit of a function `pi` is; `Compatible`. ```c++; void UniqueOwnership1() {; int *pi; // pi is Compatible; pi = new int; // pi is Defined; if (...) {; Borrow(pi); // pi is Defined; delete pi; // pi is Compatible; } else {; TakeOwnership(pi); // pi is Compatible; }; // pi is Compatible; }; ```. Let's look at an example where the raw pointer owns two different memory blocks:. ```c++; void UniqueOwnership2() {; int *pi = new int; // pi is Defined; Borrow(pi);; delete pi; // pi is Compatible; if (smth) {; pi = new int; // pi is Defined; Borrow(pi);; delete pi; // pi is Compatible; }; // pi is Compatible; }; ```. It can be refactored to use `unique_ptr` like this:. ```c++; void UniqueOwnership2() {; auto pi = make_unique<int>();; Borrow(pi);; if (smth) {; pi = make_unique<int>();; Borrow(pi);; }; }; ```. In the following example, the raw pointer is used to access the heap object; after the ",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:22469,Modifiability,refactor,refactoring,22469,"tic C++ uses smart pointers to express memory ownership, however in; pre-C++11 code one can often find raw pointers that own heap memory blocks. Imagine that we would like to refactor raw pointers that own memory to; `unique_ptr`. There are multiple ways to design a data flow analysis for this; problem; let's look at one way to do it. For example, we would like to refactor the following code that uses raw; pointers:. ```c++; void UniqueOwnership1() {; int *pi = new int;; if (...) {; Borrow(pi);; delete pi;; } else {; TakeOwnership(pi);; }; }; ```. into code that uses `unique_ptr`:. ```c++; void UniqueOwnership1() {; auto pi = std::make_unique<int>();; if (...) {; Borrow(pi.get());; } else {; TakeOwnership(pi.release());; }; }; ```. This problem can be solved with a lattice in form of map from value declarations; to pointer states:. ![Lattice that identifies candidates for unique_ptr refactoring](DataFlowAnalysisIntroImages/UniquePtrLattice.svg). We can perform the refactoring if at the exit of a function `pi` is; `Compatible`. ```c++; void UniqueOwnership1() {; int *pi; // pi is Compatible; pi = new int; // pi is Defined; if (...) {; Borrow(pi); // pi is Defined; delete pi; // pi is Compatible; } else {; TakeOwnership(pi); // pi is Compatible; }; // pi is Compatible; }; ```. Let's look at an example where the raw pointer owns two different memory blocks:. ```c++; void UniqueOwnership2() {; int *pi = new int; // pi is Defined; Borrow(pi);; delete pi; // pi is Compatible; if (smth) {; pi = new int; // pi is Defined; Borrow(pi);; delete pi; // pi is Compatible; }; // pi is Compatible; }; ```. It can be refactored to use `unique_ptr` like this:. ```c++; void UniqueOwnership2() {; auto pi = make_unique<int>();; Borrow(pi);; if (smth) {; pi = make_unique<int>();; Borrow(pi);; }; }; ```. In the following example, the raw pointer is used to access the heap object; after the ownership has been transferred. ```c++; void UniqueOwnership3() {; int *pi = new int; // pi is Defined",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:23117,Modifiability,refactor,refactored,23117,"e_unique<int>();; if (...) {; Borrow(pi.get());; } else {; TakeOwnership(pi.release());; }; }; ```. This problem can be solved with a lattice in form of map from value declarations; to pointer states:. ![Lattice that identifies candidates for unique_ptr refactoring](DataFlowAnalysisIntroImages/UniquePtrLattice.svg). We can perform the refactoring if at the exit of a function `pi` is; `Compatible`. ```c++; void UniqueOwnership1() {; int *pi; // pi is Compatible; pi = new int; // pi is Defined; if (...) {; Borrow(pi); // pi is Defined; delete pi; // pi is Compatible; } else {; TakeOwnership(pi); // pi is Compatible; }; // pi is Compatible; }; ```. Let's look at an example where the raw pointer owns two different memory blocks:. ```c++; void UniqueOwnership2() {; int *pi = new int; // pi is Defined; Borrow(pi);; delete pi; // pi is Compatible; if (smth) {; pi = new int; // pi is Defined; Borrow(pi);; delete pi; // pi is Compatible; }; // pi is Compatible; }; ```. It can be refactored to use `unique_ptr` like this:. ```c++; void UniqueOwnership2() {; auto pi = make_unique<int>();; Borrow(pi);; if (smth) {; pi = make_unique<int>();; Borrow(pi);; }; }; ```. In the following example, the raw pointer is used to access the heap object; after the ownership has been transferred. ```c++; void UniqueOwnership3() {; int *pi = new int; // pi is Defined; if (...) {; Borrow(pi);; delete pi; // pi is Compatible; } else {; vector<unique_ptr<int>> v = {std::unique_ptr(pi)}; // pi is Compatible; print(*pi);; use(v);; }; // pi is Compatible; }; ```. We can refactor this code to use `unique_ptr`, however we would have to; introduce a non-owning pointer variable, since we can't use the moved-from; `unique_ptr` to access the object:. ```c++; void UniqueOwnership3() {; std::unique_ptr<int> pi = std::make_unique<int>();; if (...) {; Borrow(pi);; } else {; int *pi_non_owning = pi.get();; vector<unique_ptr<int>> v = {std::move(pi)};; print(*pi_non_owning);; use(v);; }; }; ```. If the original co",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:23693,Modifiability,refactor,refactor,23693," }; ```. Let's look at an example where the raw pointer owns two different memory blocks:. ```c++; void UniqueOwnership2() {; int *pi = new int; // pi is Defined; Borrow(pi);; delete pi; // pi is Compatible; if (smth) {; pi = new int; // pi is Defined; Borrow(pi);; delete pi; // pi is Compatible; }; // pi is Compatible; }; ```. It can be refactored to use `unique_ptr` like this:. ```c++; void UniqueOwnership2() {; auto pi = make_unique<int>();; Borrow(pi);; if (smth) {; pi = make_unique<int>();; Borrow(pi);; }; }; ```. In the following example, the raw pointer is used to access the heap object; after the ownership has been transferred. ```c++; void UniqueOwnership3() {; int *pi = new int; // pi is Defined; if (...) {; Borrow(pi);; delete pi; // pi is Compatible; } else {; vector<unique_ptr<int>> v = {std::unique_ptr(pi)}; // pi is Compatible; print(*pi);; use(v);; }; // pi is Compatible; }; ```. We can refactor this code to use `unique_ptr`, however we would have to; introduce a non-owning pointer variable, since we can't use the moved-from; `unique_ptr` to access the object:. ```c++; void UniqueOwnership3() {; std::unique_ptr<int> pi = std::make_unique<int>();; if (...) {; Borrow(pi);; } else {; int *pi_non_owning = pi.get();; vector<unique_ptr<int>> v = {std::move(pi)};; print(*pi_non_owning);; use(v);; }; }; ```. If the original code didn't call `delete` at the very end of the function, then; our refactoring may change the point at which we run the destructor and release; memory. Specifically, if there is some user code after `delete`, then extending; the lifetime of the object until the end of the function may hold locks for; longer than necessary, introduce memory overhead etc. One solution is to always replace `delete` with a call to `reset()`, and then; perform another analysis that removes unnecessary `reset()` calls. ```c++; void AddedMemoryOverhead() {; HugeObject *ho = new HugeObject();; use(ho);; delete ho; // Release the large amount of memory quickly.; ",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:23790,Modifiability,variab,variable,23790," }; ```. Let's look at an example where the raw pointer owns two different memory blocks:. ```c++; void UniqueOwnership2() {; int *pi = new int; // pi is Defined; Borrow(pi);; delete pi; // pi is Compatible; if (smth) {; pi = new int; // pi is Defined; Borrow(pi);; delete pi; // pi is Compatible; }; // pi is Compatible; }; ```. It can be refactored to use `unique_ptr` like this:. ```c++; void UniqueOwnership2() {; auto pi = make_unique<int>();; Borrow(pi);; if (smth) {; pi = make_unique<int>();; Borrow(pi);; }; }; ```. In the following example, the raw pointer is used to access the heap object; after the ownership has been transferred. ```c++; void UniqueOwnership3() {; int *pi = new int; // pi is Defined; if (...) {; Borrow(pi);; delete pi; // pi is Compatible; } else {; vector<unique_ptr<int>> v = {std::unique_ptr(pi)}; // pi is Compatible; print(*pi);; use(v);; }; // pi is Compatible; }; ```. We can refactor this code to use `unique_ptr`, however we would have to; introduce a non-owning pointer variable, since we can't use the moved-from; `unique_ptr` to access the object:. ```c++; void UniqueOwnership3() {; std::unique_ptr<int> pi = std::make_unique<int>();; if (...) {; Borrow(pi);; } else {; int *pi_non_owning = pi.get();; vector<unique_ptr<int>> v = {std::move(pi)};; print(*pi_non_owning);; use(v);; }; }; ```. If the original code didn't call `delete` at the very end of the function, then; our refactoring may change the point at which we run the destructor and release; memory. Specifically, if there is some user code after `delete`, then extending; the lifetime of the object until the end of the function may hold locks for; longer than necessary, introduce memory overhead etc. One solution is to always replace `delete` with a call to `reset()`, and then; perform another analysis that removes unnecessary `reset()` calls. ```c++; void AddedMemoryOverhead() {; HugeObject *ho = new HugeObject();; use(ho);; delete ho; // Release the large amount of memory quickly.; ",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:24200,Modifiability,refactor,refactoring,24200," pi = make_unique<int>();; Borrow(pi);; if (smth) {; pi = make_unique<int>();; Borrow(pi);; }; }; ```. In the following example, the raw pointer is used to access the heap object; after the ownership has been transferred. ```c++; void UniqueOwnership3() {; int *pi = new int; // pi is Defined; if (...) {; Borrow(pi);; delete pi; // pi is Compatible; } else {; vector<unique_ptr<int>> v = {std::unique_ptr(pi)}; // pi is Compatible; print(*pi);; use(v);; }; // pi is Compatible; }; ```. We can refactor this code to use `unique_ptr`, however we would have to; introduce a non-owning pointer variable, since we can't use the moved-from; `unique_ptr` to access the object:. ```c++; void UniqueOwnership3() {; std::unique_ptr<int> pi = std::make_unique<int>();; if (...) {; Borrow(pi);; } else {; int *pi_non_owning = pi.get();; vector<unique_ptr<int>> v = {std::move(pi)};; print(*pi_non_owning);; use(v);; }; }; ```. If the original code didn't call `delete` at the very end of the function, then; our refactoring may change the point at which we run the destructor and release; memory. Specifically, if there is some user code after `delete`, then extending; the lifetime of the object until the end of the function may hold locks for; longer than necessary, introduce memory overhead etc. One solution is to always replace `delete` with a call to `reset()`, and then; perform another analysis that removes unnecessary `reset()` calls. ```c++; void AddedMemoryOverhead() {; HugeObject *ho = new HugeObject();; use(ho);; delete ho; // Release the large amount of memory quickly.; LongRunningFunction();; }; ```. This analysis will refuse to refactor code that mixes borrowed pointer values; and unique ownership. In the following code, `GetPtr()` returns a borrowed; pointer, which is assigned to `pi`. Then, `pi` is used to hold a uniquely-owned; pointer. We don't distinguish between these two assignments, and we want each; assignment to be paired with a corresponding sink; otherwise, we transitio",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:24347,Modifiability,extend,extending,24347,"he ownership has been transferred. ```c++; void UniqueOwnership3() {; int *pi = new int; // pi is Defined; if (...) {; Borrow(pi);; delete pi; // pi is Compatible; } else {; vector<unique_ptr<int>> v = {std::unique_ptr(pi)}; // pi is Compatible; print(*pi);; use(v);; }; // pi is Compatible; }; ```. We can refactor this code to use `unique_ptr`, however we would have to; introduce a non-owning pointer variable, since we can't use the moved-from; `unique_ptr` to access the object:. ```c++; void UniqueOwnership3() {; std::unique_ptr<int> pi = std::make_unique<int>();; if (...) {; Borrow(pi);; } else {; int *pi_non_owning = pi.get();; vector<unique_ptr<int>> v = {std::move(pi)};; print(*pi_non_owning);; use(v);; }; }; ```. If the original code didn't call `delete` at the very end of the function, then; our refactoring may change the point at which we run the destructor and release; memory. Specifically, if there is some user code after `delete`, then extending; the lifetime of the object until the end of the function may hold locks for; longer than necessary, introduce memory overhead etc. One solution is to always replace `delete` with a call to `reset()`, and then; perform another analysis that removes unnecessary `reset()` calls. ```c++; void AddedMemoryOverhead() {; HugeObject *ho = new HugeObject();; use(ho);; delete ho; // Release the large amount of memory quickly.; LongRunningFunction();; }; ```. This analysis will refuse to refactor code that mixes borrowed pointer values; and unique ownership. In the following code, `GetPtr()` returns a borrowed; pointer, which is assigned to `pi`. Then, `pi` is used to hold a uniquely-owned; pointer. We don't distinguish between these two assignments, and we want each; assignment to be paired with a corresponding sink; otherwise, we transition the; pointer to a `Conflicting` state, like in this example. ```c++; void ConflictingOwnership() {; int *pi; // pi is Compatible; pi = GetPtr(); // pi is Defined; Borrow(pi); // pi is D",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:24839,Modifiability,refactor,refactor,24839,"he object:. ```c++; void UniqueOwnership3() {; std::unique_ptr<int> pi = std::make_unique<int>();; if (...) {; Borrow(pi);; } else {; int *pi_non_owning = pi.get();; vector<unique_ptr<int>> v = {std::move(pi)};; print(*pi_non_owning);; use(v);; }; }; ```. If the original code didn't call `delete` at the very end of the function, then; our refactoring may change the point at which we run the destructor and release; memory. Specifically, if there is some user code after `delete`, then extending; the lifetime of the object until the end of the function may hold locks for; longer than necessary, introduce memory overhead etc. One solution is to always replace `delete` with a call to `reset()`, and then; perform another analysis that removes unnecessary `reset()` calls. ```c++; void AddedMemoryOverhead() {; HugeObject *ho = new HugeObject();; use(ho);; delete ho; // Release the large amount of memory quickly.; LongRunningFunction();; }; ```. This analysis will refuse to refactor code that mixes borrowed pointer values; and unique ownership. In the following code, `GetPtr()` returns a borrowed; pointer, which is assigned to `pi`. Then, `pi` is used to hold a uniquely-owned; pointer. We don't distinguish between these two assignments, and we want each; assignment to be paired with a corresponding sink; otherwise, we transition the; pointer to a `Conflicting` state, like in this example. ```c++; void ConflictingOwnership() {; int *pi; // pi is Compatible; pi = GetPtr(); // pi is Defined; Borrow(pi); // pi is Defined. pi = new int; // pi is Conflicting; Borrow(pi);; delete pi;; // pi is Conflicting; }; ```. We could still handle this case by finding a maximal range in the code where; `pi` could be in the Compatible state, and only refactoring that part. ```c++; void ConflictingOwnership() {; int *pi;; pi = GetPtr();; Borrow(pi);. std::unique_ptr<int> pi_unique = std::make_unique<int>();; Borrow(pi_unique.get());; }; ```. ## Example: finding redundant branch conditions. In the",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:25611,Modifiability,refactor,refactoring,25611,"and then; perform another analysis that removes unnecessary `reset()` calls. ```c++; void AddedMemoryOverhead() {; HugeObject *ho = new HugeObject();; use(ho);; delete ho; // Release the large amount of memory quickly.; LongRunningFunction();; }; ```. This analysis will refuse to refactor code that mixes borrowed pointer values; and unique ownership. In the following code, `GetPtr()` returns a borrowed; pointer, which is assigned to `pi`. Then, `pi` is used to hold a uniquely-owned; pointer. We don't distinguish between these two assignments, and we want each; assignment to be paired with a corresponding sink; otherwise, we transition the; pointer to a `Conflicting` state, like in this example. ```c++; void ConflictingOwnership() {; int *pi; // pi is Compatible; pi = GetPtr(); // pi is Defined; Borrow(pi); // pi is Defined. pi = new int; // pi is Conflicting; Borrow(pi);; delete pi;; // pi is Conflicting; }; ```. We could still handle this case by finding a maximal range in the code where; `pi` could be in the Compatible state, and only refactoring that part. ```c++; void ConflictingOwnership() {; int *pi;; pi = GetPtr();; Borrow(pi);. std::unique_ptr<int> pi_unique = std::make_unique<int>();; Borrow(pi_unique.get());; }; ```. ## Example: finding redundant branch conditions. In the code below `b1` should not be checked in both the outer and inner ""if""; statements. It is likely there is a bug in this code. ```c++; int F(bool b1, bool b2) {; if (b1) {; f();; if (b1 && b2) { // Check `b1` again -- unnecessary!; g();; }; }; }; ```. A checker that finds this pattern syntactically is already implemented in; ClangTidy using AST matchers (`bugprone-redundant-branch-condition`). To implement it using the data flow analysis framework, we can produce a warning; if any part of the branch condition is implied by the flow condition. ```c++; int F(bool b1, bool b2) {; // Flow condition: true.; if (b1) {; // Flow condition: b1.; f();; if (b1 && b2) { // `b1` is implied by the flow c",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:29452,Modifiability,refactor,refactoring,29452,"++; DEFINE_FLAG(std::string, example_flag, """", ""A sample flag."");. void Example() {; bool x = GetFlag(FLAGS_example_flag).empty();; f();; if (x) {; g();; } else {; h();; }; }; ```. The tool would simplify the code to:. ```c++; void Example() {; f();; g();; }; ```. We can solve this problem with a classic constant propagation lattice combined; with symbolic evaluation. ## Example: finding inefficient usages of associative containers. Real-world code often accidentally performs repeated lookups in associative; containers:. ```c++; map<int, Employee> xs;; xs[42]->name = ""..."";; xs[42]->title = ""..."";; ```. To find the above inefficiency we can use the available expressions analysis to; understand that `m[42]` is evaluated twice. ```c++; map<int, Employee> xs;; Employee &e = xs[42];; e->name = ""..."";; e->title = ""..."";; ```. We can also track the `m.contains()` check in the flow condition to find; redundant checks, like in the example below. ```c++; std::map<int, Employee> xs;; if (!xs.contains(42)) {; xs.insert({42, someEmployee});; }; ```. ## Example: refactoring types that implicitly convert to each other. Refactoring one strong type to another is difficult, but the compiler can help:; once you refactor one reference to the type, the compiler will flag other places; where this information flows with type mismatch errors. Unfortunately this; strategy does not work when you are refactoring types that implicitly convert to; each other, for example, replacing `int32_t` with `int64_t`. Imagine that we want to change user IDs from 32 to 64-bit integers. In other; words, we need to find all integers tainted with user IDs. We can use data flow; analysis to implement taint analysis. ```c++; void UseUser(int32_t user_id) {; int32_t id = user_id;; // Variable `id` is tainted with a user ID.; ...; }; ```. Taint analysis is very well suited to this problem because the program rarely; branches on user IDs, and almost certainly does not perform any computation; (like arithmetic).; ",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:29599,Modifiability,refactor,refactor,29599,"++; DEFINE_FLAG(std::string, example_flag, """", ""A sample flag."");. void Example() {; bool x = GetFlag(FLAGS_example_flag).empty();; f();; if (x) {; g();; } else {; h();; }; }; ```. The tool would simplify the code to:. ```c++; void Example() {; f();; g();; }; ```. We can solve this problem with a classic constant propagation lattice combined; with symbolic evaluation. ## Example: finding inefficient usages of associative containers. Real-world code often accidentally performs repeated lookups in associative; containers:. ```c++; map<int, Employee> xs;; xs[42]->name = ""..."";; xs[42]->title = ""..."";; ```. To find the above inefficiency we can use the available expressions analysis to; understand that `m[42]` is evaluated twice. ```c++; map<int, Employee> xs;; Employee &e = xs[42];; e->name = ""..."";; e->title = ""..."";; ```. We can also track the `m.contains()` check in the flow condition to find; redundant checks, like in the example below. ```c++; std::map<int, Employee> xs;; if (!xs.contains(42)) {; xs.insert({42, someEmployee});; }; ```. ## Example: refactoring types that implicitly convert to each other. Refactoring one strong type to another is difficult, but the compiler can help:; once you refactor one reference to the type, the compiler will flag other places; where this information flows with type mismatch errors. Unfortunately this; strategy does not work when you are refactoring types that implicitly convert to; each other, for example, replacing `int32_t` with `int64_t`. Imagine that we want to change user IDs from 32 to 64-bit integers. In other; words, we need to find all integers tainted with user IDs. We can use data flow; analysis to implement taint analysis. ```c++; void UseUser(int32_t user_id) {; int32_t id = user_id;; // Variable `id` is tainted with a user ID.; ...; }; ```. Taint analysis is very well suited to this problem because the program rarely; branches on user IDs, and almost certainly does not perform any computation; (like arithmetic).; ",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:29784,Modifiability,refactor,refactoring,29784,"++; DEFINE_FLAG(std::string, example_flag, """", ""A sample flag."");. void Example() {; bool x = GetFlag(FLAGS_example_flag).empty();; f();; if (x) {; g();; } else {; h();; }; }; ```. The tool would simplify the code to:. ```c++; void Example() {; f();; g();; }; ```. We can solve this problem with a classic constant propagation lattice combined; with symbolic evaluation. ## Example: finding inefficient usages of associative containers. Real-world code often accidentally performs repeated lookups in associative; containers:. ```c++; map<int, Employee> xs;; xs[42]->name = ""..."";; xs[42]->title = ""..."";; ```. To find the above inefficiency we can use the available expressions analysis to; understand that `m[42]` is evaluated twice. ```c++; map<int, Employee> xs;; Employee &e = xs[42];; e->name = ""..."";; e->title = ""..."";; ```. We can also track the `m.contains()` check in the flow condition to find; redundant checks, like in the example below. ```c++; std::map<int, Employee> xs;; if (!xs.contains(42)) {; xs.insert({42, someEmployee});; }; ```. ## Example: refactoring types that implicitly convert to each other. Refactoring one strong type to another is difficult, but the compiler can help:; once you refactor one reference to the type, the compiler will flag other places; where this information flows with type mismatch errors. Unfortunately this; strategy does not work when you are refactoring types that implicitly convert to; each other, for example, replacing `int32_t` with `int64_t`. Imagine that we want to change user IDs from 32 to 64-bit integers. In other; words, we need to find all integers tainted with user IDs. We can use data flow; analysis to implement taint analysis. ```c++; void UseUser(int32_t user_id) {; int32_t id = user_id;; // Variable `id` is tainted with a user ID.; ...; }; ```. Taint analysis is very well suited to this problem because the program rarely; branches on user IDs, and almost certainly does not perform any computation; (like arithmetic).; ",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:8890,Performance,perform,performs,8890,"tice. * When `x` is assigned a concrete value, its possible set of values contains; just that specific value. * When `x` is assigned some unknown value, it can have any value. We represent; this fact as `⊤`. * When two control flow paths join, we compute the set union of incoming; values (limiting the number of elements to 3, representing larger sets as; `⊤`). The sets of possible values are influenced by:. * Statements, for example, assignments. * Joins in control flow, for example, ones that appear at the end of ""if""; statements. **Effects of statements** are modeled by what is formally known as a transfer; function. A transfer function takes two arguments: the statement, and the state; of `x` at the previous program point. It produces the state of `x` at the next; program point. For example, the transfer function for assignment ignores the; state at the previous program point:. ```c++; // GIVEN: x is {42; 44}; x = 0;; // CONCLUSION: x is {0}; ```. The transfer function for `+` performs arithmetic on every set member:. ```c++; // GIVEN: x is {42, 44}; x = x + 100;; // CONCLUSION: x is {142, 144}; ```. **Effects of control flow** are modeled by joining the knowledge from all; possible previous program points. ```c++; if (...) {; ...; // GIVEN: x is {42}; } else {; ...; // GIVEN: x is {44}; }; // CONCLUSION: x is {42; 44}; ```. ```c++; // GIVEN: x is {42}; while (...) {; ...; // GIVEN: x is {44}; }; // CONCLUSION: {42; 44}; ```. The predicate that we marked ""given"" is usually called a precondition, and the; conclusion is called a postcondition. In terms of the CFG, we join the information from all predecessor basic blocks. ![Modeling the effects of a CFG basic block](DataFlowAnalysisIntroImages/CFGJoinRule.svg). Putting it all together, to model the effects of a basic block we compute:. ```; out = transfer(basic_block, join(in_1, in_2, ..., in_n)); ```. (Note that there are other ways to write this equation that produce higher; precision analysis results. The trick ",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:10852,Performance,queue,queue,10852,"ation that produce higher; precision analysis results. The trick is to keep exploring the execution paths; separately and delay joining until later. However, we won't discuss those; variations here.). To make a conclusion about all paths through the program, we repeat this; computation on all basic blocks until we reach a fixpoint. In other words, we; keep propagating information through the CFG until the computed sets of values; stop changing. If the lattice has a finite height and transfer functions are monotonic the; algorithm is guaranteed to terminate. Each iteration of the algorithm can; change computed values only to larger values from the lattice. In the worst; case, all computed values become `⊤`, which is not very useful, but at least the; analysis terminates at that point, because it can't change any of the values. Fixpoint iteration can be optimised by only reprocessing basic blocks which had; one of their inputs changed on the previous iteration. This is typically; implemented using a worklist queue. With this optimisation the time complexity; becomes `O(m * |L|)`, where `m` is the number of basic blocks in the CFG and; `|L|` is the size of lattice used by the analysis. ## Symbolic execution: a very short informal introduction. ### Symbolic values. In the previous example where we tried to figure out what values a variable can; have, the analysis had to be seeded with a concrete value. What if there are no; assignments of concrete values in the program? We can still deduce some; interesting information by representing unknown input values symbolically, and; computing results as symbolic expressions:. ```c++; void PrintAbs(int x) {; int result;; if (x >= 0) {; result = x; // result is {x}; } else {; result = -x; // result is {-x}; }; print(result); // result is {x; -x}; }; ```. We can't say what specific value gets printed, but we know that it is either `x`; or `-x`. Dataflow analysis is an instance of abstract interpretation, and does not dictate; how ex",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:18999,Performance,perform,perform,18999,"lysisIntroImages/OutputParameterIdentificationLattice.svg). To determine whether a statement reads or writes a field we can implement; symbolic evaluation of `DeclRefExpr`s, `LValueToRValue` casts, pointer; dereference operator and `MemberExpr`s. ### Using data flow results to identify output parameters. Let's take a look at how we use data flow analysis to identify an output; parameter. The refactoring can be safely done when the data flow algorithm; computes a normal state with all of the fields proven to be overwritten in the; exit basic block of the function. ```c++; struct Customer {; int account_id;; std::string name;; };. void GetCustomer(Customer* c) {; // Overwritten: {}; c->account_id = ...; // Overwritten: {c->account_id}; if (...) {; c->name = ...; // Overwritten: {c->account_id, c->name}; } else {; c->name = ...; // Overwritten: {c->account_id, c->name}; }; // Overwritten: {c->account_id, c->name}; }; ```. When the data flow algorithm computes a normal state, but not all fields are; proven to be overwritten we can't perform the refactoring. ```c++; void target(bool b, Customer* c) {; // Overwritten: {}; if (b) {; c->account_id = 42; // Overwritten: {c->account_id}; } else {; c->name = ""Konrad""; // Overwritten: {c->name}; }; // Overwritten: {}; }; ```. Similarly, when the data flow algorithm computes a failure state, we also can't; perform the refactoring. ```c++; Customer* kGlobalCustomer;. void GetCustomer(Customer* c) {; // Overwritten: {}; c->account_id = ...; // Overwritten: {c->account_id}; if (...) {; print(c->name); // Unsafe read; } else {; kGlobalCustomer = c; // Pointer escape; }; // Unsafe read, Pointer escape; }; ```. ## Example: finding dead stores. Let's say we want to find redundant stores, because they indicate potential; bugs. ```c++; x = GetX();; x = GetY();; ```. The first store to `x` is never read, probably there is a bug. The implementation of dead store analysis is very similar to output parameter; analysis: we need to track stores",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:19320,Performance,perform,perform,19320," data flow analysis to identify an output; parameter. The refactoring can be safely done when the data flow algorithm; computes a normal state with all of the fields proven to be overwritten in the; exit basic block of the function. ```c++; struct Customer {; int account_id;; std::string name;; };. void GetCustomer(Customer* c) {; // Overwritten: {}; c->account_id = ...; // Overwritten: {c->account_id}; if (...) {; c->name = ...; // Overwritten: {c->account_id, c->name}; } else {; c->name = ...; // Overwritten: {c->account_id, c->name}; }; // Overwritten: {c->account_id, c->name}; }; ```. When the data flow algorithm computes a normal state, but not all fields are; proven to be overwritten we can't perform the refactoring. ```c++; void target(bool b, Customer* c) {; // Overwritten: {}; if (b) {; c->account_id = 42; // Overwritten: {c->account_id}; } else {; c->name = ""Konrad""; // Overwritten: {c->name}; }; // Overwritten: {}; }; ```. Similarly, when the data flow algorithm computes a failure state, we also can't; perform the refactoring. ```c++; Customer* kGlobalCustomer;. void GetCustomer(Customer* c) {; // Overwritten: {}; c->account_id = ...; // Overwritten: {c->account_id}; if (...) {; print(c->name); // Unsafe read; } else {; kGlobalCustomer = c; // Pointer escape; }; // Unsafe read, Pointer escape; }; ```. ## Example: finding dead stores. Let's say we want to find redundant stores, because they indicate potential; bugs. ```c++; x = GetX();; x = GetY();; ```. The first store to `x` is never read, probably there is a bug. The implementation of dead store analysis is very similar to output parameter; analysis: we need to track stores and loads, and find stores that were never; read. [Liveness analysis](https://en.wikipedia.org/wiki/Live_variable_analysis) is a; generalization of this idea, which is often used to answer many related; questions, for example:. * finding dead stores,; * finding uninitialized variables,; * finding a good point to deallocate memory,; *",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:19960,Performance,load,loads,19960,"s a normal state, but not all fields are; proven to be overwritten we can't perform the refactoring. ```c++; void target(bool b, Customer* c) {; // Overwritten: {}; if (b) {; c->account_id = 42; // Overwritten: {c->account_id}; } else {; c->name = ""Konrad""; // Overwritten: {c->name}; }; // Overwritten: {}; }; ```. Similarly, when the data flow algorithm computes a failure state, we also can't; perform the refactoring. ```c++; Customer* kGlobalCustomer;. void GetCustomer(Customer* c) {; // Overwritten: {}; c->account_id = ...; // Overwritten: {c->account_id}; if (...) {; print(c->name); // Unsafe read; } else {; kGlobalCustomer = c; // Pointer escape; }; // Unsafe read, Pointer escape; }; ```. ## Example: finding dead stores. Let's say we want to find redundant stores, because they indicate potential; bugs. ```c++; x = GetX();; x = GetY();; ```. The first store to `x` is never read, probably there is a bug. The implementation of dead store analysis is very similar to output parameter; analysis: we need to track stores and loads, and find stores that were never; read. [Liveness analysis](https://en.wikipedia.org/wiki/Live_variable_analysis) is a; generalization of this idea, which is often used to answer many related; questions, for example:. * finding dead stores,; * finding uninitialized variables,; * finding a good point to deallocate memory,; * finding out if it would be safe to move an object. ## Example: definitive initialization. Definitive initialization proves that variables are known to be initialized when; read. If we find a variable which is read when not initialized then we generate; a warning. ```c++; void Init() {; int x; // x is uninitialized; if (cond()) {; x = 10; // x is initialized; } else {; x = 20; // x is initialized; }; print(x); // x is initialized; }; ```. ```c++; void Uninit() {; int x; // x is uninitialized; if (cond()) {; x = 10; // x is initialized; }; print(x); // x is maybe uninitialized, x is being read, report a bug.; }; ```. For this ",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:22457,Performance,perform,perform,22457,"tic C++ uses smart pointers to express memory ownership, however in; pre-C++11 code one can often find raw pointers that own heap memory blocks. Imagine that we would like to refactor raw pointers that own memory to; `unique_ptr`. There are multiple ways to design a data flow analysis for this; problem; let's look at one way to do it. For example, we would like to refactor the following code that uses raw; pointers:. ```c++; void UniqueOwnership1() {; int *pi = new int;; if (...) {; Borrow(pi);; delete pi;; } else {; TakeOwnership(pi);; }; }; ```. into code that uses `unique_ptr`:. ```c++; void UniqueOwnership1() {; auto pi = std::make_unique<int>();; if (...) {; Borrow(pi.get());; } else {; TakeOwnership(pi.release());; }; }; ```. This problem can be solved with a lattice in form of map from value declarations; to pointer states:. ![Lattice that identifies candidates for unique_ptr refactoring](DataFlowAnalysisIntroImages/UniquePtrLattice.svg). We can perform the refactoring if at the exit of a function `pi` is; `Compatible`. ```c++; void UniqueOwnership1() {; int *pi; // pi is Compatible; pi = new int; // pi is Defined; if (...) {; Borrow(pi); // pi is Defined; delete pi; // pi is Compatible; } else {; TakeOwnership(pi); // pi is Compatible; }; // pi is Compatible; }; ```. Let's look at an example where the raw pointer owns two different memory blocks:. ```c++; void UniqueOwnership2() {; int *pi = new int; // pi is Defined; Borrow(pi);; delete pi; // pi is Compatible; if (smth) {; pi = new int; // pi is Defined; Borrow(pi);; delete pi; // pi is Compatible; }; // pi is Compatible; }; ```. It can be refactored to use `unique_ptr` like this:. ```c++; void UniqueOwnership2() {; auto pi = make_unique<int>();; Borrow(pi);; if (smth) {; pi = make_unique<int>();; Borrow(pi);; }; }; ```. In the following example, the raw pointer is used to access the heap object; after the ownership has been transferred. ```c++; void UniqueOwnership3() {; int *pi = new int; // pi is Defined",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:24568,Performance,perform,perform,24568,"ector<unique_ptr<int>> v = {std::unique_ptr(pi)}; // pi is Compatible; print(*pi);; use(v);; }; // pi is Compatible; }; ```. We can refactor this code to use `unique_ptr`, however we would have to; introduce a non-owning pointer variable, since we can't use the moved-from; `unique_ptr` to access the object:. ```c++; void UniqueOwnership3() {; std::unique_ptr<int> pi = std::make_unique<int>();; if (...) {; Borrow(pi);; } else {; int *pi_non_owning = pi.get();; vector<unique_ptr<int>> v = {std::move(pi)};; print(*pi_non_owning);; use(v);; }; }; ```. If the original code didn't call `delete` at the very end of the function, then; our refactoring may change the point at which we run the destructor and release; memory. Specifically, if there is some user code after `delete`, then extending; the lifetime of the object until the end of the function may hold locks for; longer than necessary, introduce memory overhead etc. One solution is to always replace `delete` with a call to `reset()`, and then; perform another analysis that removes unnecessary `reset()` calls. ```c++; void AddedMemoryOverhead() {; HugeObject *ho = new HugeObject();; use(ho);; delete ho; // Release the large amount of memory quickly.; LongRunningFunction();; }; ```. This analysis will refuse to refactor code that mixes borrowed pointer values; and unique ownership. In the following code, `GetPtr()` returns a borrowed; pointer, which is assigned to `pi`. Then, `pi` is used to hold a uniquely-owned; pointer. We don't distinguish between these two assignments, and we want each; assignment to be paired with a corresponding sink; otherwise, we transition the; pointer to a `Conflicting` state, like in this example. ```c++; void ConflictingOwnership() {; int *pi; // pi is Compatible; pi = GetPtr(); // pi is Defined; Borrow(pi); // pi is Defined. pi = new int; // pi is Conflicting; Borrow(pi);; delete pi;; // pi is Conflicting; }; ```. We could still handle this case by finding a maximal range in the code where",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:28858,Performance,perform,performs,28858,"nding dead code behind A/B experiment flags. Finding dead code is a classic application of data flow analysis. Unused flags for A/B experiment hide dead code. However, this flavor of dead; code is invisible to the compiler because the flag can be turned on at any; moment. We could make a tool that deletes experiment flags. The user tells us which flag; they want to delete, and we assume that the it's value is a given constant. For example, the user could use the tool to remove `example_flag` from this; code:. ```c++; DEFINE_FLAG(std::string, example_flag, """", ""A sample flag."");. void Example() {; bool x = GetFlag(FLAGS_example_flag).empty();; f();; if (x) {; g();; } else {; h();; }; }; ```. The tool would simplify the code to:. ```c++; void Example() {; f();; g();; }; ```. We can solve this problem with a classic constant propagation lattice combined; with symbolic evaluation. ## Example: finding inefficient usages of associative containers. Real-world code often accidentally performs repeated lookups in associative; containers:. ```c++; map<int, Employee> xs;; xs[42]->name = ""..."";; xs[42]->title = ""..."";; ```. To find the above inefficiency we can use the available expressions analysis to; understand that `m[42]` is evaluated twice. ```c++; map<int, Employee> xs;; Employee &e = xs[42];; e->name = ""..."";; e->title = ""..."";; ```. We can also track the `m.contains()` check in the flow condition to find; redundant checks, like in the example below. ```c++; std::map<int, Employee> xs;; if (!xs.contains(42)) {; xs.insert({42, someEmployee});; }; ```. ## Example: refactoring types that implicitly convert to each other. Refactoring one strong type to another is difficult, but the compiler can help:; once you refactor one reference to the type, the compiler will flag other places; where this information flows with type mismatch errors. Unfortunately this; strategy does not work when you are refactoring types that implicitly convert to; each other, for example, replacing `i",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:30341,Performance,perform,perform,30341,"++; DEFINE_FLAG(std::string, example_flag, """", ""A sample flag."");. void Example() {; bool x = GetFlag(FLAGS_example_flag).empty();; f();; if (x) {; g();; } else {; h();; }; }; ```. The tool would simplify the code to:. ```c++; void Example() {; f();; g();; }; ```. We can solve this problem with a classic constant propagation lattice combined; with symbolic evaluation. ## Example: finding inefficient usages of associative containers. Real-world code often accidentally performs repeated lookups in associative; containers:. ```c++; map<int, Employee> xs;; xs[42]->name = ""..."";; xs[42]->title = ""..."";; ```. To find the above inefficiency we can use the available expressions analysis to; understand that `m[42]` is evaluated twice. ```c++; map<int, Employee> xs;; Employee &e = xs[42];; e->name = ""..."";; e->title = ""..."";; ```. We can also track the `m.contains()` check in the flow condition to find; redundant checks, like in the example below. ```c++; std::map<int, Employee> xs;; if (!xs.contains(42)) {; xs.insert({42, someEmployee});; }; ```. ## Example: refactoring types that implicitly convert to each other. Refactoring one strong type to another is difficult, but the compiler can help:; once you refactor one reference to the type, the compiler will flag other places; where this information flows with type mismatch errors. Unfortunately this; strategy does not work when you are refactoring types that implicitly convert to; each other, for example, replacing `int32_t` with `int64_t`. Imagine that we want to change user IDs from 32 to 64-bit integers. In other; words, we need to find all integers tainted with user IDs. We can use data flow; analysis to implement taint analysis. ```c++; void UseUser(int32_t user_id) {; int32_t id = user_id;; // Variable `id` is tainted with a user ID.; ...; }; ```. Taint analysis is very well suited to this problem because the program rarely; branches on user IDs, and almost certainly does not perform any computation; (like arithmetic).; ",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:17321,Safety,unsafe,unsafe,17321,"overwrites the pointee on all paths; before returning. * Prove that the function reads the pointee only after overwriting it. * Prove that the function does not persist the pointer in a data structure; that is live after the function returns. There are also requirements that all usage sites of the candidate function must; satisfy, for example, that function arguments do not alias, that users are not; taking the address of the function, and so on. Let's consider verifying usage; site conditions to be a separate static analysis problem. ### Lattice design. To analyze the function body we can use a lattice which consists of normal; states and failure states. A normal state describes program points where we are; sure that no behaviors that block the refactoring have occurred. Normal states; keep track of all parameter's member fields that are known to be overwritten on; every path from function entry to the corresponding program point. Failure; states accumulate observed violations (unsafe reads and pointer escapes) that; block the refactoring. In the partial order of the lattice failure states compare greater than normal; states, which guarantees that they ""win"" when joined with normal states. Order; between failure states is determined by inclusion relation on the set of; accumulated violations (lattice's `⩽` is `⊆` on the set of violations). Order; between normal states is determined by reversed inclusion relation on the set of; overwritten parameter's member fields (lattice's `⩽` is `⊇` on the set of; overwritten fields). ![Lattice for data flow analysis that identifies output parameters](DataFlowAnalysisIntroImages/OutputParameterIdentificationLattice.svg). To determine whether a statement reads or writes a field we can implement; symbolic evaluation of `DeclRefExpr`s, `LValueToRValue` casts, pointer; dereference operator and `MemberExpr`s. ### Using data flow results to identify output parameters. Let's take a look at how we use data flow analysis to identify an ou",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:18368,Safety,safe,safely,18368,"s compare greater than normal; states, which guarantees that they ""win"" when joined with normal states. Order; between failure states is determined by inclusion relation on the set of; accumulated violations (lattice's `⩽` is `⊆` on the set of violations). Order; between normal states is determined by reversed inclusion relation on the set of; overwritten parameter's member fields (lattice's `⩽` is `⊇` on the set of; overwritten fields). ![Lattice for data flow analysis that identifies output parameters](DataFlowAnalysisIntroImages/OutputParameterIdentificationLattice.svg). To determine whether a statement reads or writes a field we can implement; symbolic evaluation of `DeclRefExpr`s, `LValueToRValue` casts, pointer; dereference operator and `MemberExpr`s. ### Using data flow results to identify output parameters. Let's take a look at how we use data flow analysis to identify an output; parameter. The refactoring can be safely done when the data flow algorithm; computes a normal state with all of the fields proven to be overwritten in the; exit basic block of the function. ```c++; struct Customer {; int account_id;; std::string name;; };. void GetCustomer(Customer* c) {; // Overwritten: {}; c->account_id = ...; // Overwritten: {c->account_id}; if (...) {; c->name = ...; // Overwritten: {c->account_id, c->name}; } else {; c->name = ...; // Overwritten: {c->account_id, c->name}; }; // Overwritten: {c->account_id, c->name}; }; ```. When the data flow algorithm computes a normal state, but not all fields are; proven to be overwritten we can't perform the refactoring. ```c++; void target(bool b, Customer* c) {; // Overwritten: {}; if (b) {; c->account_id = 42; // Overwritten: {c->account_id}; } else {; c->name = ""Konrad""; // Overwritten: {c->name}; }; // Overwritten: {}; }; ```. Similarly, when the data flow algorithm computes a failure state, we also can't; perform the refactoring. ```c++; Customer* kGlobalCustomer;. void GetCustomer(Customer* c) {; // Overwritten: {}; ",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:19684,Safety,redund,redundant,19684,"if (...) {; c->name = ...; // Overwritten: {c->account_id, c->name}; } else {; c->name = ...; // Overwritten: {c->account_id, c->name}; }; // Overwritten: {c->account_id, c->name}; }; ```. When the data flow algorithm computes a normal state, but not all fields are; proven to be overwritten we can't perform the refactoring. ```c++; void target(bool b, Customer* c) {; // Overwritten: {}; if (b) {; c->account_id = 42; // Overwritten: {c->account_id}; } else {; c->name = ""Konrad""; // Overwritten: {c->name}; }; // Overwritten: {}; }; ```. Similarly, when the data flow algorithm computes a failure state, we also can't; perform the refactoring. ```c++; Customer* kGlobalCustomer;. void GetCustomer(Customer* c) {; // Overwritten: {}; c->account_id = ...; // Overwritten: {c->account_id}; if (...) {; print(c->name); // Unsafe read; } else {; kGlobalCustomer = c; // Pointer escape; }; // Unsafe read, Pointer escape; }; ```. ## Example: finding dead stores. Let's say we want to find redundant stores, because they indicate potential; bugs. ```c++; x = GetX();; x = GetY();; ```. The first store to `x` is never read, probably there is a bug. The implementation of dead store analysis is very similar to output parameter; analysis: we need to track stores and loads, and find stores that were never; read. [Liveness analysis](https://en.wikipedia.org/wiki/Live_variable_analysis) is a; generalization of this idea, which is often used to answer many related; questions, for example:. * finding dead stores,; * finding uninitialized variables,; * finding a good point to deallocate memory,; * finding out if it would be safe to move an object. ## Example: definitive initialization. Definitive initialization proves that variables are known to be initialized when; read. If we find a variable which is read when not initialized then we generate; a warning. ```c++; void Init() {; int x; // x is uninitialized; if (cond()) {; x = 10; // x is initialized; } else {; x = 20; // x is initialized; }; prin",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:20319,Safety,safe,safe,20319,"a flow algorithm computes a failure state, we also can't; perform the refactoring. ```c++; Customer* kGlobalCustomer;. void GetCustomer(Customer* c) {; // Overwritten: {}; c->account_id = ...; // Overwritten: {c->account_id}; if (...) {; print(c->name); // Unsafe read; } else {; kGlobalCustomer = c; // Pointer escape; }; // Unsafe read, Pointer escape; }; ```. ## Example: finding dead stores. Let's say we want to find redundant stores, because they indicate potential; bugs. ```c++; x = GetX();; x = GetY();; ```. The first store to `x` is never read, probably there is a bug. The implementation of dead store analysis is very similar to output parameter; analysis: we need to track stores and loads, and find stores that were never; read. [Liveness analysis](https://en.wikipedia.org/wiki/Live_variable_analysis) is a; generalization of this idea, which is often used to answer many related; questions, for example:. * finding dead stores,; * finding uninitialized variables,; * finding a good point to deallocate memory,; * finding out if it would be safe to move an object. ## Example: definitive initialization. Definitive initialization proves that variables are known to be initialized when; read. If we find a variable which is read when not initialized then we generate; a warning. ```c++; void Init() {; int x; // x is uninitialized; if (cond()) {; x = 10; // x is initialized; } else {; x = 20; // x is initialized; }; print(x); // x is initialized; }; ```. ```c++; void Uninit() {; int x; // x is uninitialized; if (cond()) {; x = 10; // x is initialized; }; print(x); // x is maybe uninitialized, x is being read, report a bug.; }; ```. For this purpose we can use lattice in a form of a mapping from variable; declarations to initialization states; each initialization state is represented; by the following lattice:. ![Lattice for definitive initialization analysis](DataFlowAnalysisIntroImages/DefinitiveInitializationLattice.svg). A lattice element could also capture the source lo",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:25825,Safety,redund,redundant,25825," refuse to refactor code that mixes borrowed pointer values; and unique ownership. In the following code, `GetPtr()` returns a borrowed; pointer, which is assigned to `pi`. Then, `pi` is used to hold a uniquely-owned; pointer. We don't distinguish between these two assignments, and we want each; assignment to be paired with a corresponding sink; otherwise, we transition the; pointer to a `Conflicting` state, like in this example. ```c++; void ConflictingOwnership() {; int *pi; // pi is Compatible; pi = GetPtr(); // pi is Defined; Borrow(pi); // pi is Defined. pi = new int; // pi is Conflicting; Borrow(pi);; delete pi;; // pi is Conflicting; }; ```. We could still handle this case by finding a maximal range in the code where; `pi` could be in the Compatible state, and only refactoring that part. ```c++; void ConflictingOwnership() {; int *pi;; pi = GetPtr();; Borrow(pi);. std::unique_ptr<int> pi_unique = std::make_unique<int>();; Borrow(pi_unique.get());; }; ```. ## Example: finding redundant branch conditions. In the code below `b1` should not be checked in both the outer and inner ""if""; statements. It is likely there is a bug in this code. ```c++; int F(bool b1, bool b2) {; if (b1) {; f();; if (b1 && b2) { // Check `b1` again -- unnecessary!; g();; }; }; }; ```. A checker that finds this pattern syntactically is already implemented in; ClangTidy using AST matchers (`bugprone-redundant-branch-condition`). To implement it using the data flow analysis framework, we can produce a warning; if any part of the branch condition is implied by the flow condition. ```c++; int F(bool b1, bool b2) {; // Flow condition: true.; if (b1) {; // Flow condition: b1.; f();; if (b1 && b2) { // `b1` is implied by the flow condition.; g();; }; }; }; ```. One way to check this implication is to use a SAT solver. Without a SAT solver,; we could keep the flow condition in the CNF form and then it would be easy to; check the implication. ## Example: finding unchecked `std::optional` unwraps. C",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:26227,Safety,redund,redundant-branch-condition,26227,"se, we transition the; pointer to a `Conflicting` state, like in this example. ```c++; void ConflictingOwnership() {; int *pi; // pi is Compatible; pi = GetPtr(); // pi is Defined; Borrow(pi); // pi is Defined. pi = new int; // pi is Conflicting; Borrow(pi);; delete pi;; // pi is Conflicting; }; ```. We could still handle this case by finding a maximal range in the code where; `pi` could be in the Compatible state, and only refactoring that part. ```c++; void ConflictingOwnership() {; int *pi;; pi = GetPtr();; Borrow(pi);. std::unique_ptr<int> pi_unique = std::make_unique<int>();; Borrow(pi_unique.get());; }; ```. ## Example: finding redundant branch conditions. In the code below `b1` should not be checked in both the outer and inner ""if""; statements. It is likely there is a bug in this code. ```c++; int F(bool b1, bool b2) {; if (b1) {; f();; if (b1 && b2) { // Check `b1` again -- unnecessary!; g();; }; }; }; ```. A checker that finds this pattern syntactically is already implemented in; ClangTidy using AST matchers (`bugprone-redundant-branch-condition`). To implement it using the data flow analysis framework, we can produce a warning; if any part of the branch condition is implied by the flow condition. ```c++; int F(bool b1, bool b2) {; // Flow condition: true.; if (b1) {; // Flow condition: b1.; f();; if (b1 && b2) { // `b1` is implied by the flow condition.; g();; }; }; }; ```. One way to check this implication is to use a SAT solver. Without a SAT solver,; we could keep the flow condition in the CNF form and then it would be easy to; check the implication. ## Example: finding unchecked `std::optional` unwraps. Calling `optional::value()` is only valid if `optional::has_value()` is true. We; want to show that when `x.value()` is executed, the flow condition implies; `x.has_value()`. In the example below `x.value()` is accessed safely because it is guarded by the; `x.has_value()` check. ```c++; void Example(std::optional<int> &x) {; if (x.has_value()) {; use(x.v",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:27048,Safety,safe,safely,27048," Check `b1` again -- unnecessary!; g();; }; }; }; ```. A checker that finds this pattern syntactically is already implemented in; ClangTidy using AST matchers (`bugprone-redundant-branch-condition`). To implement it using the data flow analysis framework, we can produce a warning; if any part of the branch condition is implied by the flow condition. ```c++; int F(bool b1, bool b2) {; // Flow condition: true.; if (b1) {; // Flow condition: b1.; f();; if (b1 && b2) { // `b1` is implied by the flow condition.; g();; }; }; }; ```. One way to check this implication is to use a SAT solver. Without a SAT solver,; we could keep the flow condition in the CNF form and then it would be easy to; check the implication. ## Example: finding unchecked `std::optional` unwraps. Calling `optional::value()` is only valid if `optional::has_value()` is true. We; want to show that when `x.value()` is executed, the flow condition implies; `x.has_value()`. In the example below `x.value()` is accessed safely because it is guarded by the; `x.has_value()` check. ```c++; void Example(std::optional<int> &x) {; if (x.has_value()) {; use(x.value());; }; }; ```. While entering the if branch we deduce that `x.has_value()` is implied by the; flow condition. ```c++; void Example(std::optional<int> x) {; // Flow condition: true.; if (x.has_value()) {; // Flow condition: x.has_value() == true.; use(x.value());; }; // Flow condition: true.; }; ```. We also need to prove that `x` is not modified between check and value access.; The modification of `x` may be very subtle:. ```c++; void F(std::optional<int> &x);. void Example(std::optional<int> &x) {; if (x.has_value()) {; // Flow condition: x.has_value() == true.; unknown_function(x); // may change x.; // Flow condition: true.; use(x.value());; }; }; ```. ## Example: finding dead code behind A/B experiment flags. Finding dead code is a classic application of data flow analysis. Unused flags for A/B experiment hide dead code. However, this flavor of dead; co",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:29293,Safety,redund,redundant,29293,"nstant. For example, the user could use the tool to remove `example_flag` from this; code:. ```c++; DEFINE_FLAG(std::string, example_flag, """", ""A sample flag."");. void Example() {; bool x = GetFlag(FLAGS_example_flag).empty();; f();; if (x) {; g();; } else {; h();; }; }; ```. The tool would simplify the code to:. ```c++; void Example() {; f();; g();; }; ```. We can solve this problem with a classic constant propagation lattice combined; with symbolic evaluation. ## Example: finding inefficient usages of associative containers. Real-world code often accidentally performs repeated lookups in associative; containers:. ```c++; map<int, Employee> xs;; xs[42]->name = ""..."";; xs[42]->title = ""..."";; ```. To find the above inefficiency we can use the available expressions analysis to; understand that `m[42]` is evaluated twice. ```c++; map<int, Employee> xs;; Employee &e = xs[42];; e->name = ""..."";; e->title = ""..."";; ```. We can also track the `m.contains()` check in the flow condition to find; redundant checks, like in the example below. ```c++; std::map<int, Employee> xs;; if (!xs.contains(42)) {; xs.insert({42, someEmployee});; }; ```. ## Example: refactoring types that implicitly convert to each other. Refactoring one strong type to another is difficult, but the compiler can help:; once you refactor one reference to the type, the compiler will flag other places; where this information flows with type mismatch errors. Unfortunately this; strategy does not work when you are refactoring types that implicitly convert to; each other, for example, replacing `int32_t` with `int64_t`. Imagine that we want to change user IDs from 32 to 64-bit integers. In other; words, we need to find all integers tainted with user IDs. We can use data flow; analysis to implement taint analysis. ```c++; void UseUser(int32_t user_id) {; int32_t id = user_id;; // Variable `id` is tainted with a user ID.; ...; }; ```. Taint analysis is very well suited to this problem because the program rarely; br",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:23355,Security,access,access,23355,"candidates for unique_ptr refactoring](DataFlowAnalysisIntroImages/UniquePtrLattice.svg). We can perform the refactoring if at the exit of a function `pi` is; `Compatible`. ```c++; void UniqueOwnership1() {; int *pi; // pi is Compatible; pi = new int; // pi is Defined; if (...) {; Borrow(pi); // pi is Defined; delete pi; // pi is Compatible; } else {; TakeOwnership(pi); // pi is Compatible; }; // pi is Compatible; }; ```. Let's look at an example where the raw pointer owns two different memory blocks:. ```c++; void UniqueOwnership2() {; int *pi = new int; // pi is Defined; Borrow(pi);; delete pi; // pi is Compatible; if (smth) {; pi = new int; // pi is Defined; Borrow(pi);; delete pi; // pi is Compatible; }; // pi is Compatible; }; ```. It can be refactored to use `unique_ptr` like this:. ```c++; void UniqueOwnership2() {; auto pi = make_unique<int>();; Borrow(pi);; if (smth) {; pi = make_unique<int>();; Borrow(pi);; }; }; ```. In the following example, the raw pointer is used to access the heap object; after the ownership has been transferred. ```c++; void UniqueOwnership3() {; int *pi = new int; // pi is Defined; if (...) {; Borrow(pi);; delete pi; // pi is Compatible; } else {; vector<unique_ptr<int>> v = {std::unique_ptr(pi)}; // pi is Compatible; print(*pi);; use(v);; }; // pi is Compatible; }; ```. We can refactor this code to use `unique_ptr`, however we would have to; introduce a non-owning pointer variable, since we can't use the moved-from; `unique_ptr` to access the object:. ```c++; void UniqueOwnership3() {; std::unique_ptr<int> pi = std::make_unique<int>();; if (...) {; Borrow(pi);; } else {; int *pi_non_owning = pi.get();; vector<unique_ptr<int>> v = {std::move(pi)};; print(*pi_non_owning);; use(v);; }; }; ```. If the original code didn't call `delete` at the very end of the function, then; our refactoring may change the point at which we run the destructor and release; memory. Specifically, if there is some user code after `delete`, then extending; the",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:23851,Security,access,access,23851," }; ```. Let's look at an example where the raw pointer owns two different memory blocks:. ```c++; void UniqueOwnership2() {; int *pi = new int; // pi is Defined; Borrow(pi);; delete pi; // pi is Compatible; if (smth) {; pi = new int; // pi is Defined; Borrow(pi);; delete pi; // pi is Compatible; }; // pi is Compatible; }; ```. It can be refactored to use `unique_ptr` like this:. ```c++; void UniqueOwnership2() {; auto pi = make_unique<int>();; Borrow(pi);; if (smth) {; pi = make_unique<int>();; Borrow(pi);; }; }; ```. In the following example, the raw pointer is used to access the heap object; after the ownership has been transferred. ```c++; void UniqueOwnership3() {; int *pi = new int; // pi is Defined; if (...) {; Borrow(pi);; delete pi; // pi is Compatible; } else {; vector<unique_ptr<int>> v = {std::unique_ptr(pi)}; // pi is Compatible; print(*pi);; use(v);; }; // pi is Compatible; }; ```. We can refactor this code to use `unique_ptr`, however we would have to; introduce a non-owning pointer variable, since we can't use the moved-from; `unique_ptr` to access the object:. ```c++; void UniqueOwnership3() {; std::unique_ptr<int> pi = std::make_unique<int>();; if (...) {; Borrow(pi);; } else {; int *pi_non_owning = pi.get();; vector<unique_ptr<int>> v = {std::move(pi)};; print(*pi_non_owning);; use(v);; }; }; ```. If the original code didn't call `delete` at the very end of the function, then; our refactoring may change the point at which we run the destructor and release; memory. Specifically, if there is some user code after `delete`, then extending; the lifetime of the object until the end of the function may hold locks for; longer than necessary, introduce memory overhead etc. One solution is to always replace `delete` with a call to `reset()`, and then; perform another analysis that removes unnecessary `reset()` calls. ```c++; void AddedMemoryOverhead() {; HugeObject *ho = new HugeObject();; use(ho);; delete ho; // Release the large amount of memory quickly.; ",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:27039,Security,access,accessed,27039," Check `b1` again -- unnecessary!; g();; }; }; }; ```. A checker that finds this pattern syntactically is already implemented in; ClangTidy using AST matchers (`bugprone-redundant-branch-condition`). To implement it using the data flow analysis framework, we can produce a warning; if any part of the branch condition is implied by the flow condition. ```c++; int F(bool b1, bool b2) {; // Flow condition: true.; if (b1) {; // Flow condition: b1.; f();; if (b1 && b2) { // `b1` is implied by the flow condition.; g();; }; }; }; ```. One way to check this implication is to use a SAT solver. Without a SAT solver,; we could keep the flow condition in the CNF form and then it would be easy to; check the implication. ## Example: finding unchecked `std::optional` unwraps. Calling `optional::value()` is only valid if `optional::has_value()` is true. We; want to show that when `x.value()` is executed, the flow condition implies; `x.has_value()`. In the example below `x.value()` is accessed safely because it is guarded by the; `x.has_value()` check. ```c++; void Example(std::optional<int> &x) {; if (x.has_value()) {; use(x.value());; }; }; ```. While entering the if branch we deduce that `x.has_value()` is implied by the; flow condition. ```c++; void Example(std::optional<int> x) {; // Flow condition: true.; if (x.has_value()) {; // Flow condition: x.has_value() == true.; use(x.value());; }; // Flow condition: true.; }; ```. We also need to prove that `x` is not modified between check and value access.; The modification of `x` may be very subtle:. ```c++; void F(std::optional<int> &x);. void Example(std::optional<int> &x) {; if (x.has_value()) {; // Flow condition: x.has_value() == true.; unknown_function(x); // may change x.; // Flow condition: true.; use(x.value());; }; }; ```. ## Example: finding dead code behind A/B experiment flags. Finding dead code is a classic application of data flow analysis. Unused flags for A/B experiment hide dead code. However, this flavor of dead; co",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:27562,Security,access,access,27562," `b1` is implied by the flow condition.; g();; }; }; }; ```. One way to check this implication is to use a SAT solver. Without a SAT solver,; we could keep the flow condition in the CNF form and then it would be easy to; check the implication. ## Example: finding unchecked `std::optional` unwraps. Calling `optional::value()` is only valid if `optional::has_value()` is true. We; want to show that when `x.value()` is executed, the flow condition implies; `x.has_value()`. In the example below `x.value()` is accessed safely because it is guarded by the; `x.has_value()` check. ```c++; void Example(std::optional<int> &x) {; if (x.has_value()) {; use(x.value());; }; }; ```. While entering the if branch we deduce that `x.has_value()` is implied by the; flow condition. ```c++; void Example(std::optional<int> x) {; // Flow condition: true.; if (x.has_value()) {; // Flow condition: x.has_value() == true.; use(x.value());; }; // Flow condition: true.; }; ```. We also need to prove that `x` is not modified between check and value access.; The modification of `x` may be very subtle:. ```c++; void F(std::optional<int> &x);. void Example(std::optional<int> &x) {; if (x.has_value()) {; // Flow condition: x.has_value() == true.; unknown_function(x); // may change x.; // Flow condition: true.; use(x.value());; }; }; ```. ## Example: finding dead code behind A/B experiment flags. Finding dead code is a classic application of data flow analysis. Unused flags for A/B experiment hide dead code. However, this flavor of dead; code is invisible to the compiler because the flag can be turned on at any; moment. We could make a tool that deletes experiment flags. The user tells us which flag; they want to delete, and we assume that the it's value is a given constant. For example, the user could use the tool to remove `example_flag` from this; code:. ```c++; DEFINE_FLAG(std::string, example_flag, """", ""A sample flag."");. void Example() {; bool x = GetFlag(FLAGS_example_flag).empty();; f();; if (x)",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:160,Usability,intuit,intuitive,160,"# Data flow analysis: an informal introduction. ## Abstract. This document introduces data flow analysis in an informal way. The goal is to; give the reader an intuitive understanding of how it works, and show how it; applies to a range of refactoring and bug finding problems. Data flow analysis is a well-established technique; it is described in many; papers, books, and videos. If you would like a more formal, or a more thorough; explanation of the concepts mentioned in this document, please refer to the; following resources:. * [The Lattice article in Wikipedia](https://en.wikipedia.org/wiki/Lattice_\(order\)).; * Videos on the PacketPrep YouTube channel that introduce lattices and the; necessary background information:; [#20](https://www.youtube.com/watch?v=73j_FXBXGm8),; [#21](https://www.youtube.com/watch?v=b5sDjo9tfE8),; [#22](https://www.youtube.com/watch?v=saOG7Uooeho),; [#23](https://www.youtube.com/watch?v=3EAYX-wZH0g),; [#24](https://www.youtube.com/watch?v=KRkHwQtW6Cc),; [#25](https://www.youtube.com/watch?v=7Gwzsc4rAgw).; * [Introduction to Dataflow Analysis](https://www.youtube.com/watch?v=OROXJ9-wUQE); * [Introduction to abstract interpretation](http://www.cs.tau.ac.il/~msagiv/courses/asv/absint-1.pdf).; * [Introduction to symbolic execution](https://www.cs.umd.edu/~mwh/se-tutorial/symbolic-exec.pdf).; * [Static Program Analysis by Anders Møller and Michael I. Schwartzbach](https://cs.au.dk/~amoeller/spa/).; * [EXE: automatically generating inputs of death](https://css.csail.mit.edu/6.858/2020/readings/exe.pdf); (a paper that successfully applies symbolic execution to real-world; software). ## Data flow analysis. ### The purpose of data flow analysis. Data flow analysis is a static analysis technique that proves facts about a; program or its fragment. It can make conclusions about all paths through the; program, while taking control flow into account and scaling to large programs.; The basic idea is propagating facts about the program through the edges",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:12009,Usability,guid,guide,12009," Symbolic values. In the previous example where we tried to figure out what values a variable can; have, the analysis had to be seeded with a concrete value. What if there are no; assignments of concrete values in the program? We can still deduce some; interesting information by representing unknown input values symbolically, and; computing results as symbolic expressions:. ```c++; void PrintAbs(int x) {; int result;; if (x >= 0) {; result = x; // result is {x}; } else {; result = -x; // result is {-x}; }; print(result); // result is {x; -x}; }; ```. We can't say what specific value gets printed, but we know that it is either `x`; or `-x`. Dataflow analysis is an instance of abstract interpretation, and does not dictate; how exactly the lattice and transfer functions should be designed, beyond the; necessary conditions for the analysis to converge. Nevertheless, we can use; symbolic execution ideas to guide our design of the lattice and transfer; functions: lattice values can be symbolic expressions, and transfer functions; can construct more complex symbolic expressions from symbolic expressions that; represent arguments. See [this StackOverflow; discussion](https://cstheory.stackexchange.com/questions/19708/symbolic-execution-is-a-case-of-abstract-interpretation); for a further comparison of abstract interpretation and symbolic execution. ### Flow condition. A human can say about the previous example that the function returns `x` when; `x >= 0`, and `-x` when `x < 0`. We can make this conclusion programmatically by; tracking a flow condition. A flow condition is a predicate written in terms of; the program state that is true at a specific program point regardless of the; execution path that led to this statement. For example, the flow condition for; the program point right before evaluating `result = x` is `x >= 0`. If we enhance the lattice to be a set of pairs of values and predicates, the; dataflow analysis computes the following values:. ```c++; void PrintAbs(",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:28582,Usability,simpl,simplify,28582,"on of `x` may be very subtle:. ```c++; void F(std::optional<int> &x);. void Example(std::optional<int> &x) {; if (x.has_value()) {; // Flow condition: x.has_value() == true.; unknown_function(x); // may change x.; // Flow condition: true.; use(x.value());; }; }; ```. ## Example: finding dead code behind A/B experiment flags. Finding dead code is a classic application of data flow analysis. Unused flags for A/B experiment hide dead code. However, this flavor of dead; code is invisible to the compiler because the flag can be turned on at any; moment. We could make a tool that deletes experiment flags. The user tells us which flag; they want to delete, and we assume that the it's value is a given constant. For example, the user could use the tool to remove `example_flag` from this; code:. ```c++; DEFINE_FLAG(std::string, example_flag, """", ""A sample flag."");. void Example() {; bool x = GetFlag(FLAGS_example_flag).empty();; f();; if (x) {; g();; } else {; h();; }; }; ```. The tool would simplify the code to:. ```c++; void Example() {; f();; g();; }; ```. We can solve this problem with a classic constant propagation lattice combined; with symbolic evaluation. ## Example: finding inefficient usages of associative containers. Real-world code often accidentally performs repeated lookups in associative; containers:. ```c++; map<int, Employee> xs;; xs[42]->name = ""..."";; xs[42]->title = ""..."";; ```. To find the above inefficiency we can use the available expressions analysis to; understand that `m[42]` is evaluated twice. ```c++; map<int, Employee> xs;; Employee &e = xs[42];; e->name = ""..."";; e->title = ""..."";; ```. We can also track the `m.contains()` check in the flow condition to find; redundant checks, like in the example below. ```c++; std::map<int, Employee> xs;; if (!xs.contains(42)) {; xs.insert({42, someEmployee});; }; ```. ## Example: refactoring types that implicitly convert to each other. Refactoring one strong type to another is difficult, but the compiler can he",MatchSource.DOCS,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/scan-build-py/README.md:3696,Availability,avail,available,3696,"ompiler calls during the build process.; The analyzer run against each modules after the build finished.; Use `--intercept-first` and `--override-compiler` flags together to get; this model. The 1. and 3. are using compiler wrappers, which works only if the build; process respects the `CC` and `CXX` environment variables. (Some build; process can override these variable as command line parameter only. This case; you need to pass the compiler wrappers manually. eg.: `intercept-build; --override-compiler make CC=intercept-cc CXX=intercept-c++ all` where the; original build command would have been `make all` only.). The 1. runs the analyzer right after the real compilation. So, if the build; process removes removes intermediate modules (generated sources) the analyzer; output still kept. The 2. and 3. generate the compilation database first, and filters out those; modules which are not exists. So, it's suitable for incremental analysis during; the development. The 2. mode is available only on FreeBSD and Linux. Where library preload; is available from the dynamic loader. Not supported on OS X (unless System; Integrity Protection feature is turned off). `intercept-build` command uses only the 2. and 3. mode to generate the; compilation database. `analyze-build` does only run the analyzer against the; captured compiler calls. Known problems; --------------. Because it uses `LD_PRELOAD` or `DYLD_INSERT_LIBRARIES` environment variables,; it does not append to it, but overrides it. So builds which are using these; variables might not work. (I don't know any build tool which does that, but; please let me know if you do.). Problem reports; ---------------. If you find a bug in this documentation or elsewhere in the program or would; like to propose an improvement, please use the project's [issue tracker][3].; Please describing the bug and where you found it. If you have a suggestion; how to fix it, include that as well. Patches are also welcome. License; -------. The project i",MatchSource.DOCS,interpreter/llvm-project/clang/tools/scan-build-py/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/scan-build-py/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/scan-build-py/README.md:3759,Availability,avail,available,3759," run against each modules after the build finished.; Use `--intercept-first` and `--override-compiler` flags together to get; this model. The 1. and 3. are using compiler wrappers, which works only if the build; process respects the `CC` and `CXX` environment variables. (Some build; process can override these variable as command line parameter only. This case; you need to pass the compiler wrappers manually. eg.: `intercept-build; --override-compiler make CC=intercept-cc CXX=intercept-c++ all` where the; original build command would have been `make all` only.). The 1. runs the analyzer right after the real compilation. So, if the build; process removes removes intermediate modules (generated sources) the analyzer; output still kept. The 2. and 3. generate the compilation database first, and filters out those; modules which are not exists. So, it's suitable for incremental analysis during; the development. The 2. mode is available only on FreeBSD and Linux. Where library preload; is available from the dynamic loader. Not supported on OS X (unless System; Integrity Protection feature is turned off). `intercept-build` command uses only the 2. and 3. mode to generate the; compilation database. `analyze-build` does only run the analyzer against the; captured compiler calls. Known problems; --------------. Because it uses `LD_PRELOAD` or `DYLD_INSERT_LIBRARIES` environment variables,; it does not append to it, but overrides it. So builds which are using these; variables might not work. (I don't know any build tool which does that, but; please let me know if you do.). Problem reports; ---------------. If you find a bug in this documentation or elsewhere in the program or would; like to propose an improvement, please use the project's [issue tracker][3].; Please describing the bug and where you found it. If you have a suggestion; how to fix it, include that as well. Patches are also welcome. License; -------. The project is licensed under Apache-2.0 with LLVM exceptions.; Se",MatchSource.DOCS,interpreter/llvm-project/clang/tools/scan-build-py/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/scan-build-py/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/scan-build-py/README.md:46,Integrability,wrap,wrap,46,"scan-build; ==========. A package designed to wrap a build so that all calls to gcc/clang are; intercepted and logged into a [compilation database][1] and/or piped to; the clang static analyzer. Includes intercept-build tool, which logs; the build, as well as scan-build tool, which logs the build and runs; the clang static analyzer on it. Portability; -----------. Should be working on UNIX operating systems. - It has been tested on FreeBSD, GNU/Linux and OS X.; - Prepared to work on windows, but need help to make it. Prerequisites; -------------. 1. **python** interpreter (version 3.6 or later). How to use; ----------. To run the Clang static analyzer against a project goes like this:. $ scan-build <your build command>. To generate a compilation database file goes like this:. $ intercept-build <your build command>. To run the Clang static analyzer against a project with compilation database; goes like this:. $ analyze-build. Use `--help` to know more about the commands. How to use the experimental Cross Translation Unit analysis; -----------------------------------------------------------. To run the CTU analysis, a compilation database file has to be created:. $ intercept-build <your build command>. To run the Clang Static Analyzer against a compilation database; with CTU analysis enabled, execute:; ; $ analyze-build --ctu. For CTU analysis an additional (external definition) collection-phase is required. ; For debugging purposes, it is possible to separately execute the collection ; and the analysis phase. By doing this, the intermediate files used for ; the analysis are kept on the disk in `./ctu-dir`.; ; # Collect and store the data required by the CTU analysis; $ analyze-build --ctu-collect-only; ; # Analyze using the previously collected data; $ analyze-build --ctu-analyze-only. Use `--help` to get more information about the commands. Limitations; -----------. Generally speaking, the `intercept-build` and `analyze-build` tools together; does the same job as `sc",MatchSource.DOCS,interpreter/llvm-project/clang/tools/scan-build-py/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/scan-build-py/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/scan-build-py/README.md:2303,Integrability,wrap,wrappers,2303,"ed, execute:; ; $ analyze-build --ctu. For CTU analysis an additional (external definition) collection-phase is required. ; For debugging purposes, it is possible to separately execute the collection ; and the analysis phase. By doing this, the intermediate files used for ; the analysis are kept on the disk in `./ctu-dir`.; ; # Collect and store the data required by the CTU analysis; $ analyze-build --ctu-collect-only; ; # Analyze using the previously collected data; $ analyze-build --ctu-analyze-only. Use `--help` to get more information about the commands. Limitations; -----------. Generally speaking, the `intercept-build` and `analyze-build` tools together; does the same job as `scan-build` does. So, you can expect the same output; from this line as simple `scan-build` would do:. $ intercept-build <your build command> && analyze-build. The major difference is how and when the analyzer is run. The `scan-build`; tool has three distinct model to run the analyzer:. 1. Use compiler wrappers to make actions.; The compiler wrappers does run the real compiler and the analyzer.; This is the default behaviour, can be enforced with `--override-compiler`; flag. 2. Use special library to intercept compiler calls during the build process.; The analyzer run against each modules after the build finished.; Use `--intercept-first` flag to get this model. 3. Use compiler wrappers to intercept compiler calls during the build process.; The analyzer run against each modules after the build finished.; Use `--intercept-first` and `--override-compiler` flags together to get; this model. The 1. and 3. are using compiler wrappers, which works only if the build; process respects the `CC` and `CXX` environment variables. (Some build; process can override these variable as command line parameter only. This case; you need to pass the compiler wrappers manually. eg.: `intercept-build; --override-compiler make CC=intercept-cc CXX=intercept-c++ all` where the; original build command would have bee",MatchSource.DOCS,interpreter/llvm-project/clang/tools/scan-build-py/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/scan-build-py/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/scan-build-py/README.md:2343,Integrability,wrap,wrappers,2343,"s an additional (external definition) collection-phase is required. ; For debugging purposes, it is possible to separately execute the collection ; and the analysis phase. By doing this, the intermediate files used for ; the analysis are kept on the disk in `./ctu-dir`.; ; # Collect and store the data required by the CTU analysis; $ analyze-build --ctu-collect-only; ; # Analyze using the previously collected data; $ analyze-build --ctu-analyze-only. Use `--help` to get more information about the commands. Limitations; -----------. Generally speaking, the `intercept-build` and `analyze-build` tools together; does the same job as `scan-build` does. So, you can expect the same output; from this line as simple `scan-build` would do:. $ intercept-build <your build command> && analyze-build. The major difference is how and when the analyzer is run. The `scan-build`; tool has three distinct model to run the analyzer:. 1. Use compiler wrappers to make actions.; The compiler wrappers does run the real compiler and the analyzer.; This is the default behaviour, can be enforced with `--override-compiler`; flag. 2. Use special library to intercept compiler calls during the build process.; The analyzer run against each modules after the build finished.; Use `--intercept-first` flag to get this model. 3. Use compiler wrappers to intercept compiler calls during the build process.; The analyzer run against each modules after the build finished.; Use `--intercept-first` and `--override-compiler` flags together to get; this model. The 1. and 3. are using compiler wrappers, which works only if the build; process respects the `CC` and `CXX` environment variables. (Some build; process can override these variable as command line parameter only. This case; you need to pass the compiler wrappers manually. eg.: `intercept-build; --override-compiler make CC=intercept-cc CXX=intercept-c++ all` where the; original build command would have been `make all` only.). The 1. runs the analyzer right a",MatchSource.DOCS,interpreter/llvm-project/clang/tools/scan-build-py/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/scan-build-py/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/scan-build-py/README.md:2686,Integrability,wrap,wrappers,2686," --ctu-collect-only; ; # Analyze using the previously collected data; $ analyze-build --ctu-analyze-only. Use `--help` to get more information about the commands. Limitations; -----------. Generally speaking, the `intercept-build` and `analyze-build` tools together; does the same job as `scan-build` does. So, you can expect the same output; from this line as simple `scan-build` would do:. $ intercept-build <your build command> && analyze-build. The major difference is how and when the analyzer is run. The `scan-build`; tool has three distinct model to run the analyzer:. 1. Use compiler wrappers to make actions.; The compiler wrappers does run the real compiler and the analyzer.; This is the default behaviour, can be enforced with `--override-compiler`; flag. 2. Use special library to intercept compiler calls during the build process.; The analyzer run against each modules after the build finished.; Use `--intercept-first` flag to get this model. 3. Use compiler wrappers to intercept compiler calls during the build process.; The analyzer run against each modules after the build finished.; Use `--intercept-first` and `--override-compiler` flags together to get; this model. The 1. and 3. are using compiler wrappers, which works only if the build; process respects the `CC` and `CXX` environment variables. (Some build; process can override these variable as command line parameter only. This case; you need to pass the compiler wrappers manually. eg.: `intercept-build; --override-compiler make CC=intercept-cc CXX=intercept-c++ all` where the; original build command would have been `make all` only.). The 1. runs the analyzer right after the real compilation. So, if the build; process removes removes intermediate modules (generated sources) the analyzer; output still kept. The 2. and 3. generate the compilation database first, and filters out those; modules which are not exists. So, it's suitable for incremental analysis during; the development. The 2. mode is available only",MatchSource.DOCS,interpreter/llvm-project/clang/tools/scan-build-py/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/scan-build-py/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/scan-build-py/README.md:2933,Integrability,wrap,wrappers,2933,"her; does the same job as `scan-build` does. So, you can expect the same output; from this line as simple `scan-build` would do:. $ intercept-build <your build command> && analyze-build. The major difference is how and when the analyzer is run. The `scan-build`; tool has three distinct model to run the analyzer:. 1. Use compiler wrappers to make actions.; The compiler wrappers does run the real compiler and the analyzer.; This is the default behaviour, can be enforced with `--override-compiler`; flag. 2. Use special library to intercept compiler calls during the build process.; The analyzer run against each modules after the build finished.; Use `--intercept-first` flag to get this model. 3. Use compiler wrappers to intercept compiler calls during the build process.; The analyzer run against each modules after the build finished.; Use `--intercept-first` and `--override-compiler` flags together to get; this model. The 1. and 3. are using compiler wrappers, which works only if the build; process respects the `CC` and `CXX` environment variables. (Some build; process can override these variable as command line parameter only. This case; you need to pass the compiler wrappers manually. eg.: `intercept-build; --override-compiler make CC=intercept-cc CXX=intercept-c++ all` where the; original build command would have been `make all` only.). The 1. runs the analyzer right after the real compilation. So, if the build; process removes removes intermediate modules (generated sources) the analyzer; output still kept. The 2. and 3. generate the compilation database first, and filters out those; modules which are not exists. So, it's suitable for incremental analysis during; the development. The 2. mode is available only on FreeBSD and Linux. Where library preload; is available from the dynamic loader. Not supported on OS X (unless System; Integrity Protection feature is turned off). `intercept-build` command uses only the 2. and 3. mode to generate the; compilation database. `a",MatchSource.DOCS,interpreter/llvm-project/clang/tools/scan-build-py/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/scan-build-py/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/scan-build-py/README.md:3155,Integrability,wrap,wrappers,3155," analyze-build. The major difference is how and when the analyzer is run. The `scan-build`; tool has three distinct model to run the analyzer:. 1. Use compiler wrappers to make actions.; The compiler wrappers does run the real compiler and the analyzer.; This is the default behaviour, can be enforced with `--override-compiler`; flag. 2. Use special library to intercept compiler calls during the build process.; The analyzer run against each modules after the build finished.; Use `--intercept-first` flag to get this model. 3. Use compiler wrappers to intercept compiler calls during the build process.; The analyzer run against each modules after the build finished.; Use `--intercept-first` and `--override-compiler` flags together to get; this model. The 1. and 3. are using compiler wrappers, which works only if the build; process respects the `CC` and `CXX` environment variables. (Some build; process can override these variable as command line parameter only. This case; you need to pass the compiler wrappers manually. eg.: `intercept-build; --override-compiler make CC=intercept-cc CXX=intercept-c++ all` where the; original build command would have been `make all` only.). The 1. runs the analyzer right after the real compilation. So, if the build; process removes removes intermediate modules (generated sources) the analyzer; output still kept. The 2. and 3. generate the compilation database first, and filters out those; modules which are not exists. So, it's suitable for incremental analysis during; the development. The 2. mode is available only on FreeBSD and Linux. Where library preload; is available from the dynamic loader. Not supported on OS X (unless System; Integrity Protection feature is turned off). `intercept-build` command uses only the 2. and 3. mode to generate the; compilation database. `analyze-build` does only run the analyzer against the; captured compiler calls. Known problems; --------------. Because it uses `LD_PRELOAD` or `DYLD_INSERT_LIBRARIES` env",MatchSource.DOCS,interpreter/llvm-project/clang/tools/scan-build-py/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/scan-build-py/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/scan-build-py/README.md:3022,Modifiability,variab,variables,3022,"her; does the same job as `scan-build` does. So, you can expect the same output; from this line as simple `scan-build` would do:. $ intercept-build <your build command> && analyze-build. The major difference is how and when the analyzer is run. The `scan-build`; tool has three distinct model to run the analyzer:. 1. Use compiler wrappers to make actions.; The compiler wrappers does run the real compiler and the analyzer.; This is the default behaviour, can be enforced with `--override-compiler`; flag. 2. Use special library to intercept compiler calls during the build process.; The analyzer run against each modules after the build finished.; Use `--intercept-first` flag to get this model. 3. Use compiler wrappers to intercept compiler calls during the build process.; The analyzer run against each modules after the build finished.; Use `--intercept-first` and `--override-compiler` flags together to get; this model. The 1. and 3. are using compiler wrappers, which works only if the build; process respects the `CC` and `CXX` environment variables. (Some build; process can override these variable as command line parameter only. This case; you need to pass the compiler wrappers manually. eg.: `intercept-build; --override-compiler make CC=intercept-cc CXX=intercept-c++ all` where the; original build command would have been `make all` only.). The 1. runs the analyzer right after the real compilation. So, if the build; process removes removes intermediate modules (generated sources) the analyzer; output still kept. The 2. and 3. generate the compilation database first, and filters out those; modules which are not exists. So, it's suitable for incremental analysis during; the development. The 2. mode is available only on FreeBSD and Linux. Where library preload; is available from the dynamic loader. Not supported on OS X (unless System; Integrity Protection feature is turned off). `intercept-build` command uses only the 2. and 3. mode to generate the; compilation database. `a",MatchSource.DOCS,interpreter/llvm-project/clang/tools/scan-build-py/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/scan-build-py/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/scan-build-py/README.md:3073,Modifiability,variab,variable,3073,"imple `scan-build` would do:. $ intercept-build <your build command> && analyze-build. The major difference is how and when the analyzer is run. The `scan-build`; tool has three distinct model to run the analyzer:. 1. Use compiler wrappers to make actions.; The compiler wrappers does run the real compiler and the analyzer.; This is the default behaviour, can be enforced with `--override-compiler`; flag. 2. Use special library to intercept compiler calls during the build process.; The analyzer run against each modules after the build finished.; Use `--intercept-first` flag to get this model. 3. Use compiler wrappers to intercept compiler calls during the build process.; The analyzer run against each modules after the build finished.; Use `--intercept-first` and `--override-compiler` flags together to get; this model. The 1. and 3. are using compiler wrappers, which works only if the build; process respects the `CC` and `CXX` environment variables. (Some build; process can override these variable as command line parameter only. This case; you need to pass the compiler wrappers manually. eg.: `intercept-build; --override-compiler make CC=intercept-cc CXX=intercept-c++ all` where the; original build command would have been `make all` only.). The 1. runs the analyzer right after the real compilation. So, if the build; process removes removes intermediate modules (generated sources) the analyzer; output still kept. The 2. and 3. generate the compilation database first, and filters out those; modules which are not exists. So, it's suitable for incremental analysis during; the development. The 2. mode is available only on FreeBSD and Linux. Where library preload; is available from the dynamic loader. Not supported on OS X (unless System; Integrity Protection feature is turned off). `intercept-build` command uses only the 2. and 3. mode to generate the; compilation database. `analyze-build` does only run the analyzer against the; captured compiler calls. Known problems; -----",MatchSource.DOCS,interpreter/llvm-project/clang/tools/scan-build-py/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/scan-build-py/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/scan-build-py/README.md:4152,Modifiability,variab,variables,4152," only if the build; process respects the `CC` and `CXX` environment variables. (Some build; process can override these variable as command line parameter only. This case; you need to pass the compiler wrappers manually. eg.: `intercept-build; --override-compiler make CC=intercept-cc CXX=intercept-c++ all` where the; original build command would have been `make all` only.). The 1. runs the analyzer right after the real compilation. So, if the build; process removes removes intermediate modules (generated sources) the analyzer; output still kept. The 2. and 3. generate the compilation database first, and filters out those; modules which are not exists. So, it's suitable for incremental analysis during; the development. The 2. mode is available only on FreeBSD and Linux. Where library preload; is available from the dynamic loader. Not supported on OS X (unless System; Integrity Protection feature is turned off). `intercept-build` command uses only the 2. and 3. mode to generate the; compilation database. `analyze-build` does only run the analyzer against the; captured compiler calls. Known problems; --------------. Because it uses `LD_PRELOAD` or `DYLD_INSERT_LIBRARIES` environment variables,; it does not append to it, but overrides it. So builds which are using these; variables might not work. (I don't know any build tool which does that, but; please let me know if you do.). Problem reports; ---------------. If you find a bug in this documentation or elsewhere in the program or would; like to propose an improvement, please use the project's [issue tracker][3].; Please describing the bug and where you found it. If you have a suggestion; how to fix it, include that as well. Patches are also welcome. License; -------. The project is licensed under Apache-2.0 with LLVM exceptions.; See LICENSE.TXT for details. [1]: http://clang.llvm.org/docs/JSONCompilationDatabase.html; [2]: https://pypi.python.org/pypi/scan-build; [3]: https://llvm.org/bugs/enter_bug.cgi?product=clang; ",MatchSource.DOCS,interpreter/llvm-project/clang/tools/scan-build-py/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/scan-build-py/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/scan-build-py/README.md:4241,Modifiability,variab,variables,4241," only if the build; process respects the `CC` and `CXX` environment variables. (Some build; process can override these variable as command line parameter only. This case; you need to pass the compiler wrappers manually. eg.: `intercept-build; --override-compiler make CC=intercept-cc CXX=intercept-c++ all` where the; original build command would have been `make all` only.). The 1. runs the analyzer right after the real compilation. So, if the build; process removes removes intermediate modules (generated sources) the analyzer; output still kept. The 2. and 3. generate the compilation database first, and filters out those; modules which are not exists. So, it's suitable for incremental analysis during; the development. The 2. mode is available only on FreeBSD and Linux. Where library preload; is available from the dynamic loader. Not supported on OS X (unless System; Integrity Protection feature is turned off). `intercept-build` command uses only the 2. and 3. mode to generate the; compilation database. `analyze-build` does only run the analyzer against the; captured compiler calls. Known problems; --------------. Because it uses `LD_PRELOAD` or `DYLD_INSERT_LIBRARIES` environment variables,; it does not append to it, but overrides it. So builds which are using these; variables might not work. (I don't know any build tool which does that, but; please let me know if you do.). Problem reports; ---------------. If you find a bug in this documentation or elsewhere in the program or would; like to propose an improvement, please use the project's [issue tracker][3].; Please describing the bug and where you found it. If you have a suggestion; how to fix it, include that as well. Patches are also welcome. License; -------. The project is licensed under Apache-2.0 with LLVM exceptions.; See LICENSE.TXT for details. [1]: http://clang.llvm.org/docs/JSONCompilationDatabase.html; [2]: https://pypi.python.org/pypi/scan-build; [3]: https://llvm.org/bugs/enter_bug.cgi?product=clang; ",MatchSource.DOCS,interpreter/llvm-project/clang/tools/scan-build-py/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/scan-build-py/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/scan-build-py/README.md:3786,Performance,load,loader,3786," run against each modules after the build finished.; Use `--intercept-first` and `--override-compiler` flags together to get; this model. The 1. and 3. are using compiler wrappers, which works only if the build; process respects the `CC` and `CXX` environment variables. (Some build; process can override these variable as command line parameter only. This case; you need to pass the compiler wrappers manually. eg.: `intercept-build; --override-compiler make CC=intercept-cc CXX=intercept-c++ all` where the; original build command would have been `make all` only.). The 1. runs the analyzer right after the real compilation. So, if the build; process removes removes intermediate modules (generated sources) the analyzer; output still kept. The 2. and 3. generate the compilation database first, and filters out those; modules which are not exists. So, it's suitable for incremental analysis during; the development. The 2. mode is available only on FreeBSD and Linux. Where library preload; is available from the dynamic loader. Not supported on OS X (unless System; Integrity Protection feature is turned off). `intercept-build` command uses only the 2. and 3. mode to generate the; compilation database. `analyze-build` does only run the analyzer against the; captured compiler calls. Known problems; --------------. Because it uses `LD_PRELOAD` or `DYLD_INSERT_LIBRARIES` environment variables,; it does not append to it, but overrides it. So builds which are using these; variables might not work. (I don't know any build tool which does that, but; please let me know if you do.). Problem reports; ---------------. If you find a bug in this documentation or elsewhere in the program or would; like to propose an improvement, please use the project's [issue tracker][3].; Please describing the bug and where you found it. If you have a suggestion; how to fix it, include that as well. Patches are also welcome. License; -------. The project is licensed under Apache-2.0 with LLVM exceptions.; Se",MatchSource.DOCS,interpreter/llvm-project/clang/tools/scan-build-py/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/scan-build-py/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/scan-build-py/README.md:111,Testability,log,logged,111,"scan-build; ==========. A package designed to wrap a build so that all calls to gcc/clang are; intercepted and logged into a [compilation database][1] and/or piped to; the clang static analyzer. Includes intercept-build tool, which logs; the build, as well as scan-build tool, which logs the build and runs; the clang static analyzer on it. Portability; -----------. Should be working on UNIX operating systems. - It has been tested on FreeBSD, GNU/Linux and OS X.; - Prepared to work on windows, but need help to make it. Prerequisites; -------------. 1. **python** interpreter (version 3.6 or later). How to use; ----------. To run the Clang static analyzer against a project goes like this:. $ scan-build <your build command>. To generate a compilation database file goes like this:. $ intercept-build <your build command>. To run the Clang static analyzer against a project with compilation database; goes like this:. $ analyze-build. Use `--help` to know more about the commands. How to use the experimental Cross Translation Unit analysis; -----------------------------------------------------------. To run the CTU analysis, a compilation database file has to be created:. $ intercept-build <your build command>. To run the Clang Static Analyzer against a compilation database; with CTU analysis enabled, execute:; ; $ analyze-build --ctu. For CTU analysis an additional (external definition) collection-phase is required. ; For debugging purposes, it is possible to separately execute the collection ; and the analysis phase. By doing this, the intermediate files used for ; the analysis are kept on the disk in `./ctu-dir`.; ; # Collect and store the data required by the CTU analysis; $ analyze-build --ctu-collect-only; ; # Analyze using the previously collected data; $ analyze-build --ctu-analyze-only. Use `--help` to get more information about the commands. Limitations; -----------. Generally speaking, the `intercept-build` and `analyze-build` tools together; does the same job as `sc",MatchSource.DOCS,interpreter/llvm-project/clang/tools/scan-build-py/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/scan-build-py/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/scan-build-py/README.md:232,Testability,log,logs,232,"scan-build; ==========. A package designed to wrap a build so that all calls to gcc/clang are; intercepted and logged into a [compilation database][1] and/or piped to; the clang static analyzer. Includes intercept-build tool, which logs; the build, as well as scan-build tool, which logs the build and runs; the clang static analyzer on it. Portability; -----------. Should be working on UNIX operating systems. - It has been tested on FreeBSD, GNU/Linux and OS X.; - Prepared to work on windows, but need help to make it. Prerequisites; -------------. 1. **python** interpreter (version 3.6 or later). How to use; ----------. To run the Clang static analyzer against a project goes like this:. $ scan-build <your build command>. To generate a compilation database file goes like this:. $ intercept-build <your build command>. To run the Clang static analyzer against a project with compilation database; goes like this:. $ analyze-build. Use `--help` to know more about the commands. How to use the experimental Cross Translation Unit analysis; -----------------------------------------------------------. To run the CTU analysis, a compilation database file has to be created:. $ intercept-build <your build command>. To run the Clang Static Analyzer against a compilation database; with CTU analysis enabled, execute:; ; $ analyze-build --ctu. For CTU analysis an additional (external definition) collection-phase is required. ; For debugging purposes, it is possible to separately execute the collection ; and the analysis phase. By doing this, the intermediate files used for ; the analysis are kept on the disk in `./ctu-dir`.; ; # Collect and store the data required by the CTU analysis; $ analyze-build --ctu-collect-only; ; # Analyze using the previously collected data; $ analyze-build --ctu-analyze-only. Use `--help` to get more information about the commands. Limitations; -----------. Generally speaking, the `intercept-build` and `analyze-build` tools together; does the same job as `sc",MatchSource.DOCS,interpreter/llvm-project/clang/tools/scan-build-py/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/scan-build-py/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/scan-build-py/README.md:283,Testability,log,logs,283,"scan-build; ==========. A package designed to wrap a build so that all calls to gcc/clang are; intercepted and logged into a [compilation database][1] and/or piped to; the clang static analyzer. Includes intercept-build tool, which logs; the build, as well as scan-build tool, which logs the build and runs; the clang static analyzer on it. Portability; -----------. Should be working on UNIX operating systems. - It has been tested on FreeBSD, GNU/Linux and OS X.; - Prepared to work on windows, but need help to make it. Prerequisites; -------------. 1. **python** interpreter (version 3.6 or later). How to use; ----------. To run the Clang static analyzer against a project goes like this:. $ scan-build <your build command>. To generate a compilation database file goes like this:. $ intercept-build <your build command>. To run the Clang static analyzer against a project with compilation database; goes like this:. $ analyze-build. Use `--help` to know more about the commands. How to use the experimental Cross Translation Unit analysis; -----------------------------------------------------------. To run the CTU analysis, a compilation database file has to be created:. $ intercept-build <your build command>. To run the Clang Static Analyzer against a compilation database; with CTU analysis enabled, execute:; ; $ analyze-build --ctu. For CTU analysis an additional (external definition) collection-phase is required. ; For debugging purposes, it is possible to separately execute the collection ; and the analysis phase. By doing this, the intermediate files used for ; the analysis are kept on the disk in `./ctu-dir`.; ; # Collect and store the data required by the CTU analysis; $ analyze-build --ctu-collect-only; ; # Analyze using the previously collected data; $ analyze-build --ctu-analyze-only. Use `--help` to get more information about the commands. Limitations; -----------. Generally speaking, the `intercept-build` and `analyze-build` tools together; does the same job as `sc",MatchSource.DOCS,interpreter/llvm-project/clang/tools/scan-build-py/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/scan-build-py/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/scan-build-py/README.md:426,Testability,test,tested,426,"scan-build; ==========. A package designed to wrap a build so that all calls to gcc/clang are; intercepted and logged into a [compilation database][1] and/or piped to; the clang static analyzer. Includes intercept-build tool, which logs; the build, as well as scan-build tool, which logs the build and runs; the clang static analyzer on it. Portability; -----------. Should be working on UNIX operating systems. - It has been tested on FreeBSD, GNU/Linux and OS X.; - Prepared to work on windows, but need help to make it. Prerequisites; -------------. 1. **python** interpreter (version 3.6 or later). How to use; ----------. To run the Clang static analyzer against a project goes like this:. $ scan-build <your build command>. To generate a compilation database file goes like this:. $ intercept-build <your build command>. To run the Clang static analyzer against a project with compilation database; goes like this:. $ analyze-build. Use `--help` to know more about the commands. How to use the experimental Cross Translation Unit analysis; -----------------------------------------------------------. To run the CTU analysis, a compilation database file has to be created:. $ intercept-build <your build command>. To run the Clang Static Analyzer against a compilation database; with CTU analysis enabled, execute:; ; $ analyze-build --ctu. For CTU analysis an additional (external definition) collection-phase is required. ; For debugging purposes, it is possible to separately execute the collection ; and the analysis phase. By doing this, the intermediate files used for ; the analysis are kept on the disk in `./ctu-dir`.; ; # Collect and store the data required by the CTU analysis; $ analyze-build --ctu-collect-only; ; # Analyze using the previously collected data; $ analyze-build --ctu-analyze-only. Use `--help` to get more information about the commands. Limitations; -----------. Generally speaking, the `intercept-build` and `analyze-build` tools together; does the same job as `sc",MatchSource.DOCS,interpreter/llvm-project/clang/tools/scan-build-py/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/scan-build-py/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/scan-build-py/README.md:2071,Usability,simpl,simple,2071,"-----------------------------------------------. To run the CTU analysis, a compilation database file has to be created:. $ intercept-build <your build command>. To run the Clang Static Analyzer against a compilation database; with CTU analysis enabled, execute:; ; $ analyze-build --ctu. For CTU analysis an additional (external definition) collection-phase is required. ; For debugging purposes, it is possible to separately execute the collection ; and the analysis phase. By doing this, the intermediate files used for ; the analysis are kept on the disk in `./ctu-dir`.; ; # Collect and store the data required by the CTU analysis; $ analyze-build --ctu-collect-only; ; # Analyze using the previously collected data; $ analyze-build --ctu-analyze-only. Use `--help` to get more information about the commands. Limitations; -----------. Generally speaking, the `intercept-build` and `analyze-build` tools together; does the same job as `scan-build` does. So, you can expect the same output; from this line as simple `scan-build` would do:. $ intercept-build <your build command> && analyze-build. The major difference is how and when the analyzer is run. The `scan-build`; tool has three distinct model to run the analyzer:. 1. Use compiler wrappers to make actions.; The compiler wrappers does run the real compiler and the analyzer.; This is the default behaviour, can be enforced with `--override-compiler`; flag. 2. Use special library to intercept compiler calls during the build process.; The analyzer run against each modules after the build finished.; Use `--intercept-first` flag to get this model. 3. Use compiler wrappers to intercept compiler calls during the build process.; The analyzer run against each modules after the build finished.; Use `--intercept-first` and `--override-compiler` flags together to get; this model. The 1. and 3. are using compiler wrappers, which works only if the build; process respects the `CC` and `CXX` environment variables. (Some build; process can o",MatchSource.DOCS,interpreter/llvm-project/clang/tools/scan-build-py/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/scan-build-py/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:10536,Availability,avail,available,10536," block. ### TODO list. As this is an experimental work in progress so there are some items we still need; to tackle:. * As mentioned in test llvm/test/DebugInfo/assignment-tracking/X86/diamond-3.ll,; the analysis should treat escaping calls like untagged stores. * The system expects locals to be backed by a local alloca. This isn't always; the case - sometimes a pointer to storage is passed into a function; (e.g. sret, byval). We need to be able to handle those cases. See; llvm/test/DebugInfo/Generic/assignment-tracking/track-assignments.ll and; clang/test/CodeGen/assignment-tracking/assignment-tracking.cpp for examples. * `trackAssignments` doesn't yet work for variables that have their; `llvm.dbg.declare` location modified by a `DIExpression`, e.g. when the; address of the variable is itself stored in an `alloca` with the; `llvm.dbg.declare` using `DIExpression(DW_OP_deref)`. See `indirectReturn` in; llvm/test/DebugInfo/Generic/assignment-tracking/track-assignments.ll and in; clang/test/CodeGen/assignment-tracking/assignment-tracking.cpp for an; example. * In order to solve the first bullet-point we need to be able to specify that a; memory location is available without using a `DIAssignID`. This is because; the storage address is not computed by an instruction (it's an argument; value) and therefore we have nowhere to put the metadata attachment. To solve; this we probably need another marker intrinsic to denote ""the variable's; stack home is X address"" - similar to `llvm.dbg.declare` except that it needs; to compose with `llvm.dbg.assign` intrinsics such that the stack home address; is only selected as a location for the variable when the `llvm.dbg.assign`; intrinsics agree it should be. * Given the above (a special ""the stack home is X"" intrinsic), and the fact; that we can only track assignments with fixed offsets and sizes, I think we; can probably get rid of the address and address-expression part, since it; will always be computable with the info we have.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:2459,Deployability,update,updated,2459,"nal debug intrinsics to assignment tracking metadata and sets; the module flag `debug-info-assignment-tracking` to the value `i1 true`. To; check whether assignment tracking is enabled for a module call; `isAssignmentTrackingEnabled(const Module &M)` (from `llvm/IR/DebugInfo.h`). ## Design and implementation. ### Assignment markers: `llvm.dbg.assign`. `llvm.dbg.value`, a conventional debug intrinsic, marks out a position in the; IR where a variable takes a particular value. Similarly, Assignment Tracking; marks out the position of assignments with a new intrinsic called; `llvm.dbg.assign`. In order to know where in IR it is appropriate to use a memory location for a; variable, each assignment marker must in some way refer to the store, if any; (or multiple!), that performs the assignment. That way, the position of the; store and marker can be considered together when making that choice. Another; important benefit of referring to the store is that we can then build a two-way; mapping of stores<->markers that can be used to find markers that need to be; updated when stores are modified. An `llvm.dbg.assign` marker that is not linked to any instruction signals that; the store that performed the assignment has been optimised out, and therefore; the memory location will not be valid for at least some part of the program. Here's the `llvm.dbg.assign` signature. Each parameter is wrapped in; `MetadataAsValue`, and `Value *` type parameters are first wrapped in; `ValueAsMetadata`:. ```; void @llvm.dbg.assign(Value *Value,; DIExpression *ValueExpression,; DILocalVariable *Variable,; DIAssignID *ID,; Value *Address,; DIExpression *AddressExpression); ```. The first three parameters look and behave like an `llvm.dbg.value`. `ID` is a; reference to a store (see next section). `Address` is the destination address; of the store and it is modified by `AddressExpression`. An empty/undef/poison; address means the address component has been killed (the memory address is no; longer a ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:5735,Deployability,update,updates,5735,".assign(metadata i32 %a, metadata !14, metadata !DIExpression(), metadata !16, metadata i32* %a.addr, metadata !DIExpression()), !dbg !15; %0 = load i32, i32* %a.addr, align 4, !dbg !17; ret i32 %0, !dbg !18; }. ...; !13 = distinct !DIAssignID(); !14 = !DILocalVariable(name: ""a"", ...); ...; !16 = distinct !DIAssignID(); ```. The first `llvm.dbg.assign` refers to the `alloca` through `!DIAssignID !13`,; and the second refers to the `store` through `!DIAssignID !16`. ### Store-like instructions. In the absence of a linked `llvm.dbg.assign`, a store to an address that is; known to be the backing storage for a variable is considered to represent an; assignment to that variable. This gives us a safe fall-back in cases where `llvm.dbg.assign` intrinsics have; been deleted, the `DIAssignID` attachment on the store has been dropped, or the; optimiser has made a once-indirect store (not tracked with Assignment Tracking); direct. ### Middle-end: Considerations for pass-writers. #### Non-debug instruction updates. **Cloning** an instruction: nothing new to do. Cloning automatically clones a; `DIAssignID` attachment. Multiple instructions may have the same `DIAssignID`; instruction. In this case, the assignment is considered to take place in; multiple positions in the program. **Moving** a non-debug instruction: nothing new to do. Instructions linked to an; `llvm.dbg.assign` have their initial IR position marked by the position of the; `llvm.dbg.assign`. **Deleting** a non-debug instruction: nothing new to do. Simple DSE does not; require any change; it’s safe to delete an instruction with a `DIAssignID`; attachment. An `llvm.dbg.assign` that uses a `DIAssignID` that is not attached; to any instruction indicates that the memory location isn’t valid. **Merging** stores: In many cases no change is required as `DIAssignID`; attachments are automatically merged if `combineMetadata` is called. One way or; another, the `DIAssignID` attachments must be merged such that new store; beco",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:7481,Deployability,update,update,7481," change is required as `DIAssignID`; attachments are automatically merged if `combineMetadata` is called. One way or; another, the `DIAssignID` attachments must be merged such that new store; becomes linked to all the `llvm.dbg.assign` intrinsics that the merged stores; were linked to. This can be achieved simply by calling a helper function; `Instruction::mergeDIAssignID`. **Inlining** stores: As stores are inlined we generate `llvm.dbg.assign`; intrinsics and `DIAssignID` attachments as if the stores represent source; assignments, just like the in frontend. This isn’t perfect, as stores may have; been moved, modified or deleted before inlining, but it does at least keep the; information about the variable correct within the non-inlined scope. **Splitting** stores: SROA and passes that split stores treat `llvm.dbg.assign`; intrinsics similarly to `llvm.dbg.declare` intrinsics. Clone the; `llvm.dbg.assign` intrinsics linked to the store, update the FragmentInfo in; the `ValueExpression`, and give the split stores (and cloned intrinsics) new; `DIAssignID` attachments each. In other words, treat the split stores as; separate assignments. For partial DSE (e.g. shortening a memset), we do the; same except that `llvm.dbg.assign` for the dead fragment gets an `Undef`; `Address`. **Promoting** allocas and store/loads: `llvm.dbg.assign` intrinsics implicitly; describe joined values in memory locations at CFG joins, but this is not; necessarily the case after promoting (or partially promoting) the; variable. Passes that promote variables are responsible for inserting; `llvm.dbg.assign` intrinsics after the resultant PHIs generated during; promotion. `mem2reg` already has to do this (with `llvm.dbg.value`) for; `llvm.dbg.declare`s. Where a store has no linked intrinsic, the store is; assumed to represent an assignment for variables stored at the destination; address. #### Debug intrinsic updates. **Moving** a debug intrinsic: avoid moving `llvm.dbg.assign` intrinsics where; p",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:8440,Deployability,update,updates,8440,"lvm.dbg.assign` intrinsics linked to the store, update the FragmentInfo in; the `ValueExpression`, and give the split stores (and cloned intrinsics) new; `DIAssignID` attachments each. In other words, treat the split stores as; separate assignments. For partial DSE (e.g. shortening a memset), we do the; same except that `llvm.dbg.assign` for the dead fragment gets an `Undef`; `Address`. **Promoting** allocas and store/loads: `llvm.dbg.assign` intrinsics implicitly; describe joined values in memory locations at CFG joins, but this is not; necessarily the case after promoting (or partially promoting) the; variable. Passes that promote variables are responsible for inserting; `llvm.dbg.assign` intrinsics after the resultant PHIs generated during; promotion. `mem2reg` already has to do this (with `llvm.dbg.value`) for; `llvm.dbg.declare`s. Where a store has no linked intrinsic, the store is; assumed to represent an assignment for variables stored at the destination; address. #### Debug intrinsic updates. **Moving** a debug intrinsic: avoid moving `llvm.dbg.assign` intrinsics where; possible, as they represent a source-level assignment, whose position in the; program should not be affected by optimization passes. **Deleting** a debug intrinsic: Nothing new to do. Just like for conventional; debug intrinsics, unless it is unreachable, it’s almost always incorrect to; delete a `llvm.dbg.assign` intrinsic. ### Lowering `llvm.dbg.assign` to MIR. To begin with only SelectionDAG ISel will be supported. `llvm.dbg.assign`; intrinsics are lowered to MIR `DBG_INSTR_REF` instructions. Before this happens; we need to decide where it is appropriate to use memory locations and where we; must use a non-memory location (or no location) for each variable. In order to; make those decisions we run a standard fixed-point dataflow analysis that makes; the choice at each instruction, iteratively joining the results for each block. ### TODO list. As this is an experimental work in progress so ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:2787,Integrability,wrap,wrapped,2787,"here a variable takes a particular value. Similarly, Assignment Tracking; marks out the position of assignments with a new intrinsic called; `llvm.dbg.assign`. In order to know where in IR it is appropriate to use a memory location for a; variable, each assignment marker must in some way refer to the store, if any; (or multiple!), that performs the assignment. That way, the position of the; store and marker can be considered together when making that choice. Another; important benefit of referring to the store is that we can then build a two-way; mapping of stores<->markers that can be used to find markers that need to be; updated when stores are modified. An `llvm.dbg.assign` marker that is not linked to any instruction signals that; the store that performed the assignment has been optimised out, and therefore; the memory location will not be valid for at least some part of the program. Here's the `llvm.dbg.assign` signature. Each parameter is wrapped in; `MetadataAsValue`, and `Value *` type parameters are first wrapped in; `ValueAsMetadata`:. ```; void @llvm.dbg.assign(Value *Value,; DIExpression *ValueExpression,; DILocalVariable *Variable,; DIAssignID *ID,; Value *Address,; DIExpression *AddressExpression); ```. The first three parameters look and behave like an `llvm.dbg.value`. `ID` is a; reference to a store (see next section). `Address` is the destination address; of the store and it is modified by `AddressExpression`. An empty/undef/poison; address means the address component has been killed (the memory address is no; longer a valid location). LLVM currently encodes variable fragment information; in `DIExpression`s, so as an implementation quirk the `FragmentInfo` for; `Variable` is contained within `ValueExpression` only. The formal LLVM-IR signature is:; ```; void @llvm.dbg.assign(metadata, metadata, metadata, metadata, metadata, metadata); ```. ### Instruction link: `DIAssignID`. `DIAssignID` metadata is the mechanism that is currently used to encode the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:2858,Integrability,wrap,wrapped,2858,"here a variable takes a particular value. Similarly, Assignment Tracking; marks out the position of assignments with a new intrinsic called; `llvm.dbg.assign`. In order to know where in IR it is appropriate to use a memory location for a; variable, each assignment marker must in some way refer to the store, if any; (or multiple!), that performs the assignment. That way, the position of the; store and marker can be considered together when making that choice. Another; important benefit of referring to the store is that we can then build a two-way; mapping of stores<->markers that can be used to find markers that need to be; updated when stores are modified. An `llvm.dbg.assign` marker that is not linked to any instruction signals that; the store that performed the assignment has been optimised out, and therefore; the memory location will not be valid for at least some part of the program. Here's the `llvm.dbg.assign` signature. Each parameter is wrapped in; `MetadataAsValue`, and `Value *` type parameters are first wrapped in; `ValueAsMetadata`:. ```; void @llvm.dbg.assign(Value *Value,; DIExpression *ValueExpression,; DILocalVariable *Variable,; DIAssignID *ID,; Value *Address,; DIExpression *AddressExpression); ```. The first three parameters look and behave like an `llvm.dbg.value`. `ID` is a; reference to a store (see next section). `Address` is the destination address; of the store and it is modified by `AddressExpression`. An empty/undef/poison; address means the address component has been killed (the memory address is no; longer a valid location). LLVM currently encodes variable fragment information; in `DIExpression`s, so as an implementation quirk the `FragmentInfo` for; `Variable` is contained within `ValueExpression` only. The formal LLVM-IR signature is:; ```; void @llvm.dbg.assign(metadata, metadata, metadata, metadata, metadata, metadata); ```. ### Instruction link: `DIAssignID`. `DIAssignID` metadata is the mechanism that is currently used to encode the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:95,Modifiability,variab,variable,95,"# Debug Info Assignment Tracking. Assignment Tracking is an alternative technique for tracking variable location; debug info through optimisations in LLVM. It provides accurate variable; locations for assignments where a local variable (or a field of one) is the; LHS. In rare and complicated circumstances indirect assignments might be; optimized away without being tracked, but otherwise we make our best effort to; track all variable locations. The core idea is to track more information about source assignments in order; and preserve enough information to be able to defer decisions about whether to; use non-memory locations (register, constant) or memory locations until after; middle end optimisations have run. This is in opposition to using; `llvm.dbg.declare` and `llvm.dbg.value`, which is to make the decision for most; variables early on, which can result in suboptimal variable locations that may; be either incorrect or incomplete. A secondary goal of assignment tracking is to cause minimal additional work for; LLVM pass writers, and minimal disruption to LLVM in general. ## Status and usage. **Status**: Experimental work in progress. Enabling is strongly advised against; except for development and testing. **Enable in Clang**: `-Xclang -fexperimental-assignment-tracking`. That causes Clang to get LLVM to run the pass `declare-to-assign`. The pass; converts conventional debug intrinsics to assignment tracking metadata and sets; the module flag `debug-info-assignment-tracking` to the value `i1 true`. To; check whether assignment tracking is enabled for a module call; `isAssignmentTrackingEnabled(const Module &M)` (from `llvm/IR/DebugInfo.h`). ## Design and implementation. ### Assignment markers: `llvm.dbg.assign`. `llvm.dbg.value`, a conventional debug intrinsic, marks out a position in the; IR where a variable takes a particular value. Similarly, Assignment Tracking; marks out the position of assignments with a new intrinsic called; `llvm.dbg.assign`. In order to k",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:177,Modifiability,variab,variable,177,"# Debug Info Assignment Tracking. Assignment Tracking is an alternative technique for tracking variable location; debug info through optimisations in LLVM. It provides accurate variable; locations for assignments where a local variable (or a field of one) is the; LHS. In rare and complicated circumstances indirect assignments might be; optimized away without being tracked, but otherwise we make our best effort to; track all variable locations. The core idea is to track more information about source assignments in order; and preserve enough information to be able to defer decisions about whether to; use non-memory locations (register, constant) or memory locations until after; middle end optimisations have run. This is in opposition to using; `llvm.dbg.declare` and `llvm.dbg.value`, which is to make the decision for most; variables early on, which can result in suboptimal variable locations that may; be either incorrect or incomplete. A secondary goal of assignment tracking is to cause minimal additional work for; LLVM pass writers, and minimal disruption to LLVM in general. ## Status and usage. **Status**: Experimental work in progress. Enabling is strongly advised against; except for development and testing. **Enable in Clang**: `-Xclang -fexperimental-assignment-tracking`. That causes Clang to get LLVM to run the pass `declare-to-assign`. The pass; converts conventional debug intrinsics to assignment tracking metadata and sets; the module flag `debug-info-assignment-tracking` to the value `i1 true`. To; check whether assignment tracking is enabled for a module call; `isAssignmentTrackingEnabled(const Module &M)` (from `llvm/IR/DebugInfo.h`). ## Design and implementation. ### Assignment markers: `llvm.dbg.assign`. `llvm.dbg.value`, a conventional debug intrinsic, marks out a position in the; IR where a variable takes a particular value. Similarly, Assignment Tracking; marks out the position of assignments with a new intrinsic called; `llvm.dbg.assign`. In order to k",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:227,Modifiability,variab,variable,227,"# Debug Info Assignment Tracking. Assignment Tracking is an alternative technique for tracking variable location; debug info through optimisations in LLVM. It provides accurate variable; locations for assignments where a local variable (or a field of one) is the; LHS. In rare and complicated circumstances indirect assignments might be; optimized away without being tracked, but otherwise we make our best effort to; track all variable locations. The core idea is to track more information about source assignments in order; and preserve enough information to be able to defer decisions about whether to; use non-memory locations (register, constant) or memory locations until after; middle end optimisations have run. This is in opposition to using; `llvm.dbg.declare` and `llvm.dbg.value`, which is to make the decision for most; variables early on, which can result in suboptimal variable locations that may; be either incorrect or incomplete. A secondary goal of assignment tracking is to cause minimal additional work for; LLVM pass writers, and minimal disruption to LLVM in general. ## Status and usage. **Status**: Experimental work in progress. Enabling is strongly advised against; except for development and testing. **Enable in Clang**: `-Xclang -fexperimental-assignment-tracking`. That causes Clang to get LLVM to run the pass `declare-to-assign`. The pass; converts conventional debug intrinsics to assignment tracking metadata and sets; the module flag `debug-info-assignment-tracking` to the value `i1 true`. To; check whether assignment tracking is enabled for a module call; `isAssignmentTrackingEnabled(const Module &M)` (from `llvm/IR/DebugInfo.h`). ## Design and implementation. ### Assignment markers: `llvm.dbg.assign`. `llvm.dbg.value`, a conventional debug intrinsic, marks out a position in the; IR where a variable takes a particular value. Similarly, Assignment Tracking; marks out the position of assignments with a new intrinsic called; `llvm.dbg.assign`. In order to k",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:428,Modifiability,variab,variable,428,"# Debug Info Assignment Tracking. Assignment Tracking is an alternative technique for tracking variable location; debug info through optimisations in LLVM. It provides accurate variable; locations for assignments where a local variable (or a field of one) is the; LHS. In rare and complicated circumstances indirect assignments might be; optimized away without being tracked, but otherwise we make our best effort to; track all variable locations. The core idea is to track more information about source assignments in order; and preserve enough information to be able to defer decisions about whether to; use non-memory locations (register, constant) or memory locations until after; middle end optimisations have run. This is in opposition to using; `llvm.dbg.declare` and `llvm.dbg.value`, which is to make the decision for most; variables early on, which can result in suboptimal variable locations that may; be either incorrect or incomplete. A secondary goal of assignment tracking is to cause minimal additional work for; LLVM pass writers, and minimal disruption to LLVM in general. ## Status and usage. **Status**: Experimental work in progress. Enabling is strongly advised against; except for development and testing. **Enable in Clang**: `-Xclang -fexperimental-assignment-tracking`. That causes Clang to get LLVM to run the pass `declare-to-assign`. The pass; converts conventional debug intrinsics to assignment tracking metadata and sets; the module flag `debug-info-assignment-tracking` to the value `i1 true`. To; check whether assignment tracking is enabled for a module call; `isAssignmentTrackingEnabled(const Module &M)` (from `llvm/IR/DebugInfo.h`). ## Design and implementation. ### Assignment markers: `llvm.dbg.assign`. `llvm.dbg.value`, a conventional debug intrinsic, marks out a position in the; IR where a variable takes a particular value. Similarly, Assignment Tracking; marks out the position of assignments with a new intrinsic called; `llvm.dbg.assign`. In order to k",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:833,Modifiability,variab,variables,833,"# Debug Info Assignment Tracking. Assignment Tracking is an alternative technique for tracking variable location; debug info through optimisations in LLVM. It provides accurate variable; locations for assignments where a local variable (or a field of one) is the; LHS. In rare and complicated circumstances indirect assignments might be; optimized away without being tracked, but otherwise we make our best effort to; track all variable locations. The core idea is to track more information about source assignments in order; and preserve enough information to be able to defer decisions about whether to; use non-memory locations (register, constant) or memory locations until after; middle end optimisations have run. This is in opposition to using; `llvm.dbg.declare` and `llvm.dbg.value`, which is to make the decision for most; variables early on, which can result in suboptimal variable locations that may; be either incorrect or incomplete. A secondary goal of assignment tracking is to cause minimal additional work for; LLVM pass writers, and minimal disruption to LLVM in general. ## Status and usage. **Status**: Experimental work in progress. Enabling is strongly advised against; except for development and testing. **Enable in Clang**: `-Xclang -fexperimental-assignment-tracking`. That causes Clang to get LLVM to run the pass `declare-to-assign`. The pass; converts conventional debug intrinsics to assignment tracking metadata and sets; the module flag `debug-info-assignment-tracking` to the value `i1 true`. To; check whether assignment tracking is enabled for a module call; `isAssignmentTrackingEnabled(const Module &M)` (from `llvm/IR/DebugInfo.h`). ## Design and implementation. ### Assignment markers: `llvm.dbg.assign`. `llvm.dbg.value`, a conventional debug intrinsic, marks out a position in the; IR where a variable takes a particular value. Similarly, Assignment Tracking; marks out the position of assignments with a new intrinsic called; `llvm.dbg.assign`. In order to k",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:884,Modifiability,variab,variable,884,"# Debug Info Assignment Tracking. Assignment Tracking is an alternative technique for tracking variable location; debug info through optimisations in LLVM. It provides accurate variable; locations for assignments where a local variable (or a field of one) is the; LHS. In rare and complicated circumstances indirect assignments might be; optimized away without being tracked, but otherwise we make our best effort to; track all variable locations. The core idea is to track more information about source assignments in order; and preserve enough information to be able to defer decisions about whether to; use non-memory locations (register, constant) or memory locations until after; middle end optimisations have run. This is in opposition to using; `llvm.dbg.declare` and `llvm.dbg.value`, which is to make the decision for most; variables early on, which can result in suboptimal variable locations that may; be either incorrect or incomplete. A secondary goal of assignment tracking is to cause minimal additional work for; LLVM pass writers, and minimal disruption to LLVM in general. ## Status and usage. **Status**: Experimental work in progress. Enabling is strongly advised against; except for development and testing. **Enable in Clang**: `-Xclang -fexperimental-assignment-tracking`. That causes Clang to get LLVM to run the pass `declare-to-assign`. The pass; converts conventional debug intrinsics to assignment tracking metadata and sets; the module flag `debug-info-assignment-tracking` to the value `i1 true`. To; check whether assignment tracking is enabled for a module call; `isAssignmentTrackingEnabled(const Module &M)` (from `llvm/IR/DebugInfo.h`). ## Design and implementation. ### Assignment markers: `llvm.dbg.assign`. `llvm.dbg.value`, a conventional debug intrinsic, marks out a position in the; IR where a variable takes a particular value. Similarly, Assignment Tracking; marks out the position of assignments with a new intrinsic called; `llvm.dbg.assign`. In order to k",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:1835,Modifiability,variab,variable,1835,"e decision for most; variables early on, which can result in suboptimal variable locations that may; be either incorrect or incomplete. A secondary goal of assignment tracking is to cause minimal additional work for; LLVM pass writers, and minimal disruption to LLVM in general. ## Status and usage. **Status**: Experimental work in progress. Enabling is strongly advised against; except for development and testing. **Enable in Clang**: `-Xclang -fexperimental-assignment-tracking`. That causes Clang to get LLVM to run the pass `declare-to-assign`. The pass; converts conventional debug intrinsics to assignment tracking metadata and sets; the module flag `debug-info-assignment-tracking` to the value `i1 true`. To; check whether assignment tracking is enabled for a module call; `isAssignmentTrackingEnabled(const Module &M)` (from `llvm/IR/DebugInfo.h`). ## Design and implementation. ### Assignment markers: `llvm.dbg.assign`. `llvm.dbg.value`, a conventional debug intrinsic, marks out a position in the; IR where a variable takes a particular value. Similarly, Assignment Tracking; marks out the position of assignments with a new intrinsic called; `llvm.dbg.assign`. In order to know where in IR it is appropriate to use a memory location for a; variable, each assignment marker must in some way refer to the store, if any; (or multiple!), that performs the assignment. That way, the position of the; store and marker can be considered together when making that choice. Another; important benefit of referring to the store is that we can then build a two-way; mapping of stores<->markers that can be used to find markers that need to be; updated when stores are modified. An `llvm.dbg.assign` marker that is not linked to any instruction signals that; the store that performed the assignment has been optimised out, and therefore; the memory location will not be valid for at least some part of the program. Here's the `llvm.dbg.assign` signature. Each parameter is wrapped in; `MetadataAsVa",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:2067,Modifiability,variab,variable,2067,"l. ## Status and usage. **Status**: Experimental work in progress. Enabling is strongly advised against; except for development and testing. **Enable in Clang**: `-Xclang -fexperimental-assignment-tracking`. That causes Clang to get LLVM to run the pass `declare-to-assign`. The pass; converts conventional debug intrinsics to assignment tracking metadata and sets; the module flag `debug-info-assignment-tracking` to the value `i1 true`. To; check whether assignment tracking is enabled for a module call; `isAssignmentTrackingEnabled(const Module &M)` (from `llvm/IR/DebugInfo.h`). ## Design and implementation. ### Assignment markers: `llvm.dbg.assign`. `llvm.dbg.value`, a conventional debug intrinsic, marks out a position in the; IR where a variable takes a particular value. Similarly, Assignment Tracking; marks out the position of assignments with a new intrinsic called; `llvm.dbg.assign`. In order to know where in IR it is appropriate to use a memory location for a; variable, each assignment marker must in some way refer to the store, if any; (or multiple!), that performs the assignment. That way, the position of the; store and marker can be considered together when making that choice. Another; important benefit of referring to the store is that we can then build a two-way; mapping of stores<->markers that can be used to find markers that need to be; updated when stores are modified. An `llvm.dbg.assign` marker that is not linked to any instruction signals that; the store that performed the assignment has been optimised out, and therefore; the memory location will not be valid for at least some part of the program. Here's the `llvm.dbg.assign` signature. Each parameter is wrapped in; `MetadataAsValue`, and `Value *` type parameters are first wrapped in; `ValueAsMetadata`:. ```; void @llvm.dbg.assign(Value *Value,; DIExpression *ValueExpression,; DILocalVariable *Variable,; DIAssignID *ID,; Value *Address,; DIExpression *AddressExpression); ```. The first three paramete",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:3431,Modifiability,variab,variable,3431,"lvm.dbg.assign` marker that is not linked to any instruction signals that; the store that performed the assignment has been optimised out, and therefore; the memory location will not be valid for at least some part of the program. Here's the `llvm.dbg.assign` signature. Each parameter is wrapped in; `MetadataAsValue`, and `Value *` type parameters are first wrapped in; `ValueAsMetadata`:. ```; void @llvm.dbg.assign(Value *Value,; DIExpression *ValueExpression,; DILocalVariable *Variable,; DIAssignID *ID,; Value *Address,; DIExpression *AddressExpression); ```. The first three parameters look and behave like an `llvm.dbg.value`. `ID` is a; reference to a store (see next section). `Address` is the destination address; of the store and it is modified by `AddressExpression`. An empty/undef/poison; address means the address component has been killed (the memory address is no; longer a valid location). LLVM currently encodes variable fragment information; in `DIExpression`s, so as an implementation quirk the `FragmentInfo` for; `Variable` is contained within `ValueExpression` only. The formal LLVM-IR signature is:; ```; void @llvm.dbg.assign(metadata, metadata, metadata, metadata, metadata, metadata); ```. ### Instruction link: `DIAssignID`. `DIAssignID` metadata is the mechanism that is currently used to encode the; store<->marker link. The metadata node has no operands and all instances are; `distinct`; equality is checked for by comparing addresses. `llvm.dbg.assign` intrinsics use a `DIAssignID` metadata node instance as an; operand. This way it refers to any store-like instruction that has the same; `DIAssignID` attachment. E.g. For this test.cpp,. ```; int fun(int a) {; return a;; }; ```; compiled without optimisations:; ```; $ clang++ test.cpp -o test.ll -emit-llvm -S -g -O0 -Xclang -fexperimental-assignment-tracking; ```; we get:; ```; define dso_local noundef i32 @_Z3funi(i32 noundef %a) #0 !dbg !8 {; entry:; %a.addr = alloca i32, align 4, !DIAssignID !13; call vo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:5339,Modifiability,variab,variable,5339,"ment-tracking; ```; we get:; ```; define dso_local noundef i32 @_Z3funi(i32 noundef %a) #0 !dbg !8 {; entry:; %a.addr = alloca i32, align 4, !DIAssignID !13; call void @llvm.dbg.assign(metadata i1 undef, metadata !14, metadata !DIExpression(), metadata !13, metadata i32* %a.addr, metadata !DIExpression()), !dbg !15; store i32 %a, i32* %a.addr, align 4, !DIAssignID !16; call void @llvm.dbg.assign(metadata i32 %a, metadata !14, metadata !DIExpression(), metadata !16, metadata i32* %a.addr, metadata !DIExpression()), !dbg !15; %0 = load i32, i32* %a.addr, align 4, !dbg !17; ret i32 %0, !dbg !18; }. ...; !13 = distinct !DIAssignID(); !14 = !DILocalVariable(name: ""a"", ...); ...; !16 = distinct !DIAssignID(); ```. The first `llvm.dbg.assign` refers to the `alloca` through `!DIAssignID !13`,; and the second refers to the `store` through `!DIAssignID !16`. ### Store-like instructions. In the absence of a linked `llvm.dbg.assign`, a store to an address that is; known to be the backing storage for a variable is considered to represent an; assignment to that variable. This gives us a safe fall-back in cases where `llvm.dbg.assign` intrinsics have; been deleted, the `DIAssignID` attachment on the store has been dropped, or the; optimiser has made a once-indirect store (not tracked with Assignment Tracking); direct. ### Middle-end: Considerations for pass-writers. #### Non-debug instruction updates. **Cloning** an instruction: nothing new to do. Cloning automatically clones a; `DIAssignID` attachment. Multiple instructions may have the same `DIAssignID`; instruction. In this case, the assignment is considered to take place in; multiple positions in the program. **Moving** a non-debug instruction: nothing new to do. Instructions linked to an; `llvm.dbg.assign` have their initial IR position marked by the position of the; `llvm.dbg.assign`. **Deleting** a non-debug instruction: nothing new to do. Simple DSE does not; require any change; it’s safe to delete an instruction with a `D",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:5398,Modifiability,variab,variable,5398,"ment-tracking; ```; we get:; ```; define dso_local noundef i32 @_Z3funi(i32 noundef %a) #0 !dbg !8 {; entry:; %a.addr = alloca i32, align 4, !DIAssignID !13; call void @llvm.dbg.assign(metadata i1 undef, metadata !14, metadata !DIExpression(), metadata !13, metadata i32* %a.addr, metadata !DIExpression()), !dbg !15; store i32 %a, i32* %a.addr, align 4, !DIAssignID !16; call void @llvm.dbg.assign(metadata i32 %a, metadata !14, metadata !DIExpression(), metadata !16, metadata i32* %a.addr, metadata !DIExpression()), !dbg !15; %0 = load i32, i32* %a.addr, align 4, !dbg !17; ret i32 %0, !dbg !18; }. ...; !13 = distinct !DIAssignID(); !14 = !DILocalVariable(name: ""a"", ...); ...; !16 = distinct !DIAssignID(); ```. The first `llvm.dbg.assign` refers to the `alloca` through `!DIAssignID !13`,; and the second refers to the `store` through `!DIAssignID !16`. ### Store-like instructions. In the absence of a linked `llvm.dbg.assign`, a store to an address that is; known to be the backing storage for a variable is considered to represent an; assignment to that variable. This gives us a safe fall-back in cases where `llvm.dbg.assign` intrinsics have; been deleted, the `DIAssignID` attachment on the store has been dropped, or the; optimiser has made a once-indirect store (not tracked with Assignment Tracking); direct. ### Middle-end: Considerations for pass-writers. #### Non-debug instruction updates. **Cloning** an instruction: nothing new to do. Cloning automatically clones a; `DIAssignID` attachment. Multiple instructions may have the same `DIAssignID`; instruction. In this case, the assignment is considered to take place in; multiple positions in the program. **Moving** a non-debug instruction: nothing new to do. Instructions linked to an; `llvm.dbg.assign` have their initial IR position marked by the position of the; `llvm.dbg.assign`. **Deleting** a non-debug instruction: nothing new to do. Simple DSE does not; require any change; it’s safe to delete an instruction with a `D",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:7237,Modifiability,variab,variable,7237,"n`. **Deleting** a non-debug instruction: nothing new to do. Simple DSE does not; require any change; it’s safe to delete an instruction with a `DIAssignID`; attachment. An `llvm.dbg.assign` that uses a `DIAssignID` that is not attached; to any instruction indicates that the memory location isn’t valid. **Merging** stores: In many cases no change is required as `DIAssignID`; attachments are automatically merged if `combineMetadata` is called. One way or; another, the `DIAssignID` attachments must be merged such that new store; becomes linked to all the `llvm.dbg.assign` intrinsics that the merged stores; were linked to. This can be achieved simply by calling a helper function; `Instruction::mergeDIAssignID`. **Inlining** stores: As stores are inlined we generate `llvm.dbg.assign`; intrinsics and `DIAssignID` attachments as if the stores represent source; assignments, just like the in frontend. This isn’t perfect, as stores may have; been moved, modified or deleted before inlining, but it does at least keep the; information about the variable correct within the non-inlined scope. **Splitting** stores: SROA and passes that split stores treat `llvm.dbg.assign`; intrinsics similarly to `llvm.dbg.declare` intrinsics. Clone the; `llvm.dbg.assign` intrinsics linked to the store, update the FragmentInfo in; the `ValueExpression`, and give the split stores (and cloned intrinsics) new; `DIAssignID` attachments each. In other words, treat the split stores as; separate assignments. For partial DSE (e.g. shortening a memset), we do the; same except that `llvm.dbg.assign` for the dead fragment gets an `Undef`; `Address`. **Promoting** allocas and store/loads: `llvm.dbg.assign` intrinsics implicitly; describe joined values in memory locations at CFG joins, but this is not; necessarily the case after promoting (or partially promoting) the; variable. Passes that promote variables are responsible for inserting; `llvm.dbg.assign` intrinsics after the resultant PHIs generated during; pr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:8044,Modifiability,variab,variable,8044,"llvm.dbg.assign`; intrinsics and `DIAssignID` attachments as if the stores represent source; assignments, just like the in frontend. This isn’t perfect, as stores may have; been moved, modified or deleted before inlining, but it does at least keep the; information about the variable correct within the non-inlined scope. **Splitting** stores: SROA and passes that split stores treat `llvm.dbg.assign`; intrinsics similarly to `llvm.dbg.declare` intrinsics. Clone the; `llvm.dbg.assign` intrinsics linked to the store, update the FragmentInfo in; the `ValueExpression`, and give the split stores (and cloned intrinsics) new; `DIAssignID` attachments each. In other words, treat the split stores as; separate assignments. For partial DSE (e.g. shortening a memset), we do the; same except that `llvm.dbg.assign` for the dead fragment gets an `Undef`; `Address`. **Promoting** allocas and store/loads: `llvm.dbg.assign` intrinsics implicitly; describe joined values in memory locations at CFG joins, but this is not; necessarily the case after promoting (or partially promoting) the; variable. Passes that promote variables are responsible for inserting; `llvm.dbg.assign` intrinsics after the resultant PHIs generated during; promotion. `mem2reg` already has to do this (with `llvm.dbg.value`) for; `llvm.dbg.declare`s. Where a store has no linked intrinsic, the store is; assumed to represent an assignment for variables stored at the destination; address. #### Debug intrinsic updates. **Moving** a debug intrinsic: avoid moving `llvm.dbg.assign` intrinsics where; possible, as they represent a source-level assignment, whose position in the; program should not be affected by optimization passes. **Deleting** a debug intrinsic: Nothing new to do. Just like for conventional; debug intrinsics, unless it is unreachable, it’s almost always incorrect to; delete a `llvm.dbg.assign` intrinsic. ### Lowering `llvm.dbg.assign` to MIR. To begin with only SelectionDAG ISel will be supported. `llvm.dbg.ass",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:8074,Modifiability,variab,variables,8074,"ontend. This isn’t perfect, as stores may have; been moved, modified or deleted before inlining, but it does at least keep the; information about the variable correct within the non-inlined scope. **Splitting** stores: SROA and passes that split stores treat `llvm.dbg.assign`; intrinsics similarly to `llvm.dbg.declare` intrinsics. Clone the; `llvm.dbg.assign` intrinsics linked to the store, update the FragmentInfo in; the `ValueExpression`, and give the split stores (and cloned intrinsics) new; `DIAssignID` attachments each. In other words, treat the split stores as; separate assignments. For partial DSE (e.g. shortening a memset), we do the; same except that `llvm.dbg.assign` for the dead fragment gets an `Undef`; `Address`. **Promoting** allocas and store/loads: `llvm.dbg.assign` intrinsics implicitly; describe joined values in memory locations at CFG joins, but this is not; necessarily the case after promoting (or partially promoting) the; variable. Passes that promote variables are responsible for inserting; `llvm.dbg.assign` intrinsics after the resultant PHIs generated during; promotion. `mem2reg` already has to do this (with `llvm.dbg.value`) for; `llvm.dbg.declare`s. Where a store has no linked intrinsic, the store is; assumed to represent an assignment for variables stored at the destination; address. #### Debug intrinsic updates. **Moving** a debug intrinsic: avoid moving `llvm.dbg.assign` intrinsics where; possible, as they represent a source-level assignment, whose position in the; program should not be affected by optimization passes. **Deleting** a debug intrinsic: Nothing new to do. Just like for conventional; debug intrinsics, unless it is unreachable, it’s almost always incorrect to; delete a `llvm.dbg.assign` intrinsic. ### Lowering `llvm.dbg.assign` to MIR. To begin with only SelectionDAG ISel will be supported. `llvm.dbg.assign`; intrinsics are lowered to MIR `DBG_INSTR_REF` instructions. Before this happens; we need to decide where it is appropr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:8373,Modifiability,variab,variables,8373,"vm.dbg.assign`; intrinsics similarly to `llvm.dbg.declare` intrinsics. Clone the; `llvm.dbg.assign` intrinsics linked to the store, update the FragmentInfo in; the `ValueExpression`, and give the split stores (and cloned intrinsics) new; `DIAssignID` attachments each. In other words, treat the split stores as; separate assignments. For partial DSE (e.g. shortening a memset), we do the; same except that `llvm.dbg.assign` for the dead fragment gets an `Undef`; `Address`. **Promoting** allocas and store/loads: `llvm.dbg.assign` intrinsics implicitly; describe joined values in memory locations at CFG joins, but this is not; necessarily the case after promoting (or partially promoting) the; variable. Passes that promote variables are responsible for inserting; `llvm.dbg.assign` intrinsics after the resultant PHIs generated during; promotion. `mem2reg` already has to do this (with `llvm.dbg.value`) for; `llvm.dbg.declare`s. Where a store has no linked intrinsic, the store is; assumed to represent an assignment for variables stored at the destination; address. #### Debug intrinsic updates. **Moving** a debug intrinsic: avoid moving `llvm.dbg.assign` intrinsics where; possible, as they represent a source-level assignment, whose position in the; program should not be affected by optimization passes. **Deleting** a debug intrinsic: Nothing new to do. Just like for conventional; debug intrinsics, unless it is unreachable, it’s almost always incorrect to; delete a `llvm.dbg.assign` intrinsic. ### Lowering `llvm.dbg.assign` to MIR. To begin with only SelectionDAG ISel will be supported. `llvm.dbg.assign`; intrinsics are lowered to MIR `DBG_INSTR_REF` instructions. Before this happens; we need to decide where it is appropriate to use memory locations and where we; must use a non-memory location (or no location) for each variable. In order to; make those decisions we run a standard fixed-point dataflow analysis that makes; the choice at each instruction, iteratively joining the re",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:9187,Modifiability,variab,variable,9187,"g; `llvm.dbg.assign` intrinsics after the resultant PHIs generated during; promotion. `mem2reg` already has to do this (with `llvm.dbg.value`) for; `llvm.dbg.declare`s. Where a store has no linked intrinsic, the store is; assumed to represent an assignment for variables stored at the destination; address. #### Debug intrinsic updates. **Moving** a debug intrinsic: avoid moving `llvm.dbg.assign` intrinsics where; possible, as they represent a source-level assignment, whose position in the; program should not be affected by optimization passes. **Deleting** a debug intrinsic: Nothing new to do. Just like for conventional; debug intrinsics, unless it is unreachable, it’s almost always incorrect to; delete a `llvm.dbg.assign` intrinsic. ### Lowering `llvm.dbg.assign` to MIR. To begin with only SelectionDAG ISel will be supported. `llvm.dbg.assign`; intrinsics are lowered to MIR `DBG_INSTR_REF` instructions. Before this happens; we need to decide where it is appropriate to use memory locations and where we; must use a non-memory location (or no location) for each variable. In order to; make those decisions we run a standard fixed-point dataflow analysis that makes; the choice at each instruction, iteratively joining the results for each block. ### TODO list. As this is an experimental work in progress so there are some items we still need; to tackle:. * As mentioned in test llvm/test/DebugInfo/assignment-tracking/X86/diamond-3.ll,; the analysis should treat escaping calls like untagged stores. * The system expects locals to be backed by a local alloca. This isn't always; the case - sometimes a pointer to storage is passed into a function; (e.g. sret, byval). We need to be able to handle those cases. See; llvm/test/DebugInfo/Generic/assignment-tracking/track-assignments.ll and; clang/test/CodeGen/assignment-tracking/assignment-tracking.cpp for examples. * `trackAssignments` doesn't yet work for variables that have their; `llvm.dbg.declare` location modified by a `DIExpres",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:10034,Modifiability,variab,variables,10034,"Before this happens; we need to decide where it is appropriate to use memory locations and where we; must use a non-memory location (or no location) for each variable. In order to; make those decisions we run a standard fixed-point dataflow analysis that makes; the choice at each instruction, iteratively joining the results for each block. ### TODO list. As this is an experimental work in progress so there are some items we still need; to tackle:. * As mentioned in test llvm/test/DebugInfo/assignment-tracking/X86/diamond-3.ll,; the analysis should treat escaping calls like untagged stores. * The system expects locals to be backed by a local alloca. This isn't always; the case - sometimes a pointer to storage is passed into a function; (e.g. sret, byval). We need to be able to handle those cases. See; llvm/test/DebugInfo/Generic/assignment-tracking/track-assignments.ll and; clang/test/CodeGen/assignment-tracking/assignment-tracking.cpp for examples. * `trackAssignments` doesn't yet work for variables that have their; `llvm.dbg.declare` location modified by a `DIExpression`, e.g. when the; address of the variable is itself stored in an `alloca` with the; `llvm.dbg.declare` using `DIExpression(DW_OP_deref)`. See `indirectReturn` in; llvm/test/DebugInfo/Generic/assignment-tracking/track-assignments.ll and in; clang/test/CodeGen/assignment-tracking/assignment-tracking.cpp for an; example. * In order to solve the first bullet-point we need to be able to specify that a; memory location is available without using a `DIAssignID`. This is because; the storage address is not computed by an instruction (it's an argument; value) and therefore we have nowhere to put the metadata attachment. To solve; this we probably need another marker intrinsic to denote ""the variable's; stack home is X address"" - similar to `llvm.dbg.declare` except that it needs; to compose with `llvm.dbg.assign` intrinsics such that the stack home address; is only selected as a location for the variable when",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:10149,Modifiability,variab,variable,10149," no location) for each variable. In order to; make those decisions we run a standard fixed-point dataflow analysis that makes; the choice at each instruction, iteratively joining the results for each block. ### TODO list. As this is an experimental work in progress so there are some items we still need; to tackle:. * As mentioned in test llvm/test/DebugInfo/assignment-tracking/X86/diamond-3.ll,; the analysis should treat escaping calls like untagged stores. * The system expects locals to be backed by a local alloca. This isn't always; the case - sometimes a pointer to storage is passed into a function; (e.g. sret, byval). We need to be able to handle those cases. See; llvm/test/DebugInfo/Generic/assignment-tracking/track-assignments.ll and; clang/test/CodeGen/assignment-tracking/assignment-tracking.cpp for examples. * `trackAssignments` doesn't yet work for variables that have their; `llvm.dbg.declare` location modified by a `DIExpression`, e.g. when the; address of the variable is itself stored in an `alloca` with the; `llvm.dbg.declare` using `DIExpression(DW_OP_deref)`. See `indirectReturn` in; llvm/test/DebugInfo/Generic/assignment-tracking/track-assignments.ll and in; clang/test/CodeGen/assignment-tracking/assignment-tracking.cpp for an; example. * In order to solve the first bullet-point we need to be able to specify that a; memory location is available without using a `DIAssignID`. This is because; the storage address is not computed by an instruction (it's an argument; value) and therefore we have nowhere to put the metadata attachment. To solve; this we probably need another marker intrinsic to denote ""the variable's; stack home is X address"" - similar to `llvm.dbg.declare` except that it needs; to compose with `llvm.dbg.assign` intrinsics such that the stack home address; is only selected as a location for the variable when the `llvm.dbg.assign`; intrinsics agree it should be. * Given the above (a special ""the stack home is X"" intrinsic), and the fact; that",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:10807,Modifiability,variab,variable,10807," block. ### TODO list. As this is an experimental work in progress so there are some items we still need; to tackle:. * As mentioned in test llvm/test/DebugInfo/assignment-tracking/X86/diamond-3.ll,; the analysis should treat escaping calls like untagged stores. * The system expects locals to be backed by a local alloca. This isn't always; the case - sometimes a pointer to storage is passed into a function; (e.g. sret, byval). We need to be able to handle those cases. See; llvm/test/DebugInfo/Generic/assignment-tracking/track-assignments.ll and; clang/test/CodeGen/assignment-tracking/assignment-tracking.cpp for examples. * `trackAssignments` doesn't yet work for variables that have their; `llvm.dbg.declare` location modified by a `DIExpression`, e.g. when the; address of the variable is itself stored in an `alloca` with the; `llvm.dbg.declare` using `DIExpression(DW_OP_deref)`. See `indirectReturn` in; llvm/test/DebugInfo/Generic/assignment-tracking/track-assignments.ll and in; clang/test/CodeGen/assignment-tracking/assignment-tracking.cpp for an; example. * In order to solve the first bullet-point we need to be able to specify that a; memory location is available without using a `DIAssignID`. This is because; the storage address is not computed by an instruction (it's an argument; value) and therefore we have nowhere to put the metadata attachment. To solve; this we probably need another marker intrinsic to denote ""the variable's; stack home is X address"" - similar to `llvm.dbg.declare` except that it needs; to compose with `llvm.dbg.assign` intrinsics such that the stack home address; is only selected as a location for the variable when the `llvm.dbg.assign`; intrinsics agree it should be. * Given the above (a special ""the stack home is X"" intrinsic), and the fact; that we can only track assignments with fixed offsets and sizes, I think we; can probably get rid of the address and address-expression part, since it; will always be computable with the info we have.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:11016,Modifiability,variab,variable,11016," block. ### TODO list. As this is an experimental work in progress so there are some items we still need; to tackle:. * As mentioned in test llvm/test/DebugInfo/assignment-tracking/X86/diamond-3.ll,; the analysis should treat escaping calls like untagged stores. * The system expects locals to be backed by a local alloca. This isn't always; the case - sometimes a pointer to storage is passed into a function; (e.g. sret, byval). We need to be able to handle those cases. See; llvm/test/DebugInfo/Generic/assignment-tracking/track-assignments.ll and; clang/test/CodeGen/assignment-tracking/assignment-tracking.cpp for examples. * `trackAssignments` doesn't yet work for variables that have their; `llvm.dbg.declare` location modified by a `DIExpression`, e.g. when the; address of the variable is itself stored in an `alloca` with the; `llvm.dbg.declare` using `DIExpression(DW_OP_deref)`. See `indirectReturn` in; llvm/test/DebugInfo/Generic/assignment-tracking/track-assignments.ll and in; clang/test/CodeGen/assignment-tracking/assignment-tracking.cpp for an; example. * In order to solve the first bullet-point we need to be able to specify that a; memory location is available without using a `DIAssignID`. This is because; the storage address is not computed by an instruction (it's an argument; value) and therefore we have nowhere to put the metadata attachment. To solve; this we probably need another marker intrinsic to denote ""the variable's; stack home is X address"" - similar to `llvm.dbg.declare` except that it needs; to compose with `llvm.dbg.assign` intrinsics such that the stack home address; is only selected as a location for the variable when the `llvm.dbg.assign`; intrinsics agree it should be. * Given the above (a special ""the stack home is X"" intrinsic), and the fact; that we can only track assignments with fixed offsets and sizes, I think we; can probably get rid of the address and address-expression part, since it; will always be computable with the info we have.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:338,Performance,optimiz,optimized,338,"# Debug Info Assignment Tracking. Assignment Tracking is an alternative technique for tracking variable location; debug info through optimisations in LLVM. It provides accurate variable; locations for assignments where a local variable (or a field of one) is the; LHS. In rare and complicated circumstances indirect assignments might be; optimized away without being tracked, but otherwise we make our best effort to; track all variable locations. The core idea is to track more information about source assignments in order; and preserve enough information to be able to defer decisions about whether to; use non-memory locations (register, constant) or memory locations until after; middle end optimisations have run. This is in opposition to using; `llvm.dbg.declare` and `llvm.dbg.value`, which is to make the decision for most; variables early on, which can result in suboptimal variable locations that may; be either incorrect or incomplete. A secondary goal of assignment tracking is to cause minimal additional work for; LLVM pass writers, and minimal disruption to LLVM in general. ## Status and usage. **Status**: Experimental work in progress. Enabling is strongly advised against; except for development and testing. **Enable in Clang**: `-Xclang -fexperimental-assignment-tracking`. That causes Clang to get LLVM to run the pass `declare-to-assign`. The pass; converts conventional debug intrinsics to assignment tracking metadata and sets; the module flag `debug-info-assignment-tracking` to the value `i1 true`. To; check whether assignment tracking is enabled for a module call; `isAssignmentTrackingEnabled(const Module &M)` (from `llvm/IR/DebugInfo.h`). ## Design and implementation. ### Assignment markers: `llvm.dbg.assign`. `llvm.dbg.value`, a conventional debug intrinsic, marks out a position in the; IR where a variable takes a particular value. Similarly, Assignment Tracking; marks out the position of assignments with a new intrinsic called; `llvm.dbg.assign`. In order to k",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:2166,Performance,perform,performs,2166,"l. ## Status and usage. **Status**: Experimental work in progress. Enabling is strongly advised against; except for development and testing. **Enable in Clang**: `-Xclang -fexperimental-assignment-tracking`. That causes Clang to get LLVM to run the pass `declare-to-assign`. The pass; converts conventional debug intrinsics to assignment tracking metadata and sets; the module flag `debug-info-assignment-tracking` to the value `i1 true`. To; check whether assignment tracking is enabled for a module call; `isAssignmentTrackingEnabled(const Module &M)` (from `llvm/IR/DebugInfo.h`). ## Design and implementation. ### Assignment markers: `llvm.dbg.assign`. `llvm.dbg.value`, a conventional debug intrinsic, marks out a position in the; IR where a variable takes a particular value. Similarly, Assignment Tracking; marks out the position of assignments with a new intrinsic called; `llvm.dbg.assign`. In order to know where in IR it is appropriate to use a memory location for a; variable, each assignment marker must in some way refer to the store, if any; (or multiple!), that performs the assignment. That way, the position of the; store and marker can be considered together when making that choice. Another; important benefit of referring to the store is that we can then build a two-way; mapping of stores<->markers that can be used to find markers that need to be; updated when stores are modified. An `llvm.dbg.assign` marker that is not linked to any instruction signals that; the store that performed the assignment has been optimised out, and therefore; the memory location will not be valid for at least some part of the program. Here's the `llvm.dbg.assign` signature. Each parameter is wrapped in; `MetadataAsValue`, and `Value *` type parameters are first wrapped in; `ValueAsMetadata`:. ```; void @llvm.dbg.assign(Value *Value,; DIExpression *ValueExpression,; DILocalVariable *Variable,; DIAssignID *ID,; Value *Address,; DIExpression *AddressExpression); ```. The first three paramete",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:2588,Performance,perform,performed,2588,"nabled(const Module &M)` (from `llvm/IR/DebugInfo.h`). ## Design and implementation. ### Assignment markers: `llvm.dbg.assign`. `llvm.dbg.value`, a conventional debug intrinsic, marks out a position in the; IR where a variable takes a particular value. Similarly, Assignment Tracking; marks out the position of assignments with a new intrinsic called; `llvm.dbg.assign`. In order to know where in IR it is appropriate to use a memory location for a; variable, each assignment marker must in some way refer to the store, if any; (or multiple!), that performs the assignment. That way, the position of the; store and marker can be considered together when making that choice. Another; important benefit of referring to the store is that we can then build a two-way; mapping of stores<->markers that can be used to find markers that need to be; updated when stores are modified. An `llvm.dbg.assign` marker that is not linked to any instruction signals that; the store that performed the assignment has been optimised out, and therefore; the memory location will not be valid for at least some part of the program. Here's the `llvm.dbg.assign` signature. Each parameter is wrapped in; `MetadataAsValue`, and `Value *` type parameters are first wrapped in; `ValueAsMetadata`:. ```; void @llvm.dbg.assign(Value *Value,; DIExpression *ValueExpression,; DILocalVariable *Variable,; DIAssignID *ID,; Value *Address,; DIExpression *AddressExpression); ```. The first three parameters look and behave like an `llvm.dbg.value`. `ID` is a; reference to a store (see next section). `Address` is the destination address; of the store and it is modified by `AddressExpression`. An empty/undef/poison; address means the address component has been killed (the memory address is no; longer a valid location). LLVM currently encodes variable fragment information; in `DIExpression`s, so as an implementation quirk the `FragmentInfo` for; `Variable` is contained within `ValueExpression` only. The formal LLVM-IR signatu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:4869,Performance,load,load,4869,"e metadata node has no operands and all instances are; `distinct`; equality is checked for by comparing addresses. `llvm.dbg.assign` intrinsics use a `DIAssignID` metadata node instance as an; operand. This way it refers to any store-like instruction that has the same; `DIAssignID` attachment. E.g. For this test.cpp,. ```; int fun(int a) {; return a;; }; ```; compiled without optimisations:; ```; $ clang++ test.cpp -o test.ll -emit-llvm -S -g -O0 -Xclang -fexperimental-assignment-tracking; ```; we get:; ```; define dso_local noundef i32 @_Z3funi(i32 noundef %a) #0 !dbg !8 {; entry:; %a.addr = alloca i32, align 4, !DIAssignID !13; call void @llvm.dbg.assign(metadata i1 undef, metadata !14, metadata !DIExpression(), metadata !13, metadata i32* %a.addr, metadata !DIExpression()), !dbg !15; store i32 %a, i32* %a.addr, align 4, !DIAssignID !16; call void @llvm.dbg.assign(metadata i32 %a, metadata !14, metadata !DIExpression(), metadata !16, metadata i32* %a.addr, metadata !DIExpression()), !dbg !15; %0 = load i32, i32* %a.addr, align 4, !dbg !17; ret i32 %0, !dbg !18; }. ...; !13 = distinct !DIAssignID(); !14 = !DILocalVariable(name: ""a"", ...); ...; !16 = distinct !DIAssignID(); ```. The first `llvm.dbg.assign` refers to the `alloca` through `!DIAssignID !13`,; and the second refers to the `store` through `!DIAssignID !16`. ### Store-like instructions. In the absence of a linked `llvm.dbg.assign`, a store to an address that is; known to be the backing storage for a variable is considered to represent an; assignment to that variable. This gives us a safe fall-back in cases where `llvm.dbg.assign` intrinsics have; been deleted, the `DIAssignID` attachment on the store has been dropped, or the; optimiser has made a once-indirect store (not tracked with Assignment Tracking); direct. ### Middle-end: Considerations for pass-writers. #### Non-debug instruction updates. **Cloning** an instruction: nothing new to do. Cloning automatically clones a; `DIAssignID` attachment. Multip",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:7855,Performance,load,loads,7855,"y calling a helper function; `Instruction::mergeDIAssignID`. **Inlining** stores: As stores are inlined we generate `llvm.dbg.assign`; intrinsics and `DIAssignID` attachments as if the stores represent source; assignments, just like the in frontend. This isn’t perfect, as stores may have; been moved, modified or deleted before inlining, but it does at least keep the; information about the variable correct within the non-inlined scope. **Splitting** stores: SROA and passes that split stores treat `llvm.dbg.assign`; intrinsics similarly to `llvm.dbg.declare` intrinsics. Clone the; `llvm.dbg.assign` intrinsics linked to the store, update the FragmentInfo in; the `ValueExpression`, and give the split stores (and cloned intrinsics) new; `DIAssignID` attachments each. In other words, treat the split stores as; separate assignments. For partial DSE (e.g. shortening a memset), we do the; same except that `llvm.dbg.assign` for the dead fragment gets an `Undef`; `Address`. **Promoting** allocas and store/loads: `llvm.dbg.assign` intrinsics implicitly; describe joined values in memory locations at CFG joins, but this is not; necessarily the case after promoting (or partially promoting) the; variable. Passes that promote variables are responsible for inserting; `llvm.dbg.assign` intrinsics after the resultant PHIs generated during; promotion. `mem2reg` already has to do this (with `llvm.dbg.value`) for; `llvm.dbg.declare`s. Where a store has no linked intrinsic, the store is; assumed to represent an assignment for variables stored at the destination; address. #### Debug intrinsic updates. **Moving** a debug intrinsic: avoid moving `llvm.dbg.assign` intrinsics where; possible, as they represent a source-level assignment, whose position in the; program should not be affected by optimization passes. **Deleting** a debug intrinsic: Nothing new to do. Just like for conventional; debug intrinsics, unless it is unreachable, it’s almost always incorrect to; delete a `llvm.dbg.assign` i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:8640,Performance,optimiz,optimization,8640," new; `DIAssignID` attachments each. In other words, treat the split stores as; separate assignments. For partial DSE (e.g. shortening a memset), we do the; same except that `llvm.dbg.assign` for the dead fragment gets an `Undef`; `Address`. **Promoting** allocas and store/loads: `llvm.dbg.assign` intrinsics implicitly; describe joined values in memory locations at CFG joins, but this is not; necessarily the case after promoting (or partially promoting) the; variable. Passes that promote variables are responsible for inserting; `llvm.dbg.assign` intrinsics after the resultant PHIs generated during; promotion. `mem2reg` already has to do this (with `llvm.dbg.value`) for; `llvm.dbg.declare`s. Where a store has no linked intrinsic, the store is; assumed to represent an assignment for variables stored at the destination; address. #### Debug intrinsic updates. **Moving** a debug intrinsic: avoid moving `llvm.dbg.assign` intrinsics where; possible, as they represent a source-level assignment, whose position in the; program should not be affected by optimization passes. **Deleting** a debug intrinsic: Nothing new to do. Just like for conventional; debug intrinsics, unless it is unreachable, it’s almost always incorrect to; delete a `llvm.dbg.assign` intrinsic. ### Lowering `llvm.dbg.assign` to MIR. To begin with only SelectionDAG ISel will be supported. `llvm.dbg.assign`; intrinsics are lowered to MIR `DBG_INSTR_REF` instructions. Before this happens; we need to decide where it is appropriate to use memory locations and where we; must use a non-memory location (or no location) for each variable. In order to; make those decisions we run a standard fixed-point dataflow analysis that makes; the choice at each instruction, iteratively joining the results for each block. ### TODO list. As this is an experimental work in progress so there are some items we still need; to tackle:. * As mentioned in test llvm/test/DebugInfo/assignment-tracking/X86/diamond-3.ll,; the analysis shoul",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:5424,Safety,safe,safe,5424,"{; entry:; %a.addr = alloca i32, align 4, !DIAssignID !13; call void @llvm.dbg.assign(metadata i1 undef, metadata !14, metadata !DIExpression(), metadata !13, metadata i32* %a.addr, metadata !DIExpression()), !dbg !15; store i32 %a, i32* %a.addr, align 4, !DIAssignID !16; call void @llvm.dbg.assign(metadata i32 %a, metadata !14, metadata !DIExpression(), metadata !16, metadata i32* %a.addr, metadata !DIExpression()), !dbg !15; %0 = load i32, i32* %a.addr, align 4, !dbg !17; ret i32 %0, !dbg !18; }. ...; !13 = distinct !DIAssignID(); !14 = !DILocalVariable(name: ""a"", ...); ...; !16 = distinct !DIAssignID(); ```. The first `llvm.dbg.assign` refers to the `alloca` through `!DIAssignID !13`,; and the second refers to the `store` through `!DIAssignID !16`. ### Store-like instructions. In the absence of a linked `llvm.dbg.assign`, a store to an address that is; known to be the backing storage for a variable is considered to represent an; assignment to that variable. This gives us a safe fall-back in cases where `llvm.dbg.assign` intrinsics have; been deleted, the `DIAssignID` attachment on the store has been dropped, or the; optimiser has made a once-indirect store (not tracked with Assignment Tracking); direct. ### Middle-end: Considerations for pass-writers. #### Non-debug instruction updates. **Cloning** an instruction: nothing new to do. Cloning automatically clones a; `DIAssignID` attachment. Multiple instructions may have the same `DIAssignID`; instruction. In this case, the assignment is considered to take place in; multiple positions in the program. **Moving** a non-debug instruction: nothing new to do. Instructions linked to an; `llvm.dbg.assign` have their initial IR position marked by the position of the; `llvm.dbg.assign`. **Deleting** a non-debug instruction: nothing new to do. Simple DSE does not; require any change; it’s safe to delete an instruction with a `DIAssignID`; attachment. An `llvm.dbg.assign` that uses a `DIAssignID` that is not attached; to any i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:6295,Safety,safe,safe,6295,"nown to be the backing storage for a variable is considered to represent an; assignment to that variable. This gives us a safe fall-back in cases where `llvm.dbg.assign` intrinsics have; been deleted, the `DIAssignID` attachment on the store has been dropped, or the; optimiser has made a once-indirect store (not tracked with Assignment Tracking); direct. ### Middle-end: Considerations for pass-writers. #### Non-debug instruction updates. **Cloning** an instruction: nothing new to do. Cloning automatically clones a; `DIAssignID` attachment. Multiple instructions may have the same `DIAssignID`; instruction. In this case, the assignment is considered to take place in; multiple positions in the program. **Moving** a non-debug instruction: nothing new to do. Instructions linked to an; `llvm.dbg.assign` have their initial IR position marked by the position of the; `llvm.dbg.assign`. **Deleting** a non-debug instruction: nothing new to do. Simple DSE does not; require any change; it’s safe to delete an instruction with a `DIAssignID`; attachment. An `llvm.dbg.assign` that uses a `DIAssignID` that is not attached; to any instruction indicates that the memory location isn’t valid. **Merging** stores: In many cases no change is required as `DIAssignID`; attachments are automatically merged if `combineMetadata` is called. One way or; another, the `DIAssignID` attachments must be merged such that new store; becomes linked to all the `llvm.dbg.assign` intrinsics that the merged stores; were linked to. This can be achieved simply by calling a helper function; `Instruction::mergeDIAssignID`. **Inlining** stores: As stores are inlined we generate `llvm.dbg.assign`; intrinsics and `DIAssignID` attachments as if the stores represent source; assignments, just like the in frontend. This isn’t perfect, as stores may have; been moved, modified or deleted before inlining, but it does at least keep the; information about the variable correct within the non-inlined scope. **Splitting** store",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:8479,Safety,avoid,avoid,8479," store, update the FragmentInfo in; the `ValueExpression`, and give the split stores (and cloned intrinsics) new; `DIAssignID` attachments each. In other words, treat the split stores as; separate assignments. For partial DSE (e.g. shortening a memset), we do the; same except that `llvm.dbg.assign` for the dead fragment gets an `Undef`; `Address`. **Promoting** allocas and store/loads: `llvm.dbg.assign` intrinsics implicitly; describe joined values in memory locations at CFG joins, but this is not; necessarily the case after promoting (or partially promoting) the; variable. Passes that promote variables are responsible for inserting; `llvm.dbg.assign` intrinsics after the resultant PHIs generated during; promotion. `mem2reg` already has to do this (with `llvm.dbg.value`) for; `llvm.dbg.declare`s. Where a store has no linked intrinsic, the store is; assumed to represent an assignment for variables stored at the destination; address. #### Debug intrinsic updates. **Moving** a debug intrinsic: avoid moving `llvm.dbg.assign` intrinsics where; possible, as they represent a source-level assignment, whose position in the; program should not be affected by optimization passes. **Deleting** a debug intrinsic: Nothing new to do. Just like for conventional; debug intrinsics, unless it is unreachable, it’s almost always incorrect to; delete a `llvm.dbg.assign` intrinsic. ### Lowering `llvm.dbg.assign` to MIR. To begin with only SelectionDAG ISel will be supported. `llvm.dbg.assign`; intrinsics are lowered to MIR `DBG_INSTR_REF` instructions. Before this happens; we need to decide where it is appropriate to use memory locations and where we; must use a non-memory location (or no location) for each variable. In order to; make those decisions we run a standard fixed-point dataflow analysis that makes; the choice at each instruction, iteratively joining the results for each block. ### TODO list. As this is an experimental work in progress so there are some items we still need; to t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:1220,Testability,test,testing,1220,"tions for assignments where a local variable (or a field of one) is the; LHS. In rare and complicated circumstances indirect assignments might be; optimized away without being tracked, but otherwise we make our best effort to; track all variable locations. The core idea is to track more information about source assignments in order; and preserve enough information to be able to defer decisions about whether to; use non-memory locations (register, constant) or memory locations until after; middle end optimisations have run. This is in opposition to using; `llvm.dbg.declare` and `llvm.dbg.value`, which is to make the decision for most; variables early on, which can result in suboptimal variable locations that may; be either incorrect or incomplete. A secondary goal of assignment tracking is to cause minimal additional work for; LLVM pass writers, and minimal disruption to LLVM in general. ## Status and usage. **Status**: Experimental work in progress. Enabling is strongly advised against; except for development and testing. **Enable in Clang**: `-Xclang -fexperimental-assignment-tracking`. That causes Clang to get LLVM to run the pass `declare-to-assign`. The pass; converts conventional debug intrinsics to assignment tracking metadata and sets; the module flag `debug-info-assignment-tracking` to the value `i1 true`. To; check whether assignment tracking is enabled for a module call; `isAssignmentTrackingEnabled(const Module &M)` (from `llvm/IR/DebugInfo.h`). ## Design and implementation. ### Assignment markers: `llvm.dbg.assign`. `llvm.dbg.value`, a conventional debug intrinsic, marks out a position in the; IR where a variable takes a particular value. Similarly, Assignment Tracking; marks out the position of assignments with a new intrinsic called; `llvm.dbg.assign`. In order to know where in IR it is appropriate to use a memory location for a; variable, each assignment marker must in some way refer to the store, if any; (or multiple!), that performs the assignment. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:4163,Testability,test,test,4163,"store (see next section). `Address` is the destination address; of the store and it is modified by `AddressExpression`. An empty/undef/poison; address means the address component has been killed (the memory address is no; longer a valid location). LLVM currently encodes variable fragment information; in `DIExpression`s, so as an implementation quirk the `FragmentInfo` for; `Variable` is contained within `ValueExpression` only. The formal LLVM-IR signature is:; ```; void @llvm.dbg.assign(metadata, metadata, metadata, metadata, metadata, metadata); ```. ### Instruction link: `DIAssignID`. `DIAssignID` metadata is the mechanism that is currently used to encode the; store<->marker link. The metadata node has no operands and all instances are; `distinct`; equality is checked for by comparing addresses. `llvm.dbg.assign` intrinsics use a `DIAssignID` metadata node instance as an; operand. This way it refers to any store-like instruction that has the same; `DIAssignID` attachment. E.g. For this test.cpp,. ```; int fun(int a) {; return a;; }; ```; compiled without optimisations:; ```; $ clang++ test.cpp -o test.ll -emit-llvm -S -g -O0 -Xclang -fexperimental-assignment-tracking; ```; we get:; ```; define dso_local noundef i32 @_Z3funi(i32 noundef %a) #0 !dbg !8 {; entry:; %a.addr = alloca i32, align 4, !DIAssignID !13; call void @llvm.dbg.assign(metadata i1 undef, metadata !14, metadata !DIExpression(), metadata !13, metadata i32* %a.addr, metadata !DIExpression()), !dbg !15; store i32 %a, i32* %a.addr, align 4, !DIAssignID !16; call void @llvm.dbg.assign(metadata i32 %a, metadata !14, metadata !DIExpression(), metadata !16, metadata i32* %a.addr, metadata !DIExpression()), !dbg !15; %0 = load i32, i32* %a.addr, align 4, !dbg !17; ret i32 %0, !dbg !18; }. ...; !13 = distinct !DIAssignID(); !14 = !DILocalVariable(name: ""a"", ...); ...; !16 = distinct !DIAssignID(); ```. The first `llvm.dbg.assign` refers to the `alloca` through `!DIAssignID !13`,; and the second refers to the `",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:4264,Testability,test,test,4264,"s; of the store and it is modified by `AddressExpression`. An empty/undef/poison; address means the address component has been killed (the memory address is no; longer a valid location). LLVM currently encodes variable fragment information; in `DIExpression`s, so as an implementation quirk the `FragmentInfo` for; `Variable` is contained within `ValueExpression` only. The formal LLVM-IR signature is:; ```; void @llvm.dbg.assign(metadata, metadata, metadata, metadata, metadata, metadata); ```. ### Instruction link: `DIAssignID`. `DIAssignID` metadata is the mechanism that is currently used to encode the; store<->marker link. The metadata node has no operands and all instances are; `distinct`; equality is checked for by comparing addresses. `llvm.dbg.assign` intrinsics use a `DIAssignID` metadata node instance as an; operand. This way it refers to any store-like instruction that has the same; `DIAssignID` attachment. E.g. For this test.cpp,. ```; int fun(int a) {; return a;; }; ```; compiled without optimisations:; ```; $ clang++ test.cpp -o test.ll -emit-llvm -S -g -O0 -Xclang -fexperimental-assignment-tracking; ```; we get:; ```; define dso_local noundef i32 @_Z3funi(i32 noundef %a) #0 !dbg !8 {; entry:; %a.addr = alloca i32, align 4, !DIAssignID !13; call void @llvm.dbg.assign(metadata i1 undef, metadata !14, metadata !DIExpression(), metadata !13, metadata i32* %a.addr, metadata !DIExpression()), !dbg !15; store i32 %a, i32* %a.addr, align 4, !DIAssignID !16; call void @llvm.dbg.assign(metadata i32 %a, metadata !14, metadata !DIExpression(), metadata !16, metadata i32* %a.addr, metadata !DIExpression()), !dbg !15; %0 = load i32, i32* %a.addr, align 4, !dbg !17; ret i32 %0, !dbg !18; }. ...; !13 = distinct !DIAssignID(); !14 = !DILocalVariable(name: ""a"", ...); ...; !16 = distinct !DIAssignID(); ```. The first `llvm.dbg.assign` refers to the `alloca` through `!DIAssignID !13`,; and the second refers to the `store` through `!DIAssignID !16`. ### Store-like instruction",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:4276,Testability,test,test,4276,"on`. An empty/undef/poison; address means the address component has been killed (the memory address is no; longer a valid location). LLVM currently encodes variable fragment information; in `DIExpression`s, so as an implementation quirk the `FragmentInfo` for; `Variable` is contained within `ValueExpression` only. The formal LLVM-IR signature is:; ```; void @llvm.dbg.assign(metadata, metadata, metadata, metadata, metadata, metadata); ```. ### Instruction link: `DIAssignID`. `DIAssignID` metadata is the mechanism that is currently used to encode the; store<->marker link. The metadata node has no operands and all instances are; `distinct`; equality is checked for by comparing addresses. `llvm.dbg.assign` intrinsics use a `DIAssignID` metadata node instance as an; operand. This way it refers to any store-like instruction that has the same; `DIAssignID` attachment. E.g. For this test.cpp,. ```; int fun(int a) {; return a;; }; ```; compiled without optimisations:; ```; $ clang++ test.cpp -o test.ll -emit-llvm -S -g -O0 -Xclang -fexperimental-assignment-tracking; ```; we get:; ```; define dso_local noundef i32 @_Z3funi(i32 noundef %a) #0 !dbg !8 {; entry:; %a.addr = alloca i32, align 4, !DIAssignID !13; call void @llvm.dbg.assign(metadata i1 undef, metadata !14, metadata !DIExpression(), metadata !13, metadata i32* %a.addr, metadata !DIExpression()), !dbg !15; store i32 %a, i32* %a.addr, align 4, !DIAssignID !16; call void @llvm.dbg.assign(metadata i32 %a, metadata !14, metadata !DIExpression(), metadata !16, metadata i32* %a.addr, metadata !DIExpression()), !dbg !15; %0 = load i32, i32* %a.addr, align 4, !dbg !17; ret i32 %0, !dbg !18; }. ...; !13 = distinct !DIAssignID(); !14 = !DILocalVariable(name: ""a"", ...); ...; !16 = distinct !DIAssignID(); ```. The first `llvm.dbg.assign` refers to the `alloca` through `!DIAssignID !13`,; and the second refers to the `store` through `!DIAssignID !16`. ### Store-like instructions. In the absence of a linked `llvm.dbg.assign`, a sto",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:9499,Testability,test,test,9499,"s where; possible, as they represent a source-level assignment, whose position in the; program should not be affected by optimization passes. **Deleting** a debug intrinsic: Nothing new to do. Just like for conventional; debug intrinsics, unless it is unreachable, it’s almost always incorrect to; delete a `llvm.dbg.assign` intrinsic. ### Lowering `llvm.dbg.assign` to MIR. To begin with only SelectionDAG ISel will be supported. `llvm.dbg.assign`; intrinsics are lowered to MIR `DBG_INSTR_REF` instructions. Before this happens; we need to decide where it is appropriate to use memory locations and where we; must use a non-memory location (or no location) for each variable. In order to; make those decisions we run a standard fixed-point dataflow analysis that makes; the choice at each instruction, iteratively joining the results for each block. ### TODO list. As this is an experimental work in progress so there are some items we still need; to tackle:. * As mentioned in test llvm/test/DebugInfo/assignment-tracking/X86/diamond-3.ll,; the analysis should treat escaping calls like untagged stores. * The system expects locals to be backed by a local alloca. This isn't always; the case - sometimes a pointer to storage is passed into a function; (e.g. sret, byval). We need to be able to handle those cases. See; llvm/test/DebugInfo/Generic/assignment-tracking/track-assignments.ll and; clang/test/CodeGen/assignment-tracking/assignment-tracking.cpp for examples. * `trackAssignments` doesn't yet work for variables that have their; `llvm.dbg.declare` location modified by a `DIExpression`, e.g. when the; address of the variable is itself stored in an `alloca` with the; `llvm.dbg.declare` using `DIExpression(DW_OP_deref)`. See `indirectReturn` in; llvm/test/DebugInfo/Generic/assignment-tracking/track-assignments.ll and in; clang/test/CodeGen/assignment-tracking/assignment-tracking.cpp for an; example. * In order to solve the first bullet-point we need to be able to specify that a; me",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:9509,Testability,test,test,9509,"s where; possible, as they represent a source-level assignment, whose position in the; program should not be affected by optimization passes. **Deleting** a debug intrinsic: Nothing new to do. Just like for conventional; debug intrinsics, unless it is unreachable, it’s almost always incorrect to; delete a `llvm.dbg.assign` intrinsic. ### Lowering `llvm.dbg.assign` to MIR. To begin with only SelectionDAG ISel will be supported. `llvm.dbg.assign`; intrinsics are lowered to MIR `DBG_INSTR_REF` instructions. Before this happens; we need to decide where it is appropriate to use memory locations and where we; must use a non-memory location (or no location) for each variable. In order to; make those decisions we run a standard fixed-point dataflow analysis that makes; the choice at each instruction, iteratively joining the results for each block. ### TODO list. As this is an experimental work in progress so there are some items we still need; to tackle:. * As mentioned in test llvm/test/DebugInfo/assignment-tracking/X86/diamond-3.ll,; the analysis should treat escaping calls like untagged stores. * The system expects locals to be backed by a local alloca. This isn't always; the case - sometimes a pointer to storage is passed into a function; (e.g. sret, byval). We need to be able to handle those cases. See; llvm/test/DebugInfo/Generic/assignment-tracking/track-assignments.ll and; clang/test/CodeGen/assignment-tracking/assignment-tracking.cpp for examples. * `trackAssignments` doesn't yet work for variables that have their; `llvm.dbg.declare` location modified by a `DIExpression`, e.g. when the; address of the variable is itself stored in an `alloca` with the; `llvm.dbg.declare` using `DIExpression(DW_OP_deref)`. See `indirectReturn` in; llvm/test/DebugInfo/Generic/assignment-tracking/track-assignments.ll and in; clang/test/CodeGen/assignment-tracking/assignment-tracking.cpp for an; example. * In order to solve the first bullet-point we need to be able to specify that a; me",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:9846,Testability,test,test,9846,"vm.dbg.assign` to MIR. To begin with only SelectionDAG ISel will be supported. `llvm.dbg.assign`; intrinsics are lowered to MIR `DBG_INSTR_REF` instructions. Before this happens; we need to decide where it is appropriate to use memory locations and where we; must use a non-memory location (or no location) for each variable. In order to; make those decisions we run a standard fixed-point dataflow analysis that makes; the choice at each instruction, iteratively joining the results for each block. ### TODO list. As this is an experimental work in progress so there are some items we still need; to tackle:. * As mentioned in test llvm/test/DebugInfo/assignment-tracking/X86/diamond-3.ll,; the analysis should treat escaping calls like untagged stores. * The system expects locals to be backed by a local alloca. This isn't always; the case - sometimes a pointer to storage is passed into a function; (e.g. sret, byval). We need to be able to handle those cases. See; llvm/test/DebugInfo/Generic/assignment-tracking/track-assignments.ll and; clang/test/CodeGen/assignment-tracking/assignment-tracking.cpp for examples. * `trackAssignments` doesn't yet work for variables that have their; `llvm.dbg.declare` location modified by a `DIExpression`, e.g. when the; address of the variable is itself stored in an `alloca` with the; `llvm.dbg.declare` using `DIExpression(DW_OP_deref)`. See `indirectReturn` in; llvm/test/DebugInfo/Generic/assignment-tracking/track-assignments.ll and in; clang/test/CodeGen/assignment-tracking/assignment-tracking.cpp for an; example. * In order to solve the first bullet-point we need to be able to specify that a; memory location is available without using a `DIAssignID`. This is because; the storage address is not computed by an instruction (it's an argument; value) and therefore we have nowhere to put the metadata attachment. To solve; this we probably need another marker intrinsic to denote ""the variable's; stack home is X address"" - similar to `llvm.dbg.decl",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:9921,Testability,test,test,9921,"upported. `llvm.dbg.assign`; intrinsics are lowered to MIR `DBG_INSTR_REF` instructions. Before this happens; we need to decide where it is appropriate to use memory locations and where we; must use a non-memory location (or no location) for each variable. In order to; make those decisions we run a standard fixed-point dataflow analysis that makes; the choice at each instruction, iteratively joining the results for each block. ### TODO list. As this is an experimental work in progress so there are some items we still need; to tackle:. * As mentioned in test llvm/test/DebugInfo/assignment-tracking/X86/diamond-3.ll,; the analysis should treat escaping calls like untagged stores. * The system expects locals to be backed by a local alloca. This isn't always; the case - sometimes a pointer to storage is passed into a function; (e.g. sret, byval). We need to be able to handle those cases. See; llvm/test/DebugInfo/Generic/assignment-tracking/track-assignments.ll and; clang/test/CodeGen/assignment-tracking/assignment-tracking.cpp for examples. * `trackAssignments` doesn't yet work for variables that have their; `llvm.dbg.declare` location modified by a `DIExpression`, e.g. when the; address of the variable is itself stored in an `alloca` with the; `llvm.dbg.declare` using `DIExpression(DW_OP_deref)`. See `indirectReturn` in; llvm/test/DebugInfo/Generic/assignment-tracking/track-assignments.ll and in; clang/test/CodeGen/assignment-tracking/assignment-tracking.cpp for an; example. * In order to solve the first bullet-point we need to be able to specify that a; memory location is available without using a `DIAssignID`. This is because; the storage address is not computed by an instruction (it's an argument; value) and therefore we have nowhere to put the metadata attachment. To solve; this we probably need another marker intrinsic to denote ""the variable's; stack home is X address"" - similar to `llvm.dbg.declare` except that it needs; to compose with `llvm.dbg.assign` intrinsic",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:10284,Testability,test,test,10284,"ce at each instruction, iteratively joining the results for each block. ### TODO list. As this is an experimental work in progress so there are some items we still need; to tackle:. * As mentioned in test llvm/test/DebugInfo/assignment-tracking/X86/diamond-3.ll,; the analysis should treat escaping calls like untagged stores. * The system expects locals to be backed by a local alloca. This isn't always; the case - sometimes a pointer to storage is passed into a function; (e.g. sret, byval). We need to be able to handle those cases. See; llvm/test/DebugInfo/Generic/assignment-tracking/track-assignments.ll and; clang/test/CodeGen/assignment-tracking/assignment-tracking.cpp for examples. * `trackAssignments` doesn't yet work for variables that have their; `llvm.dbg.declare` location modified by a `DIExpression`, e.g. when the; address of the variable is itself stored in an `alloca` with the; `llvm.dbg.declare` using `DIExpression(DW_OP_deref)`. See `indirectReturn` in; llvm/test/DebugInfo/Generic/assignment-tracking/track-assignments.ll and in; clang/test/CodeGen/assignment-tracking/assignment-tracking.cpp for an; example. * In order to solve the first bullet-point we need to be able to specify that a; memory location is available without using a `DIAssignID`. This is because; the storage address is not computed by an instruction (it's an argument; value) and therefore we have nowhere to put the metadata attachment. To solve; this we probably need another marker intrinsic to denote ""the variable's; stack home is X address"" - similar to `llvm.dbg.declare` except that it needs; to compose with `llvm.dbg.assign` intrinsics such that the stack home address; is only selected as a location for the variable when the `llvm.dbg.assign`; intrinsics agree it should be. * Given the above (a special ""the stack home is X"" intrinsic), and the fact; that we can only track assignments with fixed offsets and sizes, I think we; can probably get rid of the address and address-expression pa",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:10362,Testability,test,test,10362," block. ### TODO list. As this is an experimental work in progress so there are some items we still need; to tackle:. * As mentioned in test llvm/test/DebugInfo/assignment-tracking/X86/diamond-3.ll,; the analysis should treat escaping calls like untagged stores. * The system expects locals to be backed by a local alloca. This isn't always; the case - sometimes a pointer to storage is passed into a function; (e.g. sret, byval). We need to be able to handle those cases. See; llvm/test/DebugInfo/Generic/assignment-tracking/track-assignments.ll and; clang/test/CodeGen/assignment-tracking/assignment-tracking.cpp for examples. * `trackAssignments` doesn't yet work for variables that have their; `llvm.dbg.declare` location modified by a `DIExpression`, e.g. when the; address of the variable is itself stored in an `alloca` with the; `llvm.dbg.declare` using `DIExpression(DW_OP_deref)`. See `indirectReturn` in; llvm/test/DebugInfo/Generic/assignment-tracking/track-assignments.ll and in; clang/test/CodeGen/assignment-tracking/assignment-tracking.cpp for an; example. * In order to solve the first bullet-point we need to be able to specify that a; memory location is available without using a `DIAssignID`. This is because; the storage address is not computed by an instruction (it's an argument; value) and therefore we have nowhere to put the metadata attachment. To solve; this we probably need another marker intrinsic to denote ""the variable's; stack home is X address"" - similar to `llvm.dbg.declare` except that it needs; to compose with `llvm.dbg.assign` intrinsics such that the stack home address; is only selected as a location for the variable when the `llvm.dbg.assign`; intrinsics agree it should be. * Given the above (a special ""the stack home is X"" intrinsic), and the fact; that we can only track assignments with fixed offsets and sizes, I think we; can probably get rid of the address and address-expression part, since it; will always be computable with the info we have.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:6837,Usability,simpl,simply,6837,"tructions may have the same `DIAssignID`; instruction. In this case, the assignment is considered to take place in; multiple positions in the program. **Moving** a non-debug instruction: nothing new to do. Instructions linked to an; `llvm.dbg.assign` have their initial IR position marked by the position of the; `llvm.dbg.assign`. **Deleting** a non-debug instruction: nothing new to do. Simple DSE does not; require any change; it’s safe to delete an instruction with a `DIAssignID`; attachment. An `llvm.dbg.assign` that uses a `DIAssignID` that is not attached; to any instruction indicates that the memory location isn’t valid. **Merging** stores: In many cases no change is required as `DIAssignID`; attachments are automatically merged if `combineMetadata` is called. One way or; another, the `DIAssignID` attachments must be merged such that new store; becomes linked to all the `llvm.dbg.assign` intrinsics that the merged stores; were linked to. This can be achieved simply by calling a helper function; `Instruction::mergeDIAssignID`. **Inlining** stores: As stores are inlined we generate `llvm.dbg.assign`; intrinsics and `DIAssignID` attachments as if the stores represent source; assignments, just like the in frontend. This isn’t perfect, as stores may have; been moved, modified or deleted before inlining, but it does at least keep the; information about the variable correct within the non-inlined scope. **Splitting** stores: SROA and passes that split stores treat `llvm.dbg.assign`; intrinsics similarly to `llvm.dbg.declare` intrinsics. Clone the; `llvm.dbg.assign` intrinsics linked to the store, update the FragmentInfo in; the `ValueExpression`, and give the split stores (and cloned intrinsics) new; `DIAssignID` attachments each. In other words, treat the split stores as; separate assignments. For partial DSE (e.g. shortening a memset), we do the; same except that `llvm.dbg.assign` for the dead fragment gets an `Undef`; `Address`. **Promoting** allocas and store/loads",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md:1745,Availability,failure,failure,1745,"but with more in-depth minimization. Granted, if the community differs on this proposal, the legacy code could still; be present in the tool, but with the caveat of still being documented and; designed towards delta reduction. ### Command-Line Options; We are proposing to reduce the plethora of bugpoint’s options to just two: an; interesting-ness test and the arguments for said test, similar to other delta; reduction tools such as CReduce, Delta, and Lithium; the tool should feel less; cluttered, and there should also be no uncertainty about how to operate it. The interesting-ness test that’s going to be run to reduce the code is given; by name:; `--test=<test_name>`; If a `--test` option is not given, the program exits; this option is similar; to bugpoint’s current `-compile-custom` option, which lets the user run a; custom script. The interesting-ness test would be defined as a script that returns 0 when the; IR achieves a user-defined behaviour (e.g. failure to compile on clang) and a; nonzero value when otherwise. Leaving the user the freedom to determine what is; and isn’t interesting to the tool, and thus, streamlining the process of; reducing a test-case. If the test accepts any arguments (excluding the input ll/bc file), they are; given via the following flag:; `--test_args=<test_arguments>`; If unspecified, the test is run as given. It’s worth noting that the input file; would be passed as a parameter to the test, similar how `-compile-custom`; currently operates. ### Implementation; The tool would behave similar to CReduce’s functionality in that it would have a; list of passes that try to minimize the given test-case. We should be able to; modularize the tool’s behavior, as well as making it easier to maintain and; expand. The first version of this redesign would try to:. * Discard functions, instructions and metadata that don’t influence the; interesting-ness test; * Remove unused parameters from functions; * Eliminate unvisited conditional paths; * Rena",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BugpointRedesign.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md:1050,Energy Efficiency,reduce,reduce,1050,"have been identified; through years of use: confusing to use, slow, it doesn’t always produce high; quality test cases, etc. This document proposes a new approach with a narrower; focus: minimization of IR test cases. ## Proposed New Design. ### Narrow focus: test-case reduction; The main focus will be a code reduction strategy to obtain much smaller test; cases that still have the same property as the original one. This will be done; via classic delta debugging and by adding some IR-specific reductions (e.g.; replacing globals, removing unused instructions, etc), similar to what; already exists, but with more in-depth minimization. Granted, if the community differs on this proposal, the legacy code could still; be present in the tool, but with the caveat of still being documented and; designed towards delta reduction. ### Command-Line Options; We are proposing to reduce the plethora of bugpoint’s options to just two: an; interesting-ness test and the arguments for said test, similar to other delta; reduction tools such as CReduce, Delta, and Lithium; the tool should feel less; cluttered, and there should also be no uncertainty about how to operate it. The interesting-ness test that’s going to be run to reduce the code is given; by name:; `--test=<test_name>`; If a `--test` option is not given, the program exits; this option is similar; to bugpoint’s current `-compile-custom` option, which lets the user run a; custom script. The interesting-ness test would be defined as a script that returns 0 when the; IR achieves a user-defined behaviour (e.g. failure to compile on clang) and a; nonzero value when otherwise. Leaving the user the freedom to determine what is; and isn’t interesting to the tool, and thus, streamlining the process of; reducing a test-case. If the test accepts any arguments (excluding the input ll/bc file), they are; given via the following flag:; `--test_args=<test_arguments>`; If unspecified, the test is run as given. It’s worth noting that the input",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BugpointRedesign.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md:1396,Energy Efficiency,reduce,reduce,1396,"e reduction strategy to obtain much smaller test; cases that still have the same property as the original one. This will be done; via classic delta debugging and by adding some IR-specific reductions (e.g.; replacing globals, removing unused instructions, etc), similar to what; already exists, but with more in-depth minimization. Granted, if the community differs on this proposal, the legacy code could still; be present in the tool, but with the caveat of still being documented and; designed towards delta reduction. ### Command-Line Options; We are proposing to reduce the plethora of bugpoint’s options to just two: an; interesting-ness test and the arguments for said test, similar to other delta; reduction tools such as CReduce, Delta, and Lithium; the tool should feel less; cluttered, and there should also be no uncertainty about how to operate it. The interesting-ness test that’s going to be run to reduce the code is given; by name:; `--test=<test_name>`; If a `--test` option is not given, the program exits; this option is similar; to bugpoint’s current `-compile-custom` option, which lets the user run a; custom script. The interesting-ness test would be defined as a script that returns 0 when the; IR achieves a user-defined behaviour (e.g. failure to compile on clang) and a; nonzero value when otherwise. Leaving the user the freedom to determine what is; and isn’t interesting to the tool, and thus, streamlining the process of; reducing a test-case. If the test accepts any arguments (excluding the input ll/bc file), they are; given via the following flag:; `--test_args=<test_arguments>`; If unspecified, the test is run as given. It’s worth noting that the input file; would be passed as a parameter to the test, similar how `-compile-custom`; currently operates. ### Implementation; The tool would behave similar to CReduce’s functionality in that it would have a; list of passes that try to minimize the given test-case. We should be able to; modularize the tool’s beha",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BugpointRedesign.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md:2974,Energy Efficiency,reduce,reduce,2974,"mlining the process of; reducing a test-case. If the test accepts any arguments (excluding the input ll/bc file), they are; given via the following flag:; `--test_args=<test_arguments>`; If unspecified, the test is run as given. It’s worth noting that the input file; would be passed as a parameter to the test, similar how `-compile-custom`; currently operates. ### Implementation; The tool would behave similar to CReduce’s functionality in that it would have a; list of passes that try to minimize the given test-case. We should be able to; modularize the tool’s behavior, as well as making it easier to maintain and; expand. The first version of this redesign would try to:. * Discard functions, instructions and metadata that don’t influence the; interesting-ness test; * Remove unused parameters from functions; * Eliminate unvisited conditional paths; * Rename variables to more regular ones (such as “a”, “b”, “c”, etc.). Once these passes are implemented, more meaningful reductions (such as type; reduction) would be added to the tool, to even further reduce IR. ## Background on historical bugpoint issues. ### Root Cause Analysis; Presently, bugpoint takes a long time to find the source problem in a given IR; file, mainly due to the fact that it tries to debug the input by running; various strategies to classify the bug, which in turn run multiple optimizer; and compilation passes over the input, taking up a lot of time. Furthermore,; when the IR crashes, it tries to reduce it by performing some sub-optimal; passes (e.g. a lot of unreachable blocks), and sometimes even fails to minimize; at all. ### ""Quirky"" Interface; Bugpoint’s current interface overwhelms and confuses the user, the help screen; alone ends up confusing rather providing guidance. And, not only are there; numerous features and options, but some of them also work in unexpected ways; and most of the time the user ends up using a custom script. Pruning and; simplifying the interface will be worth considering ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BugpointRedesign.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md:3398,Energy Efficiency,reduce,reduce,3398,"uding the input ll/bc file), they are; given via the following flag:; `--test_args=<test_arguments>`; If unspecified, the test is run as given. It’s worth noting that the input file; would be passed as a parameter to the test, similar how `-compile-custom`; currently operates. ### Implementation; The tool would behave similar to CReduce’s functionality in that it would have a; list of passes that try to minimize the given test-case. We should be able to; modularize the tool’s behavior, as well as making it easier to maintain and; expand. The first version of this redesign would try to:. * Discard functions, instructions and metadata that don’t influence the; interesting-ness test; * Remove unused parameters from functions; * Eliminate unvisited conditional paths; * Rename variables to more regular ones (such as “a”, “b”, “c”, etc.). Once these passes are implemented, more meaningful reductions (such as type; reduction) would be added to the tool, to even further reduce IR. ## Background on historical bugpoint issues. ### Root Cause Analysis; Presently, bugpoint takes a long time to find the source problem in a given IR; file, mainly due to the fact that it tries to debug the input by running; various strategies to classify the bug, which in turn run multiple optimizer; and compilation passes over the input, taking up a lot of time. Furthermore,; when the IR crashes, it tries to reduce it by performing some sub-optimal; passes (e.g. a lot of unreachable blocks), and sometimes even fails to minimize; at all. ### ""Quirky"" Interface; Bugpoint’s current interface overwhelms and confuses the user, the help screen; alone ends up confusing rather providing guidance. And, not only are there; numerous features and options, but some of them also work in unexpected ways; and most of the time the user ends up using a custom script. Pruning and; simplifying the interface will be worth considering in order to make the tool; more useful in the general case and easier to maintain.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BugpointRedesign.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md:3572,Integrability,interface,interface,3572,"uding the input ll/bc file), they are; given via the following flag:; `--test_args=<test_arguments>`; If unspecified, the test is run as given. It’s worth noting that the input file; would be passed as a parameter to the test, similar how `-compile-custom`; currently operates. ### Implementation; The tool would behave similar to CReduce’s functionality in that it would have a; list of passes that try to minimize the given test-case. We should be able to; modularize the tool’s behavior, as well as making it easier to maintain and; expand. The first version of this redesign would try to:. * Discard functions, instructions and metadata that don’t influence the; interesting-ness test; * Remove unused parameters from functions; * Eliminate unvisited conditional paths; * Rename variables to more regular ones (such as “a”, “b”, “c”, etc.). Once these passes are implemented, more meaningful reductions (such as type; reduction) would be added to the tool, to even further reduce IR. ## Background on historical bugpoint issues. ### Root Cause Analysis; Presently, bugpoint takes a long time to find the source problem in a given IR; file, mainly due to the fact that it tries to debug the input by running; various strategies to classify the bug, which in turn run multiple optimizer; and compilation passes over the input, taking up a lot of time. Furthermore,; when the IR crashes, it tries to reduce it by performing some sub-optimal; passes (e.g. a lot of unreachable blocks), and sometimes even fails to minimize; at all. ### ""Quirky"" Interface; Bugpoint’s current interface overwhelms and confuses the user, the help screen; alone ends up confusing rather providing guidance. And, not only are there; numerous features and options, but some of them also work in unexpected ways; and most of the time the user ends up using a custom script. Pruning and; simplifying the interface will be worth considering in order to make the tool; more useful in the general case and easier to maintain.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BugpointRedesign.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md:3877,Integrability,interface,interface,3877,"uding the input ll/bc file), they are; given via the following flag:; `--test_args=<test_arguments>`; If unspecified, the test is run as given. It’s worth noting that the input file; would be passed as a parameter to the test, similar how `-compile-custom`; currently operates. ### Implementation; The tool would behave similar to CReduce’s functionality in that it would have a; list of passes that try to minimize the given test-case. We should be able to; modularize the tool’s behavior, as well as making it easier to maintain and; expand. The first version of this redesign would try to:. * Discard functions, instructions and metadata that don’t influence the; interesting-ness test; * Remove unused parameters from functions; * Eliminate unvisited conditional paths; * Rename variables to more regular ones (such as “a”, “b”, “c”, etc.). Once these passes are implemented, more meaningful reductions (such as type; reduction) would be added to the tool, to even further reduce IR. ## Background on historical bugpoint issues. ### Root Cause Analysis; Presently, bugpoint takes a long time to find the source problem in a given IR; file, mainly due to the fact that it tries to debug the input by running; various strategies to classify the bug, which in turn run multiple optimizer; and compilation passes over the input, taking up a lot of time. Furthermore,; when the IR crashes, it tries to reduce it by performing some sub-optimal; passes (e.g. a lot of unreachable blocks), and sometimes even fails to minimize; at all. ### ""Quirky"" Interface; Bugpoint’s current interface overwhelms and confuses the user, the help screen; alone ends up confusing rather providing guidance. And, not only are there; numerous features and options, but some of them also work in unexpected ways; and most of the time the user ends up using a custom script. Pruning and; simplifying the interface will be worth considering in order to make the tool; more useful in the general case and easier to maintain.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BugpointRedesign.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md:2780,Modifiability,variab,variables,2780,"a user-defined behaviour (e.g. failure to compile on clang) and a; nonzero value when otherwise. Leaving the user the freedom to determine what is; and isn’t interesting to the tool, and thus, streamlining the process of; reducing a test-case. If the test accepts any arguments (excluding the input ll/bc file), they are; given via the following flag:; `--test_args=<test_arguments>`; If unspecified, the test is run as given. It’s worth noting that the input file; would be passed as a parameter to the test, similar how `-compile-custom`; currently operates. ### Implementation; The tool would behave similar to CReduce’s functionality in that it would have a; list of passes that try to minimize the given test-case. We should be able to; modularize the tool’s behavior, as well as making it easier to maintain and; expand. The first version of this redesign would try to:. * Discard functions, instructions and metadata that don’t influence the; interesting-ness test; * Remove unused parameters from functions; * Eliminate unvisited conditional paths; * Rename variables to more regular ones (such as “a”, “b”, “c”, etc.). Once these passes are implemented, more meaningful reductions (such as type; reduction) would be added to the tool, to even further reduce IR. ## Background on historical bugpoint issues. ### Root Cause Analysis; Presently, bugpoint takes a long time to find the source problem in a given IR; file, mainly due to the fact that it tries to debug the input by running; various strategies to classify the bug, which in turn run multiple optimizer; and compilation passes over the input, taking up a lot of time. Furthermore,; when the IR crashes, it tries to reduce it by performing some sub-optimal; passes (e.g. a lot of unreachable blocks), and sometimes even fails to minimize; at all. ### ""Quirky"" Interface; Bugpoint’s current interface overwhelms and confuses the user, the help screen; alone ends up confusing rather providing guidance. And, not only are there; numero",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BugpointRedesign.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md:3276,Performance,optimiz,optimizer,3276,"uding the input ll/bc file), they are; given via the following flag:; `--test_args=<test_arguments>`; If unspecified, the test is run as given. It’s worth noting that the input file; would be passed as a parameter to the test, similar how `-compile-custom`; currently operates. ### Implementation; The tool would behave similar to CReduce’s functionality in that it would have a; list of passes that try to minimize the given test-case. We should be able to; modularize the tool’s behavior, as well as making it easier to maintain and; expand. The first version of this redesign would try to:. * Discard functions, instructions and metadata that don’t influence the; interesting-ness test; * Remove unused parameters from functions; * Eliminate unvisited conditional paths; * Rename variables to more regular ones (such as “a”, “b”, “c”, etc.). Once these passes are implemented, more meaningful reductions (such as type; reduction) would be added to the tool, to even further reduce IR. ## Background on historical bugpoint issues. ### Root Cause Analysis; Presently, bugpoint takes a long time to find the source problem in a given IR; file, mainly due to the fact that it tries to debug the input by running; various strategies to classify the bug, which in turn run multiple optimizer; and compilation passes over the input, taking up a lot of time. Furthermore,; when the IR crashes, it tries to reduce it by performing some sub-optimal; passes (e.g. a lot of unreachable blocks), and sometimes even fails to minimize; at all. ### ""Quirky"" Interface; Bugpoint’s current interface overwhelms and confuses the user, the help screen; alone ends up confusing rather providing guidance. And, not only are there; numerous features and options, but some of them also work in unexpected ways; and most of the time the user ends up using a custom script. Pruning and; simplifying the interface will be worth considering in order to make the tool; more useful in the general case and easier to maintain.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BugpointRedesign.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md:3411,Performance,perform,performing,3411,"uding the input ll/bc file), they are; given via the following flag:; `--test_args=<test_arguments>`; If unspecified, the test is run as given. It’s worth noting that the input file; would be passed as a parameter to the test, similar how `-compile-custom`; currently operates. ### Implementation; The tool would behave similar to CReduce’s functionality in that it would have a; list of passes that try to minimize the given test-case. We should be able to; modularize the tool’s behavior, as well as making it easier to maintain and; expand. The first version of this redesign would try to:. * Discard functions, instructions and metadata that don’t influence the; interesting-ness test; * Remove unused parameters from functions; * Eliminate unvisited conditional paths; * Rename variables to more regular ones (such as “a”, “b”, “c”, etc.). Once these passes are implemented, more meaningful reductions (such as type; reduction) would be added to the tool, to even further reduce IR. ## Background on historical bugpoint issues. ### Root Cause Analysis; Presently, bugpoint takes a long time to find the source problem in a given IR; file, mainly due to the fact that it tries to debug the input by running; various strategies to classify the bug, which in turn run multiple optimizer; and compilation passes over the input, taking up a lot of time. Furthermore,; when the IR crashes, it tries to reduce it by performing some sub-optimal; passes (e.g. a lot of unreachable blocks), and sometimes even fails to minimize; at all. ### ""Quirky"" Interface; Bugpoint’s current interface overwhelms and confuses the user, the help screen; alone ends up confusing rather providing guidance. And, not only are there; numerous features and options, but some of them also work in unexpected ways; and most of the time the user ends up using a custom script. Pruning and; simplifying the interface will be worth considering in order to make the tool; more useful in the general case and easier to maintain.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BugpointRedesign.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md:281,Testability,test,test,281,"# Bugpoint Redesign; Author: Diego Treviño (diegotf@google.com). Date: 2019-06-05. Status: Draft. ## Introduction; As use of bugpoint has grown several areas of improvement have been identified; through years of use: confusing to use, slow, it doesn’t always produce high; quality test cases, etc. This document proposes a new approach with a narrower; focus: minimization of IR test cases. ## Proposed New Design. ### Narrow focus: test-case reduction; The main focus will be a code reduction strategy to obtain much smaller test; cases that still have the same property as the original one. This will be done; via classic delta debugging and by adding some IR-specific reductions (e.g.; replacing globals, removing unused instructions, etc), similar to what; already exists, but with more in-depth minimization. Granted, if the community differs on this proposal, the legacy code could still; be present in the tool, but with the caveat of still being documented and; designed towards delta reduction. ### Command-Line Options; We are proposing to reduce the plethora of bugpoint’s options to just two: an; interesting-ness test and the arguments for said test, similar to other delta; reduction tools such as CReduce, Delta, and Lithium; the tool should feel less; cluttered, and there should also be no uncertainty about how to operate it. The interesting-ness test that’s going to be run to reduce the code is given; by name:; `--test=<test_name>`; If a `--test` option is not given, the program exits; this option is similar; to bugpoint’s current `-compile-custom` option, which lets the user run a; custom script. The interesting-ness test would be defined as a script that returns 0 when the; IR achieves a user-defined behaviour (e.g. failure to compile on clang) and a; nonzero value when otherwise. Leaving the user the freedom to determine what is; and isn’t interesting to the tool, and thus, streamlining the process of; reducing a test-case. If the test accepts any arguments (excludin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BugpointRedesign.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md:379,Testability,test,test,379,"# Bugpoint Redesign; Author: Diego Treviño (diegotf@google.com). Date: 2019-06-05. Status: Draft. ## Introduction; As use of bugpoint has grown several areas of improvement have been identified; through years of use: confusing to use, slow, it doesn’t always produce high; quality test cases, etc. This document proposes a new approach with a narrower; focus: minimization of IR test cases. ## Proposed New Design. ### Narrow focus: test-case reduction; The main focus will be a code reduction strategy to obtain much smaller test; cases that still have the same property as the original one. This will be done; via classic delta debugging and by adding some IR-specific reductions (e.g.; replacing globals, removing unused instructions, etc), similar to what; already exists, but with more in-depth minimization. Granted, if the community differs on this proposal, the legacy code could still; be present in the tool, but with the caveat of still being documented and; designed towards delta reduction. ### Command-Line Options; We are proposing to reduce the plethora of bugpoint’s options to just two: an; interesting-ness test and the arguments for said test, similar to other delta; reduction tools such as CReduce, Delta, and Lithium; the tool should feel less; cluttered, and there should also be no uncertainty about how to operate it. The interesting-ness test that’s going to be run to reduce the code is given; by name:; `--test=<test_name>`; If a `--test` option is not given, the program exits; this option is similar; to bugpoint’s current `-compile-custom` option, which lets the user run a; custom script. The interesting-ness test would be defined as a script that returns 0 when the; IR achieves a user-defined behaviour (e.g. failure to compile on clang) and a; nonzero value when otherwise. Leaving the user the freedom to determine what is; and isn’t interesting to the tool, and thus, streamlining the process of; reducing a test-case. If the test accepts any arguments (excludin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BugpointRedesign.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md:433,Testability,test,test-case,433,"# Bugpoint Redesign; Author: Diego Treviño (diegotf@google.com). Date: 2019-06-05. Status: Draft. ## Introduction; As use of bugpoint has grown several areas of improvement have been identified; through years of use: confusing to use, slow, it doesn’t always produce high; quality test cases, etc. This document proposes a new approach with a narrower; focus: minimization of IR test cases. ## Proposed New Design. ### Narrow focus: test-case reduction; The main focus will be a code reduction strategy to obtain much smaller test; cases that still have the same property as the original one. This will be done; via classic delta debugging and by adding some IR-specific reductions (e.g.; replacing globals, removing unused instructions, etc), similar to what; already exists, but with more in-depth minimization. Granted, if the community differs on this proposal, the legacy code could still; be present in the tool, but with the caveat of still being documented and; designed towards delta reduction. ### Command-Line Options; We are proposing to reduce the plethora of bugpoint’s options to just two: an; interesting-ness test and the arguments for said test, similar to other delta; reduction tools such as CReduce, Delta, and Lithium; the tool should feel less; cluttered, and there should also be no uncertainty about how to operate it. The interesting-ness test that’s going to be run to reduce the code is given; by name:; `--test=<test_name>`; If a `--test` option is not given, the program exits; this option is similar; to bugpoint’s current `-compile-custom` option, which lets the user run a; custom script. The interesting-ness test would be defined as a script that returns 0 when the; IR achieves a user-defined behaviour (e.g. failure to compile on clang) and a; nonzero value when otherwise. Leaving the user the freedom to determine what is; and isn’t interesting to the tool, and thus, streamlining the process of; reducing a test-case. If the test accepts any arguments (excludin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BugpointRedesign.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md:526,Testability,test,test,526,"# Bugpoint Redesign; Author: Diego Treviño (diegotf@google.com). Date: 2019-06-05. Status: Draft. ## Introduction; As use of bugpoint has grown several areas of improvement have been identified; through years of use: confusing to use, slow, it doesn’t always produce high; quality test cases, etc. This document proposes a new approach with a narrower; focus: minimization of IR test cases. ## Proposed New Design. ### Narrow focus: test-case reduction; The main focus will be a code reduction strategy to obtain much smaller test; cases that still have the same property as the original one. This will be done; via classic delta debugging and by adding some IR-specific reductions (e.g.; replacing globals, removing unused instructions, etc), similar to what; already exists, but with more in-depth minimization. Granted, if the community differs on this proposal, the legacy code could still; be present in the tool, but with the caveat of still being documented and; designed towards delta reduction. ### Command-Line Options; We are proposing to reduce the plethora of bugpoint’s options to just two: an; interesting-ness test and the arguments for said test, similar to other delta; reduction tools such as CReduce, Delta, and Lithium; the tool should feel less; cluttered, and there should also be no uncertainty about how to operate it. The interesting-ness test that’s going to be run to reduce the code is given; by name:; `--test=<test_name>`; If a `--test` option is not given, the program exits; this option is similar; to bugpoint’s current `-compile-custom` option, which lets the user run a; custom script. The interesting-ness test would be defined as a script that returns 0 when the; IR achieves a user-defined behaviour (e.g. failure to compile on clang) and a; nonzero value when otherwise. Leaving the user the freedom to determine what is; and isn’t interesting to the tool, and thus, streamlining the process of; reducing a test-case. If the test accepts any arguments (excludin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BugpointRedesign.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md:1126,Testability,test,test,1126,"have been identified; through years of use: confusing to use, slow, it doesn’t always produce high; quality test cases, etc. This document proposes a new approach with a narrower; focus: minimization of IR test cases. ## Proposed New Design. ### Narrow focus: test-case reduction; The main focus will be a code reduction strategy to obtain much smaller test; cases that still have the same property as the original one. This will be done; via classic delta debugging and by adding some IR-specific reductions (e.g.; replacing globals, removing unused instructions, etc), similar to what; already exists, but with more in-depth minimization. Granted, if the community differs on this proposal, the legacy code could still; be present in the tool, but with the caveat of still being documented and; designed towards delta reduction. ### Command-Line Options; We are proposing to reduce the plethora of bugpoint’s options to just two: an; interesting-ness test and the arguments for said test, similar to other delta; reduction tools such as CReduce, Delta, and Lithium; the tool should feel less; cluttered, and there should also be no uncertainty about how to operate it. The interesting-ness test that’s going to be run to reduce the code is given; by name:; `--test=<test_name>`; If a `--test` option is not given, the program exits; this option is similar; to bugpoint’s current `-compile-custom` option, which lets the user run a; custom script. The interesting-ness test would be defined as a script that returns 0 when the; IR achieves a user-defined behaviour (e.g. failure to compile on clang) and a; nonzero value when otherwise. Leaving the user the freedom to determine what is; and isn’t interesting to the tool, and thus, streamlining the process of; reducing a test-case. If the test accepts any arguments (excluding the input ll/bc file), they are; given via the following flag:; `--test_args=<test_arguments>`; If unspecified, the test is run as given. It’s worth noting that the input",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BugpointRedesign.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md:1158,Testability,test,test,1158,"have been identified; through years of use: confusing to use, slow, it doesn’t always produce high; quality test cases, etc. This document proposes a new approach with a narrower; focus: minimization of IR test cases. ## Proposed New Design. ### Narrow focus: test-case reduction; The main focus will be a code reduction strategy to obtain much smaller test; cases that still have the same property as the original one. This will be done; via classic delta debugging and by adding some IR-specific reductions (e.g.; replacing globals, removing unused instructions, etc), similar to what; already exists, but with more in-depth minimization. Granted, if the community differs on this proposal, the legacy code could still; be present in the tool, but with the caveat of still being documented and; designed towards delta reduction. ### Command-Line Options; We are proposing to reduce the plethora of bugpoint’s options to just two: an; interesting-ness test and the arguments for said test, similar to other delta; reduction tools such as CReduce, Delta, and Lithium; the tool should feel less; cluttered, and there should also be no uncertainty about how to operate it. The interesting-ness test that’s going to be run to reduce the code is given; by name:; `--test=<test_name>`; If a `--test` option is not given, the program exits; this option is similar; to bugpoint’s current `-compile-custom` option, which lets the user run a; custom script. The interesting-ness test would be defined as a script that returns 0 when the; IR achieves a user-defined behaviour (e.g. failure to compile on clang) and a; nonzero value when otherwise. Leaving the user the freedom to determine what is; and isn’t interesting to the tool, and thus, streamlining the process of; reducing a test-case. If the test accepts any arguments (excluding the input ll/bc file), they are; given via the following flag:; `--test_args=<test_arguments>`; If unspecified, the test is run as given. It’s worth noting that the input",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BugpointRedesign.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md:1365,Testability,test,test,1365,"e reduction strategy to obtain much smaller test; cases that still have the same property as the original one. This will be done; via classic delta debugging and by adding some IR-specific reductions (e.g.; replacing globals, removing unused instructions, etc), similar to what; already exists, but with more in-depth minimization. Granted, if the community differs on this proposal, the legacy code could still; be present in the tool, but with the caveat of still being documented and; designed towards delta reduction. ### Command-Line Options; We are proposing to reduce the plethora of bugpoint’s options to just two: an; interesting-ness test and the arguments for said test, similar to other delta; reduction tools such as CReduce, Delta, and Lithium; the tool should feel less; cluttered, and there should also be no uncertainty about how to operate it. The interesting-ness test that’s going to be run to reduce the code is given; by name:; `--test=<test_name>`; If a `--test` option is not given, the program exits; this option is similar; to bugpoint’s current `-compile-custom` option, which lets the user run a; custom script. The interesting-ness test would be defined as a script that returns 0 when the; IR achieves a user-defined behaviour (e.g. failure to compile on clang) and a; nonzero value when otherwise. Leaving the user the freedom to determine what is; and isn’t interesting to the tool, and thus, streamlining the process of; reducing a test-case. If the test accepts any arguments (excluding the input ll/bc file), they are; given via the following flag:; `--test_args=<test_arguments>`; If unspecified, the test is run as given. It’s worth noting that the input file; would be passed as a parameter to the test, similar how `-compile-custom`; currently operates. ### Implementation; The tool would behave similar to CReduce’s functionality in that it would have a; list of passes that try to minimize the given test-case. We should be able to; modularize the tool’s beha",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BugpointRedesign.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md:1435,Testability,test,test,1435,"e reduction strategy to obtain much smaller test; cases that still have the same property as the original one. This will be done; via classic delta debugging and by adding some IR-specific reductions (e.g.; replacing globals, removing unused instructions, etc), similar to what; already exists, but with more in-depth minimization. Granted, if the community differs on this proposal, the legacy code could still; be present in the tool, but with the caveat of still being documented and; designed towards delta reduction. ### Command-Line Options; We are proposing to reduce the plethora of bugpoint’s options to just two: an; interesting-ness test and the arguments for said test, similar to other delta; reduction tools such as CReduce, Delta, and Lithium; the tool should feel less; cluttered, and there should also be no uncertainty about how to operate it. The interesting-ness test that’s going to be run to reduce the code is given; by name:; `--test=<test_name>`; If a `--test` option is not given, the program exits; this option is similar; to bugpoint’s current `-compile-custom` option, which lets the user run a; custom script. The interesting-ness test would be defined as a script that returns 0 when the; IR achieves a user-defined behaviour (e.g. failure to compile on clang) and a; nonzero value when otherwise. Leaving the user the freedom to determine what is; and isn’t interesting to the tool, and thus, streamlining the process of; reducing a test-case. If the test accepts any arguments (excluding the input ll/bc file), they are; given via the following flag:; `--test_args=<test_arguments>`; If unspecified, the test is run as given. It’s worth noting that the input file; would be passed as a parameter to the test, similar how `-compile-custom`; currently operates. ### Implementation; The tool would behave similar to CReduce’s functionality in that it would have a; list of passes that try to minimize the given test-case. We should be able to; modularize the tool’s beha",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BugpointRedesign.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md:1462,Testability,test,test,1462,"e reduction strategy to obtain much smaller test; cases that still have the same property as the original one. This will be done; via classic delta debugging and by adding some IR-specific reductions (e.g.; replacing globals, removing unused instructions, etc), similar to what; already exists, but with more in-depth minimization. Granted, if the community differs on this proposal, the legacy code could still; be present in the tool, but with the caveat of still being documented and; designed towards delta reduction. ### Command-Line Options; We are proposing to reduce the plethora of bugpoint’s options to just two: an; interesting-ness test and the arguments for said test, similar to other delta; reduction tools such as CReduce, Delta, and Lithium; the tool should feel less; cluttered, and there should also be no uncertainty about how to operate it. The interesting-ness test that’s going to be run to reduce the code is given; by name:; `--test=<test_name>`; If a `--test` option is not given, the program exits; this option is similar; to bugpoint’s current `-compile-custom` option, which lets the user run a; custom script. The interesting-ness test would be defined as a script that returns 0 when the; IR achieves a user-defined behaviour (e.g. failure to compile on clang) and a; nonzero value when otherwise. Leaving the user the freedom to determine what is; and isn’t interesting to the tool, and thus, streamlining the process of; reducing a test-case. If the test accepts any arguments (excluding the input ll/bc file), they are; given via the following flag:; `--test_args=<test_arguments>`; If unspecified, the test is run as given. It’s worth noting that the input file; would be passed as a parameter to the test, similar how `-compile-custom`; currently operates. ### Implementation; The tool would behave similar to CReduce’s functionality in that it would have a; list of passes that try to minimize the given test-case. We should be able to; modularize the tool’s beha",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BugpointRedesign.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md:1643,Testability,test,test,1643," (e.g.; replacing globals, removing unused instructions, etc), similar to what; already exists, but with more in-depth minimization. Granted, if the community differs on this proposal, the legacy code could still; be present in the tool, but with the caveat of still being documented and; designed towards delta reduction. ### Command-Line Options; We are proposing to reduce the plethora of bugpoint’s options to just two: an; interesting-ness test and the arguments for said test, similar to other delta; reduction tools such as CReduce, Delta, and Lithium; the tool should feel less; cluttered, and there should also be no uncertainty about how to operate it. The interesting-ness test that’s going to be run to reduce the code is given; by name:; `--test=<test_name>`; If a `--test` option is not given, the program exits; this option is similar; to bugpoint’s current `-compile-custom` option, which lets the user run a; custom script. The interesting-ness test would be defined as a script that returns 0 when the; IR achieves a user-defined behaviour (e.g. failure to compile on clang) and a; nonzero value when otherwise. Leaving the user the freedom to determine what is; and isn’t interesting to the tool, and thus, streamlining the process of; reducing a test-case. If the test accepts any arguments (excluding the input ll/bc file), they are; given via the following flag:; `--test_args=<test_arguments>`; If unspecified, the test is run as given. It’s worth noting that the input file; would be passed as a parameter to the test, similar how `-compile-custom`; currently operates. ### Implementation; The tool would behave similar to CReduce’s functionality in that it would have a; list of passes that try to minimize the given test-case. We should be able to; modularize the tool’s behavior, as well as making it easier to maintain and; expand. The first version of this redesign would try to:. * Discard functions, instructions and metadata that don’t influence the; interesting-ness t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BugpointRedesign.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md:1947,Testability,test,test-case,1947,"ould still; be present in the tool, but with the caveat of still being documented and; designed towards delta reduction. ### Command-Line Options; We are proposing to reduce the plethora of bugpoint’s options to just two: an; interesting-ness test and the arguments for said test, similar to other delta; reduction tools such as CReduce, Delta, and Lithium; the tool should feel less; cluttered, and there should also be no uncertainty about how to operate it. The interesting-ness test that’s going to be run to reduce the code is given; by name:; `--test=<test_name>`; If a `--test` option is not given, the program exits; this option is similar; to bugpoint’s current `-compile-custom` option, which lets the user run a; custom script. The interesting-ness test would be defined as a script that returns 0 when the; IR achieves a user-defined behaviour (e.g. failure to compile on clang) and a; nonzero value when otherwise. Leaving the user the freedom to determine what is; and isn’t interesting to the tool, and thus, streamlining the process of; reducing a test-case. If the test accepts any arguments (excluding the input ll/bc file), they are; given via the following flag:; `--test_args=<test_arguments>`; If unspecified, the test is run as given. It’s worth noting that the input file; would be passed as a parameter to the test, similar how `-compile-custom`; currently operates. ### Implementation; The tool would behave similar to CReduce’s functionality in that it would have a; list of passes that try to minimize the given test-case. We should be able to; modularize the tool’s behavior, as well as making it easier to maintain and; expand. The first version of this redesign would try to:. * Discard functions, instructions and metadata that don’t influence the; interesting-ness test; * Remove unused parameters from functions; * Eliminate unvisited conditional paths; * Rename variables to more regular ones (such as “a”, “b”, “c”, etc.). Once these passes are implemented, more me",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BugpointRedesign.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md:1965,Testability,test,test,1965,"o reduce the plethora of bugpoint’s options to just two: an; interesting-ness test and the arguments for said test, similar to other delta; reduction tools such as CReduce, Delta, and Lithium; the tool should feel less; cluttered, and there should also be no uncertainty about how to operate it. The interesting-ness test that’s going to be run to reduce the code is given; by name:; `--test=<test_name>`; If a `--test` option is not given, the program exits; this option is similar; to bugpoint’s current `-compile-custom` option, which lets the user run a; custom script. The interesting-ness test would be defined as a script that returns 0 when the; IR achieves a user-defined behaviour (e.g. failure to compile on clang) and a; nonzero value when otherwise. Leaving the user the freedom to determine what is; and isn’t interesting to the tool, and thus, streamlining the process of; reducing a test-case. If the test accepts any arguments (excluding the input ll/bc file), they are; given via the following flag:; `--test_args=<test_arguments>`; If unspecified, the test is run as given. It’s worth noting that the input file; would be passed as a parameter to the test, similar how `-compile-custom`; currently operates. ### Implementation; The tool would behave similar to CReduce’s functionality in that it would have a; list of passes that try to minimize the given test-case. We should be able to; modularize the tool’s behavior, as well as making it easier to maintain and; expand. The first version of this redesign would try to:. * Discard functions, instructions and metadata that don’t influence the; interesting-ness test; * Remove unused parameters from functions; * Eliminate unvisited conditional paths; * Rename variables to more regular ones (such as “a”, “b”, “c”, etc.). Once these passes are implemented, more meaningful reductions (such as type; reduction) would be added to the tool, to even further reduce IR. ## Background on historical bugpoint issues. ### Root Cause Anal",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BugpointRedesign.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md:2119,Testability,test,test,2119,"o reduce the plethora of bugpoint’s options to just two: an; interesting-ness test and the arguments for said test, similar to other delta; reduction tools such as CReduce, Delta, and Lithium; the tool should feel less; cluttered, and there should also be no uncertainty about how to operate it. The interesting-ness test that’s going to be run to reduce the code is given; by name:; `--test=<test_name>`; If a `--test` option is not given, the program exits; this option is similar; to bugpoint’s current `-compile-custom` option, which lets the user run a; custom script. The interesting-ness test would be defined as a script that returns 0 when the; IR achieves a user-defined behaviour (e.g. failure to compile on clang) and a; nonzero value when otherwise. Leaving the user the freedom to determine what is; and isn’t interesting to the tool, and thus, streamlining the process of; reducing a test-case. If the test accepts any arguments (excluding the input ll/bc file), they are; given via the following flag:; `--test_args=<test_arguments>`; If unspecified, the test is run as given. It’s worth noting that the input file; would be passed as a parameter to the test, similar how `-compile-custom`; currently operates. ### Implementation; The tool would behave similar to CReduce’s functionality in that it would have a; list of passes that try to minimize the given test-case. We should be able to; modularize the tool’s behavior, as well as making it easier to maintain and; expand. The first version of this redesign would try to:. * Discard functions, instructions and metadata that don’t influence the; interesting-ness test; * Remove unused parameters from functions; * Eliminate unvisited conditional paths; * Rename variables to more regular ones (such as “a”, “b”, “c”, etc.). Once these passes are implemented, more meaningful reductions (such as type; reduction) would be added to the tool, to even further reduce IR. ## Background on historical bugpoint issues. ### Root Cause Anal",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BugpointRedesign.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md:2218,Testability,test,test,2218,"h as CReduce, Delta, and Lithium; the tool should feel less; cluttered, and there should also be no uncertainty about how to operate it. The interesting-ness test that’s going to be run to reduce the code is given; by name:; `--test=<test_name>`; If a `--test` option is not given, the program exits; this option is similar; to bugpoint’s current `-compile-custom` option, which lets the user run a; custom script. The interesting-ness test would be defined as a script that returns 0 when the; IR achieves a user-defined behaviour (e.g. failure to compile on clang) and a; nonzero value when otherwise. Leaving the user the freedom to determine what is; and isn’t interesting to the tool, and thus, streamlining the process of; reducing a test-case. If the test accepts any arguments (excluding the input ll/bc file), they are; given via the following flag:; `--test_args=<test_arguments>`; If unspecified, the test is run as given. It’s worth noting that the input file; would be passed as a parameter to the test, similar how `-compile-custom`; currently operates. ### Implementation; The tool would behave similar to CReduce’s functionality in that it would have a; list of passes that try to minimize the given test-case. We should be able to; modularize the tool’s behavior, as well as making it easier to maintain and; expand. The first version of this redesign would try to:. * Discard functions, instructions and metadata that don’t influence the; interesting-ness test; * Remove unused parameters from functions; * Eliminate unvisited conditional paths; * Rename variables to more regular ones (such as “a”, “b”, “c”, etc.). Once these passes are implemented, more meaningful reductions (such as type; reduction) would be added to the tool, to even further reduce IR. ## Background on historical bugpoint issues. ### Root Cause Analysis; Presently, bugpoint takes a long time to find the source problem in a given IR; file, mainly due to the fact that it tries to debug the input by running",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BugpointRedesign.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md:2423,Testability,test,test-case,2423,"esting-ness test that’s going to be run to reduce the code is given; by name:; `--test=<test_name>`; If a `--test` option is not given, the program exits; this option is similar; to bugpoint’s current `-compile-custom` option, which lets the user run a; custom script. The interesting-ness test would be defined as a script that returns 0 when the; IR achieves a user-defined behaviour (e.g. failure to compile on clang) and a; nonzero value when otherwise. Leaving the user the freedom to determine what is; and isn’t interesting to the tool, and thus, streamlining the process of; reducing a test-case. If the test accepts any arguments (excluding the input ll/bc file), they are; given via the following flag:; `--test_args=<test_arguments>`; If unspecified, the test is run as given. It’s worth noting that the input file; would be passed as a parameter to the test, similar how `-compile-custom`; currently operates. ### Implementation; The tool would behave similar to CReduce’s functionality in that it would have a; list of passes that try to minimize the given test-case. We should be able to; modularize the tool’s behavior, as well as making it easier to maintain and; expand. The first version of this redesign would try to:. * Discard functions, instructions and metadata that don’t influence the; interesting-ness test; * Remove unused parameters from functions; * Eliminate unvisited conditional paths; * Rename variables to more regular ones (such as “a”, “b”, “c”, etc.). Once these passes are implemented, more meaningful reductions (such as type; reduction) would be added to the tool, to even further reduce IR. ## Background on historical bugpoint issues. ### Root Cause Analysis; Presently, bugpoint takes a long time to find the source problem in a given IR; file, mainly due to the fact that it tries to debug the input by running; various strategies to classify the bug, which in turn run multiple optimizer; and compilation passes over the input, taking up a lot of time. Fur",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BugpointRedesign.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md:2681,Testability,test,test,2681,"a user-defined behaviour (e.g. failure to compile on clang) and a; nonzero value when otherwise. Leaving the user the freedom to determine what is; and isn’t interesting to the tool, and thus, streamlining the process of; reducing a test-case. If the test accepts any arguments (excluding the input ll/bc file), they are; given via the following flag:; `--test_args=<test_arguments>`; If unspecified, the test is run as given. It’s worth noting that the input file; would be passed as a parameter to the test, similar how `-compile-custom`; currently operates. ### Implementation; The tool would behave similar to CReduce’s functionality in that it would have a; list of passes that try to minimize the given test-case. We should be able to; modularize the tool’s behavior, as well as making it easier to maintain and; expand. The first version of this redesign would try to:. * Discard functions, instructions and metadata that don’t influence the; interesting-ness test; * Remove unused parameters from functions; * Eliminate unvisited conditional paths; * Rename variables to more regular ones (such as “a”, “b”, “c”, etc.). Once these passes are implemented, more meaningful reductions (such as type; reduction) would be added to the tool, to even further reduce IR. ## Background on historical bugpoint issues. ### Root Cause Analysis; Presently, bugpoint takes a long time to find the source problem in a given IR; file, mainly due to the fact that it tries to debug the input by running; various strategies to classify the bug, which in turn run multiple optimizer; and compilation passes over the input, taking up a lot of time. Furthermore,; when the IR crashes, it tries to reduce it by performing some sub-optimal; passes (e.g. a lot of unreachable blocks), and sometimes even fails to minimize; at all. ### ""Quirky"" Interface; Bugpoint’s current interface overwhelms and confuses the user, the help screen; alone ends up confusing rather providing guidance. And, not only are there; numero",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BugpointRedesign.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md:3674,Usability,guid,guidance,3674,"uding the input ll/bc file), they are; given via the following flag:; `--test_args=<test_arguments>`; If unspecified, the test is run as given. It’s worth noting that the input file; would be passed as a parameter to the test, similar how `-compile-custom`; currently operates. ### Implementation; The tool would behave similar to CReduce’s functionality in that it would have a; list of passes that try to minimize the given test-case. We should be able to; modularize the tool’s behavior, as well as making it easier to maintain and; expand. The first version of this redesign would try to:. * Discard functions, instructions and metadata that don’t influence the; interesting-ness test; * Remove unused parameters from functions; * Eliminate unvisited conditional paths; * Rename variables to more regular ones (such as “a”, “b”, “c”, etc.). Once these passes are implemented, more meaningful reductions (such as type; reduction) would be added to the tool, to even further reduce IR. ## Background on historical bugpoint issues. ### Root Cause Analysis; Presently, bugpoint takes a long time to find the source problem in a given IR; file, mainly due to the fact that it tries to debug the input by running; various strategies to classify the bug, which in turn run multiple optimizer; and compilation passes over the input, taking up a lot of time. Furthermore,; when the IR crashes, it tries to reduce it by performing some sub-optimal; passes (e.g. a lot of unreachable blocks), and sometimes even fails to minimize; at all. ### ""Quirky"" Interface; Bugpoint’s current interface overwhelms and confuses the user, the help screen; alone ends up confusing rather providing guidance. And, not only are there; numerous features and options, but some of them also work in unexpected ways; and most of the time the user ends up using a custom script. Pruning and; simplifying the interface will be worth considering in order to make the tool; more useful in the general case and easier to maintain.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BugpointRedesign.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md:3861,Usability,simpl,simplifying,3861,"uding the input ll/bc file), they are; given via the following flag:; `--test_args=<test_arguments>`; If unspecified, the test is run as given. It’s worth noting that the input file; would be passed as a parameter to the test, similar how `-compile-custom`; currently operates. ### Implementation; The tool would behave similar to CReduce’s functionality in that it would have a; list of passes that try to minimize the given test-case. We should be able to; modularize the tool’s behavior, as well as making it easier to maintain and; expand. The first version of this redesign would try to:. * Discard functions, instructions and metadata that don’t influence the; interesting-ness test; * Remove unused parameters from functions; * Eliminate unvisited conditional paths; * Rename variables to more regular ones (such as “a”, “b”, “c”, etc.). Once these passes are implemented, more meaningful reductions (such as type; reduction) would be added to the tool, to even further reduce IR. ## Background on historical bugpoint issues. ### Root Cause Analysis; Presently, bugpoint takes a long time to find the source problem in a given IR; file, mainly due to the fact that it tries to debug the input by running; various strategies to classify the bug, which in turn run multiple optimizer; and compilation passes over the input, taking up a lot of time. Furthermore,; when the IR crashes, it tries to reduce it by performing some sub-optimal; passes (e.g. a lot of unreachable blocks), and sometimes even fails to minimize; at all. ### ""Quirky"" Interface; Bugpoint’s current interface overwhelms and confuses the user, the help screen; alone ends up confusing rather providing guidance. And, not only are there; numerous features and options, but some of them also work in unexpected ways; and most of the time the user ends up using a custom script. Pruning and; simplifying the interface will be worth considering in order to make the tool; more useful in the general case and easier to maintain.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BugpointRedesign.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md:278,Deployability,update,update,278,"# Discourse Migration Guide . ## Current Status of Migration: Discourse is back online at a new URL: [https://discourse.llvm.org](https://discourse.llvm.org). The old one still works as well. We are aware of an issue with reply by email to emails from before the merge. We will update once we know more. This document is intended to help LLVM users to migrate from the mailing lists to; Discourse. Discourse has two basic ways for interaction: Via the [web; UI](https://llvm.discourse.group/) and via emails. ## Setting up your account. The easiest way is to create an account using your GitHub account:. 1. Navigate to https://llvm.discourse.group/; 1. Click on ""Sign Up"" in the top right corner.; 1. Choose ""With GitHub"" on the right side and log in with your GitHub account. ## Structure of Discourse. Discourse's structure is similar to a set of mailing lists, however different; terms are used there. To help with the transition, here's a translation table; for the terms:. <table border=1>; <tr><th>Mailing list</th><th>Discourse</th></tr>; <tr><td><i>Mailing list</i>, consists of threads</td><td><i>category</i>, consists of topics</td></tr>; <tr><td><i>thread</i>, consists of emails</td><td><i>topic</i>, consists of posts</td></tr>; <tr><td>email</td><td>post</td></tr>; </table>. ## Setting up email interactions. Some folks want to interact with Discourse purely via their email program. Here; are the typical use cases:. * You can [subscribe to a category or topic](https://discourse.mozilla.org/t/how-do-i-subscribe-to-categories-and-topics/16024); * You can reply to a post, including quoting other peoples texts; ([tested](https://llvm.discourse.group/t/email-interaction-with-discourse/3306/4) on GMail).; * [Quoting previous topics in an reply](https://meta.discourse.org/t/single-quote-block-dropped-in-email-reply/144802); * You can filter incoming emails in your email client by category using the; `List-ID` email header field.; * You can create topics through email using the e",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md:5301,Deployability,release,release-testers,5301,scourse.llvm.org</td></tr>; <tr><td>Runtimes - OpenMP</td><td>runtimes-openmp@discourse.llvm.org</td></tr>; <tr><td>Runtimes - OpenCL</td><td>runtimes-opencl@discourse.llvm.org</td></tr>; <tr><td>MLIR</td><td>mlir@discourse.llvm.org</td></tr>; <tr><td>MLIR - Announce</td><td>mlir-announce@discourse.llvm.org</td></tr>; <tr><td>MLIR - Newsletter</td><td>mlir-news@discourse.llvm.org</td></tr>; <tr><td>MLIR - TCP-WG</td><td>mlir-tcpwg@discourse.llvm.org</td></tr>; <tr><td>Subprojects</td><td>subprojects@discourse.llvm.org</td></tr>; <tr><td>Subprojects - Polly</td><td>polly@discourse.llvm.org</td></tr>; <tr><td>Subprojects - LLDB</td><td>lldb@discourse.llvm.org</td></tr>; <tr><td>Subprojects - LLD</td><td>lld@discourse.llvm.org</td></tr>; <tr><td>Subprojects - Flang</td><td> flang@discourse.llvm.org</td></tr>; <tr><td>Subprojects - Bolt</td><td>bolt@discourse.llvm.org</td></tr>; <tr><td>Project Infrastructure</td><td>infra@discourse.llvm.org</td></tr>; <tr><td>Project Infrastructure - Release Testers</td><td>infra-release-testers@discourse.llvm.org</td></tr>; <tr><td>Project Infrastructure - Website</td><td>infra-website@discourse.llvm.org</td></tr>; <tr><td>Project Infrastructure - Documentation</td><td> infra-docs@discourse.llvm.org</td></tr>; <tr><td>Project Infrastructure - GitHub</td><td>infra-github@discourse.llvm.org</td></tr>; <tr><td>Project Infrastructure - Code Review</td><td>infra-codereview@discourse.llvm.org</td></tr>; <tr><td>Project Infrastructure - Discord</td><td>infra-discord@discourse.llvm.org</td></tr>; <tr><td>Project Infrastructure - Mailing Lists and Forums</td><td>infra-mailinglists@discourse.llvm.org</td></tr>; <tr><td>Project Infrastructure - IRC</td><td> infra-irc@discourse.llvm.org</td></tr>; <tr><td>Project Infrastructure - Infrastructure Working Group</td><td>infra-iwg@discourse.llvm.org</td></tr>; <tr><td>Community</td><td>community@discourse.llvm.org</td></tr>; <tr><td>Community - Women in Compilers and Tools</td><td>wict@discourse.llvm.,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md:3288,Energy Efficiency,power,powerpc,3288,discourse category. You **must** have a Discourse account associated with the email address you are sending from or the email will be rejected. <table border=1>; <tr><th>Discourse Category</th><th>Email Address</th></tr>; <tr><td>Beginner</td><td>beginners@discourse.llvm.org</td></tr>; <tr><td>LLVM Project</td><td>llvmproject@discourse.llvm.org</td></tr>; <tr><td>IR & Optimizations</td><td>IR.Optimizations@discourse.llvm.org</td></tr>; <tr><td>IR & Optimizations - Loop Optimizations</td><td>IR.Optimizations-Loops@discourse.llvm.org</td></tr>; <tr><td>Code Generation</td><td>codegen@discourse.llvm.org</td></tr>; <tr><td>Code Generation - AMDGPU</td><td>codegen-amdgpu@discourse.llvm.org</td></tr>; <tr><td>Code Generation - Common Infrastructure</td><td>codegen-common@discourse.llvm.org</td></tr>; <tr><td>Code Generation - AArch64</td><td>codegen-aarch64@discourse.llvm.org</td></tr>; <tr><td>Code Generation - Arm</td><td>codegen-arm@discourse.llvm.org</td></tr>; <tr><td>Code Generation - PowerPC</td><td>codegen-powerpc@discourse.llvm.org</td></tr>; <tr><td>Code Generation - RISCV</td><td>codegen-riscv@discourse.llvm.org</td></tr>; <tr><td>Code Generation - WebAssembly</td><td>codegen-webassembly@discourse.llvm.org</td></tr>; <tr><td>Code Generation - X86</td><td>codegen-x86@discourse.llvm.org</td></tr>; <tr><td>Clang Frontend</td><td>clang@discourse.llvm.org</td></tr>; <tr><td>Clang Frontend - Using Clang</td><td>clang-users@discourse.llvm.org</td></tr>; <tr><td>Clang Frontend - clangd</td><td>clangd@discourse.llvm.org</td></tr>; <tr><td>Clang Frontend - Building Clang</td><td>clang-build@discourse.llvm.org</td></tr>; <tr><td>Clang Frontend - Static Analyzer</td><td>clang-staticanalyzer@discourse.llvm.org</td></tr>; <tr><td>Runtimes</td><td>runtimes@discourse.llvm.org</td></tr>; <tr><td>Runtimes - C++</td><td>runtimes-cxx@discourse.llvm.org</td></tr>; <tr><td>Runtimes - Sanitizers</td><td>runtimes-sanitizers@discourse.llvm.org</td></tr>; <tr><td>Runtimes - C</td><td>run,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md:10240,Integrability,message,message,10240,"Meeting</td></tr>; <tr><td>llvm-foundation</td><td>Community/LLVM Foundation</td></tr>; <tr><td>Mlir-commits</td><td>no migration at the moment</td></tr>; <tr><td>Openmp-commits</td><td>no migration at the moment</td></tr>; <tr><td>Openmp-dev</td><td>Runtimes/OpenMP</td></tr>; <tr><td>Parallel_libs-commits</td><td>no migration at the moment</td></tr>; <tr><td>Parallel_libs-dev</td><td>Runtimes/C++</td></tr>; <tr><td>Release-testers</td><td>Project Infrastructure/Release Testers</td></tr>; <tr><td>Test-list</td><td>Obsolete</td></tr>; <tr><td>vmkit-commits</td><td>Obsolete</td></tr>; <tr><td>WiCT</td><td>Community/Women in Compilers and Tools</td></tr>; <tr><td>www-scripts</td><td>Obsolete</td></tr> ; </table>. ## FAQ. ### I don't want to use a web UI. You can do most of the communication with your email client (see section on; Setting up email interactions above). You only need to set up your account once; and then configure which categories you want to subscribe to. ### How do I send a private message?. On the mailing list you have the opportunity to reply only to the sender of; the email, not to the entire list. That is not supported when replying via; email on Discourse. However you can send someone a private message via the; Web UI: Click on the user's name above a post and then on `Message`. Also Discourse does not expose users' email addresses , so your private; replies have to go through their platform (unless you happen to know the; email address of the user.). ### How can my script/tool send automatic messages?**. In case you want to [create a new; post/topic](https://docs.discourse.org/#tag/Posts/paths/~1posts.json/post); automatically from a script or tool, you can use the; [Discourse API](https://docs.discourse.org/). ### Who are the admins for Discourse?. See https://llvm.discourse.group/about. ### What is the reason for the migration?. See; [this email](https://lists.llvm.org/pipermail/llvm-dev/2021-June/150823.html). ### How do I set up a private mail",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md:10462,Integrability,message,message,10462,"times/OpenMP</td></tr>; <tr><td>Parallel_libs-commits</td><td>no migration at the moment</td></tr>; <tr><td>Parallel_libs-dev</td><td>Runtimes/C++</td></tr>; <tr><td>Release-testers</td><td>Project Infrastructure/Release Testers</td></tr>; <tr><td>Test-list</td><td>Obsolete</td></tr>; <tr><td>vmkit-commits</td><td>Obsolete</td></tr>; <tr><td>WiCT</td><td>Community/Women in Compilers and Tools</td></tr>; <tr><td>www-scripts</td><td>Obsolete</td></tr> ; </table>. ## FAQ. ### I don't want to use a web UI. You can do most of the communication with your email client (see section on; Setting up email interactions above). You only need to set up your account once; and then configure which categories you want to subscribe to. ### How do I send a private message?. On the mailing list you have the opportunity to reply only to the sender of; the email, not to the entire list. That is not supported when replying via; email on Discourse. However you can send someone a private message via the; Web UI: Click on the user's name above a post and then on `Message`. Also Discourse does not expose users' email addresses , so your private; replies have to go through their platform (unless you happen to know the; email address of the user.). ### How can my script/tool send automatic messages?**. In case you want to [create a new; post/topic](https://docs.discourse.org/#tag/Posts/paths/~1posts.json/post); automatically from a script or tool, you can use the; [Discourse API](https://docs.discourse.org/). ### Who are the admins for Discourse?. See https://llvm.discourse.group/about. ### What is the reason for the migration?. See; [this email](https://lists.llvm.org/pipermail/llvm-dev/2021-June/150823.html). ### How do I set up a private mailing list?. If needed categories can have individual [security; settings](https://meta.discourse.org/t/how-to-use-category-security-settings-to-create-private-categories/87678); to limit visibility and write permissions. Contact the; [admins](https://llvm.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md:10766,Integrability,message,messages,10766,"Obsolete</td></tr>; <tr><td>vmkit-commits</td><td>Obsolete</td></tr>; <tr><td>WiCT</td><td>Community/Women in Compilers and Tools</td></tr>; <tr><td>www-scripts</td><td>Obsolete</td></tr> ; </table>. ## FAQ. ### I don't want to use a web UI. You can do most of the communication with your email client (see section on; Setting up email interactions above). You only need to set up your account once; and then configure which categories you want to subscribe to. ### How do I send a private message?. On the mailing list you have the opportunity to reply only to the sender of; the email, not to the entire list. That is not supported when replying via; email on Discourse. However you can send someone a private message via the; Web UI: Click on the user's name above a post and then on `Message`. Also Discourse does not expose users' email addresses , so your private; replies have to go through their platform (unless you happen to know the; email address of the user.). ### How can my script/tool send automatic messages?**. In case you want to [create a new; post/topic](https://docs.discourse.org/#tag/Posts/paths/~1posts.json/post); automatically from a script or tool, you can use the; [Discourse API](https://docs.discourse.org/). ### Who are the admins for Discourse?. See https://llvm.discourse.group/about. ### What is the reason for the migration?. See; [this email](https://lists.llvm.org/pipermail/llvm-dev/2021-June/150823.html). ### How do I set up a private mailing list?. If needed categories can have individual [security; settings](https://meta.discourse.org/t/how-to-use-category-security-settings-to-create-private-categories/87678); to limit visibility and write permissions. Contact the; [admins](https://llvm.discourse.group/about) if you need such a category. ### What will happen to our email archives?. The Mailman archives will remain on the web server for now. ### What are advantages of Discourse over the current mailing lists?. * Users can post to any category, also ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md:10159,Modifiability,config,configure,10159,"hives</td></tr>; <tr><td>llvm-devmeeting</td><td>Community/US Developer Meeting</td></tr>; <tr><td>llvm-foundation</td><td>Community/LLVM Foundation</td></tr>; <tr><td>Mlir-commits</td><td>no migration at the moment</td></tr>; <tr><td>Openmp-commits</td><td>no migration at the moment</td></tr>; <tr><td>Openmp-dev</td><td>Runtimes/OpenMP</td></tr>; <tr><td>Parallel_libs-commits</td><td>no migration at the moment</td></tr>; <tr><td>Parallel_libs-dev</td><td>Runtimes/C++</td></tr>; <tr><td>Release-testers</td><td>Project Infrastructure/Release Testers</td></tr>; <tr><td>Test-list</td><td>Obsolete</td></tr>; <tr><td>vmkit-commits</td><td>Obsolete</td></tr>; <tr><td>WiCT</td><td>Community/Women in Compilers and Tools</td></tr>; <tr><td>www-scripts</td><td>Obsolete</td></tr> ; </table>. ## FAQ. ### I don't want to use a web UI. You can do most of the communication with your email client (see section on; Setting up email interactions above). You only need to set up your account once; and then configure which categories you want to subscribe to. ### How do I send a private message?. On the mailing list you have the opportunity to reply only to the sender of; the email, not to the entire list. That is not supported when replying via; email on Discourse. However you can send someone a private message via the; Web UI: Click on the user's name above a post and then on `Message`. Also Discourse does not expose users' email addresses , so your private; replies have to go through their platform (unless you happen to know the; email address of the user.). ### How can my script/tool send automatic messages?**. In case you want to [create a new; post/topic](https://docs.discourse.org/#tag/Posts/paths/~1posts.json/post); automatically from a script or tool, you can use the; [Discourse API](https://docs.discourse.org/). ### Who are the admins for Discourse?. See https://llvm.discourse.group/about. ### What is the reason for the migration?. See; [this email](https://lists.llvm.org/piperm",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md:4192,Security,sanitiz,sanitizers,4192,Generation - Arm</td><td>codegen-arm@discourse.llvm.org</td></tr>; <tr><td>Code Generation - PowerPC</td><td>codegen-powerpc@discourse.llvm.org</td></tr>; <tr><td>Code Generation - RISCV</td><td>codegen-riscv@discourse.llvm.org</td></tr>; <tr><td>Code Generation - WebAssembly</td><td>codegen-webassembly@discourse.llvm.org</td></tr>; <tr><td>Code Generation - X86</td><td>codegen-x86@discourse.llvm.org</td></tr>; <tr><td>Clang Frontend</td><td>clang@discourse.llvm.org</td></tr>; <tr><td>Clang Frontend - Using Clang</td><td>clang-users@discourse.llvm.org</td></tr>; <tr><td>Clang Frontend - clangd</td><td>clangd@discourse.llvm.org</td></tr>; <tr><td>Clang Frontend - Building Clang</td><td>clang-build@discourse.llvm.org</td></tr>; <tr><td>Clang Frontend - Static Analyzer</td><td>clang-staticanalyzer@discourse.llvm.org</td></tr>; <tr><td>Runtimes</td><td>runtimes@discourse.llvm.org</td></tr>; <tr><td>Runtimes - C++</td><td>runtimes-cxx@discourse.llvm.org</td></tr>; <tr><td>Runtimes - Sanitizers</td><td>runtimes-sanitizers@discourse.llvm.org</td></tr>; <tr><td>Runtimes - C</td><td>runtimes-c@discourse.llvm.org</td></tr>; <tr><td>Runtimes - OpenMP</td><td>runtimes-openmp@discourse.llvm.org</td></tr>; <tr><td>Runtimes - OpenCL</td><td>runtimes-opencl@discourse.llvm.org</td></tr>; <tr><td>MLIR</td><td>mlir@discourse.llvm.org</td></tr>; <tr><td>MLIR - Announce</td><td>mlir-announce@discourse.llvm.org</td></tr>; <tr><td>MLIR - Newsletter</td><td>mlir-news@discourse.llvm.org</td></tr>; <tr><td>MLIR - TCP-WG</td><td>mlir-tcpwg@discourse.llvm.org</td></tr>; <tr><td>Subprojects</td><td>subprojects@discourse.llvm.org</td></tr>; <tr><td>Subprojects - Polly</td><td>polly@discourse.llvm.org</td></tr>; <tr><td>Subprojects - LLDB</td><td>lldb@discourse.llvm.org</td></tr>; <tr><td>Subprojects - LLD</td><td>lld@discourse.llvm.org</td></tr>; <tr><td>Subprojects - Flang</td><td> flang@discourse.llvm.org</td></tr>; <tr><td>Subprojects - Bolt</td><td>bolt@discourse.llvm.org</td></tr>; <tr><td>P,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md:10572,Security,expose,expose,10572,"></tr>; <tr><td>Release-testers</td><td>Project Infrastructure/Release Testers</td></tr>; <tr><td>Test-list</td><td>Obsolete</td></tr>; <tr><td>vmkit-commits</td><td>Obsolete</td></tr>; <tr><td>WiCT</td><td>Community/Women in Compilers and Tools</td></tr>; <tr><td>www-scripts</td><td>Obsolete</td></tr> ; </table>. ## FAQ. ### I don't want to use a web UI. You can do most of the communication with your email client (see section on; Setting up email interactions above). You only need to set up your account once; and then configure which categories you want to subscribe to. ### How do I send a private message?. On the mailing list you have the opportunity to reply only to the sender of; the email, not to the entire list. That is not supported when replying via; email on Discourse. However you can send someone a private message via the; Web UI: Click on the user's name above a post and then on `Message`. Also Discourse does not expose users' email addresses , so your private; replies have to go through their platform (unless you happen to know the; email address of the user.). ### How can my script/tool send automatic messages?**. In case you want to [create a new; post/topic](https://docs.discourse.org/#tag/Posts/paths/~1posts.json/post); automatically from a script or tool, you can use the; [Discourse API](https://docs.discourse.org/). ### Who are the admins for Discourse?. See https://llvm.discourse.group/about. ### What is the reason for the migration?. See; [this email](https://lists.llvm.org/pipermail/llvm-dev/2021-June/150823.html). ### How do I set up a private mailing list?. If needed categories can have individual [security; settings](https://meta.discourse.org/t/how-to-use-category-security-settings-to-create-private-categories/87678); to limit visibility and write permissions. Contact the; [admins](https://llvm.discourse.group/about) if you need such a category. ### What will happen to our email archives?. The Mailman archives will remain on the web server f",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md:11283,Security,secur,security,11283,"mailing list you have the opportunity to reply only to the sender of; the email, not to the entire list. That is not supported when replying via; email on Discourse. However you can send someone a private message via the; Web UI: Click on the user's name above a post and then on `Message`. Also Discourse does not expose users' email addresses , so your private; replies have to go through their platform (unless you happen to know the; email address of the user.). ### How can my script/tool send automatic messages?**. In case you want to [create a new; post/topic](https://docs.discourse.org/#tag/Posts/paths/~1posts.json/post); automatically from a script or tool, you can use the; [Discourse API](https://docs.discourse.org/). ### Who are the admins for Discourse?. See https://llvm.discourse.group/about. ### What is the reason for the migration?. See; [this email](https://lists.llvm.org/pipermail/llvm-dev/2021-June/150823.html). ### How do I set up a private mailing list?. If needed categories can have individual [security; settings](https://meta.discourse.org/t/how-to-use-category-security-settings-to-create-private-categories/87678); to limit visibility and write permissions. Contact the; [admins](https://llvm.discourse.group/about) if you need such a category. ### What will happen to our email archives?. The Mailman archives will remain on the web server for now. ### What are advantages of Discourse over the current mailing lists?. * Users can post to any category, also without being subscribed.; * Full text search on the Web UI.; * Sending/replying via the Web UI (email is still possible).; * View entire thread on one page.; * Categories are a more light-weight option to structure the discussions than; creating new mailing lists.; * Single sign on with GitHub.; * User email addresses are kept private. ### I have another question not covered here. What should I do?. Please contact iwg@llvm.org or raise a; [ticket on GitHub](https://github.com/llvm/llvm-iwg/issues).; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md:11352,Security,secur,security-settings-to-create-private-categories,11352,"mailing list you have the opportunity to reply only to the sender of; the email, not to the entire list. That is not supported when replying via; email on Discourse. However you can send someone a private message via the; Web UI: Click on the user's name above a post and then on `Message`. Also Discourse does not expose users' email addresses , so your private; replies have to go through their platform (unless you happen to know the; email address of the user.). ### How can my script/tool send automatic messages?**. In case you want to [create a new; post/topic](https://docs.discourse.org/#tag/Posts/paths/~1posts.json/post); automatically from a script or tool, you can use the; [Discourse API](https://docs.discourse.org/). ### Who are the admins for Discourse?. See https://llvm.discourse.group/about. ### What is the reason for the migration?. See; [this email](https://lists.llvm.org/pipermail/llvm-dev/2021-June/150823.html). ### How do I set up a private mailing list?. If needed categories can have individual [security; settings](https://meta.discourse.org/t/how-to-use-category-security-settings-to-create-private-categories/87678); to limit visibility and write permissions. Contact the; [admins](https://llvm.discourse.group/about) if you need such a category. ### What will happen to our email archives?. The Mailman archives will remain on the web server for now. ### What are advantages of Discourse over the current mailing lists?. * Users can post to any category, also without being subscribed.; * Full text search on the Web UI.; * Sending/replying via the Web UI (email is still possible).; * View entire thread on one page.; * Categories are a more light-weight option to structure the discussions than; creating new mailing lists.; * Single sign on with GitHub.; * User email addresses are kept private. ### I have another question not covered here. What should I do?. Please contact iwg@llvm.org or raise a; [ticket on GitHub](https://github.com/llvm/llvm-iwg/issues).; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md:745,Testability,log,log,745,"# Discourse Migration Guide . ## Current Status of Migration: Discourse is back online at a new URL: [https://discourse.llvm.org](https://discourse.llvm.org). The old one still works as well. We are aware of an issue with reply by email to emails from before the merge. We will update once we know more. This document is intended to help LLVM users to migrate from the mailing lists to; Discourse. Discourse has two basic ways for interaction: Via the [web; UI](https://llvm.discourse.group/) and via emails. ## Setting up your account. The easiest way is to create an account using your GitHub account:. 1. Navigate to https://llvm.discourse.group/; 1. Click on ""Sign Up"" in the top right corner.; 1. Choose ""With GitHub"" on the right side and log in with your GitHub account. ## Structure of Discourse. Discourse's structure is similar to a set of mailing lists, however different; terms are used there. To help with the transition, here's a translation table; for the terms:. <table border=1>; <tr><th>Mailing list</th><th>Discourse</th></tr>; <tr><td><i>Mailing list</i>, consists of threads</td><td><i>category</i>, consists of topics</td></tr>; <tr><td><i>thread</i>, consists of emails</td><td><i>topic</i>, consists of posts</td></tr>; <tr><td>email</td><td>post</td></tr>; </table>. ## Setting up email interactions. Some folks want to interact with Discourse purely via their email program. Here; are the typical use cases:. * You can [subscribe to a category or topic](https://discourse.mozilla.org/t/how-do-i-subscribe-to-categories-and-topics/16024); * You can reply to a post, including quoting other peoples texts; ([tested](https://llvm.discourse.group/t/email-interaction-with-discourse/3306/4) on GMail).; * [Quoting previous topics in an reply](https://meta.discourse.org/t/single-quote-block-dropped-in-email-reply/144802); * You can filter incoming emails in your email client by category using the; `List-ID` email header field.; * You can create topics through email using the e",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md:1632,Testability,test,tested,1632,"ing your GitHub account:. 1. Navigate to https://llvm.discourse.group/; 1. Click on ""Sign Up"" in the top right corner.; 1. Choose ""With GitHub"" on the right side and log in with your GitHub account. ## Structure of Discourse. Discourse's structure is similar to a set of mailing lists, however different; terms are used there. To help with the transition, here's a translation table; for the terms:. <table border=1>; <tr><th>Mailing list</th><th>Discourse</th></tr>; <tr><td><i>Mailing list</i>, consists of threads</td><td><i>category</i>, consists of topics</td></tr>; <tr><td><i>thread</i>, consists of emails</td><td><i>topic</i>, consists of posts</td></tr>; <tr><td>email</td><td>post</td></tr>; </table>. ## Setting up email interactions. Some folks want to interact with Discourse purely via their email program. Here; are the typical use cases:. * You can [subscribe to a category or topic](https://discourse.mozilla.org/t/how-do-i-subscribe-to-categories-and-topics/16024); * You can reply to a post, including quoting other peoples texts; ([tested](https://llvm.discourse.group/t/email-interaction-with-discourse/3306/4) on GMail).; * [Quoting previous topics in an reply](https://meta.discourse.org/t/single-quote-block-dropped-in-email-reply/144802); * You can filter incoming emails in your email client by category using the; `List-ID` email header field.; * You can create topics through email using the email address that is specific to the category. Each category description shows the email address to use, or you can use the mapping below. ## Mapping of email addresses to Discourse categories. Use these email addresses to create a topic by email in the specific discourse category. You **must** have a Discourse account associated with the email address you are sending from or the email will be rejected. <table border=1>; <tr><th>Discourse Category</th><th>Email Address</th></tr>; <tr><td>Beginner</td><td>beginners@discourse.llvm.org</td></tr>; <tr><td>LLVM Project</td><td>",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md:5309,Testability,test,testers,5309,scourse.llvm.org</td></tr>; <tr><td>Runtimes - OpenMP</td><td>runtimes-openmp@discourse.llvm.org</td></tr>; <tr><td>Runtimes - OpenCL</td><td>runtimes-opencl@discourse.llvm.org</td></tr>; <tr><td>MLIR</td><td>mlir@discourse.llvm.org</td></tr>; <tr><td>MLIR - Announce</td><td>mlir-announce@discourse.llvm.org</td></tr>; <tr><td>MLIR - Newsletter</td><td>mlir-news@discourse.llvm.org</td></tr>; <tr><td>MLIR - TCP-WG</td><td>mlir-tcpwg@discourse.llvm.org</td></tr>; <tr><td>Subprojects</td><td>subprojects@discourse.llvm.org</td></tr>; <tr><td>Subprojects - Polly</td><td>polly@discourse.llvm.org</td></tr>; <tr><td>Subprojects - LLDB</td><td>lldb@discourse.llvm.org</td></tr>; <tr><td>Subprojects - LLD</td><td>lld@discourse.llvm.org</td></tr>; <tr><td>Subprojects - Flang</td><td> flang@discourse.llvm.org</td></tr>; <tr><td>Subprojects - Bolt</td><td>bolt@discourse.llvm.org</td></tr>; <tr><td>Project Infrastructure</td><td>infra@discourse.llvm.org</td></tr>; <tr><td>Project Infrastructure - Release Testers</td><td>infra-release-testers@discourse.llvm.org</td></tr>; <tr><td>Project Infrastructure - Website</td><td>infra-website@discourse.llvm.org</td></tr>; <tr><td>Project Infrastructure - Documentation</td><td> infra-docs@discourse.llvm.org</td></tr>; <tr><td>Project Infrastructure - GitHub</td><td>infra-github@discourse.llvm.org</td></tr>; <tr><td>Project Infrastructure - Code Review</td><td>infra-codereview@discourse.llvm.org</td></tr>; <tr><td>Project Infrastructure - Discord</td><td>infra-discord@discourse.llvm.org</td></tr>; <tr><td>Project Infrastructure - Mailing Lists and Forums</td><td>infra-mailinglists@discourse.llvm.org</td></tr>; <tr><td>Project Infrastructure - IRC</td><td> infra-irc@discourse.llvm.org</td></tr>; <tr><td>Project Infrastructure - Infrastructure Working Group</td><td>infra-iwg@discourse.llvm.org</td></tr>; <tr><td>Community</td><td>community@discourse.llvm.org</td></tr>; <tr><td>Community - Women in Compilers and Tools</td><td>wict@discourse.llvm.,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md:9658,Testability,test,testers,9658,/clangd</td></tr>; <tr><td>devmtg-organizers</td><td>Obsolete</td></tr>; <tr><td>Docs</td><td>Obsolete</td></tr>; <tr><td>eurollvm-organizers</td><td>Obsolete</td></tr>; <tr><td>flang-commits</td><td>no migration at the moment</td></tr>; <tr><td>flang-dev</td><td>Subprojects/Flang Fortran Frontend</td></tr>; <tr><td>gsoc</td><td>Obsolete</td></tr>; <tr><td>libc-commits</td><td>no migration at the moment</td></tr>; <tr><td>libc-dev</td><td>Runtimes/C</td></tr>; <tr><td>Libclc-dev</td><td>Runtimes/OpenCL</td></tr>; <tr><td>libcxx-bugs</td><td>no migration at the moment</td></tr>; <tr><td>libcxx-commits</td><td>no migration at the moment</td></tr>; <tr><td>libcxx-dev</td><td>Runtimes/C++</td></tr>; <tr><td>lldb-commits</td><td>no migration at the moment</td></tr>; <tr><td>lldb-dev</td><td>Subprojects/lldb</td></tr>; <tr><td>llvm-admin</td><td>no migration at the moment</td></tr>; <tr><td>llvm-announce</td><td>Announce</td></tr>; <tr><td>llvm-branch-commits</td><td>no migration at the moment</td></tr>; <tr><td>llvm-bugs</td><td>no migration at the moment</td></tr>; <tr><td>llvm-commits</td><td>no migration at the moment</td></tr>; <tr><td>llvm-dev</td><td>Project Infrastructure/LLVM Dev List Archives</td></tr>; <tr><td>llvm-devmeeting</td><td>Community/US Developer Meeting</td></tr>; <tr><td>llvm-foundation</td><td>Community/LLVM Foundation</td></tr>; <tr><td>Mlir-commits</td><td>no migration at the moment</td></tr>; <tr><td>Openmp-commits</td><td>no migration at the moment</td></tr>; <tr><td>Openmp-dev</td><td>Runtimes/OpenMP</td></tr>; <tr><td>Parallel_libs-commits</td><td>no migration at the moment</td></tr>; <tr><td>Parallel_libs-dev</td><td>Runtimes/C++</td></tr>; <tr><td>Release-testers</td><td>Project Infrastructure/Release Testers</td></tr>; <tr><td>Test-list</td><td>Obsolete</td></tr>; <tr><td>vmkit-commits</td><td>Obsolete</td></tr>; <tr><td>WiCT</td><td>Community/Women in Compilers and Tools</td></tr>; <tr><td>www-scripts</td><td>Obsolete</td></tr> ; </table>.,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md:7185,Usability,feedback,feedback,7185,"rse.llvm.org</td></tr>; <tr><td>Community - Women in Compilers and Tools</td><td>wict@discourse.llvm.org</td></tr>; <tr><td>Community - Job Postings</td><td>community-jobs@discourse.llvm.org</td></tr>; <tr><td>Community - US LLVM Developers' Meeting</td><td>devmtg-US@discourse.llvm.org</td></tr>; <tr><td>Community - EuroLLVM</td><td>devmtg-euro@discourse.llvm.org</td></tr>; <tr><td>Community - GSOC</td><td>gsoc@discourse.llvm.org</td></tr>; <tr><td>Community - Community.o</td><td>community-dot-o@discourse.llvm.org</td></tr>; <tr><td>Community - LLVM Foundation</td><td>foundation@discourse.llvm.org</td></tr>; <tr><td>Community - Newsletters</td><td>newsletters@discourse.llvm.org</td></tr>; <tr><td>Incubator</td><td>incubator@discourse.llvm.org</td></tr>; <tr><td>Incubator - CIRCT</td><td>circt@discourse.llvm.org</td></tr>; <tr><td>Incubator - Torch-MLIR</td><td>torch-mlir@discourse.llvm.org</td></tr>; <tr><td>Incubator - Enzyme</td><td>enzyme@discourse.llvm.org</td></tr>; <tr><td>Feedback</td><td>feedback@discourse.llvm.org</td></tr>; </table>. ## Mapping of mailing lists to categories. This table explains the mapping from mailing lists to categories in Discourse.; The email addresses of these categories will remain the same, after the; migration. Obsolete lists will become read-only as part of the Discourse; migration. <table border=1>; <tr><th>Mailing lists</th><th>Category in Discourse</th></tr>. <tr><td>All-commits</td><td>no migration at the moment</td></tr>; <tr><td>Bugs-admin</td><td>no migration at the moment</td></tr>; <tr><td>cfe-commits</td><td>no migration at the moment</td></tr>; <tr><td>cfe-dev</td><td>Clang Frontend</td></tr>; <tr><td>cfe-users</td><td>Clang Frontend/Using Clang</td></tr>; <tr><td>clangd-dev</td><td>Clang Frontend/clangd</td></tr>; <tr><td>devmtg-organizers</td><td>Obsolete</td></tr>; <tr><td>Docs</td><td>Obsolete</td></tr>; <tr><td>eurollvm-organizers</td><td>Obsolete</td></tr>; <tr><td>flang-commits</td><td>no migration at the moment<",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GitRepositoryPolicy.md:936,Deployability,integrat,integrate,936,"# Policies on git repositories. This document explains our current policies around git repositories. Everything; not covered in this document is most likely a case-by-case decision. In these; cases please create an issue with the; [Infrastructure Working Group](https://github.com/llvm/llvm-iwg/issues). ## New GitHub repositories. Requirements for *new* repositories as part of the; [LLVM organisation on GitHub](https://github.com/llvm):. * The repo will be used for something related to the LLVM ecosystem or community.; * The repo contains a `README.md` explaining the contents.; * The repo contains a `CONTRIBUTING.md`, ideally copy this from; [llvm-project](https://github.com/llvm/llvm-project/blob/main/CONTRIBUTING.md).; * The repo contains a `LICENSE.TXT`, preferably copy this from; [llvm-project](https://github.com/llvm/llvm-project/blob/main/LICENSE.TXT).; Other licences need to be discussed case-by-case. If you want to integrate your project as part of the Monorepo, please take a; look at the; [Developer Policy](project:DeveloperPolicy.rst#Adding an Established Project To the LLVM Monorepo). To request a new repository, please create an issue with the; [Infrastructure Working Group](https://github.com/llvm/llvm-iwg/issues). ## Repo access on GitHub. Some 3rd party applications require write access to our GitHub organisation in; order to work properly. Typical examples are continuous integration services; reporting build results back to GitHub. We consider granting access to such; application if they provide benefits to the LLVM community and do not raise; privacy or security concerns. To request access please run an RFC on the mailing list and get community; feedback.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GitRepositoryPolicy.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GitRepositoryPolicy.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GitRepositoryPolicy.md:1398,Deployability,continuous,continuous,1398,"# Policies on git repositories. This document explains our current policies around git repositories. Everything; not covered in this document is most likely a case-by-case decision. In these; cases please create an issue with the; [Infrastructure Working Group](https://github.com/llvm/llvm-iwg/issues). ## New GitHub repositories. Requirements for *new* repositories as part of the; [LLVM organisation on GitHub](https://github.com/llvm):. * The repo will be used for something related to the LLVM ecosystem or community.; * The repo contains a `README.md` explaining the contents.; * The repo contains a `CONTRIBUTING.md`, ideally copy this from; [llvm-project](https://github.com/llvm/llvm-project/blob/main/CONTRIBUTING.md).; * The repo contains a `LICENSE.TXT`, preferably copy this from; [llvm-project](https://github.com/llvm/llvm-project/blob/main/LICENSE.TXT).; Other licences need to be discussed case-by-case. If you want to integrate your project as part of the Monorepo, please take a; look at the; [Developer Policy](project:DeveloperPolicy.rst#Adding an Established Project To the LLVM Monorepo). To request a new repository, please create an issue with the; [Infrastructure Working Group](https://github.com/llvm/llvm-iwg/issues). ## Repo access on GitHub. Some 3rd party applications require write access to our GitHub organisation in; order to work properly. Typical examples are continuous integration services; reporting build results back to GitHub. We consider granting access to such; application if they provide benefits to the LLVM community and do not raise; privacy or security concerns. To request access please run an RFC on the mailing list and get community; feedback.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GitRepositoryPolicy.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GitRepositoryPolicy.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GitRepositoryPolicy.md:1409,Deployability,integrat,integration,1409,"# Policies on git repositories. This document explains our current policies around git repositories. Everything; not covered in this document is most likely a case-by-case decision. In these; cases please create an issue with the; [Infrastructure Working Group](https://github.com/llvm/llvm-iwg/issues). ## New GitHub repositories. Requirements for *new* repositories as part of the; [LLVM organisation on GitHub](https://github.com/llvm):. * The repo will be used for something related to the LLVM ecosystem or community.; * The repo contains a `README.md` explaining the contents.; * The repo contains a `CONTRIBUTING.md`, ideally copy this from; [llvm-project](https://github.com/llvm/llvm-project/blob/main/CONTRIBUTING.md).; * The repo contains a `LICENSE.TXT`, preferably copy this from; [llvm-project](https://github.com/llvm/llvm-project/blob/main/LICENSE.TXT).; Other licences need to be discussed case-by-case. If you want to integrate your project as part of the Monorepo, please take a; look at the; [Developer Policy](project:DeveloperPolicy.rst#Adding an Established Project To the LLVM Monorepo). To request a new repository, please create an issue with the; [Infrastructure Working Group](https://github.com/llvm/llvm-iwg/issues). ## Repo access on GitHub. Some 3rd party applications require write access to our GitHub organisation in; order to work properly. Typical examples are continuous integration services; reporting build results back to GitHub. We consider granting access to such; application if they provide benefits to the LLVM community and do not raise; privacy or security concerns. To request access please run an RFC on the mailing list and get community; feedback.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GitRepositoryPolicy.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GitRepositoryPolicy.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GitRepositoryPolicy.md:936,Integrability,integrat,integrate,936,"# Policies on git repositories. This document explains our current policies around git repositories. Everything; not covered in this document is most likely a case-by-case decision. In these; cases please create an issue with the; [Infrastructure Working Group](https://github.com/llvm/llvm-iwg/issues). ## New GitHub repositories. Requirements for *new* repositories as part of the; [LLVM organisation on GitHub](https://github.com/llvm):. * The repo will be used for something related to the LLVM ecosystem or community.; * The repo contains a `README.md` explaining the contents.; * The repo contains a `CONTRIBUTING.md`, ideally copy this from; [llvm-project](https://github.com/llvm/llvm-project/blob/main/CONTRIBUTING.md).; * The repo contains a `LICENSE.TXT`, preferably copy this from; [llvm-project](https://github.com/llvm/llvm-project/blob/main/LICENSE.TXT).; Other licences need to be discussed case-by-case. If you want to integrate your project as part of the Monorepo, please take a; look at the; [Developer Policy](project:DeveloperPolicy.rst#Adding an Established Project To the LLVM Monorepo). To request a new repository, please create an issue with the; [Infrastructure Working Group](https://github.com/llvm/llvm-iwg/issues). ## Repo access on GitHub. Some 3rd party applications require write access to our GitHub organisation in; order to work properly. Typical examples are continuous integration services; reporting build results back to GitHub. We consider granting access to such; application if they provide benefits to the LLVM community and do not raise; privacy or security concerns. To request access please run an RFC on the mailing list and get community; feedback.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GitRepositoryPolicy.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GitRepositoryPolicy.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GitRepositoryPolicy.md:1409,Integrability,integrat,integration,1409,"# Policies on git repositories. This document explains our current policies around git repositories. Everything; not covered in this document is most likely a case-by-case decision. In these; cases please create an issue with the; [Infrastructure Working Group](https://github.com/llvm/llvm-iwg/issues). ## New GitHub repositories. Requirements for *new* repositories as part of the; [LLVM organisation on GitHub](https://github.com/llvm):. * The repo will be used for something related to the LLVM ecosystem or community.; * The repo contains a `README.md` explaining the contents.; * The repo contains a `CONTRIBUTING.md`, ideally copy this from; [llvm-project](https://github.com/llvm/llvm-project/blob/main/CONTRIBUTING.md).; * The repo contains a `LICENSE.TXT`, preferably copy this from; [llvm-project](https://github.com/llvm/llvm-project/blob/main/LICENSE.TXT).; Other licences need to be discussed case-by-case. If you want to integrate your project as part of the Monorepo, please take a; look at the; [Developer Policy](project:DeveloperPolicy.rst#Adding an Established Project To the LLVM Monorepo). To request a new repository, please create an issue with the; [Infrastructure Working Group](https://github.com/llvm/llvm-iwg/issues). ## Repo access on GitHub. Some 3rd party applications require write access to our GitHub organisation in; order to work properly. Typical examples are continuous integration services; reporting build results back to GitHub. We consider granting access to such; application if they provide benefits to the LLVM community and do not raise; privacy or security concerns. To request access please run an RFC on the mailing list and get community; feedback.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GitRepositoryPolicy.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GitRepositoryPolicy.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GitRepositoryPolicy.md:1255,Security,access,access,1255,"# Policies on git repositories. This document explains our current policies around git repositories. Everything; not covered in this document is most likely a case-by-case decision. In these; cases please create an issue with the; [Infrastructure Working Group](https://github.com/llvm/llvm-iwg/issues). ## New GitHub repositories. Requirements for *new* repositories as part of the; [LLVM organisation on GitHub](https://github.com/llvm):. * The repo will be used for something related to the LLVM ecosystem or community.; * The repo contains a `README.md` explaining the contents.; * The repo contains a `CONTRIBUTING.md`, ideally copy this from; [llvm-project](https://github.com/llvm/llvm-project/blob/main/CONTRIBUTING.md).; * The repo contains a `LICENSE.TXT`, preferably copy this from; [llvm-project](https://github.com/llvm/llvm-project/blob/main/LICENSE.TXT).; Other licences need to be discussed case-by-case. If you want to integrate your project as part of the Monorepo, please take a; look at the; [Developer Policy](project:DeveloperPolicy.rst#Adding an Established Project To the LLVM Monorepo). To request a new repository, please create an issue with the; [Infrastructure Working Group](https://github.com/llvm/llvm-iwg/issues). ## Repo access on GitHub. Some 3rd party applications require write access to our GitHub organisation in; order to work properly. Typical examples are continuous integration services; reporting build results back to GitHub. We consider granting access to such; application if they provide benefits to the LLVM community and do not raise; privacy or security concerns. To request access please run an RFC on the mailing list and get community; feedback.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GitRepositoryPolicy.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GitRepositoryPolicy.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GitRepositoryPolicy.md:1315,Security,access,access,1315,"# Policies on git repositories. This document explains our current policies around git repositories. Everything; not covered in this document is most likely a case-by-case decision. In these; cases please create an issue with the; [Infrastructure Working Group](https://github.com/llvm/llvm-iwg/issues). ## New GitHub repositories. Requirements for *new* repositories as part of the; [LLVM organisation on GitHub](https://github.com/llvm):. * The repo will be used for something related to the LLVM ecosystem or community.; * The repo contains a `README.md` explaining the contents.; * The repo contains a `CONTRIBUTING.md`, ideally copy this from; [llvm-project](https://github.com/llvm/llvm-project/blob/main/CONTRIBUTING.md).; * The repo contains a `LICENSE.TXT`, preferably copy this from; [llvm-project](https://github.com/llvm/llvm-project/blob/main/LICENSE.TXT).; Other licences need to be discussed case-by-case. If you want to integrate your project as part of the Monorepo, please take a; look at the; [Developer Policy](project:DeveloperPolicy.rst#Adding an Established Project To the LLVM Monorepo). To request a new repository, please create an issue with the; [Infrastructure Working Group](https://github.com/llvm/llvm-iwg/issues). ## Repo access on GitHub. Some 3rd party applications require write access to our GitHub organisation in; order to work properly. Typical examples are continuous integration services; reporting build results back to GitHub. We consider granting access to such; application if they provide benefits to the LLVM community and do not raise; privacy or security concerns. To request access please run an RFC on the mailing list and get community; feedback.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GitRepositoryPolicy.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GitRepositoryPolicy.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GitRepositoryPolicy.md:1492,Security,access,access,1492,"# Policies on git repositories. This document explains our current policies around git repositories. Everything; not covered in this document is most likely a case-by-case decision. In these; cases please create an issue with the; [Infrastructure Working Group](https://github.com/llvm/llvm-iwg/issues). ## New GitHub repositories. Requirements for *new* repositories as part of the; [LLVM organisation on GitHub](https://github.com/llvm):. * The repo will be used for something related to the LLVM ecosystem or community.; * The repo contains a `README.md` explaining the contents.; * The repo contains a `CONTRIBUTING.md`, ideally copy this from; [llvm-project](https://github.com/llvm/llvm-project/blob/main/CONTRIBUTING.md).; * The repo contains a `LICENSE.TXT`, preferably copy this from; [llvm-project](https://github.com/llvm/llvm-project/blob/main/LICENSE.TXT).; Other licences need to be discussed case-by-case. If you want to integrate your project as part of the Monorepo, please take a; look at the; [Developer Policy](project:DeveloperPolicy.rst#Adding an Established Project To the LLVM Monorepo). To request a new repository, please create an issue with the; [Infrastructure Working Group](https://github.com/llvm/llvm-iwg/issues). ## Repo access on GitHub. Some 3rd party applications require write access to our GitHub organisation in; order to work properly. Typical examples are continuous integration services; reporting build results back to GitHub. We consider granting access to such; application if they provide benefits to the LLVM community and do not raise; privacy or security concerns. To request access please run an RFC on the mailing list and get community; feedback.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GitRepositoryPolicy.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GitRepositoryPolicy.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GitRepositoryPolicy.md:1596,Security,secur,security,1596,"# Policies on git repositories. This document explains our current policies around git repositories. Everything; not covered in this document is most likely a case-by-case decision. In these; cases please create an issue with the; [Infrastructure Working Group](https://github.com/llvm/llvm-iwg/issues). ## New GitHub repositories. Requirements for *new* repositories as part of the; [LLVM organisation on GitHub](https://github.com/llvm):. * The repo will be used for something related to the LLVM ecosystem or community.; * The repo contains a `README.md` explaining the contents.; * The repo contains a `CONTRIBUTING.md`, ideally copy this from; [llvm-project](https://github.com/llvm/llvm-project/blob/main/CONTRIBUTING.md).; * The repo contains a `LICENSE.TXT`, preferably copy this from; [llvm-project](https://github.com/llvm/llvm-project/blob/main/LICENSE.TXT).; Other licences need to be discussed case-by-case. If you want to integrate your project as part of the Monorepo, please take a; look at the; [Developer Policy](project:DeveloperPolicy.rst#Adding an Established Project To the LLVM Monorepo). To request a new repository, please create an issue with the; [Infrastructure Working Group](https://github.com/llvm/llvm-iwg/issues). ## Repo access on GitHub. Some 3rd party applications require write access to our GitHub organisation in; order to work properly. Typical examples are continuous integration services; reporting build results back to GitHub. We consider granting access to such; application if they provide benefits to the LLVM community and do not raise; privacy or security concerns. To request access please run an RFC on the mailing list and get community; feedback.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GitRepositoryPolicy.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GitRepositoryPolicy.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GitRepositoryPolicy.md:1626,Security,access,access,1626,"# Policies on git repositories. This document explains our current policies around git repositories. Everything; not covered in this document is most likely a case-by-case decision. In these; cases please create an issue with the; [Infrastructure Working Group](https://github.com/llvm/llvm-iwg/issues). ## New GitHub repositories. Requirements for *new* repositories as part of the; [LLVM organisation on GitHub](https://github.com/llvm):. * The repo will be used for something related to the LLVM ecosystem or community.; * The repo contains a `README.md` explaining the contents.; * The repo contains a `CONTRIBUTING.md`, ideally copy this from; [llvm-project](https://github.com/llvm/llvm-project/blob/main/CONTRIBUTING.md).; * The repo contains a `LICENSE.TXT`, preferably copy this from; [llvm-project](https://github.com/llvm/llvm-project/blob/main/LICENSE.TXT).; Other licences need to be discussed case-by-case. If you want to integrate your project as part of the Monorepo, please take a; look at the; [Developer Policy](project:DeveloperPolicy.rst#Adding an Established Project To the LLVM Monorepo). To request a new repository, please create an issue with the; [Infrastructure Working Group](https://github.com/llvm/llvm-iwg/issues). ## Repo access on GitHub. Some 3rd party applications require write access to our GitHub organisation in; order to work properly. Typical examples are continuous integration services; reporting build results back to GitHub. We consider granting access to such; application if they provide benefits to the LLVM community and do not raise; privacy or security concerns. To request access please run an RFC on the mailing list and get community; feedback.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GitRepositoryPolicy.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GitRepositoryPolicy.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GitRepositoryPolicy.md:1690,Usability,feedback,feedback,1690,"# Policies on git repositories. This document explains our current policies around git repositories. Everything; not covered in this document is most likely a case-by-case decision. In these; cases please create an issue with the; [Infrastructure Working Group](https://github.com/llvm/llvm-iwg/issues). ## New GitHub repositories. Requirements for *new* repositories as part of the; [LLVM organisation on GitHub](https://github.com/llvm):. * The repo will be used for something related to the LLVM ecosystem or community.; * The repo contains a `README.md` explaining the contents.; * The repo contains a `CONTRIBUTING.md`, ideally copy this from; [llvm-project](https://github.com/llvm/llvm-project/blob/main/CONTRIBUTING.md).; * The repo contains a `LICENSE.TXT`, preferably copy this from; [llvm-project](https://github.com/llvm/llvm-project/blob/main/LICENSE.TXT).; Other licences need to be discussed case-by-case. If you want to integrate your project as part of the Monorepo, please take a; look at the; [Developer Policy](project:DeveloperPolicy.rst#Adding an Established Project To the LLVM Monorepo). To request a new repository, please create an issue with the; [Infrastructure Working Group](https://github.com/llvm/llvm-iwg/issues). ## Repo access on GitHub. Some 3rd party applications require write access to our GitHub organisation in; order to work properly. Typical examples are continuous integration services; reporting build results back to GitHub. We consider granting access to such; application if they provide benefits to the LLVM community and do not raise; privacy or security concerns. To request access please run an RFC on the mailing list and get community; feedback.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GitRepositoryPolicy.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GitRepositoryPolicy.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md:2929,Availability,mainten,maintenance,2929,"d, a more consistent way of identifying; the instruction's value is to refer to the `MachineOperand` where the value is; defined: independently of which register is defined by that `MachineOperand`. In; the code above, the `DBG_INSTR_REF` instruction refers to instruction number; one, operand zero, while the `ADD32rr` has a `debug-instr-number` attribute; attached indicating that it is instruction number one. De-coupling variable locations from registers avoids difficulties involving; register allocation and optimisation, but requires additional instrumentation; when the instructions are optimised instead. Optimisations that replace; instructions with optimised versions that compute the same value must either; preserve the instruction number, or record a substitution from the old; instruction / operand number pair to the new instruction / operand pair -- see; `MachineFunction::substituteDebugValuesForInst`. If debug info maintenance is; not performed, or an instruction is eliminated as dead code, the variable; location is safely dropped and marked ""optimised out"". The exception is; instructions that are mutated rather than replaced, which always need debug info; maintenance. # Register allocator considerations. When the register allocator runs, debugging instructions do not directly refer; to any virtual registers, and thus there is no need for expensive location; maintenance during regalloc (i.e. `LiveDebugVariables`). Debug instructions are; unlinked from the function, then linked back in after register allocation; completes. The exception is `PHI` instructions: these become implicit definitions at; control flow merges once regalloc finishes, and any debug numbers attached to; `PHI` instructions are lost. To circumvent this, debug numbers of `PHI`s are; recorded at the start of register allocation (`phi-node-elimination`), then; `DBG_PHI` instructions are inserted after regalloc finishes. This requires some; maintenance of which register a variable is located in d",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md:3175,Availability,mainten,maintenance,3175,"ndently of which register is defined by that `MachineOperand`. In; the code above, the `DBG_INSTR_REF` instruction refers to instruction number; one, operand zero, while the `ADD32rr` has a `debug-instr-number` attribute; attached indicating that it is instruction number one. De-coupling variable locations from registers avoids difficulties involving; register allocation and optimisation, but requires additional instrumentation; when the instructions are optimised instead. Optimisations that replace; instructions with optimised versions that compute the same value must either; preserve the instruction number, or record a substitution from the old; instruction / operand number pair to the new instruction / operand pair -- see; `MachineFunction::substituteDebugValuesForInst`. If debug info maintenance is; not performed, or an instruction is eliminated as dead code, the variable; location is safely dropped and marked ""optimised out"". The exception is; instructions that are mutated rather than replaced, which always need debug info; maintenance. # Register allocator considerations. When the register allocator runs, debugging instructions do not directly refer; to any virtual registers, and thus there is no need for expensive location; maintenance during regalloc (i.e. `LiveDebugVariables`). Debug instructions are; unlinked from the function, then linked back in after register allocation; completes. The exception is `PHI` instructions: these become implicit definitions at; control flow merges once regalloc finishes, and any debug numbers attached to; `PHI` instructions are lost. To circumvent this, debug numbers of `PHI`s are; recorded at the start of register allocation (`phi-node-elimination`), then; `DBG_PHI` instructions are inserted after regalloc finishes. This requires some; maintenance of which register a variable is located in during regalloc, but at; single positions (block entry points) rather than ranges of instructions. An example, before regalloc:. ```text; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md:3381,Availability,mainten,maintenance,3381,"a `debug-instr-number` attribute; attached indicating that it is instruction number one. De-coupling variable locations from registers avoids difficulties involving; register allocation and optimisation, but requires additional instrumentation; when the instructions are optimised instead. Optimisations that replace; instructions with optimised versions that compute the same value must either; preserve the instruction number, or record a substitution from the old; instruction / operand number pair to the new instruction / operand pair -- see; `MachineFunction::substituteDebugValuesForInst`. If debug info maintenance is; not performed, or an instruction is eliminated as dead code, the variable; location is safely dropped and marked ""optimised out"". The exception is; instructions that are mutated rather than replaced, which always need debug info; maintenance. # Register allocator considerations. When the register allocator runs, debugging instructions do not directly refer; to any virtual registers, and thus there is no need for expensive location; maintenance during regalloc (i.e. `LiveDebugVariables`). Debug instructions are; unlinked from the function, then linked back in after register allocation; completes. The exception is `PHI` instructions: these become implicit definitions at; control flow merges once regalloc finishes, and any debug numbers attached to; `PHI` instructions are lost. To circumvent this, debug numbers of `PHI`s are; recorded at the start of register allocation (`phi-node-elimination`), then; `DBG_PHI` instructions are inserted after regalloc finishes. This requires some; maintenance of which register a variable is located in during regalloc, but at; single positions (block entry points) rather than ranges of instructions. An example, before regalloc:. ```text; bb.2:; %2 = PHI %1, %bb.0, %2, %bb.1, debug-instr-number 1; ```. After:. ```text; bb.2:; DBG_PHI $rax, 1; ```. # `LiveDebugValues`. After optimisations and code layout complete, informati",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md:3938,Availability,mainten,maintenance,3938,", the variable; location is safely dropped and marked ""optimised out"". The exception is; instructions that are mutated rather than replaced, which always need debug info; maintenance. # Register allocator considerations. When the register allocator runs, debugging instructions do not directly refer; to any virtual registers, and thus there is no need for expensive location; maintenance during regalloc (i.e. `LiveDebugVariables`). Debug instructions are; unlinked from the function, then linked back in after register allocation; completes. The exception is `PHI` instructions: these become implicit definitions at; control flow merges once regalloc finishes, and any debug numbers attached to; `PHI` instructions are lost. To circumvent this, debug numbers of `PHI`s are; recorded at the start of register allocation (`phi-node-elimination`), then; `DBG_PHI` instructions are inserted after regalloc finishes. This requires some; maintenance of which register a variable is located in during regalloc, but at; single positions (block entry points) rather than ranges of instructions. An example, before regalloc:. ```text; bb.2:; %2 = PHI %1, %bb.0, %2, %bb.1, debug-instr-number 1; ```. After:. ```text; bb.2:; DBG_PHI $rax, 1; ```. # `LiveDebugValues`. After optimisations and code layout complete, information about variable; values must be translated into variable locations, i.e. registers and stack; slots. This is performed in the [`LiveDebugValues` pass][LiveDebugValues], where; the debug instructions and machine code are separated out into two independent; functions:; * One that assigns values to variable names,; * One that assigns values to machine registers and stack slots. LLVM's existing SSA tools are used to place `PHI`s for each function, between; variable values and the values contained in machine locations, with value; propagation eliminating any unnecessary `PHI`s. The two can then be joined up; to map variables to values, then values to locations, for each instructio",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md:137,Modifiability,variab,variable,137,"# Instruction referencing for debug info. This document explains how LLVM uses value tracking, or instruction; referencing, to determine variable locations for debug info in the code; generation stage of compilation. This content is aimed at those working on code; generation targets and optimisation passes. It may also be of interest to anyone; curious about low-level debug info handling. # Problem statement. At the end of compilation, LLVM must produce a DWARF location list (or similar); describing what register or stack location a variable can be found in, for each; instruction in that variable's lexical scope. We could track the virtual; register that the variable resides in through compilation, however this is; vulnerable to register optimisations during regalloc, and instruction; movements. # Solution: instruction referencing. Rather than identify the virtual register that a variable value resides in,; instead in instruction referencing mode, LLVM refers to the machine instruction; and operand position that the value is defined in. Consider the LLVM IR way of; referring to instruction values:. ```llvm; %2 = add i32 %0, %1; call void @llvm.dbg.value(metadata i32 %2,; ```. In LLVM IR, the IR Value is synonymous with the instruction that computes the; value, to the extent that in memory a Value is a pointer to the computing; instruction. Instruction referencing implements this relationship in the; codegen backend of LLVM, after instruction selection. Consider the X86 assembly; below and instruction referencing debug info, corresponding to the earlier; LLVM IR:. ```text; %2:gr32 = ADD32rr %0, %1, implicit-def $eflags, debug-instr-number 1; DBG_INSTR_REF 1, 0, !123, !456, debug-location !789; ```. While the function remains in SSA form, virtual register `%2` is sufficient to; identify the value computed by the instruction -- however the function; eventually leaves SSA form, and register optimisations will obscure which; register the desired value is in. Instead, a mo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md:539,Modifiability,variab,variable,539,"# Instruction referencing for debug info. This document explains how LLVM uses value tracking, or instruction; referencing, to determine variable locations for debug info in the code; generation stage of compilation. This content is aimed at those working on code; generation targets and optimisation passes. It may also be of interest to anyone; curious about low-level debug info handling. # Problem statement. At the end of compilation, LLVM must produce a DWARF location list (or similar); describing what register or stack location a variable can be found in, for each; instruction in that variable's lexical scope. We could track the virtual; register that the variable resides in through compilation, however this is; vulnerable to register optimisations during regalloc, and instruction; movements. # Solution: instruction referencing. Rather than identify the virtual register that a variable value resides in,; instead in instruction referencing mode, LLVM refers to the machine instruction; and operand position that the value is defined in. Consider the LLVM IR way of; referring to instruction values:. ```llvm; %2 = add i32 %0, %1; call void @llvm.dbg.value(metadata i32 %2,; ```. In LLVM IR, the IR Value is synonymous with the instruction that computes the; value, to the extent that in memory a Value is a pointer to the computing; instruction. Instruction referencing implements this relationship in the; codegen backend of LLVM, after instruction selection. Consider the X86 assembly; below and instruction referencing debug info, corresponding to the earlier; LLVM IR:. ```text; %2:gr32 = ADD32rr %0, %1, implicit-def $eflags, debug-instr-number 1; DBG_INSTR_REF 1, 0, !123, !456, debug-location !789; ```. While the function remains in SSA form, virtual register `%2` is sufficient to; identify the value computed by the instruction -- however the function; eventually leaves SSA form, and register optimisations will obscure which; register the desired value is in. Instead, a mo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md:595,Modifiability,variab,variable,595,"# Instruction referencing for debug info. This document explains how LLVM uses value tracking, or instruction; referencing, to determine variable locations for debug info in the code; generation stage of compilation. This content is aimed at those working on code; generation targets and optimisation passes. It may also be of interest to anyone; curious about low-level debug info handling. # Problem statement. At the end of compilation, LLVM must produce a DWARF location list (or similar); describing what register or stack location a variable can be found in, for each; instruction in that variable's lexical scope. We could track the virtual; register that the variable resides in through compilation, however this is; vulnerable to register optimisations during regalloc, and instruction; movements. # Solution: instruction referencing. Rather than identify the virtual register that a variable value resides in,; instead in instruction referencing mode, LLVM refers to the machine instruction; and operand position that the value is defined in. Consider the LLVM IR way of; referring to instruction values:. ```llvm; %2 = add i32 %0, %1; call void @llvm.dbg.value(metadata i32 %2,; ```. In LLVM IR, the IR Value is synonymous with the instruction that computes the; value, to the extent that in memory a Value is a pointer to the computing; instruction. Instruction referencing implements this relationship in the; codegen backend of LLVM, after instruction selection. Consider the X86 assembly; below and instruction referencing debug info, corresponding to the earlier; LLVM IR:. ```text; %2:gr32 = ADD32rr %0, %1, implicit-def $eflags, debug-instr-number 1; DBG_INSTR_REF 1, 0, !123, !456, debug-location !789; ```. While the function remains in SSA form, virtual register `%2` is sufficient to; identify the value computed by the instruction -- however the function; eventually leaves SSA form, and register optimisations will obscure which; register the desired value is in. Instead, a mo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md:667,Modifiability,variab,variable,667,"# Instruction referencing for debug info. This document explains how LLVM uses value tracking, or instruction; referencing, to determine variable locations for debug info in the code; generation stage of compilation. This content is aimed at those working on code; generation targets and optimisation passes. It may also be of interest to anyone; curious about low-level debug info handling. # Problem statement. At the end of compilation, LLVM must produce a DWARF location list (or similar); describing what register or stack location a variable can be found in, for each; instruction in that variable's lexical scope. We could track the virtual; register that the variable resides in through compilation, however this is; vulnerable to register optimisations during regalloc, and instruction; movements. # Solution: instruction referencing. Rather than identify the virtual register that a variable value resides in,; instead in instruction referencing mode, LLVM refers to the machine instruction; and operand position that the value is defined in. Consider the LLVM IR way of; referring to instruction values:. ```llvm; %2 = add i32 %0, %1; call void @llvm.dbg.value(metadata i32 %2,; ```. In LLVM IR, the IR Value is synonymous with the instruction that computes the; value, to the extent that in memory a Value is a pointer to the computing; instruction. Instruction referencing implements this relationship in the; codegen backend of LLVM, after instruction selection. Consider the X86 assembly; below and instruction referencing debug info, corresponding to the earlier; LLVM IR:. ```text; %2:gr32 = ADD32rr %0, %1, implicit-def $eflags, debug-instr-number 1; DBG_INSTR_REF 1, 0, !123, !456, debug-location !789; ```. While the function remains in SSA form, virtual register `%2` is sufficient to; identify the value computed by the instruction -- however the function; eventually leaves SSA form, and register optimisations will obscure which; register the desired value is in. Instead, a mo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md:893,Modifiability,variab,variable,893,"# Instruction referencing for debug info. This document explains how LLVM uses value tracking, or instruction; referencing, to determine variable locations for debug info in the code; generation stage of compilation. This content is aimed at those working on code; generation targets and optimisation passes. It may also be of interest to anyone; curious about low-level debug info handling. # Problem statement. At the end of compilation, LLVM must produce a DWARF location list (or similar); describing what register or stack location a variable can be found in, for each; instruction in that variable's lexical scope. We could track the virtual; register that the variable resides in through compilation, however this is; vulnerable to register optimisations during regalloc, and instruction; movements. # Solution: instruction referencing. Rather than identify the virtual register that a variable value resides in,; instead in instruction referencing mode, LLVM refers to the machine instruction; and operand position that the value is defined in. Consider the LLVM IR way of; referring to instruction values:. ```llvm; %2 = add i32 %0, %1; call void @llvm.dbg.value(metadata i32 %2,; ```. In LLVM IR, the IR Value is synonymous with the instruction that computes the; value, to the extent that in memory a Value is a pointer to the computing; instruction. Instruction referencing implements this relationship in the; codegen backend of LLVM, after instruction selection. Consider the X86 assembly; below and instruction referencing debug info, corresponding to the earlier; LLVM IR:. ```text; %2:gr32 = ADD32rr %0, %1, implicit-def $eflags, debug-instr-number 1; DBG_INSTR_REF 1, 0, !123, !456, debug-location !789; ```. While the function remains in SSA form, virtual register `%2` is sufficient to; identify the value computed by the instruction -- however the function; eventually leaves SSA form, and register optimisations will obscure which; register the desired value is in. Instead, a mo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md:2410,Modifiability,coupling,coupling,2410,"low and instruction referencing debug info, corresponding to the earlier; LLVM IR:. ```text; %2:gr32 = ADD32rr %0, %1, implicit-def $eflags, debug-instr-number 1; DBG_INSTR_REF 1, 0, !123, !456, debug-location !789; ```. While the function remains in SSA form, virtual register `%2` is sufficient to; identify the value computed by the instruction -- however the function; eventually leaves SSA form, and register optimisations will obscure which; register the desired value is in. Instead, a more consistent way of identifying; the instruction's value is to refer to the `MachineOperand` where the value is; defined: independently of which register is defined by that `MachineOperand`. In; the code above, the `DBG_INSTR_REF` instruction refers to instruction number; one, operand zero, while the `ADD32rr` has a `debug-instr-number` attribute; attached indicating that it is instruction number one. De-coupling variable locations from registers avoids difficulties involving; register allocation and optimisation, but requires additional instrumentation; when the instructions are optimised instead. Optimisations that replace; instructions with optimised versions that compute the same value must either; preserve the instruction number, or record a substitution from the old; instruction / operand number pair to the new instruction / operand pair -- see; `MachineFunction::substituteDebugValuesForInst`. If debug info maintenance is; not performed, or an instruction is eliminated as dead code, the variable; location is safely dropped and marked ""optimised out"". The exception is; instructions that are mutated rather than replaced, which always need debug info; maintenance. # Register allocator considerations. When the register allocator runs, debugging instructions do not directly refer; to any virtual registers, and thus there is no need for expensive location; maintenance during regalloc (i.e. `LiveDebugVariables`). Debug instructions are; unlinked from the function, then linked back ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md:2419,Modifiability,variab,variable,2419,"low and instruction referencing debug info, corresponding to the earlier; LLVM IR:. ```text; %2:gr32 = ADD32rr %0, %1, implicit-def $eflags, debug-instr-number 1; DBG_INSTR_REF 1, 0, !123, !456, debug-location !789; ```. While the function remains in SSA form, virtual register `%2` is sufficient to; identify the value computed by the instruction -- however the function; eventually leaves SSA form, and register optimisations will obscure which; register the desired value is in. Instead, a more consistent way of identifying; the instruction's value is to refer to the `MachineOperand` where the value is; defined: independently of which register is defined by that `MachineOperand`. In; the code above, the `DBG_INSTR_REF` instruction refers to instruction number; one, operand zero, while the `ADD32rr` has a `debug-instr-number` attribute; attached indicating that it is instruction number one. De-coupling variable locations from registers avoids difficulties involving; register allocation and optimisation, but requires additional instrumentation; when the instructions are optimised instead. Optimisations that replace; instructions with optimised versions that compute the same value must either; preserve the instruction number, or record a substitution from the old; instruction / operand number pair to the new instruction / operand pair -- see; `MachineFunction::substituteDebugValuesForInst`. If debug info maintenance is; not performed, or an instruction is eliminated as dead code, the variable; location is safely dropped and marked ""optimised out"". The exception is; instructions that are mutated rather than replaced, which always need debug info; maintenance. # Register allocator considerations. When the register allocator runs, debugging instructions do not directly refer; to any virtual registers, and thus there is no need for expensive location; maintenance during regalloc (i.e. `LiveDebugVariables`). Debug instructions are; unlinked from the function, then linked back ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md:3010,Modifiability,variab,variable,3010,"d, a more consistent way of identifying; the instruction's value is to refer to the `MachineOperand` where the value is; defined: independently of which register is defined by that `MachineOperand`. In; the code above, the `DBG_INSTR_REF` instruction refers to instruction number; one, operand zero, while the `ADD32rr` has a `debug-instr-number` attribute; attached indicating that it is instruction number one. De-coupling variable locations from registers avoids difficulties involving; register allocation and optimisation, but requires additional instrumentation; when the instructions are optimised instead. Optimisations that replace; instructions with optimised versions that compute the same value must either; preserve the instruction number, or record a substitution from the old; instruction / operand number pair to the new instruction / operand pair -- see; `MachineFunction::substituteDebugValuesForInst`. If debug info maintenance is; not performed, or an instruction is eliminated as dead code, the variable; location is safely dropped and marked ""optimised out"". The exception is; instructions that are mutated rather than replaced, which always need debug info; maintenance. # Register allocator considerations. When the register allocator runs, debugging instructions do not directly refer; to any virtual registers, and thus there is no need for expensive location; maintenance during regalloc (i.e. `LiveDebugVariables`). Debug instructions are; unlinked from the function, then linked back in after register allocation; completes. The exception is `PHI` instructions: these become implicit definitions at; control flow merges once regalloc finishes, and any debug numbers attached to; `PHI` instructions are lost. To circumvent this, debug numbers of `PHI`s are; recorded at the start of register allocation (`phi-node-elimination`), then; `DBG_PHI` instructions are inserted after regalloc finishes. This requires some; maintenance of which register a variable is located in d",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md:3970,Modifiability,variab,variable,3970,", the variable; location is safely dropped and marked ""optimised out"". The exception is; instructions that are mutated rather than replaced, which always need debug info; maintenance. # Register allocator considerations. When the register allocator runs, debugging instructions do not directly refer; to any virtual registers, and thus there is no need for expensive location; maintenance during regalloc (i.e. `LiveDebugVariables`). Debug instructions are; unlinked from the function, then linked back in after register allocation; completes. The exception is `PHI` instructions: these become implicit definitions at; control flow merges once regalloc finishes, and any debug numbers attached to; `PHI` instructions are lost. To circumvent this, debug numbers of `PHI`s are; recorded at the start of register allocation (`phi-node-elimination`), then; `DBG_PHI` instructions are inserted after regalloc finishes. This requires some; maintenance of which register a variable is located in during regalloc, but at; single positions (block entry points) rather than ranges of instructions. An example, before regalloc:. ```text; bb.2:; %2 = PHI %1, %bb.0, %2, %bb.1, debug-instr-number 1; ```. After:. ```text; bb.2:; DBG_PHI $rax, 1; ```. # `LiveDebugValues`. After optimisations and code layout complete, information about variable; values must be translated into variable locations, i.e. registers and stack; slots. This is performed in the [`LiveDebugValues` pass][LiveDebugValues], where; the debug instructions and machine code are separated out into two independent; functions:; * One that assigns values to variable names,; * One that assigns values to machine registers and stack slots. LLVM's existing SSA tools are used to place `PHI`s for each function, between; variable values and the values contained in machine locations, with value; propagation eliminating any unnecessary `PHI`s. The two can then be joined up; to map variables to values, then values to locations, for each instructio",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md:4327,Modifiability,variab,variable,4327,"ers, and thus there is no need for expensive location; maintenance during regalloc (i.e. `LiveDebugVariables`). Debug instructions are; unlinked from the function, then linked back in after register allocation; completes. The exception is `PHI` instructions: these become implicit definitions at; control flow merges once regalloc finishes, and any debug numbers attached to; `PHI` instructions are lost. To circumvent this, debug numbers of `PHI`s are; recorded at the start of register allocation (`phi-node-elimination`), then; `DBG_PHI` instructions are inserted after regalloc finishes. This requires some; maintenance of which register a variable is located in during regalloc, but at; single positions (block entry points) rather than ranges of instructions. An example, before regalloc:. ```text; bb.2:; %2 = PHI %1, %bb.0, %2, %bb.1, debug-instr-number 1; ```. After:. ```text; bb.2:; DBG_PHI $rax, 1; ```. # `LiveDebugValues`. After optimisations and code layout complete, information about variable; values must be translated into variable locations, i.e. registers and stack; slots. This is performed in the [`LiveDebugValues` pass][LiveDebugValues], where; the debug instructions and machine code are separated out into two independent; functions:; * One that assigns values to variable names,; * One that assigns values to machine registers and stack slots. LLVM's existing SSA tools are used to place `PHI`s for each function, between; variable values and the values contained in machine locations, with value; propagation eliminating any unnecessary `PHI`s. The two can then be joined up; to map variables to values, then values to locations, for each instruction in; the function. Key to this process is being able to identify the movement of values between; registers and stack locations, so that the location of values can be preserved; for the full time that they are resident in the machine. # Required target support and transition guide. Instruction referencing will work on an",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md:4368,Modifiability,variab,variable,4368,"ers, and thus there is no need for expensive location; maintenance during regalloc (i.e. `LiveDebugVariables`). Debug instructions are; unlinked from the function, then linked back in after register allocation; completes. The exception is `PHI` instructions: these become implicit definitions at; control flow merges once regalloc finishes, and any debug numbers attached to; `PHI` instructions are lost. To circumvent this, debug numbers of `PHI`s are; recorded at the start of register allocation (`phi-node-elimination`), then; `DBG_PHI` instructions are inserted after regalloc finishes. This requires some; maintenance of which register a variable is located in during regalloc, but at; single positions (block entry points) rather than ranges of instructions. An example, before regalloc:. ```text; bb.2:; %2 = PHI %1, %bb.0, %2, %bb.1, debug-instr-number 1; ```. After:. ```text; bb.2:; DBG_PHI $rax, 1; ```. # `LiveDebugValues`. After optimisations and code layout complete, information about variable; values must be translated into variable locations, i.e. registers and stack; slots. This is performed in the [`LiveDebugValues` pass][LiveDebugValues], where; the debug instructions and machine code are separated out into two independent; functions:; * One that assigns values to variable names,; * One that assigns values to machine registers and stack slots. LLVM's existing SSA tools are used to place `PHI`s for each function, between; variable values and the values contained in machine locations, with value; propagation eliminating any unnecessary `PHI`s. The two can then be joined up; to map variables to values, then values to locations, for each instruction in; the function. Key to this process is being able to identify the movement of values between; registers and stack locations, so that the location of values can be preserved; for the full time that they are resident in the machine. # Required target support and transition guide. Instruction referencing will work on an",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md:4617,Modifiability,variab,variable,4617,"ion is `PHI` instructions: these become implicit definitions at; control flow merges once regalloc finishes, and any debug numbers attached to; `PHI` instructions are lost. To circumvent this, debug numbers of `PHI`s are; recorded at the start of register allocation (`phi-node-elimination`), then; `DBG_PHI` instructions are inserted after regalloc finishes. This requires some; maintenance of which register a variable is located in during regalloc, but at; single positions (block entry points) rather than ranges of instructions. An example, before regalloc:. ```text; bb.2:; %2 = PHI %1, %bb.0, %2, %bb.1, debug-instr-number 1; ```. After:. ```text; bb.2:; DBG_PHI $rax, 1; ```. # `LiveDebugValues`. After optimisations and code layout complete, information about variable; values must be translated into variable locations, i.e. registers and stack; slots. This is performed in the [`LiveDebugValues` pass][LiveDebugValues], where; the debug instructions and machine code are separated out into two independent; functions:; * One that assigns values to variable names,; * One that assigns values to machine registers and stack slots. LLVM's existing SSA tools are used to place `PHI`s for each function, between; variable values and the values contained in machine locations, with value; propagation eliminating any unnecessary `PHI`s. The two can then be joined up; to map variables to values, then values to locations, for each instruction in; the function. Key to this process is being able to identify the movement of values between; registers and stack locations, so that the location of values can be preserved; for the full time that they are resident in the machine. # Required target support and transition guide. Instruction referencing will work on any target, but likely with poor coverage.; Supporting instruction referencing well requires:; * Target hooks to be implemented to allow `LiveDebugValues` to follow values; through the machine,; * Target-specific optimisations to be in",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md:4777,Modifiability,variab,variable,4777,"art of register allocation (`phi-node-elimination`), then; `DBG_PHI` instructions are inserted after regalloc finishes. This requires some; maintenance of which register a variable is located in during regalloc, but at; single positions (block entry points) rather than ranges of instructions. An example, before regalloc:. ```text; bb.2:; %2 = PHI %1, %bb.0, %2, %bb.1, debug-instr-number 1; ```. After:. ```text; bb.2:; DBG_PHI $rax, 1; ```. # `LiveDebugValues`. After optimisations and code layout complete, information about variable; values must be translated into variable locations, i.e. registers and stack; slots. This is performed in the [`LiveDebugValues` pass][LiveDebugValues], where; the debug instructions and machine code are separated out into two independent; functions:; * One that assigns values to variable names,; * One that assigns values to machine registers and stack slots. LLVM's existing SSA tools are used to place `PHI`s for each function, between; variable values and the values contained in machine locations, with value; propagation eliminating any unnecessary `PHI`s. The two can then be joined up; to map variables to values, then values to locations, for each instruction in; the function. Key to this process is being able to identify the movement of values between; registers and stack locations, so that the location of values can be preserved; for the full time that they are resident in the machine. # Required target support and transition guide. Instruction referencing will work on any target, but likely with poor coverage.; Supporting instruction referencing well requires:; * Target hooks to be implemented to allow `LiveDebugValues` to follow values; through the machine,; * Target-specific optimisations to be instrumented, to preserve instruction; numbers. ## Target hooks. `TargetInstrInfo::isCopyInstrImpl` must be implemented to recognise any; instructions that are copy-like -- `LiveDebugValues` uses this to identify when; values move between re",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md:4938,Modifiability,variab,variables,4938,"gister a variable is located in during regalloc, but at; single positions (block entry points) rather than ranges of instructions. An example, before regalloc:. ```text; bb.2:; %2 = PHI %1, %bb.0, %2, %bb.1, debug-instr-number 1; ```. After:. ```text; bb.2:; DBG_PHI $rax, 1; ```. # `LiveDebugValues`. After optimisations and code layout complete, information about variable; values must be translated into variable locations, i.e. registers and stack; slots. This is performed in the [`LiveDebugValues` pass][LiveDebugValues], where; the debug instructions and machine code are separated out into two independent; functions:; * One that assigns values to variable names,; * One that assigns values to machine registers and stack slots. LLVM's existing SSA tools are used to place `PHI`s for each function, between; variable values and the values contained in machine locations, with value; propagation eliminating any unnecessary `PHI`s. The two can then be joined up; to map variables to values, then values to locations, for each instruction in; the function. Key to this process is being able to identify the movement of values between; registers and stack locations, so that the location of values can be preserved; for the full time that they are resident in the machine. # Required target support and transition guide. Instruction referencing will work on any target, but likely with poor coverage.; Supporting instruction referencing well requires:; * Target hooks to be implemented to allow `LiveDebugValues` to follow values; through the machine,; * Target-specific optimisations to be instrumented, to preserve instruction; numbers. ## Target hooks. `TargetInstrInfo::isCopyInstrImpl` must be implemented to recognise any; instructions that are copy-like -- `LiveDebugValues` uses this to identify when; values move between registers. `TargetInstrInfo::isLoadFromStackSlotPostFE` and; `TargetInstrInfo::isStoreToStackSlotPostFE` are needed to identify spill and; restore instructions. Each",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md:6837,Modifiability,variab,variable,6837,"sters. `TargetInstrInfo::isLoadFromStackSlotPostFE` and; `TargetInstrInfo::isStoreToStackSlotPostFE` are needed to identify spill and; restore instructions. Each should return the destination or source register; respectively. `LiveDebugValues` will track the movement of a value from / to; the stack slot. In addition, any instruction that writes to a stack spill; should have a `MachineMemoryOperand` attached, so that `LiveDebugValues` can; recognise that a slot has been clobbered. ## Target-specific optimisation instrumentation. Optimisations come in two flavours: those that mutate a `MachineInstr` to make; it do something different, and those that create a new instruction to replace; the operation of the old. The former _must_ be instrumented -- the relevant question is whether any; register def in any operand will produce a different value, as a result of the; mutation. If the answer is yes, then there is a risk that a `DBG_INSTR_REF`; instruction referring to that operand will end up assigning the different; value to a variable, presenting the debugging developer with an unexpected; variable value. In such scenarios, call `MachineInstr::dropDebugNumber()` on the; mutated instruction to erase its instruction number. Any `DBG_INSTR_REF`; referring to it will produce an empty variable location instead, that appears; as ""optimised out"" in the debugger. For the latter flavour of optimisation, to increase coverage you should record; an instruction number substitution: a mapping from the old instruction number /; operand pair to new instruction number / operand pair. Consider if we replace; a three-address add instruction with a two-address add:. ```text; %2:gr32 = ADD32rr %0, %1, debug-instr-number 1; ```. becomes. ```text; %2:gr32 = ADD32rr %0(tied-def 0), %1, debug-instr-number 2; ```. With a substitution from ""instruction number 1 operand 0"" to ""instruction number; 2 operand 0"" recorded in the `MachineFunction`. In `LiveDebugValues`,; `DBG_INSTR_REF`s will be mapped ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md:6902,Modifiability,variab,variable,6902,"sters. `TargetInstrInfo::isLoadFromStackSlotPostFE` and; `TargetInstrInfo::isStoreToStackSlotPostFE` are needed to identify spill and; restore instructions. Each should return the destination or source register; respectively. `LiveDebugValues` will track the movement of a value from / to; the stack slot. In addition, any instruction that writes to a stack spill; should have a `MachineMemoryOperand` attached, so that `LiveDebugValues` can; recognise that a slot has been clobbered. ## Target-specific optimisation instrumentation. Optimisations come in two flavours: those that mutate a `MachineInstr` to make; it do something different, and those that create a new instruction to replace; the operation of the old. The former _must_ be instrumented -- the relevant question is whether any; register def in any operand will produce a different value, as a result of the; mutation. If the answer is yes, then there is a risk that a `DBG_INSTR_REF`; instruction referring to that operand will end up assigning the different; value to a variable, presenting the debugging developer with an unexpected; variable value. In such scenarios, call `MachineInstr::dropDebugNumber()` on the; mutated instruction to erase its instruction number. Any `DBG_INSTR_REF`; referring to it will produce an empty variable location instead, that appears; as ""optimised out"" in the debugger. For the latter flavour of optimisation, to increase coverage you should record; an instruction number substitution: a mapping from the old instruction number /; operand pair to new instruction number / operand pair. Consider if we replace; a three-address add instruction with a two-address add:. ```text; %2:gr32 = ADD32rr %0, %1, debug-instr-number 1; ```. becomes. ```text; %2:gr32 = ADD32rr %0(tied-def 0), %1, debug-instr-number 2; ```. With a substitution from ""instruction number 1 operand 0"" to ""instruction number; 2 operand 0"" recorded in the `MachineFunction`. In `LiveDebugValues`,; `DBG_INSTR_REF`s will be mapped ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md:7096,Modifiability,variab,variable,7096,". In addition, any instruction that writes to a stack spill; should have a `MachineMemoryOperand` attached, so that `LiveDebugValues` can; recognise that a slot has been clobbered. ## Target-specific optimisation instrumentation. Optimisations come in two flavours: those that mutate a `MachineInstr` to make; it do something different, and those that create a new instruction to replace; the operation of the old. The former _must_ be instrumented -- the relevant question is whether any; register def in any operand will produce a different value, as a result of the; mutation. If the answer is yes, then there is a risk that a `DBG_INSTR_REF`; instruction referring to that operand will end up assigning the different; value to a variable, presenting the debugging developer with an unexpected; variable value. In such scenarios, call `MachineInstr::dropDebugNumber()` on the; mutated instruction to erase its instruction number. Any `DBG_INSTR_REF`; referring to it will produce an empty variable location instead, that appears; as ""optimised out"" in the debugger. For the latter flavour of optimisation, to increase coverage you should record; an instruction number substitution: a mapping from the old instruction number /; operand pair to new instruction number / operand pair. Consider if we replace; a three-address add instruction with a two-address add:. ```text; %2:gr32 = ADD32rr %0, %1, debug-instr-number 1; ```. becomes. ```text; %2:gr32 = ADD32rr %0(tied-def 0), %1, debug-instr-number 2; ```. With a substitution from ""instruction number 1 operand 0"" to ""instruction number; 2 operand 0"" recorded in the `MachineFunction`. In `LiveDebugValues`,; `DBG_INSTR_REF`s will be mapped through the substitution table to find the most; recent instruction number / operand number of the value it refers to. Use `MachineFunction::substituteDebugValuesForInst` to automatically produce; substitutions between an old and new instruction. It assumes that any operand; that is a def in the old ins",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md:8722,Modifiability,variab,variable,8722,"g from the old instruction number /; operand pair to new instruction number / operand pair. Consider if we replace; a three-address add instruction with a two-address add:. ```text; %2:gr32 = ADD32rr %0, %1, debug-instr-number 1; ```. becomes. ```text; %2:gr32 = ADD32rr %0(tied-def 0), %1, debug-instr-number 2; ```. With a substitution from ""instruction number 1 operand 0"" to ""instruction number; 2 operand 0"" recorded in the `MachineFunction`. In `LiveDebugValues`,; `DBG_INSTR_REF`s will be mapped through the substitution table to find the most; recent instruction number / operand number of the value it refers to. Use `MachineFunction::substituteDebugValuesForInst` to automatically produce; substitutions between an old and new instruction. It assumes that any operand; that is a def in the old instruction is a def in the new instruction at the; same operand position. This works most of the time, for example in the example; above. If operand numbers do not line up between the old and new instruction, use; `MachineInstr::getDebugInstrNum` to acquire the instruction number for the new; instruction, and `MachineFunction::makeDebugValueSubstitution` to record the; mapping between register definitions in the old and new instructions. If some; values computed by the old instruction are no longer computed by the new; instruction, record no substitution -- `LiveDebugValues` will safely drop the; now unavailable variable value. Should your target clone instructions, much the same as the `TailDuplicator`; optimisation pass, do not attempt to preserve the instruction numbers or; record any substitutions. `MachineFunction::CloneMachineInstr` should drop the; instruction number of any cloned instruction, to avoid duplicate numbers; appearing to `LiveDebugValues`. Dealing with duplicated instructions is a; natural extension to instruction referencing that's currently unimplemented. [LiveDebugValues]: project:SourceLevelDebugging.rst#LiveDebugValues expansion of variable locations; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md:9277,Modifiability,variab,variable,9277,"g from the old instruction number /; operand pair to new instruction number / operand pair. Consider if we replace; a three-address add instruction with a two-address add:. ```text; %2:gr32 = ADD32rr %0, %1, debug-instr-number 1; ```. becomes. ```text; %2:gr32 = ADD32rr %0(tied-def 0), %1, debug-instr-number 2; ```. With a substitution from ""instruction number 1 operand 0"" to ""instruction number; 2 operand 0"" recorded in the `MachineFunction`. In `LiveDebugValues`,; `DBG_INSTR_REF`s will be mapped through the substitution table to find the most; recent instruction number / operand number of the value it refers to. Use `MachineFunction::substituteDebugValuesForInst` to automatically produce; substitutions between an old and new instruction. It assumes that any operand; that is a def in the old instruction is a def in the new instruction at the; same operand position. This works most of the time, for example in the example; above. If operand numbers do not line up between the old and new instruction, use; `MachineInstr::getDebugInstrNum` to acquire the instruction number for the new; instruction, and `MachineFunction::makeDebugValueSubstitution` to record the; mapping between register definitions in the old and new instructions. If some; values computed by the old instruction are no longer computed by the new; instruction, record no substitution -- `LiveDebugValues` will safely drop the; now unavailable variable value. Should your target clone instructions, much the same as the `TailDuplicator`; optimisation pass, do not attempt to preserve the instruction numbers or; record any substitutions. `MachineFunction::CloneMachineInstr` should drop the; instruction number of any cloned instruction, to avoid duplicate numbers; appearing to `LiveDebugValues`. Dealing with duplicated instructions is a; natural extension to instruction referencing that's currently unimplemented. [LiveDebugValues]: project:SourceLevelDebugging.rst#LiveDebugValues expansion of variable locations; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md:2949,Performance,perform,performed,2949,"d, a more consistent way of identifying; the instruction's value is to refer to the `MachineOperand` where the value is; defined: independently of which register is defined by that `MachineOperand`. In; the code above, the `DBG_INSTR_REF` instruction refers to instruction number; one, operand zero, while the `ADD32rr` has a `debug-instr-number` attribute; attached indicating that it is instruction number one. De-coupling variable locations from registers avoids difficulties involving; register allocation and optimisation, but requires additional instrumentation; when the instructions are optimised instead. Optimisations that replace; instructions with optimised versions that compute the same value must either; preserve the instruction number, or record a substitution from the old; instruction / operand number pair to the new instruction / operand pair -- see; `MachineFunction::substituteDebugValuesForInst`. If debug info maintenance is; not performed, or an instruction is eliminated as dead code, the variable; location is safely dropped and marked ""optimised out"". The exception is; instructions that are mutated rather than replaced, which always need debug info; maintenance. # Register allocator considerations. When the register allocator runs, debugging instructions do not directly refer; to any virtual registers, and thus there is no need for expensive location; maintenance during regalloc (i.e. `LiveDebugVariables`). Debug instructions are; unlinked from the function, then linked back in after register allocation; completes. The exception is `PHI` instructions: these become implicit definitions at; control flow merges once regalloc finishes, and any debug numbers attached to; `PHI` instructions are lost. To circumvent this, debug numbers of `PHI`s are; recorded at the start of register allocation (`phi-node-elimination`), then; `DBG_PHI` instructions are inserted after regalloc finishes. This requires some; maintenance of which register a variable is located in d",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md:4429,Performance,perform,performed,4429,"ion is `PHI` instructions: these become implicit definitions at; control flow merges once regalloc finishes, and any debug numbers attached to; `PHI` instructions are lost. To circumvent this, debug numbers of `PHI`s are; recorded at the start of register allocation (`phi-node-elimination`), then; `DBG_PHI` instructions are inserted after regalloc finishes. This requires some; maintenance of which register a variable is located in during regalloc, but at; single positions (block entry points) rather than ranges of instructions. An example, before regalloc:. ```text; bb.2:; %2 = PHI %1, %bb.0, %2, %bb.1, debug-instr-number 1; ```. After:. ```text; bb.2:; DBG_PHI $rax, 1; ```. # `LiveDebugValues`. After optimisations and code layout complete, information about variable; values must be translated into variable locations, i.e. registers and stack; slots. This is performed in the [`LiveDebugValues` pass][LiveDebugValues], where; the debug instructions and machine code are separated out into two independent; functions:; * One that assigns values to variable names,; * One that assigns values to machine registers and stack slots. LLVM's existing SSA tools are used to place `PHI`s for each function, between; variable values and the values contained in machine locations, with value; propagation eliminating any unnecessary `PHI`s. The two can then be joined up; to map variables to values, then values to locations, for each instruction in; the function. Key to this process is being able to identify the movement of values between; registers and stack locations, so that the location of values can be preserved; for the full time that they are resident in the machine. # Required target support and transition guide. Instruction referencing will work on any target, but likely with poor coverage.; Supporting instruction referencing well requires:; * Target hooks to be implemented to allow `LiveDebugValues` to follow values; through the machine,; * Target-specific optimisations to be in",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md:2453,Safety,avoid,avoids,2453,"low and instruction referencing debug info, corresponding to the earlier; LLVM IR:. ```text; %2:gr32 = ADD32rr %0, %1, implicit-def $eflags, debug-instr-number 1; DBG_INSTR_REF 1, 0, !123, !456, debug-location !789; ```. While the function remains in SSA form, virtual register `%2` is sufficient to; identify the value computed by the instruction -- however the function; eventually leaves SSA form, and register optimisations will obscure which; register the desired value is in. Instead, a more consistent way of identifying; the instruction's value is to refer to the `MachineOperand` where the value is; defined: independently of which register is defined by that `MachineOperand`. In; the code above, the `DBG_INSTR_REF` instruction refers to instruction number; one, operand zero, while the `ADD32rr` has a `debug-instr-number` attribute; attached indicating that it is instruction number one. De-coupling variable locations from registers avoids difficulties involving; register allocation and optimisation, but requires additional instrumentation; when the instructions are optimised instead. Optimisations that replace; instructions with optimised versions that compute the same value must either; preserve the instruction number, or record a substitution from the old; instruction / operand number pair to the new instruction / operand pair -- see; `MachineFunction::substituteDebugValuesForInst`. If debug info maintenance is; not performed, or an instruction is eliminated as dead code, the variable; location is safely dropped and marked ""optimised out"". The exception is; instructions that are mutated rather than replaced, which always need debug info; maintenance. # Register allocator considerations. When the register allocator runs, debugging instructions do not directly refer; to any virtual registers, and thus there is no need for expensive location; maintenance during regalloc (i.e. `LiveDebugVariables`). Debug instructions are; unlinked from the function, then linked back ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md:3032,Safety,safe,safely,3032,"d, a more consistent way of identifying; the instruction's value is to refer to the `MachineOperand` where the value is; defined: independently of which register is defined by that `MachineOperand`. In; the code above, the `DBG_INSTR_REF` instruction refers to instruction number; one, operand zero, while the `ADD32rr` has a `debug-instr-number` attribute; attached indicating that it is instruction number one. De-coupling variable locations from registers avoids difficulties involving; register allocation and optimisation, but requires additional instrumentation; when the instructions are optimised instead. Optimisations that replace; instructions with optimised versions that compute the same value must either; preserve the instruction number, or record a substitution from the old; instruction / operand number pair to the new instruction / operand pair -- see; `MachineFunction::substituteDebugValuesForInst`. If debug info maintenance is; not performed, or an instruction is eliminated as dead code, the variable; location is safely dropped and marked ""optimised out"". The exception is; instructions that are mutated rather than replaced, which always need debug info; maintenance. # Register allocator considerations. When the register allocator runs, debugging instructions do not directly refer; to any virtual registers, and thus there is no need for expensive location; maintenance during regalloc (i.e. `LiveDebugVariables`). Debug instructions are; unlinked from the function, then linked back in after register allocation; completes. The exception is `PHI` instructions: these become implicit definitions at; control flow merges once regalloc finishes, and any debug numbers attached to; `PHI` instructions are lost. To circumvent this, debug numbers of `PHI`s are; recorded at the start of register allocation (`phi-node-elimination`), then; `DBG_PHI` instructions are inserted after regalloc finishes. This requires some; maintenance of which register a variable is located in d",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md:6722,Safety,risk,risk,6722,"sters. `TargetInstrInfo::isLoadFromStackSlotPostFE` and; `TargetInstrInfo::isStoreToStackSlotPostFE` are needed to identify spill and; restore instructions. Each should return the destination or source register; respectively. `LiveDebugValues` will track the movement of a value from / to; the stack slot. In addition, any instruction that writes to a stack spill; should have a `MachineMemoryOperand` attached, so that `LiveDebugValues` can; recognise that a slot has been clobbered. ## Target-specific optimisation instrumentation. Optimisations come in two flavours: those that mutate a `MachineInstr` to make; it do something different, and those that create a new instruction to replace; the operation of the old. The former _must_ be instrumented -- the relevant question is whether any; register def in any operand will produce a different value, as a result of the; mutation. If the answer is yes, then there is a risk that a `DBG_INSTR_REF`; instruction referring to that operand will end up assigning the different; value to a variable, presenting the debugging developer with an unexpected; variable value. In such scenarios, call `MachineInstr::dropDebugNumber()` on the; mutated instruction to erase its instruction number. Any `DBG_INSTR_REF`; referring to it will produce an empty variable location instead, that appears; as ""optimised out"" in the debugger. For the latter flavour of optimisation, to increase coverage you should record; an instruction number substitution: a mapping from the old instruction number /; operand pair to new instruction number / operand pair. Consider if we replace; a three-address add instruction with a two-address add:. ```text; %2:gr32 = ADD32rr %0, %1, debug-instr-number 1; ```. becomes. ```text; %2:gr32 = ADD32rr %0(tied-def 0), %1, debug-instr-number 2; ```. With a substitution from ""instruction number 1 operand 0"" to ""instruction number; 2 operand 0"" recorded in the `MachineFunction`. In `LiveDebugValues`,; `DBG_INSTR_REF`s will be mapped ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md:8689,Safety,safe,safely,8689,"g from the old instruction number /; operand pair to new instruction number / operand pair. Consider if we replace; a three-address add instruction with a two-address add:. ```text; %2:gr32 = ADD32rr %0, %1, debug-instr-number 1; ```. becomes. ```text; %2:gr32 = ADD32rr %0(tied-def 0), %1, debug-instr-number 2; ```. With a substitution from ""instruction number 1 operand 0"" to ""instruction number; 2 operand 0"" recorded in the `MachineFunction`. In `LiveDebugValues`,; `DBG_INSTR_REF`s will be mapped through the substitution table to find the most; recent instruction number / operand number of the value it refers to. Use `MachineFunction::substituteDebugValuesForInst` to automatically produce; substitutions between an old and new instruction. It assumes that any operand; that is a def in the old instruction is a def in the new instruction at the; same operand position. This works most of the time, for example in the example; above. If operand numbers do not line up between the old and new instruction, use; `MachineInstr::getDebugInstrNum` to acquire the instruction number for the new; instruction, and `MachineFunction::makeDebugValueSubstitution` to record the; mapping between register definitions in the old and new instructions. If some; values computed by the old instruction are no longer computed by the new; instruction, record no substitution -- `LiveDebugValues` will safely drop the; now unavailable variable value. Should your target clone instructions, much the same as the `TailDuplicator`; optimisation pass, do not attempt to preserve the instruction numbers or; record any substitutions. `MachineFunction::CloneMachineInstr` should drop the; instruction number of any cloned instruction, to avoid duplicate numbers; appearing to `LiveDebugValues`. Dealing with duplicated instructions is a; natural extension to instruction referencing that's currently unimplemented. [LiveDebugValues]: project:SourceLevelDebugging.rst#LiveDebugValues expansion of variable locations; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md:9019,Safety,avoid,avoid,9019,"g from the old instruction number /; operand pair to new instruction number / operand pair. Consider if we replace; a three-address add instruction with a two-address add:. ```text; %2:gr32 = ADD32rr %0, %1, debug-instr-number 1; ```. becomes. ```text; %2:gr32 = ADD32rr %0(tied-def 0), %1, debug-instr-number 2; ```. With a substitution from ""instruction number 1 operand 0"" to ""instruction number; 2 operand 0"" recorded in the `MachineFunction`. In `LiveDebugValues`,; `DBG_INSTR_REF`s will be mapped through the substitution table to find the most; recent instruction number / operand number of the value it refers to. Use `MachineFunction::substituteDebugValuesForInst` to automatically produce; substitutions between an old and new instruction. It assumes that any operand; that is a def in the old instruction is a def in the new instruction at the; same operand position. This works most of the time, for example in the example; above. If operand numbers do not line up between the old and new instruction, use; `MachineInstr::getDebugInstrNum` to acquire the instruction number for the new; instruction, and `MachineFunction::makeDebugValueSubstitution` to record the; mapping between register definitions in the old and new instructions. If some; values computed by the old instruction are no longer computed by the new; instruction, record no substitution -- `LiveDebugValues` will safely drop the; now unavailable variable value. Should your target clone instructions, much the same as the `TailDuplicator`; optimisation pass, do not attempt to preserve the instruction numbers or; record any substitutions. `MachineFunction::CloneMachineInstr` should drop the; instruction number of any cloned instruction, to avoid duplicate numbers; appearing to `LiveDebugValues`. Dealing with duplicated instructions is a; natural extension to instruction referencing that's currently unimplemented. [LiveDebugValues]: project:SourceLevelDebugging.rst#LiveDebugValues expansion of variable locations; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md:5280,Usability,guid,guide,5280," After optimisations and code layout complete, information about variable; values must be translated into variable locations, i.e. registers and stack; slots. This is performed in the [`LiveDebugValues` pass][LiveDebugValues], where; the debug instructions and machine code are separated out into two independent; functions:; * One that assigns values to variable names,; * One that assigns values to machine registers and stack slots. LLVM's existing SSA tools are used to place `PHI`s for each function, between; variable values and the values contained in machine locations, with value; propagation eliminating any unnecessary `PHI`s. The two can then be joined up; to map variables to values, then values to locations, for each instruction in; the function. Key to this process is being able to identify the movement of values between; registers and stack locations, so that the location of values can be preserved; for the full time that they are resident in the machine. # Required target support and transition guide. Instruction referencing will work on any target, but likely with poor coverage.; Supporting instruction referencing well requires:; * Target hooks to be implemented to allow `LiveDebugValues` to follow values; through the machine,; * Target-specific optimisations to be instrumented, to preserve instruction; numbers. ## Target hooks. `TargetInstrInfo::isCopyInstrImpl` must be implemented to recognise any; instructions that are copy-like -- `LiveDebugValues` uses this to identify when; values move between registers. `TargetInstrInfo::isLoadFromStackSlotPostFE` and; `TargetInstrInfo::isStoreToStackSlotPostFE` are needed to identify spill and; restore instructions. Each should return the destination or source register; respectively. `LiveDebugValues` will track the movement of a value from / to; the stack slot. In addition, any instruction that writes to a stack spill; should have a `MachineMemoryOperand` attached, so that `LiveDebugValues` can; recognise that a sl",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MarkdownQuickstartTemplate.md:3364,Availability,echo,echo,3364,"se blank lines to separate paragraphs. Headings (like `Example Section` just above) give your document its; structure. ### Example Subsection. Make a link [like this](https://llvm.org/). There is also a more; sophisticated syntax which [can be more readable] for longer links since; it disrupts the flow less. You can put the `[link name]: <URL>` block; pretty much anywhere later in the document. [can be more readable]: http://en.wikipedia.org/wiki/LLVM. Lists can be made like this:. 1. A list starting with `[0-9].` will be automatically numbered. 1. This is a second list element. 1. Use indentation to create nested lists. You can also use unordered lists. * Stuff. + Deeper stuff. * More stuff. #### Example Subsubsection. You can make blocks of code like this:. ```; int main() {; return 0;; }; ```. As an extension to markdown, you can also specify a highlighter to use. ``` C++; int main() {; return 0;; }; ```. For a shell session, use a `console` code block. ```console; $ echo ""Goodbye cruel world!""; $ rm -rf /; ```. If you need to show LLVM IR use the `llvm` code block. ``` llvm; define i32 @test1() {; entry:; ret i32 0; }; ```. Some other common code blocks you might need are `c`, `objc`, `make`,; and `cmake`. If you need something beyond that, you can look at the [full; list] of supported code blocks. [full list]: http://pygments.org/docs/lexers/. However, don't waste time fiddling with syntax highlighting when you could; be adding meaningful content. When in doubt, show preformatted text; without any syntax highlighting like this:. .; +:.; ..:: ::; .++:+:: ::+:.:.; .:+ :; ::.::..:: .+.; ..:+ :: :; ......+:. ..; :++. .. :; .+:::+:: :; .. . .+ ::; +.: .::+.; ...+. .: .; .++:..; ... ##### Hopefully you won't need to be this deep. If you need to do fancier things than what has been shown in this document,; you can mail the list or check the [Common Mark spec]. Sphinx specific; integration documentation can be found in the [myst-parser docs]. [Common Mark spec]: http:/",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/MarkdownQuickstartTemplate.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MarkdownQuickstartTemplate.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MarkdownQuickstartTemplate.md:4287,Deployability,integrat,integration,4287," which [can be more readable] for longer links since; it disrupts the flow less. You can put the `[link name]: <URL>` block; pretty much anywhere later in the document. [can be more readable]: http://en.wikipedia.org/wiki/LLVM. Lists can be made like this:. 1. A list starting with `[0-9].` will be automatically numbered. 1. This is a second list element. 1. Use indentation to create nested lists. You can also use unordered lists. * Stuff. + Deeper stuff. * More stuff. #### Example Subsubsection. You can make blocks of code like this:. ```; int main() {; return 0;; }; ```. As an extension to markdown, you can also specify a highlighter to use. ``` C++; int main() {; return 0;; }; ```. For a shell session, use a `console` code block. ```console; $ echo ""Goodbye cruel world!""; $ rm -rf /; ```. If you need to show LLVM IR use the `llvm` code block. ``` llvm; define i32 @test1() {; entry:; ret i32 0; }; ```. Some other common code blocks you might need are `c`, `objc`, `make`,; and `cmake`. If you need something beyond that, you can look at the [full; list] of supported code blocks. [full list]: http://pygments.org/docs/lexers/. However, don't waste time fiddling with syntax highlighting when you could; be adding meaningful content. When in doubt, show preformatted text; without any syntax highlighting like this:. .; +:.; ..:: ::; .++:+:: ::+:.:.; .:+ :; ::.::..:: .+.; ..:+ :: :; ......+:. ..; :++. .. :; .+:::+:: :; .. . .+ ::; +.: .::+.; ...+. .: .; .++:..; ... ##### Hopefully you won't need to be this deep. If you need to do fancier things than what has been shown in this document,; you can mail the list or check the [Common Mark spec]. Sphinx specific; integration documentation can be found in the [myst-parser docs]. [Common Mark spec]: http://spec.commonmark.org/0.28/; [myst-parser docs]: https://myst-parser.readthedocs.io/en/latest/. ## Generating the documentation. see [Sphinx Quickstart Template](project:SphinxQuickstartTemplate.rst#Generating the documentation); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/MarkdownQuickstartTemplate.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MarkdownQuickstartTemplate.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MarkdownQuickstartTemplate.md:4287,Integrability,integrat,integration,4287," which [can be more readable] for longer links since; it disrupts the flow less. You can put the `[link name]: <URL>` block; pretty much anywhere later in the document. [can be more readable]: http://en.wikipedia.org/wiki/LLVM. Lists can be made like this:. 1. A list starting with `[0-9].` will be automatically numbered. 1. This is a second list element. 1. Use indentation to create nested lists. You can also use unordered lists. * Stuff. + Deeper stuff. * More stuff. #### Example Subsubsection. You can make blocks of code like this:. ```; int main() {; return 0;; }; ```. As an extension to markdown, you can also specify a highlighter to use. ``` C++; int main() {; return 0;; }; ```. For a shell session, use a `console` code block. ```console; $ echo ""Goodbye cruel world!""; $ rm -rf /; ```. If you need to show LLVM IR use the `llvm` code block. ``` llvm; define i32 @test1() {; entry:; ret i32 0; }; ```. Some other common code blocks you might need are `c`, `objc`, `make`,; and `cmake`. If you need something beyond that, you can look at the [full; list] of supported code blocks. [full list]: http://pygments.org/docs/lexers/. However, don't waste time fiddling with syntax highlighting when you could; be adding meaningful content. When in doubt, show preformatted text; without any syntax highlighting like this:. .; +:.; ..:: ::; .++:+:: ::+:.:.; .:+ :; ::.::..:: .+.; ..:+ :: :; ......+:. ..; :++. .. :; .+:::+:: :; .. . .+ ::; +.: .::+.; ...+. .: .; .++:..; ... ##### Hopefully you won't need to be this deep. If you need to do fancier things than what has been shown in this document,; you can mail the list or check the [Common Mark spec]. Sphinx specific; integration documentation can be found in the [myst-parser docs]. [Common Mark spec]: http://spec.commonmark.org/0.28/; [myst-parser docs]: https://myst-parser.readthedocs.io/en/latest/. ## Generating the documentation. see [Sphinx Quickstart Template](project:SphinxQuickstartTemplate.rst#Generating the documentation); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/MarkdownQuickstartTemplate.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MarkdownQuickstartTemplate.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MarkdownQuickstartTemplate.md:1445,Usability,learn,learned,1445,"ckstartTemplate.md`. You; should copy it, open the new file in your text editor, write your docs, and; then send the new document to llvm-commits for review. Focus on *content*. It is easy to fix the Markdown syntax; later if necessary, although Markdown tries to imitate common; plain-text conventions so it should be quite natural. A basic knowledge of; Markdown syntax is useful when writing the document, so the last; ~half of this document (starting with [Example Section](#example-section)) gives examples; which should cover 99% of use cases. Let me say that again: focus on *content*. But if you really need to verify; Sphinx's output, see `docs/README.txt` for information. Once you have finished with the content, please send the `.md` file to; llvm-commits for review. ## Guidelines. Try to answer the following questions in your first section:. 1. Why would I want to read this document?. 2. What should I know to be able to follow along with this document?. 3. What will I have learned by the end of this document?. Common names for the first section are `Introduction`, `Overview`, or; `Background`. If possible, make your document a ""how to"". Give it a name `HowTo*.md`; like the other ""how to"" documents. This format is usually the easiest; for another person to understand and also the most useful. You generally should not be writing documentation other than a ""how to""; unless there is already a ""how to"" about your topic. The reason for this; is that without a ""how to"" document to read first, it is difficult for a; person to understand a more advanced document. Focus on content (yes, I had to say it again). The rest of this document shows example Markdown markup constructs; that are meant to be read by you in your text editor after you have copied; this file into a new file for the documentation you are about to write. ## Example Section. Your text can be *emphasized*, **bold**, or `monospace`. Use blank lines to separate paragraphs. Headings (like `Example Section` just",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/MarkdownQuickstartTemplate.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MarkdownQuickstartTemplate.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PointerAuth.md:4632,Performance,perform,performs,4632,"ey that was used to generate `value`, the behavior is; target-specific. #### '`llvm.ptrauth.resign`'. ##### Syntax:. ```llvm; declare i64 @llvm.ptrauth.resign(i64 <value>,; i32 <old key>, i64 <old discriminator>,; i32 <new key>, i64 <new discriminator>); ```. ##### Overview:. The '`llvm.ptrauth.resign`' intrinsic re-signs a signed pointer using; a different key and diversity data. ##### Arguments:. The `value` argument is the signed pointer value to be authenticated.; The `old key` argument is the identifier of the key that was used to generate; the signed value.; The `old discriminator` argument is the additional diversity data to be used; as a discriminator in the auth operation.; The `new key` argument is the identifier of the key to use to generate the; resigned value.; The `new discriminator` argument is the additional diversity data to be used; as a discriminator in the sign operation. ##### Semantics:. The '`llvm.ptrauth.resign`' intrinsic performs a combined `auth`_ and `sign`_; operation, without exposing the intermediate raw pointer.; It returns a signed pointer value.; If `value` does not have a correct signature for `old key` and; `old discriminator`, the intrinsic traps in a target-specific way. #### '`llvm.ptrauth.sign_generic`'. ##### Syntax:. ```llvm; declare i64 @llvm.ptrauth.sign_generic(i64 <value>, i64 <discriminator>); ```. ##### Overview:. The '`llvm.ptrauth.sign_generic`' intrinsic computes a generic signature of; arbitrary data. ##### Arguments:. The `value` argument is the arbitrary data value to be signed.; The `discriminator` argument is the additional diversity data to be used as a; discriminator. ##### Semantics:. The '`llvm.ptrauth.sign_generic`' intrinsic computes the signature of a given; combination of value and additional diversity data. It returns a full signature value (as opposed to a signed pointer value, with; an embedded partial signature). As opposed to [`llvm.ptrauth.sign`](#llvm-ptrauth-sign), it does not interpret; `value` ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PointerAuth.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PointerAuth.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PointerAuth.md:164,Security,hash,hash,164,"# Pointer Authentication. ## Introduction. Pointer Authentication is a mechanism by which certain pointers are signed.; When a pointer gets signed, a cryptographic hash of its value and other values; (pepper and salt) is stored in unused bits of that pointer. Before the pointer is used, it needs to be authenticated, i.e., have its; signature checked. This prevents pointer values of unknown origin from being; used to replace the signed pointer value. At the IR level, it is represented using:. * a [set of intrinsics](#intrinsics) (to sign/authenticate pointers); * a [call operand bundle](#operand-bundle) (to authenticate called pointers). The current implementation leverages the; [Armv8.3-A PAuth/Pointer Authentication Code](#armv8-3-a-pauth-pointer-authentication-code); instructions in the [AArch64 backend](#aarch64-support).; This support is used to implement the Darwin arm64e ABI, as well as the; [PAuth ABI Extension to ELF](https://github.com/ARM-software/abi-aa/blob/main/pauthabielf64/pauthabielf64.rst). ## LLVM IR Representation. ### Intrinsics. These intrinsics are provided by LLVM to expose pointer authentication; operations. #### '`llvm.ptrauth.sign`'. ##### Syntax:. ```llvm; declare i64 @llvm.ptrauth.sign(i64 <value>, i32 <key>, i64 <discriminator>); ```. ##### Overview:. The '`llvm.ptrauth.sign`' intrinsic signs a raw pointer. ##### Arguments:. The `value` argument is the raw pointer value to be signed.; The `key` argument is the identifier of the key to be used to generate the; signed value.; The `discriminator` argument is the additional diversity data to be used as a; discriminator (an integer, an address, or a blend of the two). ##### Semantics:. The '`llvm.ptrauth.sign`' intrinsic implements the `sign`_ operation.; It returns a signed value. If `value` is already a signed value, the behavior is undefined. If `value` is not a pointer value for which `key` is appropriate, the; behavior is undefined. #### '`llvm.ptrauth.auth`'. ##### Syntax:. ```llvm; decl",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PointerAuth.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PointerAuth.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PointerAuth.md:303,Security,authenticat,authenticated,303,"# Pointer Authentication. ## Introduction. Pointer Authentication is a mechanism by which certain pointers are signed.; When a pointer gets signed, a cryptographic hash of its value and other values; (pepper and salt) is stored in unused bits of that pointer. Before the pointer is used, it needs to be authenticated, i.e., have its; signature checked. This prevents pointer values of unknown origin from being; used to replace the signed pointer value. At the IR level, it is represented using:. * a [set of intrinsics](#intrinsics) (to sign/authenticate pointers); * a [call operand bundle](#operand-bundle) (to authenticate called pointers). The current implementation leverages the; [Armv8.3-A PAuth/Pointer Authentication Code](#armv8-3-a-pauth-pointer-authentication-code); instructions in the [AArch64 backend](#aarch64-support).; This support is used to implement the Darwin arm64e ABI, as well as the; [PAuth ABI Extension to ELF](https://github.com/ARM-software/abi-aa/blob/main/pauthabielf64/pauthabielf64.rst). ## LLVM IR Representation. ### Intrinsics. These intrinsics are provided by LLVM to expose pointer authentication; operations. #### '`llvm.ptrauth.sign`'. ##### Syntax:. ```llvm; declare i64 @llvm.ptrauth.sign(i64 <value>, i32 <key>, i64 <discriminator>); ```. ##### Overview:. The '`llvm.ptrauth.sign`' intrinsic signs a raw pointer. ##### Arguments:. The `value` argument is the raw pointer value to be signed.; The `key` argument is the identifier of the key to be used to generate the; signed value.; The `discriminator` argument is the additional diversity data to be used as a; discriminator (an integer, an address, or a blend of the two). ##### Semantics:. The '`llvm.ptrauth.sign`' intrinsic implements the `sign`_ operation.; It returns a signed value. If `value` is already a signed value, the behavior is undefined. If `value` is not a pointer value for which `key` is appropriate, the; behavior is undefined. #### '`llvm.ptrauth.auth`'. ##### Syntax:. ```llvm; decl",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PointerAuth.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PointerAuth.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PointerAuth.md:543,Security,authenticat,authenticate,543,"# Pointer Authentication. ## Introduction. Pointer Authentication is a mechanism by which certain pointers are signed.; When a pointer gets signed, a cryptographic hash of its value and other values; (pepper and salt) is stored in unused bits of that pointer. Before the pointer is used, it needs to be authenticated, i.e., have its; signature checked. This prevents pointer values of unknown origin from being; used to replace the signed pointer value. At the IR level, it is represented using:. * a [set of intrinsics](#intrinsics) (to sign/authenticate pointers); * a [call operand bundle](#operand-bundle) (to authenticate called pointers). The current implementation leverages the; [Armv8.3-A PAuth/Pointer Authentication Code](#armv8-3-a-pauth-pointer-authentication-code); instructions in the [AArch64 backend](#aarch64-support).; This support is used to implement the Darwin arm64e ABI, as well as the; [PAuth ABI Extension to ELF](https://github.com/ARM-software/abi-aa/blob/main/pauthabielf64/pauthabielf64.rst). ## LLVM IR Representation. ### Intrinsics. These intrinsics are provided by LLVM to expose pointer authentication; operations. #### '`llvm.ptrauth.sign`'. ##### Syntax:. ```llvm; declare i64 @llvm.ptrauth.sign(i64 <value>, i32 <key>, i64 <discriminator>); ```. ##### Overview:. The '`llvm.ptrauth.sign`' intrinsic signs a raw pointer. ##### Arguments:. The `value` argument is the raw pointer value to be signed.; The `key` argument is the identifier of the key to be used to generate the; signed value.; The `discriminator` argument is the additional diversity data to be used as a; discriminator (an integer, an address, or a blend of the two). ##### Semantics:. The '`llvm.ptrauth.sign`' intrinsic implements the `sign`_ operation.; It returns a signed value. If `value` is already a signed value, the behavior is undefined. If `value` is not a pointer value for which `key` is appropriate, the; behavior is undefined. #### '`llvm.ptrauth.auth`'. ##### Syntax:. ```llvm; decl",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PointerAuth.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PointerAuth.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PointerAuth.md:614,Security,authenticat,authenticate,614,"# Pointer Authentication. ## Introduction. Pointer Authentication is a mechanism by which certain pointers are signed.; When a pointer gets signed, a cryptographic hash of its value and other values; (pepper and salt) is stored in unused bits of that pointer. Before the pointer is used, it needs to be authenticated, i.e., have its; signature checked. This prevents pointer values of unknown origin from being; used to replace the signed pointer value. At the IR level, it is represented using:. * a [set of intrinsics](#intrinsics) (to sign/authenticate pointers); * a [call operand bundle](#operand-bundle) (to authenticate called pointers). The current implementation leverages the; [Armv8.3-A PAuth/Pointer Authentication Code](#armv8-3-a-pauth-pointer-authentication-code); instructions in the [AArch64 backend](#aarch64-support).; This support is used to implement the Darwin arm64e ABI, as well as the; [PAuth ABI Extension to ELF](https://github.com/ARM-software/abi-aa/blob/main/pauthabielf64/pauthabielf64.rst). ## LLVM IR Representation. ### Intrinsics. These intrinsics are provided by LLVM to expose pointer authentication; operations. #### '`llvm.ptrauth.sign`'. ##### Syntax:. ```llvm; declare i64 @llvm.ptrauth.sign(i64 <value>, i32 <key>, i64 <discriminator>); ```. ##### Overview:. The '`llvm.ptrauth.sign`' intrinsic signs a raw pointer. ##### Arguments:. The `value` argument is the raw pointer value to be signed.; The `key` argument is the identifier of the key to be used to generate the; signed value.; The `discriminator` argument is the additional diversity data to be used as a; discriminator (an integer, an address, or a blend of the two). ##### Semantics:. The '`llvm.ptrauth.sign`' intrinsic implements the `sign`_ operation.; It returns a signed value. If `value` is already a signed value, the behavior is undefined. If `value` is not a pointer value for which `key` is appropriate, the; behavior is undefined. #### '`llvm.ptrauth.auth`'. ##### Syntax:. ```llvm; decl",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PointerAuth.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PointerAuth.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PointerAuth.md:758,Security,authenticat,authentication-code,758,"# Pointer Authentication. ## Introduction. Pointer Authentication is a mechanism by which certain pointers are signed.; When a pointer gets signed, a cryptographic hash of its value and other values; (pepper and salt) is stored in unused bits of that pointer. Before the pointer is used, it needs to be authenticated, i.e., have its; signature checked. This prevents pointer values of unknown origin from being; used to replace the signed pointer value. At the IR level, it is represented using:. * a [set of intrinsics](#intrinsics) (to sign/authenticate pointers); * a [call operand bundle](#operand-bundle) (to authenticate called pointers). The current implementation leverages the; [Armv8.3-A PAuth/Pointer Authentication Code](#armv8-3-a-pauth-pointer-authentication-code); instructions in the [AArch64 backend](#aarch64-support).; This support is used to implement the Darwin arm64e ABI, as well as the; [PAuth ABI Extension to ELF](https://github.com/ARM-software/abi-aa/blob/main/pauthabielf64/pauthabielf64.rst). ## LLVM IR Representation. ### Intrinsics. These intrinsics are provided by LLVM to expose pointer authentication; operations. #### '`llvm.ptrauth.sign`'. ##### Syntax:. ```llvm; declare i64 @llvm.ptrauth.sign(i64 <value>, i32 <key>, i64 <discriminator>); ```. ##### Overview:. The '`llvm.ptrauth.sign`' intrinsic signs a raw pointer. ##### Arguments:. The `value` argument is the raw pointer value to be signed.; The `key` argument is the identifier of the key to be used to generate the; signed value.; The `discriminator` argument is the additional diversity data to be used as a; discriminator (an integer, an address, or a blend of the two). ##### Semantics:. The '`llvm.ptrauth.sign`' intrinsic implements the `sign`_ operation.; It returns a signed value. If `value` is already a signed value, the behavior is undefined. If `value` is not a pointer value for which `key` is appropriate, the; behavior is undefined. #### '`llvm.ptrauth.auth`'. ##### Syntax:. ```llvm; decl",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PointerAuth.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PointerAuth.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PointerAuth.md:1107,Security,expose,expose,1107,"are signed.; When a pointer gets signed, a cryptographic hash of its value and other values; (pepper and salt) is stored in unused bits of that pointer. Before the pointer is used, it needs to be authenticated, i.e., have its; signature checked. This prevents pointer values of unknown origin from being; used to replace the signed pointer value. At the IR level, it is represented using:. * a [set of intrinsics](#intrinsics) (to sign/authenticate pointers); * a [call operand bundle](#operand-bundle) (to authenticate called pointers). The current implementation leverages the; [Armv8.3-A PAuth/Pointer Authentication Code](#armv8-3-a-pauth-pointer-authentication-code); instructions in the [AArch64 backend](#aarch64-support).; This support is used to implement the Darwin arm64e ABI, as well as the; [PAuth ABI Extension to ELF](https://github.com/ARM-software/abi-aa/blob/main/pauthabielf64/pauthabielf64.rst). ## LLVM IR Representation. ### Intrinsics. These intrinsics are provided by LLVM to expose pointer authentication; operations. #### '`llvm.ptrauth.sign`'. ##### Syntax:. ```llvm; declare i64 @llvm.ptrauth.sign(i64 <value>, i32 <key>, i64 <discriminator>); ```. ##### Overview:. The '`llvm.ptrauth.sign`' intrinsic signs a raw pointer. ##### Arguments:. The `value` argument is the raw pointer value to be signed.; The `key` argument is the identifier of the key to be used to generate the; signed value.; The `discriminator` argument is the additional diversity data to be used as a; discriminator (an integer, an address, or a blend of the two). ##### Semantics:. The '`llvm.ptrauth.sign`' intrinsic implements the `sign`_ operation.; It returns a signed value. If `value` is already a signed value, the behavior is undefined. If `value` is not a pointer value for which `key` is appropriate, the; behavior is undefined. #### '`llvm.ptrauth.auth`'. ##### Syntax:. ```llvm; declare i64 @llvm.ptrauth.auth(i64 <value>, i32 <key>, i64 <discriminator>); ```. ##### Overview:. The '`llvm.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PointerAuth.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PointerAuth.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PointerAuth.md:1122,Security,authenticat,authentication,1122,"are signed.; When a pointer gets signed, a cryptographic hash of its value and other values; (pepper and salt) is stored in unused bits of that pointer. Before the pointer is used, it needs to be authenticated, i.e., have its; signature checked. This prevents pointer values of unknown origin from being; used to replace the signed pointer value. At the IR level, it is represented using:. * a [set of intrinsics](#intrinsics) (to sign/authenticate pointers); * a [call operand bundle](#operand-bundle) (to authenticate called pointers). The current implementation leverages the; [Armv8.3-A PAuth/Pointer Authentication Code](#armv8-3-a-pauth-pointer-authentication-code); instructions in the [AArch64 backend](#aarch64-support).; This support is used to implement the Darwin arm64e ABI, as well as the; [PAuth ABI Extension to ELF](https://github.com/ARM-software/abi-aa/blob/main/pauthabielf64/pauthabielf64.rst). ## LLVM IR Representation. ### Intrinsics. These intrinsics are provided by LLVM to expose pointer authentication; operations. #### '`llvm.ptrauth.sign`'. ##### Syntax:. ```llvm; declare i64 @llvm.ptrauth.sign(i64 <value>, i32 <key>, i64 <discriminator>); ```. ##### Overview:. The '`llvm.ptrauth.sign`' intrinsic signs a raw pointer. ##### Arguments:. The `value` argument is the raw pointer value to be signed.; The `key` argument is the identifier of the key to be used to generate the; signed value.; The `discriminator` argument is the additional diversity data to be used as a; discriminator (an integer, an address, or a blend of the two). ##### Semantics:. The '`llvm.ptrauth.sign`' intrinsic implements the `sign`_ operation.; It returns a signed value. If `value` is already a signed value, the behavior is undefined. If `value` is not a pointer value for which `key` is appropriate, the; behavior is undefined. #### '`llvm.ptrauth.auth`'. ##### Syntax:. ```llvm; declare i64 @llvm.ptrauth.auth(i64 <value>, i32 <key>, i64 <discriminator>); ```. ##### Overview:. The '`llvm.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PointerAuth.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PointerAuth.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PointerAuth.md:2132,Security,authenticat,authenticates,2132,"perations. #### '`llvm.ptrauth.sign`'. ##### Syntax:. ```llvm; declare i64 @llvm.ptrauth.sign(i64 <value>, i32 <key>, i64 <discriminator>); ```. ##### Overview:. The '`llvm.ptrauth.sign`' intrinsic signs a raw pointer. ##### Arguments:. The `value` argument is the raw pointer value to be signed.; The `key` argument is the identifier of the key to be used to generate the; signed value.; The `discriminator` argument is the additional diversity data to be used as a; discriminator (an integer, an address, or a blend of the two). ##### Semantics:. The '`llvm.ptrauth.sign`' intrinsic implements the `sign`_ operation.; It returns a signed value. If `value` is already a signed value, the behavior is undefined. If `value` is not a pointer value for which `key` is appropriate, the; behavior is undefined. #### '`llvm.ptrauth.auth`'. ##### Syntax:. ```llvm; declare i64 @llvm.ptrauth.auth(i64 <value>, i32 <key>, i64 <discriminator>); ```. ##### Overview:. The '`llvm.ptrauth.auth`' intrinsic authenticates a signed pointer. ##### Arguments:. The `value` argument is the signed pointer value to be authenticated.; The `key` argument is the identifier of the key that was used to generate; the signed value.; The `discriminator` argument is the additional diversity data to be used as a; discriminator. ##### Semantics:. The '`llvm.ptrauth.auth`' intrinsic implements the `auth`_ operation.; It returns a raw pointer value.; If `value` does not have a correct signature for `key` and `discriminator`,; the intrinsic traps in a target-specific way. #### '`llvm.ptrauth.strip`'. ##### Syntax:. ```llvm; declare i64 @llvm.ptrauth.strip(i64 <value>, i32 <key>); ```. ##### Overview:. The '`llvm.ptrauth.strip`' intrinsic strips the embedded signature out of a; possibly-signed pointer. ##### Arguments:. The `value` argument is the signed pointer value to be stripped.; The `key` argument is the identifier of the key that was used to generate; the signed value. ##### Semantics:. The '`llvm.ptrauth.strip",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PointerAuth.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PointerAuth.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PointerAuth.md:2237,Security,authenticat,authenticated,2237,"lvm.ptrauth.sign(i64 <value>, i32 <key>, i64 <discriminator>); ```. ##### Overview:. The '`llvm.ptrauth.sign`' intrinsic signs a raw pointer. ##### Arguments:. The `value` argument is the raw pointer value to be signed.; The `key` argument is the identifier of the key to be used to generate the; signed value.; The `discriminator` argument is the additional diversity data to be used as a; discriminator (an integer, an address, or a blend of the two). ##### Semantics:. The '`llvm.ptrauth.sign`' intrinsic implements the `sign`_ operation.; It returns a signed value. If `value` is already a signed value, the behavior is undefined. If `value` is not a pointer value for which `key` is appropriate, the; behavior is undefined. #### '`llvm.ptrauth.auth`'. ##### Syntax:. ```llvm; declare i64 @llvm.ptrauth.auth(i64 <value>, i32 <key>, i64 <discriminator>); ```. ##### Overview:. The '`llvm.ptrauth.auth`' intrinsic authenticates a signed pointer. ##### Arguments:. The `value` argument is the signed pointer value to be authenticated.; The `key` argument is the identifier of the key that was used to generate; the signed value.; The `discriminator` argument is the additional diversity data to be used as a; discriminator. ##### Semantics:. The '`llvm.ptrauth.auth`' intrinsic implements the `auth`_ operation.; It returns a raw pointer value.; If `value` does not have a correct signature for `key` and `discriminator`,; the intrinsic traps in a target-specific way. #### '`llvm.ptrauth.strip`'. ##### Syntax:. ```llvm; declare i64 @llvm.ptrauth.strip(i64 <value>, i32 <key>); ```. ##### Overview:. The '`llvm.ptrauth.strip`' intrinsic strips the embedded signature out of a; possibly-signed pointer. ##### Arguments:. The `value` argument is the signed pointer value to be stripped.; The `key` argument is the identifier of the key that was used to generate; the signed value. ##### Semantics:. The '`llvm.ptrauth.strip`' intrinsic implements the `strip`_ operation.; It returns a raw pointer val",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PointerAuth.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PointerAuth.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PointerAuth.md:4128,Security,authenticat,authenticated,4128,"ntics:. The '`llvm.ptrauth.strip`' intrinsic implements the `strip`_ operation.; It returns a raw pointer value. It does **not** check that the; signature is valid. `key` should identify a key that is appropriate for `value`, as defined; by the target-specific [keys](#keys)). If `value` is a raw pointer value, it is returned as-is (provided the `key`; is appropriate for the pointer). If `value` is not a pointer value for which `key` is appropriate, the; behavior is target-specific. If `value` is a signed pointer value, but `key` does not identify the; same key that was used to generate `value`, the behavior is; target-specific. #### '`llvm.ptrauth.resign`'. ##### Syntax:. ```llvm; declare i64 @llvm.ptrauth.resign(i64 <value>,; i32 <old key>, i64 <old discriminator>,; i32 <new key>, i64 <new discriminator>); ```. ##### Overview:. The '`llvm.ptrauth.resign`' intrinsic re-signs a signed pointer using; a different key and diversity data. ##### Arguments:. The `value` argument is the signed pointer value to be authenticated.; The `old key` argument is the identifier of the key that was used to generate; the signed value.; The `old discriminator` argument is the additional diversity data to be used; as a discriminator in the auth operation.; The `new key` argument is the identifier of the key to use to generate the; resigned value.; The `new discriminator` argument is the additional diversity data to be used; as a discriminator in the sign operation. ##### Semantics:. The '`llvm.ptrauth.resign`' intrinsic performs a combined `auth`_ and `sign`_; operation, without exposing the intermediate raw pointer.; It returns a signed pointer value.; If `value` does not have a correct signature for `old key` and; `old discriminator`, the intrinsic traps in a target-specific way. #### '`llvm.ptrauth.sign_generic`'. ##### Syntax:. ```llvm; declare i64 @llvm.ptrauth.sign_generic(i64 <value>, i64 <discriminator>); ```. ##### Overview:. The '`llvm.ptrauth.sign_generic`' intrinsic computes",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PointerAuth.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PointerAuth.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PointerAuth.md:6511,Security,authenticat,authenticated,6511,"ns a full signature value (as opposed to a signed pointer value, with; an embedded partial signature). As opposed to [`llvm.ptrauth.sign`](#llvm-ptrauth-sign), it does not interpret; `value` as a pointer value. Instead, it is an arbitrary data value. #### '`llvm.ptrauth.blend`'. ##### Syntax:. ```llvm; declare i64 @llvm.ptrauth.blend(i64 <address discriminator>, i64 <integer discriminator>); ```. ##### Overview:. The '`llvm.ptrauth.blend`' intrinsic blends a pointer address discriminator; with a small integer discriminator to produce a new ""blended"" discriminator. ##### Arguments:. The `address discriminator` argument is a pointer value.; The `integer discriminator` argument is a small integer, as specified by the; target. ##### Semantics:. The '`llvm.ptrauth.blend`' intrinsic combines a small integer discriminator; with a pointer address discriminator, in a way that is specified by the target; implementation. ### Operand Bundle. Function pointers used as indirect call targets can be signed when materialized,; and authenticated before calls. This can be accomplished with the; [`llvm.ptrauth.auth`](#llvm-ptrauth-auth) intrinsic, feeding its result to; an indirect call. However, that exposes the intermediate, unauthenticated pointer, e.g., if it; gets spilled to the stack. An attacker can then overwrite the pointer in; memory, negating the security benefit provided by pointer authentication.; To prevent that, the `ptrauth` operand bundle may be used: it guarantees that; the intermediate call target is kept in a register and never stored to memory.; This hardening benefit is similar to that provided by; [`llvm.ptrauth.resign`](#llvm-ptrauth-resign)). Concretely:. ```llvm; define void @f(void ()* %fp) {; call void %fp() [ ""ptrauth""(i32 <key>, i64 <data>) ]; ret void; }; ```. is functionally equivalent to:. ```llvm; define void @f(void ()* %fp) {; %fp_i = ptrtoint void ()* %fp to i64; %fp_auth = call i64 @llvm.ptrauth.auth(i64 %fp_i, i32 <key>, i64 <data>); %fp_auth_p = ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PointerAuth.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PointerAuth.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PointerAuth.md:6682,Security,expose,exposes,6682,"it is an arbitrary data value. #### '`llvm.ptrauth.blend`'. ##### Syntax:. ```llvm; declare i64 @llvm.ptrauth.blend(i64 <address discriminator>, i64 <integer discriminator>); ```. ##### Overview:. The '`llvm.ptrauth.blend`' intrinsic blends a pointer address discriminator; with a small integer discriminator to produce a new ""blended"" discriminator. ##### Arguments:. The `address discriminator` argument is a pointer value.; The `integer discriminator` argument is a small integer, as specified by the; target. ##### Semantics:. The '`llvm.ptrauth.blend`' intrinsic combines a small integer discriminator; with a pointer address discriminator, in a way that is specified by the target; implementation. ### Operand Bundle. Function pointers used as indirect call targets can be signed when materialized,; and authenticated before calls. This can be accomplished with the; [`llvm.ptrauth.auth`](#llvm-ptrauth-auth) intrinsic, feeding its result to; an indirect call. However, that exposes the intermediate, unauthenticated pointer, e.g., if it; gets spilled to the stack. An attacker can then overwrite the pointer in; memory, negating the security benefit provided by pointer authentication.; To prevent that, the `ptrauth` operand bundle may be used: it guarantees that; the intermediate call target is kept in a register and never stored to memory.; This hardening benefit is similar to that provided by; [`llvm.ptrauth.resign`](#llvm-ptrauth-resign)). Concretely:. ```llvm; define void @f(void ()* %fp) {; call void %fp() [ ""ptrauth""(i32 <key>, i64 <data>) ]; ret void; }; ```. is functionally equivalent to:. ```llvm; define void @f(void ()* %fp) {; %fp_i = ptrtoint void ()* %fp to i64; %fp_auth = call i64 @llvm.ptrauth.auth(i64 %fp_i, i32 <key>, i64 <data>); %fp_auth_p = inttoptr i64 %fp_auth to void ()*; call void %fp_auth_p(); ret void; }; ```. but with the added guarantee that `%fp_i`, `%fp_auth`, and `%fp_auth_p`; are not stored to (and reloaded from) memory. ## AArch64 Support. AArc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PointerAuth.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PointerAuth.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PointerAuth.md:6776,Security,attack,attacker,6776,"scriminator>, i64 <integer discriminator>); ```. ##### Overview:. The '`llvm.ptrauth.blend`' intrinsic blends a pointer address discriminator; with a small integer discriminator to produce a new ""blended"" discriminator. ##### Arguments:. The `address discriminator` argument is a pointer value.; The `integer discriminator` argument is a small integer, as specified by the; target. ##### Semantics:. The '`llvm.ptrauth.blend`' intrinsic combines a small integer discriminator; with a pointer address discriminator, in a way that is specified by the target; implementation. ### Operand Bundle. Function pointers used as indirect call targets can be signed when materialized,; and authenticated before calls. This can be accomplished with the; [`llvm.ptrauth.auth`](#llvm-ptrauth-auth) intrinsic, feeding its result to; an indirect call. However, that exposes the intermediate, unauthenticated pointer, e.g., if it; gets spilled to the stack. An attacker can then overwrite the pointer in; memory, negating the security benefit provided by pointer authentication.; To prevent that, the `ptrauth` operand bundle may be used: it guarantees that; the intermediate call target is kept in a register and never stored to memory.; This hardening benefit is similar to that provided by; [`llvm.ptrauth.resign`](#llvm-ptrauth-resign)). Concretely:. ```llvm; define void @f(void ()* %fp) {; call void %fp() [ ""ptrauth""(i32 <key>, i64 <data>) ]; ret void; }; ```. is functionally equivalent to:. ```llvm; define void @f(void ()* %fp) {; %fp_i = ptrtoint void ()* %fp to i64; %fp_auth = call i64 @llvm.ptrauth.auth(i64 %fp_i, i32 <key>, i64 <data>); %fp_auth_p = inttoptr i64 %fp_auth to void ()*; call void %fp_auth_p(); ret void; }; ```. but with the added guarantee that `%fp_i`, `%fp_auth`, and `%fp_auth_p`; are not stored to (and reloaded from) memory. ## AArch64 Support. AArch64 is currently the only architecture with full support of the pointer; authentication primitives, based on Armv8.3-A instructions.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PointerAuth.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PointerAuth.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PointerAuth.md:6841,Security,secur,security,6841,"scriminator>, i64 <integer discriminator>); ```. ##### Overview:. The '`llvm.ptrauth.blend`' intrinsic blends a pointer address discriminator; with a small integer discriminator to produce a new ""blended"" discriminator. ##### Arguments:. The `address discriminator` argument is a pointer value.; The `integer discriminator` argument is a small integer, as specified by the; target. ##### Semantics:. The '`llvm.ptrauth.blend`' intrinsic combines a small integer discriminator; with a pointer address discriminator, in a way that is specified by the target; implementation. ### Operand Bundle. Function pointers used as indirect call targets can be signed when materialized,; and authenticated before calls. This can be accomplished with the; [`llvm.ptrauth.auth`](#llvm-ptrauth-auth) intrinsic, feeding its result to; an indirect call. However, that exposes the intermediate, unauthenticated pointer, e.g., if it; gets spilled to the stack. An attacker can then overwrite the pointer in; memory, negating the security benefit provided by pointer authentication.; To prevent that, the `ptrauth` operand bundle may be used: it guarantees that; the intermediate call target is kept in a register and never stored to memory.; This hardening benefit is similar to that provided by; [`llvm.ptrauth.resign`](#llvm-ptrauth-resign)). Concretely:. ```llvm; define void @f(void ()* %fp) {; call void %fp() [ ""ptrauth""(i32 <key>, i64 <data>) ]; ret void; }; ```. is functionally equivalent to:. ```llvm; define void @f(void ()* %fp) {; %fp_i = ptrtoint void ()* %fp to i64; %fp_auth = call i64 @llvm.ptrauth.auth(i64 %fp_i, i32 <key>, i64 <data>); %fp_auth_p = inttoptr i64 %fp_auth to void ()*; call void %fp_auth_p(); ret void; }; ```. but with the added guarantee that `%fp_i`, `%fp_auth`, and `%fp_auth_p`; are not stored to (and reloaded from) memory. ## AArch64 Support. AArch64 is currently the only architecture with full support of the pointer; authentication primitives, based on Armv8.3-A instructions.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PointerAuth.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PointerAuth.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PointerAuth.md:6878,Security,authenticat,authentication,6878,"scriminator>, i64 <integer discriminator>); ```. ##### Overview:. The '`llvm.ptrauth.blend`' intrinsic blends a pointer address discriminator; with a small integer discriminator to produce a new ""blended"" discriminator. ##### Arguments:. The `address discriminator` argument is a pointer value.; The `integer discriminator` argument is a small integer, as specified by the; target. ##### Semantics:. The '`llvm.ptrauth.blend`' intrinsic combines a small integer discriminator; with a pointer address discriminator, in a way that is specified by the target; implementation. ### Operand Bundle. Function pointers used as indirect call targets can be signed when materialized,; and authenticated before calls. This can be accomplished with the; [`llvm.ptrauth.auth`](#llvm-ptrauth-auth) intrinsic, feeding its result to; an indirect call. However, that exposes the intermediate, unauthenticated pointer, e.g., if it; gets spilled to the stack. An attacker can then overwrite the pointer in; memory, negating the security benefit provided by pointer authentication.; To prevent that, the `ptrauth` operand bundle may be used: it guarantees that; the intermediate call target is kept in a register and never stored to memory.; This hardening benefit is similar to that provided by; [`llvm.ptrauth.resign`](#llvm-ptrauth-resign)). Concretely:. ```llvm; define void @f(void ()* %fp) {; call void %fp() [ ""ptrauth""(i32 <key>, i64 <data>) ]; ret void; }; ```. is functionally equivalent to:. ```llvm; define void @f(void ()* %fp) {; %fp_i = ptrtoint void ()* %fp to i64; %fp_auth = call i64 @llvm.ptrauth.auth(i64 %fp_i, i32 <key>, i64 <data>); %fp_auth_p = inttoptr i64 %fp_auth to void ()*; call void %fp_auth_p(); ret void; }; ```. but with the added guarantee that `%fp_i`, `%fp_auth`, and `%fp_auth_p`; are not stored to (and reloaded from) memory. ## AArch64 Support. AArch64 is currently the only architecture with full support of the pointer; authentication primitives, based on Armv8.3-A instructions.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PointerAuth.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PointerAuth.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PointerAuth.md:7774,Security,authenticat,authentication,7774,"ed to the stack. An attacker can then overwrite the pointer in; memory, negating the security benefit provided by pointer authentication.; To prevent that, the `ptrauth` operand bundle may be used: it guarantees that; the intermediate call target is kept in a register and never stored to memory.; This hardening benefit is similar to that provided by; [`llvm.ptrauth.resign`](#llvm-ptrauth-resign)). Concretely:. ```llvm; define void @f(void ()* %fp) {; call void %fp() [ ""ptrauth""(i32 <key>, i64 <data>) ]; ret void; }; ```. is functionally equivalent to:. ```llvm; define void @f(void ()* %fp) {; %fp_i = ptrtoint void ()* %fp to i64; %fp_auth = call i64 @llvm.ptrauth.auth(i64 %fp_i, i32 <key>, i64 <data>); %fp_auth_p = inttoptr i64 %fp_auth to void ()*; call void %fp_auth_p(); ret void; }; ```. but with the added guarantee that `%fp_i`, `%fp_auth`, and `%fp_auth_p`; are not stored to (and reloaded from) memory. ## AArch64 Support. AArch64 is currently the only architecture with full support of the pointer; authentication primitives, based on Armv8.3-A instructions. ### Armv8.3-A PAuth Pointer Authentication Code. The Armv8.3-A architecture extension defines the PAuth feature, which provides; support for instructions that manipulate Pointer Authentication Codes (PAC). #### Keys. 5 keys are supported by the PAuth feature. Of those, 4 keys are interchangeably usable to specify the key used in IR; constructs:; * `ASIA`/`ASIB` are instruction keys (encoded as respectively 0 and 1).; * `ASDA`/`ASDB` are data keys (encoded as respectively 2 and 3). `ASGA` is a special key that cannot be explicitly specified, and is only ever; used implicitly, to implement the; [`llvm.ptrauth.sign_generic`](#llvm-ptrauth-sign-generic) intrinsic. #### Instructions. The IR [Intrinsics](#intrinsics) described above map onto these; instructions as such:; * [`llvm.ptrauth.sign`](#llvm-ptrauth-sign): `PAC{I,D}{A,B}{Z,SP,}`; * [`llvm.ptrauth.auth`](#llvm-ptrauth-auth): `AUT{I,D}{A,B}{Z,SP,}`; * [`llvm",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PointerAuth.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PointerAuth.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PointerAuth.md:9373,Security,attack,attackable,9373,"ly 2 and 3). `ASGA` is a special key that cannot be explicitly specified, and is only ever; used implicitly, to implement the; [`llvm.ptrauth.sign_generic`](#llvm-ptrauth-sign-generic) intrinsic. #### Instructions. The IR [Intrinsics](#intrinsics) described above map onto these; instructions as such:; * [`llvm.ptrauth.sign`](#llvm-ptrauth-sign): `PAC{I,D}{A,B}{Z,SP,}`; * [`llvm.ptrauth.auth`](#llvm-ptrauth-auth): `AUT{I,D}{A,B}{Z,SP,}`; * [`llvm.ptrauth.strip`](#llvm-ptrauth-strip): `XPAC{I,D}`; * [`llvm.ptrauth.blend`](#llvm-ptrauth-blend): The semantics of the blend; operation are specified by the ABI. In both the ELF PAuth ABI Extension and; arm64e, it's a `MOVK` into the high 16 bits. Consequently, this limits; the width of the integer discriminator used in blends to 16 bits.; * [`llvm.ptrauth.sign_generic`](#llvm-ptrauth-sign-generic): `PACGA`; * [`llvm.ptrauth.resign`](#llvm-ptrauth-resign): `AUT*+PAC*`. These are; represented as a single pseudo-instruction in the backend to guarantee that; the intermediate raw pointer value is not spilled and attackable. #### Assembly Representation. At the assembly level, authenticated relocations are represented; using the `@AUTH` modifier:. ```asm; .quad _target@AUTH(<key>,<discriminator>[,addr]); ```. where:; * `key` is the Armv8.3-A key identifier (`ia`, `ib`, `da`, `db`); * `discriminator` is the 16-bit unsigned discriminator value; * `addr` signifies that the authenticated pointer is address-discriminated; (that is, that the relocation's target address is to be blended into the; `discriminator` before it is used in the sign operation. For example:; ```asm; _authenticated_reference_to_sym:; .quad _sym@AUTH(db,0); _authenticated_reference_to_sym_addr_disc:; .quad _sym@AUTH(ia,12,addr); ```. #### ELF Object File Representation. At the object file level, authenticated relocations are represented; using the `R_AARCH64_AUTH_ABS64` relocation kind (with value `0xE100`). The signing schema is encoded in the place of relocation",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PointerAuth.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PointerAuth.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PointerAuth.md:9438,Security,authenticat,authenticated,9438,"`](#llvm-ptrauth-sign-generic) intrinsic. #### Instructions. The IR [Intrinsics](#intrinsics) described above map onto these; instructions as such:; * [`llvm.ptrauth.sign`](#llvm-ptrauth-sign): `PAC{I,D}{A,B}{Z,SP,}`; * [`llvm.ptrauth.auth`](#llvm-ptrauth-auth): `AUT{I,D}{A,B}{Z,SP,}`; * [`llvm.ptrauth.strip`](#llvm-ptrauth-strip): `XPAC{I,D}`; * [`llvm.ptrauth.blend`](#llvm-ptrauth-blend): The semantics of the blend; operation are specified by the ABI. In both the ELF PAuth ABI Extension and; arm64e, it's a `MOVK` into the high 16 bits. Consequently, this limits; the width of the integer discriminator used in blends to 16 bits.; * [`llvm.ptrauth.sign_generic`](#llvm-ptrauth-sign-generic): `PACGA`; * [`llvm.ptrauth.resign`](#llvm-ptrauth-resign): `AUT*+PAC*`. These are; represented as a single pseudo-instruction in the backend to guarantee that; the intermediate raw pointer value is not spilled and attackable. #### Assembly Representation. At the assembly level, authenticated relocations are represented; using the `@AUTH` modifier:. ```asm; .quad _target@AUTH(<key>,<discriminator>[,addr]); ```. where:; * `key` is the Armv8.3-A key identifier (`ia`, `ib`, `da`, `db`); * `discriminator` is the 16-bit unsigned discriminator value; * `addr` signifies that the authenticated pointer is address-discriminated; (that is, that the relocation's target address is to be blended into the; `discriminator` before it is used in the sign operation. For example:; ```asm; _authenticated_reference_to_sym:; .quad _sym@AUTH(db,0); _authenticated_reference_to_sym_addr_disc:; .quad _sym@AUTH(ia,12,addr); ```. #### ELF Object File Representation. At the object file level, authenticated relocations are represented; using the `R_AARCH64_AUTH_ABS64` relocation kind (with value `0xE100`). The signing schema is encoded in the place of relocation to be applied; as follows:. ```; | 63 | 62 | 61:60 | 59:48 | 47:32 | 31:0 |; | ----------------- | -------- | -------- | -------- | ------------- | ------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PointerAuth.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PointerAuth.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PointerAuth.md:9737,Security,authenticat,authenticated,9737,"p onto these; instructions as such:; * [`llvm.ptrauth.sign`](#llvm-ptrauth-sign): `PAC{I,D}{A,B}{Z,SP,}`; * [`llvm.ptrauth.auth`](#llvm-ptrauth-auth): `AUT{I,D}{A,B}{Z,SP,}`; * [`llvm.ptrauth.strip`](#llvm-ptrauth-strip): `XPAC{I,D}`; * [`llvm.ptrauth.blend`](#llvm-ptrauth-blend): The semantics of the blend; operation are specified by the ABI. In both the ELF PAuth ABI Extension and; arm64e, it's a `MOVK` into the high 16 bits. Consequently, this limits; the width of the integer discriminator used in blends to 16 bits.; * [`llvm.ptrauth.sign_generic`](#llvm-ptrauth-sign-generic): `PACGA`; * [`llvm.ptrauth.resign`](#llvm-ptrauth-resign): `AUT*+PAC*`. These are; represented as a single pseudo-instruction in the backend to guarantee that; the intermediate raw pointer value is not spilled and attackable. #### Assembly Representation. At the assembly level, authenticated relocations are represented; using the `@AUTH` modifier:. ```asm; .quad _target@AUTH(<key>,<discriminator>[,addr]); ```. where:; * `key` is the Armv8.3-A key identifier (`ia`, `ib`, `da`, `db`); * `discriminator` is the 16-bit unsigned discriminator value; * `addr` signifies that the authenticated pointer is address-discriminated; (that is, that the relocation's target address is to be blended into the; `discriminator` before it is used in the sign operation. For example:; ```asm; _authenticated_reference_to_sym:; .quad _sym@AUTH(db,0); _authenticated_reference_to_sym_addr_disc:; .quad _sym@AUTH(ia,12,addr); ```. #### ELF Object File Representation. At the object file level, authenticated relocations are represented; using the `R_AARCH64_AUTH_ABS64` relocation kind (with value `0xE100`). The signing schema is encoded in the place of relocation to be applied; as follows:. ```; | 63 | 62 | 61:60 | 59:48 | 47:32 | 31:0 |; | ----------------- | -------- | -------- | -------- | ------------- | ------------------- |; | address diversity | reserved | key | reserved | discriminator | reserved for addend |; ```; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PointerAuth.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PointerAuth.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PointerAuth.md:10136,Security,authenticat,authenticated,10136,"p onto these; instructions as such:; * [`llvm.ptrauth.sign`](#llvm-ptrauth-sign): `PAC{I,D}{A,B}{Z,SP,}`; * [`llvm.ptrauth.auth`](#llvm-ptrauth-auth): `AUT{I,D}{A,B}{Z,SP,}`; * [`llvm.ptrauth.strip`](#llvm-ptrauth-strip): `XPAC{I,D}`; * [`llvm.ptrauth.blend`](#llvm-ptrauth-blend): The semantics of the blend; operation are specified by the ABI. In both the ELF PAuth ABI Extension and; arm64e, it's a `MOVK` into the high 16 bits. Consequently, this limits; the width of the integer discriminator used in blends to 16 bits.; * [`llvm.ptrauth.sign_generic`](#llvm-ptrauth-sign-generic): `PACGA`; * [`llvm.ptrauth.resign`](#llvm-ptrauth-resign): `AUT*+PAC*`. These are; represented as a single pseudo-instruction in the backend to guarantee that; the intermediate raw pointer value is not spilled and attackable. #### Assembly Representation. At the assembly level, authenticated relocations are represented; using the `@AUTH` modifier:. ```asm; .quad _target@AUTH(<key>,<discriminator>[,addr]); ```. where:; * `key` is the Armv8.3-A key identifier (`ia`, `ib`, `da`, `db`); * `discriminator` is the 16-bit unsigned discriminator value; * `addr` signifies that the authenticated pointer is address-discriminated; (that is, that the relocation's target address is to be blended into the; `discriminator` before it is used in the sign operation. For example:; ```asm; _authenticated_reference_to_sym:; .quad _sym@AUTH(db,0); _authenticated_reference_to_sym_addr_disc:; .quad _sym@AUTH(ia,12,addr); ```. #### ELF Object File Representation. At the object file level, authenticated relocations are represented; using the `R_AARCH64_AUTH_ABS64` relocation kind (with value `0xE100`). The signing schema is encoded in the place of relocation to be applied; as follows:. ```; | 63 | 62 | 61:60 | 59:48 | 47:32 | 31:0 |; | ----------------- | -------- | -------- | -------- | ------------- | ------------------- |; | address diversity | reserved | key | reserved | discriminator | reserved for addend |; ```; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PointerAuth.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PointerAuth.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PointerAuth.md:8131,Usability,usab,usable,8131,"llvm; define void @f(void ()* %fp) {; call void %fp() [ ""ptrauth""(i32 <key>, i64 <data>) ]; ret void; }; ```. is functionally equivalent to:. ```llvm; define void @f(void ()* %fp) {; %fp_i = ptrtoint void ()* %fp to i64; %fp_auth = call i64 @llvm.ptrauth.auth(i64 %fp_i, i32 <key>, i64 <data>); %fp_auth_p = inttoptr i64 %fp_auth to void ()*; call void %fp_auth_p(); ret void; }; ```. but with the added guarantee that `%fp_i`, `%fp_auth`, and `%fp_auth_p`; are not stored to (and reloaded from) memory. ## AArch64 Support. AArch64 is currently the only architecture with full support of the pointer; authentication primitives, based on Armv8.3-A instructions. ### Armv8.3-A PAuth Pointer Authentication Code. The Armv8.3-A architecture extension defines the PAuth feature, which provides; support for instructions that manipulate Pointer Authentication Codes (PAC). #### Keys. 5 keys are supported by the PAuth feature. Of those, 4 keys are interchangeably usable to specify the key used in IR; constructs:; * `ASIA`/`ASIB` are instruction keys (encoded as respectively 0 and 1).; * `ASDA`/`ASDB` are data keys (encoded as respectively 2 and 3). `ASGA` is a special key that cannot be explicitly specified, and is only ever; used implicitly, to implement the; [`llvm.ptrauth.sign_generic`](#llvm-ptrauth-sign-generic) intrinsic. #### Instructions. The IR [Intrinsics](#intrinsics) described above map onto these; instructions as such:; * [`llvm.ptrauth.sign`](#llvm-ptrauth-sign): `PAC{I,D}{A,B}{Z,SP,}`; * [`llvm.ptrauth.auth`](#llvm-ptrauth-auth): `AUT{I,D}{A,B}{Z,SP,}`; * [`llvm.ptrauth.strip`](#llvm-ptrauth-strip): `XPAC{I,D}`; * [`llvm.ptrauth.blend`](#llvm-ptrauth-blend): The semantics of the blend; operation are specified by the ABI. In both the ELF PAuth ABI Extension and; arm64e, it's a `MOVK` into the high 16 bits. Consequently, this limits; the width of the integer discriminator used in blends to 16 bits.; * [`llvm.ptrauth.sign_generic`](#llvm-ptrauth-sign-generic): `PACGA`; * [`",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PointerAuth.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PointerAuth.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/RemoveDIsDebugInfo.md:6062,Modifiability,variab,variable,6062," in a `DebugValueUser` base class. This refers to a `ValueAsMetadata` object referring to `Value`s, via the `TrackingMetadata` facility. The various kinds of debug intrinsic (value, declare, assign) are all stored in the `DPValue` object, with a ""Type"" field disamgibuating which is which. ## Finding debug info records. Utilities such as `findDbgUsers` and the like now have an optional argument that will return the set of `DPValue` records that refer to a `Value`. You should be able to treat them the same as intrinsics. ## Examining debug info records at positions. Call `Instruction::getDbgValueRange()` to get the range of `DPValue` objects that are attached to an instruction. ## Moving around, deleting. You can use `DPValue::removeFromParent` to unlink a `DPValue` from it's marker, and then `BasicBlock::insertDPValueBefore` or `BasicBlock::insertDPValueAfter` to re-insert the `DPValue` somewhere else. You cannot insert a `DPValue` at an arbitary point in a list of `DPValue`s (if you're doing this with `dbg.value`s then it's unlikely to be correct). Erase `DPValue`s by calling `eraseFromParent` or `deleteInstr` if it's already been removed. ## What about dangling `DPValue`s?. If you have a block like so:. ```text; foo:; %bar = add i32 %baz...; dbg.value(metadata i32 %bar,...; br label %xyzzy; ```. your optimisation pass may wish to erase the terminator and then do something to the block. This is easy to do when debug info is kept in instructions, but with `DPValue`s there is no trailing instruction to attach the variable information to in the block above, once the terminator is erased. For such degenerate blocks, `DPValue`s are stored temporarily in a map in `LLVMContext`, and are re-inserted when a terminator is reinserted to the block or other instruction inserted at `end()`. This can technically lead to trouble in the vanishingly rare scenario where an optimisation pass erases a terminator and then decides to erase the whole block. (We recommend not doing that).; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/RemoveDIsDebugInfo.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/RemoveDIsDebugInfo.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:364,Availability,down,down,364,"# Speculative Load Hardening. ## A Spectre Variant #1 Mitigation Technique. Author: Chandler Carruth - [chandlerc@google.com](mailto:chandlerc@google.com). ## Problem Statement. Recently, Google Project Zero and other researchers have found information leak; vulnerabilities by exploiting speculative execution in modern CPUs. These; exploits are currently broken down into three variants:; * GPZ Variant #1 (a.k.a. Spectre Variant #1): Bounds check (or predicate) bypass; * GPZ Variant #2 (a.k.a. Spectre Variant #2): Branch target injection; * GPZ Variant #3 (a.k.a. Meltdown): Rogue data cache load. For more details, see the Google Project Zero blog post and the Spectre research; paper:; * https://googleprojectzero.blogspot.com/2018/01/reading-privileged-memory-with-side.html; * https://spectreattack.com/spectre.pdf. The core problem of GPZ Variant #1 is that speculative execution uses branch; prediction to select the path of instructions speculatively executed. This path; is speculatively executed with the available data, and may load from memory and; leak the loaded values through various side channels that survive even when the; speculative execution is unwound due to being incorrect. Mispredicted paths can; cause code to be executed with data inputs that never occur in correct; executions, making checks against malicious inputs ineffective and allowing; attackers to use malicious data inputs to leak secret data. Here is an example,; extracted and simplified from the Project Zero paper:; ```; struct array {; unsigned long length;; unsigned char data[];; };; struct array *arr1 = ...; // small array; struct array *arr2 = ...; // array of size 0x400; unsigned long untrusted_offset_from_caller = ...;; if (untrusted_offset_from_caller < arr1->length) {; unsigned char value = arr1->data[untrusted_offset_from_caller];; unsigned long index2 = ((value&1)*0x100)+0x200;; unsigned char value2 = arr2->data[index2];; }; ```. The key of the attack is to call this with `untrusted_off",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:1019,Availability,avail,available,1019,"ndler Carruth - [chandlerc@google.com](mailto:chandlerc@google.com). ## Problem Statement. Recently, Google Project Zero and other researchers have found information leak; vulnerabilities by exploiting speculative execution in modern CPUs. These; exploits are currently broken down into three variants:; * GPZ Variant #1 (a.k.a. Spectre Variant #1): Bounds check (or predicate) bypass; * GPZ Variant #2 (a.k.a. Spectre Variant #2): Branch target injection; * GPZ Variant #3 (a.k.a. Meltdown): Rogue data cache load. For more details, see the Google Project Zero blog post and the Spectre research; paper:; * https://googleprojectzero.blogspot.com/2018/01/reading-privileged-memory-with-side.html; * https://spectreattack.com/spectre.pdf. The core problem of GPZ Variant #1 is that speculative execution uses branch; prediction to select the path of instructions speculatively executed. This path; is speculatively executed with the available data, and may load from memory and; leak the loaded values through various side channels that survive even when the; speculative execution is unwound due to being incorrect. Mispredicted paths can; cause code to be executed with data inputs that never occur in correct; executions, making checks against malicious inputs ineffective and allowing; attackers to use malicious data inputs to leak secret data. Here is an example,; extracted and simplified from the Project Zero paper:; ```; struct array {; unsigned long length;; unsigned char data[];; };; struct array *arr1 = ...; // small array; struct array *arr2 = ...; // array of size 0x400; unsigned long untrusted_offset_from_caller = ...;; if (untrusted_offset_from_caller < arr1->length) {; unsigned char value = arr1->data[untrusted_offset_from_caller];; unsigned long index2 = ((value&1)*0x100)+0x200;; unsigned char value2 = arr2->data[index2];; }; ```. The key of the attack is to call this with `untrusted_offset_from_caller` that; is far outside of the bounds when the branch predictor will pre",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:8228,Availability,mask,masking,8228,"xed addresses. This primarily consists of accesses; at compile-time constant offsets of global and local variables. Code which; needs this protection and intentionally stores secret data must ensure the; memory regions used for secret data are necessarily dynamic mappings or heap; allocations. This is an area which can be tuned to provide more comprehensive; protection at the cost of performance.; * [Hardened loads](#hardening-the-address-of-the-load) may still load data from; _valid_ addresses if not _attacker-controlled_ addresses. To prevent these; from reading secret data, the low 2gb of the address space and 2gb above and; below any executable pages should be protected. Credit:; * The core idea of tracing misspeculation through data and marking pointers to; block misspeculated loads was developed as part of a HACS 2018 discussion; between Chandler Carruth, Paul Kocher, Thomas Pornin, and several other; individuals.; * Core idea of masking out loaded bits was part of the original mitigation; suggested by Jann Horn when these attacks were reported. ### Indirect Branches, Calls, and Returns. It is possible to attack control flow other than conditional branches with; variant #1 style mispredictions.; * A prediction towards a hot call target of a virtual method can lead to it; being speculatively executed when an expected type is used (often called; ""type confusion"").; * A hot case may be speculatively executed due to prediction instead of the; correct case for a switch statement implemented as a jump table.; * A hot common return address may be predicted incorrectly when returning from; a function. These code patterns are also vulnerable to Spectre variant #2, and as such are; best mitigated with a; [retpoline](https://support.google.com/faqs/answer/7625886) on x86 platforms.; When a mitigation technique like retpoline is used, speculation simply cannot; proceed through an indirect control flow edge (or it cannot be mispredicted in; the case of a filled RSB) and so",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:14880,Availability,down,down,14880,"value that has been read back. For both of these, using retpolines would be equally sufficient. One possible; hybrid approach is to use retpolines for indirect call and jump, while relying; on SLH to mitigate returns. Another approach that is sufficient for both of these is to harden all of the; speculative stores. However, as most stores aren't interesting and don't; inherently leak data, this is expected to be prohibitively expensive given the; attack it is defending against. ## Implementation Details. There are a number of complex details impacting the implementation of this; technique, both on a particular architecture and within a particular compiler.; We discuss proposed implementation techniques for the x86 architecture and the; LLVM compiler. These are primarily to serve as an example, as other; implementation techniques are very possible. ### x86 Implementation Details. On the x86 platform we break down the implementation into three core; components: accumulating the predicate state through the control flow graph,; checking the loads, and checking control transfers between procedures. #### Accumulating Predicate State. Consider baseline x86 instructions like the following, which test three; conditions and if all pass, loads data from memory and potentially leaks it; through some side channel:; ```; # %bb.0: # %entry; pushq %rax; testl %edi, %edi; jne .LBB0_4; # %bb.1: # %then1; testl %esi, %esi; jne .LBB0_4; # %bb.2: # %then2; testl %edx, %edx; je .LBB0_3; .LBB0_4: # %exit; popq %rax; retq; .LBB0_3: # %danger; movl (%rcx), %edi; callq leak; popq %rax; retq; ```. When we go to speculatively execute the load, we want to know whether any of; the dynamically executed predicates have been misspeculated. To track that,; along each conditional edge, we need to track the data which would allow that; edge to be taken. On x86, this data is stored in the flags register used by the; conditional jump instruction. Along both edges after this fork in control flow,; the fla",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:15980,Availability,alive,alive,15980,"ol flow graph,; checking the loads, and checking control transfers between procedures. #### Accumulating Predicate State. Consider baseline x86 instructions like the following, which test three; conditions and if all pass, loads data from memory and potentially leaks it; through some side channel:; ```; # %bb.0: # %entry; pushq %rax; testl %edi, %edi; jne .LBB0_4; # %bb.1: # %then1; testl %esi, %esi; jne .LBB0_4; # %bb.2: # %then2; testl %edx, %edx; je .LBB0_3; .LBB0_4: # %exit; popq %rax; retq; .LBB0_3: # %danger; movl (%rcx), %edi; callq leak; popq %rax; retq; ```. When we go to speculatively execute the load, we want to know whether any of; the dynamically executed predicates have been misspeculated. To track that,; along each conditional edge, we need to track the data which would allow that; edge to be taken. On x86, this data is stored in the flags register used by the; conditional jump instruction. Along both edges after this fork in control flow,; the flags register remains alive and contains data that we can use to build up; our accumulated predicate state. We accumulate it using the x86 conditional; move instruction which also reads the flag registers where the state resides.; These conditional move instructions are known to not be predicted on any x86; processors, making them immune to misprediction that could reintroduce the; vulnerability. When we insert the conditional moves, the code ends up looking; like the following:; ```; # %bb.0: # %entry; pushq %rax; xorl %eax, %eax # Zero out initial predicate state.; movq $-1, %r8 # Put all-ones mask into a register.; testl %edi, %edi; jne .LBB0_1; # %bb.2: # %then1; cmovneq %r8, %rax # Conditionally update predicate state.; testl %esi, %esi; jne .LBB0_1; # %bb.3: # %then2; cmovneq %r8, %rax # Conditionally update predicate state.; testl %edx, %edx; je .LBB0_4; .LBB0_1:; cmoveq %r8, %rax # Conditionally update predicate state.; popq %rax; retq; .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:16561,Availability,mask,mask,16561," When we go to speculatively execute the load, we want to know whether any of; the dynamically executed predicates have been misspeculated. To track that,; along each conditional edge, we need to track the data which would allow that; edge to be taken. On x86, this data is stored in the flags register used by the; conditional jump instruction. Along both edges after this fork in control flow,; the flags register remains alive and contains data that we can use to build up; our accumulated predicate state. We accumulate it using the x86 conditional; move instruction which also reads the flag registers where the state resides.; These conditional move instructions are known to not be predicted on any x86; processors, making them immune to misprediction that could reintroduce the; vulnerability. When we insert the conditional moves, the code ends up looking; like the following:; ```; # %bb.0: # %entry; pushq %rax; xorl %eax, %eax # Zero out initial predicate state.; movq $-1, %r8 # Put all-ones mask into a register.; testl %edi, %edi; jne .LBB0_1; # %bb.2: # %then1; cmovneq %r8, %rax # Conditionally update predicate state.; testl %esi, %esi; jne .LBB0_1; # %bb.3: # %then2; cmovneq %r8, %rax # Conditionally update predicate state.; testl %edx, %edx; je .LBB0_4; .LBB0_1:; cmoveq %r8, %rax # Conditionally update predicate state.; popq %rax; retq; .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; ...; ```. Here we create the ""empty"" or ""correct execution"" predicate state by zeroing; `%rax`, and we create a constant ""incorrect execution"" predicate value by; putting `-1` into `%r8`. Then, along each edge coming out of a conditional; branch we do a conditional move that in a correct execution will be a no-op,; but if misspeculated, will replace the `%rax` with the value of `%r8`.; Misspeculating any one of the three predicates will cause `%rax` to hold the; ""incorrect execution"" value from `%r8` as we preserve incoming values when; execution is corr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:18410,Availability,mask,mask,18410,"ne of the three predicates will cause `%rax` to hold the; ""incorrect execution"" value from `%r8` as we preserve incoming values when; execution is correct rather than overwriting it. We now have a value in `%rax` in each basic block that indicates if at some; point previously a predicate was mispredicted. And we have arranged for that; value to be particularly effective when used below to harden loads. ##### Indirect Call, Branch, and Return Predicates. There is no analogous flag to use when tracing indirect calls, branches, and; returns. The predicate state must be accumulated through some other means.; Fundamentally, this is the reverse of the problem posed in CFI: we need to; check where we came from rather than where we are going. For function-local; jump tables, this is easily arranged by testing the input to the jump table; within each destination (not yet implemented, use retpolines):; ```; pushq %rax; xorl %eax, %eax # Zero out initial predicate state.; movq $-1, %r8 # Put all-ones mask into a register.; jmpq *.LJTI0_0(,%rdi,8) # Indirect jump through table.; .LBB0_2: # %sw.bb; testq $0, %rdi # Validate index used for jump table.; cmovneq %r8, %rax # Conditionally update predicate state.; ...; jmp _Z4leaki # TAILCALL. .LBB0_3: # %sw.bb1; testq $1, %rdi # Validate index used for jump table.; cmovneq %r8, %rax # Conditionally update predicate state.; ...; jmp _Z4leaki # TAILCALL. .LBB0_5: # %sw.bb10; testq $2, %rdi # Validate index used for jump table.; cmovneq %r8, %rax # Conditionally update predicate state.; ...; jmp _Z4leaki # TAILCALL; ... .section .rodata,""a"",@progbits; .p2align 3; .LJTI0_0:; .quad .LBB0_2; .quad .LBB0_3; .quad .LBB0_5; ...; ```. Returns have a simple mitigation technique on x86-64 (or other ABIs which have; what is called a ""red zone"" region beyond the end of the stack). This region is; guaranteed to be preserved across interrupts and context switches, making the; return address used in returning to the current code remain on the stack ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:22786,Availability,mask,mask,22786,"dge to track it. Second, we trade register pressure for simpler `cmovCC` instructions by; allocating a register for the ""bad"" state. We could read that value from memory; as part of the conditional move instruction, however, this creates more; micro-ops and requires the load-store unit to be involved. Currently, we place; the value into a virtual register and allow the register allocator to decide; when the register pressure is sufficient to make it worth spilling to memory; and reloading. #### Hardening Loads. Once we have the predicate accumulated into a special value for correct vs.; misspeculated, we need to apply this to loads in a way that ensures they do not; leak secret data. There are two primary techniques for this: we can either; harden the loaded value to prevent observation, or we can harden the address; itself to prevent the load from occurring. These have significantly different; performance tradeoffs. ##### Hardening loaded values. The most appealing way to harden loads is to mask out all of the bits loaded.; The key requirement is that for each bit loaded, along the misspeculated path; that bit is always fixed at either 0 or 1 regardless of the value of the bit; loaded. The most obvious implementation uses either an `and` instruction with; an all-zero mask along misspeculated paths and an all-one mask along correct; paths, or an `or` instruction with an all-one mask along misspeculated paths; and an all-zero mask along correct paths. Other options become less appealing; such as multiplying by zero, or multiple shift instructions. For reasons we; elaborate on below, we end up suggesting you use `or` with an all-ones mask,; making the x86 instruction sequence look like the following:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; movl (%rsi), %edi # Load potentially secret data from %rsi.; orl %eax, %edi; ```. Other useful patterns may be to fold the load into the `or` instruction itself; at the cost of a regi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:23068,Availability,mask,mask,23068,"a virtual register and allow the register allocator to decide; when the register pressure is sufficient to make it worth spilling to memory; and reloading. #### Hardening Loads. Once we have the predicate accumulated into a special value for correct vs.; misspeculated, we need to apply this to loads in a way that ensures they do not; leak secret data. There are two primary techniques for this: we can either; harden the loaded value to prevent observation, or we can harden the address; itself to prevent the load from occurring. These have significantly different; performance tradeoffs. ##### Hardening loaded values. The most appealing way to harden loads is to mask out all of the bits loaded.; The key requirement is that for each bit loaded, along the misspeculated path; that bit is always fixed at either 0 or 1 regardless of the value of the bit; loaded. The most obvious implementation uses either an `and` instruction with; an all-zero mask along misspeculated paths and an all-one mask along correct; paths, or an `or` instruction with an all-one mask along misspeculated paths; and an all-zero mask along correct paths. Other options become less appealing; such as multiplying by zero, or multiple shift instructions. For reasons we; elaborate on below, we end up suggesting you use `or` with an all-ones mask,; making the x86 instruction sequence look like the following:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; movl (%rsi), %edi # Load potentially secret data from %rsi.; orl %eax, %edi; ```. Other useful patterns may be to fold the load into the `or` instruction itself; at the cost of a register-to-register copy. There are some challenges with deploying this approach:; 1. Many loads on x86 are folded into other instructions. Separating them would; add very significant and costly register pressure with prohibitive; performance cost.; 1. Loads may not target a general purpose register requiring extra instructions; to map the s",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:23114,Availability,mask,mask,23114,"a virtual register and allow the register allocator to decide; when the register pressure is sufficient to make it worth spilling to memory; and reloading. #### Hardening Loads. Once we have the predicate accumulated into a special value for correct vs.; misspeculated, we need to apply this to loads in a way that ensures they do not; leak secret data. There are two primary techniques for this: we can either; harden the loaded value to prevent observation, or we can harden the address; itself to prevent the load from occurring. These have significantly different; performance tradeoffs. ##### Hardening loaded values. The most appealing way to harden loads is to mask out all of the bits loaded.; The key requirement is that for each bit loaded, along the misspeculated path; that bit is always fixed at either 0 or 1 regardless of the value of the bit; loaded. The most obvious implementation uses either an `and` instruction with; an all-zero mask along misspeculated paths and an all-one mask along correct; paths, or an `or` instruction with an all-one mask along misspeculated paths; and an all-zero mask along correct paths. Other options become less appealing; such as multiplying by zero, or multiple shift instructions. For reasons we; elaborate on below, we end up suggesting you use `or` with an all-ones mask,; making the x86 instruction sequence look like the following:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; movl (%rsi), %edi # Load potentially secret data from %rsi.; orl %eax, %edi; ```. Other useful patterns may be to fold the load into the `or` instruction itself; at the cost of a register-to-register copy. There are some challenges with deploying this approach:; 1. Many loads on x86 are folded into other instructions. Separating them would; add very significant and costly register pressure with prohibitive; performance cost.; 1. Loads may not target a general purpose register requiring extra instructions; to map the s",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:23180,Availability,mask,mask,23180,"a virtual register and allow the register allocator to decide; when the register pressure is sufficient to make it worth spilling to memory; and reloading. #### Hardening Loads. Once we have the predicate accumulated into a special value for correct vs.; misspeculated, we need to apply this to loads in a way that ensures they do not; leak secret data. There are two primary techniques for this: we can either; harden the loaded value to prevent observation, or we can harden the address; itself to prevent the load from occurring. These have significantly different; performance tradeoffs. ##### Hardening loaded values. The most appealing way to harden loads is to mask out all of the bits loaded.; The key requirement is that for each bit loaded, along the misspeculated path; that bit is always fixed at either 0 or 1 regardless of the value of the bit; loaded. The most obvious implementation uses either an `and` instruction with; an all-zero mask along misspeculated paths and an all-one mask along correct; paths, or an `or` instruction with an all-one mask along misspeculated paths; and an all-zero mask along correct paths. Other options become less appealing; such as multiplying by zero, or multiple shift instructions. For reasons we; elaborate on below, we end up suggesting you use `or` with an all-ones mask,; making the x86 instruction sequence look like the following:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; movl (%rsi), %edi # Load potentially secret data from %rsi.; orl %eax, %edi; ```. Other useful patterns may be to fold the load into the `or` instruction itself; at the cost of a register-to-register copy. There are some challenges with deploying this approach:; 1. Many loads on x86 are folded into other instructions. Separating them would; add very significant and costly register pressure with prohibitive; performance cost.; 1. Loads may not target a general purpose register requiring extra instructions; to map the s",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:23228,Availability,mask,mask,23228,"a virtual register and allow the register allocator to decide; when the register pressure is sufficient to make it worth spilling to memory; and reloading. #### Hardening Loads. Once we have the predicate accumulated into a special value for correct vs.; misspeculated, we need to apply this to loads in a way that ensures they do not; leak secret data. There are two primary techniques for this: we can either; harden the loaded value to prevent observation, or we can harden the address; itself to prevent the load from occurring. These have significantly different; performance tradeoffs. ##### Hardening loaded values. The most appealing way to harden loads is to mask out all of the bits loaded.; The key requirement is that for each bit loaded, along the misspeculated path; that bit is always fixed at either 0 or 1 regardless of the value of the bit; loaded. The most obvious implementation uses either an `and` instruction with; an all-zero mask along misspeculated paths and an all-one mask along correct; paths, or an `or` instruction with an all-one mask along misspeculated paths; and an all-zero mask along correct paths. Other options become less appealing; such as multiplying by zero, or multiple shift instructions. For reasons we; elaborate on below, we end up suggesting you use `or` with an all-ones mask,; making the x86 instruction sequence look like the following:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; movl (%rsi), %edi # Load potentially secret data from %rsi.; orl %eax, %edi; ```. Other useful patterns may be to fold the load into the `or` instruction itself; at the cost of a register-to-register copy. There are some challenges with deploying this approach:; 1. Many loads on x86 are folded into other instructions. Separating them would; add very significant and costly register pressure with prohibitive; performance cost.; 1. Loads may not target a general purpose register requiring extra instructions; to map the s",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:23439,Availability,mask,mask,23439," ensures they do not; leak secret data. There are two primary techniques for this: we can either; harden the loaded value to prevent observation, or we can harden the address; itself to prevent the load from occurring. These have significantly different; performance tradeoffs. ##### Hardening loaded values. The most appealing way to harden loads is to mask out all of the bits loaded.; The key requirement is that for each bit loaded, along the misspeculated path; that bit is always fixed at either 0 or 1 regardless of the value of the bit; loaded. The most obvious implementation uses either an `and` instruction with; an all-zero mask along misspeculated paths and an all-one mask along correct; paths, or an `or` instruction with an all-one mask along misspeculated paths; and an all-zero mask along correct paths. Other options become less appealing; such as multiplying by zero, or multiple shift instructions. For reasons we; elaborate on below, we end up suggesting you use `or` with an all-ones mask,; making the x86 instruction sequence look like the following:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; movl (%rsi), %edi # Load potentially secret data from %rsi.; orl %eax, %edi; ```. Other useful patterns may be to fold the load into the `or` instruction itself; at the cost of a register-to-register copy. There are some challenges with deploying this approach:; 1. Many loads on x86 are folded into other instructions. Separating them would; add very significant and costly register pressure with prohibitive; performance cost.; 1. Loads may not target a general purpose register requiring extra instructions; to map the state value into the correct register class, and potentially more; expensive instructions to mask the value in some way.; 1. The flags registers on x86 are very likely to be live, and challenging to; preserve cheaply.; 1. There are many more values loaded than pointers & indices used for loads. As; a consequence, ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:24211,Availability,mask,mask,24211," paths, or an `or` instruction with an all-one mask along misspeculated paths; and an all-zero mask along correct paths. Other options become less appealing; such as multiplying by zero, or multiple shift instructions. For reasons we; elaborate on below, we end up suggesting you use `or` with an all-ones mask,; making the x86 instruction sequence look like the following:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; movl (%rsi), %edi # Load potentially secret data from %rsi.; orl %eax, %edi; ```. Other useful patterns may be to fold the load into the `or` instruction itself; at the cost of a register-to-register copy. There are some challenges with deploying this approach:; 1. Many loads on x86 are folded into other instructions. Separating them would; add very significant and costly register pressure with prohibitive; performance cost.; 1. Loads may not target a general purpose register requiring extra instructions; to map the state value into the correct register class, and potentially more; expensive instructions to mask the value in some way.; 1. The flags registers on x86 are very likely to be live, and challenging to; preserve cheaply.; 1. There are many more values loaded than pointers & indices used for loads. As; a consequence, hardening the result of a load requires substantially more; instructions than hardening the address of the load (see below). Despite these challenges, hardening the result of the load critically allows; the load to proceed and thus has dramatically less impact on the total; speculative / out-of-order potential of the execution. There are also several; interesting techniques to try and mitigate these challenges and make hardening; the results of loads viable in at least some cases. However, we generally; expect to fall back when unprofitable from hardening the loaded value to the; next approach of hardening the address itself. ###### Loads folded into data-invariant operations can be hardened",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:26055,Availability,down,down,26055,"dress itself. ###### Loads folded into data-invariant operations can be hardened after the operation. The first key to making this feasible is to recognize that many operations on; x86 are ""data-invariant"". That is, they have no (known) observable behavior; differences due to the particular input data. These instructions are often used; when implementing cryptographic primitives dealing with private key data; because they are not believed to provide any side-channels. Similarly, we can; defer hardening until after them as they will not in-and-of-themselves; introduce a speculative execution side-channel. This results in code sequences; that look like:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate without leaking.; orl %eax, %edi; ```. While an addition happens to the loaded (potentially secret) value, that; doesn't leak any data and we then immediately harden it. ###### Hardening of loaded values deferred down the data-invariant expression graph. We can generalize the previous idea and sink the hardening down the expression; graph across as many data-invariant operations as desirable. This can use very; conservative rules for whether something is data-invariant. The primary goal; should be to handle multiple loads with a single hardening instruction:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate without leaking.; addl 4(%rsi), %edi # Continue without leaking.; addl 8(%rsi), %edi; orl %eax, %edi # Mask out bits from all three loads.; ```. ###### Preserving the flags while hardening loaded values on Haswell, Zen, and newer processors. Sadly, there are no useful instructions on x86 that apply a mask to all 64 bits; without touching the flag registers. However, we can harden loaded values that; are narrower than a word (fewer than 32-bits on 32-bit systems and fewer than; 64-bits on 64-bit systems) by zero-e",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:26156,Availability,down,down,26156,"ey to making this feasible is to recognize that many operations on; x86 are ""data-invariant"". That is, they have no (known) observable behavior; differences due to the particular input data. These instructions are often used; when implementing cryptographic primitives dealing with private key data; because they are not believed to provide any side-channels. Similarly, we can; defer hardening until after them as they will not in-and-of-themselves; introduce a speculative execution side-channel. This results in code sequences; that look like:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate without leaking.; orl %eax, %edi; ```. While an addition happens to the loaded (potentially secret) value, that; doesn't leak any data and we then immediately harden it. ###### Hardening of loaded values deferred down the data-invariant expression graph. We can generalize the previous idea and sink the hardening down the expression; graph across as many data-invariant operations as desirable. This can use very; conservative rules for whether something is data-invariant. The primary goal; should be to handle multiple loads with a single hardening instruction:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate without leaking.; addl 4(%rsi), %edi # Continue without leaking.; addl 8(%rsi), %edi; orl %eax, %edi # Mask out bits from all three loads.; ```. ###### Preserving the flags while hardening loaded values on Haswell, Zen, and newer processors. Sadly, there are no useful instructions on x86 that apply a mask to all 64 bits; without touching the flag registers. However, we can harden loaded values that; are narrower than a word (fewer than 32-bits on 32-bit systems and fewer than; 64-bits on 64-bit systems) by zero-extending the value to the full word size; and then shifting right by at least the number of original bits using t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:26838,Availability,mask,mask,26838,"ulate without leaking.; orl %eax, %edi; ```. While an addition happens to the loaded (potentially secret) value, that; doesn't leak any data and we then immediately harden it. ###### Hardening of loaded values deferred down the data-invariant expression graph. We can generalize the previous idea and sink the hardening down the expression; graph across as many data-invariant operations as desirable. This can use very; conservative rules for whether something is data-invariant. The primary goal; should be to handle multiple loads with a single hardening instruction:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate without leaking.; addl 4(%rsi), %edi # Continue without leaking.; addl 8(%rsi), %edi; orl %eax, %edi # Mask out bits from all three loads.; ```. ###### Preserving the flags while hardening loaded values on Haswell, Zen, and newer processors. Sadly, there are no useful instructions on x86 that apply a mask to all 64 bits; without touching the flag registers. However, we can harden loaded values that; are narrower than a word (fewer than 32-bits on 32-bit systems and fewer than; 64-bits on 64-bit systems) by zero-extending the value to the full word size; and then shifting right by at least the number of original bits using the BMI2; `shrx` instruction:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate 32 bits of data.; shrxq %rax, %rdi, %rdi # Shift out all 32 bits loaded.; ```. Because on x86 the zero-extend is free, this can efficiently harden the loaded; value. ##### Hardening the address of the load. When hardening the loaded value is inapplicable, most often because the; instruction directly leaks information (like `cmp` or `jmpq`), we switch to; hardening the _address_ of the load instead of the loaded value. This avoids; increasing register pressure by unfolding the load or paying some other high",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:29981,Availability,fault,fault,29981,"operating system; to preclude mapping memory in the low two gigabytes of address space. ###### 64-bit load checking instructions. We can use the following instruction sequences to check loads. We set up `%r8`; in these examples to hold the special value of `-1` which will be `cmov`ed over; `%rax` in misspeculated paths. Single register addressing mode:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rsi # Mask the pointer if misspeculating.; movl (%rsi), %edi; ```. Two register addressing mode:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rsi # Mask the pointer if misspeculating.; orq %rax, %rcx # Mask the index if misspeculating.; movl (%rsi,%rcx), %edi; ```. This will result in a negative address near zero or in `offset` wrapping the; address space back to a small positive address. Small, negative addresses will; fault in user-mode for most operating systems, but targets which need the high; address space to be user accessible may need to adjust the exact sequence used; above. Additionally, the low addresses will need to be marked unreadable by the; OS to fully harden the load. ###### RIP-relative addressing is even easier to break. There is a common addressing mode idiom that is substantially harder to check:; addressing relative to the instruction pointer. We cannot change the value of; the instruction pointer register and so we have the harder problem of forcing; `%base + scale * %index + offset` to be an invalid address, by *only* changing; `%index`. The only advantage we have is that the attacker also cannot modify; `%base`. If we use the fast instruction sequence above, but only apply it to; the index, we will always access `%rip + (scale * -1) + offset`. If the; attacker can find a load which with this address happens to point to secret; data, then they can reach it. However, the loader and base libraries can also; simply refuse to map the heap, data se",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:31453,Availability,alive,alive,31453,"instruction pointer. We cannot change the value of; the instruction pointer register and so we have the harder problem of forcing; `%base + scale * %index + offset` to be an invalid address, by *only* changing; `%index`. The only advantage we have is that the attacker also cannot modify; `%base`. If we use the fast instruction sequence above, but only apply it to; the index, we will always access `%rip + (scale * -1) + offset`. If the; attacker can find a load which with this address happens to point to secret; data, then they can reach it. However, the loader and base libraries can also; simply refuse to map the heap, data segments, or stack within 2gb of any of the; text in the program, much like it can reserve the low 2gb of address space. ###### The flag registers again make everything hard. Unfortunately, the technique of using `orq`-instructions has a serious flaw on; x86. The very thing that makes it easy to accumulate state, the flag registers; containing predicates, causes serious problems here because they may be alive; and used by the loading instruction or subsequent instructions. On x86, the; `orq` instruction **sets** the flags and will override anything already there.; This makes inserting them into the instruction stream very hazardous.; Unfortunately, unlike when hardening the loaded value, we have no fallback here; and so we must have a fully general approach available. The first thing we must do when generating these sequences is try to analyze; the surrounding code to prove that the flags are not in fact alive or being; used. Typically, it has been set by some other instruction which just happens; to set the flags register (much like ours!) with no actual dependency. In those; cases, it is safe to directly insert these instructions. Alternatively we may; be able to move them earlier to avoid clobbering the used value. However, this may ultimately be impossible. In that case, we need to preserve; the flags around these instructions:; ```; ... .LBB",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:31814,Availability,avail,available,31814,"ve, but only apply it to; the index, we will always access `%rip + (scale * -1) + offset`. If the; attacker can find a load which with this address happens to point to secret; data, then they can reach it. However, the loader and base libraries can also; simply refuse to map the heap, data segments, or stack within 2gb of any of the; text in the program, much like it can reserve the low 2gb of address space. ###### The flag registers again make everything hard. Unfortunately, the technique of using `orq`-instructions has a serious flaw on; x86. The very thing that makes it easy to accumulate state, the flag registers; containing predicates, causes serious problems here because they may be alive; and used by the loading instruction or subsequent instructions. On x86, the; `orq` instruction **sets** the flags and will override anything already there.; This makes inserting them into the instruction stream very hazardous.; Unfortunately, unlike when hardening the loaded value, we have no fallback here; and so we must have a fully general approach available. The first thing we must do when generating these sequences is try to analyze; the surrounding code to prove that the flags are not in fact alive or being; used. Typically, it has been set by some other instruction which just happens; to set the flags register (much like ours!) with no actual dependency. In those; cases, it is safe to directly insert these instructions. Alternatively we may; be able to move them earlier to avoid clobbering the used value. However, this may ultimately be impossible. In that case, we need to preserve; the flags around these instructions:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; pushfq; orq %rax, %rcx # Mask the pointer if misspeculating.; orq %rax, %rdx # Mask the index if misspeculating.; popfq; movl (%rcx,%rdx), %edi; ```. Using the `pushf` and `popf` instructions saves the flags register around our; inserted code, but comes at a high co",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:31964,Availability,alive,alive,31964,"appens to point to secret; data, then they can reach it. However, the loader and base libraries can also; simply refuse to map the heap, data segments, or stack within 2gb of any of the; text in the program, much like it can reserve the low 2gb of address space. ###### The flag registers again make everything hard. Unfortunately, the technique of using `orq`-instructions has a serious flaw on; x86. The very thing that makes it easy to accumulate state, the flag registers; containing predicates, causes serious problems here because they may be alive; and used by the loading instruction or subsequent instructions. On x86, the; `orq` instruction **sets** the flags and will override anything already there.; This makes inserting them into the instruction stream very hazardous.; Unfortunately, unlike when hardening the loaded value, we have no fallback here; and so we must have a fully general approach available. The first thing we must do when generating these sequences is try to analyze; the surrounding code to prove that the flags are not in fact alive or being; used. Typically, it has been set by some other instruction which just happens; to set the flags register (much like ours!) with no actual dependency. In those; cases, it is safe to directly insert these instructions. Alternatively we may; be able to move them earlier to avoid clobbering the used value. However, this may ultimately be impossible. In that case, we need to preserve; the flags around these instructions:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; pushfq; orq %rax, %rcx # Mask the pointer if misspeculating.; orq %rax, %rdx # Mask the index if misspeculating.; popfq; movl (%rcx,%rdx), %edi; ```. Using the `pushf` and `popf` instructions saves the flags register around our; inserted code, but comes at a high cost. First, we must store the flags to the; stack and reload them. Second, this causes the stack pointer to be adjusted; dynamically, requiring a frame",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:33567,Availability,avail,available,33567,"ing.; popfq; movl (%rcx,%rdx), %edi; ```. Using the `pushf` and `popf` instructions saves the flags register around our; inserted code, but comes at a high cost. First, we must store the flags to the; stack and reload them. Second, this causes the stack pointer to be adjusted; dynamically, requiring a frame pointer be used for referring to temporaries; spilled to the stack, etc. On newer x86 processors we can use the `lahf` and `sahf` instructions to save; all of the flags besides the overflow flag in a register rather than on the; stack. We can then use `seto` and `add` to save and restore the overflow flag; in a register. Combined, this will save and restore flags in the same manner as; above but using two registers rather than the stack. That is still very; expensive if slightly less expensive than `pushf` and `popf` in most cases. ###### A flag-less alternative on Haswell, Zen and newer processors. Starting with the BMI2 x86 instruction set extensions available on Haswell and; Zen processors, there is an instruction for shifting that does not set any; flags: `shrx`. We can use this and the `lea` instruction to implement analogous; code sequences to the above ones. However, these are still very marginally; slower, as there are fewer ports able to dispatch shift instructions in most; modern x86 processors than there are for `or` instructions. Fast, single register addressing mode:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; shrxq %rax, %rsi, %rsi # Shift away bits if misspeculating.; movl (%rsi), %edi; ```. This will collapse the register to zero or one, and everything but the offset; in the addressing mode to be less than or equal to 9. This means the full; address can only be guaranteed to be less than `(1 << 31) + 9`. The OS may wish; to protect an extra page of the low address space to account for this. ##### Optimizations. A very large portion of the cost for this approach comes from checking loads in; this way, so ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:37000,Availability,failure,failure,37000,"di # Hardened load.; movl (%rdi), %edx # Unhardened load due to dependent addr.; ```. This doesn't check the load through `%rdi` as that pointer is dependent on a; checked load already. ###### Protect large, load-heavy blocks with a single lfence. It may be worth using a single `lfence` instruction at the start of a block; which begins with a (very) large number of loads that require independent; protection *and* which require hardening the address of the load. However, this; is unlikely to be profitable in practice. The latency hit of the hardening; would need to exceed that of an `lfence` when *correctly* speculatively; executed. But in that case, the `lfence` cost is a complete loss of speculative; execution (at a minimum). So far, the evidence we have of the performance cost; of using `lfence` indicates few if any hot code patterns where this trade off; would make sense. ###### Tempting optimizations that break the security model. Several optimizations were considered which didn't pan out due to failure to; uphold the security model. One in particular is worth discussing as many others; will reduce to it. We wondered whether only the *first* load in a basic block could be checked. If; the check works as intended, it forms an invalid pointer that doesn't even; virtual-address translate in the hardware. It should fault very early on in its; processing. Maybe that would stop things in time for the misspeculated path to; fail to leak any secrets. This doesn't end up working because the processor is; fundamentally out-of-order, even in its speculative domain. As a consequence,; the attacker could cause the initial address computation itself to stall and; allow an arbitrary number of unrelated loads (including attacked loads of; secret data) to pass through. #### Interprocedural Checking. Modern x86 processors may speculate into called functions and out of functions; to their return address. As a consequence, we need a way to check loads that; occur after a misspeculat",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:37322,Availability,fault,fault,37322," large number of loads that require independent; protection *and* which require hardening the address of the load. However, this; is unlikely to be profitable in practice. The latency hit of the hardening; would need to exceed that of an `lfence` when *correctly* speculatively; executed. But in that case, the `lfence` cost is a complete loss of speculative; execution (at a minimum). So far, the evidence we have of the performance cost; of using `lfence` indicates few if any hot code patterns where this trade off; would make sense. ###### Tempting optimizations that break the security model. Several optimizations were considered which didn't pan out due to failure to; uphold the security model. One in particular is worth discussing as many others; will reduce to it. We wondered whether only the *first* load in a basic block could be checked. If; the check works as intended, it forms an invalid pointer that doesn't even; virtual-address translate in the hardware. It should fault very early on in its; processing. Maybe that would stop things in time for the misspeculated path to; fail to leak any secrets. This doesn't end up working because the processor is; fundamentally out-of-order, even in its speculative domain. As a consequence,; the attacker could cause the initial address computation itself to stall and; allow an arbitrary number of unrelated loads (including attacked loads of; secret data) to pass through. #### Interprocedural Checking. Modern x86 processors may speculate into called functions and out of functions; to their return address. As a consequence, we need a way to check loads that; occur after a misspeculated predicate but where the load and the misspeculated; predicate are in different functions. In essence, we need some interprocedural; generalization of the predicate state tracking. A primary challenge to passing; the predicate state between functions is that we would like to not require a; change to the ABI or calling convention in order to make ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:44044,Availability,mask,masking,44044,"ected to be substantially more expensive even than using; `%rsp` and potentially `lfence` within the function entry block. ##### Define a new ABI and/or calling convention. We could define a new ABI and/or calling convention to explicitly pass the; predicate state in and out of functions. This may be interesting if none of the; alternatives have adequate performance, but it makes deployment and adoption; dramatically more complex, and potentially infeasible. ## High-Level Alternative Mitigation Strategies. There are completely different alternative approaches to mitigating variant 1; attacks. [Most](https://lwn.net/Articles/743265/); [discussion](https://lwn.net/Articles/744287/) so far focuses on mitigating; specific known attackable components in the Linux kernel (or other kernels) by; manually rewriting the code to contain an instruction sequence that is not; vulnerable. For x86 systems this is done by either injecting an `lfence`; instruction along the code path which would leak data if executed speculatively; or by rewriting memory accesses to have branch-less masking to a known safe; region. On Intel systems, `lfence` [will prevent the speculative load of secret; data](https://newsroom.intel.com/wp-content/uploads/sites/11/2018/01/Intel-Analysis-of-Speculative-Execution-Side-Channels.pdf).; On AMD systems `lfence` is currently a no-op, but can be made; dispatch-serializing by setting an MSR, and thus preclude misspeculation of the; code path ([mitigation G-2 +; V1-1](https://developer.amd.com/wp-content/resources/Managing-Speculation-on-AMD-Processors.pdf)). However, this relies on finding and enumerating all possible points in code; which could be attacked to leak information. While in some cases static; analysis is effective at doing this at scale, in many cases it still relies on; human judgement to evaluate whether code might be vulnerable. Especially for; software systems which receive less detailed scrutiny but remain sensitive to; these attacks, this se",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:4899,Deployability,update,update,4899,"ate_state = !condition ? all_zeros_mask : predicate_state;; // ... lots of code ...; //; // Harden the pointer so it can't be loaded; pointer1 &= predicate_state;; leak(*pointer1);; } else {; predicate_state = condition ? all_zeros_mask : predicate_state;; // ... more code ...; //; // Alternative: Harden the loaded value; int value2 = *pointer2 & predicate_state;; leak(value2);; }; }; ```. The result should be that if the `if (condition) {` branch is mis-predicted,; there is a *data* dependency on the condition used to zero out any pointers; prior to loading through them or to zero out all of the loaded bits. Even; though this code pattern may still execute speculatively, *invalid* speculative; executions are prevented from leaking secret data from memory (but note that; this data might still be loaded in safe ways, and some regions of memory are; required to not hold secrets, see below for detailed limitations). This; approach only requires the underlying hardware have a way to implement a; branchless and unpredicted conditional update of a register's value. All modern; architectures have support for this, and in fact such support is necessary to; correctly implement constant time cryptographic primitives. Crucial properties of this approach:; * It is not preventing any particular side-channel from working. This is; important as there are an unknown number of potential side channels and we; expect to continue discovering more. Instead, it prevents the observation of; secret data in the first place.; * It accumulates the predicate state, protecting even in the face of nested; *correctly* predicted control flows.; * It passes this predicate state across function boundaries to provide; [interprocedural protection](#interprocedural-checking).; * When hardening the address of a load, it uses a *destructive* or; *non-reversible* modification of the address to prevent an attacker from; reversing the check using attacker-controlled inputs.; * It does not completely block sp",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:6166,Deployability,update,updates,6166," approach:; * It is not preventing any particular side-channel from working. This is; important as there are an unknown number of potential side channels and we; expect to continue discovering more. Instead, it prevents the observation of; secret data in the first place.; * It accumulates the predicate state, protecting even in the face of nested; *correctly* predicted control flows.; * It passes this predicate state across function boundaries to provide; [interprocedural protection](#interprocedural-checking).; * When hardening the address of a load, it uses a *destructive* or; *non-reversible* modification of the address to prevent an attacker from; reversing the check using attacker-controlled inputs.; * It does not completely block speculative execution, and merely prevents; *mis*-speculated paths from leaking secrets from memory (and stalls; speculation until this can be determined).; * It is completely general and makes no fundamental assumptions about the; underlying architecture other than the ability to do branchless conditional; data updates and a lack of value prediction.; * It does not require programmers to identify all possible secret data using; static source code annotations or code vulnerable to a variant #1 style; attack. Limitations of this approach:; * It requires re-compiling source code to insert hardening instruction; sequences. Only software compiled in this mode is protected.; * The performance is heavily dependent on a particular architecture's; implementation strategy. We outline a potential x86 implementation below and; characterize its performance.; * It does not defend against secret data already loaded from memory and; residing in registers or leaked through other side-channels in; non-speculative execution. Code dealing with this, e.g cryptographic; routines, already uses constant-time algorithms and code to prevent; side-channels. Such code should also scrub registers of secret data following; [these; guidelines](https://github.com/H",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:16668,Deployability,update,update,16668,"ted predicates have been misspeculated. To track that,; along each conditional edge, we need to track the data which would allow that; edge to be taken. On x86, this data is stored in the flags register used by the; conditional jump instruction. Along both edges after this fork in control flow,; the flags register remains alive and contains data that we can use to build up; our accumulated predicate state. We accumulate it using the x86 conditional; move instruction which also reads the flag registers where the state resides.; These conditional move instructions are known to not be predicted on any x86; processors, making them immune to misprediction that could reintroduce the; vulnerability. When we insert the conditional moves, the code ends up looking; like the following:; ```; # %bb.0: # %entry; pushq %rax; xorl %eax, %eax # Zero out initial predicate state.; movq $-1, %r8 # Put all-ones mask into a register.; testl %edi, %edi; jne .LBB0_1; # %bb.2: # %then1; cmovneq %r8, %rax # Conditionally update predicate state.; testl %esi, %esi; jne .LBB0_1; # %bb.3: # %then2; cmovneq %r8, %rax # Conditionally update predicate state.; testl %edx, %edx; je .LBB0_4; .LBB0_1:; cmoveq %r8, %rax # Conditionally update predicate state.; popq %rax; retq; .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; ...; ```. Here we create the ""empty"" or ""correct execution"" predicate state by zeroing; `%rax`, and we create a constant ""incorrect execution"" predicate value by; putting `-1` into `%r8`. Then, along each edge coming out of a conditional; branch we do a conditional move that in a correct execution will be a no-op,; but if misspeculated, will replace the `%rax` with the value of `%r8`.; Misspeculating any one of the three predicates will cause `%rax` to hold the; ""incorrect execution"" value from `%r8` as we preserve incoming values when; execution is correct rather than overwriting it. We now have a value in `%rax` in each basic block that indicates if ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:16777,Deployability,update,update,16777,"a which would allow that; edge to be taken. On x86, this data is stored in the flags register used by the; conditional jump instruction. Along both edges after this fork in control flow,; the flags register remains alive and contains data that we can use to build up; our accumulated predicate state. We accumulate it using the x86 conditional; move instruction which also reads the flag registers where the state resides.; These conditional move instructions are known to not be predicted on any x86; processors, making them immune to misprediction that could reintroduce the; vulnerability. When we insert the conditional moves, the code ends up looking; like the following:; ```; # %bb.0: # %entry; pushq %rax; xorl %eax, %eax # Zero out initial predicate state.; movq $-1, %r8 # Put all-ones mask into a register.; testl %edi, %edi; jne .LBB0_1; # %bb.2: # %then1; cmovneq %r8, %rax # Conditionally update predicate state.; testl %esi, %esi; jne .LBB0_1; # %bb.3: # %then2; cmovneq %r8, %rax # Conditionally update predicate state.; testl %edx, %edx; je .LBB0_4; .LBB0_1:; cmoveq %r8, %rax # Conditionally update predicate state.; popq %rax; retq; .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; ...; ```. Here we create the ""empty"" or ""correct execution"" predicate state by zeroing; `%rax`, and we create a constant ""incorrect execution"" predicate value by; putting `-1` into `%r8`. Then, along each edge coming out of a conditional; branch we do a conditional move that in a correct execution will be a no-op,; but if misspeculated, will replace the `%rax` with the value of `%r8`.; Misspeculating any one of the three predicates will cause `%rax` to hold the; ""incorrect execution"" value from `%r8` as we preserve incoming values when; execution is correct rather than overwriting it. We now have a value in `%rax` in each basic block that indicates if at some; point previously a predicate was mispredicted. And we have arranged for that; value to be particular",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:16875,Deployability,update,update,16875,"y the; conditional jump instruction. Along both edges after this fork in control flow,; the flags register remains alive and contains data that we can use to build up; our accumulated predicate state. We accumulate it using the x86 conditional; move instruction which also reads the flag registers where the state resides.; These conditional move instructions are known to not be predicted on any x86; processors, making them immune to misprediction that could reintroduce the; vulnerability. When we insert the conditional moves, the code ends up looking; like the following:; ```; # %bb.0: # %entry; pushq %rax; xorl %eax, %eax # Zero out initial predicate state.; movq $-1, %r8 # Put all-ones mask into a register.; testl %edi, %edi; jne .LBB0_1; # %bb.2: # %then1; cmovneq %r8, %rax # Conditionally update predicate state.; testl %esi, %esi; jne .LBB0_1; # %bb.3: # %then2; cmovneq %r8, %rax # Conditionally update predicate state.; testl %edx, %edx; je .LBB0_4; .LBB0_1:; cmoveq %r8, %rax # Conditionally update predicate state.; popq %rax; retq; .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; ...; ```. Here we create the ""empty"" or ""correct execution"" predicate state by zeroing; `%rax`, and we create a constant ""incorrect execution"" predicate value by; putting `-1` into `%r8`. Then, along each edge coming out of a conditional; branch we do a conditional move that in a correct execution will be a no-op,; but if misspeculated, will replace the `%rax` with the value of `%r8`.; Misspeculating any one of the three predicates will cause `%rax` to hold the; ""incorrect execution"" value from `%r8` as we preserve incoming values when; execution is correct rather than overwriting it. We now have a value in `%rax` in each basic block that indicates if at some; point previously a predicate was mispredicted. And we have arranged for that; value to be particularly effective when used below to harden loads. ##### Indirect Call, Branch, and Return Predicates. The",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:16971,Deployability,update,update,16971," flags register remains alive and contains data that we can use to build up; our accumulated predicate state. We accumulate it using the x86 conditional; move instruction which also reads the flag registers where the state resides.; These conditional move instructions are known to not be predicted on any x86; processors, making them immune to misprediction that could reintroduce the; vulnerability. When we insert the conditional moves, the code ends up looking; like the following:; ```; # %bb.0: # %entry; pushq %rax; xorl %eax, %eax # Zero out initial predicate state.; movq $-1, %r8 # Put all-ones mask into a register.; testl %edi, %edi; jne .LBB0_1; # %bb.2: # %then1; cmovneq %r8, %rax # Conditionally update predicate state.; testl %esi, %esi; jne .LBB0_1; # %bb.3: # %then2; cmovneq %r8, %rax # Conditionally update predicate state.; testl %edx, %edx; je .LBB0_4; .LBB0_1:; cmoveq %r8, %rax # Conditionally update predicate state.; popq %rax; retq; .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; ...; ```. Here we create the ""empty"" or ""correct execution"" predicate state by zeroing; `%rax`, and we create a constant ""incorrect execution"" predicate value by; putting `-1` into `%r8`. Then, along each edge coming out of a conditional; branch we do a conditional move that in a correct execution will be a no-op,; but if misspeculated, will replace the `%rax` with the value of `%r8`.; Misspeculating any one of the three predicates will cause `%rax` to hold the; ""incorrect execution"" value from `%r8` as we preserve incoming values when; execution is correct rather than overwriting it. We now have a value in `%rax` in each basic block that indicates if at some; point previously a predicate was mispredicted. And we have arranged for that; value to be particularly effective when used below to harden loads. ##### Indirect Call, Branch, and Return Predicates. There is no analogous flag to use when tracing indirect calls, branches, and; returns. The pr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:18596,Deployability,update,update,18596,"e now have a value in `%rax` in each basic block that indicates if at some; point previously a predicate was mispredicted. And we have arranged for that; value to be particularly effective when used below to harden loads. ##### Indirect Call, Branch, and Return Predicates. There is no analogous flag to use when tracing indirect calls, branches, and; returns. The predicate state must be accumulated through some other means.; Fundamentally, this is the reverse of the problem posed in CFI: we need to; check where we came from rather than where we are going. For function-local; jump tables, this is easily arranged by testing the input to the jump table; within each destination (not yet implemented, use retpolines):; ```; pushq %rax; xorl %eax, %eax # Zero out initial predicate state.; movq $-1, %r8 # Put all-ones mask into a register.; jmpq *.LJTI0_0(,%rdi,8) # Indirect jump through table.; .LBB0_2: # %sw.bb; testq $0, %rdi # Validate index used for jump table.; cmovneq %r8, %rax # Conditionally update predicate state.; ...; jmp _Z4leaki # TAILCALL. .LBB0_3: # %sw.bb1; testq $1, %rdi # Validate index used for jump table.; cmovneq %r8, %rax # Conditionally update predicate state.; ...; jmp _Z4leaki # TAILCALL. .LBB0_5: # %sw.bb10; testq $2, %rdi # Validate index used for jump table.; cmovneq %r8, %rax # Conditionally update predicate state.; ...; jmp _Z4leaki # TAILCALL; ... .section .rodata,""a"",@progbits; .p2align 3; .LJTI0_0:; .quad .LBB0_2; .quad .LBB0_3; .quad .LBB0_5; ...; ```. Returns have a simple mitigation technique on x86-64 (or other ABIs which have; what is called a ""red zone"" region beyond the end of the stack). This region is; guaranteed to be preserved across interrupts and context switches, making the; return address used in returning to the current code remain on the stack and; valid to read. We can emit code in the caller to verify that a return edge was; not mispredicted:; ```; callq other_function; return_addr:; testq -8(%rsp), return_addr # Validate r",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:18759,Deployability,update,update,18759,"be particularly effective when used below to harden loads. ##### Indirect Call, Branch, and Return Predicates. There is no analogous flag to use when tracing indirect calls, branches, and; returns. The predicate state must be accumulated through some other means.; Fundamentally, this is the reverse of the problem posed in CFI: we need to; check where we came from rather than where we are going. For function-local; jump tables, this is easily arranged by testing the input to the jump table; within each destination (not yet implemented, use retpolines):; ```; pushq %rax; xorl %eax, %eax # Zero out initial predicate state.; movq $-1, %r8 # Put all-ones mask into a register.; jmpq *.LJTI0_0(,%rdi,8) # Indirect jump through table.; .LBB0_2: # %sw.bb; testq $0, %rdi # Validate index used for jump table.; cmovneq %r8, %rax # Conditionally update predicate state.; ...; jmp _Z4leaki # TAILCALL. .LBB0_3: # %sw.bb1; testq $1, %rdi # Validate index used for jump table.; cmovneq %r8, %rax # Conditionally update predicate state.; ...; jmp _Z4leaki # TAILCALL. .LBB0_5: # %sw.bb10; testq $2, %rdi # Validate index used for jump table.; cmovneq %r8, %rax # Conditionally update predicate state.; ...; jmp _Z4leaki # TAILCALL; ... .section .rodata,""a"",@progbits; .p2align 3; .LJTI0_0:; .quad .LBB0_2; .quad .LBB0_3; .quad .LBB0_5; ...; ```. Returns have a simple mitigation technique on x86-64 (or other ABIs which have; what is called a ""red zone"" region beyond the end of the stack). This region is; guaranteed to be preserved across interrupts and context switches, making the; return address used in returning to the current code remain on the stack and; valid to read. We can emit code in the caller to verify that a return edge was; not mispredicted:; ```; callq other_function; return_addr:; testq -8(%rsp), return_addr # Validate return address.; cmovneq %r8, %rax # Update predicate state.; ```. For an ABI without a ""red zone"" (and thus unable to read the return address; from the stack), we ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:18923,Deployability,update,update,18923,"ct calls, branches, and; returns. The predicate state must be accumulated through some other means.; Fundamentally, this is the reverse of the problem posed in CFI: we need to; check where we came from rather than where we are going. For function-local; jump tables, this is easily arranged by testing the input to the jump table; within each destination (not yet implemented, use retpolines):; ```; pushq %rax; xorl %eax, %eax # Zero out initial predicate state.; movq $-1, %r8 # Put all-ones mask into a register.; jmpq *.LJTI0_0(,%rdi,8) # Indirect jump through table.; .LBB0_2: # %sw.bb; testq $0, %rdi # Validate index used for jump table.; cmovneq %r8, %rax # Conditionally update predicate state.; ...; jmp _Z4leaki # TAILCALL. .LBB0_3: # %sw.bb1; testq $1, %rdi # Validate index used for jump table.; cmovneq %r8, %rax # Conditionally update predicate state.; ...; jmp _Z4leaki # TAILCALL. .LBB0_5: # %sw.bb10; testq $2, %rdi # Validate index used for jump table.; cmovneq %r8, %rax # Conditionally update predicate state.; ...; jmp _Z4leaki # TAILCALL; ... .section .rodata,""a"",@progbits; .p2align 3; .LJTI0_0:; .quad .LBB0_2; .quad .LBB0_3; .quad .LBB0_5; ...; ```. Returns have a simple mitigation technique on x86-64 (or other ABIs which have; what is called a ""red zone"" region beyond the end of the stack). This region is; guaranteed to be preserved across interrupts and context switches, making the; return address used in returning to the current code remain on the stack and; valid to read. We can emit code in the caller to verify that a return edge was; not mispredicted:; ```; callq other_function; return_addr:; testq -8(%rsp), return_addr # Validate return address.; cmovneq %r8, %rax # Update predicate state.; ```. For an ABI without a ""red zone"" (and thus unable to read the return address; from the stack), we can compute the expected return address prior to the call; into a register preserved across the call and use that similarly to the above. Indirect calls (and return",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:20201,Deployability,deploy,deploy,20201,"a ""red zone"" region beyond the end of the stack). This region is; guaranteed to be preserved across interrupts and context switches, making the; return address used in returning to the current code remain on the stack and; valid to read. We can emit code in the caller to verify that a return edge was; not mispredicted:; ```; callq other_function; return_addr:; testq -8(%rsp), return_addr # Validate return address.; cmovneq %r8, %rax # Update predicate state.; ```. For an ABI without a ""red zone"" (and thus unable to read the return address; from the stack), we can compute the expected return address prior to the call; into a register preserved across the call and use that similarly to the above. Indirect calls (and returns in the absence of a red zone ABI) pose the most; significant challenge to propagate. The simplest technique would be to define a; new ABI such that the intended call target is passed into the called function; and checked in the entry. Unfortunately, new ABIs are quite expensive to deploy; in C and C++. While the target function could be passed in TLS, we would still; require complex logic to handle a mixture of functions compiled with and; without this extra logic (essentially, making the ABI backwards compatible).; Currently, we suggest using retpolines here and will continue to investigate; ways of mitigating this. ##### Optimizations, Alternatives, and Tradeoffs. Merely accumulating predicate state involves significant cost. There are; several key optimizations we employ to minimize this and various alternatives; that present different tradeoffs in the generated code. First, we work to reduce the number of instructions used to track the state:; * Rather than inserting a `cmovCC` instruction along every conditional edge in; the original program, we track each set of condition flags we need to capture; prior to entering each basic block and reuse a common `cmovCC` sequence for; those.; * We could further reuse suffixes when there are multiple `cmov",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:23571,Deployability,update,update,23571," prevent observation, or we can harden the address; itself to prevent the load from occurring. These have significantly different; performance tradeoffs. ##### Hardening loaded values. The most appealing way to harden loads is to mask out all of the bits loaded.; The key requirement is that for each bit loaded, along the misspeculated path; that bit is always fixed at either 0 or 1 regardless of the value of the bit; loaded. The most obvious implementation uses either an `and` instruction with; an all-zero mask along misspeculated paths and an all-one mask along correct; paths, or an `or` instruction with an all-one mask along misspeculated paths; and an all-zero mask along correct paths. Other options become less appealing; such as multiplying by zero, or multiple shift instructions. For reasons we; elaborate on below, we end up suggesting you use `or` with an all-ones mask,; making the x86 instruction sequence look like the following:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; movl (%rsi), %edi # Load potentially secret data from %rsi.; orl %eax, %edi; ```. Other useful patterns may be to fold the load into the `or` instruction itself; at the cost of a register-to-register copy. There are some challenges with deploying this approach:; 1. Many loads on x86 are folded into other instructions. Separating them would; add very significant and costly register pressure with prohibitive; performance cost.; 1. Loads may not target a general purpose register requiring extra instructions; to map the state value into the correct register class, and potentially more; expensive instructions to mask the value in some way.; 1. The flags registers on x86 are very likely to be live, and challenging to; preserve cheaply.; 1. There are many more values loaded than pointers & indices used for loads. As; a consequence, hardening the result of a load requires substantially more; instructions than hardening the address of the load (see below)",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:23833,Deployability,deploy,deploying,23833,"uirement is that for each bit loaded, along the misspeculated path; that bit is always fixed at either 0 or 1 regardless of the value of the bit; loaded. The most obvious implementation uses either an `and` instruction with; an all-zero mask along misspeculated paths and an all-one mask along correct; paths, or an `or` instruction with an all-one mask along misspeculated paths; and an all-zero mask along correct paths. Other options become less appealing; such as multiplying by zero, or multiple shift instructions. For reasons we; elaborate on below, we end up suggesting you use `or` with an all-ones mask,; making the x86 instruction sequence look like the following:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; movl (%rsi), %edi # Load potentially secret data from %rsi.; orl %eax, %edi; ```. Other useful patterns may be to fold the load into the `or` instruction itself; at the cost of a register-to-register copy. There are some challenges with deploying this approach:; 1. Many loads on x86 are folded into other instructions. Separating them would; add very significant and costly register pressure with prohibitive; performance cost.; 1. Loads may not target a general purpose register requiring extra instructions; to map the state value into the correct register class, and potentially more; expensive instructions to mask the value in some way.; 1. The flags registers on x86 are very likely to be live, and challenging to; preserve cheaply.; 1. There are many more values loaded than pointers & indices used for loads. As; a consequence, hardening the result of a load requires substantially more; instructions than hardening the address of the load (see below). Despite these challenges, hardening the result of the load critically allows; the load to proceed and thus has dramatically less impact on the total; speculative / out-of-order potential of the execution. There are also several; interesting techniques to try and mitigate t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:25777,Deployability,update,update,25777," There are also several; interesting techniques to try and mitigate these challenges and make hardening; the results of loads viable in at least some cases. However, we generally; expect to fall back when unprofitable from hardening the loaded value to the; next approach of hardening the address itself. ###### Loads folded into data-invariant operations can be hardened after the operation. The first key to making this feasible is to recognize that many operations on; x86 are ""data-invariant"". That is, they have no (known) observable behavior; differences due to the particular input data. These instructions are often used; when implementing cryptographic primitives dealing with private key data; because they are not believed to provide any side-channels. Similarly, we can; defer hardening until after them as they will not in-and-of-themselves; introduce a speculative execution side-channel. This results in code sequences; that look like:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate without leaking.; orl %eax, %edi; ```. While an addition happens to the loaded (potentially secret) value, that; doesn't leak any data and we then immediately harden it. ###### Hardening of loaded values deferred down the data-invariant expression graph. We can generalize the previous idea and sink the hardening down the expression; graph across as many data-invariant operations as desirable. This can use very; conservative rules for whether something is data-invariant. The primary goal; should be to handle multiple loads with a single hardening instruction:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate without leaking.; addl 4(%rsi), %edi # Continue without leaking.; addl 8(%rsi), %edi; orl %eax, %edi # Mask out bits from all three loads.; ```. ###### Preserving the flags while hardening loaded values on Haswell, Zen, and ne",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:26471,Deployability,update,update,26471,"key data; because they are not believed to provide any side-channels. Similarly, we can; defer hardening until after them as they will not in-and-of-themselves; introduce a speculative execution side-channel. This results in code sequences; that look like:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate without leaking.; orl %eax, %edi; ```. While an addition happens to the loaded (potentially secret) value, that; doesn't leak any data and we then immediately harden it. ###### Hardening of loaded values deferred down the data-invariant expression graph. We can generalize the previous idea and sink the hardening down the expression; graph across as many data-invariant operations as desirable. This can use very; conservative rules for whether something is data-invariant. The primary goal; should be to handle multiple loads with a single hardening instruction:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate without leaking.; addl 4(%rsi), %edi # Continue without leaking.; addl 8(%rsi), %edi; orl %eax, %edi # Mask out bits from all three loads.; ```. ###### Preserving the flags while hardening loaded values on Haswell, Zen, and newer processors. Sadly, there are no useful instructions on x86 that apply a mask to all 64 bits; without touching the flag registers. However, we can harden loaded values that; are narrower than a word (fewer than 32-bits on 32-bit systems and fewer than; 64-bits on 64-bit systems) by zero-extending the value to the full word size; and then shifting right by at least the number of original bits using the BMI2; `shrx` instruction:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate 32 bits of data.; shrxq %rax, %rdi, %rdi # Shift out all 32 bits loaded.; ```. Because on x86 the zero-extend is free, this can eff",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:27260,Deployability,update,update,27260,"n use very; conservative rules for whether something is data-invariant. The primary goal; should be to handle multiple loads with a single hardening instruction:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate without leaking.; addl 4(%rsi), %edi # Continue without leaking.; addl 8(%rsi), %edi; orl %eax, %edi # Mask out bits from all three loads.; ```. ###### Preserving the flags while hardening loaded values on Haswell, Zen, and newer processors. Sadly, there are no useful instructions on x86 that apply a mask to all 64 bits; without touching the flag registers. However, we can harden loaded values that; are narrower than a word (fewer than 32-bits on 32-bit systems and fewer than; 64-bits on 64-bit systems) by zero-extending the value to the full word size; and then shifting right by at least the number of original bits using the BMI2; `shrx` instruction:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate 32 bits of data.; shrxq %rax, %rdi, %rdi # Shift out all 32 bits loaded.; ```. Because on x86 the zero-extend is free, this can efficiently harden the loaded; value. ##### Hardening the address of the load. When hardening the loaded value is inapplicable, most often because the; instruction directly leaks information (like `cmp` or `jmpq`), we switch to; hardening the _address_ of the load instead of the loaded value. This avoids; increasing register pressure by unfolding the load or paying some other high; cost. To understand how this works in practice, we need to examine the exact; semantics of the x86 addressing modes which, in its fully general form, looks; like `(%base,%index,scale)offset`. Here `%base` and `%index` are 64-bit; registers that can potentially be any value, and may be attacker controlled,; and `scale` and `offset` are fixed immediate values. `scale` must be `1`, `2`,; `4`, or `8`, and `o",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:29466,Deployability,update,update,29466,"h this approach is that, after hardening, the `%base + (scale *; %index)` subexpression will compute a value near zero (`-1 + (scale * -1)`) and; then a large, positive `offset` will index into memory within the first two; gigabytes of address space. While these offsets are not attacker controlled,; the attacker could chose to attack a load which happens to have the desired; offset and then successfully read memory in that region. This significantly; raises the burden on the attacker and limits the scope of attack but does not; eliminate it. To fully close the attack we must work with the operating system; to preclude mapping memory in the low two gigabytes of address space. ###### 64-bit load checking instructions. We can use the following instruction sequences to check loads. We set up `%r8`; in these examples to hold the special value of `-1` which will be `cmov`ed over; `%rax` in misspeculated paths. Single register addressing mode:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rsi # Mask the pointer if misspeculating.; movl (%rsi), %edi; ```. Two register addressing mode:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rsi # Mask the pointer if misspeculating.; orq %rax, %rcx # Mask the index if misspeculating.; movl (%rsi,%rcx), %edi; ```. This will result in a negative address near zero or in `offset` wrapping the; address space back to a small positive address. Small, negative addresses will; fault in user-mode for most operating systems, but targets which need the high; address space to be user accessible may need to adjust the exact sequence used; above. Additionally, the low addresses will need to be marked unreadable by the; OS to fully harden the load. ###### RIP-relative addressing is even easier to break. There is a common addressing mode idiom that is substantially harder to check:; addressing relative to the instruction pointer. We cannot change",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:29663,Deployability,update,update,29663,"ory within the first two; gigabytes of address space. While these offsets are not attacker controlled,; the attacker could chose to attack a load which happens to have the desired; offset and then successfully read memory in that region. This significantly; raises the burden on the attacker and limits the scope of attack but does not; eliminate it. To fully close the attack we must work with the operating system; to preclude mapping memory in the low two gigabytes of address space. ###### 64-bit load checking instructions. We can use the following instruction sequences to check loads. We set up `%r8`; in these examples to hold the special value of `-1` which will be `cmov`ed over; `%rax` in misspeculated paths. Single register addressing mode:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rsi # Mask the pointer if misspeculating.; movl (%rsi), %edi; ```. Two register addressing mode:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rsi # Mask the pointer if misspeculating.; orq %rax, %rcx # Mask the index if misspeculating.; movl (%rsi,%rcx), %edi; ```. This will result in a negative address near zero or in `offset` wrapping the; address space back to a small positive address. Small, negative addresses will; fault in user-mode for most operating systems, but targets which need the high; address space to be user accessible may need to adjust the exact sequence used; above. Additionally, the low addresses will need to be marked unreadable by the; OS to fully harden the load. ###### RIP-relative addressing is even easier to break. There is a common addressing mode idiom that is substantially harder to check:; addressing relative to the instruction pointer. We cannot change the value of; the instruction pointer register and so we have the harder problem of forcing; `%base + scale * %index + offset` to be an invalid address, by *only* changing; `%index`. The only adva",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:32464,Deployability,update,update,32464," be alive; and used by the loading instruction or subsequent instructions. On x86, the; `orq` instruction **sets** the flags and will override anything already there.; This makes inserting them into the instruction stream very hazardous.; Unfortunately, unlike when hardening the loaded value, we have no fallback here; and so we must have a fully general approach available. The first thing we must do when generating these sequences is try to analyze; the surrounding code to prove that the flags are not in fact alive or being; used. Typically, it has been set by some other instruction which just happens; to set the flags register (much like ours!) with no actual dependency. In those; cases, it is safe to directly insert these instructions. Alternatively we may; be able to move them earlier to avoid clobbering the used value. However, this may ultimately be impossible. In that case, we need to preserve; the flags around these instructions:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; pushfq; orq %rax, %rcx # Mask the pointer if misspeculating.; orq %rax, %rdx # Mask the index if misspeculating.; popfq; movl (%rcx,%rdx), %edi; ```. Using the `pushf` and `popf` instructions saves the flags register around our; inserted code, but comes at a high cost. First, we must store the flags to the; stack and reload them. Second, this causes the stack pointer to be adjusted; dynamically, requiring a frame pointer be used for referring to temporaries; spilled to the stack, etc. On newer x86 processors we can use the `lahf` and `sahf` instructions to save; all of the flags besides the overflow flag in a register rather than on the; stack. We can then use `seto` and `add` to save and restore the overflow flag; in a register. Combined, this will save and restore flags in the same manner as; above but using two registers rather than the stack. That is still very; expensive if slightly less expensive than `pushf` and `popf` in most cases. #####",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:34067,Deployability,update,update,34067,"save; all of the flags besides the overflow flag in a register rather than on the; stack. We can then use `seto` and `add` to save and restore the overflow flag; in a register. Combined, this will save and restore flags in the same manner as; above but using two registers rather than the stack. That is still very; expensive if slightly less expensive than `pushf` and `popf` in most cases. ###### A flag-less alternative on Haswell, Zen and newer processors. Starting with the BMI2 x86 instruction set extensions available on Haswell and; Zen processors, there is an instruction for shifting that does not set any; flags: `shrx`. We can use this and the `lea` instruction to implement analogous; code sequences to the above ones. However, these are still very marginally; slower, as there are fewer ports able to dispatch shift instructions in most; modern x86 processors than there are for `or` instructions. Fast, single register addressing mode:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; shrxq %rax, %rsi, %rsi # Shift away bits if misspeculating.; movl (%rsi), %edi; ```. This will collapse the register to zero or one, and everything but the offset; in the addressing mode to be less than or equal to 9. This means the full; address can only be guaranteed to be less than `(1 << 31) + 9`. The OS may wish; to protect an extra page of the low address space to account for this. ##### Optimizations. A very large portion of the cost for this approach comes from checking loads in; this way, so it is important to work to optimize this. However, beyond making; the instruction sequences to *apply* the checks efficient (for example by; avoiding `pushfq` and `popfq` sequences), the only significant optimization is; to check fewer loads without introducing a vulnerability. We apply several; techniques to accomplish that. ###### Don't check loads from compile-time constant stack offsets. We implement this optimization on x86 by skipping the check",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:35891,Deployability,update,update,35891," We apply several; techniques to accomplish that. ###### Don't check loads from compile-time constant stack offsets. We implement this optimization on x86 by skipping the checking of loads which; use a fixed frame pointer offset. The result of this optimization is that patterns like reloading a spilled; register or accessing a global field don't get checked. This is a very; significant performance win. ###### Don't check dependent loads. A core part of why this mitigation strategy works is that it establishes a; data-flow check on the loaded address. However, this means that if the address; itself was already loaded using a checked load, there is no need to check a; dependent load provided it is within the same basic block as the checked load,; and therefore has no additional predicates guarding it. Consider code like the; following:; ```; ... .LBB0_4: # %danger; movq (%rcx), %rdi; movl (%rdi), %edx; ```. This will get transformed into:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rcx # Mask the pointer if misspeculating.; movq (%rcx), %rdi # Hardened load.; movl (%rdi), %edx # Unhardened load due to dependent addr.; ```. This doesn't check the load through `%rdi` as that pointer is dependent on a; checked load already. ###### Protect large, load-heavy blocks with a single lfence. It may be worth using a single `lfence` instruction at the start of a block; which begins with a (very) large number of loads that require independent; protection *and* which require hardening the address of the load. However, this; is unlikely to be profitable in practice. The latency hit of the hardening; would need to exceed that of an `lfence` when *correctly* speculatively; executed. But in that case, the `lfence` cost is a complete loss of speculative; execution (at a minimum). So far, the evidence we have of the performance cost; of using `lfence` indicates few if any hot code patterns where this trade off; would make sense. ###",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:38358,Deployability,deploy,deployable,38358,"rocessing. Maybe that would stop things in time for the misspeculated path to; fail to leak any secrets. This doesn't end up working because the processor is; fundamentally out-of-order, even in its speculative domain. As a consequence,; the attacker could cause the initial address computation itself to stall and; allow an arbitrary number of unrelated loads (including attacked loads of; secret data) to pass through. #### Interprocedural Checking. Modern x86 processors may speculate into called functions and out of functions; to their return address. As a consequence, we need a way to check loads that; occur after a misspeculated predicate but where the load and the misspeculated; predicate are in different functions. In essence, we need some interprocedural; generalization of the predicate state tracking. A primary challenge to passing; the predicate state between functions is that we would like to not require a; change to the ABI or calling convention in order to make this mitigation more; deployable, and further would like code mitigated in this way to be easily; mixed with code not mitigated in this way and without completely losing the; value of the mitigation. ##### Embed the predicate state into the high bit(s) of the stack pointer. We can use the same technique that allows hardening pointers to pass the; predicate state into and out of functions. The stack pointer is trivially; passed between functions and we can test for it having the high bits set to; detect when it has been marked due to misspeculation. The callsite instruction; sequence looks like (assuming a misspeculated state value of `-1`):; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; shlq $47, %rax; orq %rax, %rsp; callq other_function; movq %rsp, %rax; sarq 63, %rax # Sign extend the high bit to all bits.; ```. This first puts the predicate state into the high bits of `%rsp` before calling; the function and then reads it back out of high bits of `%rsp` aft",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:39049,Deployability,update,update,39049,"lated; predicate are in different functions. In essence, we need some interprocedural; generalization of the predicate state tracking. A primary challenge to passing; the predicate state between functions is that we would like to not require a; change to the ABI or calling convention in order to make this mitigation more; deployable, and further would like code mitigated in this way to be easily; mixed with code not mitigated in this way and without completely losing the; value of the mitigation. ##### Embed the predicate state into the high bit(s) of the stack pointer. We can use the same technique that allows hardening pointers to pass the; predicate state into and out of functions. The stack pointer is trivially; passed between functions and we can test for it having the high bits set to; detect when it has been marked due to misspeculation. The callsite instruction; sequence looks like (assuming a misspeculated state value of `-1`):; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; shlq $47, %rax; orq %rax, %rsp; callq other_function; movq %rsp, %rax; sarq 63, %rax # Sign extend the high bit to all bits.; ```. This first puts the predicate state into the high bits of `%rsp` before calling; the function and then reads it back out of high bits of `%rsp` afterward. When; correctly executing (speculatively or not), these are all no-ops. When; misspeculating, the stack pointer will end up negative. We arrange for it to; remain a canonical address, but otherwise leave the low bits alone to allow; stack adjustments to proceed normally without disrupting this. Within the; called function, we can extract this predicate state and then reset it on; return:; ```; other_function:; # prolog; callq other_function; movq %rsp, %rax; sarq 63, %rax # Sign extend the high bit to all bits.; # ... .LBB0_N:; cmovneq %r8, %rax # Conditionally update predicate state.; shlq $47, %rax; orq %rax, %rsp; retq; ```. This approach is effective when all co",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:39928,Deployability,update,update,39928,"equence looks like (assuming a misspeculated state value of `-1`):; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; shlq $47, %rax; orq %rax, %rsp; callq other_function; movq %rsp, %rax; sarq 63, %rax # Sign extend the high bit to all bits.; ```. This first puts the predicate state into the high bits of `%rsp` before calling; the function and then reads it back out of high bits of `%rsp` afterward. When; correctly executing (speculatively or not), these are all no-ops. When; misspeculating, the stack pointer will end up negative. We arrange for it to; remain a canonical address, but otherwise leave the low bits alone to allow; stack adjustments to proceed normally without disrupting this. Within the; called function, we can extract this predicate state and then reset it on; return:; ```; other_function:; # prolog; callq other_function; movq %rsp, %rax; sarq 63, %rax # Sign extend the high bit to all bits.; # ... .LBB0_N:; cmovneq %r8, %rax # Conditionally update predicate state.; shlq $47, %rax; orq %rax, %rsp; retq; ```. This approach is effective when all code is mitigated in this fashion, and can; even survive very limited reaches into unmitigated code (the state will; round-trip in and back out of an unmitigated function, it just won't be; updated). But it does have some limitations. There is a cost to merging the; state into `%rsp` and it doesn't insulate mitigated code from misspeculation in; an unmitigated caller. There is also an advantage to using this form of interprocedural mitigation: by; forming these invalid stack pointer addresses we can prevent speculative; returns from successfully reading speculatively written values to the actual; stack. This works first by forming a data-dependency between computing the; address of the return address on the stack and our predicate state. And even; when satisfied, if a misprediction causes the state to be poisoned the; resulting stack pointer will be invalid. ##### Rewrite A",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:40222,Deployability,update,updated,40222,"ther_function; movq %rsp, %rax; sarq 63, %rax # Sign extend the high bit to all bits.; ```. This first puts the predicate state into the high bits of `%rsp` before calling; the function and then reads it back out of high bits of `%rsp` afterward. When; correctly executing (speculatively or not), these are all no-ops. When; misspeculating, the stack pointer will end up negative. We arrange for it to; remain a canonical address, but otherwise leave the low bits alone to allow; stack adjustments to proceed normally without disrupting this. Within the; called function, we can extract this predicate state and then reset it on; return:; ```; other_function:; # prolog; callq other_function; movq %rsp, %rax; sarq 63, %rax # Sign extend the high bit to all bits.; # ... .LBB0_N:; cmovneq %r8, %rax # Conditionally update predicate state.; shlq $47, %rax; orq %rax, %rsp; retq; ```. This approach is effective when all code is mitigated in this fashion, and can; even survive very limited reaches into unmitigated code (the state will; round-trip in and back out of an unmitigated function, it just won't be; updated). But it does have some limitations. There is a cost to merging the; state into `%rsp` and it doesn't insulate mitigated code from misspeculation in; an unmitigated caller. There is also an advantage to using this form of interprocedural mitigation: by; forming these invalid stack pointer addresses we can prevent speculative; returns from successfully reading speculatively written values to the actual; stack. This works first by forming a data-dependency between computing the; address of the return address on the stack and our predicate state. And even; when satisfied, if a misprediction causes the state to be poisoned the; resulting stack pointer will be invalid. ##### Rewrite API of internal functions to directly propagate predicate state. (Not yet implemented.). We have the option with internal functions to directly adjust their API to; accept the predicate as an argu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:43345,Deployability,deploy,deployment,43345,"nt; tradeoff even when only used in a mixture of code. ##### Use an internal TLS location to pass predicate state. We can define a special thread-local value to hold the predicate state between; functions. This avoids direct ABI implications by using a side channel between; callers and callees to communicate the predicate state. It also allows implicit; zero-initialization of the state, which allows non-checked code to be the first; code executed. However, this requires a load from TLS in the entry block, a store to TLS; before every call and every ret, and a load from TLS after every call. As a; consequence it is expected to be substantially more expensive even than using; `%rsp` and potentially `lfence` within the function entry block. ##### Define a new ABI and/or calling convention. We could define a new ABI and/or calling convention to explicitly pass the; predicate state in and out of functions. This may be interesting if none of the; alternatives have adequate performance, but it makes deployment and adoption; dramatically more complex, and potentially infeasible. ## High-Level Alternative Mitigation Strategies. There are completely different alternative approaches to mitigating variant 1; attacks. [Most](https://lwn.net/Articles/743265/); [discussion](https://lwn.net/Articles/744287/) so far focuses on mitigating; specific known attackable components in the Linux kernel (or other kernels) by; manually rewriting the code to contain an instruction sequence that is not; vulnerable. For x86 systems this is done by either injecting an `lfence`; instruction along the code path which would leak data if executed speculatively; or by rewriting memory accesses to have branch-less masking to a known safe; region. On Intel systems, `lfence` [will prevent the speculative load of secret; data](https://newsroom.intel.com/wp-content/uploads/sites/11/2018/01/Intel-Analysis-of-Speculative-Execution-Side-Channels.pdf).; On AMD systems `lfence` is currently a no-op, but can be m",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:45672,Deployability,deploy,deploy,45672," to leak information. While in some cases static; analysis is effective at doing this at scale, in many cases it still relies on; human judgement to evaluate whether code might be vulnerable. Especially for; software systems which receive less detailed scrutiny but remain sensitive to; these attacks, this seems like an impractical security model. We need an; automatic and systematic mitigation strategy. ### Automatic `lfence` on Conditional Edges. A natural way to scale up the existing hand-coded mitigations is simply to; inject an `lfence` instruction into both the target and fallthrough; destinations of every conditional branch. This ensures that no predicate or; bounds check can be bypassed speculatively. However, the performance overhead; of this approach is, simply put, catastrophic. Yet it remains the only truly; ""secure by default"" approach known prior to this effort and serves as the; baseline for performance. One attempt to address the performance overhead of this and make it more; realistic to deploy is [MSVC's /Qspectre; switch](https://blogs.msdn.microsoft.com/vcblog/2018/01/15/spectre-mitigations-in-msvc/).; Their technique is to use static analysis within the compiler to only insert; `lfence` instructions into conditional edges at risk of attack. However,; [initial](https://arstechnica.com/gadgets/2018/02/microsofts-compiler-level-spectre-fix-shows-how-hard-this-problem-will-be-to-solve/); [analysis](https://www.paulkocher.com/doc/MicrosoftCompilerSpectreMitigation.html); has shown that this approach is incomplete and only catches a small and limited; subset of attackable patterns which happen to resemble very closely the initial; proofs of concept. As such, while its performance is acceptable, it does not; appear to be an adequate systematic mitigation. ## Performance Overhead. The performance overhead of this style of comprehensive mitigation is very; high. However, it compares very favorably with previously recommended; approaches such as the `lfence",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:20821,Energy Efficiency,reduce,reduce,20821,"most; significant challenge to propagate. The simplest technique would be to define a; new ABI such that the intended call target is passed into the called function; and checked in the entry. Unfortunately, new ABIs are quite expensive to deploy; in C and C++. While the target function could be passed in TLS, we would still; require complex logic to handle a mixture of functions compiled with and; without this extra logic (essentially, making the ABI backwards compatible).; Currently, we suggest using retpolines here and will continue to investigate; ways of mitigating this. ##### Optimizations, Alternatives, and Tradeoffs. Merely accumulating predicate state involves significant cost. There are; several key optimizations we employ to minimize this and various alternatives; that present different tradeoffs in the generated code. First, we work to reduce the number of instructions used to track the state:; * Rather than inserting a `cmovCC` instruction along every conditional edge in; the original program, we track each set of condition flags we need to capture; prior to entering each basic block and reuse a common `cmovCC` sequence for; those.; * We could further reuse suffixes when there are multiple `cmovCC`; instructions required to capture the set of flags. Currently this is; believed to not be worth the cost as paired flags are relatively rare and; suffixes of them are exceedingly rare.; * A common pattern in x86 is to have multiple conditional jump instructions; that use the same flags but handle different conditions. Naively, we could; consider each fallthrough between them an ""edge"" but this causes a much more; complex control flow graph. Instead, we accumulate the set of conditions; necessary for fallthrough and use a sequence of `cmovCC` instructions in a; single fallthrough edge to track it. Second, we trade register pressure for simpler `cmovCC` instructions by; allocating a register for the ""bad"" state. We could read that value from memory; as part of th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:27453,Energy Efficiency,efficient,efficiently,27453,"r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate without leaking.; addl 4(%rsi), %edi # Continue without leaking.; addl 8(%rsi), %edi; orl %eax, %edi # Mask out bits from all three loads.; ```. ###### Preserving the flags while hardening loaded values on Haswell, Zen, and newer processors. Sadly, there are no useful instructions on x86 that apply a mask to all 64 bits; without touching the flag registers. However, we can harden loaded values that; are narrower than a word (fewer than 32-bits on 32-bit systems and fewer than; 64-bits on 64-bit systems) by zero-extending the value to the full word size; and then shifting right by at least the number of original bits using the BMI2; `shrx` instruction:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate 32 bits of data.; shrxq %rax, %rdi, %rdi # Shift out all 32 bits loaded.; ```. Because on x86 the zero-extend is free, this can efficiently harden the loaded; value. ##### Hardening the address of the load. When hardening the loaded value is inapplicable, most often because the; instruction directly leaks information (like `cmp` or `jmpq`), we switch to; hardening the _address_ of the load instead of the loaded value. This avoids; increasing register pressure by unfolding the load or paying some other high; cost. To understand how this works in practice, we need to examine the exact; semantics of the x86 addressing modes which, in its fully general form, looks; like `(%base,%index,scale)offset`. Here `%base` and `%index` are 64-bit; registers that can potentially be any value, and may be attacker controlled,; and `scale` and `offset` are fixed immediate values. `scale` must be `1`, `2`,; `4`, or `8`, and `offset` can be any 32-bit sign extended value. The exact; computation performed to find the address is then: `%base + (scale * %index) +; offset` under 64-bit 2's complement modular arithmetic. One issue",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:34712,Energy Efficiency,efficient,efficient,34712,"quences to the above ones. However, these are still very marginally; slower, as there are fewer ports able to dispatch shift instructions in most; modern x86 processors than there are for `or` instructions. Fast, single register addressing mode:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; shrxq %rax, %rsi, %rsi # Shift away bits if misspeculating.; movl (%rsi), %edi; ```. This will collapse the register to zero or one, and everything but the offset; in the addressing mode to be less than or equal to 9. This means the full; address can only be guaranteed to be less than `(1 << 31) + 9`. The OS may wish; to protect an extra page of the low address space to account for this. ##### Optimizations. A very large portion of the cost for this approach comes from checking loads in; this way, so it is important to work to optimize this. However, beyond making; the instruction sequences to *apply* the checks efficient (for example by; avoiding `pushfq` and `popfq` sequences), the only significant optimization is; to check fewer loads without introducing a vulnerability. We apply several; techniques to accomplish that. ###### Don't check loads from compile-time constant stack offsets. We implement this optimization on x86 by skipping the checking of loads which; use a fixed frame pointer offset. The result of this optimization is that patterns like reloading a spilled; register or accessing a global field don't get checked. This is a very; significant performance win. ###### Don't check dependent loads. A core part of why this mitigation strategy works is that it establishes a; data-flow check on the loaded address. However, this means that if the address; itself was already loaded using a checked load, there is no need to check a; dependent load provided it is within the same basic block as the checked load,; and therefore has no additional predicates guarding it. Consider code like the; following:; ```; ... .LBB0_4: # %danger; movq (",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:37098,Energy Efficiency,reduce,reduce,37098,"s doesn't check the load through `%rdi` as that pointer is dependent on a; checked load already. ###### Protect large, load-heavy blocks with a single lfence. It may be worth using a single `lfence` instruction at the start of a block; which begins with a (very) large number of loads that require independent; protection *and* which require hardening the address of the load. However, this; is unlikely to be profitable in practice. The latency hit of the hardening; would need to exceed that of an `lfence` when *correctly* speculatively; executed. But in that case, the `lfence` cost is a complete loss of speculative; execution (at a minimum). So far, the evidence we have of the performance cost; of using `lfence` indicates few if any hot code patterns where this trade off; would make sense. ###### Tempting optimizations that break the security model. Several optimizations were considered which didn't pan out due to failure to; uphold the security model. One in particular is worth discussing as many others; will reduce to it. We wondered whether only the *first* load in a basic block could be checked. If; the check works as intended, it forms an invalid pointer that doesn't even; virtual-address translate in the hardware. It should fault very early on in its; processing. Maybe that would stop things in time for the misspeculated path to; fail to leak any secrets. This doesn't end up working because the processor is; fundamentally out-of-order, even in its speculative domain. As a consequence,; the attacker could cause the initial address computation itself to stall and; allow an arbitrary number of unrelated loads (including attacked loads of; secret data) to pass through. #### Interprocedural Checking. Modern x86 processors may speculate into called functions and out of functions; to their return address. As a consequence, we need a way to check loads that; occur after a misspeculated predicate but where the load and the misspeculated; predicate are in different functio",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:48991,Energy Efficiency,reduce,reduce,48991,"rver QPS (using ThinLTO & PGO) | -62% | -29% | **1.8x** |. Below is a visualization of the microbenchmark suite results which helps show; the distribution of results that is somewhat lost in the summary. The y-axis is; a log-scale speedup ratio of load hardening relative to `lfence` (up -> faster; -> better). Each box-and-whiskers represents one microbenchmark which may have; many different metrics measured. The red line marks the median, the box marks; the first and third quartiles, and the whiskers mark the min and max. ![Microbenchmark result visualization](speculative_load_hardening_microbenchmarks.png). We don't yet have benchmark data on SPEC or the LLVM test suite, but we can; work on getting that. Still, the above should give a pretty clear; characterization of the performance, and specific benchmarks are unlikely to; reveal especially interesting properties. ### Future Work: Fine Grained Control and API-Integration. The performance overhead of this technique is likely to be very significant and; something users wish to control or reduce. There are interesting options here; that impact the implementation strategy used. One particularly appealing option is to allow both opt-in and opt-out of this; mitigation at reasonably fine granularity such as on a per-function basis,; including intelligent handling of inlining decisions -- protected code can be; prevented from inlining into unprotected code, and unprotected code will become; protected when inlined into protected code. For systems where only a limited; set of code is reachable by externally controlled inputs, it may be possible to; limit the scope of mitigation through such mechanisms without compromising the; application's overall security. The performance impact may also be focused in a; few key functions that can be hand-mitigated in ways that have lower; performance overhead while the remainder of the application receives automatic; protection. For both limiting the scope of mitigation or manually miti",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:533,Integrability,inject,injection,533,"# Speculative Load Hardening. ## A Spectre Variant #1 Mitigation Technique. Author: Chandler Carruth - [chandlerc@google.com](mailto:chandlerc@google.com). ## Problem Statement. Recently, Google Project Zero and other researchers have found information leak; vulnerabilities by exploiting speculative execution in modern CPUs. These; exploits are currently broken down into three variants:; * GPZ Variant #1 (a.k.a. Spectre Variant #1): Bounds check (or predicate) bypass; * GPZ Variant #2 (a.k.a. Spectre Variant #2): Branch target injection; * GPZ Variant #3 (a.k.a. Meltdown): Rogue data cache load. For more details, see the Google Project Zero blog post and the Spectre research; paper:; * https://googleprojectzero.blogspot.com/2018/01/reading-privileged-memory-with-side.html; * https://spectreattack.com/spectre.pdf. The core problem of GPZ Variant #1 is that speculative execution uses branch; prediction to select the path of instructions speculatively executed. This path; is speculatively executed with the available data, and may load from memory and; leak the loaded values through various side channels that survive even when the; speculative execution is unwound due to being incorrect. Mispredicted paths can; cause code to be executed with data inputs that never occur in correct; executions, making checks against malicious inputs ineffective and allowing; attackers to use malicious data inputs to leak secret data. Here is an example,; extracted and simplified from the Project Zero paper:; ```; struct array {; unsigned long length;; unsigned char data[];; };; struct array *arr1 = ...; // small array; struct array *arr2 = ...; // array of size 0x400; unsigned long untrusted_offset_from_caller = ...;; if (untrusted_offset_from_caller < arr1->length) {; unsigned char value = arr1->data[untrusted_offset_from_caller];; unsigned long index2 = ((value&1)*0x100)+0x200;; unsigned char value2 = arr2->data[index2];; }; ```. The key of the attack is to call this with `untrusted_off",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:2278,Integrability,depend,dependent,2278," can; cause code to be executed with data inputs that never occur in correct; executions, making checks against malicious inputs ineffective and allowing; attackers to use malicious data inputs to leak secret data. Here is an example,; extracted and simplified from the Project Zero paper:; ```; struct array {; unsigned long length;; unsigned char data[];; };; struct array *arr1 = ...; // small array; struct array *arr2 = ...; // array of size 0x400; unsigned long untrusted_offset_from_caller = ...;; if (untrusted_offset_from_caller < arr1->length) {; unsigned char value = arr1->data[untrusted_offset_from_caller];; unsigned long index2 = ((value&1)*0x100)+0x200;; unsigned char value2 = arr2->data[index2];; }; ```. The key of the attack is to call this with `untrusted_offset_from_caller` that; is far outside of the bounds when the branch predictor will predict that it; will be in-bounds. In that case, the body of the `if` will be executed; speculatively, and may read secret data into `value` and leak it via a; cache-timing side channel when a dependent access is made to populate `value2`. ## High Level Mitigation Approach. While several approaches are being actively pursued to mitigate specific; branches and/or loads inside especially risky software (most notably various OS; kernels), these approaches require manual and/or static analysis aided auditing; of code and explicit source changes to apply the mitigation. They are unlikely; to scale well to large applications. We are proposing a comprehensive; mitigation approach that would apply automatically across an entire program; rather than through manual changes to the code. While this is likely to have a; high performance cost, some applications may be in a good position to take this; performance / security tradeoff. The specific technique we propose is to cause loads to be checked using; branchless code to ensure that they are executing along a valid control flow; path. Consider the following C-pseudo-code representi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:4342,Integrability,depend,dependency,4342,"er2) {; if (condition) {; // ... lots of code ...; leak(*pointer1);; } else {; // ... more code ...; leak(*pointer2);; }; }; ```. This would get transformed into something resembling the following:; ```; uintptr_t all_ones_mask = std::numerical_limits<uintptr_t>::max();; uintptr_t all_zeros_mask = 0;; void leak(int data);; void example(int* pointer1, int* pointer2) {; uintptr_t predicate_state = all_ones_mask;; if (condition) {; // Assuming ?: is implemented using branchless logic...; predicate_state = !condition ? all_zeros_mask : predicate_state;; // ... lots of code ...; //; // Harden the pointer so it can't be loaded; pointer1 &= predicate_state;; leak(*pointer1);; } else {; predicate_state = condition ? all_zeros_mask : predicate_state;; // ... more code ...; //; // Alternative: Harden the loaded value; int value2 = *pointer2 & predicate_state;; leak(value2);; }; }; ```. The result should be that if the `if (condition) {` branch is mis-predicted,; there is a *data* dependency on the condition used to zero out any pointers; prior to loading through them or to zero out all of the loaded bits. Even; though this code pattern may still execute speculatively, *invalid* speculative; executions are prevented from leaking secret data from memory (but note that; this data might still be loaded in safe ways, and some regions of memory are; required to not hold secrets, see below for detailed limitations). This; approach only requires the underlying hardware have a way to implement a; branchless and unpredicted conditional update of a register's value. All modern; architectures have support for this, and in fact such support is necessary to; correctly implement constant time cryptographic primitives. Crucial properties of this approach:; * It is not preventing any particular side-channel from working. This is; important as there are an unknown number of potential side channels and we; expect to continue discovering more. Instead, it prevents the observation of; secret data",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:6560,Integrability,depend,dependent,6560,"dural protection](#interprocedural-checking).; * When hardening the address of a load, it uses a *destructive* or; *non-reversible* modification of the address to prevent an attacker from; reversing the check using attacker-controlled inputs.; * It does not completely block speculative execution, and merely prevents; *mis*-speculated paths from leaking secrets from memory (and stalls; speculation until this can be determined).; * It is completely general and makes no fundamental assumptions about the; underlying architecture other than the ability to do branchless conditional; data updates and a lack of value prediction.; * It does not require programmers to identify all possible secret data using; static source code annotations or code vulnerable to a variant #1 style; attack. Limitations of this approach:; * It requires re-compiling source code to insert hardening instruction; sequences. Only software compiled in this mode is protected.; * The performance is heavily dependent on a particular architecture's; implementation strategy. We outline a potential x86 implementation below and; characterize its performance.; * It does not defend against secret data already loaded from memory and; residing in registers or leaked through other side-channels in; non-speculative execution. Code dealing with this, e.g cryptographic; routines, already uses constant-time algorithms and code to prevent; side-channels. Such code should also scrub registers of secret data following; [these; guidelines](https://github.com/HACS-workshop/spectre-mitigations/blob/master/crypto_guidelines.md).; * To achieve reasonable performance, many loads may not be checked, such as; those with compile-time fixed addresses. This primarily consists of accesses; at compile-time constant offsets of global and local variables. Code which; needs this protection and intentionally stores secret data must ensure the; memory regions used for secret data are necessarily dynamic mappings or heap; allocations. This ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:6918,Integrability,rout,routines,6918," (and stalls; speculation until this can be determined).; * It is completely general and makes no fundamental assumptions about the; underlying architecture other than the ability to do branchless conditional; data updates and a lack of value prediction.; * It does not require programmers to identify all possible secret data using; static source code annotations or code vulnerable to a variant #1 style; attack. Limitations of this approach:; * It requires re-compiling source code to insert hardening instruction; sequences. Only software compiled in this mode is protected.; * The performance is heavily dependent on a particular architecture's; implementation strategy. We outline a potential x86 implementation below and; characterize its performance.; * It does not defend against secret data already loaded from memory and; residing in registers or leaked through other side-channels in; non-speculative execution. Code dealing with this, e.g cryptographic; routines, already uses constant-time algorithms and code to prevent; side-channels. Such code should also scrub registers of secret data following; [these; guidelines](https://github.com/HACS-workshop/spectre-mitigations/blob/master/crypto_guidelines.md).; * To achieve reasonable performance, many loads may not be checked, such as; those with compile-time fixed addresses. This primarily consists of accesses; at compile-time constant offsets of global and local variables. Code which; needs this protection and intentionally stores secret data must ensure the; memory regions used for secret data are necessarily dynamic mappings or heap; allocations. This is an area which can be tuned to provide more comprehensive; protection at the cost of performance.; * [Hardened loads](#hardening-the-address-of-the-load) may still load data from; _valid_ addresses if not _attacker-controlled_ addresses. To prevent these; from reading secret data, the low 2gb of the address space and 2gb above and; below any executable pages should be ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:13561,Integrability,rout,routine,13561,"ons. This additionally causes a misspeculation to have an invalid stack; pointer and never be able to read the speculatively stored return address. See; the detailed discussion below. For variant #1.2, the attacker speculatively stores into the vtable or jump; table used to implement an indirect call or indirect jump. Because this is; speculative, this will often be possible even when these are stored in; read-only pages. For example:; ```; class FancyObject : public BaseObject {; public:; void DoSomething() override;; };; void f(unsigned long attacker_offset, unsigned long attacker_data) {; FancyObject object = getMyObject();; unsigned long *arr[4] = getFourDataPointers();; if (attacker_offset < 4) {; // We have bypassed the bounds check speculatively.; unsigned long *data = arr[attacker_offset];; // Now we have computed a pointer inside of `object`, the vptr.; *data = attacker_data;; // The vptr points to the virtual table and we speculatively clobber that.; g(object); // Hand the object to some other routine.; }; }; // In another file, we call a method on the object.; void g(BaseObject &object) {; object.DoSomething();; // This speculatively calls the address stored over the vtable.; }; ```. Mitigating this requires hardening loads from these locations, or mitigating; the indirect call or indirect jump. Any of these are sufficient to block the; call or jump from using a speculatively stored value that has been read back. For both of these, using retpolines would be equally sufficient. One possible; hybrid approach is to use retpolines for indirect call and jump, while relying; on SLH to mitigate returns. Another approach that is sufficient for both of these is to harden all of the; speculative stores. However, as most stores aren't interesting and don't; inherently leak data, this is expected to be prohibitively expensive given the; attack it is defending against. ## Implementation Details. There are a number of complex details impacting the implementation of thi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:29887,Integrability,wrap,wrapping,29887," This significantly; raises the burden on the attacker and limits the scope of attack but does not; eliminate it. To fully close the attack we must work with the operating system; to preclude mapping memory in the low two gigabytes of address space. ###### 64-bit load checking instructions. We can use the following instruction sequences to check loads. We set up `%r8`; in these examples to hold the special value of `-1` which will be `cmov`ed over; `%rax` in misspeculated paths. Single register addressing mode:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rsi # Mask the pointer if misspeculating.; movl (%rsi), %edi; ```. Two register addressing mode:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rsi # Mask the pointer if misspeculating.; orq %rax, %rcx # Mask the index if misspeculating.; movl (%rsi,%rcx), %edi; ```. This will result in a negative address near zero or in `offset` wrapping the; address space back to a small positive address. Small, negative addresses will; fault in user-mode for most operating systems, but targets which need the high; address space to be user accessible may need to adjust the exact sequence used; above. Additionally, the low addresses will need to be marked unreadable by the; OS to fully harden the load. ###### RIP-relative addressing is even easier to break. There is a common addressing mode idiom that is substantially harder to check:; addressing relative to the instruction pointer. We cannot change the value of; the instruction pointer register and so we have the harder problem of forcing; `%base + scale * %index + offset` to be an invalid address, by *only* changing; `%index`. The only advantage we have is that the attacker also cannot modify; `%base`. If we use the fast instruction sequence above, but only apply it to; the index, we will always access `%rip + (scale * -1) + offset`. If the; attacker can find a load which ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:32118,Integrability,depend,dependency,32118,"r stack within 2gb of any of the; text in the program, much like it can reserve the low 2gb of address space. ###### The flag registers again make everything hard. Unfortunately, the technique of using `orq`-instructions has a serious flaw on; x86. The very thing that makes it easy to accumulate state, the flag registers; containing predicates, causes serious problems here because they may be alive; and used by the loading instruction or subsequent instructions. On x86, the; `orq` instruction **sets** the flags and will override anything already there.; This makes inserting them into the instruction stream very hazardous.; Unfortunately, unlike when hardening the loaded value, we have no fallback here; and so we must have a fully general approach available. The first thing we must do when generating these sequences is try to analyze; the surrounding code to prove that the flags are not in fact alive or being; used. Typically, it has been set by some other instruction which just happens; to set the flags register (much like ours!) with no actual dependency. In those; cases, it is safe to directly insert these instructions. Alternatively we may; be able to move them earlier to avoid clobbering the used value. However, this may ultimately be impossible. In that case, we need to preserve; the flags around these instructions:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; pushfq; orq %rax, %rcx # Mask the pointer if misspeculating.; orq %rax, %rdx # Mask the index if misspeculating.; popfq; movl (%rcx,%rdx), %edi; ```. Using the `pushf` and `popf` instructions saves the flags register around our; inserted code, but comes at a high cost. First, we must store the flags to the; stack and reload them. Second, this causes the stack pointer to be adjusted; dynamically, requiring a frame pointer be used for referring to temporaries; spilled to the stack, etc. On newer x86 processors we can use the `lahf` and `sahf` instructions to save;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:35301,Integrability,depend,dependent,35301,"qual to 9. This means the full; address can only be guaranteed to be less than `(1 << 31) + 9`. The OS may wish; to protect an extra page of the low address space to account for this. ##### Optimizations. A very large portion of the cost for this approach comes from checking loads in; this way, so it is important to work to optimize this. However, beyond making; the instruction sequences to *apply* the checks efficient (for example by; avoiding `pushfq` and `popfq` sequences), the only significant optimization is; to check fewer loads without introducing a vulnerability. We apply several; techniques to accomplish that. ###### Don't check loads from compile-time constant stack offsets. We implement this optimization on x86 by skipping the checking of loads which; use a fixed frame pointer offset. The result of this optimization is that patterns like reloading a spilled; register or accessing a global field don't get checked. This is a very; significant performance win. ###### Don't check dependent loads. A core part of why this mitigation strategy works is that it establishes a; data-flow check on the loaded address. However, this means that if the address; itself was already loaded using a checked load, there is no need to check a; dependent load provided it is within the same basic block as the checked load,; and therefore has no additional predicates guarding it. Consider code like the; following:; ```; ... .LBB0_4: # %danger; movq (%rcx), %rdi; movl (%rdi), %edx; ```. This will get transformed into:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rcx # Mask the pointer if misspeculating.; movq (%rcx), %rdi # Hardened load.; movl (%rdi), %edx # Unhardened load due to dependent addr.; ```. This doesn't check the load through `%rdi` as that pointer is dependent on a; checked load already. ###### Protect large, load-heavy blocks with a single lfence. It may be worth using a single `lfence` instruction at the start o",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:35551,Integrability,depend,dependent,35551,"s from checking loads in; this way, so it is important to work to optimize this. However, beyond making; the instruction sequences to *apply* the checks efficient (for example by; avoiding `pushfq` and `popfq` sequences), the only significant optimization is; to check fewer loads without introducing a vulnerability. We apply several; techniques to accomplish that. ###### Don't check loads from compile-time constant stack offsets. We implement this optimization on x86 by skipping the checking of loads which; use a fixed frame pointer offset. The result of this optimization is that patterns like reloading a spilled; register or accessing a global field don't get checked. This is a very; significant performance win. ###### Don't check dependent loads. A core part of why this mitigation strategy works is that it establishes a; data-flow check on the loaded address. However, this means that if the address; itself was already loaded using a checked load, there is no need to check a; dependent load provided it is within the same basic block as the checked load,; and therefore has no additional predicates guarding it. Consider code like the; following:; ```; ... .LBB0_4: # %danger; movq (%rcx), %rdi; movl (%rdi), %edx; ```. This will get transformed into:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rcx # Mask the pointer if misspeculating.; movq (%rcx), %rdi # Hardened load.; movl (%rdi), %edx # Unhardened load due to dependent addr.; ```. This doesn't check the load through `%rdi` as that pointer is dependent on a; checked load already. ###### Protect large, load-heavy blocks with a single lfence. It may be worth using a single `lfence` instruction at the start of a block; which begins with a (very) large number of loads that require independent; protection *and* which require hardening the address of the load. However, this; is unlikely to be profitable in practice. The latency hit of the hardening; would need to exc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:36049,Integrability,depend,dependent,36049,"skipping the checking of loads which; use a fixed frame pointer offset. The result of this optimization is that patterns like reloading a spilled; register or accessing a global field don't get checked. This is a very; significant performance win. ###### Don't check dependent loads. A core part of why this mitigation strategy works is that it establishes a; data-flow check on the loaded address. However, this means that if the address; itself was already loaded using a checked load, there is no need to check a; dependent load provided it is within the same basic block as the checked load,; and therefore has no additional predicates guarding it. Consider code like the; following:; ```; ... .LBB0_4: # %danger; movq (%rcx), %rdi; movl (%rdi), %edx; ```. This will get transformed into:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rcx # Mask the pointer if misspeculating.; movq (%rcx), %rdi # Hardened load.; movl (%rdi), %edx # Unhardened load due to dependent addr.; ```. This doesn't check the load through `%rdi` as that pointer is dependent on a; checked load already. ###### Protect large, load-heavy blocks with a single lfence. It may be worth using a single `lfence` instruction at the start of a block; which begins with a (very) large number of loads that require independent; protection *and* which require hardening the address of the load. However, this; is unlikely to be profitable in practice. The latency hit of the hardening; would need to exceed that of an `lfence` when *correctly* speculatively; executed. But in that case, the `lfence` cost is a complete loss of speculative; execution (at a minimum). So far, the evidence we have of the performance cost; of using `lfence` indicates few if any hot code patterns where this trade off; would make sense. ###### Tempting optimizations that break the security model. Several optimizations were considered which didn't pan out due to failure to; uphold the security mo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:36133,Integrability,depend,dependent,36133,"this optimization is that patterns like reloading a spilled; register or accessing a global field don't get checked. This is a very; significant performance win. ###### Don't check dependent loads. A core part of why this mitigation strategy works is that it establishes a; data-flow check on the loaded address. However, this means that if the address; itself was already loaded using a checked load, there is no need to check a; dependent load provided it is within the same basic block as the checked load,; and therefore has no additional predicates guarding it. Consider code like the; following:; ```; ... .LBB0_4: # %danger; movq (%rcx), %rdi; movl (%rdi), %edx; ```. This will get transformed into:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rcx # Mask the pointer if misspeculating.; movq (%rcx), %rdi # Hardened load.; movl (%rdi), %edx # Unhardened load due to dependent addr.; ```. This doesn't check the load through `%rdi` as that pointer is dependent on a; checked load already. ###### Protect large, load-heavy blocks with a single lfence. It may be worth using a single `lfence` instruction at the start of a block; which begins with a (very) large number of loads that require independent; protection *and* which require hardening the address of the load. However, this; is unlikely to be profitable in practice. The latency hit of the hardening; would need to exceed that of an `lfence` when *correctly* speculatively; executed. But in that case, the `lfence` cost is a complete loss of speculative; execution (at a minimum). So far, the evidence we have of the performance cost; of using `lfence` indicates few if any hot code patterns where this trade off; would make sense. ###### Tempting optimizations that break the security model. Several optimizations were considered which didn't pan out due to failure to; uphold the security model. One in particular is worth discussing as many others; will reduce to it. We wonde",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:40678,Integrability,depend,dependency,40678,"cate state and then reset it on; return:; ```; other_function:; # prolog; callq other_function; movq %rsp, %rax; sarq 63, %rax # Sign extend the high bit to all bits.; # ... .LBB0_N:; cmovneq %r8, %rax # Conditionally update predicate state.; shlq $47, %rax; orq %rax, %rsp; retq; ```. This approach is effective when all code is mitigated in this fashion, and can; even survive very limited reaches into unmitigated code (the state will; round-trip in and back out of an unmitigated function, it just won't be; updated). But it does have some limitations. There is a cost to merging the; state into `%rsp` and it doesn't insulate mitigated code from misspeculation in; an unmitigated caller. There is also an advantage to using this form of interprocedural mitigation: by; forming these invalid stack pointer addresses we can prevent speculative; returns from successfully reading speculatively written values to the actual; stack. This works first by forming a data-dependency between computing the; address of the return address on the stack and our predicate state. And even; when satisfied, if a misprediction causes the state to be poisoned the; resulting stack pointer will be invalid. ##### Rewrite API of internal functions to directly propagate predicate state. (Not yet implemented.). We have the option with internal functions to directly adjust their API to; accept the predicate as an argument and return it. This is likely to be; marginally cheaper than embedding into `%rsp` for entering functions. ##### Use `lfence` to guard function transitions. An `lfence` instruction can be used to prevent subsequent loads from; speculatively executing until all prior mispredicted predicates have resolved.; We can use this broader barrier to speculative loads executing between; functions. We emit it in the entry block to handle calls, and prior to each; return. This approach also has the advantage of providing the strongest degree; of mitigation when mixed with unmitigated code by halting",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:43888,Integrability,inject,injecting,43888,"ected to be substantially more expensive even than using; `%rsp` and potentially `lfence` within the function entry block. ##### Define a new ABI and/or calling convention. We could define a new ABI and/or calling convention to explicitly pass the; predicate state in and out of functions. This may be interesting if none of the; alternatives have adequate performance, but it makes deployment and adoption; dramatically more complex, and potentially infeasible. ## High-Level Alternative Mitigation Strategies. There are completely different alternative approaches to mitigating variant 1; attacks. [Most](https://lwn.net/Articles/743265/); [discussion](https://lwn.net/Articles/744287/) so far focuses on mitigating; specific known attackable components in the Linux kernel (or other kernels) by; manually rewriting the code to contain an instruction sequence that is not; vulnerable. For x86 systems this is done by either injecting an `lfence`; instruction along the code path which would leak data if executed speculatively; or by rewriting memory accesses to have branch-less masking to a known safe; region. On Intel systems, `lfence` [will prevent the speculative load of secret; data](https://newsroom.intel.com/wp-content/uploads/sites/11/2018/01/Intel-Analysis-of-Speculative-Execution-Side-Channels.pdf).; On AMD systems `lfence` is currently a no-op, but can be made; dispatch-serializing by setting an MSR, and thus preclude misspeculation of the; code path ([mitigation G-2 +; V1-1](https://developer.amd.com/wp-content/resources/Managing-Speculation-on-AMD-Processors.pdf)). However, this relies on finding and enumerating all possible points in code; which could be attacked to leak information. While in some cases static; analysis is effective at doing this at scale, in many cases it still relies on; human judgement to evaluate whether code might be vulnerable. Especially for; software systems which receive less detailed scrutiny but remain sensitive to; these attacks, this se",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:45181,Integrability,inject,inject,45181,"oads/sites/11/2018/01/Intel-Analysis-of-Speculative-Execution-Side-Channels.pdf).; On AMD systems `lfence` is currently a no-op, but can be made; dispatch-serializing by setting an MSR, and thus preclude misspeculation of the; code path ([mitigation G-2 +; V1-1](https://developer.amd.com/wp-content/resources/Managing-Speculation-on-AMD-Processors.pdf)). However, this relies on finding and enumerating all possible points in code; which could be attacked to leak information. While in some cases static; analysis is effective at doing this at scale, in many cases it still relies on; human judgement to evaluate whether code might be vulnerable. Especially for; software systems which receive less detailed scrutiny but remain sensitive to; these attacks, this seems like an impractical security model. We need an; automatic and systematic mitigation strategy. ### Automatic `lfence` on Conditional Edges. A natural way to scale up the existing hand-coded mitigations is simply to; inject an `lfence` instruction into both the target and fallthrough; destinations of every conditional branch. This ensures that no predicate or; bounds check can be bypassed speculatively. However, the performance overhead; of this approach is, simply put, catastrophic. Yet it remains the only truly; ""secure by default"" approach known prior to this effort and serves as the; baseline for performance. One attempt to address the performance overhead of this and make it more; realistic to deploy is [MSVC's /Qspectre; switch](https://blogs.msdn.microsoft.com/vcblog/2018/01/15/spectre-mitigations-in-msvc/).; Their technique is to use static analysis within the compiler to only insert; `lfence` instructions into conditional edges at risk of attack. However,; [initial](https://arstechnica.com/gadgets/2018/02/microsofts-compiler-level-spectre-fix-shows-how-hard-this-problem-will-be-to-solve/); [analysis](https://www.paulkocher.com/doc/MicrosoftCompilerSpectreMitigation.html); has shown that this approach is in",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:7383,Modifiability,variab,variables,7383,"riant #1 style; attack. Limitations of this approach:; * It requires re-compiling source code to insert hardening instruction; sequences. Only software compiled in this mode is protected.; * The performance is heavily dependent on a particular architecture's; implementation strategy. We outline a potential x86 implementation below and; characterize its performance.; * It does not defend against secret data already loaded from memory and; residing in registers or leaked through other side-channels in; non-speculative execution. Code dealing with this, e.g cryptographic; routines, already uses constant-time algorithms and code to prevent; side-channels. Such code should also scrub registers of secret data following; [these; guidelines](https://github.com/HACS-workshop/spectre-mitigations/blob/master/crypto_guidelines.md).; * To achieve reasonable performance, many loads may not be checked, such as; those with compile-time fixed addresses. This primarily consists of accesses; at compile-time constant offsets of global and local variables. Code which; needs this protection and intentionally stores secret data must ensure the; memory regions used for secret data are necessarily dynamic mappings or heap; allocations. This is an area which can be tuned to provide more comprehensive; protection at the cost of performance.; * [Hardened loads](#hardening-the-address-of-the-load) may still load data from; _valid_ addresses if not _attacker-controlled_ addresses. To prevent these; from reading secret data, the low 2gb of the address space and 2gb above and; below any executable pages should be protected. Credit:; * The core idea of tracing misspeculation through data and marking pointers to; block misspeculated loads was developed as part of a HACS 2018 discussion; between Chandler Carruth, Paul Kocher, Thomas Pornin, and several other; individuals.; * Core idea of masking out loaded bits was part of the original mitigation; suggested by Jann Horn when these attacks were reporte",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:11069,Modifiability,extend,extend,11069,"cate_state = (condition != 0) ? all_zeros_mask : predicate_state;; // ... lots of code ...; //; // Harden the pointer so it can't be loaded; pointer1 &= predicate_state;; leak(*pointer1);; break;. case 1:; predicate_state = (condition != 1) ? all_zeros_mask : predicate_state;; // ... more code ...; //; // Alternative: Harden the loaded value; int value2 = *pointer2 & predicate_state;; leak(value2);; break;. // ...; }; }; ```. The core idea remains the same: validate the control flow using data-flow and; use that validation to check that loads cannot leak information along; misspeculated paths. Typically this involves passing the desired target of such; control flow across the edge and checking that it is correct afterwards. Note; that while it is tempting to think that this mitigates variant #2 attacks, it; does not. Those attacks go to arbitrary gadgets that don't include the checks. ### Variant #1.1 and #1.2 attacks: ""Bounds Check Bypass Store"". Beyond the core variant #1 attack, there are techniques to extend this attack.; The primary technique is known as ""Bounds Check Bypass Store"" and is discussed; in this research paper: https://people.csail.mit.edu/vlk/spectre11.pdf. We will analyze these two variants independently. First, variant #1.1 works by; speculatively storing over the return address after a bounds check bypass. This; speculative store then ends up being used by the CPU during speculative; execution of the return, potentially directing speculative execution to; arbitrary gadgets in the binary. Let's look at an example.; ```; unsigned char local_buffer[4];; unsigned char *untrusted_data_from_caller = ...;; unsigned long untrusted_size_from_caller = ...;; if (untrusted_size_from_caller < sizeof(local_buffer)) {; // Speculative execution enters here with a too-large size.; memcpy(local_buffer, untrusted_data_from_caller,; untrusted_size_from_caller);; // The stack has now been smashed, writing an attacker-controlled; // address over the return address.; m",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:27053,Modifiability,extend,extending,27053,"erred down the data-invariant expression graph. We can generalize the previous idea and sink the hardening down the expression; graph across as many data-invariant operations as desirable. This can use very; conservative rules for whether something is data-invariant. The primary goal; should be to handle multiple loads with a single hardening instruction:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate without leaking.; addl 4(%rsi), %edi # Continue without leaking.; addl 8(%rsi), %edi; orl %eax, %edi # Mask out bits from all three loads.; ```. ###### Preserving the flags while hardening loaded values on Haswell, Zen, and newer processors. Sadly, there are no useful instructions on x86 that apply a mask to all 64 bits; without touching the flag registers. However, we can harden loaded values that; are narrower than a word (fewer than 32-bits on 32-bit systems and fewer than; 64-bits on 64-bit systems) by zero-extending the value to the full word size; and then shifting right by at least the number of original bits using the BMI2; `shrx` instruction:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate 32 bits of data.; shrxq %rax, %rdi, %rdi # Shift out all 32 bits loaded.; ```. Because on x86 the zero-extend is free, this can efficiently harden the loaded; value. ##### Hardening the address of the load. When hardening the loaded value is inapplicable, most often because the; instruction directly leaks information (like `cmp` or `jmpq`), we switch to; hardening the _address_ of the load instead of the loaded value. This avoids; increasing register pressure by unfolding the load or paying some other high; cost. To understand how this works in practice, we need to examine the exact; semantics of the x86 addressing modes which, in its fully general form, looks; like `(%base,%index,scale)offset`. Here `%base` and `%",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:27428,Modifiability,extend,extend,27428,"r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate without leaking.; addl 4(%rsi), %edi # Continue without leaking.; addl 8(%rsi), %edi; orl %eax, %edi # Mask out bits from all three loads.; ```. ###### Preserving the flags while hardening loaded values on Haswell, Zen, and newer processors. Sadly, there are no useful instructions on x86 that apply a mask to all 64 bits; without touching the flag registers. However, we can harden loaded values that; are narrower than a word (fewer than 32-bits on 32-bit systems and fewer than; 64-bits on 64-bit systems) by zero-extending the value to the full word size; and then shifting right by at least the number of original bits using the BMI2; `shrx` instruction:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate 32 bits of data.; shrxq %rax, %rdi, %rdi # Shift out all 32 bits loaded.; ```. Because on x86 the zero-extend is free, this can efficiently harden the loaded; value. ##### Hardening the address of the load. When hardening the loaded value is inapplicable, most often because the; instruction directly leaks information (like `cmp` or `jmpq`), we switch to; hardening the _address_ of the load instead of the loaded value. This avoids; increasing register pressure by unfolding the load or paying some other high; cost. To understand how this works in practice, we need to examine the exact; semantics of the x86 addressing modes which, in its fully general form, looks; like `(%base,%index,scale)offset`. Here `%base` and `%index` are 64-bit; registers that can potentially be any value, and may be attacker controlled,; and `scale` and `offset` are fixed immediate values. `scale` must be `1`, `2`,; `4`, or `8`, and `offset` can be any 32-bit sign extended value. The exact; computation performed to find the address is then: `%base + (scale * %index) +; offset` under 64-bit 2's complement modular arithmetic. One issue",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:28275,Modifiability,extend,extended,28275,"# Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate 32 bits of data.; shrxq %rax, %rdi, %rdi # Shift out all 32 bits loaded.; ```. Because on x86 the zero-extend is free, this can efficiently harden the loaded; value. ##### Hardening the address of the load. When hardening the loaded value is inapplicable, most often because the; instruction directly leaks information (like `cmp` or `jmpq`), we switch to; hardening the _address_ of the load instead of the loaded value. This avoids; increasing register pressure by unfolding the load or paying some other high; cost. To understand how this works in practice, we need to examine the exact; semantics of the x86 addressing modes which, in its fully general form, looks; like `(%base,%index,scale)offset`. Here `%base` and `%index` are 64-bit; registers that can potentially be any value, and may be attacker controlled,; and `scale` and `offset` are fixed immediate values. `scale` must be `1`, `2`,; `4`, or `8`, and `offset` can be any 32-bit sign extended value. The exact; computation performed to find the address is then: `%base + (scale * %index) +; offset` under 64-bit 2's complement modular arithmetic. One issue with this approach is that, after hardening, the `%base + (scale *; %index)` subexpression will compute a value near zero (`-1 + (scale * -1)`) and; then a large, positive `offset` will index into memory within the first two; gigabytes of address space. While these offsets are not attacker controlled,; the attacker could chose to attack a load which happens to have the desired; offset and then successfully read memory in that region. This significantly; raises the burden on the attacker and limits the scope of attack but does not; eliminate it. To fully close the attack we must work with the operating system; to preclude mapping memory in the low two gigabytes of address space. ###### 64-bit load checking instructions. We can use the following instruction sequences to check loads. We s",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:39166,Modifiability,extend,extend,39166," of the predicate state tracking. A primary challenge to passing; the predicate state between functions is that we would like to not require a; change to the ABI or calling convention in order to make this mitigation more; deployable, and further would like code mitigated in this way to be easily; mixed with code not mitigated in this way and without completely losing the; value of the mitigation. ##### Embed the predicate state into the high bit(s) of the stack pointer. We can use the same technique that allows hardening pointers to pass the; predicate state into and out of functions. The stack pointer is trivially; passed between functions and we can test for it having the high bits set to; detect when it has been marked due to misspeculation. The callsite instruction; sequence looks like (assuming a misspeculated state value of `-1`):; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; shlq $47, %rax; orq %rax, %rsp; callq other_function; movq %rsp, %rax; sarq 63, %rax # Sign extend the high bit to all bits.; ```. This first puts the predicate state into the high bits of `%rsp` before calling; the function and then reads it back out of high bits of `%rsp` afterward. When; correctly executing (speculatively or not), these are all no-ops. When; misspeculating, the stack pointer will end up negative. We arrange for it to; remain a canonical address, but otherwise leave the low bits alone to allow; stack adjustments to proceed normally without disrupting this. Within the; called function, we can extract this predicate state and then reset it on; return:; ```; other_function:; # prolog; callq other_function; movq %rsp, %rax; sarq 63, %rax # Sign extend the high bit to all bits.; # ... .LBB0_N:; cmovneq %r8, %rax # Conditionally update predicate state.; shlq $47, %rax; orq %rax, %rsp; retq; ```. This approach is effective when all code is mitigated in this fashion, and can; even survive very limited reaches into unmitigated code (th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:39844,Modifiability,extend,extend,39844,"d between functions and we can test for it having the high bits set to; detect when it has been marked due to misspeculation. The callsite instruction; sequence looks like (assuming a misspeculated state value of `-1`):; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; shlq $47, %rax; orq %rax, %rsp; callq other_function; movq %rsp, %rax; sarq 63, %rax # Sign extend the high bit to all bits.; ```. This first puts the predicate state into the high bits of `%rsp` before calling; the function and then reads it back out of high bits of `%rsp` afterward. When; correctly executing (speculatively or not), these are all no-ops. When; misspeculating, the stack pointer will end up negative. We arrange for it to; remain a canonical address, but otherwise leave the low bits alone to allow; stack adjustments to proceed normally without disrupting this. Within the; called function, we can extract this predicate state and then reset it on; return:; ```; other_function:; # prolog; callq other_function; movq %rsp, %rax; sarq 63, %rax # Sign extend the high bit to all bits.; # ... .LBB0_N:; cmovneq %r8, %rax # Conditionally update predicate state.; shlq $47, %rax; orq %rax, %rsp; retq; ```. This approach is effective when all code is mitigated in this fashion, and can; even survive very limited reaches into unmitigated code (the state will; round-trip in and back out of an unmitigated function, it just won't be; updated). But it does have some limitations. There is a cost to merging the; state into `%rsp` and it doesn't insulate mitigated code from misspeculation in; an unmitigated caller. There is also an advantage to using this form of interprocedural mitigation: by; forming these invalid stack pointer addresses we can prevent speculative; returns from successfully reading speculatively written values to the actual; stack. This works first by forming a data-dependency between computing the; address of the return address on the stack and our pre",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:591,Performance,cache,cache,591,"# Speculative Load Hardening. ## A Spectre Variant #1 Mitigation Technique. Author: Chandler Carruth - [chandlerc@google.com](mailto:chandlerc@google.com). ## Problem Statement. Recently, Google Project Zero and other researchers have found information leak; vulnerabilities by exploiting speculative execution in modern CPUs. These; exploits are currently broken down into three variants:; * GPZ Variant #1 (a.k.a. Spectre Variant #1): Bounds check (or predicate) bypass; * GPZ Variant #2 (a.k.a. Spectre Variant #2): Branch target injection; * GPZ Variant #3 (a.k.a. Meltdown): Rogue data cache load. For more details, see the Google Project Zero blog post and the Spectre research; paper:; * https://googleprojectzero.blogspot.com/2018/01/reading-privileged-memory-with-side.html; * https://spectreattack.com/spectre.pdf. The core problem of GPZ Variant #1 is that speculative execution uses branch; prediction to select the path of instructions speculatively executed. This path; is speculatively executed with the available data, and may load from memory and; leak the loaded values through various side channels that survive even when the; speculative execution is unwound due to being incorrect. Mispredicted paths can; cause code to be executed with data inputs that never occur in correct; executions, making checks against malicious inputs ineffective and allowing; attackers to use malicious data inputs to leak secret data. Here is an example,; extracted and simplified from the Project Zero paper:; ```; struct array {; unsigned long length;; unsigned char data[];; };; struct array *arr1 = ...; // small array; struct array *arr2 = ...; // array of size 0x400; unsigned long untrusted_offset_from_caller = ...;; if (untrusted_offset_from_caller < arr1->length) {; unsigned char value = arr1->data[untrusted_offset_from_caller];; unsigned long index2 = ((value&1)*0x100)+0x200;; unsigned char value2 = arr2->data[index2];; }; ```. The key of the attack is to call this with `untrusted_off",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:597,Performance,load,load,597,"# Speculative Load Hardening. ## A Spectre Variant #1 Mitigation Technique. Author: Chandler Carruth - [chandlerc@google.com](mailto:chandlerc@google.com). ## Problem Statement. Recently, Google Project Zero and other researchers have found information leak; vulnerabilities by exploiting speculative execution in modern CPUs. These; exploits are currently broken down into three variants:; * GPZ Variant #1 (a.k.a. Spectre Variant #1): Bounds check (or predicate) bypass; * GPZ Variant #2 (a.k.a. Spectre Variant #2): Branch target injection; * GPZ Variant #3 (a.k.a. Meltdown): Rogue data cache load. For more details, see the Google Project Zero blog post and the Spectre research; paper:; * https://googleprojectzero.blogspot.com/2018/01/reading-privileged-memory-with-side.html; * https://spectreattack.com/spectre.pdf. The core problem of GPZ Variant #1 is that speculative execution uses branch; prediction to select the path of instructions speculatively executed. This path; is speculatively executed with the available data, and may load from memory and; leak the loaded values through various side channels that survive even when the; speculative execution is unwound due to being incorrect. Mispredicted paths can; cause code to be executed with data inputs that never occur in correct; executions, making checks against malicious inputs ineffective and allowing; attackers to use malicious data inputs to leak secret data. Here is an example,; extracted and simplified from the Project Zero paper:; ```; struct array {; unsigned long length;; unsigned char data[];; };; struct array *arr1 = ...; // small array; struct array *arr2 = ...; // array of size 0x400; unsigned long untrusted_offset_from_caller = ...;; if (untrusted_offset_from_caller < arr1->length) {; unsigned char value = arr1->data[untrusted_offset_from_caller];; unsigned long index2 = ((value&1)*0x100)+0x200;; unsigned char value2 = arr2->data[index2];; }; ```. The key of the attack is to call this with `untrusted_off",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:1043,Performance,load,load,1043,"ndler Carruth - [chandlerc@google.com](mailto:chandlerc@google.com). ## Problem Statement. Recently, Google Project Zero and other researchers have found information leak; vulnerabilities by exploiting speculative execution in modern CPUs. These; exploits are currently broken down into three variants:; * GPZ Variant #1 (a.k.a. Spectre Variant #1): Bounds check (or predicate) bypass; * GPZ Variant #2 (a.k.a. Spectre Variant #2): Branch target injection; * GPZ Variant #3 (a.k.a. Meltdown): Rogue data cache load. For more details, see the Google Project Zero blog post and the Spectre research; paper:; * https://googleprojectzero.blogspot.com/2018/01/reading-privileged-memory-with-side.html; * https://spectreattack.com/spectre.pdf. The core problem of GPZ Variant #1 is that speculative execution uses branch; prediction to select the path of instructions speculatively executed. This path; is speculatively executed with the available data, and may load from memory and; leak the loaded values through various side channels that survive even when the; speculative execution is unwound due to being incorrect. Mispredicted paths can; cause code to be executed with data inputs that never occur in correct; executions, making checks against malicious inputs ineffective and allowing; attackers to use malicious data inputs to leak secret data. Here is an example,; extracted and simplified from the Project Zero paper:; ```; struct array {; unsigned long length;; unsigned char data[];; };; struct array *arr1 = ...; // small array; struct array *arr2 = ...; // array of size 0x400; unsigned long untrusted_offset_from_caller = ...;; if (untrusted_offset_from_caller < arr1->length) {; unsigned char value = arr1->data[untrusted_offset_from_caller];; unsigned long index2 = ((value&1)*0x100)+0x200;; unsigned char value2 = arr2->data[index2];; }; ```. The key of the attack is to call this with `untrusted_offset_from_caller` that; is far outside of the bounds when the branch predictor will pre",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:1074,Performance,load,loaded,1074,"ndler Carruth - [chandlerc@google.com](mailto:chandlerc@google.com). ## Problem Statement. Recently, Google Project Zero and other researchers have found information leak; vulnerabilities by exploiting speculative execution in modern CPUs. These; exploits are currently broken down into three variants:; * GPZ Variant #1 (a.k.a. Spectre Variant #1): Bounds check (or predicate) bypass; * GPZ Variant #2 (a.k.a. Spectre Variant #2): Branch target injection; * GPZ Variant #3 (a.k.a. Meltdown): Rogue data cache load. For more details, see the Google Project Zero blog post and the Spectre research; paper:; * https://googleprojectzero.blogspot.com/2018/01/reading-privileged-memory-with-side.html; * https://spectreattack.com/spectre.pdf. The core problem of GPZ Variant #1 is that speculative execution uses branch; prediction to select the path of instructions speculatively executed. This path; is speculatively executed with the available data, and may load from memory and; leak the loaded values through various side channels that survive even when the; speculative execution is unwound due to being incorrect. Mispredicted paths can; cause code to be executed with data inputs that never occur in correct; executions, making checks against malicious inputs ineffective and allowing; attackers to use malicious data inputs to leak secret data. Here is an example,; extracted and simplified from the Project Zero paper:; ```; struct array {; unsigned long length;; unsigned char data[];; };; struct array *arr1 = ...; // small array; struct array *arr2 = ...; // array of size 0x400; unsigned long untrusted_offset_from_caller = ...;; if (untrusted_offset_from_caller < arr1->length) {; unsigned char value = arr1->data[untrusted_offset_from_caller];; unsigned long index2 = ((value&1)*0x100)+0x200;; unsigned char value2 = arr2->data[index2];; }; ```. The key of the attack is to call this with `untrusted_offset_from_caller` that; is far outside of the bounds when the branch predictor will pre",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:2245,Performance,cache,cache-timing,2245," can; cause code to be executed with data inputs that never occur in correct; executions, making checks against malicious inputs ineffective and allowing; attackers to use malicious data inputs to leak secret data. Here is an example,; extracted and simplified from the Project Zero paper:; ```; struct array {; unsigned long length;; unsigned char data[];; };; struct array *arr1 = ...; // small array; struct array *arr2 = ...; // array of size 0x400; unsigned long untrusted_offset_from_caller = ...;; if (untrusted_offset_from_caller < arr1->length) {; unsigned char value = arr1->data[untrusted_offset_from_caller];; unsigned long index2 = ((value&1)*0x100)+0x200;; unsigned char value2 = arr2->data[index2];; }; ```. The key of the attack is to call this with `untrusted_offset_from_caller` that; is far outside of the bounds when the branch predictor will predict that it; will be in-bounds. In that case, the body of the `if` will be executed; speculatively, and may read secret data into `value` and leak it via a; cache-timing side channel when a dependent access is made to populate `value2`. ## High Level Mitigation Approach. While several approaches are being actively pursued to mitigate specific; branches and/or loads inside especially risky software (most notably various OS; kernels), these approaches require manual and/or static analysis aided auditing; of code and explicit source changes to apply the mitigation. They are unlikely; to scale well to large applications. We are proposing a comprehensive; mitigation approach that would apply automatically across an entire program; rather than through manual changes to the code. While this is likely to have a; high performance cost, some applications may be in a good position to take this; performance / security tradeoff. The specific technique we propose is to cause loads to be checked using; branchless code to ensure that they are executing along a valid control flow; path. Consider the following C-pseudo-code representi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:2450,Performance,load,loads,2450,"er:; ```; struct array {; unsigned long length;; unsigned char data[];; };; struct array *arr1 = ...; // small array; struct array *arr2 = ...; // array of size 0x400; unsigned long untrusted_offset_from_caller = ...;; if (untrusted_offset_from_caller < arr1->length) {; unsigned char value = arr1->data[untrusted_offset_from_caller];; unsigned long index2 = ((value&1)*0x100)+0x200;; unsigned char value2 = arr2->data[index2];; }; ```. The key of the attack is to call this with `untrusted_offset_from_caller` that; is far outside of the bounds when the branch predictor will predict that it; will be in-bounds. In that case, the body of the `if` will be executed; speculatively, and may read secret data into `value` and leak it via a; cache-timing side channel when a dependent access is made to populate `value2`. ## High Level Mitigation Approach. While several approaches are being actively pursued to mitigate specific; branches and/or loads inside especially risky software (most notably various OS; kernels), these approaches require manual and/or static analysis aided auditing; of code and explicit source changes to apply the mitigation. They are unlikely; to scale well to large applications. We are proposing a comprehensive; mitigation approach that would apply automatically across an entire program; rather than through manual changes to the code. While this is likely to have a; high performance cost, some applications may be in a good position to take this; performance / security tradeoff. The specific technique we propose is to cause loads to be checked using; branchless code to ensure that they are executing along a valid control flow; path. Consider the following C-pseudo-code representing the core idea of a; predicate guarding potentially invalid loads:; ```; void leak(int data);; void example(int* pointer1, int* pointer2) {; if (condition) {; // ... lots of code ...; leak(*pointer1);; } else {; // ... more code ...; leak(*pointer2);; }; }; ```. This would get transf",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:2909,Performance,perform,performance,2909,"The key of the attack is to call this with `untrusted_offset_from_caller` that; is far outside of the bounds when the branch predictor will predict that it; will be in-bounds. In that case, the body of the `if` will be executed; speculatively, and may read secret data into `value` and leak it via a; cache-timing side channel when a dependent access is made to populate `value2`. ## High Level Mitigation Approach. While several approaches are being actively pursued to mitigate specific; branches and/or loads inside especially risky software (most notably various OS; kernels), these approaches require manual and/or static analysis aided auditing; of code and explicit source changes to apply the mitigation. They are unlikely; to scale well to large applications. We are proposing a comprehensive; mitigation approach that would apply automatically across an entire program; rather than through manual changes to the code. While this is likely to have a; high performance cost, some applications may be in a good position to take this; performance / security tradeoff. The specific technique we propose is to cause loads to be checked using; branchless code to ensure that they are executing along a valid control flow; path. Consider the following C-pseudo-code representing the core idea of a; predicate guarding potentially invalid loads:; ```; void leak(int data);; void example(int* pointer1, int* pointer2) {; if (condition) {; // ... lots of code ...; leak(*pointer1);; } else {; // ... more code ...; leak(*pointer2);; }; }; ```. This would get transformed into something resembling the following:; ```; uintptr_t all_ones_mask = std::numerical_limits<uintptr_t>::max();; uintptr_t all_zeros_mask = 0;; void leak(int data);; void example(int* pointer1, int* pointer2) {; uintptr_t predicate_state = all_ones_mask;; if (condition) {; // Assuming ?: is implemented using branchless logic...; predicate_state = !condition ? all_zeros_mask : predicate_state;; // ... lots of code ...; //; //",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:2985,Performance,perform,performance,2985,"The key of the attack is to call this with `untrusted_offset_from_caller` that; is far outside of the bounds when the branch predictor will predict that it; will be in-bounds. In that case, the body of the `if` will be executed; speculatively, and may read secret data into `value` and leak it via a; cache-timing side channel when a dependent access is made to populate `value2`. ## High Level Mitigation Approach. While several approaches are being actively pursued to mitigate specific; branches and/or loads inside especially risky software (most notably various OS; kernels), these approaches require manual and/or static analysis aided auditing; of code and explicit source changes to apply the mitigation. They are unlikely; to scale well to large applications. We are proposing a comprehensive; mitigation approach that would apply automatically across an entire program; rather than through manual changes to the code. While this is likely to have a; high performance cost, some applications may be in a good position to take this; performance / security tradeoff. The specific technique we propose is to cause loads to be checked using; branchless code to ensure that they are executing along a valid control flow; path. Consider the following C-pseudo-code representing the core idea of a; predicate guarding potentially invalid loads:; ```; void leak(int data);; void example(int* pointer1, int* pointer2) {; if (condition) {; // ... lots of code ...; leak(*pointer1);; } else {; // ... more code ...; leak(*pointer2);; }; }; ```. This would get transformed into something resembling the following:; ```; uintptr_t all_ones_mask = std::numerical_limits<uintptr_t>::max();; uintptr_t all_zeros_mask = 0;; void leak(int data);; void example(int* pointer1, int* pointer2) {; uintptr_t predicate_state = all_ones_mask;; if (condition) {; // Assuming ?: is implemented using branchless logic...; predicate_state = !condition ? all_zeros_mask : predicate_state;; // ... lots of code ...; //; //",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:3064,Performance,load,loads,3064,"t it; will be in-bounds. In that case, the body of the `if` will be executed; speculatively, and may read secret data into `value` and leak it via a; cache-timing side channel when a dependent access is made to populate `value2`. ## High Level Mitigation Approach. While several approaches are being actively pursued to mitigate specific; branches and/or loads inside especially risky software (most notably various OS; kernels), these approaches require manual and/or static analysis aided auditing; of code and explicit source changes to apply the mitigation. They are unlikely; to scale well to large applications. We are proposing a comprehensive; mitigation approach that would apply automatically across an entire program; rather than through manual changes to the code. While this is likely to have a; high performance cost, some applications may be in a good position to take this; performance / security tradeoff. The specific technique we propose is to cause loads to be checked using; branchless code to ensure that they are executing along a valid control flow; path. Consider the following C-pseudo-code representing the core idea of a; predicate guarding potentially invalid loads:; ```; void leak(int data);; void example(int* pointer1, int* pointer2) {; if (condition) {; // ... lots of code ...; leak(*pointer1);; } else {; // ... more code ...; leak(*pointer2);; }; }; ```. This would get transformed into something resembling the following:; ```; uintptr_t all_ones_mask = std::numerical_limits<uintptr_t>::max();; uintptr_t all_zeros_mask = 0;; void leak(int data);; void example(int* pointer1, int* pointer2) {; uintptr_t predicate_state = all_ones_mask;; if (condition) {; // Assuming ?: is implemented using branchless logic...; predicate_state = !condition ? all_zeros_mask : predicate_state;; // ... lots of code ...; //; // Harden the pointer so it can't be loaded; pointer1 &= predicate_state;; leak(*pointer1);; } else {; predicate_state = condition ? all_zeros_mask : pred",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:3284,Performance,load,loads,3284,"pendent access is made to populate `value2`. ## High Level Mitigation Approach. While several approaches are being actively pursued to mitigate specific; branches and/or loads inside especially risky software (most notably various OS; kernels), these approaches require manual and/or static analysis aided auditing; of code and explicit source changes to apply the mitigation. They are unlikely; to scale well to large applications. We are proposing a comprehensive; mitigation approach that would apply automatically across an entire program; rather than through manual changes to the code. While this is likely to have a; high performance cost, some applications may be in a good position to take this; performance / security tradeoff. The specific technique we propose is to cause loads to be checked using; branchless code to ensure that they are executing along a valid control flow; path. Consider the following C-pseudo-code representing the core idea of a; predicate guarding potentially invalid loads:; ```; void leak(int data);; void example(int* pointer1, int* pointer2) {; if (condition) {; // ... lots of code ...; leak(*pointer1);; } else {; // ... more code ...; leak(*pointer2);; }; }; ```. This would get transformed into something resembling the following:; ```; uintptr_t all_ones_mask = std::numerical_limits<uintptr_t>::max();; uintptr_t all_zeros_mask = 0;; void leak(int data);; void example(int* pointer1, int* pointer2) {; uintptr_t predicate_state = all_ones_mask;; if (condition) {; // Assuming ?: is implemented using branchless logic...; predicate_state = !condition ? all_zeros_mask : predicate_state;; // ... lots of code ...; //; // Harden the pointer so it can't be loaded; pointer1 &= predicate_state;; leak(*pointer1);; } else {; predicate_state = condition ? all_zeros_mask : predicate_state;; // ... more code ...; //; // Alternative: Harden the loaded value; int value2 = *pointer2 & predicate_state;; leak(value2);; }; }; ```. The result should be that if the `i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:3979,Performance,load,loaded,3979,"cific technique we propose is to cause loads to be checked using; branchless code to ensure that they are executing along a valid control flow; path. Consider the following C-pseudo-code representing the core idea of a; predicate guarding potentially invalid loads:; ```; void leak(int data);; void example(int* pointer1, int* pointer2) {; if (condition) {; // ... lots of code ...; leak(*pointer1);; } else {; // ... more code ...; leak(*pointer2);; }; }; ```. This would get transformed into something resembling the following:; ```; uintptr_t all_ones_mask = std::numerical_limits<uintptr_t>::max();; uintptr_t all_zeros_mask = 0;; void leak(int data);; void example(int* pointer1, int* pointer2) {; uintptr_t predicate_state = all_ones_mask;; if (condition) {; // Assuming ?: is implemented using branchless logic...; predicate_state = !condition ? all_zeros_mask : predicate_state;; // ... lots of code ...; //; // Harden the pointer so it can't be loaded; pointer1 &= predicate_state;; leak(*pointer1);; } else {; predicate_state = condition ? all_zeros_mask : predicate_state;; // ... more code ...; //; // Alternative: Harden the loaded value; int value2 = *pointer2 & predicate_state;; leak(value2);; }; }; ```. The result should be that if the `if (condition) {` branch is mis-predicted,; there is a *data* dependency on the condition used to zero out any pointers; prior to loading through them or to zero out all of the loaded bits. Even; though this code pattern may still execute speculatively, *invalid* speculative; executions are prevented from leaking secret data from memory (but note that; this data might still be loaded in safe ways, and some regions of memory are; required to not hold secrets, see below for detailed limitations). This; approach only requires the underlying hardware have a way to implement a; branchless and unpredicted conditional update of a register's value. All modern; architectures have support for this, and in fact such support is necessary to; corre",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:4163,Performance,load,loaded,4163," following C-pseudo-code representing the core idea of a; predicate guarding potentially invalid loads:; ```; void leak(int data);; void example(int* pointer1, int* pointer2) {; if (condition) {; // ... lots of code ...; leak(*pointer1);; } else {; // ... more code ...; leak(*pointer2);; }; }; ```. This would get transformed into something resembling the following:; ```; uintptr_t all_ones_mask = std::numerical_limits<uintptr_t>::max();; uintptr_t all_zeros_mask = 0;; void leak(int data);; void example(int* pointer1, int* pointer2) {; uintptr_t predicate_state = all_ones_mask;; if (condition) {; // Assuming ?: is implemented using branchless logic...; predicate_state = !condition ? all_zeros_mask : predicate_state;; // ... lots of code ...; //; // Harden the pointer so it can't be loaded; pointer1 &= predicate_state;; leak(*pointer1);; } else {; predicate_state = condition ? all_zeros_mask : predicate_state;; // ... more code ...; //; // Alternative: Harden the loaded value; int value2 = *pointer2 & predicate_state;; leak(value2);; }; }; ```. The result should be that if the `if (condition) {` branch is mis-predicted,; there is a *data* dependency on the condition used to zero out any pointers; prior to loading through them or to zero out all of the loaded bits. Even; though this code pattern may still execute speculatively, *invalid* speculative; executions are prevented from leaking secret data from memory (but note that; this data might still be loaded in safe ways, and some regions of memory are; required to not hold secrets, see below for detailed limitations). This; approach only requires the underlying hardware have a way to implement a; branchless and unpredicted conditional update of a register's value. All modern; architectures have support for this, and in fact such support is necessary to; correctly implement constant time cryptographic primitives. Crucial properties of this approach:; * It is not preventing any particular side-channel from working. This ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:4410,Performance,load,loading,4410,"er2) {; if (condition) {; // ... lots of code ...; leak(*pointer1);; } else {; // ... more code ...; leak(*pointer2);; }; }; ```. This would get transformed into something resembling the following:; ```; uintptr_t all_ones_mask = std::numerical_limits<uintptr_t>::max();; uintptr_t all_zeros_mask = 0;; void leak(int data);; void example(int* pointer1, int* pointer2) {; uintptr_t predicate_state = all_ones_mask;; if (condition) {; // Assuming ?: is implemented using branchless logic...; predicate_state = !condition ? all_zeros_mask : predicate_state;; // ... lots of code ...; //; // Harden the pointer so it can't be loaded; pointer1 &= predicate_state;; leak(*pointer1);; } else {; predicate_state = condition ? all_zeros_mask : predicate_state;; // ... more code ...; //; // Alternative: Harden the loaded value; int value2 = *pointer2 & predicate_state;; leak(value2);; }; }; ```. The result should be that if the `if (condition) {` branch is mis-predicted,; there is a *data* dependency on the condition used to zero out any pointers; prior to loading through them or to zero out all of the loaded bits. Even; though this code pattern may still execute speculatively, *invalid* speculative; executions are prevented from leaking secret data from memory (but note that; this data might still be loaded in safe ways, and some regions of memory are; required to not hold secrets, see below for detailed limitations). This; approach only requires the underlying hardware have a way to implement a; branchless and unpredicted conditional update of a register's value. All modern; architectures have support for this, and in fact such support is necessary to; correctly implement constant time cryptographic primitives. Crucial properties of this approach:; * It is not preventing any particular side-channel from working. This is; important as there are an unknown number of potential side channels and we; expect to continue discovering more. Instead, it prevents the observation of; secret data",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:4457,Performance,load,loaded,4457,"er2) {; if (condition) {; // ... lots of code ...; leak(*pointer1);; } else {; // ... more code ...; leak(*pointer2);; }; }; ```. This would get transformed into something resembling the following:; ```; uintptr_t all_ones_mask = std::numerical_limits<uintptr_t>::max();; uintptr_t all_zeros_mask = 0;; void leak(int data);; void example(int* pointer1, int* pointer2) {; uintptr_t predicate_state = all_ones_mask;; if (condition) {; // Assuming ?: is implemented using branchless logic...; predicate_state = !condition ? all_zeros_mask : predicate_state;; // ... lots of code ...; //; // Harden the pointer so it can't be loaded; pointer1 &= predicate_state;; leak(*pointer1);; } else {; predicate_state = condition ? all_zeros_mask : predicate_state;; // ... more code ...; //; // Alternative: Harden the loaded value; int value2 = *pointer2 & predicate_state;; leak(value2);; }; }; ```. The result should be that if the `if (condition) {` branch is mis-predicted,; there is a *data* dependency on the condition used to zero out any pointers; prior to loading through them or to zero out all of the loaded bits. Even; though this code pattern may still execute speculatively, *invalid* speculative; executions are prevented from leaking secret data from memory (but note that; this data might still be loaded in safe ways, and some regions of memory are; required to not hold secrets, see below for detailed limitations). This; approach only requires the underlying hardware have a way to implement a; branchless and unpredicted conditional update of a register's value. All modern; architectures have support for this, and in fact such support is necessary to; correctly implement constant time cryptographic primitives. Crucial properties of this approach:; * It is not preventing any particular side-channel from working. This is; important as there are an unknown number of potential side channels and we; expect to continue discovering more. Instead, it prevents the observation of; secret data",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:4660,Performance,load,loaded,4660,"();; uintptr_t all_zeros_mask = 0;; void leak(int data);; void example(int* pointer1, int* pointer2) {; uintptr_t predicate_state = all_ones_mask;; if (condition) {; // Assuming ?: is implemented using branchless logic...; predicate_state = !condition ? all_zeros_mask : predicate_state;; // ... lots of code ...; //; // Harden the pointer so it can't be loaded; pointer1 &= predicate_state;; leak(*pointer1);; } else {; predicate_state = condition ? all_zeros_mask : predicate_state;; // ... more code ...; //; // Alternative: Harden the loaded value; int value2 = *pointer2 & predicate_state;; leak(value2);; }; }; ```. The result should be that if the `if (condition) {` branch is mis-predicted,; there is a *data* dependency on the condition used to zero out any pointers; prior to loading through them or to zero out all of the loaded bits. Even; though this code pattern may still execute speculatively, *invalid* speculative; executions are prevented from leaking secret data from memory (but note that; this data might still be loaded in safe ways, and some regions of memory are; required to not hold secrets, see below for detailed limitations). This; approach only requires the underlying hardware have a way to implement a; branchless and unpredicted conditional update of a register's value. All modern; architectures have support for this, and in fact such support is necessary to; correctly implement constant time cryptographic primitives. Crucial properties of this approach:; * It is not preventing any particular side-channel from working. This is; important as there are an unknown number of potential side channels and we; expect to continue discovering more. Instead, it prevents the observation of; secret data in the first place.; * It accumulates the predicate state, protecting even in the face of nested; *correctly* predicted control flows.; * It passes this predicate state across function boundaries to provide; [interprocedural protection](#interprocedural-checking).; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:5658,Performance,load,load,5658,"d to not hold secrets, see below for detailed limitations). This; approach only requires the underlying hardware have a way to implement a; branchless and unpredicted conditional update of a register's value. All modern; architectures have support for this, and in fact such support is necessary to; correctly implement constant time cryptographic primitives. Crucial properties of this approach:; * It is not preventing any particular side-channel from working. This is; important as there are an unknown number of potential side channels and we; expect to continue discovering more. Instead, it prevents the observation of; secret data in the first place.; * It accumulates the predicate state, protecting even in the face of nested; *correctly* predicted control flows.; * It passes this predicate state across function boundaries to provide; [interprocedural protection](#interprocedural-checking).; * When hardening the address of a load, it uses a *destructive* or; *non-reversible* modification of the address to prevent an attacker from; reversing the check using attacker-controlled inputs.; * It does not completely block speculative execution, and merely prevents; *mis*-speculated paths from leaking secrets from memory (and stalls; speculation until this can be determined).; * It is completely general and makes no fundamental assumptions about the; underlying architecture other than the ability to do branchless conditional; data updates and a lack of value prediction.; * It does not require programmers to identify all possible secret data using; static source code annotations or code vulnerable to a variant #1 style; attack. Limitations of this approach:; * It requires re-compiling source code to insert hardening instruction; sequences. Only software compiled in this mode is protected.; * The performance is heavily dependent on a particular architecture's; implementation strategy. We outline a potential x86 implementation below and; characterize its performance.; * It does ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:6537,Performance,perform,performance,6537,"dural protection](#interprocedural-checking).; * When hardening the address of a load, it uses a *destructive* or; *non-reversible* modification of the address to prevent an attacker from; reversing the check using attacker-controlled inputs.; * It does not completely block speculative execution, and merely prevents; *mis*-speculated paths from leaking secrets from memory (and stalls; speculation until this can be determined).; * It is completely general and makes no fundamental assumptions about the; underlying architecture other than the ability to do branchless conditional; data updates and a lack of value prediction.; * It does not require programmers to identify all possible secret data using; static source code annotations or code vulnerable to a variant #1 style; attack. Limitations of this approach:; * It requires re-compiling source code to insert hardening instruction; sequences. Only software compiled in this mode is protected.; * The performance is heavily dependent on a particular architecture's; implementation strategy. We outline a potential x86 implementation below and; characterize its performance.; * It does not defend against secret data already loaded from memory and; residing in registers or leaked through other side-channels in; non-speculative execution. Code dealing with this, e.g cryptographic; routines, already uses constant-time algorithms and code to prevent; side-channels. Such code should also scrub registers of secret data following; [these; guidelines](https://github.com/HACS-workshop/spectre-mitigations/blob/master/crypto_guidelines.md).; * To achieve reasonable performance, many loads may not be checked, such as; those with compile-time fixed addresses. This primarily consists of accesses; at compile-time constant offsets of global and local variables. Code which; needs this protection and intentionally stores secret data must ensure the; memory regions used for secret data are necessarily dynamic mappings or heap; allocations. This ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:6697,Performance,perform,performance,6697,"uses a *destructive* or; *non-reversible* modification of the address to prevent an attacker from; reversing the check using attacker-controlled inputs.; * It does not completely block speculative execution, and merely prevents; *mis*-speculated paths from leaking secrets from memory (and stalls; speculation until this can be determined).; * It is completely general and makes no fundamental assumptions about the; underlying architecture other than the ability to do branchless conditional; data updates and a lack of value prediction.; * It does not require programmers to identify all possible secret data using; static source code annotations or code vulnerable to a variant #1 style; attack. Limitations of this approach:; * It requires re-compiling source code to insert hardening instruction; sequences. Only software compiled in this mode is protected.; * The performance is heavily dependent on a particular architecture's; implementation strategy. We outline a potential x86 implementation below and; characterize its performance.; * It does not defend against secret data already loaded from memory and; residing in registers or leaked through other side-channels in; non-speculative execution. Code dealing with this, e.g cryptographic; routines, already uses constant-time algorithms and code to prevent; side-channels. Such code should also scrub registers of secret data following; [these; guidelines](https://github.com/HACS-workshop/spectre-mitigations/blob/master/crypto_guidelines.md).; * To achieve reasonable performance, many loads may not be checked, such as; those with compile-time fixed addresses. This primarily consists of accesses; at compile-time constant offsets of global and local variables. Code which; needs this protection and intentionally stores secret data must ensure the; memory regions used for secret data are necessarily dynamic mappings or heap; allocations. This is an area which can be tuned to provide more comprehensive; protection at the cost of per",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:6760,Performance,load,loaded,6760," attacker-controlled inputs.; * It does not completely block speculative execution, and merely prevents; *mis*-speculated paths from leaking secrets from memory (and stalls; speculation until this can be determined).; * It is completely general and makes no fundamental assumptions about the; underlying architecture other than the ability to do branchless conditional; data updates and a lack of value prediction.; * It does not require programmers to identify all possible secret data using; static source code annotations or code vulnerable to a variant #1 style; attack. Limitations of this approach:; * It requires re-compiling source code to insert hardening instruction; sequences. Only software compiled in this mode is protected.; * The performance is heavily dependent on a particular architecture's; implementation strategy. We outline a potential x86 implementation below and; characterize its performance.; * It does not defend against secret data already loaded from memory and; residing in registers or leaked through other side-channels in; non-speculative execution. Code dealing with this, e.g cryptographic; routines, already uses constant-time algorithms and code to prevent; side-channels. Such code should also scrub registers of secret data following; [these; guidelines](https://github.com/HACS-workshop/spectre-mitigations/blob/master/crypto_guidelines.md).; * To achieve reasonable performance, many loads may not be checked, such as; those with compile-time fixed addresses. This primarily consists of accesses; at compile-time constant offsets of global and local variables. Code which; needs this protection and intentionally stores secret data must ensure the; memory regions used for secret data are necessarily dynamic mappings or heap; allocations. This is an area which can be tuned to provide more comprehensive; protection at the cost of performance.; * [Hardened loads](#hardening-the-address-of-the-load) may still load data from; _valid_ addresses if not _attack",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:7199,Performance,perform,performance,7199,"grammers to identify all possible secret data using; static source code annotations or code vulnerable to a variant #1 style; attack. Limitations of this approach:; * It requires re-compiling source code to insert hardening instruction; sequences. Only software compiled in this mode is protected.; * The performance is heavily dependent on a particular architecture's; implementation strategy. We outline a potential x86 implementation below and; characterize its performance.; * It does not defend against secret data already loaded from memory and; residing in registers or leaked through other side-channels in; non-speculative execution. Code dealing with this, e.g cryptographic; routines, already uses constant-time algorithms and code to prevent; side-channels. Such code should also scrub registers of secret data following; [these; guidelines](https://github.com/HACS-workshop/spectre-mitigations/blob/master/crypto_guidelines.md).; * To achieve reasonable performance, many loads may not be checked, such as; those with compile-time fixed addresses. This primarily consists of accesses; at compile-time constant offsets of global and local variables. Code which; needs this protection and intentionally stores secret data must ensure the; memory regions used for secret data are necessarily dynamic mappings or heap; allocations. This is an area which can be tuned to provide more comprehensive; protection at the cost of performance.; * [Hardened loads](#hardening-the-address-of-the-load) may still load data from; _valid_ addresses if not _attacker-controlled_ addresses. To prevent these; from reading secret data, the low 2gb of the address space and 2gb above and; below any executable pages should be protected. Credit:; * The core idea of tracing misspeculation through data and marking pointers to; block misspeculated loads was developed as part of a HACS 2018 discussion; between Chandler Carruth, Paul Kocher, Thomas Pornin, and several other; individuals.; * Core idea of maski",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:7217,Performance,load,loads,7217,"grammers to identify all possible secret data using; static source code annotations or code vulnerable to a variant #1 style; attack. Limitations of this approach:; * It requires re-compiling source code to insert hardening instruction; sequences. Only software compiled in this mode is protected.; * The performance is heavily dependent on a particular architecture's; implementation strategy. We outline a potential x86 implementation below and; characterize its performance.; * It does not defend against secret data already loaded from memory and; residing in registers or leaked through other side-channels in; non-speculative execution. Code dealing with this, e.g cryptographic; routines, already uses constant-time algorithms and code to prevent; side-channels. Such code should also scrub registers of secret data following; [these; guidelines](https://github.com/HACS-workshop/spectre-mitigations/blob/master/crypto_guidelines.md).; * To achieve reasonable performance, many loads may not be checked, such as; those with compile-time fixed addresses. This primarily consists of accesses; at compile-time constant offsets of global and local variables. Code which; needs this protection and intentionally stores secret data must ensure the; memory regions used for secret data are necessarily dynamic mappings or heap; allocations. This is an area which can be tuned to provide more comprehensive; protection at the cost of performance.; * [Hardened loads](#hardening-the-address-of-the-load) may still load data from; _valid_ addresses if not _attacker-controlled_ addresses. To prevent these; from reading secret data, the low 2gb of the address space and 2gb above and; below any executable pages should be protected. Credit:; * The core idea of tracing misspeculation through data and marking pointers to; block misspeculated loads was developed as part of a HACS 2018 discussion; between Chandler Carruth, Paul Kocher, Thomas Pornin, and several other; individuals.; * Core idea of maski",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:7602,Performance,tune,tuned,7602,"y. We outline a potential x86 implementation below and; characterize its performance.; * It does not defend against secret data already loaded from memory and; residing in registers or leaked through other side-channels in; non-speculative execution. Code dealing with this, e.g cryptographic; routines, already uses constant-time algorithms and code to prevent; side-channels. Such code should also scrub registers of secret data following; [these; guidelines](https://github.com/HACS-workshop/spectre-mitigations/blob/master/crypto_guidelines.md).; * To achieve reasonable performance, many loads may not be checked, such as; those with compile-time fixed addresses. This primarily consists of accesses; at compile-time constant offsets of global and local variables. Code which; needs this protection and intentionally stores secret data must ensure the; memory regions used for secret data are necessarily dynamic mappings or heap; allocations. This is an area which can be tuned to provide more comprehensive; protection at the cost of performance.; * [Hardened loads](#hardening-the-address-of-the-load) may still load data from; _valid_ addresses if not _attacker-controlled_ addresses. To prevent these; from reading secret data, the low 2gb of the address space and 2gb above and; below any executable pages should be protected. Credit:; * The core idea of tracing misspeculation through data and marking pointers to; block misspeculated loads was developed as part of a HACS 2018 discussion; between Chandler Carruth, Paul Kocher, Thomas Pornin, and several other; individuals.; * Core idea of masking out loaded bits was part of the original mitigation; suggested by Jann Horn when these attacks were reported. ### Indirect Branches, Calls, and Returns. It is possible to attack control flow other than conditional branches with; variant #1 style mispredictions.; * A prediction towards a hot call target of a virtual method can lead to it; being speculatively executed when an expected typ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:7665,Performance,perform,performance,7665,"y. We outline a potential x86 implementation below and; characterize its performance.; * It does not defend against secret data already loaded from memory and; residing in registers or leaked through other side-channels in; non-speculative execution. Code dealing with this, e.g cryptographic; routines, already uses constant-time algorithms and code to prevent; side-channels. Such code should also scrub registers of secret data following; [these; guidelines](https://github.com/HACS-workshop/spectre-mitigations/blob/master/crypto_guidelines.md).; * To achieve reasonable performance, many loads may not be checked, such as; those with compile-time fixed addresses. This primarily consists of accesses; at compile-time constant offsets of global and local variables. Code which; needs this protection and intentionally stores secret data must ensure the; memory regions used for secret data are necessarily dynamic mappings or heap; allocations. This is an area which can be tuned to provide more comprehensive; protection at the cost of performance.; * [Hardened loads](#hardening-the-address-of-the-load) may still load data from; _valid_ addresses if not _attacker-controlled_ addresses. To prevent these; from reading secret data, the low 2gb of the address space and 2gb above and; below any executable pages should be protected. Credit:; * The core idea of tracing misspeculation through data and marking pointers to; block misspeculated loads was developed as part of a HACS 2018 discussion; between Chandler Carruth, Paul Kocher, Thomas Pornin, and several other; individuals.; * Core idea of masking out loaded bits was part of the original mitigation; suggested by Jann Horn when these attacks were reported. ### Indirect Branches, Calls, and Returns. It is possible to attack control flow other than conditional branches with; variant #1 style mispredictions.; * A prediction towards a hot call target of a virtual method can lead to it; being speculatively executed when an expected typ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:7691,Performance,load,loads,7691,"data already loaded from memory and; residing in registers or leaked through other side-channels in; non-speculative execution. Code dealing with this, e.g cryptographic; routines, already uses constant-time algorithms and code to prevent; side-channels. Such code should also scrub registers of secret data following; [these; guidelines](https://github.com/HACS-workshop/spectre-mitigations/blob/master/crypto_guidelines.md).; * To achieve reasonable performance, many loads may not be checked, such as; those with compile-time fixed addresses. This primarily consists of accesses; at compile-time constant offsets of global and local variables. Code which; needs this protection and intentionally stores secret data must ensure the; memory regions used for secret data are necessarily dynamic mappings or heap; allocations. This is an area which can be tuned to provide more comprehensive; protection at the cost of performance.; * [Hardened loads](#hardening-the-address-of-the-load) may still load data from; _valid_ addresses if not _attacker-controlled_ addresses. To prevent these; from reading secret data, the low 2gb of the address space and 2gb above and; below any executable pages should be protected. Credit:; * The core idea of tracing misspeculation through data and marking pointers to; block misspeculated loads was developed as part of a HACS 2018 discussion; between Chandler Carruth, Paul Kocher, Thomas Pornin, and several other; individuals.; * Core idea of masking out loaded bits was part of the original mitigation; suggested by Jann Horn when these attacks were reported. ### Indirect Branches, Calls, and Returns. It is possible to attack control flow other than conditional branches with; variant #1 style mispredictions.; * A prediction towards a hot call target of a virtual method can lead to it; being speculatively executed when an expected type is used (often called; ""type confusion"").; * A hot case may be speculatively executed due to prediction instead of the; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:7728,Performance,load,load,7728,"data already loaded from memory and; residing in registers or leaked through other side-channels in; non-speculative execution. Code dealing with this, e.g cryptographic; routines, already uses constant-time algorithms and code to prevent; side-channels. Such code should also scrub registers of secret data following; [these; guidelines](https://github.com/HACS-workshop/spectre-mitigations/blob/master/crypto_guidelines.md).; * To achieve reasonable performance, many loads may not be checked, such as; those with compile-time fixed addresses. This primarily consists of accesses; at compile-time constant offsets of global and local variables. Code which; needs this protection and intentionally stores secret data must ensure the; memory regions used for secret data are necessarily dynamic mappings or heap; allocations. This is an area which can be tuned to provide more comprehensive; protection at the cost of performance.; * [Hardened loads](#hardening-the-address-of-the-load) may still load data from; _valid_ addresses if not _attacker-controlled_ addresses. To prevent these; from reading secret data, the low 2gb of the address space and 2gb above and; below any executable pages should be protected. Credit:; * The core idea of tracing misspeculation through data and marking pointers to; block misspeculated loads was developed as part of a HACS 2018 discussion; between Chandler Carruth, Paul Kocher, Thomas Pornin, and several other; individuals.; * Core idea of masking out loaded bits was part of the original mitigation; suggested by Jann Horn when these attacks were reported. ### Indirect Branches, Calls, and Returns. It is possible to attack control flow other than conditional branches with; variant #1 style mispredictions.; * A prediction towards a hot call target of a virtual method can lead to it; being speculatively executed when an expected type is used (often called; ""type confusion"").; * A hot case may be speculatively executed due to prediction instead of the; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:7744,Performance,load,load,7744,"data already loaded from memory and; residing in registers or leaked through other side-channels in; non-speculative execution. Code dealing with this, e.g cryptographic; routines, already uses constant-time algorithms and code to prevent; side-channels. Such code should also scrub registers of secret data following; [these; guidelines](https://github.com/HACS-workshop/spectre-mitigations/blob/master/crypto_guidelines.md).; * To achieve reasonable performance, many loads may not be checked, such as; those with compile-time fixed addresses. This primarily consists of accesses; at compile-time constant offsets of global and local variables. Code which; needs this protection and intentionally stores secret data must ensure the; memory regions used for secret data are necessarily dynamic mappings or heap; allocations. This is an area which can be tuned to provide more comprehensive; protection at the cost of performance.; * [Hardened loads](#hardening-the-address-of-the-load) may still load data from; _valid_ addresses if not _attacker-controlled_ addresses. To prevent these; from reading secret data, the low 2gb of the address space and 2gb above and; below any executable pages should be protected. Credit:; * The core idea of tracing misspeculation through data and marking pointers to; block misspeculated loads was developed as part of a HACS 2018 discussion; between Chandler Carruth, Paul Kocher, Thomas Pornin, and several other; individuals.; * Core idea of masking out loaded bits was part of the original mitigation; suggested by Jann Horn when these attacks were reported. ### Indirect Branches, Calls, and Returns. It is possible to attack control flow other than conditional branches with; variant #1 style mispredictions.; * A prediction towards a hot call target of a virtual method can lead to it; being speculatively executed when an expected type is used (often called; ""type confusion"").; * A hot case may be speculatively executed due to prediction instead of the; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:8071,Performance,load,loads,8071,"https://github.com/HACS-workshop/spectre-mitigations/blob/master/crypto_guidelines.md).; * To achieve reasonable performance, many loads may not be checked, such as; those with compile-time fixed addresses. This primarily consists of accesses; at compile-time constant offsets of global and local variables. Code which; needs this protection and intentionally stores secret data must ensure the; memory regions used for secret data are necessarily dynamic mappings or heap; allocations. This is an area which can be tuned to provide more comprehensive; protection at the cost of performance.; * [Hardened loads](#hardening-the-address-of-the-load) may still load data from; _valid_ addresses if not _attacker-controlled_ addresses. To prevent these; from reading secret data, the low 2gb of the address space and 2gb above and; below any executable pages should be protected. Credit:; * The core idea of tracing misspeculation through data and marking pointers to; block misspeculated loads was developed as part of a HACS 2018 discussion; between Chandler Carruth, Paul Kocher, Thomas Pornin, and several other; individuals.; * Core idea of masking out loaded bits was part of the original mitigation; suggested by Jann Horn when these attacks were reported. ### Indirect Branches, Calls, and Returns. It is possible to attack control flow other than conditional branches with; variant #1 style mispredictions.; * A prediction towards a hot call target of a virtual method can lead to it; being speculatively executed when an expected type is used (often called; ""type confusion"").; * A hot case may be speculatively executed due to prediction instead of the; correct case for a switch statement implemented as a jump table.; * A hot common return address may be predicted incorrectly when returning from; a function. These code patterns are also vulnerable to Spectre variant #2, and as such are; best mitigated with a; [retpoline](https://support.google.com/faqs/answer/7625886) on x86 platforms.;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:8240,Performance,load,loaded,8240,"xed addresses. This primarily consists of accesses; at compile-time constant offsets of global and local variables. Code which; needs this protection and intentionally stores secret data must ensure the; memory regions used for secret data are necessarily dynamic mappings or heap; allocations. This is an area which can be tuned to provide more comprehensive; protection at the cost of performance.; * [Hardened loads](#hardening-the-address-of-the-load) may still load data from; _valid_ addresses if not _attacker-controlled_ addresses. To prevent these; from reading secret data, the low 2gb of the address space and 2gb above and; below any executable pages should be protected. Credit:; * The core idea of tracing misspeculation through data and marking pointers to; block misspeculated loads was developed as part of a HACS 2018 discussion; between Chandler Carruth, Paul Kocher, Thomas Pornin, and several other; individuals.; * Core idea of masking out loaded bits was part of the original mitigation; suggested by Jann Horn when these attacks were reported. ### Indirect Branches, Calls, and Returns. It is possible to attack control flow other than conditional branches with; variant #1 style mispredictions.; * A prediction towards a hot call target of a virtual method can lead to it; being speculatively executed when an expected type is used (often called; ""type confusion"").; * A hot case may be speculatively executed due to prediction instead of the; correct case for a switch statement implemented as a jump table.; * A hot common return address may be predicted incorrectly when returning from; a function. These code patterns are also vulnerable to Spectre variant #2, and as such are; best mitigated with a; [retpoline](https://support.google.com/faqs/answer/7625886) on x86 platforms.; When a mitigation technique like retpoline is used, speculation simply cannot; proceed through an indirect control flow edge (or it cannot be mispredicted in; the case of a filled RSB) and so",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:10181,Performance,load,loaded,10181,"ct control flow edge (or it cannot be mispredicted in; the case of a filled RSB) and so it is also protected from variant #1 style; attacks. However, some architectures, micro-architectures, or vendors do not; employ the retpoline mitigation, and on future x86 hardware (both Intel and; AMD) it is expected to become unnecessary due to hardware-based mitigation. When not using a retpoline, these edges will need independent protection from; variant #1 style attacks. The analogous approach to that used for conditional; control flow should work:; ```; uintptr_t all_ones_mask = std::numerical_limits<uintptr_t>::max();; uintptr_t all_zeros_mask = 0;; void leak(int data);; void example(int* pointer1, int* pointer2) {; uintptr_t predicate_state = all_ones_mask;; switch (condition) {; case 0:; // Assuming ?: is implemented using branchless logic...; predicate_state = (condition != 0) ? all_zeros_mask : predicate_state;; // ... lots of code ...; //; // Harden the pointer so it can't be loaded; pointer1 &= predicate_state;; leak(*pointer1);; break;. case 1:; predicate_state = (condition != 1) ? all_zeros_mask : predicate_state;; // ... more code ...; //; // Alternative: Harden the loaded value; int value2 = *pointer2 & predicate_state;; leak(value2);; break;. // ...; }; }; ```. The core idea remains the same: validate the control flow using data-flow and; use that validation to check that loads cannot leak information along; misspeculated paths. Typically this involves passing the desired target of such; control flow across the edge and checking that it is correct afterwards. Note; that while it is tempting to think that this mitigates variant #2 attacks, it; does not. Those attacks go to arbitrary gadgets that don't include the checks. ### Variant #1.1 and #1.2 attacks: ""Bounds Check Bypass Store"". Beyond the core variant #1 attack, there are techniques to extend this attack.; The primary technique is known as ""Bounds Check Bypass Store"" and is discussed; in this research pape",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:10379,Performance,load,loaded,10379,"mploy the retpoline mitigation, and on future x86 hardware (both Intel and; AMD) it is expected to become unnecessary due to hardware-based mitigation. When not using a retpoline, these edges will need independent protection from; variant #1 style attacks. The analogous approach to that used for conditional; control flow should work:; ```; uintptr_t all_ones_mask = std::numerical_limits<uintptr_t>::max();; uintptr_t all_zeros_mask = 0;; void leak(int data);; void example(int* pointer1, int* pointer2) {; uintptr_t predicate_state = all_ones_mask;; switch (condition) {; case 0:; // Assuming ?: is implemented using branchless logic...; predicate_state = (condition != 0) ? all_zeros_mask : predicate_state;; // ... lots of code ...; //; // Harden the pointer so it can't be loaded; pointer1 &= predicate_state;; leak(*pointer1);; break;. case 1:; predicate_state = (condition != 1) ? all_zeros_mask : predicate_state;; // ... more code ...; //; // Alternative: Harden the loaded value; int value2 = *pointer2 & predicate_state;; leak(value2);; break;. // ...; }; }; ```. The core idea remains the same: validate the control flow using data-flow and; use that validation to check that loads cannot leak information along; misspeculated paths. Typically this involves passing the desired target of such; control flow across the edge and checking that it is correct afterwards. Note; that while it is tempting to think that this mitigates variant #2 attacks, it; does not. Those attacks go to arbitrary gadgets that don't include the checks. ### Variant #1.1 and #1.2 attacks: ""Bounds Check Bypass Store"". Beyond the core variant #1 attack, there are techniques to extend this attack.; The primary technique is known as ""Bounds Check Bypass Store"" and is discussed; in this research paper: https://people.csail.mit.edu/vlk/spectre11.pdf. We will analyze these two variants independently. First, variant #1.1 works by; speculatively storing over the return address after a bounds check bypass. This;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:10591,Performance,load,loads,10591," using a retpoline, these edges will need independent protection from; variant #1 style attacks. The analogous approach to that used for conditional; control flow should work:; ```; uintptr_t all_ones_mask = std::numerical_limits<uintptr_t>::max();; uintptr_t all_zeros_mask = 0;; void leak(int data);; void example(int* pointer1, int* pointer2) {; uintptr_t predicate_state = all_ones_mask;; switch (condition) {; case 0:; // Assuming ?: is implemented using branchless logic...; predicate_state = (condition != 0) ? all_zeros_mask : predicate_state;; // ... lots of code ...; //; // Harden the pointer so it can't be loaded; pointer1 &= predicate_state;; leak(*pointer1);; break;. case 1:; predicate_state = (condition != 1) ? all_zeros_mask : predicate_state;; // ... more code ...; //; // Alternative: Harden the loaded value; int value2 = *pointer2 & predicate_state;; leak(value2);; break;. // ...; }; }; ```. The core idea remains the same: validate the control flow using data-flow and; use that validation to check that loads cannot leak information along; misspeculated paths. Typically this involves passing the desired target of such; control flow across the edge and checking that it is correct afterwards. Note; that while it is tempting to think that this mitigates variant #2 attacks, it; does not. Those attacks go to arbitrary gadgets that don't include the checks. ### Variant #1.1 and #1.2 attacks: ""Bounds Check Bypass Store"". Beyond the core variant #1 attack, there are techniques to extend this attack.; The primary technique is known as ""Bounds Check Bypass Store"" and is discussed; in this research paper: https://people.csail.mit.edu/vlk/spectre11.pdf. We will analyze these two variants independently. First, variant #1.1 works by; speculatively storing over the return address after a bounds check bypass. This; speculative store then ends up being used by the CPU during speculative; execution of the return, potentially directing speculative execution to; arbitrary gadg",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:12206,Performance,load,load,12206,".csail.mit.edu/vlk/spectre11.pdf. We will analyze these two variants independently. First, variant #1.1 works by; speculatively storing over the return address after a bounds check bypass. This; speculative store then ends up being used by the CPU during speculative; execution of the return, potentially directing speculative execution to; arbitrary gadgets in the binary. Let's look at an example.; ```; unsigned char local_buffer[4];; unsigned char *untrusted_data_from_caller = ...;; unsigned long untrusted_size_from_caller = ...;; if (untrusted_size_from_caller < sizeof(local_buffer)) {; // Speculative execution enters here with a too-large size.; memcpy(local_buffer, untrusted_data_from_caller,; untrusted_size_from_caller);; // The stack has now been smashed, writing an attacker-controlled; // address over the return address.; minor_processing(local_buffer);; return;; // Control will speculate to the attacker-written address.; }; ```. However, this can be mitigated by hardening the load of the return address just; like any other load. This is sometimes complicated because x86 for example; *implicitly* loads the return address off the stack. However, the; implementation technique below is specifically designed to mitigate this; implicit load by using the stack pointer to communicate misspeculation between; functions. This additionally causes a misspeculation to have an invalid stack; pointer and never be able to read the speculatively stored return address. See; the detailed discussion below. For variant #1.2, the attacker speculatively stores into the vtable or jump; table used to implement an indirect call or indirect jump. Because this is; speculative, this will often be possible even when these are stored in; read-only pages. For example:; ```; class FancyObject : public BaseObject {; public:; void DoSomething() override;; };; void f(unsigned long attacker_offset, unsigned long attacker_data) {; FancyObject object = getMyObject();; unsigned long *arr[4] = getFou",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:12254,Performance,load,load,12254,".csail.mit.edu/vlk/spectre11.pdf. We will analyze these two variants independently. First, variant #1.1 works by; speculatively storing over the return address after a bounds check bypass. This; speculative store then ends up being used by the CPU during speculative; execution of the return, potentially directing speculative execution to; arbitrary gadgets in the binary. Let's look at an example.; ```; unsigned char local_buffer[4];; unsigned char *untrusted_data_from_caller = ...;; unsigned long untrusted_size_from_caller = ...;; if (untrusted_size_from_caller < sizeof(local_buffer)) {; // Speculative execution enters here with a too-large size.; memcpy(local_buffer, untrusted_data_from_caller,; untrusted_size_from_caller);; // The stack has now been smashed, writing an attacker-controlled; // address over the return address.; minor_processing(local_buffer);; return;; // Control will speculate to the attacker-written address.; }; ```. However, this can be mitigated by hardening the load of the return address just; like any other load. This is sometimes complicated because x86 for example; *implicitly* loads the return address off the stack. However, the; implementation technique below is specifically designed to mitigate this; implicit load by using the stack pointer to communicate misspeculation between; functions. This additionally causes a misspeculation to have an invalid stack; pointer and never be able to read the speculatively stored return address. See; the detailed discussion below. For variant #1.2, the attacker speculatively stores into the vtable or jump; table used to implement an indirect call or indirect jump. Because this is; speculative, this will often be possible even when these are stored in; read-only pages. For example:; ```; class FancyObject : public BaseObject {; public:; void DoSomething() override;; };; void f(unsigned long attacker_offset, unsigned long attacker_data) {; FancyObject object = getMyObject();; unsigned long *arr[4] = getFou",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:12328,Performance,load,loads,12328,"orks by; speculatively storing over the return address after a bounds check bypass. This; speculative store then ends up being used by the CPU during speculative; execution of the return, potentially directing speculative execution to; arbitrary gadgets in the binary. Let's look at an example.; ```; unsigned char local_buffer[4];; unsigned char *untrusted_data_from_caller = ...;; unsigned long untrusted_size_from_caller = ...;; if (untrusted_size_from_caller < sizeof(local_buffer)) {; // Speculative execution enters here with a too-large size.; memcpy(local_buffer, untrusted_data_from_caller,; untrusted_size_from_caller);; // The stack has now been smashed, writing an attacker-controlled; // address over the return address.; minor_processing(local_buffer);; return;; // Control will speculate to the attacker-written address.; }; ```. However, this can be mitigated by hardening the load of the return address just; like any other load. This is sometimes complicated because x86 for example; *implicitly* loads the return address off the stack. However, the; implementation technique below is specifically designed to mitigate this; implicit load by using the stack pointer to communicate misspeculation between; functions. This additionally causes a misspeculation to have an invalid stack; pointer and never be able to read the speculatively stored return address. See; the detailed discussion below. For variant #1.2, the attacker speculatively stores into the vtable or jump; table used to implement an indirect call or indirect jump. Because this is; speculative, this will often be possible even when these are stored in; read-only pages. For example:; ```; class FancyObject : public BaseObject {; public:; void DoSomething() override;; };; void f(unsigned long attacker_offset, unsigned long attacker_data) {; FancyObject object = getMyObject();; unsigned long *arr[4] = getFourDataPointers();; if (attacker_offset < 4) {; // We have bypassed the bounds check speculatively.; unsign",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:12465,Performance,load,load,12465,"during speculative; execution of the return, potentially directing speculative execution to; arbitrary gadgets in the binary. Let's look at an example.; ```; unsigned char local_buffer[4];; unsigned char *untrusted_data_from_caller = ...;; unsigned long untrusted_size_from_caller = ...;; if (untrusted_size_from_caller < sizeof(local_buffer)) {; // Speculative execution enters here with a too-large size.; memcpy(local_buffer, untrusted_data_from_caller,; untrusted_size_from_caller);; // The stack has now been smashed, writing an attacker-controlled; // address over the return address.; minor_processing(local_buffer);; return;; // Control will speculate to the attacker-written address.; }; ```. However, this can be mitigated by hardening the load of the return address just; like any other load. This is sometimes complicated because x86 for example; *implicitly* loads the return address off the stack. However, the; implementation technique below is specifically designed to mitigate this; implicit load by using the stack pointer to communicate misspeculation between; functions. This additionally causes a misspeculation to have an invalid stack; pointer and never be able to read the speculatively stored return address. See; the detailed discussion below. For variant #1.2, the attacker speculatively stores into the vtable or jump; table used to implement an indirect call or indirect jump. Because this is; speculative, this will often be possible even when these are stored in; read-only pages. For example:; ```; class FancyObject : public BaseObject {; public:; void DoSomething() override;; };; void f(unsigned long attacker_offset, unsigned long attacker_data) {; FancyObject object = getMyObject();; unsigned long *arr[4] = getFourDataPointers();; if (attacker_offset < 4) {; // We have bypassed the bounds check speculatively.; unsigned long *data = arr[attacker_offset];; // Now we have computed a pointer inside of `object`, the vptr.; *data = attacker_data;; // The vptr poin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:13791,Performance,load,loads,13791,"d to implement an indirect call or indirect jump. Because this is; speculative, this will often be possible even when these are stored in; read-only pages. For example:; ```; class FancyObject : public BaseObject {; public:; void DoSomething() override;; };; void f(unsigned long attacker_offset, unsigned long attacker_data) {; FancyObject object = getMyObject();; unsigned long *arr[4] = getFourDataPointers();; if (attacker_offset < 4) {; // We have bypassed the bounds check speculatively.; unsigned long *data = arr[attacker_offset];; // Now we have computed a pointer inside of `object`, the vptr.; *data = attacker_data;; // The vptr points to the virtual table and we speculatively clobber that.; g(object); // Hand the object to some other routine.; }; }; // In another file, we call a method on the object.; void g(BaseObject &object) {; object.DoSomething();; // This speculatively calls the address stored over the vtable.; }; ```. Mitigating this requires hardening loads from these locations, or mitigating; the indirect call or indirect jump. Any of these are sufficient to block the; call or jump from using a speculatively stored value that has been read back. For both of these, using retpolines would be equally sufficient. One possible; hybrid approach is to use retpolines for indirect call and jump, while relying; on SLH to mitigate returns. Another approach that is sufficient for both of these is to harden all of the; speculative stores. However, as most stores aren't interesting and don't; inherently leak data, this is expected to be prohibitively expensive given the; attack it is defending against. ## Implementation Details. There are a number of complex details impacting the implementation of this; technique, both on a particular architecture and within a particular compiler.; We discuss proposed implementation techniques for the x86 architecture and the; LLVM compiler. These are primarily to serve as an example, as other; implementation techniques are very pos",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:15012,Performance,load,loads,15012,"value that has been read back. For both of these, using retpolines would be equally sufficient. One possible; hybrid approach is to use retpolines for indirect call and jump, while relying; on SLH to mitigate returns. Another approach that is sufficient for both of these is to harden all of the; speculative stores. However, as most stores aren't interesting and don't; inherently leak data, this is expected to be prohibitively expensive given the; attack it is defending against. ## Implementation Details. There are a number of complex details impacting the implementation of this; technique, both on a particular architecture and within a particular compiler.; We discuss proposed implementation techniques for the x86 architecture and the; LLVM compiler. These are primarily to serve as an example, as other; implementation techniques are very possible. ### x86 Implementation Details. On the x86 platform we break down the implementation into three core; components: accumulating the predicate state through the control flow graph,; checking the loads, and checking control transfers between procedures. #### Accumulating Predicate State. Consider baseline x86 instructions like the following, which test three; conditions and if all pass, loads data from memory and potentially leaks it; through some side channel:; ```; # %bb.0: # %entry; pushq %rax; testl %edi, %edi; jne .LBB0_4; # %bb.1: # %then1; testl %esi, %esi; jne .LBB0_4; # %bb.2: # %then2; testl %edx, %edx; je .LBB0_3; .LBB0_4: # %exit; popq %rax; retq; .LBB0_3: # %danger; movl (%rcx), %edi; callq leak; popq %rax; retq; ```. When we go to speculatively execute the load, we want to know whether any of; the dynamically executed predicates have been misspeculated. To track that,; along each conditional edge, we need to track the data which would allow that; edge to be taken. On x86, this data is stored in the flags register used by the; conditional jump instruction. Along both edges after this fork in control flow,; the fla",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:15206,Performance,load,loads,15206,"is sufficient for both of these is to harden all of the; speculative stores. However, as most stores aren't interesting and don't; inherently leak data, this is expected to be prohibitively expensive given the; attack it is defending against. ## Implementation Details. There are a number of complex details impacting the implementation of this; technique, both on a particular architecture and within a particular compiler.; We discuss proposed implementation techniques for the x86 architecture and the; LLVM compiler. These are primarily to serve as an example, as other; implementation techniques are very possible. ### x86 Implementation Details. On the x86 platform we break down the implementation into three core; components: accumulating the predicate state through the control flow graph,; checking the loads, and checking control transfers between procedures. #### Accumulating Predicate State. Consider baseline x86 instructions like the following, which test three; conditions and if all pass, loads data from memory and potentially leaks it; through some side channel:; ```; # %bb.0: # %entry; pushq %rax; testl %edi, %edi; jne .LBB0_4; # %bb.1: # %then1; testl %esi, %esi; jne .LBB0_4; # %bb.2: # %then2; testl %edx, %edx; je .LBB0_3; .LBB0_4: # %exit; popq %rax; retq; .LBB0_3: # %danger; movl (%rcx), %edi; callq leak; popq %rax; retq; ```. When we go to speculatively execute the load, we want to know whether any of; the dynamically executed predicates have been misspeculated. To track that,; along each conditional edge, we need to track the data which would allow that; edge to be taken. On x86, this data is stored in the flags register used by the; conditional jump instruction. Along both edges after this fork in control flow,; the flags register remains alive and contains data that we can use to build up; our accumulated predicate state. We accumulate it using the x86 conditional; move instruction which also reads the flag registers where the state resides.; These cond",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:15597,Performance,load,load,15597,"We discuss proposed implementation techniques for the x86 architecture and the; LLVM compiler. These are primarily to serve as an example, as other; implementation techniques are very possible. ### x86 Implementation Details. On the x86 platform we break down the implementation into three core; components: accumulating the predicate state through the control flow graph,; checking the loads, and checking control transfers between procedures. #### Accumulating Predicate State. Consider baseline x86 instructions like the following, which test three; conditions and if all pass, loads data from memory and potentially leaks it; through some side channel:; ```; # %bb.0: # %entry; pushq %rax; testl %edi, %edi; jne .LBB0_4; # %bb.1: # %then1; testl %esi, %esi; jne .LBB0_4; # %bb.2: # %then2; testl %edx, %edx; je .LBB0_3; .LBB0_4: # %exit; popq %rax; retq; .LBB0_3: # %danger; movl (%rcx), %edi; callq leak; popq %rax; retq; ```. When we go to speculatively execute the load, we want to know whether any of; the dynamically executed predicates have been misspeculated. To track that,; along each conditional edge, we need to track the data which would allow that; edge to be taken. On x86, this data is stored in the flags register used by the; conditional jump instruction. Along both edges after this fork in control flow,; the flags register remains alive and contains data that we can use to build up; our accumulated predicate state. We accumulate it using the x86 conditional; move instruction which also reads the flag registers where the state resides.; These conditional move instructions are known to not be predicted on any x86; processors, making them immune to misprediction that could reintroduce the; vulnerability. When we insert the conditional moves, the code ends up looking; like the following:; ```; # %bb.0: # %entry; pushq %rax; xorl %eax, %eax # Zero out initial predicate state.; movq $-1, %r8 # Put all-ones mask into a register.; testl %edi, %edi; jne .LBB0_1; # %bb.2: # ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:17804,Performance,load,loads,17804," # Conditionally update predicate state.; testl %edx, %edx; je .LBB0_4; .LBB0_1:; cmoveq %r8, %rax # Conditionally update predicate state.; popq %rax; retq; .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; ...; ```. Here we create the ""empty"" or ""correct execution"" predicate state by zeroing; `%rax`, and we create a constant ""incorrect execution"" predicate value by; putting `-1` into `%r8`. Then, along each edge coming out of a conditional; branch we do a conditional move that in a correct execution will be a no-op,; but if misspeculated, will replace the `%rax` with the value of `%r8`.; Misspeculating any one of the three predicates will cause `%rax` to hold the; ""incorrect execution"" value from `%r8` as we preserve incoming values when; execution is correct rather than overwriting it. We now have a value in `%rax` in each basic block that indicates if at some; point previously a predicate was mispredicted. And we have arranged for that; value to be particularly effective when used below to harden loads. ##### Indirect Call, Branch, and Return Predicates. There is no analogous flag to use when tracing indirect calls, branches, and; returns. The predicate state must be accumulated through some other means.; Fundamentally, this is the reverse of the problem posed in CFI: we need to; check where we came from rather than where we are going. For function-local; jump tables, this is easily arranged by testing the input to the jump table; within each destination (not yet implemented, use retpolines):; ```; pushq %rax; xorl %eax, %eax # Zero out initial predicate state.; movq $-1, %r8 # Put all-ones mask into a register.; jmpq *.LJTI0_0(,%rdi,8) # Indirect jump through table.; .LBB0_2: # %sw.bb; testq $0, %rdi # Validate index used for jump table.; cmovneq %r8, %rax # Conditionally update predicate state.; ...; jmp _Z4leaki # TAILCALL. .LBB0_3: # %sw.bb1; testq $1, %rdi # Validate index used for jump table.; cmovneq %r8, %rax # Conditionally up",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:20680,Performance,optimiz,optimizations,20680,"ss; from the stack), we can compute the expected return address prior to the call; into a register preserved across the call and use that similarly to the above. Indirect calls (and returns in the absence of a red zone ABI) pose the most; significant challenge to propagate. The simplest technique would be to define a; new ABI such that the intended call target is passed into the called function; and checked in the entry. Unfortunately, new ABIs are quite expensive to deploy; in C and C++. While the target function could be passed in TLS, we would still; require complex logic to handle a mixture of functions compiled with and; without this extra logic (essentially, making the ABI backwards compatible).; Currently, we suggest using retpolines here and will continue to investigate; ways of mitigating this. ##### Optimizations, Alternatives, and Tradeoffs. Merely accumulating predicate state involves significant cost. There are; several key optimizations we employ to minimize this and various alternatives; that present different tradeoffs in the generated code. First, we work to reduce the number of instructions used to track the state:; * Rather than inserting a `cmovCC` instruction along every conditional edge in; the original program, we track each set of condition flags we need to capture; prior to entering each basic block and reuse a common `cmovCC` sequence for; those.; * We could further reuse suffixes when there are multiple `cmovCC`; instructions required to capture the set of flags. Currently this is; believed to not be worth the cost as paired flags are relatively rare and; suffixes of them are exceedingly rare.; * A common pattern in x86 is to have multiple conditional jump instructions; that use the same flags but handle different conditions. Naively, we could; consider each fallthrough between them an ""edge"" but this causes a much more; complex control flow graph. Instead, we accumulate the set of conditions; necessary for fallthrough and use a sequence o",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:22050,Performance,load,load-store,22050," set of condition flags we need to capture; prior to entering each basic block and reuse a common `cmovCC` sequence for; those.; * We could further reuse suffixes when there are multiple `cmovCC`; instructions required to capture the set of flags. Currently this is; believed to not be worth the cost as paired flags are relatively rare and; suffixes of them are exceedingly rare.; * A common pattern in x86 is to have multiple conditional jump instructions; that use the same flags but handle different conditions. Naively, we could; consider each fallthrough between them an ""edge"" but this causes a much more; complex control flow graph. Instead, we accumulate the set of conditions; necessary for fallthrough and use a sequence of `cmovCC` instructions in a; single fallthrough edge to track it. Second, we trade register pressure for simpler `cmovCC` instructions by; allocating a register for the ""bad"" state. We could read that value from memory; as part of the conditional move instruction, however, this creates more; micro-ops and requires the load-store unit to be involved. Currently, we place; the value into a virtual register and allow the register allocator to decide; when the register pressure is sufficient to make it worth spilling to memory; and reloading. #### Hardening Loads. Once we have the predicate accumulated into a special value for correct vs.; misspeculated, we need to apply this to loads in a way that ensures they do not; leak secret data. There are two primary techniques for this: we can either; harden the loaded value to prevent observation, or we can harden the address; itself to prevent the load from occurring. These have significantly different; performance tradeoffs. ##### Hardening loaded values. The most appealing way to harden loads is to mask out all of the bits loaded.; The key requirement is that for each bit loaded, along the misspeculated path; that bit is always fixed at either 0 or 1 regardless of the value of the bit; loaded. The most ob",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:22413,Performance,load,loads,22413,"le conditional jump instructions; that use the same flags but handle different conditions. Naively, we could; consider each fallthrough between them an ""edge"" but this causes a much more; complex control flow graph. Instead, we accumulate the set of conditions; necessary for fallthrough and use a sequence of `cmovCC` instructions in a; single fallthrough edge to track it. Second, we trade register pressure for simpler `cmovCC` instructions by; allocating a register for the ""bad"" state. We could read that value from memory; as part of the conditional move instruction, however, this creates more; micro-ops and requires the load-store unit to be involved. Currently, we place; the value into a virtual register and allow the register allocator to decide; when the register pressure is sufficient to make it worth spilling to memory; and reloading. #### Hardening Loads. Once we have the predicate accumulated into a special value for correct vs.; misspeculated, we need to apply this to loads in a way that ensures they do not; leak secret data. There are two primary techniques for this: we can either; harden the loaded value to prevent observation, or we can harden the address; itself to prevent the load from occurring. These have significantly different; performance tradeoffs. ##### Hardening loaded values. The most appealing way to harden loads is to mask out all of the bits loaded.; The key requirement is that for each bit loaded, along the misspeculated path; that bit is always fixed at either 0 or 1 regardless of the value of the bit; loaded. The most obvious implementation uses either an `and` instruction with; an all-zero mask along misspeculated paths and an all-one mask along correct; paths, or an `or` instruction with an all-one mask along misspeculated paths; and an all-zero mask along correct paths. Other options become less appealing; such as multiplying by zero, or multiple shift instructions. For reasons we; elaborate on below, we end up suggesting you use `or`",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:22541,Performance,load,loaded,22541,"ween them an ""edge"" but this causes a much more; complex control flow graph. Instead, we accumulate the set of conditions; necessary for fallthrough and use a sequence of `cmovCC` instructions in a; single fallthrough edge to track it. Second, we trade register pressure for simpler `cmovCC` instructions by; allocating a register for the ""bad"" state. We could read that value from memory; as part of the conditional move instruction, however, this creates more; micro-ops and requires the load-store unit to be involved. Currently, we place; the value into a virtual register and allow the register allocator to decide; when the register pressure is sufficient to make it worth spilling to memory; and reloading. #### Hardening Loads. Once we have the predicate accumulated into a special value for correct vs.; misspeculated, we need to apply this to loads in a way that ensures they do not; leak secret data. There are two primary techniques for this: we can either; harden the loaded value to prevent observation, or we can harden the address; itself to prevent the load from occurring. These have significantly different; performance tradeoffs. ##### Hardening loaded values. The most appealing way to harden loads is to mask out all of the bits loaded.; The key requirement is that for each bit loaded, along the misspeculated path; that bit is always fixed at either 0 or 1 regardless of the value of the bit; loaded. The most obvious implementation uses either an `and` instruction with; an all-zero mask along misspeculated paths and an all-one mask along correct; paths, or an `or` instruction with an all-one mask along misspeculated paths; and an all-zero mask along correct paths. Other options become less appealing; such as multiplying by zero, or multiple shift instructions. For reasons we; elaborate on below, we end up suggesting you use `or` with an all-ones mask,; making the x86 instruction sequence look like the following:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Cond",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:22630,Performance,load,load,22630,"ween them an ""edge"" but this causes a much more; complex control flow graph. Instead, we accumulate the set of conditions; necessary for fallthrough and use a sequence of `cmovCC` instructions in a; single fallthrough edge to track it. Second, we trade register pressure for simpler `cmovCC` instructions by; allocating a register for the ""bad"" state. We could read that value from memory; as part of the conditional move instruction, however, this creates more; micro-ops and requires the load-store unit to be involved. Currently, we place; the value into a virtual register and allow the register allocator to decide; when the register pressure is sufficient to make it worth spilling to memory; and reloading. #### Hardening Loads. Once we have the predicate accumulated into a special value for correct vs.; misspeculated, we need to apply this to loads in a way that ensures they do not; leak secret data. There are two primary techniques for this: we can either; harden the loaded value to prevent observation, or we can harden the address; itself to prevent the load from occurring. These have significantly different; performance tradeoffs. ##### Hardening loaded values. The most appealing way to harden loads is to mask out all of the bits loaded.; The key requirement is that for each bit loaded, along the misspeculated path; that bit is always fixed at either 0 or 1 regardless of the value of the bit; loaded. The most obvious implementation uses either an `and` instruction with; an all-zero mask along misspeculated paths and an all-one mask along correct; paths, or an `or` instruction with an all-one mask along misspeculated paths; and an all-zero mask along correct paths. Other options become less appealing; such as multiplying by zero, or multiple shift instructions. For reasons we; elaborate on below, we end up suggesting you use `or` with an all-ones mask,; making the x86 instruction sequence look like the following:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Cond",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:22687,Performance,perform,performance,22687,"ns; necessary for fallthrough and use a sequence of `cmovCC` instructions in a; single fallthrough edge to track it. Second, we trade register pressure for simpler `cmovCC` instructions by; allocating a register for the ""bad"" state. We could read that value from memory; as part of the conditional move instruction, however, this creates more; micro-ops and requires the load-store unit to be involved. Currently, we place; the value into a virtual register and allow the register allocator to decide; when the register pressure is sufficient to make it worth spilling to memory; and reloading. #### Hardening Loads. Once we have the predicate accumulated into a special value for correct vs.; misspeculated, we need to apply this to loads in a way that ensures they do not; leak secret data. There are two primary techniques for this: we can either; harden the loaded value to prevent observation, or we can harden the address; itself to prevent the load from occurring. These have significantly different; performance tradeoffs. ##### Hardening loaded values. The most appealing way to harden loads is to mask out all of the bits loaded.; The key requirement is that for each bit loaded, along the misspeculated path; that bit is always fixed at either 0 or 1 regardless of the value of the bit; loaded. The most obvious implementation uses either an `and` instruction with; an all-zero mask along misspeculated paths and an all-one mask along correct; paths, or an `or` instruction with an all-one mask along misspeculated paths; and an all-zero mask along correct paths. Other options become less appealing; such as multiplying by zero, or multiple shift instructions. For reasons we; elaborate on below, we end up suggesting you use `or` with an all-ones mask,; making the x86 instruction sequence look like the following:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; movl (%rsi), %edi # Load potentially secret data from %rsi.; orl %eax, %edi; ```. Ot",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:22726,Performance,load,loaded,22726,"nce of `cmovCC` instructions in a; single fallthrough edge to track it. Second, we trade register pressure for simpler `cmovCC` instructions by; allocating a register for the ""bad"" state. We could read that value from memory; as part of the conditional move instruction, however, this creates more; micro-ops and requires the load-store unit to be involved. Currently, we place; the value into a virtual register and allow the register allocator to decide; when the register pressure is sufficient to make it worth spilling to memory; and reloading. #### Hardening Loads. Once we have the predicate accumulated into a special value for correct vs.; misspeculated, we need to apply this to loads in a way that ensures they do not; leak secret data. There are two primary techniques for this: we can either; harden the loaded value to prevent observation, or we can harden the address; itself to prevent the load from occurring. These have significantly different; performance tradeoffs. ##### Hardening loaded values. The most appealing way to harden loads is to mask out all of the bits loaded.; The key requirement is that for each bit loaded, along the misspeculated path; that bit is always fixed at either 0 or 1 regardless of the value of the bit; loaded. The most obvious implementation uses either an `and` instruction with; an all-zero mask along misspeculated paths and an all-one mask along correct; paths, or an `or` instruction with an all-one mask along misspeculated paths; and an all-zero mask along correct paths. Other options become less appealing; such as multiplying by zero, or multiple shift instructions. For reasons we; elaborate on below, we end up suggesting you use `or` with an all-ones mask,; making the x86 instruction sequence look like the following:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; movl (%rsi), %edi # Load potentially secret data from %rsi.; orl %eax, %edi; ```. Other useful patterns may be to fold the load i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:22774,Performance,load,loads,22774,"dge to track it. Second, we trade register pressure for simpler `cmovCC` instructions by; allocating a register for the ""bad"" state. We could read that value from memory; as part of the conditional move instruction, however, this creates more; micro-ops and requires the load-store unit to be involved. Currently, we place; the value into a virtual register and allow the register allocator to decide; when the register pressure is sufficient to make it worth spilling to memory; and reloading. #### Hardening Loads. Once we have the predicate accumulated into a special value for correct vs.; misspeculated, we need to apply this to loads in a way that ensures they do not; leak secret data. There are two primary techniques for this: we can either; harden the loaded value to prevent observation, or we can harden the address; itself to prevent the load from occurring. These have significantly different; performance tradeoffs. ##### Hardening loaded values. The most appealing way to harden loads is to mask out all of the bits loaded.; The key requirement is that for each bit loaded, along the misspeculated path; that bit is always fixed at either 0 or 1 regardless of the value of the bit; loaded. The most obvious implementation uses either an `and` instruction with; an all-zero mask along misspeculated paths and an all-one mask along correct; paths, or an `or` instruction with an all-one mask along misspeculated paths; and an all-zero mask along correct paths. Other options become less appealing; such as multiplying by zero, or multiple shift instructions. For reasons we; elaborate on below, we end up suggesting you use `or` with an all-ones mask,; making the x86 instruction sequence look like the following:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; movl (%rsi), %edi # Load potentially secret data from %rsi.; orl %eax, %edi; ```. Other useful patterns may be to fold the load into the `or` instruction itself; at the cost of a regi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:22811,Performance,load,loaded,22811,"dge to track it. Second, we trade register pressure for simpler `cmovCC` instructions by; allocating a register for the ""bad"" state. We could read that value from memory; as part of the conditional move instruction, however, this creates more; micro-ops and requires the load-store unit to be involved. Currently, we place; the value into a virtual register and allow the register allocator to decide; when the register pressure is sufficient to make it worth spilling to memory; and reloading. #### Hardening Loads. Once we have the predicate accumulated into a special value for correct vs.; misspeculated, we need to apply this to loads in a way that ensures they do not; leak secret data. There are two primary techniques for this: we can either; harden the loaded value to prevent observation, or we can harden the address; itself to prevent the load from occurring. These have significantly different; performance tradeoffs. ##### Hardening loaded values. The most appealing way to harden loads is to mask out all of the bits loaded.; The key requirement is that for each bit loaded, along the misspeculated path; that bit is always fixed at either 0 or 1 regardless of the value of the bit; loaded. The most obvious implementation uses either an `and` instruction with; an all-zero mask along misspeculated paths and an all-one mask along correct; paths, or an `or` instruction with an all-one mask along misspeculated paths; and an all-zero mask along correct paths. Other options become less appealing; such as multiplying by zero, or multiple shift instructions. For reasons we; elaborate on below, we end up suggesting you use `or` with an all-ones mask,; making the x86 instruction sequence look like the following:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; movl (%rsi), %edi # Load potentially secret data from %rsi.; orl %eax, %edi; ```. Other useful patterns may be to fold the load into the `or` instruction itself; at the cost of a regi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:22861,Performance,load,loaded,22861,"ad"" state. We could read that value from memory; as part of the conditional move instruction, however, this creates more; micro-ops and requires the load-store unit to be involved. Currently, we place; the value into a virtual register and allow the register allocator to decide; when the register pressure is sufficient to make it worth spilling to memory; and reloading. #### Hardening Loads. Once we have the predicate accumulated into a special value for correct vs.; misspeculated, we need to apply this to loads in a way that ensures they do not; leak secret data. There are two primary techniques for this: we can either; harden the loaded value to prevent observation, or we can harden the address; itself to prevent the load from occurring. These have significantly different; performance tradeoffs. ##### Hardening loaded values. The most appealing way to harden loads is to mask out all of the bits loaded.; The key requirement is that for each bit loaded, along the misspeculated path; that bit is always fixed at either 0 or 1 regardless of the value of the bit; loaded. The most obvious implementation uses either an `and` instruction with; an all-zero mask along misspeculated paths and an all-one mask along correct; paths, or an `or` instruction with an all-one mask along misspeculated paths; and an all-zero mask along correct paths. Other options become less appealing; such as multiplying by zero, or multiple shift instructions. For reasons we; elaborate on below, we end up suggesting you use `or` with an all-ones mask,; making the x86 instruction sequence look like the following:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; movl (%rsi), %edi # Load potentially secret data from %rsi.; orl %eax, %edi; ```. Other useful patterns may be to fold the load into the `or` instruction itself; at the cost of a register-to-register copy. There are some challenges with deploying this approach:; 1. Many loads on x86 are folded into other",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:22977,Performance,load,loaded,22977,"ad"" state. We could read that value from memory; as part of the conditional move instruction, however, this creates more; micro-ops and requires the load-store unit to be involved. Currently, we place; the value into a virtual register and allow the register allocator to decide; when the register pressure is sufficient to make it worth spilling to memory; and reloading. #### Hardening Loads. Once we have the predicate accumulated into a special value for correct vs.; misspeculated, we need to apply this to loads in a way that ensures they do not; leak secret data. There are two primary techniques for this: we can either; harden the loaded value to prevent observation, or we can harden the address; itself to prevent the load from occurring. These have significantly different; performance tradeoffs. ##### Hardening loaded values. The most appealing way to harden loads is to mask out all of the bits loaded.; The key requirement is that for each bit loaded, along the misspeculated path; that bit is always fixed at either 0 or 1 regardless of the value of the bit; loaded. The most obvious implementation uses either an `and` instruction with; an all-zero mask along misspeculated paths and an all-one mask along correct; paths, or an `or` instruction with an all-one mask along misspeculated paths; and an all-zero mask along correct paths. Other options become less appealing; such as multiplying by zero, or multiple shift instructions. For reasons we; elaborate on below, we end up suggesting you use `or` with an all-ones mask,; making the x86 instruction sequence look like the following:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; movl (%rsi), %edi # Load potentially secret data from %rsi.; orl %eax, %edi; ```. Other useful patterns may be to fold the load into the `or` instruction itself; at the cost of a register-to-register copy. There are some challenges with deploying this approach:; 1. Many loads on x86 are folded into other",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:23719,Performance,load,load,23719,". The most appealing way to harden loads is to mask out all of the bits loaded.; The key requirement is that for each bit loaded, along the misspeculated path; that bit is always fixed at either 0 or 1 regardless of the value of the bit; loaded. The most obvious implementation uses either an `and` instruction with; an all-zero mask along misspeculated paths and an all-one mask along correct; paths, or an `or` instruction with an all-one mask along misspeculated paths; and an all-zero mask along correct paths. Other options become less appealing; such as multiplying by zero, or multiple shift instructions. For reasons we; elaborate on below, we end up suggesting you use `or` with an all-ones mask,; making the x86 instruction sequence look like the following:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; movl (%rsi), %edi # Load potentially secret data from %rsi.; orl %eax, %edi; ```. Other useful patterns may be to fold the load into the `or` instruction itself; at the cost of a register-to-register copy. There are some challenges with deploying this approach:; 1. Many loads on x86 are folded into other instructions. Separating them would; add very significant and costly register pressure with prohibitive; performance cost.; 1. Loads may not target a general purpose register requiring extra instructions; to map the state value into the correct register class, and potentially more; expensive instructions to mask the value in some way.; 1. The flags registers on x86 are very likely to be live, and challenging to; preserve cheaply.; 1. There are many more values loaded than pointers & indices used for loads. As; a consequence, hardening the result of a load requires substantially more; instructions than hardening the address of the load (see below). Despite these challenges, hardening the result of the load critically allows; the load to proceed and thus has dramatically less impact on the total; speculative / out-of-order pote",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:23867,Performance,load,loads,23867,"ated path; that bit is always fixed at either 0 or 1 regardless of the value of the bit; loaded. The most obvious implementation uses either an `and` instruction with; an all-zero mask along misspeculated paths and an all-one mask along correct; paths, or an `or` instruction with an all-one mask along misspeculated paths; and an all-zero mask along correct paths. Other options become less appealing; such as multiplying by zero, or multiple shift instructions. For reasons we; elaborate on below, we end up suggesting you use `or` with an all-ones mask,; making the x86 instruction sequence look like the following:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; movl (%rsi), %edi # Load potentially secret data from %rsi.; orl %eax, %edi; ```. Other useful patterns may be to fold the load into the `or` instruction itself; at the cost of a register-to-register copy. There are some challenges with deploying this approach:; 1. Many loads on x86 are folded into other instructions. Separating them would; add very significant and costly register pressure with prohibitive; performance cost.; 1. Loads may not target a general purpose register requiring extra instructions; to map the state value into the correct register class, and potentially more; expensive instructions to mask the value in some way.; 1. The flags registers on x86 are very likely to be live, and challenging to; preserve cheaply.; 1. There are many more values loaded than pointers & indices used for loads. As; a consequence, hardening the result of a load requires substantially more; instructions than hardening the address of the load (see below). Despite these challenges, hardening the result of the load critically allows; the load to proceed and thus has dramatically less impact on the total; speculative / out-of-order potential of the execution. There are also several; interesting techniques to try and mitigate these challenges and make hardening; the results of loads ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:24007,Performance,perform,performance,24007,"he bit; loaded. The most obvious implementation uses either an `and` instruction with; an all-zero mask along misspeculated paths and an all-one mask along correct; paths, or an `or` instruction with an all-one mask along misspeculated paths; and an all-zero mask along correct paths. Other options become less appealing; such as multiplying by zero, or multiple shift instructions. For reasons we; elaborate on below, we end up suggesting you use `or` with an all-ones mask,; making the x86 instruction sequence look like the following:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; movl (%rsi), %edi # Load potentially secret data from %rsi.; orl %eax, %edi; ```. Other useful patterns may be to fold the load into the `or` instruction itself; at the cost of a register-to-register copy. There are some challenges with deploying this approach:; 1. Many loads on x86 are folded into other instructions. Separating them would; add very significant and costly register pressure with prohibitive; performance cost.; 1. Loads may not target a general purpose register requiring extra instructions; to map the state value into the correct register class, and potentially more; expensive instructions to mask the value in some way.; 1. The flags registers on x86 are very likely to be live, and challenging to; preserve cheaply.; 1. There are many more values loaded than pointers & indices used for loads. As; a consequence, hardening the result of a load requires substantially more; instructions than hardening the address of the load (see below). Despite these challenges, hardening the result of the load critically allows; the load to proceed and thus has dramatically less impact on the total; speculative / out-of-order potential of the execution. There are also several; interesting techniques to try and mitigate these challenges and make hardening; the results of loads viable in at least some cases. However, we generally; expect to fall back when unp",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:24367,Performance,load,loaded,24367,"e on below, we end up suggesting you use `or` with an all-ones mask,; making the x86 instruction sequence look like the following:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; movl (%rsi), %edi # Load potentially secret data from %rsi.; orl %eax, %edi; ```. Other useful patterns may be to fold the load into the `or` instruction itself; at the cost of a register-to-register copy. There are some challenges with deploying this approach:; 1. Many loads on x86 are folded into other instructions. Separating them would; add very significant and costly register pressure with prohibitive; performance cost.; 1. Loads may not target a general purpose register requiring extra instructions; to map the state value into the correct register class, and potentially more; expensive instructions to mask the value in some way.; 1. The flags registers on x86 are very likely to be live, and challenging to; preserve cheaply.; 1. There are many more values loaded than pointers & indices used for loads. As; a consequence, hardening the result of a load requires substantially more; instructions than hardening the address of the load (see below). Despite these challenges, hardening the result of the load critically allows; the load to proceed and thus has dramatically less impact on the total; speculative / out-of-order potential of the execution. There are also several; interesting techniques to try and mitigate these challenges and make hardening; the results of loads viable in at least some cases. However, we generally; expect to fall back when unprofitable from hardening the loaded value to the; next approach of hardening the address itself. ###### Loads folded into data-invariant operations can be hardened after the operation. The first key to making this feasible is to recognize that many operations on; x86 are ""data-invariant"". That is, they have no (known) observable behavior; differences due to the particular input data. These instructions ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:24407,Performance,load,loads,24407,"e on below, we end up suggesting you use `or` with an all-ones mask,; making the x86 instruction sequence look like the following:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; movl (%rsi), %edi # Load potentially secret data from %rsi.; orl %eax, %edi; ```. Other useful patterns may be to fold the load into the `or` instruction itself; at the cost of a register-to-register copy. There are some challenges with deploying this approach:; 1. Many loads on x86 are folded into other instructions. Separating them would; add very significant and costly register pressure with prohibitive; performance cost.; 1. Loads may not target a general purpose register requiring extra instructions; to map the state value into the correct register class, and potentially more; expensive instructions to mask the value in some way.; 1. The flags registers on x86 are very likely to be live, and challenging to; preserve cheaply.; 1. There are many more values loaded than pointers & indices used for loads. As; a consequence, hardening the result of a load requires substantially more; instructions than hardening the address of the load (see below). Despite these challenges, hardening the result of the load critically allows; the load to proceed and thus has dramatically less impact on the total; speculative / out-of-order potential of the execution. There are also several; interesting techniques to try and mitigate these challenges and make hardening; the results of loads viable in at least some cases. However, we generally; expect to fall back when unprofitable from hardening the loaded value to the; next approach of hardening the address itself. ###### Loads folded into data-invariant operations can be hardened after the operation. The first key to making this feasible is to recognize that many operations on; x86 are ""data-invariant"". That is, they have no (known) observable behavior; differences due to the particular input data. These instructions ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:24459,Performance,load,load,24459,"k like the following:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; movl (%rsi), %edi # Load potentially secret data from %rsi.; orl %eax, %edi; ```. Other useful patterns may be to fold the load into the `or` instruction itself; at the cost of a register-to-register copy. There are some challenges with deploying this approach:; 1. Many loads on x86 are folded into other instructions. Separating them would; add very significant and costly register pressure with prohibitive; performance cost.; 1. Loads may not target a general purpose register requiring extra instructions; to map the state value into the correct register class, and potentially more; expensive instructions to mask the value in some way.; 1. The flags registers on x86 are very likely to be live, and challenging to; preserve cheaply.; 1. There are many more values loaded than pointers & indices used for loads. As; a consequence, hardening the result of a load requires substantially more; instructions than hardening the address of the load (see below). Despite these challenges, hardening the result of the load critically allows; the load to proceed and thus has dramatically less impact on the total; speculative / out-of-order potential of the execution. There are also several; interesting techniques to try and mitigate these challenges and make hardening; the results of loads viable in at least some cases. However, we generally; expect to fall back when unprofitable from hardening the loaded value to the; next approach of hardening the address itself. ###### Loads folded into data-invariant operations can be hardened after the operation. The first key to making this feasible is to recognize that many operations on; x86 are ""data-invariant"". That is, they have no (known) observable behavior; differences due to the particular input data. These instructions are often used; when implementing cryptographic primitives dealing with private key data; because they are no",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:24540,Performance,load,load,24540,"k like the following:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; movl (%rsi), %edi # Load potentially secret data from %rsi.; orl %eax, %edi; ```. Other useful patterns may be to fold the load into the `or` instruction itself; at the cost of a register-to-register copy. There are some challenges with deploying this approach:; 1. Many loads on x86 are folded into other instructions. Separating them would; add very significant and costly register pressure with prohibitive; performance cost.; 1. Loads may not target a general purpose register requiring extra instructions; to map the state value into the correct register class, and potentially more; expensive instructions to mask the value in some way.; 1. The flags registers on x86 are very likely to be live, and challenging to; preserve cheaply.; 1. There are many more values loaded than pointers & indices used for loads. As; a consequence, hardening the result of a load requires substantially more; instructions than hardening the address of the load (see below). Despite these challenges, hardening the result of the load critically allows; the load to proceed and thus has dramatically less impact on the total; speculative / out-of-order potential of the execution. There are also several; interesting techniques to try and mitigate these challenges and make hardening; the results of loads viable in at least some cases. However, we generally; expect to fall back when unprofitable from hardening the loaded value to the; next approach of hardening the address itself. ###### Loads folded into data-invariant operations can be hardened after the operation. The first key to making this feasible is to recognize that many operations on; x86 are ""data-invariant"". That is, they have no (known) observable behavior; differences due to the particular input data. These instructions are often used; when implementing cryptographic primitives dealing with private key data; because they are no",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:24612,Performance,load,load,24612,"l %eax, %edi; ```. Other useful patterns may be to fold the load into the `or` instruction itself; at the cost of a register-to-register copy. There are some challenges with deploying this approach:; 1. Many loads on x86 are folded into other instructions. Separating them would; add very significant and costly register pressure with prohibitive; performance cost.; 1. Loads may not target a general purpose register requiring extra instructions; to map the state value into the correct register class, and potentially more; expensive instructions to mask the value in some way.; 1. The flags registers on x86 are very likely to be live, and challenging to; preserve cheaply.; 1. There are many more values loaded than pointers & indices used for loads. As; a consequence, hardening the result of a load requires substantially more; instructions than hardening the address of the load (see below). Despite these challenges, hardening the result of the load critically allows; the load to proceed and thus has dramatically less impact on the total; speculative / out-of-order potential of the execution. There are also several; interesting techniques to try and mitigate these challenges and make hardening; the results of loads viable in at least some cases. However, we generally; expect to fall back when unprofitable from hardening the loaded value to the; next approach of hardening the address itself. ###### Loads folded into data-invariant operations can be hardened after the operation. The first key to making this feasible is to recognize that many operations on; x86 are ""data-invariant"". That is, they have no (known) observable behavior; differences due to the particular input data. These instructions are often used; when implementing cryptographic primitives dealing with private key data; because they are not believed to provide any side-channels. Similarly, we can; defer hardening until after them as they will not in-and-of-themselves; introduce a speculative execution side-chan",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:24640,Performance,load,load,24640,"l %eax, %edi; ```. Other useful patterns may be to fold the load into the `or` instruction itself; at the cost of a register-to-register copy. There are some challenges with deploying this approach:; 1. Many loads on x86 are folded into other instructions. Separating them would; add very significant and costly register pressure with prohibitive; performance cost.; 1. Loads may not target a general purpose register requiring extra instructions; to map the state value into the correct register class, and potentially more; expensive instructions to mask the value in some way.; 1. The flags registers on x86 are very likely to be live, and challenging to; preserve cheaply.; 1. There are many more values loaded than pointers & indices used for loads. As; a consequence, hardening the result of a load requires substantially more; instructions than hardening the address of the load (see below). Despite these challenges, hardening the result of the load critically allows; the load to proceed and thus has dramatically less impact on the total; speculative / out-of-order potential of the execution. There are also several; interesting techniques to try and mitigate these challenges and make hardening; the results of loads viable in at least some cases. However, we generally; expect to fall back when unprofitable from hardening the loaded value to the; next approach of hardening the address itself. ###### Loads folded into data-invariant operations can be hardened after the operation. The first key to making this feasible is to recognize that many operations on; x86 are ""data-invariant"". That is, they have no (known) observable behavior; differences due to the particular input data. These instructions are often used; when implementing cryptographic primitives dealing with private key data; because they are not believed to provide any side-channels. Similarly, we can; defer hardening until after them as they will not in-and-of-themselves; introduce a speculative execution side-chan",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:24882,Performance,load,loads,24882,"ng this approach:; 1. Many loads on x86 are folded into other instructions. Separating them would; add very significant and costly register pressure with prohibitive; performance cost.; 1. Loads may not target a general purpose register requiring extra instructions; to map the state value into the correct register class, and potentially more; expensive instructions to mask the value in some way.; 1. The flags registers on x86 are very likely to be live, and challenging to; preserve cheaply.; 1. There are many more values loaded than pointers & indices used for loads. As; a consequence, hardening the result of a load requires substantially more; instructions than hardening the address of the load (see below). Despite these challenges, hardening the result of the load critically allows; the load to proceed and thus has dramatically less impact on the total; speculative / out-of-order potential of the execution. There are also several; interesting techniques to try and mitigate these challenges and make hardening; the results of loads viable in at least some cases. However, we generally; expect to fall back when unprofitable from hardening the loaded value to the; next approach of hardening the address itself. ###### Loads folded into data-invariant operations can be hardened after the operation. The first key to making this feasible is to recognize that many operations on; x86 are ""data-invariant"". That is, they have no (known) observable behavior; differences due to the particular input data. These instructions are often used; when implementing cryptographic primitives dealing with private key data; because they are not believed to provide any side-channels. Similarly, we can; defer hardening until after them as they will not in-and-of-themselves; introduce a speculative execution side-channel. This results in code sequences; that look like:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulat",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:24999,Performance,load,loaded,24999,"h prohibitive; performance cost.; 1. Loads may not target a general purpose register requiring extra instructions; to map the state value into the correct register class, and potentially more; expensive instructions to mask the value in some way.; 1. The flags registers on x86 are very likely to be live, and challenging to; preserve cheaply.; 1. There are many more values loaded than pointers & indices used for loads. As; a consequence, hardening the result of a load requires substantially more; instructions than hardening the address of the load (see below). Despite these challenges, hardening the result of the load critically allows; the load to proceed and thus has dramatically less impact on the total; speculative / out-of-order potential of the execution. There are also several; interesting techniques to try and mitigate these challenges and make hardening; the results of loads viable in at least some cases. However, we generally; expect to fall back when unprofitable from hardening the loaded value to the; next approach of hardening the address itself. ###### Loads folded into data-invariant operations can be hardened after the operation. The first key to making this feasible is to recognize that many operations on; x86 are ""data-invariant"". That is, they have no (known) observable behavior; differences due to the particular input data. These instructions are often used; when implementing cryptographic primitives dealing with private key data; because they are not believed to provide any side-channels. Similarly, we can; defer hardening until after them as they will not in-and-of-themselves; introduce a speculative execution side-channel. This results in code sequences; that look like:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate without leaking.; orl %eax, %edi; ```. While an addition happens to the loaded (potentially secret) value, that; doesn't leak any data and we then imm",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:25914,Performance,load,loaded,25914,"ect to fall back when unprofitable from hardening the loaded value to the; next approach of hardening the address itself. ###### Loads folded into data-invariant operations can be hardened after the operation. The first key to making this feasible is to recognize that many operations on; x86 are ""data-invariant"". That is, they have no (known) observable behavior; differences due to the particular input data. These instructions are often used; when implementing cryptographic primitives dealing with private key data; because they are not believed to provide any side-channels. Similarly, we can; defer hardening until after them as they will not in-and-of-themselves; introduce a speculative execution side-channel. This results in code sequences; that look like:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate without leaking.; orl %eax, %edi; ```. While an addition happens to the loaded (potentially secret) value, that; doesn't leak any data and we then immediately harden it. ###### Hardening of loaded values deferred down the data-invariant expression graph. We can generalize the previous idea and sink the hardening down the expression; graph across as many data-invariant operations as desirable. This can use very; conservative rules for whether something is data-invariant. The primary goal; should be to handle multiple loads with a single hardening instruction:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate without leaking.; addl 4(%rsi), %edi # Continue without leaking.; addl 8(%rsi), %edi; orl %eax, %edi # Mask out bits from all three loads.; ```. ###### Preserving the flags while hardening loaded values on Haswell, Zen, and newer processors. Sadly, there are no useful instructions on x86 that apply a mask to all 64 bits; without touching the flag registers. However, we can harden loaded values that; are nar",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:26032,Performance,load,loaded,26032,"dress itself. ###### Loads folded into data-invariant operations can be hardened after the operation. The first key to making this feasible is to recognize that many operations on; x86 are ""data-invariant"". That is, they have no (known) observable behavior; differences due to the particular input data. These instructions are often used; when implementing cryptographic primitives dealing with private key data; because they are not believed to provide any side-channels. Similarly, we can; defer hardening until after them as they will not in-and-of-themselves; introduce a speculative execution side-channel. This results in code sequences; that look like:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate without leaking.; orl %eax, %edi; ```. While an addition happens to the loaded (potentially secret) value, that; doesn't leak any data and we then immediately harden it. ###### Hardening of loaded values deferred down the data-invariant expression graph. We can generalize the previous idea and sink the hardening down the expression; graph across as many data-invariant operations as desirable. This can use very; conservative rules for whether something is data-invariant. The primary goal; should be to handle multiple loads with a single hardening instruction:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate without leaking.; addl 4(%rsi), %edi # Continue without leaking.; addl 8(%rsi), %edi; orl %eax, %edi # Mask out bits from all three loads.; ```. ###### Preserving the flags while hardening loaded values on Haswell, Zen, and newer processors. Sadly, there are no useful instructions on x86 that apply a mask to all 64 bits; without touching the flag registers. However, we can harden loaded values that; are narrower than a word (fewer than 32-bits on 32-bit systems and fewer than; 64-bits on 64-bit systems) by zero-e",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:26364,Performance,load,loads,26364,"structions are often used; when implementing cryptographic primitives dealing with private key data; because they are not believed to provide any side-channels. Similarly, we can; defer hardening until after them as they will not in-and-of-themselves; introduce a speculative execution side-channel. This results in code sequences; that look like:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate without leaking.; orl %eax, %edi; ```. While an addition happens to the loaded (potentially secret) value, that; doesn't leak any data and we then immediately harden it. ###### Hardening of loaded values deferred down the data-invariant expression graph. We can generalize the previous idea and sink the hardening down the expression; graph across as many data-invariant operations as desirable. This can use very; conservative rules for whether something is data-invariant. The primary goal; should be to handle multiple loads with a single hardening instruction:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate without leaking.; addl 4(%rsi), %edi # Continue without leaking.; addl 8(%rsi), %edi; orl %eax, %edi # Mask out bits from all three loads.; ```. ###### Preserving the flags while hardening loaded values on Haswell, Zen, and newer processors. Sadly, there are no useful instructions on x86 that apply a mask to all 64 bits; without touching the flag registers. However, we can harden loaded values that; are narrower than a word (fewer than 32-bits on 32-bit systems and fewer than; 64-bits on 64-bit systems) by zero-extending the value to the full word size; and then shifting right by at least the number of original bits using the BMI2; `shrx` instruction:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate 32 bits of data.; shrxq %rax, %rdi, %rdi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:26668,Performance,load,loads,26668,"ive execution side-channel. This results in code sequences; that look like:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate without leaking.; orl %eax, %edi; ```. While an addition happens to the loaded (potentially secret) value, that; doesn't leak any data and we then immediately harden it. ###### Hardening of loaded values deferred down the data-invariant expression graph. We can generalize the previous idea and sink the hardening down the expression; graph across as many data-invariant operations as desirable. This can use very; conservative rules for whether something is data-invariant. The primary goal; should be to handle multiple loads with a single hardening instruction:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate without leaking.; addl 4(%rsi), %edi # Continue without leaking.; addl 8(%rsi), %edi; orl %eax, %edi # Mask out bits from all three loads.; ```. ###### Preserving the flags while hardening loaded values on Haswell, Zen, and newer processors. Sadly, there are no useful instructions on x86 that apply a mask to all 64 bits; without touching the flag registers. However, we can harden loaded values that; are narrower than a word (fewer than 32-bits on 32-bit systems and fewer than; 64-bits on 64-bit systems) by zero-extending the value to the full word size; and then shifting right by at least the number of original bits using the BMI2; `shrx` instruction:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate 32 bits of data.; shrxq %rax, %rdi, %rdi # Shift out all 32 bits loaded.; ```. Because on x86 the zero-extend is free, this can efficiently harden the loaded; value. ##### Hardening the address of the load. When hardening the loaded value is inapplicable, most often because the; instruction directly leaks infor",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:26725,Performance,load,loaded,26725,"_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate without leaking.; orl %eax, %edi; ```. While an addition happens to the loaded (potentially secret) value, that; doesn't leak any data and we then immediately harden it. ###### Hardening of loaded values deferred down the data-invariant expression graph. We can generalize the previous idea and sink the hardening down the expression; graph across as many data-invariant operations as desirable. This can use very; conservative rules for whether something is data-invariant. The primary goal; should be to handle multiple loads with a single hardening instruction:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate without leaking.; addl 4(%rsi), %edi # Continue without leaking.; addl 8(%rsi), %edi; orl %eax, %edi # Mask out bits from all three loads.; ```. ###### Preserving the flags while hardening loaded values on Haswell, Zen, and newer processors. Sadly, there are no useful instructions on x86 that apply a mask to all 64 bits; without touching the flag registers. However, we can harden loaded values that; are narrower than a word (fewer than 32-bits on 32-bit systems and fewer than; 64-bits on 64-bit systems) by zero-extending the value to the full word size; and then shifting right by at least the number of original bits using the BMI2; `shrx` instruction:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate 32 bits of data.; shrxq %rax, %rdi, %rdi # Shift out all 32 bits loaded.; ```. Because on x86 the zero-extend is free, this can efficiently harden the loaded; value. ##### Hardening the address of the load. When hardening the loaded value is inapplicable, most often because the; instruction directly leaks information (like `cmp` or `jmpq`), we switch to; hardening the _address_ of the load instead of ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:26919,Performance,load,loaded,26919,"erred down the data-invariant expression graph. We can generalize the previous idea and sink the hardening down the expression; graph across as many data-invariant operations as desirable. This can use very; conservative rules for whether something is data-invariant. The primary goal; should be to handle multiple loads with a single hardening instruction:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate without leaking.; addl 4(%rsi), %edi # Continue without leaking.; addl 8(%rsi), %edi; orl %eax, %edi # Mask out bits from all three loads.; ```. ###### Preserving the flags while hardening loaded values on Haswell, Zen, and newer processors. Sadly, there are no useful instructions on x86 that apply a mask to all 64 bits; without touching the flag registers. However, we can harden loaded values that; are narrower than a word (fewer than 32-bits on 32-bit systems and fewer than; 64-bits on 64-bit systems) by zero-extending the value to the full word size; and then shifting right by at least the number of original bits using the BMI2; `shrx` instruction:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate 32 bits of data.; shrxq %rax, %rdi, %rdi # Shift out all 32 bits loaded.; ```. Because on x86 the zero-extend is free, this can efficiently harden the loaded; value. ##### Hardening the address of the load. When hardening the loaded value is inapplicable, most often because the; instruction directly leaks information (like `cmp` or `jmpq`), we switch to; hardening the _address_ of the load instead of the loaded value. This avoids; increasing register pressure by unfolding the load or paying some other high; cost. To understand how this works in practice, we need to examine the exact; semantics of the x86 addressing modes which, in its fully general form, looks; like `(%base,%index,scale)offset`. Here `%base` and `%",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:27390,Performance,load,loaded,27390," with a single hardening instruction:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate without leaking.; addl 4(%rsi), %edi # Continue without leaking.; addl 8(%rsi), %edi; orl %eax, %edi # Mask out bits from all three loads.; ```. ###### Preserving the flags while hardening loaded values on Haswell, Zen, and newer processors. Sadly, there are no useful instructions on x86 that apply a mask to all 64 bits; without touching the flag registers. However, we can harden loaded values that; are narrower than a word (fewer than 32-bits on 32-bit systems and fewer than; 64-bits on 64-bit systems) by zero-extending the value to the full word size; and then shifting right by at least the number of original bits using the BMI2; `shrx` instruction:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate 32 bits of data.; shrxq %rax, %rdi, %rdi # Shift out all 32 bits loaded.; ```. Because on x86 the zero-extend is free, this can efficiently harden the loaded; value. ##### Hardening the address of the load. When hardening the loaded value is inapplicable, most often because the; instruction directly leaks information (like `cmp` or `jmpq`), we switch to; hardening the _address_ of the load instead of the loaded value. This avoids; increasing register pressure by unfolding the load or paying some other high; cost. To understand how this works in practice, we need to examine the exact; semantics of the x86 addressing modes which, in its fully general form, looks; like `(%base,%index,scale)offset`. Here `%base` and `%index` are 64-bit; registers that can potentially be any value, and may be attacker controlled,; and `scale` and `offset` are fixed immediate values. `scale` must be `1`, `2`,; `4`, or `8`, and `offset` can be any 32-bit sign extended value. The exact; computation performed to find the address is then: `%base + (scale ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:27476,Performance,load,loaded,27476,"r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate without leaking.; addl 4(%rsi), %edi # Continue without leaking.; addl 8(%rsi), %edi; orl %eax, %edi # Mask out bits from all three loads.; ```. ###### Preserving the flags while hardening loaded values on Haswell, Zen, and newer processors. Sadly, there are no useful instructions on x86 that apply a mask to all 64 bits; without touching the flag registers. However, we can harden loaded values that; are narrower than a word (fewer than 32-bits on 32-bit systems and fewer than; 64-bits on 64-bit systems) by zero-extending the value to the full word size; and then shifting right by at least the number of original bits using the BMI2; `shrx` instruction:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate 32 bits of data.; shrxq %rax, %rdi, %rdi # Shift out all 32 bits loaded.; ```. Because on x86 the zero-extend is free, this can efficiently harden the loaded; value. ##### Hardening the address of the load. When hardening the loaded value is inapplicable, most often because the; instruction directly leaks information (like `cmp` or `jmpq`), we switch to; hardening the _address_ of the load instead of the loaded value. This avoids; increasing register pressure by unfolding the load or paying some other high; cost. To understand how this works in practice, we need to examine the exact; semantics of the x86 addressing modes which, in its fully general form, looks; like `(%base,%index,scale)offset`. Here `%base` and `%index` are 64-bit; registers that can potentially be any value, and may be attacker controlled,; and `scale` and `offset` are fixed immediate values. `scale` must be `1`, `2`,; `4`, or `8`, and `offset` can be any 32-bit sign extended value. The exact; computation performed to find the address is then: `%base + (scale * %index) +; offset` under 64-bit 2's complement modular arithmetic. One issue",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:27526,Performance,load,load,27526,"edi # Load and accumulate without leaking.; addl 4(%rsi), %edi # Continue without leaking.; addl 8(%rsi), %edi; orl %eax, %edi # Mask out bits from all three loads.; ```. ###### Preserving the flags while hardening loaded values on Haswell, Zen, and newer processors. Sadly, there are no useful instructions on x86 that apply a mask to all 64 bits; without touching the flag registers. However, we can harden loaded values that; are narrower than a word (fewer than 32-bits on 32-bit systems and fewer than; 64-bits on 64-bit systems) by zero-extending the value to the full word size; and then shifting right by at least the number of original bits using the BMI2; `shrx` instruction:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate 32 bits of data.; shrxq %rax, %rdi, %rdi # Shift out all 32 bits loaded.; ```. Because on x86 the zero-extend is free, this can efficiently harden the loaded; value. ##### Hardening the address of the load. When hardening the loaded value is inapplicable, most often because the; instruction directly leaks information (like `cmp` or `jmpq`), we switch to; hardening the _address_ of the load instead of the loaded value. This avoids; increasing register pressure by unfolding the load or paying some other high; cost. To understand how this works in practice, we need to examine the exact; semantics of the x86 addressing modes which, in its fully general form, looks; like `(%base,%index,scale)offset`. Here `%base` and `%index` are 64-bit; registers that can potentially be any value, and may be attacker controlled,; and `scale` and `offset` are fixed immediate values. `scale` must be `1`, `2`,; `4`, or `8`, and `offset` can be any 32-bit sign extended value. The exact; computation performed to find the address is then: `%base + (scale * %index) +; offset` under 64-bit 2's complement modular arithmetic. One issue with this approach is that, after hardening, the `%base + (scal",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:27551,Performance,load,loaded,27551," Mask out bits from all three loads.; ```. ###### Preserving the flags while hardening loaded values on Haswell, Zen, and newer processors. Sadly, there are no useful instructions on x86 that apply a mask to all 64 bits; without touching the flag registers. However, we can harden loaded values that; are narrower than a word (fewer than 32-bits on 32-bit systems and fewer than; 64-bits on 64-bit systems) by zero-extending the value to the full word size; and then shifting right by at least the number of original bits using the BMI2; `shrx` instruction:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate 32 bits of data.; shrxq %rax, %rdi, %rdi # Shift out all 32 bits loaded.; ```. Because on x86 the zero-extend is free, this can efficiently harden the loaded; value. ##### Hardening the address of the load. When hardening the loaded value is inapplicable, most often because the; instruction directly leaks information (like `cmp` or `jmpq`), we switch to; hardening the _address_ of the load instead of the loaded value. This avoids; increasing register pressure by unfolding the load or paying some other high; cost. To understand how this works in practice, we need to examine the exact; semantics of the x86 addressing modes which, in its fully general form, looks; like `(%base,%index,scale)offset`. Here `%base` and `%index` are 64-bit; registers that can potentially be any value, and may be attacker controlled,; and `scale` and `offset` are fixed immediate values. `scale` must be `1`, `2`,; `4`, or `8`, and `offset` can be any 32-bit sign extended value. The exact; computation performed to find the address is then: `%base + (scale * %index) +; offset` under 64-bit 2's complement modular arithmetic. One issue with this approach is that, after hardening, the `%base + (scale *; %index)` subexpression will compute a value near zero (`-1 + (scale * -1)`) and; then a large, positive `offset` will index",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:27713,Performance,load,load,27713," Mask out bits from all three loads.; ```. ###### Preserving the flags while hardening loaded values on Haswell, Zen, and newer processors. Sadly, there are no useful instructions on x86 that apply a mask to all 64 bits; without touching the flag registers. However, we can harden loaded values that; are narrower than a word (fewer than 32-bits on 32-bit systems and fewer than; 64-bits on 64-bit systems) by zero-extending the value to the full word size; and then shifting right by at least the number of original bits using the BMI2; `shrx` instruction:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate 32 bits of data.; shrxq %rax, %rdi, %rdi # Shift out all 32 bits loaded.; ```. Because on x86 the zero-extend is free, this can efficiently harden the loaded; value. ##### Hardening the address of the load. When hardening the loaded value is inapplicable, most often because the; instruction directly leaks information (like `cmp` or `jmpq`), we switch to; hardening the _address_ of the load instead of the loaded value. This avoids; increasing register pressure by unfolding the load or paying some other high; cost. To understand how this works in practice, we need to examine the exact; semantics of the x86 addressing modes which, in its fully general form, looks; like `(%base,%index,scale)offset`. Here `%base` and `%index` are 64-bit; registers that can potentially be any value, and may be attacker controlled,; and `scale` and `offset` are fixed immediate values. `scale` must be `1`, `2`,; `4`, or `8`, and `offset` can be any 32-bit sign extended value. The exact; computation performed to find the address is then: `%base + (scale * %index) +; offset` under 64-bit 2's complement modular arithmetic. One issue with this approach is that, after hardening, the `%base + (scale *; %index)` subexpression will compute a value near zero (`-1 + (scale * -1)`) and; then a large, positive `offset` will index",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:27733,Performance,load,loaded,27733," Mask out bits from all three loads.; ```. ###### Preserving the flags while hardening loaded values on Haswell, Zen, and newer processors. Sadly, there are no useful instructions on x86 that apply a mask to all 64 bits; without touching the flag registers. However, we can harden loaded values that; are narrower than a word (fewer than 32-bits on 32-bit systems and fewer than; 64-bits on 64-bit systems) by zero-extending the value to the full word size; and then shifting right by at least the number of original bits using the BMI2; `shrx` instruction:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate 32 bits of data.; shrxq %rax, %rdi, %rdi # Shift out all 32 bits loaded.; ```. Because on x86 the zero-extend is free, this can efficiently harden the loaded; value. ##### Hardening the address of the load. When hardening the loaded value is inapplicable, most often because the; instruction directly leaks information (like `cmp` or `jmpq`), we switch to; hardening the _address_ of the load instead of the loaded value. This avoids; increasing register pressure by unfolding the load or paying some other high; cost. To understand how this works in practice, we need to examine the exact; semantics of the x86 addressing modes which, in its fully general form, looks; like `(%base,%index,scale)offset`. Here `%base` and `%index` are 64-bit; registers that can potentially be any value, and may be attacker controlled,; and `scale` and `offset` are fixed immediate values. `scale` must be `1`, `2`,; `4`, or `8`, and `offset` can be any 32-bit sign extended value. The exact; computation performed to find the address is then: `%base + (scale * %index) +; offset` under 64-bit 2's complement modular arithmetic. One issue with this approach is that, after hardening, the `%base + (scale *; %index)` subexpression will compute a value near zero (`-1 + (scale * -1)`) and; then a large, positive `offset` will index",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:27806,Performance,load,load,27806," no useful instructions on x86 that apply a mask to all 64 bits; without touching the flag registers. However, we can harden loaded values that; are narrower than a word (fewer than 32-bits on 32-bit systems and fewer than; 64-bits on 64-bit systems) by zero-extending the value to the full word size; and then shifting right by at least the number of original bits using the BMI2; `shrx` instruction:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate 32 bits of data.; shrxq %rax, %rdi, %rdi # Shift out all 32 bits loaded.; ```. Because on x86 the zero-extend is free, this can efficiently harden the loaded; value. ##### Hardening the address of the load. When hardening the loaded value is inapplicable, most often because the; instruction directly leaks information (like `cmp` or `jmpq`), we switch to; hardening the _address_ of the load instead of the loaded value. This avoids; increasing register pressure by unfolding the load or paying some other high; cost. To understand how this works in practice, we need to examine the exact; semantics of the x86 addressing modes which, in its fully general form, looks; like `(%base,%index,scale)offset`. Here `%base` and `%index` are 64-bit; registers that can potentially be any value, and may be attacker controlled,; and `scale` and `offset` are fixed immediate values. `scale` must be `1`, `2`,; `4`, or `8`, and `offset` can be any 32-bit sign extended value. The exact; computation performed to find the address is then: `%base + (scale * %index) +; offset` under 64-bit 2's complement modular arithmetic. One issue with this approach is that, after hardening, the `%base + (scale *; %index)` subexpression will compute a value near zero (`-1 + (scale * -1)`) and; then a large, positive `offset` will index into memory within the first two; gigabytes of address space. While these offsets are not attacker controlled,; the attacker could chose to attack a load w",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:28314,Performance,perform,performed,28314,"di # Shift out all 32 bits loaded.; ```. Because on x86 the zero-extend is free, this can efficiently harden the loaded; value. ##### Hardening the address of the load. When hardening the loaded value is inapplicable, most often because the; instruction directly leaks information (like `cmp` or `jmpq`), we switch to; hardening the _address_ of the load instead of the loaded value. This avoids; increasing register pressure by unfolding the load or paying some other high; cost. To understand how this works in practice, we need to examine the exact; semantics of the x86 addressing modes which, in its fully general form, looks; like `(%base,%index,scale)offset`. Here `%base` and `%index` are 64-bit; registers that can potentially be any value, and may be attacker controlled,; and `scale` and `offset` are fixed immediate values. `scale` must be `1`, `2`,; `4`, or `8`, and `offset` can be any 32-bit sign extended value. The exact; computation performed to find the address is then: `%base + (scale * %index) +; offset` under 64-bit 2's complement modular arithmetic. One issue with this approach is that, after hardening, the `%base + (scale *; %index)` subexpression will compute a value near zero (`-1 + (scale * -1)`) and; then a large, positive `offset` will index into memory within the first two; gigabytes of address space. While these offsets are not attacker controlled,; the attacker could chose to attack a load which happens to have the desired; offset and then successfully read memory in that region. This significantly; raises the burden on the attacker and limits the scope of attack but does not; eliminate it. To fully close the attack we must work with the operating system; to preclude mapping memory in the low two gigabytes of address space. ###### 64-bit load checking instructions. We can use the following instruction sequences to check loads. We set up `%r8`; in these examples to hold the special value of `-1` which will be `cmov`ed over; `%rax` in misspeculated pa",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:28789,Performance,load,load,28789,"nfolding the load or paying some other high; cost. To understand how this works in practice, we need to examine the exact; semantics of the x86 addressing modes which, in its fully general form, looks; like `(%base,%index,scale)offset`. Here `%base` and `%index` are 64-bit; registers that can potentially be any value, and may be attacker controlled,; and `scale` and `offset` are fixed immediate values. `scale` must be `1`, `2`,; `4`, or `8`, and `offset` can be any 32-bit sign extended value. The exact; computation performed to find the address is then: `%base + (scale * %index) +; offset` under 64-bit 2's complement modular arithmetic. One issue with this approach is that, after hardening, the `%base + (scale *; %index)` subexpression will compute a value near zero (`-1 + (scale * -1)`) and; then a large, positive `offset` will index into memory within the first two; gigabytes of address space. While these offsets are not attacker controlled,; the attacker could chose to attack a load which happens to have the desired; offset and then successfully read memory in that region. This significantly; raises the burden on the attacker and limits the scope of attack but does not; eliminate it. To fully close the attack we must work with the operating system; to preclude mapping memory in the low two gigabytes of address space. ###### 64-bit load checking instructions. We can use the following instruction sequences to check loads. We set up `%r8`; in these examples to hold the special value of `-1` which will be `cmov`ed over; `%rax` in misspeculated paths. Single register addressing mode:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rsi # Mask the pointer if misspeculating.; movl (%rsi), %edi; ```. Two register addressing mode:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rsi # Mask the pointer if misspeculating.; orq %rax, %rcx # Mask the index if misspeculating.;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:29149,Performance,load,load,29149,"e` and `offset` are fixed immediate values. `scale` must be `1`, `2`,; `4`, or `8`, and `offset` can be any 32-bit sign extended value. The exact; computation performed to find the address is then: `%base + (scale * %index) +; offset` under 64-bit 2's complement modular arithmetic. One issue with this approach is that, after hardening, the `%base + (scale *; %index)` subexpression will compute a value near zero (`-1 + (scale * -1)`) and; then a large, positive `offset` will index into memory within the first two; gigabytes of address space. While these offsets are not attacker controlled,; the attacker could chose to attack a load which happens to have the desired; offset and then successfully read memory in that region. This significantly; raises the burden on the attacker and limits the scope of attack but does not; eliminate it. To fully close the attack we must work with the operating system; to preclude mapping memory in the low two gigabytes of address space. ###### 64-bit load checking instructions. We can use the following instruction sequences to check loads. We set up `%r8`; in these examples to hold the special value of `-1` which will be `cmov`ed over; `%rax` in misspeculated paths. Single register addressing mode:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rsi # Mask the pointer if misspeculating.; movl (%rsi), %edi; ```. Two register addressing mode:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rsi # Mask the pointer if misspeculating.; orq %rax, %rcx # Mask the index if misspeculating.; movl (%rsi,%rcx), %edi; ```. This will result in a negative address near zero or in `offset` wrapping the; address space back to a small positive address. Small, negative addresses will; fault in user-mode for most operating systems, but targets which need the high; address space to be user accessible may need to adjust the exact sequence used; above. Additio",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:29233,Performance,load,loads,29233,"must be `1`, `2`,; `4`, or `8`, and `offset` can be any 32-bit sign extended value. The exact; computation performed to find the address is then: `%base + (scale * %index) +; offset` under 64-bit 2's complement modular arithmetic. One issue with this approach is that, after hardening, the `%base + (scale *; %index)` subexpression will compute a value near zero (`-1 + (scale * -1)`) and; then a large, positive `offset` will index into memory within the first two; gigabytes of address space. While these offsets are not attacker controlled,; the attacker could chose to attack a load which happens to have the desired; offset and then successfully read memory in that region. This significantly; raises the burden on the attacker and limits the scope of attack but does not; eliminate it. To fully close the attack we must work with the operating system; to preclude mapping memory in the low two gigabytes of address space. ###### 64-bit load checking instructions. We can use the following instruction sequences to check loads. We set up `%r8`; in these examples to hold the special value of `-1` which will be `cmov`ed over; `%rax` in misspeculated paths. Single register addressing mode:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rsi # Mask the pointer if misspeculating.; movl (%rsi), %edi; ```. Two register addressing mode:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rsi # Mask the pointer if misspeculating.; orq %rax, %rcx # Mask the index if misspeculating.; movl (%rsi,%rcx), %edi; ```. This will result in a negative address near zero or in `offset` wrapping the; address space back to a small positive address. Small, negative addresses will; fault in user-mode for most operating systems, but targets which need the high; address space to be user accessible may need to adjust the exact sequence used; above. Additionally, the low addresses will need to be marked unrea",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:30245,Performance,load,load,30245,"ing instruction sequences to check loads. We set up `%r8`; in these examples to hold the special value of `-1` which will be `cmov`ed over; `%rax` in misspeculated paths. Single register addressing mode:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rsi # Mask the pointer if misspeculating.; movl (%rsi), %edi; ```. Two register addressing mode:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rsi # Mask the pointer if misspeculating.; orq %rax, %rcx # Mask the index if misspeculating.; movl (%rsi,%rcx), %edi; ```. This will result in a negative address near zero or in `offset` wrapping the; address space back to a small positive address. Small, negative addresses will; fault in user-mode for most operating systems, but targets which need the high; address space to be user accessible may need to adjust the exact sequence used; above. Additionally, the low addresses will need to be marked unreadable by the; OS to fully harden the load. ###### RIP-relative addressing is even easier to break. There is a common addressing mode idiom that is substantially harder to check:; addressing relative to the instruction pointer. We cannot change the value of; the instruction pointer register and so we have the harder problem of forcing; `%base + scale * %index + offset` to be an invalid address, by *only* changing; `%index`. The only advantage we have is that the attacker also cannot modify; `%base`. If we use the fast instruction sequence above, but only apply it to; the index, we will always access `%rip + (scale * -1) + offset`. If the; attacker can find a load which with this address happens to point to secret; data, then they can reach it. However, the loader and base libraries can also; simply refuse to map the heap, data segments, or stack within 2gb of any of the; text in the program, much like it can reserve the low 2gb of address space. ###### The flag registers again ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:30874,Performance,load,load,30874,"ddress space back to a small positive address. Small, negative addresses will; fault in user-mode for most operating systems, but targets which need the high; address space to be user accessible may need to adjust the exact sequence used; above. Additionally, the low addresses will need to be marked unreadable by the; OS to fully harden the load. ###### RIP-relative addressing is even easier to break. There is a common addressing mode idiom that is substantially harder to check:; addressing relative to the instruction pointer. We cannot change the value of; the instruction pointer register and so we have the harder problem of forcing; `%base + scale * %index + offset` to be an invalid address, by *only* changing; `%index`. The only advantage we have is that the attacker also cannot modify; `%base`. If we use the fast instruction sequence above, but only apply it to; the index, we will always access `%rip + (scale * -1) + offset`. If the; attacker can find a load which with this address happens to point to secret; data, then they can reach it. However, the loader and base libraries can also; simply refuse to map the heap, data segments, or stack within 2gb of any of the; text in the program, much like it can reserve the low 2gb of address space. ###### The flag registers again make everything hard. Unfortunately, the technique of using `orq`-instructions has a serious flaw on; x86. The very thing that makes it easy to accumulate state, the flag registers; containing predicates, causes serious problems here because they may be alive; and used by the loading instruction or subsequent instructions. On x86, the; `orq` instruction **sets** the flags and will override anything already there.; This makes inserting them into the instruction stream very hazardous.; Unfortunately, unlike when hardening the loaded value, we have no fallback here; and so we must have a fully general approach available. The first thing we must do when generating these sequences is try to analyze; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:30974,Performance,load,loader,30974,"dress space to be user accessible may need to adjust the exact sequence used; above. Additionally, the low addresses will need to be marked unreadable by the; OS to fully harden the load. ###### RIP-relative addressing is even easier to break. There is a common addressing mode idiom that is substantially harder to check:; addressing relative to the instruction pointer. We cannot change the value of; the instruction pointer register and so we have the harder problem of forcing; `%base + scale * %index + offset` to be an invalid address, by *only* changing; `%index`. The only advantage we have is that the attacker also cannot modify; `%base`. If we use the fast instruction sequence above, but only apply it to; the index, we will always access `%rip + (scale * -1) + offset`. If the; attacker can find a load which with this address happens to point to secret; data, then they can reach it. However, the loader and base libraries can also; simply refuse to map the heap, data segments, or stack within 2gb of any of the; text in the program, much like it can reserve the low 2gb of address space. ###### The flag registers again make everything hard. Unfortunately, the technique of using `orq`-instructions has a serious flaw on; x86. The very thing that makes it easy to accumulate state, the flag registers; containing predicates, causes serious problems here because they may be alive; and used by the loading instruction or subsequent instructions. On x86, the; `orq` instruction **sets** the flags and will override anything already there.; This makes inserting them into the instruction stream very hazardous.; Unfortunately, unlike when hardening the loaded value, we have no fallback here; and so we must have a fully general approach available. The first thing we must do when generating these sequences is try to analyze; the surrounding code to prove that the flags are not in fact alive or being; used. Typically, it has been set by some other instruction which just happens; to s",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:31476,Performance,load,loading,31476,"instruction pointer. We cannot change the value of; the instruction pointer register and so we have the harder problem of forcing; `%base + scale * %index + offset` to be an invalid address, by *only* changing; `%index`. The only advantage we have is that the attacker also cannot modify; `%base`. If we use the fast instruction sequence above, but only apply it to; the index, we will always access `%rip + (scale * -1) + offset`. If the; attacker can find a load which with this address happens to point to secret; data, then they can reach it. However, the loader and base libraries can also; simply refuse to map the heap, data segments, or stack within 2gb of any of the; text in the program, much like it can reserve the low 2gb of address space. ###### The flag registers again make everything hard. Unfortunately, the technique of using `orq`-instructions has a serious flaw on; x86. The very thing that makes it easy to accumulate state, the flag registers; containing predicates, causes serious problems here because they may be alive; and used by the loading instruction or subsequent instructions. On x86, the; `orq` instruction **sets** the flags and will override anything already there.; This makes inserting them into the instruction stream very hazardous.; Unfortunately, unlike when hardening the loaded value, we have no fallback here; and so we must have a fully general approach available. The first thing we must do when generating these sequences is try to analyze; the surrounding code to prove that the flags are not in fact alive or being; used. Typically, it has been set by some other instruction which just happens; to set the flags register (much like ours!) with no actual dependency. In those; cases, it is safe to directly insert these instructions. Alternatively we may; be able to move them earlier to avoid clobbering the used value. However, this may ultimately be impossible. In that case, we need to preserve; the flags around these instructions:; ```; ... .LBB",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:31729,Performance,load,loaded,31729,"ve, but only apply it to; the index, we will always access `%rip + (scale * -1) + offset`. If the; attacker can find a load which with this address happens to point to secret; data, then they can reach it. However, the loader and base libraries can also; simply refuse to map the heap, data segments, or stack within 2gb of any of the; text in the program, much like it can reserve the low 2gb of address space. ###### The flag registers again make everything hard. Unfortunately, the technique of using `orq`-instructions has a serious flaw on; x86. The very thing that makes it easy to accumulate state, the flag registers; containing predicates, causes serious problems here because they may be alive; and used by the loading instruction or subsequent instructions. On x86, the; `orq` instruction **sets** the flags and will override anything already there.; This makes inserting them into the instruction stream very hazardous.; Unfortunately, unlike when hardening the loaded value, we have no fallback here; and so we must have a fully general approach available. The first thing we must do when generating these sequences is try to analyze; the surrounding code to prove that the flags are not in fact alive or being; used. Typically, it has been set by some other instruction which just happens; to set the flags register (much like ours!) with no actual dependency. In those; cases, it is safe to directly insert these instructions. Alternatively we may; be able to move them earlier to avoid clobbering the used value. However, this may ultimately be impossible. In that case, we need to preserve; the flags around these instructions:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; pushfq; orq %rax, %rcx # Mask the pointer if misspeculating.; orq %rax, %rdx # Mask the index if misspeculating.; popfq; movl (%rcx,%rdx), %edi; ```. Using the `pushf` and `popf` instructions saves the flags register around our; inserted code, but comes at a high co",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:34575,Performance,load,loads,34575,"lable on Haswell and; Zen processors, there is an instruction for shifting that does not set any; flags: `shrx`. We can use this and the `lea` instruction to implement analogous; code sequences to the above ones. However, these are still very marginally; slower, as there are fewer ports able to dispatch shift instructions in most; modern x86 processors than there are for `or` instructions. Fast, single register addressing mode:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; shrxq %rax, %rsi, %rsi # Shift away bits if misspeculating.; movl (%rsi), %edi; ```. This will collapse the register to zero or one, and everything but the offset; in the addressing mode to be less than or equal to 9. This means the full; address can only be guaranteed to be less than `(1 << 31) + 9`. The OS may wish; to protect an extra page of the low address space to account for this. ##### Optimizations. A very large portion of the cost for this approach comes from checking loads in; this way, so it is important to work to optimize this. However, beyond making; the instruction sequences to *apply* the checks efficient (for example by; avoiding `pushfq` and `popfq` sequences), the only significant optimization is; to check fewer loads without introducing a vulnerability. We apply several; techniques to accomplish that. ###### Don't check loads from compile-time constant stack offsets. We implement this optimization on x86 by skipping the checking of loads which; use a fixed frame pointer offset. The result of this optimization is that patterns like reloading a spilled; register or accessing a global field don't get checked. This is a very; significant performance win. ###### Don't check dependent loads. A core part of why this mitigation strategy works is that it establishes a; data-flow check on the loaded address. However, this means that if the address; itself was already loaded using a checked load, there is no need to check a; dependent load provi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:34625,Performance,optimiz,optimize,34625,"lable on Haswell and; Zen processors, there is an instruction for shifting that does not set any; flags: `shrx`. We can use this and the `lea` instruction to implement analogous; code sequences to the above ones. However, these are still very marginally; slower, as there are fewer ports able to dispatch shift instructions in most; modern x86 processors than there are for `or` instructions. Fast, single register addressing mode:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; shrxq %rax, %rsi, %rsi # Shift away bits if misspeculating.; movl (%rsi), %edi; ```. This will collapse the register to zero or one, and everything but the offset; in the addressing mode to be less than or equal to 9. This means the full; address can only be guaranteed to be less than `(1 << 31) + 9`. The OS may wish; to protect an extra page of the low address space to account for this. ##### Optimizations. A very large portion of the cost for this approach comes from checking loads in; this way, so it is important to work to optimize this. However, beyond making; the instruction sequences to *apply* the checks efficient (for example by; avoiding `pushfq` and `popfq` sequences), the only significant optimization is; to check fewer loads without introducing a vulnerability. We apply several; techniques to accomplish that. ###### Don't check loads from compile-time constant stack offsets. We implement this optimization on x86 by skipping the checking of loads which; use a fixed frame pointer offset. The result of this optimization is that patterns like reloading a spilled; register or accessing a global field don't get checked. This is a very; significant performance win. ###### Don't check dependent loads. A core part of why this mitigation strategy works is that it establishes a; data-flow check on the loaded address. However, this means that if the address; itself was already loaded using a checked load, there is no need to check a; dependent load provi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:34802,Performance,optimiz,optimization,34802,"quences to the above ones. However, these are still very marginally; slower, as there are fewer ports able to dispatch shift instructions in most; modern x86 processors than there are for `or` instructions. Fast, single register addressing mode:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; shrxq %rax, %rsi, %rsi # Shift away bits if misspeculating.; movl (%rsi), %edi; ```. This will collapse the register to zero or one, and everything but the offset; in the addressing mode to be less than or equal to 9. This means the full; address can only be guaranteed to be less than `(1 << 31) + 9`. The OS may wish; to protect an extra page of the low address space to account for this. ##### Optimizations. A very large portion of the cost for this approach comes from checking loads in; this way, so it is important to work to optimize this. However, beyond making; the instruction sequences to *apply* the checks efficient (for example by; avoiding `pushfq` and `popfq` sequences), the only significant optimization is; to check fewer loads without introducing a vulnerability. We apply several; techniques to accomplish that. ###### Don't check loads from compile-time constant stack offsets. We implement this optimization on x86 by skipping the checking of loads which; use a fixed frame pointer offset. The result of this optimization is that patterns like reloading a spilled; register or accessing a global field don't get checked. This is a very; significant performance win. ###### Don't check dependent loads. A core part of why this mitigation strategy works is that it establishes a; data-flow check on the loaded address. However, this means that if the address; itself was already loaded using a checked load, there is no need to check a; dependent load provided it is within the same basic block as the checked load,; and therefore has no additional predicates guarding it. Consider code like the; following:; ```; ... .LBB0_4: # %danger; movq (",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:34834,Performance,load,loads,34834,"quences to the above ones. However, these are still very marginally; slower, as there are fewer ports able to dispatch shift instructions in most; modern x86 processors than there are for `or` instructions. Fast, single register addressing mode:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; shrxq %rax, %rsi, %rsi # Shift away bits if misspeculating.; movl (%rsi), %edi; ```. This will collapse the register to zero or one, and everything but the offset; in the addressing mode to be less than or equal to 9. This means the full; address can only be guaranteed to be less than `(1 << 31) + 9`. The OS may wish; to protect an extra page of the low address space to account for this. ##### Optimizations. A very large portion of the cost for this approach comes from checking loads in; this way, so it is important to work to optimize this. However, beyond making; the instruction sequences to *apply* the checks efficient (for example by; avoiding `pushfq` and `popfq` sequences), the only significant optimization is; to check fewer loads without introducing a vulnerability. We apply several; techniques to accomplish that. ###### Don't check loads from compile-time constant stack offsets. We implement this optimization on x86 by skipping the checking of loads which; use a fixed frame pointer offset. The result of this optimization is that patterns like reloading a spilled; register or accessing a global field don't get checked. This is a very; significant performance win. ###### Don't check dependent loads. A core part of why this mitigation strategy works is that it establishes a; data-flow check on the loaded address. However, this means that if the address; itself was already loaded using a checked load, there is no need to check a; dependent load provided it is within the same basic block as the checked load,; and therefore has no additional predicates guarding it. Consider code like the; following:; ```; ... .LBB0_4: # %danger; movq (",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:34945,Performance,load,loads,34945,"ions. Fast, single register addressing mode:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; shrxq %rax, %rsi, %rsi # Shift away bits if misspeculating.; movl (%rsi), %edi; ```. This will collapse the register to zero or one, and everything but the offset; in the addressing mode to be less than or equal to 9. This means the full; address can only be guaranteed to be less than `(1 << 31) + 9`. The OS may wish; to protect an extra page of the low address space to account for this. ##### Optimizations. A very large portion of the cost for this approach comes from checking loads in; this way, so it is important to work to optimize this. However, beyond making; the instruction sequences to *apply* the checks efficient (for example by; avoiding `pushfq` and `popfq` sequences), the only significant optimization is; to check fewer loads without introducing a vulnerability. We apply several; techniques to accomplish that. ###### Don't check loads from compile-time constant stack offsets. We implement this optimization on x86 by skipping the checking of loads which; use a fixed frame pointer offset. The result of this optimization is that patterns like reloading a spilled; register or accessing a global field don't get checked. This is a very; significant performance win. ###### Don't check dependent loads. A core part of why this mitigation strategy works is that it establishes a; data-flow check on the loaded address. However, this means that if the address; itself was already loaded using a checked load, there is no need to check a; dependent load provided it is within the same basic block as the checked load,; and therefore has no additional predicates guarding it. Consider code like the; following:; ```; ... .LBB0_4: # %danger; movq (%rcx), %rdi; movl (%rdi), %edx; ```. This will get transformed into:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rcx # Mask the pointer if misspe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:35011,Performance,optimiz,optimization,35011,"ax # Conditionally update predicate state.; shrxq %rax, %rsi, %rsi # Shift away bits if misspeculating.; movl (%rsi), %edi; ```. This will collapse the register to zero or one, and everything but the offset; in the addressing mode to be less than or equal to 9. This means the full; address can only be guaranteed to be less than `(1 << 31) + 9`. The OS may wish; to protect an extra page of the low address space to account for this. ##### Optimizations. A very large portion of the cost for this approach comes from checking loads in; this way, so it is important to work to optimize this. However, beyond making; the instruction sequences to *apply* the checks efficient (for example by; avoiding `pushfq` and `popfq` sequences), the only significant optimization is; to check fewer loads without introducing a vulnerability. We apply several; techniques to accomplish that. ###### Don't check loads from compile-time constant stack offsets. We implement this optimization on x86 by skipping the checking of loads which; use a fixed frame pointer offset. The result of this optimization is that patterns like reloading a spilled; register or accessing a global field don't get checked. This is a very; significant performance win. ###### Don't check dependent loads. A core part of why this mitigation strategy works is that it establishes a; data-flow check on the loaded address. However, this means that if the address; itself was already loaded using a checked load, there is no need to check a; dependent load provided it is within the same basic block as the checked load,; and therefore has no additional predicates guarding it. Consider code like the; following:; ```; ... .LBB0_4: # %danger; movq (%rcx), %rdi; movl (%rdi), %edx; ```. This will get transformed into:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rcx # Mask the pointer if misspeculating.; movq (%rcx), %rdi # Hardened load.; movl (%rdi), %edx # Unhardened load due to ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:35059,Performance,load,loads,35059,"ax # Conditionally update predicate state.; shrxq %rax, %rsi, %rsi # Shift away bits if misspeculating.; movl (%rsi), %edi; ```. This will collapse the register to zero or one, and everything but the offset; in the addressing mode to be less than or equal to 9. This means the full; address can only be guaranteed to be less than `(1 << 31) + 9`. The OS may wish; to protect an extra page of the low address space to account for this. ##### Optimizations. A very large portion of the cost for this approach comes from checking loads in; this way, so it is important to work to optimize this. However, beyond making; the instruction sequences to *apply* the checks efficient (for example by; avoiding `pushfq` and `popfq` sequences), the only significant optimization is; to check fewer loads without introducing a vulnerability. We apply several; techniques to accomplish that. ###### Don't check loads from compile-time constant stack offsets. We implement this optimization on x86 by skipping the checking of loads which; use a fixed frame pointer offset. The result of this optimization is that patterns like reloading a spilled; register or accessing a global field don't get checked. This is a very; significant performance win. ###### Don't check dependent loads. A core part of why this mitigation strategy works is that it establishes a; data-flow check on the loaded address. However, this means that if the address; itself was already loaded using a checked load, there is no need to check a; dependent load provided it is within the same basic block as the checked load,; and therefore has no additional predicates guarding it. Consider code like the; following:; ```; ... .LBB0_4: # %danger; movq (%rcx), %rdi; movl (%rdi), %edx; ```. This will get transformed into:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rcx # Mask the pointer if misspeculating.; movq (%rcx), %rdi # Hardened load.; movl (%rdi), %edx # Unhardened load due to ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:35125,Performance,optimiz,optimization,35125,"; ```. This will collapse the register to zero or one, and everything but the offset; in the addressing mode to be less than or equal to 9. This means the full; address can only be guaranteed to be less than `(1 << 31) + 9`. The OS may wish; to protect an extra page of the low address space to account for this. ##### Optimizations. A very large portion of the cost for this approach comes from checking loads in; this way, so it is important to work to optimize this. However, beyond making; the instruction sequences to *apply* the checks efficient (for example by; avoiding `pushfq` and `popfq` sequences), the only significant optimization is; to check fewer loads without introducing a vulnerability. We apply several; techniques to accomplish that. ###### Don't check loads from compile-time constant stack offsets. We implement this optimization on x86 by skipping the checking of loads which; use a fixed frame pointer offset. The result of this optimization is that patterns like reloading a spilled; register or accessing a global field don't get checked. This is a very; significant performance win. ###### Don't check dependent loads. A core part of why this mitigation strategy works is that it establishes a; data-flow check on the loaded address. However, this means that if the address; itself was already loaded using a checked load, there is no need to check a; dependent load provided it is within the same basic block as the checked load,; and therefore has no additional predicates guarding it. Consider code like the; following:; ```; ... .LBB0_4: # %danger; movq (%rcx), %rdi; movl (%rdi), %edx; ```. This will get transformed into:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rcx # Mask the pointer if misspeculating.; movq (%rcx), %rdi # Hardened load.; movl (%rdi), %edx # Unhardened load due to dependent addr.; ```. This doesn't check the load through `%rdi` as that pointer is dependent on a; checked load already. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:35265,Performance,perform,performance,35265," the addressing mode to be less than or equal to 9. This means the full; address can only be guaranteed to be less than `(1 << 31) + 9`. The OS may wish; to protect an extra page of the low address space to account for this. ##### Optimizations. A very large portion of the cost for this approach comes from checking loads in; this way, so it is important to work to optimize this. However, beyond making; the instruction sequences to *apply* the checks efficient (for example by; avoiding `pushfq` and `popfq` sequences), the only significant optimization is; to check fewer loads without introducing a vulnerability. We apply several; techniques to accomplish that. ###### Don't check loads from compile-time constant stack offsets. We implement this optimization on x86 by skipping the checking of loads which; use a fixed frame pointer offset. The result of this optimization is that patterns like reloading a spilled; register or accessing a global field don't get checked. This is a very; significant performance win. ###### Don't check dependent loads. A core part of why this mitigation strategy works is that it establishes a; data-flow check on the loaded address. However, this means that if the address; itself was already loaded using a checked load, there is no need to check a; dependent load provided it is within the same basic block as the checked load,; and therefore has no additional predicates guarding it. Consider code like the; following:; ```; ... .LBB0_4: # %danger; movq (%rcx), %rdi; movl (%rdi), %edx; ```. This will get transformed into:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rcx # Mask the pointer if misspeculating.; movq (%rcx), %rdi # Hardened load.; movl (%rdi), %edx # Unhardened load due to dependent addr.; ```. This doesn't check the load through `%rdi` as that pointer is dependent on a; checked load already. ###### Protect large, load-heavy blocks with a single lfence. It may be worth using a si",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:35311,Performance,load,loads,35311,"qual to 9. This means the full; address can only be guaranteed to be less than `(1 << 31) + 9`. The OS may wish; to protect an extra page of the low address space to account for this. ##### Optimizations. A very large portion of the cost for this approach comes from checking loads in; this way, so it is important to work to optimize this. However, beyond making; the instruction sequences to *apply* the checks efficient (for example by; avoiding `pushfq` and `popfq` sequences), the only significant optimization is; to check fewer loads without introducing a vulnerability. We apply several; techniques to accomplish that. ###### Don't check loads from compile-time constant stack offsets. We implement this optimization on x86 by skipping the checking of loads which; use a fixed frame pointer offset. The result of this optimization is that patterns like reloading a spilled; register or accessing a global field don't get checked. This is a very; significant performance win. ###### Don't check dependent loads. A core part of why this mitigation strategy works is that it establishes a; data-flow check on the loaded address. However, this means that if the address; itself was already loaded using a checked load, there is no need to check a; dependent load provided it is within the same basic block as the checked load,; and therefore has no additional predicates guarding it. Consider code like the; following:; ```; ... .LBB0_4: # %danger; movq (%rcx), %rdi; movl (%rdi), %edx; ```. This will get transformed into:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rcx # Mask the pointer if misspeculating.; movq (%rcx), %rdi # Hardened load.; movl (%rdi), %edx # Unhardened load due to dependent addr.; ```. This doesn't check the load through `%rdi` as that pointer is dependent on a; checked load already. ###### Protect large, load-heavy blocks with a single lfence. It may be worth using a single `lfence` instruction at the start o",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:35417,Performance,load,loaded,35417,"han `(1 << 31) + 9`. The OS may wish; to protect an extra page of the low address space to account for this. ##### Optimizations. A very large portion of the cost for this approach comes from checking loads in; this way, so it is important to work to optimize this. However, beyond making; the instruction sequences to *apply* the checks efficient (for example by; avoiding `pushfq` and `popfq` sequences), the only significant optimization is; to check fewer loads without introducing a vulnerability. We apply several; techniques to accomplish that. ###### Don't check loads from compile-time constant stack offsets. We implement this optimization on x86 by skipping the checking of loads which; use a fixed frame pointer offset. The result of this optimization is that patterns like reloading a spilled; register or accessing a global field don't get checked. This is a very; significant performance win. ###### Don't check dependent loads. A core part of why this mitigation strategy works is that it establishes a; data-flow check on the loaded address. However, this means that if the address; itself was already loaded using a checked load, there is no need to check a; dependent load provided it is within the same basic block as the checked load,; and therefore has no additional predicates guarding it. Consider code like the; following:; ```; ... .LBB0_4: # %danger; movq (%rcx), %rdi; movl (%rdi), %edx; ```. This will get transformed into:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rcx # Mask the pointer if misspeculating.; movq (%rcx), %rdi # Hardened load.; movl (%rdi), %edx # Unhardened load due to dependent addr.; ```. This doesn't check the load through `%rdi` as that pointer is dependent on a; checked load already. ###### Protect large, load-heavy blocks with a single lfence. It may be worth using a single `lfence` instruction at the start of a block; which begins with a (very) large number of loads that require ind",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:35493,Performance,load,loaded,35493,"s from checking loads in; this way, so it is important to work to optimize this. However, beyond making; the instruction sequences to *apply* the checks efficient (for example by; avoiding `pushfq` and `popfq` sequences), the only significant optimization is; to check fewer loads without introducing a vulnerability. We apply several; techniques to accomplish that. ###### Don't check loads from compile-time constant stack offsets. We implement this optimization on x86 by skipping the checking of loads which; use a fixed frame pointer offset. The result of this optimization is that patterns like reloading a spilled; register or accessing a global field don't get checked. This is a very; significant performance win. ###### Don't check dependent loads. A core part of why this mitigation strategy works is that it establishes a; data-flow check on the loaded address. However, this means that if the address; itself was already loaded using a checked load, there is no need to check a; dependent load provided it is within the same basic block as the checked load,; and therefore has no additional predicates guarding it. Consider code like the; following:; ```; ... .LBB0_4: # %danger; movq (%rcx), %rdi; movl (%rdi), %edx; ```. This will get transformed into:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rcx # Mask the pointer if misspeculating.; movq (%rcx), %rdi # Hardened load.; movl (%rdi), %edx # Unhardened load due to dependent addr.; ```. This doesn't check the load through `%rdi` as that pointer is dependent on a; checked load already. ###### Protect large, load-heavy blocks with a single lfence. It may be worth using a single `lfence` instruction at the start of a block; which begins with a (very) large number of loads that require independent; protection *and* which require hardening the address of the load. However, this; is unlikely to be profitable in practice. The latency hit of the hardening; would need to exc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:35516,Performance,load,load,35516,"s from checking loads in; this way, so it is important to work to optimize this. However, beyond making; the instruction sequences to *apply* the checks efficient (for example by; avoiding `pushfq` and `popfq` sequences), the only significant optimization is; to check fewer loads without introducing a vulnerability. We apply several; techniques to accomplish that. ###### Don't check loads from compile-time constant stack offsets. We implement this optimization on x86 by skipping the checking of loads which; use a fixed frame pointer offset. The result of this optimization is that patterns like reloading a spilled; register or accessing a global field don't get checked. This is a very; significant performance win. ###### Don't check dependent loads. A core part of why this mitigation strategy works is that it establishes a; data-flow check on the loaded address. However, this means that if the address; itself was already loaded using a checked load, there is no need to check a; dependent load provided it is within the same basic block as the checked load,; and therefore has no additional predicates guarding it. Consider code like the; following:; ```; ... .LBB0_4: # %danger; movq (%rcx), %rdi; movl (%rdi), %edx; ```. This will get transformed into:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rcx # Mask the pointer if misspeculating.; movq (%rcx), %rdi # Hardened load.; movl (%rdi), %edx # Unhardened load due to dependent addr.; ```. This doesn't check the load through `%rdi` as that pointer is dependent on a; checked load already. ###### Protect large, load-heavy blocks with a single lfence. It may be worth using a single `lfence` instruction at the start of a block; which begins with a (very) large number of loads that require independent; protection *and* which require hardening the address of the load. However, this; is unlikely to be profitable in practice. The latency hit of the hardening; would need to exc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:35561,Performance,load,load,35561,"s from checking loads in; this way, so it is important to work to optimize this. However, beyond making; the instruction sequences to *apply* the checks efficient (for example by; avoiding `pushfq` and `popfq` sequences), the only significant optimization is; to check fewer loads without introducing a vulnerability. We apply several; techniques to accomplish that. ###### Don't check loads from compile-time constant stack offsets. We implement this optimization on x86 by skipping the checking of loads which; use a fixed frame pointer offset. The result of this optimization is that patterns like reloading a spilled; register or accessing a global field don't get checked. This is a very; significant performance win. ###### Don't check dependent loads. A core part of why this mitigation strategy works is that it establishes a; data-flow check on the loaded address. However, this means that if the address; itself was already loaded using a checked load, there is no need to check a; dependent load provided it is within the same basic block as the checked load,; and therefore has no additional predicates guarding it. Consider code like the; following:; ```; ... .LBB0_4: # %danger; movq (%rcx), %rdi; movl (%rdi), %edx; ```. This will get transformed into:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rcx # Mask the pointer if misspeculating.; movq (%rcx), %rdi # Hardened load.; movl (%rdi), %edx # Unhardened load due to dependent addr.; ```. This doesn't check the load through `%rdi` as that pointer is dependent on a; checked load already. ###### Protect large, load-heavy blocks with a single lfence. It may be worth using a single `lfence` instruction at the start of a block; which begins with a (very) large number of loads that require independent; protection *and* which require hardening the address of the load. However, this; is unlikely to be profitable in practice. The latency hit of the hardening; would need to exc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:35624,Performance,load,load,35624,"s from checking loads in; this way, so it is important to work to optimize this. However, beyond making; the instruction sequences to *apply* the checks efficient (for example by; avoiding `pushfq` and `popfq` sequences), the only significant optimization is; to check fewer loads without introducing a vulnerability. We apply several; techniques to accomplish that. ###### Don't check loads from compile-time constant stack offsets. We implement this optimization on x86 by skipping the checking of loads which; use a fixed frame pointer offset. The result of this optimization is that patterns like reloading a spilled; register or accessing a global field don't get checked. This is a very; significant performance win. ###### Don't check dependent loads. A core part of why this mitigation strategy works is that it establishes a; data-flow check on the loaded address. However, this means that if the address; itself was already loaded using a checked load, there is no need to check a; dependent load provided it is within the same basic block as the checked load,; and therefore has no additional predicates guarding it. Consider code like the; following:; ```; ... .LBB0_4: # %danger; movq (%rcx), %rdi; movl (%rdi), %edx; ```. This will get transformed into:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rcx # Mask the pointer if misspeculating.; movq (%rcx), %rdi # Hardened load.; movl (%rdi), %edx # Unhardened load due to dependent addr.; ```. This doesn't check the load through `%rdi` as that pointer is dependent on a; checked load already. ###### Protect large, load-heavy blocks with a single lfence. It may be worth using a single `lfence` instruction at the start of a block; which begins with a (very) large number of loads that require independent; protection *and* which require hardening the address of the load. However, this; is unlikely to be profitable in practice. The latency hit of the hardening; would need to exc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:35999,Performance,load,load,35999,"fsets. We implement this optimization on x86 by skipping the checking of loads which; use a fixed frame pointer offset. The result of this optimization is that patterns like reloading a spilled; register or accessing a global field don't get checked. This is a very; significant performance win. ###### Don't check dependent loads. A core part of why this mitigation strategy works is that it establishes a; data-flow check on the loaded address. However, this means that if the address; itself was already loaded using a checked load, there is no need to check a; dependent load provided it is within the same basic block as the checked load,; and therefore has no additional predicates guarding it. Consider code like the; following:; ```; ... .LBB0_4: # %danger; movq (%rcx), %rdi; movl (%rdi), %edx; ```. This will get transformed into:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rcx # Mask the pointer if misspeculating.; movq (%rcx), %rdi # Hardened load.; movl (%rdi), %edx # Unhardened load due to dependent addr.; ```. This doesn't check the load through `%rdi` as that pointer is dependent on a; checked load already. ###### Protect large, load-heavy blocks with a single lfence. It may be worth using a single `lfence` instruction at the start of a block; which begins with a (very) large number of loads that require independent; protection *and* which require hardening the address of the load. However, this; is unlikely to be profitable in practice. The latency hit of the hardening; would need to exceed that of an `lfence` when *correctly* speculatively; executed. But in that case, the `lfence` cost is a complete loss of speculative; execution (at a minimum). So far, the evidence we have of the performance cost; of using `lfence` indicates few if any hot code patterns where this trade off; would make sense. ###### Tempting optimizations that break the security model. Several optimizations were considered which didn't p",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:36037,Performance,load,load,36037,"skipping the checking of loads which; use a fixed frame pointer offset. The result of this optimization is that patterns like reloading a spilled; register or accessing a global field don't get checked. This is a very; significant performance win. ###### Don't check dependent loads. A core part of why this mitigation strategy works is that it establishes a; data-flow check on the loaded address. However, this means that if the address; itself was already loaded using a checked load, there is no need to check a; dependent load provided it is within the same basic block as the checked load,; and therefore has no additional predicates guarding it. Consider code like the; following:; ```; ... .LBB0_4: # %danger; movq (%rcx), %rdi; movl (%rdi), %edx; ```. This will get transformed into:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rcx # Mask the pointer if misspeculating.; movq (%rcx), %rdi # Hardened load.; movl (%rdi), %edx # Unhardened load due to dependent addr.; ```. This doesn't check the load through `%rdi` as that pointer is dependent on a; checked load already. ###### Protect large, load-heavy blocks with a single lfence. It may be worth using a single `lfence` instruction at the start of a block; which begins with a (very) large number of loads that require independent; protection *and* which require hardening the address of the load. However, this; is unlikely to be profitable in practice. The latency hit of the hardening; would need to exceed that of an `lfence` when *correctly* speculatively; executed. But in that case, the `lfence` cost is a complete loss of speculative; execution (at a minimum). So far, the evidence we have of the performance cost; of using `lfence` indicates few if any hot code patterns where this trade off; would make sense. ###### Tempting optimizations that break the security model. Several optimizations were considered which didn't pan out due to failure to; uphold the security mo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:36094,Performance,load,load,36094,"this optimization is that patterns like reloading a spilled; register or accessing a global field don't get checked. This is a very; significant performance win. ###### Don't check dependent loads. A core part of why this mitigation strategy works is that it establishes a; data-flow check on the loaded address. However, this means that if the address; itself was already loaded using a checked load, there is no need to check a; dependent load provided it is within the same basic block as the checked load,; and therefore has no additional predicates guarding it. Consider code like the; following:; ```; ... .LBB0_4: # %danger; movq (%rcx), %rdi; movl (%rdi), %edx; ```. This will get transformed into:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rcx # Mask the pointer if misspeculating.; movq (%rcx), %rdi # Hardened load.; movl (%rdi), %edx # Unhardened load due to dependent addr.; ```. This doesn't check the load through `%rdi` as that pointer is dependent on a; checked load already. ###### Protect large, load-heavy blocks with a single lfence. It may be worth using a single `lfence` instruction at the start of a block; which begins with a (very) large number of loads that require independent; protection *and* which require hardening the address of the load. However, this; is unlikely to be profitable in practice. The latency hit of the hardening; would need to exceed that of an `lfence` when *correctly* speculatively; executed. But in that case, the `lfence` cost is a complete loss of speculative; execution (at a minimum). So far, the evidence we have of the performance cost; of using `lfence` indicates few if any hot code patterns where this trade off; would make sense. ###### Tempting optimizations that break the security model. Several optimizations were considered which didn't pan out due to failure to; uphold the security model. One in particular is worth discussing as many others; will reduce to it. We wonde",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:36157,Performance,load,load,36157,"this optimization is that patterns like reloading a spilled; register or accessing a global field don't get checked. This is a very; significant performance win. ###### Don't check dependent loads. A core part of why this mitigation strategy works is that it establishes a; data-flow check on the loaded address. However, this means that if the address; itself was already loaded using a checked load, there is no need to check a; dependent load provided it is within the same basic block as the checked load,; and therefore has no additional predicates guarding it. Consider code like the; following:; ```; ... .LBB0_4: # %danger; movq (%rcx), %rdi; movl (%rdi), %edx; ```. This will get transformed into:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rcx # Mask the pointer if misspeculating.; movq (%rcx), %rdi # Hardened load.; movl (%rdi), %edx # Unhardened load due to dependent addr.; ```. This doesn't check the load through `%rdi` as that pointer is dependent on a; checked load already. ###### Protect large, load-heavy blocks with a single lfence. It may be worth using a single `lfence` instruction at the start of a block; which begins with a (very) large number of loads that require independent; protection *and* which require hardening the address of the load. However, this; is unlikely to be profitable in practice. The latency hit of the hardening; would need to exceed that of an `lfence` when *correctly* speculatively; executed. But in that case, the `lfence` cost is a complete loss of speculative; execution (at a minimum). So far, the evidence we have of the performance cost; of using `lfence` indicates few if any hot code patterns where this trade off; would make sense. ###### Tempting optimizations that break the security model. Several optimizations were considered which didn't pan out due to failure to; uphold the security model. One in particular is worth discussing as many others; will reduce to it. We wonde",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:36193,Performance,load,load-heavy,36193,"g a global field don't get checked. This is a very; significant performance win. ###### Don't check dependent loads. A core part of why this mitigation strategy works is that it establishes a; data-flow check on the loaded address. However, this means that if the address; itself was already loaded using a checked load, there is no need to check a; dependent load provided it is within the same basic block as the checked load,; and therefore has no additional predicates guarding it. Consider code like the; following:; ```; ... .LBB0_4: # %danger; movq (%rcx), %rdi; movl (%rdi), %edx; ```. This will get transformed into:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rcx # Mask the pointer if misspeculating.; movq (%rcx), %rdi # Hardened load.; movl (%rdi), %edx # Unhardened load due to dependent addr.; ```. This doesn't check the load through `%rdi` as that pointer is dependent on a; checked load already. ###### Protect large, load-heavy blocks with a single lfence. It may be worth using a single `lfence` instruction at the start of a block; which begins with a (very) large number of loads that require independent; protection *and* which require hardening the address of the load. However, this; is unlikely to be profitable in practice. The latency hit of the hardening; would need to exceed that of an `lfence` when *correctly* speculatively; executed. But in that case, the `lfence` cost is a complete loss of speculative; execution (at a minimum). So far, the evidence we have of the performance cost; of using `lfence` indicates few if any hot code patterns where this trade off; would make sense. ###### Tempting optimizations that break the security model. Several optimizations were considered which didn't pan out due to failure to; uphold the security model. One in particular is worth discussing as many others; will reduce to it. We wondered whether only the *first* load in a basic block could be checked. If; the chec",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:36353,Performance,load,loads,36353," mitigation strategy works is that it establishes a; data-flow check on the loaded address. However, this means that if the address; itself was already loaded using a checked load, there is no need to check a; dependent load provided it is within the same basic block as the checked load,; and therefore has no additional predicates guarding it. Consider code like the; following:; ```; ... .LBB0_4: # %danger; movq (%rcx), %rdi; movl (%rdi), %edx; ```. This will get transformed into:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rcx # Mask the pointer if misspeculating.; movq (%rcx), %rdi # Hardened load.; movl (%rdi), %edx # Unhardened load due to dependent addr.; ```. This doesn't check the load through `%rdi` as that pointer is dependent on a; checked load already. ###### Protect large, load-heavy blocks with a single lfence. It may be worth using a single `lfence` instruction at the start of a block; which begins with a (very) large number of loads that require independent; protection *and* which require hardening the address of the load. However, this; is unlikely to be profitable in practice. The latency hit of the hardening; would need to exceed that of an `lfence` when *correctly* speculatively; executed. But in that case, the `lfence` cost is a complete loss of speculative; execution (at a minimum). So far, the evidence we have of the performance cost; of using `lfence` indicates few if any hot code patterns where this trade off; would make sense. ###### Tempting optimizations that break the security model. Several optimizations were considered which didn't pan out due to failure to; uphold the security model. One in particular is worth discussing as many others; will reduce to it. We wondered whether only the *first* load in a basic block could be checked. If; the check works as intended, it forms an invalid pointer that doesn't even; virtual-address translate in the hardware. It should fault very early on",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:36445,Performance,load,load,36445," mitigation strategy works is that it establishes a; data-flow check on the loaded address. However, this means that if the address; itself was already loaded using a checked load, there is no need to check a; dependent load provided it is within the same basic block as the checked load,; and therefore has no additional predicates guarding it. Consider code like the; following:; ```; ... .LBB0_4: # %danger; movq (%rcx), %rdi; movl (%rdi), %edx; ```. This will get transformed into:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rcx # Mask the pointer if misspeculating.; movq (%rcx), %rdi # Hardened load.; movl (%rdi), %edx # Unhardened load due to dependent addr.; ```. This doesn't check the load through `%rdi` as that pointer is dependent on a; checked load already. ###### Protect large, load-heavy blocks with a single lfence. It may be worth using a single `lfence` instruction at the start of a block; which begins with a (very) large number of loads that require independent; protection *and* which require hardening the address of the load. However, this; is unlikely to be profitable in practice. The latency hit of the hardening; would need to exceed that of an `lfence` when *correctly* speculatively; executed. But in that case, the `lfence` cost is a complete loss of speculative; execution (at a minimum). So far, the evidence we have of the performance cost; of using `lfence` indicates few if any hot code patterns where this trade off; would make sense. ###### Tempting optimizations that break the security model. Several optimizations were considered which didn't pan out due to failure to; uphold the security model. One in particular is worth discussing as many others; will reduce to it. We wondered whether only the *first* load in a basic block could be checked. If; the check works as intended, it forms an invalid pointer that doesn't even; virtual-address translate in the hardware. It should fault very early on",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:36512,Performance,latency,latency,36512," provided it is within the same basic block as the checked load,; and therefore has no additional predicates guarding it. Consider code like the; following:; ```; ... .LBB0_4: # %danger; movq (%rcx), %rdi; movl (%rdi), %edx; ```. This will get transformed into:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rcx # Mask the pointer if misspeculating.; movq (%rcx), %rdi # Hardened load.; movl (%rdi), %edx # Unhardened load due to dependent addr.; ```. This doesn't check the load through `%rdi` as that pointer is dependent on a; checked load already. ###### Protect large, load-heavy blocks with a single lfence. It may be worth using a single `lfence` instruction at the start of a block; which begins with a (very) large number of loads that require independent; protection *and* which require hardening the address of the load. However, this; is unlikely to be profitable in practice. The latency hit of the hardening; would need to exceed that of an `lfence` when *correctly* speculatively; executed. But in that case, the `lfence` cost is a complete loss of speculative; execution (at a minimum). So far, the evidence we have of the performance cost; of using `lfence` indicates few if any hot code patterns where this trade off; would make sense. ###### Tempting optimizations that break the security model. Several optimizations were considered which didn't pan out due to failure to; uphold the security model. One in particular is worth discussing as many others; will reduce to it. We wondered whether only the *first* load in a basic block could be checked. If; the check works as intended, it forms an invalid pointer that doesn't even; virtual-address translate in the hardware. It should fault very early on in its; processing. Maybe that would stop things in time for the misspeculated path to; fail to leak any secrets. This doesn't end up working because the processor is; fundamentally out-of-order, even in its speculative doma",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:36758,Performance,perform,performance,36758,"his will get transformed into:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rcx # Mask the pointer if misspeculating.; movq (%rcx), %rdi # Hardened load.; movl (%rdi), %edx # Unhardened load due to dependent addr.; ```. This doesn't check the load through `%rdi` as that pointer is dependent on a; checked load already. ###### Protect large, load-heavy blocks with a single lfence. It may be worth using a single `lfence` instruction at the start of a block; which begins with a (very) large number of loads that require independent; protection *and* which require hardening the address of the load. However, this; is unlikely to be profitable in practice. The latency hit of the hardening; would need to exceed that of an `lfence` when *correctly* speculatively; executed. But in that case, the `lfence` cost is a complete loss of speculative; execution (at a minimum). So far, the evidence we have of the performance cost; of using `lfence` indicates few if any hot code patterns where this trade off; would make sense. ###### Tempting optimizations that break the security model. Several optimizations were considered which didn't pan out due to failure to; uphold the security model. One in particular is worth discussing as many others; will reduce to it. We wondered whether only the *first* load in a basic block could be checked. If; the check works as intended, it forms an invalid pointer that doesn't even; virtual-address translate in the hardware. It should fault very early on in its; processing. Maybe that would stop things in time for the misspeculated path to; fail to leak any secrets. This doesn't end up working because the processor is; fundamentally out-of-order, even in its speculative domain. As a consequence,; the attacker could cause the initial address computation itself to stall and; allow an arbitrary number of unrelated loads (including attacked loads of; secret data) to pass through. #### Interprocedural Chec",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:36889,Performance,optimiz,optimizations,36889,"icate state.; orq %rax, %rcx # Mask the pointer if misspeculating.; movq (%rcx), %rdi # Hardened load.; movl (%rdi), %edx # Unhardened load due to dependent addr.; ```. This doesn't check the load through `%rdi` as that pointer is dependent on a; checked load already. ###### Protect large, load-heavy blocks with a single lfence. It may be worth using a single `lfence` instruction at the start of a block; which begins with a (very) large number of loads that require independent; protection *and* which require hardening the address of the load. However, this; is unlikely to be profitable in practice. The latency hit of the hardening; would need to exceed that of an `lfence` when *correctly* speculatively; executed. But in that case, the `lfence` cost is a complete loss of speculative; execution (at a minimum). So far, the evidence we have of the performance cost; of using `lfence` indicates few if any hot code patterns where this trade off; would make sense. ###### Tempting optimizations that break the security model. Several optimizations were considered which didn't pan out due to failure to; uphold the security model. One in particular is worth discussing as many others; will reduce to it. We wondered whether only the *first* load in a basic block could be checked. If; the check works as intended, it forms an invalid pointer that doesn't even; virtual-address translate in the hardware. It should fault very early on in its; processing. Maybe that would stop things in time for the misspeculated path to; fail to leak any secrets. This doesn't end up working because the processor is; fundamentally out-of-order, even in its speculative domain. As a consequence,; the attacker could cause the initial address computation itself to stall and; allow an arbitrary number of unrelated loads (including attacked loads of; secret data) to pass through. #### Interprocedural Checking. Modern x86 processors may speculate into called functions and out of functions; to their return addr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:36942,Performance,optimiz,optimizations,36942,"di # Hardened load.; movl (%rdi), %edx # Unhardened load due to dependent addr.; ```. This doesn't check the load through `%rdi` as that pointer is dependent on a; checked load already. ###### Protect large, load-heavy blocks with a single lfence. It may be worth using a single `lfence` instruction at the start of a block; which begins with a (very) large number of loads that require independent; protection *and* which require hardening the address of the load. However, this; is unlikely to be profitable in practice. The latency hit of the hardening; would need to exceed that of an `lfence` when *correctly* speculatively; executed. But in that case, the `lfence` cost is a complete loss of speculative; execution (at a minimum). So far, the evidence we have of the performance cost; of using `lfence` indicates few if any hot code patterns where this trade off; would make sense. ###### Tempting optimizations that break the security model. Several optimizations were considered which didn't pan out due to failure to; uphold the security model. One in particular is worth discussing as many others; will reduce to it. We wondered whether only the *first* load in a basic block could be checked. If; the check works as intended, it forms an invalid pointer that doesn't even; virtual-address translate in the hardware. It should fault very early on in its; processing. Maybe that would stop things in time for the misspeculated path to; fail to leak any secrets. This doesn't end up working because the processor is; fundamentally out-of-order, even in its speculative domain. As a consequence,; the attacker could cause the initial address computation itself to stall and; allow an arbitrary number of unrelated loads (including attacked loads of; secret data) to pass through. #### Interprocedural Checking. Modern x86 processors may speculate into called functions and out of functions; to their return address. As a consequence, we need a way to check loads that; occur after a misspeculat",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:37149,Performance,load,load,37149,"checked load already. ###### Protect large, load-heavy blocks with a single lfence. It may be worth using a single `lfence` instruction at the start of a block; which begins with a (very) large number of loads that require independent; protection *and* which require hardening the address of the load. However, this; is unlikely to be profitable in practice. The latency hit of the hardening; would need to exceed that of an `lfence` when *correctly* speculatively; executed. But in that case, the `lfence` cost is a complete loss of speculative; execution (at a minimum). So far, the evidence we have of the performance cost; of using `lfence` indicates few if any hot code patterns where this trade off; would make sense. ###### Tempting optimizations that break the security model. Several optimizations were considered which didn't pan out due to failure to; uphold the security model. One in particular is worth discussing as many others; will reduce to it. We wondered whether only the *first* load in a basic block could be checked. If; the check works as intended, it forms an invalid pointer that doesn't even; virtual-address translate in the hardware. It should fault very early on in its; processing. Maybe that would stop things in time for the misspeculated path to; fail to leak any secrets. This doesn't end up working because the processor is; fundamentally out-of-order, even in its speculative domain. As a consequence,; the attacker could cause the initial address computation itself to stall and; allow an arbitrary number of unrelated loads (including attacked loads of; secret data) to pass through. #### Interprocedural Checking. Modern x86 processors may speculate into called functions and out of functions; to their return address. As a consequence, we need a way to check loads that; occur after a misspeculated predicate but where the load and the misspeculated; predicate are in different functions. In essence, we need some interprocedural; generalization of the predica",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:37706,Performance,load,loads,37706,"lete loss of speculative; execution (at a minimum). So far, the evidence we have of the performance cost; of using `lfence` indicates few if any hot code patterns where this trade off; would make sense. ###### Tempting optimizations that break the security model. Several optimizations were considered which didn't pan out due to failure to; uphold the security model. One in particular is worth discussing as many others; will reduce to it. We wondered whether only the *first* load in a basic block could be checked. If; the check works as intended, it forms an invalid pointer that doesn't even; virtual-address translate in the hardware. It should fault very early on in its; processing. Maybe that would stop things in time for the misspeculated path to; fail to leak any secrets. This doesn't end up working because the processor is; fundamentally out-of-order, even in its speculative domain. As a consequence,; the attacker could cause the initial address computation itself to stall and; allow an arbitrary number of unrelated loads (including attacked loads of; secret data) to pass through. #### Interprocedural Checking. Modern x86 processors may speculate into called functions and out of functions; to their return address. As a consequence, we need a way to check loads that; occur after a misspeculated predicate but where the load and the misspeculated; predicate are in different functions. In essence, we need some interprocedural; generalization of the predicate state tracking. A primary challenge to passing; the predicate state between functions is that we would like to not require a; change to the ABI or calling convention in order to make this mitigation more; deployable, and further would like code mitigated in this way to be easily; mixed with code not mitigated in this way and without completely losing the; value of the mitigation. ##### Embed the predicate state into the high bit(s) of the stack pointer. We can use the same technique that allows hardening pointer",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:37732,Performance,load,loads,37732,"lete loss of speculative; execution (at a minimum). So far, the evidence we have of the performance cost; of using `lfence` indicates few if any hot code patterns where this trade off; would make sense. ###### Tempting optimizations that break the security model. Several optimizations were considered which didn't pan out due to failure to; uphold the security model. One in particular is worth discussing as many others; will reduce to it. We wondered whether only the *first* load in a basic block could be checked. If; the check works as intended, it forms an invalid pointer that doesn't even; virtual-address translate in the hardware. It should fault very early on in its; processing. Maybe that would stop things in time for the misspeculated path to; fail to leak any secrets. This doesn't end up working because the processor is; fundamentally out-of-order, even in its speculative domain. As a consequence,; the attacker could cause the initial address computation itself to stall and; allow an arbitrary number of unrelated loads (including attacked loads of; secret data) to pass through. #### Interprocedural Checking. Modern x86 processors may speculate into called functions and out of functions; to their return address. As a consequence, we need a way to check loads that; occur after a misspeculated predicate but where the load and the misspeculated; predicate are in different functions. In essence, we need some interprocedural; generalization of the predicate state tracking. A primary challenge to passing; the predicate state between functions is that we would like to not require a; change to the ABI or calling convention in order to make this mitigation more; deployable, and further would like code mitigated in this way to be easily; mixed with code not mitigated in this way and without completely losing the; value of the mitigation. ##### Embed the predicate state into the high bit(s) of the stack pointer. We can use the same technique that allows hardening pointer",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:37949,Performance,load,loads,37949," due to failure to; uphold the security model. One in particular is worth discussing as many others; will reduce to it. We wondered whether only the *first* load in a basic block could be checked. If; the check works as intended, it forms an invalid pointer that doesn't even; virtual-address translate in the hardware. It should fault very early on in its; processing. Maybe that would stop things in time for the misspeculated path to; fail to leak any secrets. This doesn't end up working because the processor is; fundamentally out-of-order, even in its speculative domain. As a consequence,; the attacker could cause the initial address computation itself to stall and; allow an arbitrary number of unrelated loads (including attacked loads of; secret data) to pass through. #### Interprocedural Checking. Modern x86 processors may speculate into called functions and out of functions; to their return address. As a consequence, we need a way to check loads that; occur after a misspeculated predicate but where the load and the misspeculated; predicate are in different functions. In essence, we need some interprocedural; generalization of the predicate state tracking. A primary challenge to passing; the predicate state between functions is that we would like to not require a; change to the ABI or calling convention in order to make this mitigation more; deployable, and further would like code mitigated in this way to be easily; mixed with code not mitigated in this way and without completely losing the; value of the mitigation. ##### Embed the predicate state into the high bit(s) of the stack pointer. We can use the same technique that allows hardening pointers to pass the; predicate state into and out of functions. The stack pointer is trivially; passed between functions and we can test for it having the high bits set to; detect when it has been marked due to misspeculation. The callsite instruction; sequence looks like (assuming a misspeculated state value of `-1`):; ```; ..",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:38013,Performance,load,load,38013," due to failure to; uphold the security model. One in particular is worth discussing as many others; will reduce to it. We wondered whether only the *first* load in a basic block could be checked. If; the check works as intended, it forms an invalid pointer that doesn't even; virtual-address translate in the hardware. It should fault very early on in its; processing. Maybe that would stop things in time for the misspeculated path to; fail to leak any secrets. This doesn't end up working because the processor is; fundamentally out-of-order, even in its speculative domain. As a consequence,; the attacker could cause the initial address computation itself to stall and; allow an arbitrary number of unrelated loads (including attacked loads of; secret data) to pass through. #### Interprocedural Checking. Modern x86 processors may speculate into called functions and out of functions; to their return address. As a consequence, we need a way to check loads that; occur after a misspeculated predicate but where the load and the misspeculated; predicate are in different functions. In essence, we need some interprocedural; generalization of the predicate state tracking. A primary challenge to passing; the predicate state between functions is that we would like to not require a; change to the ABI or calling convention in order to make this mitigation more; deployable, and further would like code mitigated in this way to be easily; mixed with code not mitigated in this way and without completely losing the; value of the mitigation. ##### Embed the predicate state into the high bit(s) of the stack pointer. We can use the same technique that allows hardening pointers to pass the; predicate state into and out of functions. The stack pointer is trivially; passed between functions and we can test for it having the high bits set to; detect when it has been marked due to misspeculation. The callsite instruction; sequence looks like (assuming a misspeculated state value of `-1`):; ```; ..",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:41333,Performance,load,loads,41333,"ed code from misspeculation in; an unmitigated caller. There is also an advantage to using this form of interprocedural mitigation: by; forming these invalid stack pointer addresses we can prevent speculative; returns from successfully reading speculatively written values to the actual; stack. This works first by forming a data-dependency between computing the; address of the return address on the stack and our predicate state. And even; when satisfied, if a misprediction causes the state to be poisoned the; resulting stack pointer will be invalid. ##### Rewrite API of internal functions to directly propagate predicate state. (Not yet implemented.). We have the option with internal functions to directly adjust their API to; accept the predicate as an argument and return it. This is likely to be; marginally cheaper than embedding into `%rsp` for entering functions. ##### Use `lfence` to guard function transitions. An `lfence` instruction can be used to prevent subsequent loads from; speculatively executing until all prior mispredicted predicates have resolved.; We can use this broader barrier to speculative loads executing between; functions. We emit it in the entry block to handle calls, and prior to each; return. This approach also has the advantage of providing the strongest degree; of mitigation when mixed with unmitigated code by halting all misspeculation; entering a function which is mitigated, regardless of what occurred in the; caller. However, such a mixture is inherently more risky. Whether this kind of; mixture is a sufficient mitigation requires careful analysis. Unfortunately, experimental results indicate that the performance overhead of; this approach is very high for certain patterns of code. A classic example is; any form of recursive evaluation engine. The hot, rapid call and return; sequences exhibit dramatic performance loss when mitigated with `lfence`. This; component alone can regress performance by 2x or more, making it an unpleasant; tradeoff",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:41472,Performance,load,loads,41472,"al mitigation: by; forming these invalid stack pointer addresses we can prevent speculative; returns from successfully reading speculatively written values to the actual; stack. This works first by forming a data-dependency between computing the; address of the return address on the stack and our predicate state. And even; when satisfied, if a misprediction causes the state to be poisoned the; resulting stack pointer will be invalid. ##### Rewrite API of internal functions to directly propagate predicate state. (Not yet implemented.). We have the option with internal functions to directly adjust their API to; accept the predicate as an argument and return it. This is likely to be; marginally cheaper than embedding into `%rsp` for entering functions. ##### Use `lfence` to guard function transitions. An `lfence` instruction can be used to prevent subsequent loads from; speculatively executing until all prior mispredicted predicates have resolved.; We can use this broader barrier to speculative loads executing between; functions. We emit it in the entry block to handle calls, and prior to each; return. This approach also has the advantage of providing the strongest degree; of mitigation when mixed with unmitigated code by halting all misspeculation; entering a function which is mitigated, regardless of what occurred in the; caller. However, such a mixture is inherently more risky. Whether this kind of; mixture is a sufficient mitigation requires careful analysis. Unfortunately, experimental results indicate that the performance overhead of; this approach is very high for certain patterns of code. A classic example is; any form of recursive evaluation engine. The hot, rapid call and return; sequences exhibit dramatic performance loss when mitigated with `lfence`. This; component alone can regress performance by 2x or more, making it an unpleasant; tradeoff even when only used in a mixture of code. ##### Use an internal TLS location to pass predicate state. We can define",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:42004,Performance,perform,performance,42004," option with internal functions to directly adjust their API to; accept the predicate as an argument and return it. This is likely to be; marginally cheaper than embedding into `%rsp` for entering functions. ##### Use `lfence` to guard function transitions. An `lfence` instruction can be used to prevent subsequent loads from; speculatively executing until all prior mispredicted predicates have resolved.; We can use this broader barrier to speculative loads executing between; functions. We emit it in the entry block to handle calls, and prior to each; return. This approach also has the advantage of providing the strongest degree; of mitigation when mixed with unmitigated code by halting all misspeculation; entering a function which is mitigated, regardless of what occurred in the; caller. However, such a mixture is inherently more risky. Whether this kind of; mixture is a sufficient mitigation requires careful analysis. Unfortunately, experimental results indicate that the performance overhead of; this approach is very high for certain patterns of code. A classic example is; any form of recursive evaluation engine. The hot, rapid call and return; sequences exhibit dramatic performance loss when mitigated with `lfence`. This; component alone can regress performance by 2x or more, making it an unpleasant; tradeoff even when only used in a mixture of code. ##### Use an internal TLS location to pass predicate state. We can define a special thread-local value to hold the predicate state between; functions. This avoids direct ABI implications by using a side channel between; callers and callees to communicate the predicate state. It also allows implicit; zero-initialization of the state, which allows non-checked code to be the first; code executed. However, this requires a load from TLS in the entry block, a store to TLS; before every call and every ret, and a load from TLS after every call. As a; consequence it is expected to be substantially more expensive even than usin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:42208,Performance,perform,performance,42208,"for entering functions. ##### Use `lfence` to guard function transitions. An `lfence` instruction can be used to prevent subsequent loads from; speculatively executing until all prior mispredicted predicates have resolved.; We can use this broader barrier to speculative loads executing between; functions. We emit it in the entry block to handle calls, and prior to each; return. This approach also has the advantage of providing the strongest degree; of mitigation when mixed with unmitigated code by halting all misspeculation; entering a function which is mitigated, regardless of what occurred in the; caller. However, such a mixture is inherently more risky. Whether this kind of; mixture is a sufficient mitigation requires careful analysis. Unfortunately, experimental results indicate that the performance overhead of; this approach is very high for certain patterns of code. A classic example is; any form of recursive evaluation engine. The hot, rapid call and return; sequences exhibit dramatic performance loss when mitigated with `lfence`. This; component alone can regress performance by 2x or more, making it an unpleasant; tradeoff even when only used in a mixture of code. ##### Use an internal TLS location to pass predicate state. We can define a special thread-local value to hold the predicate state between; functions. This avoids direct ABI implications by using a side channel between; callers and callees to communicate the predicate state. It also allows implicit; zero-initialization of the state, which allows non-checked code to be the first; code executed. However, this requires a load from TLS in the entry block, a store to TLS; before every call and every ret, and a load from TLS after every call. As a; consequence it is expected to be substantially more expensive even than using; `%rsp` and potentially `lfence` within the function entry block. ##### Define a new ABI and/or calling convention. We could define a new ABI and/or calling convention to explicitly ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:42289,Performance,perform,performance,42289,"subsequent loads from; speculatively executing until all prior mispredicted predicates have resolved.; We can use this broader barrier to speculative loads executing between; functions. We emit it in the entry block to handle calls, and prior to each; return. This approach also has the advantage of providing the strongest degree; of mitigation when mixed with unmitigated code by halting all misspeculation; entering a function which is mitigated, regardless of what occurred in the; caller. However, such a mixture is inherently more risky. Whether this kind of; mixture is a sufficient mitigation requires careful analysis. Unfortunately, experimental results indicate that the performance overhead of; this approach is very high for certain patterns of code. A classic example is; any form of recursive evaluation engine. The hot, rapid call and return; sequences exhibit dramatic performance loss when mitigated with `lfence`. This; component alone can regress performance by 2x or more, making it an unpleasant; tradeoff even when only used in a mixture of code. ##### Use an internal TLS location to pass predicate state. We can define a special thread-local value to hold the predicate state between; functions. This avoids direct ABI implications by using a side channel between; callers and callees to communicate the predicate state. It also allows implicit; zero-initialization of the state, which allows non-checked code to be the first; code executed. However, this requires a load from TLS in the entry block, a store to TLS; before every call and every ret, and a load from TLS after every call. As a; consequence it is expected to be substantially more expensive even than using; `%rsp` and potentially `lfence` within the function entry block. ##### Define a new ABI and/or calling convention. We could define a new ABI and/or calling convention to explicitly pass the; predicate state in and out of functions. This may be interesting if none of the; alternatives have adequate perf",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:42814,Performance,load,load,42814,"sky. Whether this kind of; mixture is a sufficient mitigation requires careful analysis. Unfortunately, experimental results indicate that the performance overhead of; this approach is very high for certain patterns of code. A classic example is; any form of recursive evaluation engine. The hot, rapid call and return; sequences exhibit dramatic performance loss when mitigated with `lfence`. This; component alone can regress performance by 2x or more, making it an unpleasant; tradeoff even when only used in a mixture of code. ##### Use an internal TLS location to pass predicate state. We can define a special thread-local value to hold the predicate state between; functions. This avoids direct ABI implications by using a side channel between; callers and callees to communicate the predicate state. It also allows implicit; zero-initialization of the state, which allows non-checked code to be the first; code executed. However, this requires a load from TLS in the entry block, a store to TLS; before every call and every ret, and a load from TLS after every call. As a; consequence it is expected to be substantially more expensive even than using; `%rsp` and potentially `lfence` within the function entry block. ##### Define a new ABI and/or calling convention. We could define a new ABI and/or calling convention to explicitly pass the; predicate state in and out of functions. This may be interesting if none of the; alternatives have adequate performance, but it makes deployment and adoption; dramatically more complex, and potentially infeasible. ## High-Level Alternative Mitigation Strategies. There are completely different alternative approaches to mitigating variant 1; attacks. [Most](https://lwn.net/Articles/743265/); [discussion](https://lwn.net/Articles/744287/) so far focuses on mitigating; specific known attackable components in the Linux kernel (or other kernels) by; manually rewriting the code to contain an instruction sequence that is not; vulnerable. For x86 syst",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:42903,Performance,load,load,42903,"sky. Whether this kind of; mixture is a sufficient mitigation requires careful analysis. Unfortunately, experimental results indicate that the performance overhead of; this approach is very high for certain patterns of code. A classic example is; any form of recursive evaluation engine. The hot, rapid call and return; sequences exhibit dramatic performance loss when mitigated with `lfence`. This; component alone can regress performance by 2x or more, making it an unpleasant; tradeoff even when only used in a mixture of code. ##### Use an internal TLS location to pass predicate state. We can define a special thread-local value to hold the predicate state between; functions. This avoids direct ABI implications by using a side channel between; callers and callees to communicate the predicate state. It also allows implicit; zero-initialization of the state, which allows non-checked code to be the first; code executed. However, this requires a load from TLS in the entry block, a store to TLS; before every call and every ret, and a load from TLS after every call. As a; consequence it is expected to be substantially more expensive even than using; `%rsp` and potentially `lfence` within the function entry block. ##### Define a new ABI and/or calling convention. We could define a new ABI and/or calling convention to explicitly pass the; predicate state in and out of functions. This may be interesting if none of the; alternatives have adequate performance, but it makes deployment and adoption; dramatically more complex, and potentially infeasible. ## High-Level Alternative Mitigation Strategies. There are completely different alternative approaches to mitigating variant 1; attacks. [Most](https://lwn.net/Articles/743265/); [discussion](https://lwn.net/Articles/744287/) so far focuses on mitigating; specific known attackable components in the Linux kernel (or other kernels) by; manually rewriting the code to contain an instruction sequence that is not; vulnerable. For x86 syst",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:43319,Performance,perform,performance,43319,"nt; tradeoff even when only used in a mixture of code. ##### Use an internal TLS location to pass predicate state. We can define a special thread-local value to hold the predicate state between; functions. This avoids direct ABI implications by using a side channel between; callers and callees to communicate the predicate state. It also allows implicit; zero-initialization of the state, which allows non-checked code to be the first; code executed. However, this requires a load from TLS in the entry block, a store to TLS; before every call and every ret, and a load from TLS after every call. As a; consequence it is expected to be substantially more expensive even than using; `%rsp` and potentially `lfence` within the function entry block. ##### Define a new ABI and/or calling convention. We could define a new ABI and/or calling convention to explicitly pass the; predicate state in and out of functions. This may be interesting if none of the; alternatives have adequate performance, but it makes deployment and adoption; dramatically more complex, and potentially infeasible. ## High-Level Alternative Mitigation Strategies. There are completely different alternative approaches to mitigating variant 1; attacks. [Most](https://lwn.net/Articles/743265/); [discussion](https://lwn.net/Articles/744287/) so far focuses on mitigating; specific known attackable components in the Linux kernel (or other kernels) by; manually rewriting the code to contain an instruction sequence that is not; vulnerable. For x86 systems this is done by either injecting an `lfence`; instruction along the code path which would leak data if executed speculatively; or by rewriting memory accesses to have branch-less masking to a known safe; region. On Intel systems, `lfence` [will prevent the speculative load of secret; data](https://newsroom.intel.com/wp-content/uploads/sites/11/2018/01/Intel-Analysis-of-Speculative-Execution-Side-Channels.pdf).; On AMD systems `lfence` is currently a no-op, but can be m",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:44134,Performance,load,load,44134,"onvention. We could define a new ABI and/or calling convention to explicitly pass the; predicate state in and out of functions. This may be interesting if none of the; alternatives have adequate performance, but it makes deployment and adoption; dramatically more complex, and potentially infeasible. ## High-Level Alternative Mitigation Strategies. There are completely different alternative approaches to mitigating variant 1; attacks. [Most](https://lwn.net/Articles/743265/); [discussion](https://lwn.net/Articles/744287/) so far focuses on mitigating; specific known attackable components in the Linux kernel (or other kernels) by; manually rewriting the code to contain an instruction sequence that is not; vulnerable. For x86 systems this is done by either injecting an `lfence`; instruction along the code path which would leak data if executed speculatively; or by rewriting memory accesses to have branch-less masking to a known safe; region. On Intel systems, `lfence` [will prevent the speculative load of secret; data](https://newsroom.intel.com/wp-content/uploads/sites/11/2018/01/Intel-Analysis-of-Speculative-Execution-Side-Channels.pdf).; On AMD systems `lfence` is currently a no-op, but can be made; dispatch-serializing by setting an MSR, and thus preclude misspeculation of the; code path ([mitigation G-2 +; V1-1](https://developer.amd.com/wp-content/resources/Managing-Speculation-on-AMD-Processors.pdf)). However, this relies on finding and enumerating all possible points in code; which could be attacked to leak information. While in some cases static; analysis is effective at doing this at scale, in many cases it still relies on; human judgement to evaluate whether code might be vulnerable. Especially for; software systems which receive less detailed scrutiny but remain sensitive to; these attacks, this seems like an impractical security model. We need an; automatic and systematic mitigation strategy. ### Automatic `lfence` on Conditional Edges. A natural way to sca",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:45384,Performance,perform,performance,45384,"tion of the; code path ([mitigation G-2 +; V1-1](https://developer.amd.com/wp-content/resources/Managing-Speculation-on-AMD-Processors.pdf)). However, this relies on finding and enumerating all possible points in code; which could be attacked to leak information. While in some cases static; analysis is effective at doing this at scale, in many cases it still relies on; human judgement to evaluate whether code might be vulnerable. Especially for; software systems which receive less detailed scrutiny but remain sensitive to; these attacks, this seems like an impractical security model. We need an; automatic and systematic mitigation strategy. ### Automatic `lfence` on Conditional Edges. A natural way to scale up the existing hand-coded mitigations is simply to; inject an `lfence` instruction into both the target and fallthrough; destinations of every conditional branch. This ensures that no predicate or; bounds check can be bypassed speculatively. However, the performance overhead; of this approach is, simply put, catastrophic. Yet it remains the only truly; ""secure by default"" approach known prior to this effort and serves as the; baseline for performance. One attempt to address the performance overhead of this and make it more; realistic to deploy is [MSVC's /Qspectre; switch](https://blogs.msdn.microsoft.com/vcblog/2018/01/15/spectre-mitigations-in-msvc/).; Their technique is to use static analysis within the compiler to only insert; `lfence` instructions into conditional edges at risk of attack. However,; [initial](https://arstechnica.com/gadgets/2018/02/microsofts-compiler-level-spectre-fix-shows-how-hard-this-problem-will-be-to-solve/); [analysis](https://www.paulkocher.com/doc/MicrosoftCompilerSpectreMitigation.html); has shown that this approach is incomplete and only catches a small and limited; subset of attackable patterns which happen to resemble very closely the initial; proofs of concept. As such, while its performance is acceptable, it does not; appear ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:45572,Performance,perform,performance,45572,"eculation-on-AMD-Processors.pdf)). However, this relies on finding and enumerating all possible points in code; which could be attacked to leak information. While in some cases static; analysis is effective at doing this at scale, in many cases it still relies on; human judgement to evaluate whether code might be vulnerable. Especially for; software systems which receive less detailed scrutiny but remain sensitive to; these attacks, this seems like an impractical security model. We need an; automatic and systematic mitigation strategy. ### Automatic `lfence` on Conditional Edges. A natural way to scale up the existing hand-coded mitigations is simply to; inject an `lfence` instruction into both the target and fallthrough; destinations of every conditional branch. This ensures that no predicate or; bounds check can be bypassed speculatively. However, the performance overhead; of this approach is, simply put, catastrophic. Yet it remains the only truly; ""secure by default"" approach known prior to this effort and serves as the; baseline for performance. One attempt to address the performance overhead of this and make it more; realistic to deploy is [MSVC's /Qspectre; switch](https://blogs.msdn.microsoft.com/vcblog/2018/01/15/spectre-mitigations-in-msvc/).; Their technique is to use static analysis within the compiler to only insert; `lfence` instructions into conditional edges at risk of attack. However,; [initial](https://arstechnica.com/gadgets/2018/02/microsofts-compiler-level-spectre-fix-shows-how-hard-this-problem-will-be-to-solve/); [analysis](https://www.paulkocher.com/doc/MicrosoftCompilerSpectreMitigation.html); has shown that this approach is incomplete and only catches a small and limited; subset of attackable patterns which happen to resemble very closely the initial; proofs of concept. As such, while its performance is acceptable, it does not; appear to be an adequate systematic mitigation. ## Performance Overhead. The performance overhead of this style of",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:45612,Performance,perform,performance,45612," to leak information. While in some cases static; analysis is effective at doing this at scale, in many cases it still relies on; human judgement to evaluate whether code might be vulnerable. Especially for; software systems which receive less detailed scrutiny but remain sensitive to; these attacks, this seems like an impractical security model. We need an; automatic and systematic mitigation strategy. ### Automatic `lfence` on Conditional Edges. A natural way to scale up the existing hand-coded mitigations is simply to; inject an `lfence` instruction into both the target and fallthrough; destinations of every conditional branch. This ensures that no predicate or; bounds check can be bypassed speculatively. However, the performance overhead; of this approach is, simply put, catastrophic. Yet it remains the only truly; ""secure by default"" approach known prior to this effort and serves as the; baseline for performance. One attempt to address the performance overhead of this and make it more; realistic to deploy is [MSVC's /Qspectre; switch](https://blogs.msdn.microsoft.com/vcblog/2018/01/15/spectre-mitigations-in-msvc/).; Their technique is to use static analysis within the compiler to only insert; `lfence` instructions into conditional edges at risk of attack. However,; [initial](https://arstechnica.com/gadgets/2018/02/microsofts-compiler-level-spectre-fix-shows-how-hard-this-problem-will-be-to-solve/); [analysis](https://www.paulkocher.com/doc/MicrosoftCompilerSpectreMitigation.html); has shown that this approach is incomplete and only catches a small and limited; subset of attackable patterns which happen to resemble very closely the initial; proofs of concept. As such, while its performance is acceptable, it does not; appear to be an adequate systematic mitigation. ## Performance Overhead. The performance overhead of this style of comprehensive mitigation is very; high. However, it compares very favorably with previously recommended; approaches such as the `lfence",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:46364,Performance,perform,performance,46364,"verhead; of this approach is, simply put, catastrophic. Yet it remains the only truly; ""secure by default"" approach known prior to this effort and serves as the; baseline for performance. One attempt to address the performance overhead of this and make it more; realistic to deploy is [MSVC's /Qspectre; switch](https://blogs.msdn.microsoft.com/vcblog/2018/01/15/spectre-mitigations-in-msvc/).; Their technique is to use static analysis within the compiler to only insert; `lfence` instructions into conditional edges at risk of attack. However,; [initial](https://arstechnica.com/gadgets/2018/02/microsofts-compiler-level-spectre-fix-shows-how-hard-this-problem-will-be-to-solve/); [analysis](https://www.paulkocher.com/doc/MicrosoftCompilerSpectreMitigation.html); has shown that this approach is incomplete and only catches a small and limited; subset of attackable patterns which happen to resemble very closely the initial; proofs of concept. As such, while its performance is acceptable, it does not; appear to be an adequate systematic mitigation. ## Performance Overhead. The performance overhead of this style of comprehensive mitigation is very; high. However, it compares very favorably with previously recommended; approaches such as the `lfence` instruction. Just as users can restrict the; scope of `lfence` to control its performance impact, this mitigation technique; could be restricted in scope as well. However, it is important to understand what it would cost to get a fully; mitigated baseline. Here we assume targeting a Haswell (or newer) processor and; using all of the tricks to improve performance (so leaves the low 2gb; unprotected and +/- 2gb surrounding any PC in the program). We ran both; Google's microbenchmark suite and a large highly-tuned server built using; ThinLTO and PGO. All were built with `-march=haswell` to give access to BMI2; instructions, and benchmarks were run on large Haswell servers. We collected; data both with an `lfence`-based mitigation and l",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:46481,Performance,perform,performance,46481,"n prior to this effort and serves as the; baseline for performance. One attempt to address the performance overhead of this and make it more; realistic to deploy is [MSVC's /Qspectre; switch](https://blogs.msdn.microsoft.com/vcblog/2018/01/15/spectre-mitigations-in-msvc/).; Their technique is to use static analysis within the compiler to only insert; `lfence` instructions into conditional edges at risk of attack. However,; [initial](https://arstechnica.com/gadgets/2018/02/microsofts-compiler-level-spectre-fix-shows-how-hard-this-problem-will-be-to-solve/); [analysis](https://www.paulkocher.com/doc/MicrosoftCompilerSpectreMitigation.html); has shown that this approach is incomplete and only catches a small and limited; subset of attackable patterns which happen to resemble very closely the initial; proofs of concept. As such, while its performance is acceptable, it does not; appear to be an adequate systematic mitigation. ## Performance Overhead. The performance overhead of this style of comprehensive mitigation is very; high. However, it compares very favorably with previously recommended; approaches such as the `lfence` instruction. Just as users can restrict the; scope of `lfence` to control its performance impact, this mitigation technique; could be restricted in scope as well. However, it is important to understand what it would cost to get a fully; mitigated baseline. Here we assume targeting a Haswell (or newer) processor and; using all of the tricks to improve performance (so leaves the low 2gb; unprotected and +/- 2gb surrounding any PC in the program). We ran both; Google's microbenchmark suite and a large highly-tuned server built using; ThinLTO and PGO. All were built with `-march=haswell` to give access to BMI2; instructions, and benchmarks were run on large Haswell servers. We collected; data both with an `lfence`-based mitigation and load hardening as presented; here. The summary is that mitigating with load hardening is 1.77x faster than; mitigating w",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:46734,Performance,perform,performance,46734,"cblog/2018/01/15/spectre-mitigations-in-msvc/).; Their technique is to use static analysis within the compiler to only insert; `lfence` instructions into conditional edges at risk of attack. However,; [initial](https://arstechnica.com/gadgets/2018/02/microsofts-compiler-level-spectre-fix-shows-how-hard-this-problem-will-be-to-solve/); [analysis](https://www.paulkocher.com/doc/MicrosoftCompilerSpectreMitigation.html); has shown that this approach is incomplete and only catches a small and limited; subset of attackable patterns which happen to resemble very closely the initial; proofs of concept. As such, while its performance is acceptable, it does not; appear to be an adequate systematic mitigation. ## Performance Overhead. The performance overhead of this style of comprehensive mitigation is very; high. However, it compares very favorably with previously recommended; approaches such as the `lfence` instruction. Just as users can restrict the; scope of `lfence` to control its performance impact, this mitigation technique; could be restricted in scope as well. However, it is important to understand what it would cost to get a fully; mitigated baseline. Here we assume targeting a Haswell (or newer) processor and; using all of the tricks to improve performance (so leaves the low 2gb; unprotected and +/- 2gb surrounding any PC in the program). We ran both; Google's microbenchmark suite and a large highly-tuned server built using; ThinLTO and PGO. All were built with `-march=haswell` to give access to BMI2; instructions, and benchmarks were run on large Haswell servers. We collected; data both with an `lfence`-based mitigation and load hardening as presented; here. The summary is that mitigating with load hardening is 1.77x faster than; mitigating with `lfence`, and the overhead of load hardening compared to a; normal program is likely between a 10% overhead and a 50% overhead with most; large applications seeing a 30% overhead or less. | Benchmark | `lfence` | Load Hard",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:47009,Performance,perform,performance,47009,"piler-level-spectre-fix-shows-how-hard-this-problem-will-be-to-solve/); [analysis](https://www.paulkocher.com/doc/MicrosoftCompilerSpectreMitigation.html); has shown that this approach is incomplete and only catches a small and limited; subset of attackable patterns which happen to resemble very closely the initial; proofs of concept. As such, while its performance is acceptable, it does not; appear to be an adequate systematic mitigation. ## Performance Overhead. The performance overhead of this style of comprehensive mitigation is very; high. However, it compares very favorably with previously recommended; approaches such as the `lfence` instruction. Just as users can restrict the; scope of `lfence` to control its performance impact, this mitigation technique; could be restricted in scope as well. However, it is important to understand what it would cost to get a fully; mitigated baseline. Here we assume targeting a Haswell (or newer) processor and; using all of the tricks to improve performance (so leaves the low 2gb; unprotected and +/- 2gb surrounding any PC in the program). We ran both; Google's microbenchmark suite and a large highly-tuned server built using; ThinLTO and PGO. All were built with `-march=haswell` to give access to BMI2; instructions, and benchmarks were run on large Haswell servers. We collected; data both with an `lfence`-based mitigation and load hardening as presented; here. The summary is that mitigating with load hardening is 1.77x faster than; mitigating with `lfence`, and the overhead of load hardening compared to a; normal program is likely between a 10% overhead and a 50% overhead with most; large applications seeing a 30% overhead or less. | Benchmark | `lfence` | Load Hardening | Mitigated Speedup |; | -------------------------------------- | -------: | -------------: | ----------------: |; | Google microbenchmark suite | -74.8% | -36.4% | **2.5x** |; | Large server QPS (using ThinLTO & PGO) | -62% | -29% | **1.8x** |. Below is a vi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:47167,Performance,tune,tuned,47167,".html); has shown that this approach is incomplete and only catches a small and limited; subset of attackable patterns which happen to resemble very closely the initial; proofs of concept. As such, while its performance is acceptable, it does not; appear to be an adequate systematic mitigation. ## Performance Overhead. The performance overhead of this style of comprehensive mitigation is very; high. However, it compares very favorably with previously recommended; approaches such as the `lfence` instruction. Just as users can restrict the; scope of `lfence` to control its performance impact, this mitigation technique; could be restricted in scope as well. However, it is important to understand what it would cost to get a fully; mitigated baseline. Here we assume targeting a Haswell (or newer) processor and; using all of the tricks to improve performance (so leaves the low 2gb; unprotected and +/- 2gb surrounding any PC in the program). We ran both; Google's microbenchmark suite and a large highly-tuned server built using; ThinLTO and PGO. All were built with `-march=haswell` to give access to BMI2; instructions, and benchmarks were run on large Haswell servers. We collected; data both with an `lfence`-based mitigation and load hardening as presented; here. The summary is that mitigating with load hardening is 1.77x faster than; mitigating with `lfence`, and the overhead of load hardening compared to a; normal program is likely between a 10% overhead and a 50% overhead with most; large applications seeing a 30% overhead or less. | Benchmark | `lfence` | Load Hardening | Mitigated Speedup |; | -------------------------------------- | -------: | -------------: | ----------------: |; | Google microbenchmark suite | -74.8% | -36.4% | **2.5x** |; | Large server QPS (using ThinLTO & PGO) | -62% | -29% | **1.8x** |. Below is a visualization of the microbenchmark suite results which helps show; the distribution of results that is somewhat lost in the summary. The y-axis is; a ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:47397,Performance,load,load,47397,"eptable, it does not; appear to be an adequate systematic mitigation. ## Performance Overhead. The performance overhead of this style of comprehensive mitigation is very; high. However, it compares very favorably with previously recommended; approaches such as the `lfence` instruction. Just as users can restrict the; scope of `lfence` to control its performance impact, this mitigation technique; could be restricted in scope as well. However, it is important to understand what it would cost to get a fully; mitigated baseline. Here we assume targeting a Haswell (or newer) processor and; using all of the tricks to improve performance (so leaves the low 2gb; unprotected and +/- 2gb surrounding any PC in the program). We ran both; Google's microbenchmark suite and a large highly-tuned server built using; ThinLTO and PGO. All were built with `-march=haswell` to give access to BMI2; instructions, and benchmarks were run on large Haswell servers. We collected; data both with an `lfence`-based mitigation and load hardening as presented; here. The summary is that mitigating with load hardening is 1.77x faster than; mitigating with `lfence`, and the overhead of load hardening compared to a; normal program is likely between a 10% overhead and a 50% overhead with most; large applications seeing a 30% overhead or less. | Benchmark | `lfence` | Load Hardening | Mitigated Speedup |; | -------------------------------------- | -------: | -------------: | ----------------: |; | Google microbenchmark suite | -74.8% | -36.4% | **2.5x** |; | Large server QPS (using ThinLTO & PGO) | -62% | -29% | **1.8x** |. Below is a visualization of the microbenchmark suite results which helps show; the distribution of results that is somewhat lost in the summary. The y-axis is; a log-scale speedup ratio of load hardening relative to `lfence` (up -> faster; -> better). Each box-and-whiskers represents one microbenchmark which may have; many different metrics measured. The red line marks the median, the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:47468,Performance,load,load,47468,"ormance Overhead. The performance overhead of this style of comprehensive mitigation is very; high. However, it compares very favorably with previously recommended; approaches such as the `lfence` instruction. Just as users can restrict the; scope of `lfence` to control its performance impact, this mitigation technique; could be restricted in scope as well. However, it is important to understand what it would cost to get a fully; mitigated baseline. Here we assume targeting a Haswell (or newer) processor and; using all of the tricks to improve performance (so leaves the low 2gb; unprotected and +/- 2gb surrounding any PC in the program). We ran both; Google's microbenchmark suite and a large highly-tuned server built using; ThinLTO and PGO. All were built with `-march=haswell` to give access to BMI2; instructions, and benchmarks were run on large Haswell servers. We collected; data both with an `lfence`-based mitigation and load hardening as presented; here. The summary is that mitigating with load hardening is 1.77x faster than; mitigating with `lfence`, and the overhead of load hardening compared to a; normal program is likely between a 10% overhead and a 50% overhead with most; large applications seeing a 30% overhead or less. | Benchmark | `lfence` | Load Hardening | Mitigated Speedup |; | -------------------------------------- | -------: | -------------: | ----------------: |; | Google microbenchmark suite | -74.8% | -36.4% | **2.5x** |; | Large server QPS (using ThinLTO & PGO) | -62% | -29% | **1.8x** |. Below is a visualization of the microbenchmark suite results which helps show; the distribution of results that is somewhat lost in the summary. The y-axis is; a log-scale speedup ratio of load hardening relative to `lfence` (up -> faster; -> better). Each box-and-whiskers represents one microbenchmark which may have; many different metrics measured. The red line marks the median, the box marks; the first and third quartiles, and the whiskers mark the min and m",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:47551,Performance,load,load,47551,"h previously recommended; approaches such as the `lfence` instruction. Just as users can restrict the; scope of `lfence` to control its performance impact, this mitigation technique; could be restricted in scope as well. However, it is important to understand what it would cost to get a fully; mitigated baseline. Here we assume targeting a Haswell (or newer) processor and; using all of the tricks to improve performance (so leaves the low 2gb; unprotected and +/- 2gb surrounding any PC in the program). We ran both; Google's microbenchmark suite and a large highly-tuned server built using; ThinLTO and PGO. All were built with `-march=haswell` to give access to BMI2; instructions, and benchmarks were run on large Haswell servers. We collected; data both with an `lfence`-based mitigation and load hardening as presented; here. The summary is that mitigating with load hardening is 1.77x faster than; mitigating with `lfence`, and the overhead of load hardening compared to a; normal program is likely between a 10% overhead and a 50% overhead with most; large applications seeing a 30% overhead or less. | Benchmark | `lfence` | Load Hardening | Mitigated Speedup |; | -------------------------------------- | -------: | -------------: | ----------------: |; | Google microbenchmark suite | -74.8% | -36.4% | **2.5x** |; | Large server QPS (using ThinLTO & PGO) | -62% | -29% | **1.8x** |. Below is a visualization of the microbenchmark suite results which helps show; the distribution of results that is somewhat lost in the summary. The y-axis is; a log-scale speedup ratio of load hardening relative to `lfence` (up -> faster; -> better). Each box-and-whiskers represents one microbenchmark which may have; many different metrics measured. The red line marks the median, the box marks; the first and third quartiles, and the whiskers mark the min and max. ![Microbenchmark result visualization](speculative_load_hardening_microbenchmarks.png). We don't yet have benchmark data on SPEC or th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:48184,Performance,load,load,48184," ThinLTO and PGO. All were built with `-march=haswell` to give access to BMI2; instructions, and benchmarks were run on large Haswell servers. We collected; data both with an `lfence`-based mitigation and load hardening as presented; here. The summary is that mitigating with load hardening is 1.77x faster than; mitigating with `lfence`, and the overhead of load hardening compared to a; normal program is likely between a 10% overhead and a 50% overhead with most; large applications seeing a 30% overhead or less. | Benchmark | `lfence` | Load Hardening | Mitigated Speedup |; | -------------------------------------- | -------: | -------------: | ----------------: |; | Google microbenchmark suite | -74.8% | -36.4% | **2.5x** |; | Large server QPS (using ThinLTO & PGO) | -62% | -29% | **1.8x** |. Below is a visualization of the microbenchmark suite results which helps show; the distribution of results that is somewhat lost in the summary. The y-axis is; a log-scale speedup ratio of load hardening relative to `lfence` (up -> faster; -> better). Each box-and-whiskers represents one microbenchmark which may have; many different metrics measured. The red line marks the median, the box marks; the first and third quartiles, and the whiskers mark the min and max. ![Microbenchmark result visualization](speculative_load_hardening_microbenchmarks.png). We don't yet have benchmark data on SPEC or the LLVM test suite, but we can; work on getting that. Still, the above should give a pretty clear; characterization of the performance, and specific benchmarks are unlikely to; reveal especially interesting properties. ### Future Work: Fine Grained Control and API-Integration. The performance overhead of this technique is likely to be very significant and; something users wish to control or reduce. There are interesting options here; that impact the implementation strategy used. One particularly appealing option is to allow both opt-in and opt-out of this; mitigation at reasonably fine gra",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:48720,Performance,perform,performance,48720,"| Load Hardening | Mitigated Speedup |; | -------------------------------------- | -------: | -------------: | ----------------: |; | Google microbenchmark suite | -74.8% | -36.4% | **2.5x** |; | Large server QPS (using ThinLTO & PGO) | -62% | -29% | **1.8x** |. Below is a visualization of the microbenchmark suite results which helps show; the distribution of results that is somewhat lost in the summary. The y-axis is; a log-scale speedup ratio of load hardening relative to `lfence` (up -> faster; -> better). Each box-and-whiskers represents one microbenchmark which may have; many different metrics measured. The red line marks the median, the box marks; the first and third quartiles, and the whiskers mark the min and max. ![Microbenchmark result visualization](speculative_load_hardening_microbenchmarks.png). We don't yet have benchmark data on SPEC or the LLVM test suite, but we can; work on getting that. Still, the above should give a pretty clear; characterization of the performance, and specific benchmarks are unlikely to; reveal especially interesting properties. ### Future Work: Fine Grained Control and API-Integration. The performance overhead of this technique is likely to be very significant and; something users wish to control or reduce. There are interesting options here; that impact the implementation strategy used. One particularly appealing option is to allow both opt-in and opt-out of this; mitigation at reasonably fine granularity such as on a per-function basis,; including intelligent handling of inlining decisions -- protected code can be; prevented from inlining into unprotected code, and unprotected code will become; protected when inlined into protected code. For systems where only a limited; set of code is reachable by externally controlled inputs, it may be possible to; limit the scope of mitigation through such mechanisms without compromising the; application's overall security. The performance impact may also be focused in a; few key functions",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:48879,Performance,perform,performance,48879,"rver QPS (using ThinLTO & PGO) | -62% | -29% | **1.8x** |. Below is a visualization of the microbenchmark suite results which helps show; the distribution of results that is somewhat lost in the summary. The y-axis is; a log-scale speedup ratio of load hardening relative to `lfence` (up -> faster; -> better). Each box-and-whiskers represents one microbenchmark which may have; many different metrics measured. The red line marks the median, the box marks; the first and third quartiles, and the whiskers mark the min and max. ![Microbenchmark result visualization](speculative_load_hardening_microbenchmarks.png). We don't yet have benchmark data on SPEC or the LLVM test suite, but we can; work on getting that. Still, the above should give a pretty clear; characterization of the performance, and specific benchmarks are unlikely to; reveal especially interesting properties. ### Future Work: Fine Grained Control and API-Integration. The performance overhead of this technique is likely to be very significant and; something users wish to control or reduce. There are interesting options here; that impact the implementation strategy used. One particularly appealing option is to allow both opt-in and opt-out of this; mitigation at reasonably fine granularity such as on a per-function basis,; including intelligent handling of inlining decisions -- protected code can be; prevented from inlining into unprotected code, and unprotected code will become; protected when inlined into protected code. For systems where only a limited; set of code is reachable by externally controlled inputs, it may be possible to; limit the scope of mitigation through such mechanisms without compromising the; application's overall security. The performance impact may also be focused in a; few key functions that can be hand-mitigated in ways that have lower; performance overhead while the remainder of the application receives automatic; protection. For both limiting the scope of mitigation or manually miti",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:49671,Performance,perform,performance,49671,"haracterization of the performance, and specific benchmarks are unlikely to; reveal especially interesting properties. ### Future Work: Fine Grained Control and API-Integration. The performance overhead of this technique is likely to be very significant and; something users wish to control or reduce. There are interesting options here; that impact the implementation strategy used. One particularly appealing option is to allow both opt-in and opt-out of this; mitigation at reasonably fine granularity such as on a per-function basis,; including intelligent handling of inlining decisions -- protected code can be; prevented from inlining into unprotected code, and unprotected code will become; protected when inlined into protected code. For systems where only a limited; set of code is reachable by externally controlled inputs, it may be possible to; limit the scope of mitigation through such mechanisms without compromising the; application's overall security. The performance impact may also be focused in a; few key functions that can be hand-mitigated in ways that have lower; performance overhead while the remainder of the application receives automatic; protection. For both limiting the scope of mitigation or manually mitigating hot functions,; there needs to be some support for mixing mitigated and unmitigated code; without completely defeating the mitigation. For the first use case, it would; be particularly desirable that mitigated code remains safe when being called; during misspeculation from unmitigated code. For the second use case, it may be important to connect the automatic; mitigation technique to explicit mitigation APIs such as what is described in; http://wg21.link/p0928 (or any other eventual API) so that there is a clean way; to switch from automatic to manual mitigation without immediately exposing a; hole. However, the design for how to do this is hard to come up with until the; APIs are better established. We will revisit this as those APIs mature.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:49786,Performance,perform,performance,49786,"haracterization of the performance, and specific benchmarks are unlikely to; reveal especially interesting properties. ### Future Work: Fine Grained Control and API-Integration. The performance overhead of this technique is likely to be very significant and; something users wish to control or reduce. There are interesting options here; that impact the implementation strategy used. One particularly appealing option is to allow both opt-in and opt-out of this; mitigation at reasonably fine granularity such as on a per-function basis,; including intelligent handling of inlining decisions -- protected code can be; prevented from inlining into unprotected code, and unprotected code will become; protected when inlined into protected code. For systems where only a limited; set of code is reachable by externally controlled inputs, it may be possible to; limit the scope of mitigation through such mechanisms without compromising the; application's overall security. The performance impact may also be focused in a; few key functions that can be hand-mitigated in ways that have lower; performance overhead while the remainder of the application receives automatic; protection. For both limiting the scope of mitigation or manually mitigating hot functions,; there needs to be some support for mixing mitigated and unmitigated code; without completely defeating the mitigation. For the first use case, it would; be particularly desirable that mitigated code remains safe when being called; during misspeculation from unmitigated code. For the second use case, it may be important to connect the automatic; mitigation technique to explicit mitigation APIs such as what is described in; http://wg21.link/p0928 (or any other eventual API) so that there is a clean way; to switch from automatic to manual mitigation without immediately exposing a; hole. However, the design for how to do this is hard to come up with until the; APIs are better established. We will revisit this as those APIs mature.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:903,Safety,predict,prediction,903,"# Speculative Load Hardening. ## A Spectre Variant #1 Mitigation Technique. Author: Chandler Carruth - [chandlerc@google.com](mailto:chandlerc@google.com). ## Problem Statement. Recently, Google Project Zero and other researchers have found information leak; vulnerabilities by exploiting speculative execution in modern CPUs. These; exploits are currently broken down into three variants:; * GPZ Variant #1 (a.k.a. Spectre Variant #1): Bounds check (or predicate) bypass; * GPZ Variant #2 (a.k.a. Spectre Variant #2): Branch target injection; * GPZ Variant #3 (a.k.a. Meltdown): Rogue data cache load. For more details, see the Google Project Zero blog post and the Spectre research; paper:; * https://googleprojectzero.blogspot.com/2018/01/reading-privileged-memory-with-side.html; * https://spectreattack.com/spectre.pdf. The core problem of GPZ Variant #1 is that speculative execution uses branch; prediction to select the path of instructions speculatively executed. This path; is speculatively executed with the available data, and may load from memory and; leak the loaded values through various side channels that survive even when the; speculative execution is unwound due to being incorrect. Mispredicted paths can; cause code to be executed with data inputs that never occur in correct; executions, making checks against malicious inputs ineffective and allowing; attackers to use malicious data inputs to leak secret data. Here is an example,; extracted and simplified from the Project Zero paper:; ```; struct array {; unsigned long length;; unsigned char data[];; };; struct array *arr1 = ...; // small array; struct array *arr2 = ...; // array of size 0x400; unsigned long untrusted_offset_from_caller = ...;; if (untrusted_offset_from_caller < arr1->length) {; unsigned char value = arr1->data[untrusted_offset_from_caller];; unsigned long index2 = ((value&1)*0x100)+0x200;; unsigned char value2 = arr2->data[index2];; }; ```. The key of the attack is to call this with `untrusted_off",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:2069,Safety,predict,predictor,2069,"ta, and may load from memory and; leak the loaded values through various side channels that survive even when the; speculative execution is unwound due to being incorrect. Mispredicted paths can; cause code to be executed with data inputs that never occur in correct; executions, making checks against malicious inputs ineffective and allowing; attackers to use malicious data inputs to leak secret data. Here is an example,; extracted and simplified from the Project Zero paper:; ```; struct array {; unsigned long length;; unsigned char data[];; };; struct array *arr1 = ...; // small array; struct array *arr2 = ...; // array of size 0x400; unsigned long untrusted_offset_from_caller = ...;; if (untrusted_offset_from_caller < arr1->length) {; unsigned char value = arr1->data[untrusted_offset_from_caller];; unsigned long index2 = ((value&1)*0x100)+0x200;; unsigned char value2 = arr2->data[index2];; }; ```. The key of the attack is to call this with `untrusted_offset_from_caller` that; is far outside of the bounds when the branch predictor will predict that it; will be in-bounds. In that case, the body of the `if` will be executed; speculatively, and may read secret data into `value` and leak it via a; cache-timing side channel when a dependent access is made to populate `value2`. ## High Level Mitigation Approach. While several approaches are being actively pursued to mitigate specific; branches and/or loads inside especially risky software (most notably various OS; kernels), these approaches require manual and/or static analysis aided auditing; of code and explicit source changes to apply the mitigation. They are unlikely; to scale well to large applications. We are proposing a comprehensive; mitigation approach that would apply automatically across an entire program; rather than through manual changes to the code. While this is likely to have a; high performance cost, some applications may be in a good position to take this; performance / security tradeoff. The specific ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:2084,Safety,predict,predict,2084,"ta, and may load from memory and; leak the loaded values through various side channels that survive even when the; speculative execution is unwound due to being incorrect. Mispredicted paths can; cause code to be executed with data inputs that never occur in correct; executions, making checks against malicious inputs ineffective and allowing; attackers to use malicious data inputs to leak secret data. Here is an example,; extracted and simplified from the Project Zero paper:; ```; struct array {; unsigned long length;; unsigned char data[];; };; struct array *arr1 = ...; // small array; struct array *arr2 = ...; // array of size 0x400; unsigned long untrusted_offset_from_caller = ...;; if (untrusted_offset_from_caller < arr1->length) {; unsigned char value = arr1->data[untrusted_offset_from_caller];; unsigned long index2 = ((value&1)*0x100)+0x200;; unsigned char value2 = arr2->data[index2];; }; ```. The key of the attack is to call this with `untrusted_offset_from_caller` that; is far outside of the bounds when the branch predictor will predict that it; will be in-bounds. In that case, the body of the `if` will be executed; speculatively, and may read secret data into `value` and leak it via a; cache-timing side channel when a dependent access is made to populate `value2`. ## High Level Mitigation Approach. While several approaches are being actively pursued to mitigate specific; branches and/or loads inside especially risky software (most notably various OS; kernels), these approaches require manual and/or static analysis aided auditing; of code and explicit source changes to apply the mitigation. They are unlikely; to scale well to large applications. We are proposing a comprehensive; mitigation approach that would apply automatically across an entire program; rather than through manual changes to the code. While this is likely to have a; high performance cost, some applications may be in a good position to take this; performance / security tradeoff. The specific ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:2474,Safety,risk,risky,2474,"er:; ```; struct array {; unsigned long length;; unsigned char data[];; };; struct array *arr1 = ...; // small array; struct array *arr2 = ...; // array of size 0x400; unsigned long untrusted_offset_from_caller = ...;; if (untrusted_offset_from_caller < arr1->length) {; unsigned char value = arr1->data[untrusted_offset_from_caller];; unsigned long index2 = ((value&1)*0x100)+0x200;; unsigned char value2 = arr2->data[index2];; }; ```. The key of the attack is to call this with `untrusted_offset_from_caller` that; is far outside of the bounds when the branch predictor will predict that it; will be in-bounds. In that case, the body of the `if` will be executed; speculatively, and may read secret data into `value` and leak it via a; cache-timing side channel when a dependent access is made to populate `value2`. ## High Level Mitigation Approach. While several approaches are being actively pursued to mitigate specific; branches and/or loads inside especially risky software (most notably various OS; kernels), these approaches require manual and/or static analysis aided auditing; of code and explicit source changes to apply the mitigation. They are unlikely; to scale well to large applications. We are proposing a comprehensive; mitigation approach that would apply automatically across an entire program; rather than through manual changes to the code. While this is likely to have a; high performance cost, some applications may be in a good position to take this; performance / security tradeoff. The specific technique we propose is to cause loads to be checked using; branchless code to ensure that they are executing along a valid control flow; path. Consider the following C-pseudo-code representing the core idea of a; predicate guarding potentially invalid loads:; ```; void leak(int data);; void example(int* pointer1, int* pointer2) {; if (condition) {; // ... lots of code ...; leak(*pointer1);; } else {; // ... more code ...; leak(*pointer2);; }; }; ```. This would get transf",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:4312,Safety,predict,predicted,4312,"er2) {; if (condition) {; // ... lots of code ...; leak(*pointer1);; } else {; // ... more code ...; leak(*pointer2);; }; }; ```. This would get transformed into something resembling the following:; ```; uintptr_t all_ones_mask = std::numerical_limits<uintptr_t>::max();; uintptr_t all_zeros_mask = 0;; void leak(int data);; void example(int* pointer1, int* pointer2) {; uintptr_t predicate_state = all_ones_mask;; if (condition) {; // Assuming ?: is implemented using branchless logic...; predicate_state = !condition ? all_zeros_mask : predicate_state;; // ... lots of code ...; //; // Harden the pointer so it can't be loaded; pointer1 &= predicate_state;; leak(*pointer1);; } else {; predicate_state = condition ? all_zeros_mask : predicate_state;; // ... more code ...; //; // Alternative: Harden the loaded value; int value2 = *pointer2 & predicate_state;; leak(value2);; }; }; ```. The result should be that if the `if (condition) {` branch is mis-predicted,; there is a *data* dependency on the condition used to zero out any pointers; prior to loading through them or to zero out all of the loaded bits. Even; though this code pattern may still execute speculatively, *invalid* speculative; executions are prevented from leaking secret data from memory (but note that; this data might still be loaded in safe ways, and some regions of memory are; required to not hold secrets, see below for detailed limitations). This; approach only requires the underlying hardware have a way to implement a; branchless and unpredicted conditional update of a register's value. All modern; architectures have support for this, and in fact such support is necessary to; correctly implement constant time cryptographic primitives. Crucial properties of this approach:; * It is not preventing any particular side-channel from working. This is; important as there are an unknown number of potential side channels and we; expect to continue discovering more. Instead, it prevents the observation of; secret data",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:4670,Safety,safe,safe,4670,"();; uintptr_t all_zeros_mask = 0;; void leak(int data);; void example(int* pointer1, int* pointer2) {; uintptr_t predicate_state = all_ones_mask;; if (condition) {; // Assuming ?: is implemented using branchless logic...; predicate_state = !condition ? all_zeros_mask : predicate_state;; // ... lots of code ...; //; // Harden the pointer so it can't be loaded; pointer1 &= predicate_state;; leak(*pointer1);; } else {; predicate_state = condition ? all_zeros_mask : predicate_state;; // ... more code ...; //; // Alternative: Harden the loaded value; int value2 = *pointer2 & predicate_state;; leak(value2);; }; }; ```. The result should be that if the `if (condition) {` branch is mis-predicted,; there is a *data* dependency on the condition used to zero out any pointers; prior to loading through them or to zero out all of the loaded bits. Even; though this code pattern may still execute speculatively, *invalid* speculative; executions are prevented from leaking secret data from memory (but note that; this data might still be loaded in safe ways, and some regions of memory are; required to not hold secrets, see below for detailed limitations). This; approach only requires the underlying hardware have a way to implement a; branchless and unpredicted conditional update of a register's value. All modern; architectures have support for this, and in fact such support is necessary to; correctly implement constant time cryptographic primitives. Crucial properties of this approach:; * It is not preventing any particular side-channel from working. This is; important as there are an unknown number of potential side channels and we; expect to continue discovering more. Instead, it prevents the observation of; secret data in the first place.; * It accumulates the predicate state, protecting even in the face of nested; *correctly* predicted control flows.; * It passes this predicate state across function boundaries to provide; [interprocedural protection](#interprocedural-checking).; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:5468,Safety,predict,predicted,5468,"to zero out all of the loaded bits. Even; though this code pattern may still execute speculatively, *invalid* speculative; executions are prevented from leaking secret data from memory (but note that; this data might still be loaded in safe ways, and some regions of memory are; required to not hold secrets, see below for detailed limitations). This; approach only requires the underlying hardware have a way to implement a; branchless and unpredicted conditional update of a register's value. All modern; architectures have support for this, and in fact such support is necessary to; correctly implement constant time cryptographic primitives. Crucial properties of this approach:; * It is not preventing any particular side-channel from working. This is; important as there are an unknown number of potential side channels and we; expect to continue discovering more. Instead, it prevents the observation of; secret data in the first place.; * It accumulates the predicate state, protecting even in the face of nested; *correctly* predicted control flows.; * It passes this predicate state across function boundaries to provide; [interprocedural protection](#interprocedural-checking).; * When hardening the address of a load, it uses a *destructive* or; *non-reversible* modification of the address to prevent an attacker from; reversing the check using attacker-controlled inputs.; * It does not completely block speculative execution, and merely prevents; *mis*-speculated paths from leaking secrets from memory (and stalls; speculation until this can be determined).; * It is completely general and makes no fundamental assumptions about the; underlying architecture other than the ability to do branchless conditional; data updates and a lack of value prediction.; * It does not require programmers to identify all possible secret data using; static source code annotations or code vulnerable to a variant #1 style; attack. Limitations of this approach:; * It requires re-compiling source code",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:6194,Safety,predict,prediction,6194," approach:; * It is not preventing any particular side-channel from working. This is; important as there are an unknown number of potential side channels and we; expect to continue discovering more. Instead, it prevents the observation of; secret data in the first place.; * It accumulates the predicate state, protecting even in the face of nested; *correctly* predicted control flows.; * It passes this predicate state across function boundaries to provide; [interprocedural protection](#interprocedural-checking).; * When hardening the address of a load, it uses a *destructive* or; *non-reversible* modification of the address to prevent an attacker from; reversing the check using attacker-controlled inputs.; * It does not completely block speculative execution, and merely prevents; *mis*-speculated paths from leaking secrets from memory (and stalls; speculation until this can be determined).; * It is completely general and makes no fundamental assumptions about the; underlying architecture other than the ability to do branchless conditional; data updates and a lack of value prediction.; * It does not require programmers to identify all possible secret data using; static source code annotations or code vulnerable to a variant #1 style; attack. Limitations of this approach:; * It requires re-compiling source code to insert hardening instruction; sequences. Only software compiled in this mode is protected.; * The performance is heavily dependent on a particular architecture's; implementation strategy. We outline a potential x86 implementation below and; characterize its performance.; * It does not defend against secret data already loaded from memory and; residing in registers or leaked through other side-channels in; non-speculative execution. Code dealing with this, e.g cryptographic; routines, already uses constant-time algorithms and code to prevent; side-channels. Such code should also scrub registers of secret data following; [these; guidelines](https://github.com/H",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:8503,Safety,predict,prediction,8503,"n area which can be tuned to provide more comprehensive; protection at the cost of performance.; * [Hardened loads](#hardening-the-address-of-the-load) may still load data from; _valid_ addresses if not _attacker-controlled_ addresses. To prevent these; from reading secret data, the low 2gb of the address space and 2gb above and; below any executable pages should be protected. Credit:; * The core idea of tracing misspeculation through data and marking pointers to; block misspeculated loads was developed as part of a HACS 2018 discussion; between Chandler Carruth, Paul Kocher, Thomas Pornin, and several other; individuals.; * Core idea of masking out loaded bits was part of the original mitigation; suggested by Jann Horn when these attacks were reported. ### Indirect Branches, Calls, and Returns. It is possible to attack control flow other than conditional branches with; variant #1 style mispredictions.; * A prediction towards a hot call target of a virtual method can lead to it; being speculatively executed when an expected type is used (often called; ""type confusion"").; * A hot case may be speculatively executed due to prediction instead of the; correct case for a switch statement implemented as a jump table.; * A hot common return address may be predicted incorrectly when returning from; a function. These code patterns are also vulnerable to Spectre variant #2, and as such are; best mitigated with a; [retpoline](https://support.google.com/faqs/answer/7625886) on x86 platforms.; When a mitigation technique like retpoline is used, speculation simply cannot; proceed through an indirect control flow edge (or it cannot be mispredicted in; the case of a filled RSB) and so it is also protected from variant #1 style; attacks. However, some architectures, micro-architectures, or vendors do not; employ the retpoline mitigation, and on future x86 hardware (both Intel and; AMD) it is expected to become unnecessary due to hardware-based mitigation. When not using a retpoline, t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:8720,Safety,predict,prediction,8720,"till load data from; _valid_ addresses if not _attacker-controlled_ addresses. To prevent these; from reading secret data, the low 2gb of the address space and 2gb above and; below any executable pages should be protected. Credit:; * The core idea of tracing misspeculation through data and marking pointers to; block misspeculated loads was developed as part of a HACS 2018 discussion; between Chandler Carruth, Paul Kocher, Thomas Pornin, and several other; individuals.; * Core idea of masking out loaded bits was part of the original mitigation; suggested by Jann Horn when these attacks were reported. ### Indirect Branches, Calls, and Returns. It is possible to attack control flow other than conditional branches with; variant #1 style mispredictions.; * A prediction towards a hot call target of a virtual method can lead to it; being speculatively executed when an expected type is used (often called; ""type confusion"").; * A hot case may be speculatively executed due to prediction instead of the; correct case for a switch statement implemented as a jump table.; * A hot common return address may be predicted incorrectly when returning from; a function. These code patterns are also vulnerable to Spectre variant #2, and as such are; best mitigated with a; [retpoline](https://support.google.com/faqs/answer/7625886) on x86 platforms.; When a mitigation technique like retpoline is used, speculation simply cannot; proceed through an indirect control flow edge (or it cannot be mispredicted in; the case of a filled RSB) and so it is also protected from variant #1 style; attacks. However, some architectures, micro-architectures, or vendors do not; employ the retpoline mitigation, and on future x86 hardware (both Intel and; AMD) it is expected to become unnecessary due to hardware-based mitigation. When not using a retpoline, these edges will need independent protection from; variant #1 style attacks. The analogous approach to that used for conditional; control flow should work:; `",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:8850,Safety,predict,predicted,8850,"ata, the low 2gb of the address space and 2gb above and; below any executable pages should be protected. Credit:; * The core idea of tracing misspeculation through data and marking pointers to; block misspeculated loads was developed as part of a HACS 2018 discussion; between Chandler Carruth, Paul Kocher, Thomas Pornin, and several other; individuals.; * Core idea of masking out loaded bits was part of the original mitigation; suggested by Jann Horn when these attacks were reported. ### Indirect Branches, Calls, and Returns. It is possible to attack control flow other than conditional branches with; variant #1 style mispredictions.; * A prediction towards a hot call target of a virtual method can lead to it; being speculatively executed when an expected type is used (often called; ""type confusion"").; * A hot case may be speculatively executed due to prediction instead of the; correct case for a switch statement implemented as a jump table.; * A hot common return address may be predicted incorrectly when returning from; a function. These code patterns are also vulnerable to Spectre variant #2, and as such are; best mitigated with a; [retpoline](https://support.google.com/faqs/answer/7625886) on x86 platforms.; When a mitigation technique like retpoline is used, speculation simply cannot; proceed through an indirect control flow edge (or it cannot be mispredicted in; the case of a filled RSB) and so it is also protected from variant #1 style; attacks. However, some architectures, micro-architectures, or vendors do not; employ the retpoline mitigation, and on future x86 hardware (both Intel and; AMD) it is expected to become unnecessary due to hardware-based mitigation. When not using a retpoline, these edges will need independent protection from; variant #1 style attacks. The analogous approach to that used for conditional; control flow should work:; ```; uintptr_t all_ones_mask = std::numerical_limits<uintptr_t>::max();; uintptr_t all_zeros_mask = 0;; void leak(int d",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:16245,Safety,predict,predicted,16245," channel:; ```; # %bb.0: # %entry; pushq %rax; testl %edi, %edi; jne .LBB0_4; # %bb.1: # %then1; testl %esi, %esi; jne .LBB0_4; # %bb.2: # %then2; testl %edx, %edx; je .LBB0_3; .LBB0_4: # %exit; popq %rax; retq; .LBB0_3: # %danger; movl (%rcx), %edi; callq leak; popq %rax; retq; ```. When we go to speculatively execute the load, we want to know whether any of; the dynamically executed predicates have been misspeculated. To track that,; along each conditional edge, we need to track the data which would allow that; edge to be taken. On x86, this data is stored in the flags register used by the; conditional jump instruction. Along both edges after this fork in control flow,; the flags register remains alive and contains data that we can use to build up; our accumulated predicate state. We accumulate it using the x86 conditional; move instruction which also reads the flag registers where the state resides.; These conditional move instructions are known to not be predicted on any x86; processors, making them immune to misprediction that could reintroduce the; vulnerability. When we insert the conditional moves, the code ends up looking; like the following:; ```; # %bb.0: # %entry; pushq %rax; xorl %eax, %eax # Zero out initial predicate state.; movq $-1, %r8 # Put all-ones mask into a register.; testl %edi, %edi; jne .LBB0_1; # %bb.2: # %then1; cmovneq %r8, %rax # Conditionally update predicate state.; testl %esi, %esi; jne .LBB0_1; # %bb.3: # %then2; cmovneq %r8, %rax # Conditionally update predicate state.; testl %edx, %edx; je .LBB0_4; .LBB0_1:; cmoveq %r8, %rax # Conditionally update predicate state.; popq %rax; retq; .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; ...; ```. Here we create the ""empty"" or ""correct execution"" predicate state by zeroing; `%rax`, and we create a constant ""incorrect execution"" predicate value by; putting `-1` into `%r8`. Then, along each edge coming out of a conditional; branch we do a conditional move that ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:27752,Safety,avoid,avoids,27752," no useful instructions on x86 that apply a mask to all 64 bits; without touching the flag registers. However, we can harden loaded values that; are narrower than a word (fewer than 32-bits on 32-bit systems and fewer than; 64-bits on 64-bit systems) by zero-extending the value to the full word size; and then shifting right by at least the number of original bits using the BMI2; `shrx` instruction:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate 32 bits of data.; shrxq %rax, %rdi, %rdi # Shift out all 32 bits loaded.; ```. Because on x86 the zero-extend is free, this can efficiently harden the loaded; value. ##### Hardening the address of the load. When hardening the loaded value is inapplicable, most often because the; instruction directly leaks information (like `cmp` or `jmpq`), we switch to; hardening the _address_ of the load instead of the loaded value. This avoids; increasing register pressure by unfolding the load or paying some other high; cost. To understand how this works in practice, we need to examine the exact; semantics of the x86 addressing modes which, in its fully general form, looks; like `(%base,%index,scale)offset`. Here `%base` and `%index` are 64-bit; registers that can potentially be any value, and may be attacker controlled,; and `scale` and `offset` are fixed immediate values. `scale` must be `1`, `2`,; `4`, or `8`, and `offset` can be any 32-bit sign extended value. The exact; computation performed to find the address is then: `%base + (scale * %index) +; offset` under 64-bit 2's complement modular arithmetic. One issue with this approach is that, after hardening, the `%base + (scale *; %index)` subexpression will compute a value near zero (`-1 + (scale * -1)`) and; then a large, positive `offset` will index into memory within the first two; gigabytes of address space. While these offsets are not attacker controlled,; the attacker could chose to attack a load w",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:31676,Safety,hazard,hazardous,31676,"age we have is that the attacker also cannot modify; `%base`. If we use the fast instruction sequence above, but only apply it to; the index, we will always access `%rip + (scale * -1) + offset`. If the; attacker can find a load which with this address happens to point to secret; data, then they can reach it. However, the loader and base libraries can also; simply refuse to map the heap, data segments, or stack within 2gb of any of the; text in the program, much like it can reserve the low 2gb of address space. ###### The flag registers again make everything hard. Unfortunately, the technique of using `orq`-instructions has a serious flaw on; x86. The very thing that makes it easy to accumulate state, the flag registers; containing predicates, causes serious problems here because they may be alive; and used by the loading instruction or subsequent instructions. On x86, the; `orq` instruction **sets** the flags and will override anything already there.; This makes inserting them into the instruction stream very hazardous.; Unfortunately, unlike when hardening the loaded value, we have no fallback here; and so we must have a fully general approach available. The first thing we must do when generating these sequences is try to analyze; the surrounding code to prove that the flags are not in fact alive or being; used. Typically, it has been set by some other instruction which just happens; to set the flags register (much like ours!) with no actual dependency. In those; cases, it is safe to directly insert these instructions. Alternatively we may; be able to move them earlier to avoid clobbering the used value. However, this may ultimately be impossible. In that case, we need to preserve; the flags around these instructions:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; pushfq; orq %rax, %rcx # Mask the pointer if misspeculating.; orq %rax, %rdx # Mask the index if misspeculating.; popfq; movl (%rcx,%rdx), %edi; ```. Using the `p",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:32153,Safety,safe,safe,32153,"ace. ###### The flag registers again make everything hard. Unfortunately, the technique of using `orq`-instructions has a serious flaw on; x86. The very thing that makes it easy to accumulate state, the flag registers; containing predicates, causes serious problems here because they may be alive; and used by the loading instruction or subsequent instructions. On x86, the; `orq` instruction **sets** the flags and will override anything already there.; This makes inserting them into the instruction stream very hazardous.; Unfortunately, unlike when hardening the loaded value, we have no fallback here; and so we must have a fully general approach available. The first thing we must do when generating these sequences is try to analyze; the surrounding code to prove that the flags are not in fact alive or being; used. Typically, it has been set by some other instruction which just happens; to set the flags register (much like ours!) with no actual dependency. In those; cases, it is safe to directly insert these instructions. Alternatively we may; be able to move them earlier to avoid clobbering the used value. However, this may ultimately be impossible. In that case, we need to preserve; the flags around these instructions:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; pushfq; orq %rax, %rcx # Mask the pointer if misspeculating.; orq %rax, %rdx # Mask the index if misspeculating.; popfq; movl (%rcx,%rdx), %edi; ```. Using the `pushf` and `popf` instructions saves the flags register around our; inserted code, but comes at a high cost. First, we must store the flags to the; stack and reload them. Second, this causes the stack pointer to be adjusted; dynamically, requiring a frame pointer be used for referring to temporaries; spilled to the stack, etc. On newer x86 processors we can use the `lahf` and `sahf` instructions to save; all of the flags besides the overflow flag in a register rather than on the; stack. We can then use `seto",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:32251,Safety,avoid,avoid,32251," technique of using `orq`-instructions has a serious flaw on; x86. The very thing that makes it easy to accumulate state, the flag registers; containing predicates, causes serious problems here because they may be alive; and used by the loading instruction or subsequent instructions. On x86, the; `orq` instruction **sets** the flags and will override anything already there.; This makes inserting them into the instruction stream very hazardous.; Unfortunately, unlike when hardening the loaded value, we have no fallback here; and so we must have a fully general approach available. The first thing we must do when generating these sequences is try to analyze; the surrounding code to prove that the flags are not in fact alive or being; used. Typically, it has been set by some other instruction which just happens; to set the flags register (much like ours!) with no actual dependency. In those; cases, it is safe to directly insert these instructions. Alternatively we may; be able to move them earlier to avoid clobbering the used value. However, this may ultimately be impossible. In that case, we need to preserve; the flags around these instructions:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; pushfq; orq %rax, %rcx # Mask the pointer if misspeculating.; orq %rax, %rdx # Mask the index if misspeculating.; popfq; movl (%rcx,%rdx), %edi; ```. Using the `pushf` and `popf` instructions saves the flags register around our; inserted code, but comes at a high cost. First, we must store the flags to the; stack and reload them. Second, this causes the stack pointer to be adjusted; dynamically, requiring a frame pointer be used for referring to temporaries; spilled to the stack, etc. On newer x86 processors we can use the `lahf` and `sahf` instructions to save; all of the flags besides the overflow flag in a register rather than on the; stack. We can then use `seto` and `add` to save and restore the overflow flag; in a register. Combined, t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:34739,Safety,avoid,avoiding,34739,"quences to the above ones. However, these are still very marginally; slower, as there are fewer ports able to dispatch shift instructions in most; modern x86 processors than there are for `or` instructions. Fast, single register addressing mode:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; shrxq %rax, %rsi, %rsi # Shift away bits if misspeculating.; movl (%rsi), %edi; ```. This will collapse the register to zero or one, and everything but the offset; in the addressing mode to be less than or equal to 9. This means the full; address can only be guaranteed to be less than `(1 << 31) + 9`. The OS may wish; to protect an extra page of the low address space to account for this. ##### Optimizations. A very large portion of the cost for this approach comes from checking loads in; this way, so it is important to work to optimize this. However, beyond making; the instruction sequences to *apply* the checks efficient (for example by; avoiding `pushfq` and `popfq` sequences), the only significant optimization is; to check fewer loads without introducing a vulnerability. We apply several; techniques to accomplish that. ###### Don't check loads from compile-time constant stack offsets. We implement this optimization on x86 by skipping the checking of loads which; use a fixed frame pointer offset. The result of this optimization is that patterns like reloading a spilled; register or accessing a global field don't get checked. This is a very; significant performance win. ###### Don't check dependent loads. A core part of why this mitigation strategy works is that it establishes a; data-flow check on the loaded address. However, this means that if the address; itself was already loaded using a checked load, there is no need to check a; dependent load provided it is within the same basic block as the checked load,; and therefore has no additional predicates guarding it. Consider code like the; following:; ```; ... .LBB0_4: # %danger; movq (",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:38837,Safety,detect,detect,38837,"n x86 processors may speculate into called functions and out of functions; to their return address. As a consequence, we need a way to check loads that; occur after a misspeculated predicate but where the load and the misspeculated; predicate are in different functions. In essence, we need some interprocedural; generalization of the predicate state tracking. A primary challenge to passing; the predicate state between functions is that we would like to not require a; change to the ABI or calling convention in order to make this mitigation more; deployable, and further would like code mitigated in this way to be easily; mixed with code not mitigated in this way and without completely losing the; value of the mitigation. ##### Embed the predicate state into the high bit(s) of the stack pointer. We can use the same technique that allows hardening pointers to pass the; predicate state into and out of functions. The stack pointer is trivially; passed between functions and we can test for it having the high bits set to; detect when it has been marked due to misspeculation. The callsite instruction; sequence looks like (assuming a misspeculated state value of `-1`):; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; shlq $47, %rax; orq %rax, %rsp; callq other_function; movq %rsp, %rax; sarq 63, %rax # Sign extend the high bit to all bits.; ```. This first puts the predicate state into the high bits of `%rsp` before calling; the function and then reads it back out of high bits of `%rsp` afterward. When; correctly executing (speculatively or not), these are all no-ops. When; misspeculating, the stack pointer will end up negative. We arrange for it to; remain a canonical address, but otherwise leave the low bits alone to allow; stack adjustments to proceed normally without disrupting this. Within the; called function, we can extract this predicate state and then reset it on; return:; ```; other_function:; # prolog; callq other_function; mov",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:41859,Safety,risk,risky,41859,"e to be poisoned the; resulting stack pointer will be invalid. ##### Rewrite API of internal functions to directly propagate predicate state. (Not yet implemented.). We have the option with internal functions to directly adjust their API to; accept the predicate as an argument and return it. This is likely to be; marginally cheaper than embedding into `%rsp` for entering functions. ##### Use `lfence` to guard function transitions. An `lfence` instruction can be used to prevent subsequent loads from; speculatively executing until all prior mispredicted predicates have resolved.; We can use this broader barrier to speculative loads executing between; functions. We emit it in the entry block to handle calls, and prior to each; return. This approach also has the advantage of providing the strongest degree; of mitigation when mixed with unmitigated code by halting all misspeculation; entering a function which is mitigated, regardless of what occurred in the; caller. However, such a mixture is inherently more risky. Whether this kind of; mixture is a sufficient mitigation requires careful analysis. Unfortunately, experimental results indicate that the performance overhead of; this approach is very high for certain patterns of code. A classic example is; any form of recursive evaluation engine. The hot, rapid call and return; sequences exhibit dramatic performance loss when mitigated with `lfence`. This; component alone can regress performance by 2x or more, making it an unpleasant; tradeoff even when only used in a mixture of code. ##### Use an internal TLS location to pass predicate state. We can define a special thread-local value to hold the predicate state between; functions. This avoids direct ABI implications by using a side channel between; callers and callees to communicate the predicate state. It also allows implicit; zero-initialization of the state, which allows non-checked code to be the first; code executed. However, this requires a load from TLS in the entry",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:42548,Safety,avoid,avoids,42548," the advantage of providing the strongest degree; of mitigation when mixed with unmitigated code by halting all misspeculation; entering a function which is mitigated, regardless of what occurred in the; caller. However, such a mixture is inherently more risky. Whether this kind of; mixture is a sufficient mitigation requires careful analysis. Unfortunately, experimental results indicate that the performance overhead of; this approach is very high for certain patterns of code. A classic example is; any form of recursive evaluation engine. The hot, rapid call and return; sequences exhibit dramatic performance loss when mitigated with `lfence`. This; component alone can regress performance by 2x or more, making it an unpleasant; tradeoff even when only used in a mixture of code. ##### Use an internal TLS location to pass predicate state. We can define a special thread-local value to hold the predicate state between; functions. This avoids direct ABI implications by using a side channel between; callers and callees to communicate the predicate state. It also allows implicit; zero-initialization of the state, which allows non-checked code to be the first; code executed. However, this requires a load from TLS in the entry block, a store to TLS; before every call and every ret, and a load from TLS after every call. As a; consequence it is expected to be substantially more expensive even than using; `%rsp` and potentially `lfence` within the function entry block. ##### Define a new ABI and/or calling convention. We could define a new ABI and/or calling convention to explicitly pass the; predicate state in and out of functions. This may be interesting if none of the; alternatives have adequate performance, but it makes deployment and adoption; dramatically more complex, and potentially infeasible. ## High-Level Alternative Mitigation Strategies. There are completely different alternative approaches to mitigating variant 1; attacks. [Most](https://lwn.net/Articles/743265/); [",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:44063,Safety,safe,safe,44063,"ected to be substantially more expensive even than using; `%rsp` and potentially `lfence` within the function entry block. ##### Define a new ABI and/or calling convention. We could define a new ABI and/or calling convention to explicitly pass the; predicate state in and out of functions. This may be interesting if none of the; alternatives have adequate performance, but it makes deployment and adoption; dramatically more complex, and potentially infeasible. ## High-Level Alternative Mitigation Strategies. There are completely different alternative approaches to mitigating variant 1; attacks. [Most](https://lwn.net/Articles/743265/); [discussion](https://lwn.net/Articles/744287/) so far focuses on mitigating; specific known attackable components in the Linux kernel (or other kernels) by; manually rewriting the code to contain an instruction sequence that is not; vulnerable. For x86 systems this is done by either injecting an `lfence`; instruction along the code path which would leak data if executed speculatively; or by rewriting memory accesses to have branch-less masking to a known safe; region. On Intel systems, `lfence` [will prevent the speculative load of secret; data](https://newsroom.intel.com/wp-content/uploads/sites/11/2018/01/Intel-Analysis-of-Speculative-Execution-Side-Channels.pdf).; On AMD systems `lfence` is currently a no-op, but can be made; dispatch-serializing by setting an MSR, and thus preclude misspeculation of the; code path ([mitigation G-2 +; V1-1](https://developer.amd.com/wp-content/resources/Managing-Speculation-on-AMD-Processors.pdf)). However, this relies on finding and enumerating all possible points in code; which could be attacked to leak information. While in some cases static; analysis is effective at doing this at scale, in many cases it still relies on; human judgement to evaluate whether code might be vulnerable. Especially for; software systems which receive less detailed scrutiny but remain sensitive to; these attacks, this se",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:45918,Safety,risk,risk,45918,"software systems which receive less detailed scrutiny but remain sensitive to; these attacks, this seems like an impractical security model. We need an; automatic and systematic mitigation strategy. ### Automatic `lfence` on Conditional Edges. A natural way to scale up the existing hand-coded mitigations is simply to; inject an `lfence` instruction into both the target and fallthrough; destinations of every conditional branch. This ensures that no predicate or; bounds check can be bypassed speculatively. However, the performance overhead; of this approach is, simply put, catastrophic. Yet it remains the only truly; ""secure by default"" approach known prior to this effort and serves as the; baseline for performance. One attempt to address the performance overhead of this and make it more; realistic to deploy is [MSVC's /Qspectre; switch](https://blogs.msdn.microsoft.com/vcblog/2018/01/15/spectre-mitigations-in-msvc/).; Their technique is to use static analysis within the compiler to only insert; `lfence` instructions into conditional edges at risk of attack. However,; [initial](https://arstechnica.com/gadgets/2018/02/microsofts-compiler-level-spectre-fix-shows-how-hard-this-problem-will-be-to-solve/); [analysis](https://www.paulkocher.com/doc/MicrosoftCompilerSpectreMitigation.html); has shown that this approach is incomplete and only catches a small and limited; subset of attackable patterns which happen to resemble very closely the initial; proofs of concept. As such, while its performance is acceptable, it does not; appear to be an adequate systematic mitigation. ## Performance Overhead. The performance overhead of this style of comprehensive mitigation is very; high. However, it compares very favorably with previously recommended; approaches such as the `lfence` instruction. Just as users can restrict the; scope of `lfence` to control its performance impact, this mitigation technique; could be restricted in scope as well. However, it is important to understand what",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:50166,Safety,safe,safe,50166,"haracterization of the performance, and specific benchmarks are unlikely to; reveal especially interesting properties. ### Future Work: Fine Grained Control and API-Integration. The performance overhead of this technique is likely to be very significant and; something users wish to control or reduce. There are interesting options here; that impact the implementation strategy used. One particularly appealing option is to allow both opt-in and opt-out of this; mitigation at reasonably fine granularity such as on a per-function basis,; including intelligent handling of inlining decisions -- protected code can be; prevented from inlining into unprotected code, and unprotected code will become; protected when inlined into protected code. For systems where only a limited; set of code is reachable by externally controlled inputs, it may be possible to; limit the scope of mitigation through such mechanisms without compromising the; application's overall security. The performance impact may also be focused in a; few key functions that can be hand-mitigated in ways that have lower; performance overhead while the remainder of the application receives automatic; protection. For both limiting the scope of mitigation or manually mitigating hot functions,; there needs to be some support for mixing mitigated and unmitigated code; without completely defeating the mitigation. For the first use case, it would; be particularly desirable that mitigated code remains safe when being called; during misspeculation from unmitigated code. For the second use case, it may be important to connect the automatic; mitigation technique to explicit mitigation APIs such as what is described in; http://wg21.link/p0928 (or any other eventual API) so that there is a clean way; to switch from automatic to manual mitigation without immediately exposing a; hole. However, the design for how to do this is hard to come up with until the; APIs are better established. We will revisit this as those APIs mature.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:533,Security,inject,injection,533,"# Speculative Load Hardening. ## A Spectre Variant #1 Mitigation Technique. Author: Chandler Carruth - [chandlerc@google.com](mailto:chandlerc@google.com). ## Problem Statement. Recently, Google Project Zero and other researchers have found information leak; vulnerabilities by exploiting speculative execution in modern CPUs. These; exploits are currently broken down into three variants:; * GPZ Variant #1 (a.k.a. Spectre Variant #1): Bounds check (or predicate) bypass; * GPZ Variant #2 (a.k.a. Spectre Variant #2): Branch target injection; * GPZ Variant #3 (a.k.a. Meltdown): Rogue data cache load. For more details, see the Google Project Zero blog post and the Spectre research; paper:; * https://googleprojectzero.blogspot.com/2018/01/reading-privileged-memory-with-side.html; * https://spectreattack.com/spectre.pdf. The core problem of GPZ Variant #1 is that speculative execution uses branch; prediction to select the path of instructions speculatively executed. This path; is speculatively executed with the available data, and may load from memory and; leak the loaded values through various side channels that survive even when the; speculative execution is unwound due to being incorrect. Mispredicted paths can; cause code to be executed with data inputs that never occur in correct; executions, making checks against malicious inputs ineffective and allowing; attackers to use malicious data inputs to leak secret data. Here is an example,; extracted and simplified from the Project Zero paper:; ```; struct array {; unsigned long length;; unsigned char data[];; };; struct array *arr1 = ...; // small array; struct array *arr2 = ...; // array of size 0x400; unsigned long untrusted_offset_from_caller = ...;; if (untrusted_offset_from_caller < arr1->length) {; unsigned char value = arr1->data[untrusted_offset_from_caller];; unsigned long index2 = ((value&1)*0x100)+0x200;; unsigned char value2 = arr2->data[index2];; }; ```. The key of the attack is to call this with `untrusted_off",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:1376,Security,attack,attackers,1376,"rn CPUs. These; exploits are currently broken down into three variants:; * GPZ Variant #1 (a.k.a. Spectre Variant #1): Bounds check (or predicate) bypass; * GPZ Variant #2 (a.k.a. Spectre Variant #2): Branch target injection; * GPZ Variant #3 (a.k.a. Meltdown): Rogue data cache load. For more details, see the Google Project Zero blog post and the Spectre research; paper:; * https://googleprojectzero.blogspot.com/2018/01/reading-privileged-memory-with-side.html; * https://spectreattack.com/spectre.pdf. The core problem of GPZ Variant #1 is that speculative execution uses branch; prediction to select the path of instructions speculatively executed. This path; is speculatively executed with the available data, and may load from memory and; leak the loaded values through various side channels that survive even when the; speculative execution is unwound due to being incorrect. Mispredicted paths can; cause code to be executed with data inputs that never occur in correct; executions, making checks against malicious inputs ineffective and allowing; attackers to use malicious data inputs to leak secret data. Here is an example,; extracted and simplified from the Project Zero paper:; ```; struct array {; unsigned long length;; unsigned char data[];; };; struct array *arr1 = ...; // small array; struct array *arr2 = ...; // array of size 0x400; unsigned long untrusted_offset_from_caller = ...;; if (untrusted_offset_from_caller < arr1->length) {; unsigned char value = arr1->data[untrusted_offset_from_caller];; unsigned long index2 = ((value&1)*0x100)+0x200;; unsigned char value2 = arr2->data[index2];; }; ```. The key of the attack is to call this with `untrusted_offset_from_caller` that; is far outside of the bounds when the branch predictor will predict that it; will be in-bounds. In that case, the body of the `if` will be executed; speculatively, and may read secret data into `value` and leak it via a; cache-timing side channel when a dependent access is made to populate `val",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:1959,Security,attack,attack,1959,"ta, and may load from memory and; leak the loaded values through various side channels that survive even when the; speculative execution is unwound due to being incorrect. Mispredicted paths can; cause code to be executed with data inputs that never occur in correct; executions, making checks against malicious inputs ineffective and allowing; attackers to use malicious data inputs to leak secret data. Here is an example,; extracted and simplified from the Project Zero paper:; ```; struct array {; unsigned long length;; unsigned char data[];; };; struct array *arr1 = ...; // small array; struct array *arr2 = ...; // array of size 0x400; unsigned long untrusted_offset_from_caller = ...;; if (untrusted_offset_from_caller < arr1->length) {; unsigned char value = arr1->data[untrusted_offset_from_caller];; unsigned long index2 = ((value&1)*0x100)+0x200;; unsigned char value2 = arr2->data[index2];; }; ```. The key of the attack is to call this with `untrusted_offset_from_caller` that; is far outside of the bounds when the branch predictor will predict that it; will be in-bounds. In that case, the body of the `if` will be executed; speculatively, and may read secret data into `value` and leak it via a; cache-timing side channel when a dependent access is made to populate `value2`. ## High Level Mitigation Approach. While several approaches are being actively pursued to mitigate specific; branches and/or loads inside especially risky software (most notably various OS; kernels), these approaches require manual and/or static analysis aided auditing; of code and explicit source changes to apply the mitigation. They are unlikely; to scale well to large applications. We are proposing a comprehensive; mitigation approach that would apply automatically across an entire program; rather than through manual changes to the code. While this is likely to have a; high performance cost, some applications may be in a good position to take this; performance / security tradeoff. The specific ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:2288,Security,access,access,2288," can; cause code to be executed with data inputs that never occur in correct; executions, making checks against malicious inputs ineffective and allowing; attackers to use malicious data inputs to leak secret data. Here is an example,; extracted and simplified from the Project Zero paper:; ```; struct array {; unsigned long length;; unsigned char data[];; };; struct array *arr1 = ...; // small array; struct array *arr2 = ...; // array of size 0x400; unsigned long untrusted_offset_from_caller = ...;; if (untrusted_offset_from_caller < arr1->length) {; unsigned char value = arr1->data[untrusted_offset_from_caller];; unsigned long index2 = ((value&1)*0x100)+0x200;; unsigned char value2 = arr2->data[index2];; }; ```. The key of the attack is to call this with `untrusted_offset_from_caller` that; is far outside of the bounds when the branch predictor will predict that it; will be in-bounds. In that case, the body of the `if` will be executed; speculatively, and may read secret data into `value` and leak it via a; cache-timing side channel when a dependent access is made to populate `value2`. ## High Level Mitigation Approach. While several approaches are being actively pursued to mitigate specific; branches and/or loads inside especially risky software (most notably various OS; kernels), these approaches require manual and/or static analysis aided auditing; of code and explicit source changes to apply the mitigation. They are unlikely; to scale well to large applications. We are proposing a comprehensive; mitigation approach that would apply automatically across an entire program; rather than through manual changes to the code. While this is likely to have a; high performance cost, some applications may be in a good position to take this; performance / security tradeoff. The specific technique we propose is to cause loads to be checked using; branchless code to ensure that they are executing along a valid control flow; path. Consider the following C-pseudo-code representi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:2586,Security,audit,auditing,2586,"er:; ```; struct array {; unsigned long length;; unsigned char data[];; };; struct array *arr1 = ...; // small array; struct array *arr2 = ...; // array of size 0x400; unsigned long untrusted_offset_from_caller = ...;; if (untrusted_offset_from_caller < arr1->length) {; unsigned char value = arr1->data[untrusted_offset_from_caller];; unsigned long index2 = ((value&1)*0x100)+0x200;; unsigned char value2 = arr2->data[index2];; }; ```. The key of the attack is to call this with `untrusted_offset_from_caller` that; is far outside of the bounds when the branch predictor will predict that it; will be in-bounds. In that case, the body of the `if` will be executed; speculatively, and may read secret data into `value` and leak it via a; cache-timing side channel when a dependent access is made to populate `value2`. ## High Level Mitigation Approach. While several approaches are being actively pursued to mitigate specific; branches and/or loads inside especially risky software (most notably various OS; kernels), these approaches require manual and/or static analysis aided auditing; of code and explicit source changes to apply the mitigation. They are unlikely; to scale well to large applications. We are proposing a comprehensive; mitigation approach that would apply automatically across an entire program; rather than through manual changes to the code. While this is likely to have a; high performance cost, some applications may be in a good position to take this; performance / security tradeoff. The specific technique we propose is to cause loads to be checked using; branchless code to ensure that they are executing along a valid control flow; path. Consider the following C-pseudo-code representing the core idea of a; predicate guarding potentially invalid loads:; ```; void leak(int data);; void example(int* pointer1, int* pointer2) {; if (condition) {; // ... lots of code ...; leak(*pointer1);; } else {; // ... more code ...; leak(*pointer2);; }; }; ```. This would get transf",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:2999,Security,secur,security,2999,"The key of the attack is to call this with `untrusted_offset_from_caller` that; is far outside of the bounds when the branch predictor will predict that it; will be in-bounds. In that case, the body of the `if` will be executed; speculatively, and may read secret data into `value` and leak it via a; cache-timing side channel when a dependent access is made to populate `value2`. ## High Level Mitigation Approach. While several approaches are being actively pursued to mitigate specific; branches and/or loads inside especially risky software (most notably various OS; kernels), these approaches require manual and/or static analysis aided auditing; of code and explicit source changes to apply the mitigation. They are unlikely; to scale well to large applications. We are proposing a comprehensive; mitigation approach that would apply automatically across an entire program; rather than through manual changes to the code. While this is likely to have a; high performance cost, some applications may be in a good position to take this; performance / security tradeoff. The specific technique we propose is to cause loads to be checked using; branchless code to ensure that they are executing along a valid control flow; path. Consider the following C-pseudo-code representing the core idea of a; predicate guarding potentially invalid loads:; ```; void leak(int data);; void example(int* pointer1, int* pointer2) {; if (condition) {; // ... lots of code ...; leak(*pointer1);; } else {; // ... more code ...; leak(*pointer2);; }; }; ```. This would get transformed into something resembling the following:; ```; uintptr_t all_ones_mask = std::numerical_limits<uintptr_t>::max();; uintptr_t all_zeros_mask = 0;; void leak(int data);; void example(int* pointer1, int* pointer2) {; uintptr_t predicate_state = all_ones_mask;; if (condition) {; // Assuming ?: is implemented using branchless logic...; predicate_state = !condition ? all_zeros_mask : predicate_state;; // ... lots of code ...; //; //",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:5751,Security,attack,attacker,5751,"d to not hold secrets, see below for detailed limitations). This; approach only requires the underlying hardware have a way to implement a; branchless and unpredicted conditional update of a register's value. All modern; architectures have support for this, and in fact such support is necessary to; correctly implement constant time cryptographic primitives. Crucial properties of this approach:; * It is not preventing any particular side-channel from working. This is; important as there are an unknown number of potential side channels and we; expect to continue discovering more. Instead, it prevents the observation of; secret data in the first place.; * It accumulates the predicate state, protecting even in the face of nested; *correctly* predicted control flows.; * It passes this predicate state across function boundaries to provide; [interprocedural protection](#interprocedural-checking).; * When hardening the address of a load, it uses a *destructive* or; *non-reversible* modification of the address to prevent an attacker from; reversing the check using attacker-controlled inputs.; * It does not completely block speculative execution, and merely prevents; *mis*-speculated paths from leaking secrets from memory (and stalls; speculation until this can be determined).; * It is completely general and makes no fundamental assumptions about the; underlying architecture other than the ability to do branchless conditional; data updates and a lack of value prediction.; * It does not require programmers to identify all possible secret data using; static source code annotations or code vulnerable to a variant #1 style; attack. Limitations of this approach:; * It requires re-compiling source code to insert hardening instruction; sequences. Only software compiled in this mode is protected.; * The performance is heavily dependent on a particular architecture's; implementation strategy. We outline a potential x86 implementation below and; characterize its performance.; * It does ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:5792,Security,attack,attacker-controlled,5792,"d to not hold secrets, see below for detailed limitations). This; approach only requires the underlying hardware have a way to implement a; branchless and unpredicted conditional update of a register's value. All modern; architectures have support for this, and in fact such support is necessary to; correctly implement constant time cryptographic primitives. Crucial properties of this approach:; * It is not preventing any particular side-channel from working. This is; important as there are an unknown number of potential side channels and we; expect to continue discovering more. Instead, it prevents the observation of; secret data in the first place.; * It accumulates the predicate state, protecting even in the face of nested; *correctly* predicted control flows.; * It passes this predicate state across function boundaries to provide; [interprocedural protection](#interprocedural-checking).; * When hardening the address of a load, it uses a *destructive* or; *non-reversible* modification of the address to prevent an attacker from; reversing the check using attacker-controlled inputs.; * It does not completely block speculative execution, and merely prevents; *mis*-speculated paths from leaking secrets from memory (and stalls; speculation until this can be determined).; * It is completely general and makes no fundamental assumptions about the; underlying architecture other than the ability to do branchless conditional; data updates and a lack of value prediction.; * It does not require programmers to identify all possible secret data using; static source code annotations or code vulnerable to a variant #1 style; attack. Limitations of this approach:; * It requires re-compiling source code to insert hardening instruction; sequences. Only software compiled in this mode is protected.; * The performance is heavily dependent on a particular architecture's; implementation strategy. We outline a potential x86 implementation below and; characterize its performance.; * It does ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:6358,Security,attack,attack,6358,"e discovering more. Instead, it prevents the observation of; secret data in the first place.; * It accumulates the predicate state, protecting even in the face of nested; *correctly* predicted control flows.; * It passes this predicate state across function boundaries to provide; [interprocedural protection](#interprocedural-checking).; * When hardening the address of a load, it uses a *destructive* or; *non-reversible* modification of the address to prevent an attacker from; reversing the check using attacker-controlled inputs.; * It does not completely block speculative execution, and merely prevents; *mis*-speculated paths from leaking secrets from memory (and stalls; speculation until this can be determined).; * It is completely general and makes no fundamental assumptions about the; underlying architecture other than the ability to do branchless conditional; data updates and a lack of value prediction.; * It does not require programmers to identify all possible secret data using; static source code annotations or code vulnerable to a variant #1 style; attack. Limitations of this approach:; * It requires re-compiling source code to insert hardening instruction; sequences. Only software compiled in this mode is protected.; * The performance is heavily dependent on a particular architecture's; implementation strategy. We outline a potential x86 implementation below and; characterize its performance.; * It does not defend against secret data already loaded from memory and; residing in registers or leaked through other side-channels in; non-speculative execution. Code dealing with this, e.g cryptographic; routines, already uses constant-time algorithms and code to prevent; side-channels. Such code should also scrub registers of secret data following; [these; guidelines](https://github.com/HACS-workshop/spectre-mitigations/blob/master/crypto_guidelines.md).; * To achieve reasonable performance, many loads may not be checked, such as; those with compile-time fixed add",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:7320,Security,access,accesses,7320,"riant #1 style; attack. Limitations of this approach:; * It requires re-compiling source code to insert hardening instruction; sequences. Only software compiled in this mode is protected.; * The performance is heavily dependent on a particular architecture's; implementation strategy. We outline a potential x86 implementation below and; characterize its performance.; * It does not defend against secret data already loaded from memory and; residing in registers or leaked through other side-channels in; non-speculative execution. Code dealing with this, e.g cryptographic; routines, already uses constant-time algorithms and code to prevent; side-channels. Such code should also scrub registers of secret data following; [these; guidelines](https://github.com/HACS-workshop/spectre-mitigations/blob/master/crypto_guidelines.md).; * To achieve reasonable performance, many loads may not be checked, such as; those with compile-time fixed addresses. This primarily consists of accesses; at compile-time constant offsets of global and local variables. Code which; needs this protection and intentionally stores secret data must ensure the; memory regions used for secret data are necessarily dynamic mappings or heap; allocations. This is an area which can be tuned to provide more comprehensive; protection at the cost of performance.; * [Hardened loads](#hardening-the-address-of-the-load) may still load data from; _valid_ addresses if not _attacker-controlled_ addresses. To prevent these; from reading secret data, the low 2gb of the address space and 2gb above and; below any executable pages should be protected. Credit:; * The core idea of tracing misspeculation through data and marking pointers to; block misspeculated loads was developed as part of a HACS 2018 discussion; between Chandler Carruth, Paul Kocher, Thomas Pornin, and several other; individuals.; * Core idea of masking out loaded bits was part of the original mitigation; suggested by Jann Horn when these attacks were reporte",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:8323,Security,attack,attacks,8323,"xed addresses. This primarily consists of accesses; at compile-time constant offsets of global and local variables. Code which; needs this protection and intentionally stores secret data must ensure the; memory regions used for secret data are necessarily dynamic mappings or heap; allocations. This is an area which can be tuned to provide more comprehensive; protection at the cost of performance.; * [Hardened loads](#hardening-the-address-of-the-load) may still load data from; _valid_ addresses if not _attacker-controlled_ addresses. To prevent these; from reading secret data, the low 2gb of the address space and 2gb above and; below any executable pages should be protected. Credit:; * The core idea of tracing misspeculation through data and marking pointers to; block misspeculated loads was developed as part of a HACS 2018 discussion; between Chandler Carruth, Paul Kocher, Thomas Pornin, and several other; individuals.; * Core idea of masking out loaded bits was part of the original mitigation; suggested by Jann Horn when these attacks were reported. ### Indirect Branches, Calls, and Returns. It is possible to attack control flow other than conditional branches with; variant #1 style mispredictions.; * A prediction towards a hot call target of a virtual method can lead to it; being speculatively executed when an expected type is used (often called; ""type confusion"").; * A hot case may be speculatively executed due to prediction instead of the; correct case for a switch statement implemented as a jump table.; * A hot common return address may be predicted incorrectly when returning from; a function. These code patterns are also vulnerable to Spectre variant #2, and as such are; best mitigated with a; [retpoline](https://support.google.com/faqs/answer/7625886) on x86 platforms.; When a mitigation technique like retpoline is used, speculation simply cannot; proceed through an indirect control flow edge (or it cannot be mispredicted in; the case of a filled RSB) and so",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:8407,Security,attack,attack,8407,"lly stores secret data must ensure the; memory regions used for secret data are necessarily dynamic mappings or heap; allocations. This is an area which can be tuned to provide more comprehensive; protection at the cost of performance.; * [Hardened loads](#hardening-the-address-of-the-load) may still load data from; _valid_ addresses if not _attacker-controlled_ addresses. To prevent these; from reading secret data, the low 2gb of the address space and 2gb above and; below any executable pages should be protected. Credit:; * The core idea of tracing misspeculation through data and marking pointers to; block misspeculated loads was developed as part of a HACS 2018 discussion; between Chandler Carruth, Paul Kocher, Thomas Pornin, and several other; individuals.; * Core idea of masking out loaded bits was part of the original mitigation; suggested by Jann Horn when these attacks were reported. ### Indirect Branches, Calls, and Returns. It is possible to attack control flow other than conditional branches with; variant #1 style mispredictions.; * A prediction towards a hot call target of a virtual method can lead to it; being speculatively executed when an expected type is used (often called; ""type confusion"").; * A hot case may be speculatively executed due to prediction instead of the; correct case for a switch statement implemented as a jump table.; * A hot common return address may be predicted incorrectly when returning from; a function. These code patterns are also vulnerable to Spectre variant #2, and as such are; best mitigated with a; [retpoline](https://support.google.com/faqs/answer/7625886) on x86 platforms.; When a mitigation technique like retpoline is used, speculation simply cannot; proceed through an indirect control flow edge (or it cannot be mispredicted in; the case of a filled RSB) and so it is also protected from variant #1 style; attacks. However, some architectures, micro-architectures, or vendors do not; employ the retpoline mitigation, and on fu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:9323,Security,attack,attacks,9323,"ls.; * Core idea of masking out loaded bits was part of the original mitigation; suggested by Jann Horn when these attacks were reported. ### Indirect Branches, Calls, and Returns. It is possible to attack control flow other than conditional branches with; variant #1 style mispredictions.; * A prediction towards a hot call target of a virtual method can lead to it; being speculatively executed when an expected type is used (often called; ""type confusion"").; * A hot case may be speculatively executed due to prediction instead of the; correct case for a switch statement implemented as a jump table.; * A hot common return address may be predicted incorrectly when returning from; a function. These code patterns are also vulnerable to Spectre variant #2, and as such are; best mitigated with a; [retpoline](https://support.google.com/faqs/answer/7625886) on x86 platforms.; When a mitigation technique like retpoline is used, speculation simply cannot; proceed through an indirect control flow edge (or it cannot be mispredicted in; the case of a filled RSB) and so it is also protected from variant #1 style; attacks. However, some architectures, micro-architectures, or vendors do not; employ the retpoline mitigation, and on future x86 hardware (both Intel and; AMD) it is expected to become unnecessary due to hardware-based mitigation. When not using a retpoline, these edges will need independent protection from; variant #1 style attacks. The analogous approach to that used for conditional; control flow should work:; ```; uintptr_t all_ones_mask = std::numerical_limits<uintptr_t>::max();; uintptr_t all_zeros_mask = 0;; void leak(int data);; void example(int* pointer1, int* pointer2) {; uintptr_t predicate_state = all_ones_mask;; switch (condition) {; case 0:; // Assuming ?: is implemented using branchless logic...; predicate_state = (condition != 0) ? all_zeros_mask : predicate_state;; // ... lots of code ...; //; // Harden the pointer so it can't be loaded; pointer1 &= predica",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:9650,Security,attack,attacks,9650,"when an expected type is used (often called; ""type confusion"").; * A hot case may be speculatively executed due to prediction instead of the; correct case for a switch statement implemented as a jump table.; * A hot common return address may be predicted incorrectly when returning from; a function. These code patterns are also vulnerable to Spectre variant #2, and as such are; best mitigated with a; [retpoline](https://support.google.com/faqs/answer/7625886) on x86 platforms.; When a mitigation technique like retpoline is used, speculation simply cannot; proceed through an indirect control flow edge (or it cannot be mispredicted in; the case of a filled RSB) and so it is also protected from variant #1 style; attacks. However, some architectures, micro-architectures, or vendors do not; employ the retpoline mitigation, and on future x86 hardware (both Intel and; AMD) it is expected to become unnecessary due to hardware-based mitigation. When not using a retpoline, these edges will need independent protection from; variant #1 style attacks. The analogous approach to that used for conditional; control flow should work:; ```; uintptr_t all_ones_mask = std::numerical_limits<uintptr_t>::max();; uintptr_t all_zeros_mask = 0;; void leak(int data);; void example(int* pointer1, int* pointer2) {; uintptr_t predicate_state = all_ones_mask;; switch (condition) {; case 0:; // Assuming ?: is implemented using branchless logic...; predicate_state = (condition != 0) ? all_zeros_mask : predicate_state;; // ... lots of code ...; //; // Harden the pointer so it can't be loaded; pointer1 &= predicate_state;; leak(*pointer1);; break;. case 1:; predicate_state = (condition != 1) ? all_zeros_mask : predicate_state;; // ... more code ...; //; // Alternative: Harden the loaded value; int value2 = *pointer2 & predicate_state;; leak(value2);; break;. // ...; }; }; ```. The core idea remains the same: validate the control flow using data-flow and; use that validation to check that loads cannot le",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:10510,Security,validat,validate,10510," using a retpoline, these edges will need independent protection from; variant #1 style attacks. The analogous approach to that used for conditional; control flow should work:; ```; uintptr_t all_ones_mask = std::numerical_limits<uintptr_t>::max();; uintptr_t all_zeros_mask = 0;; void leak(int data);; void example(int* pointer1, int* pointer2) {; uintptr_t predicate_state = all_ones_mask;; switch (condition) {; case 0:; // Assuming ?: is implemented using branchless logic...; predicate_state = (condition != 0) ? all_zeros_mask : predicate_state;; // ... lots of code ...; //; // Harden the pointer so it can't be loaded; pointer1 &= predicate_state;; leak(*pointer1);; break;. case 1:; predicate_state = (condition != 1) ? all_zeros_mask : predicate_state;; // ... more code ...; //; // Alternative: Harden the loaded value; int value2 = *pointer2 & predicate_state;; leak(value2);; break;. // ...; }; }; ```. The core idea remains the same: validate the control flow using data-flow and; use that validation to check that loads cannot leak information along; misspeculated paths. Typically this involves passing the desired target of such; control flow across the edge and checking that it is correct afterwards. Note; that while it is tempting to think that this mitigates variant #2 attacks, it; does not. Those attacks go to arbitrary gadgets that don't include the checks. ### Variant #1.1 and #1.2 attacks: ""Bounds Check Bypass Store"". Beyond the core variant #1 attack, there are techniques to extend this attack.; The primary technique is known as ""Bounds Check Bypass Store"" and is discussed; in this research paper: https://people.csail.mit.edu/vlk/spectre11.pdf. We will analyze these two variants independently. First, variant #1.1 works by; speculatively storing over the return address after a bounds check bypass. This; speculative store then ends up being used by the CPU during speculative; execution of the return, potentially directing speculative execution to; arbitrary gadg",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:10566,Security,validat,validation,10566," using a retpoline, these edges will need independent protection from; variant #1 style attacks. The analogous approach to that used for conditional; control flow should work:; ```; uintptr_t all_ones_mask = std::numerical_limits<uintptr_t>::max();; uintptr_t all_zeros_mask = 0;; void leak(int data);; void example(int* pointer1, int* pointer2) {; uintptr_t predicate_state = all_ones_mask;; switch (condition) {; case 0:; // Assuming ?: is implemented using branchless logic...; predicate_state = (condition != 0) ? all_zeros_mask : predicate_state;; // ... lots of code ...; //; // Harden the pointer so it can't be loaded; pointer1 &= predicate_state;; leak(*pointer1);; break;. case 1:; predicate_state = (condition != 1) ? all_zeros_mask : predicate_state;; // ... more code ...; //; // Alternative: Harden the loaded value; int value2 = *pointer2 & predicate_state;; leak(value2);; break;. // ...; }; }; ```. The core idea remains the same: validate the control flow using data-flow and; use that validation to check that loads cannot leak information along; misspeculated paths. Typically this involves passing the desired target of such; control flow across the edge and checking that it is correct afterwards. Note; that while it is tempting to think that this mitigates variant #2 attacks, it; does not. Those attacks go to arbitrary gadgets that don't include the checks. ### Variant #1.1 and #1.2 attacks: ""Bounds Check Bypass Store"". Beyond the core variant #1 attack, there are techniques to extend this attack.; The primary technique is known as ""Bounds Check Bypass Store"" and is discussed; in this research paper: https://people.csail.mit.edu/vlk/spectre11.pdf. We will analyze these two variants independently. First, variant #1.1 works by; speculatively storing over the return address after a bounds check bypass. This; speculative store then ends up being used by the CPU during speculative; execution of the return, potentially directing speculative execution to; arbitrary gadg",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:10854,Security,attack,attacks,10854,"ros_mask = 0;; void leak(int data);; void example(int* pointer1, int* pointer2) {; uintptr_t predicate_state = all_ones_mask;; switch (condition) {; case 0:; // Assuming ?: is implemented using branchless logic...; predicate_state = (condition != 0) ? all_zeros_mask : predicate_state;; // ... lots of code ...; //; // Harden the pointer so it can't be loaded; pointer1 &= predicate_state;; leak(*pointer1);; break;. case 1:; predicate_state = (condition != 1) ? all_zeros_mask : predicate_state;; // ... more code ...; //; // Alternative: Harden the loaded value; int value2 = *pointer2 & predicate_state;; leak(value2);; break;. // ...; }; }; ```. The core idea remains the same: validate the control flow using data-flow and; use that validation to check that loads cannot leak information along; misspeculated paths. Typically this involves passing the desired target of such; control flow across the edge and checking that it is correct afterwards. Note; that while it is tempting to think that this mitigates variant #2 attacks, it; does not. Those attacks go to arbitrary gadgets that don't include the checks. ### Variant #1.1 and #1.2 attacks: ""Bounds Check Bypass Store"". Beyond the core variant #1 attack, there are techniques to extend this attack.; The primary technique is known as ""Bounds Check Bypass Store"" and is discussed; in this research paper: https://people.csail.mit.edu/vlk/spectre11.pdf. We will analyze these two variants independently. First, variant #1.1 works by; speculatively storing over the return address after a bounds check bypass. This; speculative store then ends up being used by the CPU during speculative; execution of the return, potentially directing speculative execution to; arbitrary gadgets in the binary. Let's look at an example.; ```; unsigned char local_buffer[4];; unsigned char *untrusted_data_from_caller = ...;; unsigned long untrusted_size_from_caller = ...;; if (untrusted_size_from_caller < sizeof(local_buffer)) {; // Speculative execution e",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:10883,Security,attack,attacks,10883," uintptr_t predicate_state = all_ones_mask;; switch (condition) {; case 0:; // Assuming ?: is implemented using branchless logic...; predicate_state = (condition != 0) ? all_zeros_mask : predicate_state;; // ... lots of code ...; //; // Harden the pointer so it can't be loaded; pointer1 &= predicate_state;; leak(*pointer1);; break;. case 1:; predicate_state = (condition != 1) ? all_zeros_mask : predicate_state;; // ... more code ...; //; // Alternative: Harden the loaded value; int value2 = *pointer2 & predicate_state;; leak(value2);; break;. // ...; }; }; ```. The core idea remains the same: validate the control flow using data-flow and; use that validation to check that loads cannot leak information along; misspeculated paths. Typically this involves passing the desired target of such; control flow across the edge and checking that it is correct afterwards. Note; that while it is tempting to think that this mitigates variant #2 attacks, it; does not. Those attacks go to arbitrary gadgets that don't include the checks. ### Variant #1.1 and #1.2 attacks: ""Bounds Check Bypass Store"". Beyond the core variant #1 attack, there are techniques to extend this attack.; The primary technique is known as ""Bounds Check Bypass Store"" and is discussed; in this research paper: https://people.csail.mit.edu/vlk/spectre11.pdf. We will analyze these two variants independently. First, variant #1.1 works by; speculatively storing over the return address after a bounds check bypass. This; speculative store then ends up being used by the CPU during speculative; execution of the return, potentially directing speculative execution to; arbitrary gadgets in the binary. Let's look at an example.; ```; unsigned char local_buffer[4];; unsigned char *untrusted_data_from_caller = ...;; unsigned long untrusted_size_from_caller = ...;; if (untrusted_size_from_caller < sizeof(local_buffer)) {; // Speculative execution enters here with a too-large size.; memcpy(local_buffer, untrusted_data_from_caller",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:10972,Security,attack,attacks,10972,"Assuming ?: is implemented using branchless logic...; predicate_state = (condition != 0) ? all_zeros_mask : predicate_state;; // ... lots of code ...; //; // Harden the pointer so it can't be loaded; pointer1 &= predicate_state;; leak(*pointer1);; break;. case 1:; predicate_state = (condition != 1) ? all_zeros_mask : predicate_state;; // ... more code ...; //; // Alternative: Harden the loaded value; int value2 = *pointer2 & predicate_state;; leak(value2);; break;. // ...; }; }; ```. The core idea remains the same: validate the control flow using data-flow and; use that validation to check that loads cannot leak information along; misspeculated paths. Typically this involves passing the desired target of such; control flow across the edge and checking that it is correct afterwards. Note; that while it is tempting to think that this mitigates variant #2 attacks, it; does not. Those attacks go to arbitrary gadgets that don't include the checks. ### Variant #1.1 and #1.2 attacks: ""Bounds Check Bypass Store"". Beyond the core variant #1 attack, there are techniques to extend this attack.; The primary technique is known as ""Bounds Check Bypass Store"" and is discussed; in this research paper: https://people.csail.mit.edu/vlk/spectre11.pdf. We will analyze these two variants independently. First, variant #1.1 works by; speculatively storing over the return address after a bounds check bypass. This; speculative store then ends up being used by the CPU during speculative; execution of the return, potentially directing speculative execution to; arbitrary gadgets in the binary. Let's look at an example.; ```; unsigned char local_buffer[4];; unsigned char *untrusted_data_from_caller = ...;; unsigned long untrusted_size_from_caller = ...;; if (untrusted_size_from_caller < sizeof(local_buffer)) {; // Speculative execution enters here with a too-large size.; memcpy(local_buffer, untrusted_data_from_caller,; untrusted_size_from_caller);; // The stack has now been smashed, writing an ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:11037,Security,attack,attack,11037,"cate_state = (condition != 0) ? all_zeros_mask : predicate_state;; // ... lots of code ...; //; // Harden the pointer so it can't be loaded; pointer1 &= predicate_state;; leak(*pointer1);; break;. case 1:; predicate_state = (condition != 1) ? all_zeros_mask : predicate_state;; // ... more code ...; //; // Alternative: Harden the loaded value; int value2 = *pointer2 & predicate_state;; leak(value2);; break;. // ...; }; }; ```. The core idea remains the same: validate the control flow using data-flow and; use that validation to check that loads cannot leak information along; misspeculated paths. Typically this involves passing the desired target of such; control flow across the edge and checking that it is correct afterwards. Note; that while it is tempting to think that this mitigates variant #2 attacks, it; does not. Those attacks go to arbitrary gadgets that don't include the checks. ### Variant #1.1 and #1.2 attacks: ""Bounds Check Bypass Store"". Beyond the core variant #1 attack, there are techniques to extend this attack.; The primary technique is known as ""Bounds Check Bypass Store"" and is discussed; in this research paper: https://people.csail.mit.edu/vlk/spectre11.pdf. We will analyze these two variants independently. First, variant #1.1 works by; speculatively storing over the return address after a bounds check bypass. This; speculative store then ends up being used by the CPU during speculative; execution of the return, potentially directing speculative execution to; arbitrary gadgets in the binary. Let's look at an example.; ```; unsigned char local_buffer[4];; unsigned char *untrusted_data_from_caller = ...;; unsigned long untrusted_size_from_caller = ...;; if (untrusted_size_from_caller < sizeof(local_buffer)) {; // Speculative execution enters here with a too-large size.; memcpy(local_buffer, untrusted_data_from_caller,; untrusted_size_from_caller);; // The stack has now been smashed, writing an attacker-controlled; // address over the return address.; m",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:11081,Security,attack,attack,11081,"cate_state = (condition != 0) ? all_zeros_mask : predicate_state;; // ... lots of code ...; //; // Harden the pointer so it can't be loaded; pointer1 &= predicate_state;; leak(*pointer1);; break;. case 1:; predicate_state = (condition != 1) ? all_zeros_mask : predicate_state;; // ... more code ...; //; // Alternative: Harden the loaded value; int value2 = *pointer2 & predicate_state;; leak(value2);; break;. // ...; }; }; ```. The core idea remains the same: validate the control flow using data-flow and; use that validation to check that loads cannot leak information along; misspeculated paths. Typically this involves passing the desired target of such; control flow across the edge and checking that it is correct afterwards. Note; that while it is tempting to think that this mitigates variant #2 attacks, it; does not. Those attacks go to arbitrary gadgets that don't include the checks. ### Variant #1.1 and #1.2 attacks: ""Bounds Check Bypass Store"". Beyond the core variant #1 attack, there are techniques to extend this attack.; The primary technique is known as ""Bounds Check Bypass Store"" and is discussed; in this research paper: https://people.csail.mit.edu/vlk/spectre11.pdf. We will analyze these two variants independently. First, variant #1.1 works by; speculatively storing over the return address after a bounds check bypass. This; speculative store then ends up being used by the CPU during speculative; execution of the return, potentially directing speculative execution to; arbitrary gadgets in the binary. Let's look at an example.; ```; unsigned char local_buffer[4];; unsigned char *untrusted_data_from_caller = ...;; unsigned long untrusted_size_from_caller = ...;; if (untrusted_size_from_caller < sizeof(local_buffer)) {; // Speculative execution enters here with a too-large size.; memcpy(local_buffer, untrusted_data_from_caller,; untrusted_size_from_caller);; // The stack has now been smashed, writing an attacker-controlled; // address over the return address.; m",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:11990,Security,attack,attacker-controlled,11990,"ant #1.1 and #1.2 attacks: ""Bounds Check Bypass Store"". Beyond the core variant #1 attack, there are techniques to extend this attack.; The primary technique is known as ""Bounds Check Bypass Store"" and is discussed; in this research paper: https://people.csail.mit.edu/vlk/spectre11.pdf. We will analyze these two variants independently. First, variant #1.1 works by; speculatively storing over the return address after a bounds check bypass. This; speculative store then ends up being used by the CPU during speculative; execution of the return, potentially directing speculative execution to; arbitrary gadgets in the binary. Let's look at an example.; ```; unsigned char local_buffer[4];; unsigned char *untrusted_data_from_caller = ...;; unsigned long untrusted_size_from_caller = ...;; if (untrusted_size_from_caller < sizeof(local_buffer)) {; // Speculative execution enters here with a too-large size.; memcpy(local_buffer, untrusted_data_from_caller,; untrusted_size_from_caller);; // The stack has now been smashed, writing an attacker-controlled; // address over the return address.; minor_processing(local_buffer);; return;; // Control will speculate to the attacker-written address.; }; ```. However, this can be mitigated by hardening the load of the return address just; like any other load. This is sometimes complicated because x86 for example; *implicitly* loads the return address off the stack. However, the; implementation technique below is specifically designed to mitigate this; implicit load by using the stack pointer to communicate misspeculation between; functions. This additionally causes a misspeculation to have an invalid stack; pointer and never be able to read the speculatively stored return address. See; the detailed discussion below. For variant #1.2, the attacker speculatively stores into the vtable or jump; table used to implement an indirect call or indirect jump. Because this is; speculative, this will often be possible even when these are stored in; rea",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:12123,Security,attack,attacker-written,12123,"mary technique is known as ""Bounds Check Bypass Store"" and is discussed; in this research paper: https://people.csail.mit.edu/vlk/spectre11.pdf. We will analyze these two variants independently. First, variant #1.1 works by; speculatively storing over the return address after a bounds check bypass. This; speculative store then ends up being used by the CPU during speculative; execution of the return, potentially directing speculative execution to; arbitrary gadgets in the binary. Let's look at an example.; ```; unsigned char local_buffer[4];; unsigned char *untrusted_data_from_caller = ...;; unsigned long untrusted_size_from_caller = ...;; if (untrusted_size_from_caller < sizeof(local_buffer)) {; // Speculative execution enters here with a too-large size.; memcpy(local_buffer, untrusted_data_from_caller,; untrusted_size_from_caller);; // The stack has now been smashed, writing an attacker-controlled; // address over the return address.; minor_processing(local_buffer);; return;; // Control will speculate to the attacker-written address.; }; ```. However, this can be mitigated by hardening the load of the return address just; like any other load. This is sometimes complicated because x86 for example; *implicitly* loads the return address off the stack. However, the; implementation technique below is specifically designed to mitigate this; implicit load by using the stack pointer to communicate misspeculation between; functions. This additionally causes a misspeculation to have an invalid stack; pointer and never be able to read the speculatively stored return address. See; the detailed discussion below. For variant #1.2, the attacker speculatively stores into the vtable or jump; table used to implement an indirect call or indirect jump. Because this is; speculative, this will often be possible even when these are stored in; read-only pages. For example:; ```; class FancyObject : public BaseObject {; public:; void DoSomething() override;; };; void f(unsigned long attac",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:12748,Security,attack,attacker,12748,"; // Speculative execution enters here with a too-large size.; memcpy(local_buffer, untrusted_data_from_caller,; untrusted_size_from_caller);; // The stack has now been smashed, writing an attacker-controlled; // address over the return address.; minor_processing(local_buffer);; return;; // Control will speculate to the attacker-written address.; }; ```. However, this can be mitigated by hardening the load of the return address just; like any other load. This is sometimes complicated because x86 for example; *implicitly* loads the return address off the stack. However, the; implementation technique below is specifically designed to mitigate this; implicit load by using the stack pointer to communicate misspeculation between; functions. This additionally causes a misspeculation to have an invalid stack; pointer and never be able to read the speculatively stored return address. See; the detailed discussion below. For variant #1.2, the attacker speculatively stores into the vtable or jump; table used to implement an indirect call or indirect jump. Because this is; speculative, this will often be possible even when these are stored in; read-only pages. For example:; ```; class FancyObject : public BaseObject {; public:; void DoSomething() override;; };; void f(unsigned long attacker_offset, unsigned long attacker_data) {; FancyObject object = getMyObject();; unsigned long *arr[4] = getFourDataPointers();; if (attacker_offset < 4) {; // We have bypassed the bounds check speculatively.; unsigned long *data = arr[attacker_offset];; // Now we have computed a pointer inside of `object`, the vptr.; *data = attacker_data;; // The vptr points to the virtual table and we speculatively clobber that.; g(object); // Hand the object to some other routine.; }; }; // In another file, we call a method on the object.; void g(BaseObject &object) {; object.DoSomething();; // This speculatively calls the address stored over the vtable.; }; ```. Mitigating this requires hardening loads from",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:14410,Security,attack,attack,14410," we have computed a pointer inside of `object`, the vptr.; *data = attacker_data;; // The vptr points to the virtual table and we speculatively clobber that.; g(object); // Hand the object to some other routine.; }; }; // In another file, we call a method on the object.; void g(BaseObject &object) {; object.DoSomething();; // This speculatively calls the address stored over the vtable.; }; ```. Mitigating this requires hardening loads from these locations, or mitigating; the indirect call or indirect jump. Any of these are sufficient to block the; call or jump from using a speculatively stored value that has been read back. For both of these, using retpolines would be equally sufficient. One possible; hybrid approach is to use retpolines for indirect call and jump, while relying; on SLH to mitigate returns. Another approach that is sufficient for both of these is to harden all of the; speculative stores. However, as most stores aren't interesting and don't; inherently leak data, this is expected to be prohibitively expensive given the; attack it is defending against. ## Implementation Details. There are a number of complex details impacting the implementation of this; technique, both on a particular architecture and within a particular compiler.; We discuss proposed implementation techniques for the x86 architecture and the; LLVM compiler. These are primarily to serve as an example, as other; implementation techniques are very possible. ### x86 Implementation Details. On the x86 platform we break down the implementation into three core; components: accumulating the predicate state through the control flow graph,; checking the loads, and checking control transfers between procedures. #### Accumulating Predicate State. Consider baseline x86 instructions like the following, which test three; conditions and if all pass, loads data from memory and potentially leaks it; through some side channel:; ```; # %bb.0: # %entry; pushq %rax; testl %edi, %edi; jne .LBB0_4; # %bb.1:",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:28124,Security,attack,attacker,28124," right by at least the number of original bits using the BMI2; `shrx` instruction:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate 32 bits of data.; shrxq %rax, %rdi, %rdi # Shift out all 32 bits loaded.; ```. Because on x86 the zero-extend is free, this can efficiently harden the loaded; value. ##### Hardening the address of the load. When hardening the loaded value is inapplicable, most often because the; instruction directly leaks information (like `cmp` or `jmpq`), we switch to; hardening the _address_ of the load instead of the loaded value. This avoids; increasing register pressure by unfolding the load or paying some other high; cost. To understand how this works in practice, we need to examine the exact; semantics of the x86 addressing modes which, in its fully general form, looks; like `(%base,%index,scale)offset`. Here `%base` and `%index` are 64-bit; registers that can potentially be any value, and may be attacker controlled,; and `scale` and `offset` are fixed immediate values. `scale` must be `1`, `2`,; `4`, or `8`, and `offset` can be any 32-bit sign extended value. The exact; computation performed to find the address is then: `%base + (scale * %index) +; offset` under 64-bit 2's complement modular arithmetic. One issue with this approach is that, after hardening, the `%base + (scale *; %index)` subexpression will compute a value near zero (`-1 + (scale * -1)`) and; then a large, positive `offset` will index into memory within the first two; gigabytes of address space. While these offsets are not attacker controlled,; the attacker could chose to attack a load which happens to have the desired; offset and then successfully read memory in that region. This significantly; raises the burden on the attacker and limits the scope of attack but does not; eliminate it. To fully close the attack we must work with the operating system; to preclude mapping memory in the low two gigabyt",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:28730,Security,attack,attacker,28730,"nfolding the load or paying some other high; cost. To understand how this works in practice, we need to examine the exact; semantics of the x86 addressing modes which, in its fully general form, looks; like `(%base,%index,scale)offset`. Here `%base` and `%index` are 64-bit; registers that can potentially be any value, and may be attacker controlled,; and `scale` and `offset` are fixed immediate values. `scale` must be `1`, `2`,; `4`, or `8`, and `offset` can be any 32-bit sign extended value. The exact; computation performed to find the address is then: `%base + (scale * %index) +; offset` under 64-bit 2's complement modular arithmetic. One issue with this approach is that, after hardening, the `%base + (scale *; %index)` subexpression will compute a value near zero (`-1 + (scale * -1)`) and; then a large, positive `offset` will index into memory within the first two; gigabytes of address space. While these offsets are not attacker controlled,; the attacker could chose to attack a load which happens to have the desired; offset and then successfully read memory in that region. This significantly; raises the burden on the attacker and limits the scope of attack but does not; eliminate it. To fully close the attack we must work with the operating system; to preclude mapping memory in the low two gigabytes of address space. ###### 64-bit load checking instructions. We can use the following instruction sequences to check loads. We set up `%r8`; in these examples to hold the special value of `-1` which will be `cmov`ed over; `%rax` in misspeculated paths. Single register addressing mode:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rsi # Mask the pointer if misspeculating.; movl (%rsi), %edi; ```. Two register addressing mode:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rsi # Mask the pointer if misspeculating.; orq %rax, %rcx # Mask the index if misspeculating.;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:28756,Security,attack,attacker,28756,"nfolding the load or paying some other high; cost. To understand how this works in practice, we need to examine the exact; semantics of the x86 addressing modes which, in its fully general form, looks; like `(%base,%index,scale)offset`. Here `%base` and `%index` are 64-bit; registers that can potentially be any value, and may be attacker controlled,; and `scale` and `offset` are fixed immediate values. `scale` must be `1`, `2`,; `4`, or `8`, and `offset` can be any 32-bit sign extended value. The exact; computation performed to find the address is then: `%base + (scale * %index) +; offset` under 64-bit 2's complement modular arithmetic. One issue with this approach is that, after hardening, the `%base + (scale *; %index)` subexpression will compute a value near zero (`-1 + (scale * -1)`) and; then a large, positive `offset` will index into memory within the first two; gigabytes of address space. While these offsets are not attacker controlled,; the attacker could chose to attack a load which happens to have the desired; offset and then successfully read memory in that region. This significantly; raises the burden on the attacker and limits the scope of attack but does not; eliminate it. To fully close the attack we must work with the operating system; to preclude mapping memory in the low two gigabytes of address space. ###### 64-bit load checking instructions. We can use the following instruction sequences to check loads. We set up `%r8`; in these examples to hold the special value of `-1` which will be `cmov`ed over; `%rax` in misspeculated paths. Single register addressing mode:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rsi # Mask the pointer if misspeculating.; movl (%rsi), %edi; ```. Two register addressing mode:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rsi # Mask the pointer if misspeculating.; orq %rax, %rcx # Mask the index if misspeculating.;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:28780,Security,attack,attack,28780,"nfolding the load or paying some other high; cost. To understand how this works in practice, we need to examine the exact; semantics of the x86 addressing modes which, in its fully general form, looks; like `(%base,%index,scale)offset`. Here `%base` and `%index` are 64-bit; registers that can potentially be any value, and may be attacker controlled,; and `scale` and `offset` are fixed immediate values. `scale` must be `1`, `2`,; `4`, or `8`, and `offset` can be any 32-bit sign extended value. The exact; computation performed to find the address is then: `%base + (scale * %index) +; offset` under 64-bit 2's complement modular arithmetic. One issue with this approach is that, after hardening, the `%base + (scale *; %index)` subexpression will compute a value near zero (`-1 + (scale * -1)`) and; then a large, positive `offset` will index into memory within the first two; gigabytes of address space. While these offsets are not attacker controlled,; the attacker could chose to attack a load which happens to have the desired; offset and then successfully read memory in that region. This significantly; raises the burden on the attacker and limits the scope of attack but does not; eliminate it. To fully close the attack we must work with the operating system; to preclude mapping memory in the low two gigabytes of address space. ###### 64-bit load checking instructions. We can use the following instruction sequences to check loads. We set up `%r8`; in these examples to hold the special value of `-1` which will be `cmov`ed over; `%rax` in misspeculated paths. Single register addressing mode:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rsi # Mask the pointer if misspeculating.; movl (%rsi), %edi; ```. Two register addressing mode:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rsi # Mask the pointer if misspeculating.; orq %rax, %rcx # Mask the index if misspeculating.;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:28931,Security,attack,attacker,28931,"essing modes which, in its fully general form, looks; like `(%base,%index,scale)offset`. Here `%base` and `%index` are 64-bit; registers that can potentially be any value, and may be attacker controlled,; and `scale` and `offset` are fixed immediate values. `scale` must be `1`, `2`,; `4`, or `8`, and `offset` can be any 32-bit sign extended value. The exact; computation performed to find the address is then: `%base + (scale * %index) +; offset` under 64-bit 2's complement modular arithmetic. One issue with this approach is that, after hardening, the `%base + (scale *; %index)` subexpression will compute a value near zero (`-1 + (scale * -1)`) and; then a large, positive `offset` will index into memory within the first two; gigabytes of address space. While these offsets are not attacker controlled,; the attacker could chose to attack a load which happens to have the desired; offset and then successfully read memory in that region. This significantly; raises the burden on the attacker and limits the scope of attack but does not; eliminate it. To fully close the attack we must work with the operating system; to preclude mapping memory in the low two gigabytes of address space. ###### 64-bit load checking instructions. We can use the following instruction sequences to check loads. We set up `%r8`; in these examples to hold the special value of `-1` which will be `cmov`ed over; `%rax` in misspeculated paths. Single register addressing mode:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rsi # Mask the pointer if misspeculating.; movl (%rsi), %edi; ```. Two register addressing mode:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rsi # Mask the pointer if misspeculating.; orq %rax, %rcx # Mask the index if misspeculating.; movl (%rsi,%rcx), %edi; ```. This will result in a negative address near zero or in `offset` wrapping the; address space back to a small positive ad",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:28964,Security,attack,attack,28964,"essing modes which, in its fully general form, looks; like `(%base,%index,scale)offset`. Here `%base` and `%index` are 64-bit; registers that can potentially be any value, and may be attacker controlled,; and `scale` and `offset` are fixed immediate values. `scale` must be `1`, `2`,; `4`, or `8`, and `offset` can be any 32-bit sign extended value. The exact; computation performed to find the address is then: `%base + (scale * %index) +; offset` under 64-bit 2's complement modular arithmetic. One issue with this approach is that, after hardening, the `%base + (scale *; %index)` subexpression will compute a value near zero (`-1 + (scale * -1)`) and; then a large, positive `offset` will index into memory within the first two; gigabytes of address space. While these offsets are not attacker controlled,; the attacker could chose to attack a load which happens to have the desired; offset and then successfully read memory in that region. This significantly; raises the burden on the attacker and limits the scope of attack but does not; eliminate it. To fully close the attack we must work with the operating system; to preclude mapping memory in the low two gigabytes of address space. ###### 64-bit load checking instructions. We can use the following instruction sequences to check loads. We set up `%r8`; in these examples to hold the special value of `-1` which will be `cmov`ed over; `%rax` in misspeculated paths. Single register addressing mode:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rsi # Mask the pointer if misspeculating.; movl (%rsi), %edi; ```. Two register addressing mode:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rsi # Mask the pointer if misspeculating.; orq %rax, %rcx # Mask the index if misspeculating.; movl (%rsi,%rcx), %edi; ```. This will result in a negative address near zero or in `offset` wrapping the; address space back to a small positive ad",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:29018,Security,attack,attack,29018,"; registers that can potentially be any value, and may be attacker controlled,; and `scale` and `offset` are fixed immediate values. `scale` must be `1`, `2`,; `4`, or `8`, and `offset` can be any 32-bit sign extended value. The exact; computation performed to find the address is then: `%base + (scale * %index) +; offset` under 64-bit 2's complement modular arithmetic. One issue with this approach is that, after hardening, the `%base + (scale *; %index)` subexpression will compute a value near zero (`-1 + (scale * -1)`) and; then a large, positive `offset` will index into memory within the first two; gigabytes of address space. While these offsets are not attacker controlled,; the attacker could chose to attack a load which happens to have the desired; offset and then successfully read memory in that region. This significantly; raises the burden on the attacker and limits the scope of attack but does not; eliminate it. To fully close the attack we must work with the operating system; to preclude mapping memory in the low two gigabytes of address space. ###### 64-bit load checking instructions. We can use the following instruction sequences to check loads. We set up `%r8`; in these examples to hold the special value of `-1` which will be `cmov`ed over; `%rax` in misspeculated paths. Single register addressing mode:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rsi # Mask the pointer if misspeculating.; movl (%rsi), %edi; ```. Two register addressing mode:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rsi # Mask the pointer if misspeculating.; orq %rax, %rcx # Mask the index if misspeculating.; movl (%rsi,%rcx), %edi; ```. This will result in a negative address near zero or in `offset` wrapping the; address space back to a small positive address. Small, negative addresses will; fault in user-mode for most operating systems, but targets which need the high; addre",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:30086,Security,access,accessible,30086,"operating system; to preclude mapping memory in the low two gigabytes of address space. ###### 64-bit load checking instructions. We can use the following instruction sequences to check loads. We set up `%r8`; in these examples to hold the special value of `-1` which will be `cmov`ed over; `%rax` in misspeculated paths. Single register addressing mode:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rsi # Mask the pointer if misspeculating.; movl (%rsi), %edi; ```. Two register addressing mode:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rsi # Mask the pointer if misspeculating.; orq %rax, %rcx # Mask the index if misspeculating.; movl (%rsi,%rcx), %edi; ```. This will result in a negative address near zero or in `offset` wrapping the; address space back to a small positive address. Small, negative addresses will; fault in user-mode for most operating systems, but targets which need the high; address space to be user accessible may need to adjust the exact sequence used; above. Additionally, the low addresses will need to be marked unreadable by the; OS to fully harden the load. ###### RIP-relative addressing is even easier to break. There is a common addressing mode idiom that is substantially harder to check:; addressing relative to the instruction pointer. We cannot change the value of; the instruction pointer register and so we have the harder problem of forcing; `%base + scale * %index + offset` to be an invalid address, by *only* changing; `%index`. The only advantage we have is that the attacker also cannot modify; `%base`. If we use the fast instruction sequence above, but only apply it to; the index, we will always access `%rip + (scale * -1) + offset`. If the; attacker can find a load which with this address happens to point to secret; data, then they can reach it. However, the loader and base libraries can also; simply refuse to map the heap, data se",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:30674,Security,attack,attacker,30674,"edicate state.; orq %rax, %rsi # Mask the pointer if misspeculating.; orq %rax, %rcx # Mask the index if misspeculating.; movl (%rsi,%rcx), %edi; ```. This will result in a negative address near zero or in `offset` wrapping the; address space back to a small positive address. Small, negative addresses will; fault in user-mode for most operating systems, but targets which need the high; address space to be user accessible may need to adjust the exact sequence used; above. Additionally, the low addresses will need to be marked unreadable by the; OS to fully harden the load. ###### RIP-relative addressing is even easier to break. There is a common addressing mode idiom that is substantially harder to check:; addressing relative to the instruction pointer. We cannot change the value of; the instruction pointer register and so we have the harder problem of forcing; `%base + scale * %index + offset` to be an invalid address, by *only* changing; `%index`. The only advantage we have is that the attacker also cannot modify; `%base`. If we use the fast instruction sequence above, but only apply it to; the index, we will always access `%rip + (scale * -1) + offset`. If the; attacker can find a load which with this address happens to point to secret; data, then they can reach it. However, the loader and base libraries can also; simply refuse to map the heap, data segments, or stack within 2gb of any of the; text in the program, much like it can reserve the low 2gb of address space. ###### The flag registers again make everything hard. Unfortunately, the technique of using `orq`-instructions has a serious flaw on; x86. The very thing that makes it easy to accumulate state, the flag registers; containing predicates, causes serious problems here because they may be alive; and used by the loading instruction or subsequent instructions. On x86, the; `orq` instruction **sets** the flags and will override anything already there.; This makes inserting them into the instruction stream ve",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:30807,Security,access,access,30807,"isspeculating.; movl (%rsi,%rcx), %edi; ```. This will result in a negative address near zero or in `offset` wrapping the; address space back to a small positive address. Small, negative addresses will; fault in user-mode for most operating systems, but targets which need the high; address space to be user accessible may need to adjust the exact sequence used; above. Additionally, the low addresses will need to be marked unreadable by the; OS to fully harden the load. ###### RIP-relative addressing is even easier to break. There is a common addressing mode idiom that is substantially harder to check:; addressing relative to the instruction pointer. We cannot change the value of; the instruction pointer register and so we have the harder problem of forcing; `%base + scale * %index + offset` to be an invalid address, by *only* changing; `%index`. The only advantage we have is that the attacker also cannot modify; `%base`. If we use the fast instruction sequence above, but only apply it to; the index, we will always access `%rip + (scale * -1) + offset`. If the; attacker can find a load which with this address happens to point to secret; data, then they can reach it. However, the loader and base libraries can also; simply refuse to map the heap, data segments, or stack within 2gb of any of the; text in the program, much like it can reserve the low 2gb of address space. ###### The flag registers again make everything hard. Unfortunately, the technique of using `orq`-instructions has a serious flaw on; x86. The very thing that makes it easy to accumulate state, the flag registers; containing predicates, causes serious problems here because they may be alive; and used by the loading instruction or subsequent instructions. On x86, the; `orq` instruction **sets** the flags and will override anything already there.; This makes inserting them into the instruction stream very hazardous.; Unfortunately, unlike when hardening the loaded value, we have no fallback here; and so we",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:30854,Security,attack,attacker,30854,"ddress space back to a small positive address. Small, negative addresses will; fault in user-mode for most operating systems, but targets which need the high; address space to be user accessible may need to adjust the exact sequence used; above. Additionally, the low addresses will need to be marked unreadable by the; OS to fully harden the load. ###### RIP-relative addressing is even easier to break. There is a common addressing mode idiom that is substantially harder to check:; addressing relative to the instruction pointer. We cannot change the value of; the instruction pointer register and so we have the harder problem of forcing; `%base + scale * %index + offset` to be an invalid address, by *only* changing; `%index`. The only advantage we have is that the attacker also cannot modify; `%base`. If we use the fast instruction sequence above, but only apply it to; the index, we will always access `%rip + (scale * -1) + offset`. If the; attacker can find a load which with this address happens to point to secret; data, then they can reach it. However, the loader and base libraries can also; simply refuse to map the heap, data segments, or stack within 2gb of any of the; text in the program, much like it can reserve the low 2gb of address space. ###### The flag registers again make everything hard. Unfortunately, the technique of using `orq`-instructions has a serious flaw on; x86. The very thing that makes it easy to accumulate state, the flag registers; containing predicates, causes serious problems here because they may be alive; and used by the loading instruction or subsequent instructions. On x86, the; `orq` instruction **sets** the flags and will override anything already there.; This makes inserting them into the instruction stream very hazardous.; Unfortunately, unlike when hardening the loaded value, we have no fallback here; and so we must have a fully general approach available. The first thing we must do when generating these sequences is try to analyze; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:35193,Security,access,accessing,35193,"; ```. This will collapse the register to zero or one, and everything but the offset; in the addressing mode to be less than or equal to 9. This means the full; address can only be guaranteed to be less than `(1 << 31) + 9`. The OS may wish; to protect an extra page of the low address space to account for this. ##### Optimizations. A very large portion of the cost for this approach comes from checking loads in; this way, so it is important to work to optimize this. However, beyond making; the instruction sequences to *apply* the checks efficient (for example by; avoiding `pushfq` and `popfq` sequences), the only significant optimization is; to check fewer loads without introducing a vulnerability. We apply several; techniques to accomplish that. ###### Don't check loads from compile-time constant stack offsets. We implement this optimization on x86 by skipping the checking of loads which; use a fixed frame pointer offset. The result of this optimization is that patterns like reloading a spilled; register or accessing a global field don't get checked. This is a very; significant performance win. ###### Don't check dependent loads. A core part of why this mitigation strategy works is that it establishes a; data-flow check on the loaded address. However, this means that if the address; itself was already loaded using a checked load, there is no need to check a; dependent load provided it is within the same basic block as the checked load,; and therefore has no additional predicates guarding it. Consider code like the; following:; ```; ... .LBB0_4: # %danger; movq (%rcx), %rdi; movl (%rdi), %edx; ```. This will get transformed into:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rcx # Mask the pointer if misspeculating.; movq (%rcx), %rdi # Hardened load.; movl (%rdi), %edx # Unhardened load due to dependent addr.; ```. This doesn't check the load through `%rdi` as that pointer is dependent on a; checked load already. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:36918,Security,secur,security,36918,"icate state.; orq %rax, %rcx # Mask the pointer if misspeculating.; movq (%rcx), %rdi # Hardened load.; movl (%rdi), %edx # Unhardened load due to dependent addr.; ```. This doesn't check the load through `%rdi` as that pointer is dependent on a; checked load already. ###### Protect large, load-heavy blocks with a single lfence. It may be worth using a single `lfence` instruction at the start of a block; which begins with a (very) large number of loads that require independent; protection *and* which require hardening the address of the load. However, this; is unlikely to be profitable in practice. The latency hit of the hardening; would need to exceed that of an `lfence` when *correctly* speculatively; executed. But in that case, the `lfence` cost is a complete loss of speculative; execution (at a minimum). So far, the evidence we have of the performance cost; of using `lfence` indicates few if any hot code patterns where this trade off; would make sense. ###### Tempting optimizations that break the security model. Several optimizations were considered which didn't pan out due to failure to; uphold the security model. One in particular is worth discussing as many others; will reduce to it. We wondered whether only the *first* load in a basic block could be checked. If; the check works as intended, it forms an invalid pointer that doesn't even; virtual-address translate in the hardware. It should fault very early on in its; processing. Maybe that would stop things in time for the misspeculated path to; fail to leak any secrets. This doesn't end up working because the processor is; fundamentally out-of-order, even in its speculative domain. As a consequence,; the attacker could cause the initial address computation itself to stall and; allow an arbitrary number of unrelated loads (including attacked loads of; secret data) to pass through. #### Interprocedural Checking. Modern x86 processors may speculate into called functions and out of functions; to their return addr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:37023,Security,secur,security,37023,"di # Hardened load.; movl (%rdi), %edx # Unhardened load due to dependent addr.; ```. This doesn't check the load through `%rdi` as that pointer is dependent on a; checked load already. ###### Protect large, load-heavy blocks with a single lfence. It may be worth using a single `lfence` instruction at the start of a block; which begins with a (very) large number of loads that require independent; protection *and* which require hardening the address of the load. However, this; is unlikely to be profitable in practice. The latency hit of the hardening; would need to exceed that of an `lfence` when *correctly* speculatively; executed. But in that case, the `lfence` cost is a complete loss of speculative; execution (at a minimum). So far, the evidence we have of the performance cost; of using `lfence` indicates few if any hot code patterns where this trade off; would make sense. ###### Tempting optimizations that break the security model. Several optimizations were considered which didn't pan out due to failure to; uphold the security model. One in particular is worth discussing as many others; will reduce to it. We wondered whether only the *first* load in a basic block could be checked. If; the check works as intended, it forms an invalid pointer that doesn't even; virtual-address translate in the hardware. It should fault very early on in its; processing. Maybe that would stop things in time for the misspeculated path to; fail to leak any secrets. This doesn't end up working because the processor is; fundamentally out-of-order, even in its speculative domain. As a consequence,; the attacker could cause the initial address computation itself to stall and; allow an arbitrary number of unrelated loads (including attacked loads of; secret data) to pass through. #### Interprocedural Checking. Modern x86 processors may speculate into called functions and out of functions; to their return address. As a consequence, we need a way to check loads that; occur after a misspeculat",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:37593,Security,attack,attacker,37593,"lete loss of speculative; execution (at a minimum). So far, the evidence we have of the performance cost; of using `lfence` indicates few if any hot code patterns where this trade off; would make sense. ###### Tempting optimizations that break the security model. Several optimizations were considered which didn't pan out due to failure to; uphold the security model. One in particular is worth discussing as many others; will reduce to it. We wondered whether only the *first* load in a basic block could be checked. If; the check works as intended, it forms an invalid pointer that doesn't even; virtual-address translate in the hardware. It should fault very early on in its; processing. Maybe that would stop things in time for the misspeculated path to; fail to leak any secrets. This doesn't end up working because the processor is; fundamentally out-of-order, even in its speculative domain. As a consequence,; the attacker could cause the initial address computation itself to stall and; allow an arbitrary number of unrelated loads (including attacked loads of; secret data) to pass through. #### Interprocedural Checking. Modern x86 processors may speculate into called functions and out of functions; to their return address. As a consequence, we need a way to check loads that; occur after a misspeculated predicate but where the load and the misspeculated; predicate are in different functions. In essence, we need some interprocedural; generalization of the predicate state tracking. A primary challenge to passing; the predicate state between functions is that we would like to not require a; change to the ABI or calling convention in order to make this mitigation more; deployable, and further would like code mitigated in this way to be easily; mixed with code not mitigated in this way and without completely losing the; value of the mitigation. ##### Embed the predicate state into the high bit(s) of the stack pointer. We can use the same technique that allows hardening pointer",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:37723,Security,attack,attacked,37723,"lete loss of speculative; execution (at a minimum). So far, the evidence we have of the performance cost; of using `lfence` indicates few if any hot code patterns where this trade off; would make sense. ###### Tempting optimizations that break the security model. Several optimizations were considered which didn't pan out due to failure to; uphold the security model. One in particular is worth discussing as many others; will reduce to it. We wondered whether only the *first* load in a basic block could be checked. If; the check works as intended, it forms an invalid pointer that doesn't even; virtual-address translate in the hardware. It should fault very early on in its; processing. Maybe that would stop things in time for the misspeculated path to; fail to leak any secrets. This doesn't end up working because the processor is; fundamentally out-of-order, even in its speculative domain. As a consequence,; the attacker could cause the initial address computation itself to stall and; allow an arbitrary number of unrelated loads (including attacked loads of; secret data) to pass through. #### Interprocedural Checking. Modern x86 processors may speculate into called functions and out of functions; to their return address. As a consequence, we need a way to check loads that; occur after a misspeculated predicate but where the load and the misspeculated; predicate are in different functions. In essence, we need some interprocedural; generalization of the predicate state tracking. A primary challenge to passing; the predicate state between functions is that we would like to not require a; change to the ABI or calling convention in order to make this mitigation more; deployable, and further would like code mitigated in this way to be easily; mixed with code not mitigated in this way and without completely losing the; value of the mitigation. ##### Embed the predicate state into the high bit(s) of the stack pointer. We can use the same technique that allows hardening pointer",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:43553,Security,attack,attacks,43553,"state between; functions. This avoids direct ABI implications by using a side channel between; callers and callees to communicate the predicate state. It also allows implicit; zero-initialization of the state, which allows non-checked code to be the first; code executed. However, this requires a load from TLS in the entry block, a store to TLS; before every call and every ret, and a load from TLS after every call. As a; consequence it is expected to be substantially more expensive even than using; `%rsp` and potentially `lfence` within the function entry block. ##### Define a new ABI and/or calling convention. We could define a new ABI and/or calling convention to explicitly pass the; predicate state in and out of functions. This may be interesting if none of the; alternatives have adequate performance, but it makes deployment and adoption; dramatically more complex, and potentially infeasible. ## High-Level Alternative Mitigation Strategies. There are completely different alternative approaches to mitigating variant 1; attacks. [Most](https://lwn.net/Articles/743265/); [discussion](https://lwn.net/Articles/744287/) so far focuses on mitigating; specific known attackable components in the Linux kernel (or other kernels) by; manually rewriting the code to contain an instruction sequence that is not; vulnerable. For x86 systems this is done by either injecting an `lfence`; instruction along the code path which would leak data if executed speculatively; or by rewriting memory accesses to have branch-less masking to a known safe; region. On Intel systems, `lfence` [will prevent the speculative load of secret; data](https://newsroom.intel.com/wp-content/uploads/sites/11/2018/01/Intel-Analysis-of-Speculative-Execution-Side-Channels.pdf).; On AMD systems `lfence` is currently a no-op, but can be made; dispatch-serializing by setting an MSR, and thus preclude misspeculation of the; code path ([mitigation G-2 +; V1-1](https://developer.amd.com/wp-content/resources/Managing-S",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:43696,Security,attack,attackable,43696,"s non-checked code to be the first; code executed. However, this requires a load from TLS in the entry block, a store to TLS; before every call and every ret, and a load from TLS after every call. As a; consequence it is expected to be substantially more expensive even than using; `%rsp` and potentially `lfence` within the function entry block. ##### Define a new ABI and/or calling convention. We could define a new ABI and/or calling convention to explicitly pass the; predicate state in and out of functions. This may be interesting if none of the; alternatives have adequate performance, but it makes deployment and adoption; dramatically more complex, and potentially infeasible. ## High-Level Alternative Mitigation Strategies. There are completely different alternative approaches to mitigating variant 1; attacks. [Most](https://lwn.net/Articles/743265/); [discussion](https://lwn.net/Articles/744287/) so far focuses on mitigating; specific known attackable components in the Linux kernel (or other kernels) by; manually rewriting the code to contain an instruction sequence that is not; vulnerable. For x86 systems this is done by either injecting an `lfence`; instruction along the code path which would leak data if executed speculatively; or by rewriting memory accesses to have branch-less masking to a known safe; region. On Intel systems, `lfence` [will prevent the speculative load of secret; data](https://newsroom.intel.com/wp-content/uploads/sites/11/2018/01/Intel-Analysis-of-Speculative-Execution-Side-Channels.pdf).; On AMD systems `lfence` is currently a no-op, but can be made; dispatch-serializing by setting an MSR, and thus preclude misspeculation of the; code path ([mitigation G-2 +; V1-1](https://developer.amd.com/wp-content/resources/Managing-Speculation-on-AMD-Processors.pdf)). However, this relies on finding and enumerating all possible points in code; which could be attacked to leak information. While in some cases static; analysis is effective at doing this ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:43888,Security,inject,injecting,43888,"ected to be substantially more expensive even than using; `%rsp` and potentially `lfence` within the function entry block. ##### Define a new ABI and/or calling convention. We could define a new ABI and/or calling convention to explicitly pass the; predicate state in and out of functions. This may be interesting if none of the; alternatives have adequate performance, but it makes deployment and adoption; dramatically more complex, and potentially infeasible. ## High-Level Alternative Mitigation Strategies. There are completely different alternative approaches to mitigating variant 1; attacks. [Most](https://lwn.net/Articles/743265/); [discussion](https://lwn.net/Articles/744287/) so far focuses on mitigating; specific known attackable components in the Linux kernel (or other kernels) by; manually rewriting the code to contain an instruction sequence that is not; vulnerable. For x86 systems this is done by either injecting an `lfence`; instruction along the code path which would leak data if executed speculatively; or by rewriting memory accesses to have branch-less masking to a known safe; region. On Intel systems, `lfence` [will prevent the speculative load of secret; data](https://newsroom.intel.com/wp-content/uploads/sites/11/2018/01/Intel-Analysis-of-Speculative-Execution-Side-Channels.pdf).; On AMD systems `lfence` is currently a no-op, but can be made; dispatch-serializing by setting an MSR, and thus preclude misspeculation of the; code path ([mitigation G-2 +; V1-1](https://developer.amd.com/wp-content/resources/Managing-Speculation-on-AMD-Processors.pdf)). However, this relies on finding and enumerating all possible points in code; which could be attacked to leak information. While in some cases static; analysis is effective at doing this at scale, in many cases it still relies on; human judgement to evaluate whether code might be vulnerable. Especially for; software systems which receive less detailed scrutiny but remain sensitive to; these attacks, this se",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:44015,Security,access,accesses,44015,"ected to be substantially more expensive even than using; `%rsp` and potentially `lfence` within the function entry block. ##### Define a new ABI and/or calling convention. We could define a new ABI and/or calling convention to explicitly pass the; predicate state in and out of functions. This may be interesting if none of the; alternatives have adequate performance, but it makes deployment and adoption; dramatically more complex, and potentially infeasible. ## High-Level Alternative Mitigation Strategies. There are completely different alternative approaches to mitigating variant 1; attacks. [Most](https://lwn.net/Articles/743265/); [discussion](https://lwn.net/Articles/744287/) so far focuses on mitigating; specific known attackable components in the Linux kernel (or other kernels) by; manually rewriting the code to contain an instruction sequence that is not; vulnerable. For x86 systems this is done by either injecting an `lfence`; instruction along the code path which would leak data if executed speculatively; or by rewriting memory accesses to have branch-less masking to a known safe; region. On Intel systems, `lfence` [will prevent the speculative load of secret; data](https://newsroom.intel.com/wp-content/uploads/sites/11/2018/01/Intel-Analysis-of-Speculative-Execution-Side-Channels.pdf).; On AMD systems `lfence` is currently a no-op, but can be made; dispatch-serializing by setting an MSR, and thus preclude misspeculation of the; code path ([mitigation G-2 +; V1-1](https://developer.amd.com/wp-content/resources/Managing-Speculation-on-AMD-Processors.pdf)). However, this relies on finding and enumerating all possible points in code; which could be attacked to leak information. While in some cases static; analysis is effective at doing this at scale, in many cases it still relies on; human judgement to evaluate whether code might be vulnerable. Especially for; software systems which receive less detailed scrutiny but remain sensitive to; these attacks, this se",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:44645,Security,attack,attacked,44645,"on](https://lwn.net/Articles/744287/) so far focuses on mitigating; specific known attackable components in the Linux kernel (or other kernels) by; manually rewriting the code to contain an instruction sequence that is not; vulnerable. For x86 systems this is done by either injecting an `lfence`; instruction along the code path which would leak data if executed speculatively; or by rewriting memory accesses to have branch-less masking to a known safe; region. On Intel systems, `lfence` [will prevent the speculative load of secret; data](https://newsroom.intel.com/wp-content/uploads/sites/11/2018/01/Intel-Analysis-of-Speculative-Execution-Side-Channels.pdf).; On AMD systems `lfence` is currently a no-op, but can be made; dispatch-serializing by setting an MSR, and thus preclude misspeculation of the; code path ([mitigation G-2 +; V1-1](https://developer.amd.com/wp-content/resources/Managing-Speculation-on-AMD-Processors.pdf)). However, this relies on finding and enumerating all possible points in code; which could be attacked to leak information. While in some cases static; analysis is effective at doing this at scale, in many cases it still relies on; human judgement to evaluate whether code might be vulnerable. Especially for; software systems which receive less detailed scrutiny but remain sensitive to; these attacks, this seems like an impractical security model. We need an; automatic and systematic mitigation strategy. ### Automatic `lfence` on Conditional Edges. A natural way to scale up the existing hand-coded mitigations is simply to; inject an `lfence` instruction into both the target and fallthrough; destinations of every conditional branch. This ensures that no predicate or; bounds check can be bypassed speculatively. However, the performance overhead; of this approach is, simply put, catastrophic. Yet it remains the only truly; ""secure by default"" approach known prior to this effort and serves as the; baseline for performance. One attempt to address the p",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:44946,Security,attack,attacks,44946," along the code path which would leak data if executed speculatively; or by rewriting memory accesses to have branch-less masking to a known safe; region. On Intel systems, `lfence` [will prevent the speculative load of secret; data](https://newsroom.intel.com/wp-content/uploads/sites/11/2018/01/Intel-Analysis-of-Speculative-Execution-Side-Channels.pdf).; On AMD systems `lfence` is currently a no-op, but can be made; dispatch-serializing by setting an MSR, and thus preclude misspeculation of the; code path ([mitigation G-2 +; V1-1](https://developer.amd.com/wp-content/resources/Managing-Speculation-on-AMD-Processors.pdf)). However, this relies on finding and enumerating all possible points in code; which could be attacked to leak information. While in some cases static; analysis is effective at doing this at scale, in many cases it still relies on; human judgement to evaluate whether code might be vulnerable. Especially for; software systems which receive less detailed scrutiny but remain sensitive to; these attacks, this seems like an impractical security model. We need an; automatic and systematic mitigation strategy. ### Automatic `lfence` on Conditional Edges. A natural way to scale up the existing hand-coded mitigations is simply to; inject an `lfence` instruction into both the target and fallthrough; destinations of every conditional branch. This ensures that no predicate or; bounds check can be bypassed speculatively. However, the performance overhead; of this approach is, simply put, catastrophic. Yet it remains the only truly; ""secure by default"" approach known prior to this effort and serves as the; baseline for performance. One attempt to address the performance overhead of this and make it more; realistic to deploy is [MSVC's /Qspectre; switch](https://blogs.msdn.microsoft.com/vcblog/2018/01/15/spectre-mitigations-in-msvc/).; Their technique is to use static analysis within the compiler to only insert; `lfence` instructions into conditional edges at risk ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:44986,Security,secur,security,44986," along the code path which would leak data if executed speculatively; or by rewriting memory accesses to have branch-less masking to a known safe; region. On Intel systems, `lfence` [will prevent the speculative load of secret; data](https://newsroom.intel.com/wp-content/uploads/sites/11/2018/01/Intel-Analysis-of-Speculative-Execution-Side-Channels.pdf).; On AMD systems `lfence` is currently a no-op, but can be made; dispatch-serializing by setting an MSR, and thus preclude misspeculation of the; code path ([mitigation G-2 +; V1-1](https://developer.amd.com/wp-content/resources/Managing-Speculation-on-AMD-Processors.pdf)). However, this relies on finding and enumerating all possible points in code; which could be attacked to leak information. While in some cases static; analysis is effective at doing this at scale, in many cases it still relies on; human judgement to evaluate whether code might be vulnerable. Especially for; software systems which receive less detailed scrutiny but remain sensitive to; these attacks, this seems like an impractical security model. We need an; automatic and systematic mitigation strategy. ### Automatic `lfence` on Conditional Edges. A natural way to scale up the existing hand-coded mitigations is simply to; inject an `lfence` instruction into both the target and fallthrough; destinations of every conditional branch. This ensures that no predicate or; bounds check can be bypassed speculatively. However, the performance overhead; of this approach is, simply put, catastrophic. Yet it remains the only truly; ""secure by default"" approach known prior to this effort and serves as the; baseline for performance. One attempt to address the performance overhead of this and make it more; realistic to deploy is [MSVC's /Qspectre; switch](https://blogs.msdn.microsoft.com/vcblog/2018/01/15/spectre-mitigations-in-msvc/).; Their technique is to use static analysis within the compiler to only insert; `lfence` instructions into conditional edges at risk ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:45181,Security,inject,inject,45181,"oads/sites/11/2018/01/Intel-Analysis-of-Speculative-Execution-Side-Channels.pdf).; On AMD systems `lfence` is currently a no-op, but can be made; dispatch-serializing by setting an MSR, and thus preclude misspeculation of the; code path ([mitigation G-2 +; V1-1](https://developer.amd.com/wp-content/resources/Managing-Speculation-on-AMD-Processors.pdf)). However, this relies on finding and enumerating all possible points in code; which could be attacked to leak information. While in some cases static; analysis is effective at doing this at scale, in many cases it still relies on; human judgement to evaluate whether code might be vulnerable. Especially for; software systems which receive less detailed scrutiny but remain sensitive to; these attacks, this seems like an impractical security model. We need an; automatic and systematic mitigation strategy. ### Automatic `lfence` on Conditional Edges. A natural way to scale up the existing hand-coded mitigations is simply to; inject an `lfence` instruction into both the target and fallthrough; destinations of every conditional branch. This ensures that no predicate or; bounds check can be bypassed speculatively. However, the performance overhead; of this approach is, simply put, catastrophic. Yet it remains the only truly; ""secure by default"" approach known prior to this effort and serves as the; baseline for performance. One attempt to address the performance overhead of this and make it more; realistic to deploy is [MSVC's /Qspectre; switch](https://blogs.msdn.microsoft.com/vcblog/2018/01/15/spectre-mitigations-in-msvc/).; Their technique is to use static analysis within the compiler to only insert; `lfence` instructions into conditional edges at risk of attack. However,; [initial](https://arstechnica.com/gadgets/2018/02/microsofts-compiler-level-spectre-fix-shows-how-hard-this-problem-will-be-to-solve/); [analysis](https://www.paulkocher.com/doc/MicrosoftCompilerSpectreMitigation.html); has shown that this approach is in",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:45485,Security,secur,secure,45485,"eculation-on-AMD-Processors.pdf)). However, this relies on finding and enumerating all possible points in code; which could be attacked to leak information. While in some cases static; analysis is effective at doing this at scale, in many cases it still relies on; human judgement to evaluate whether code might be vulnerable. Especially for; software systems which receive less detailed scrutiny but remain sensitive to; these attacks, this seems like an impractical security model. We need an; automatic and systematic mitigation strategy. ### Automatic `lfence` on Conditional Edges. A natural way to scale up the existing hand-coded mitigations is simply to; inject an `lfence` instruction into both the target and fallthrough; destinations of every conditional branch. This ensures that no predicate or; bounds check can be bypassed speculatively. However, the performance overhead; of this approach is, simply put, catastrophic. Yet it remains the only truly; ""secure by default"" approach known prior to this effort and serves as the; baseline for performance. One attempt to address the performance overhead of this and make it more; realistic to deploy is [MSVC's /Qspectre; switch](https://blogs.msdn.microsoft.com/vcblog/2018/01/15/spectre-mitigations-in-msvc/).; Their technique is to use static analysis within the compiler to only insert; `lfence` instructions into conditional edges at risk of attack. However,; [initial](https://arstechnica.com/gadgets/2018/02/microsofts-compiler-level-spectre-fix-shows-how-hard-this-problem-will-be-to-solve/); [analysis](https://www.paulkocher.com/doc/MicrosoftCompilerSpectreMitigation.html); has shown that this approach is incomplete and only catches a small and limited; subset of attackable patterns which happen to resemble very closely the initial; proofs of concept. As such, while its performance is acceptable, it does not; appear to be an adequate systematic mitigation. ## Performance Overhead. The performance overhead of this style of",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:45926,Security,attack,attack,45926,"software systems which receive less detailed scrutiny but remain sensitive to; these attacks, this seems like an impractical security model. We need an; automatic and systematic mitigation strategy. ### Automatic `lfence` on Conditional Edges. A natural way to scale up the existing hand-coded mitigations is simply to; inject an `lfence` instruction into both the target and fallthrough; destinations of every conditional branch. This ensures that no predicate or; bounds check can be bypassed speculatively. However, the performance overhead; of this approach is, simply put, catastrophic. Yet it remains the only truly; ""secure by default"" approach known prior to this effort and serves as the; baseline for performance. One attempt to address the performance overhead of this and make it more; realistic to deploy is [MSVC's /Qspectre; switch](https://blogs.msdn.microsoft.com/vcblog/2018/01/15/spectre-mitigations-in-msvc/).; Their technique is to use static analysis within the compiler to only insert; `lfence` instructions into conditional edges at risk of attack. However,; [initial](https://arstechnica.com/gadgets/2018/02/microsofts-compiler-level-spectre-fix-shows-how-hard-this-problem-will-be-to-solve/); [analysis](https://www.paulkocher.com/doc/MicrosoftCompilerSpectreMitigation.html); has shown that this approach is incomplete and only catches a small and limited; subset of attackable patterns which happen to resemble very closely the initial; proofs of concept. As such, while its performance is acceptable, it does not; appear to be an adequate systematic mitigation. ## Performance Overhead. The performance overhead of this style of comprehensive mitigation is very; high. However, it compares very favorably with previously recommended; approaches such as the `lfence` instruction. Just as users can restrict the; scope of `lfence` to control its performance impact, this mitigation technique; could be restricted in scope as well. However, it is important to understand what",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:46255,Security,attack,attackable,46255,"destinations of every conditional branch. This ensures that no predicate or; bounds check can be bypassed speculatively. However, the performance overhead; of this approach is, simply put, catastrophic. Yet it remains the only truly; ""secure by default"" approach known prior to this effort and serves as the; baseline for performance. One attempt to address the performance overhead of this and make it more; realistic to deploy is [MSVC's /Qspectre; switch](https://blogs.msdn.microsoft.com/vcblog/2018/01/15/spectre-mitigations-in-msvc/).; Their technique is to use static analysis within the compiler to only insert; `lfence` instructions into conditional edges at risk of attack. However,; [initial](https://arstechnica.com/gadgets/2018/02/microsofts-compiler-level-spectre-fix-shows-how-hard-this-problem-will-be-to-solve/); [analysis](https://www.paulkocher.com/doc/MicrosoftCompilerSpectreMitigation.html); has shown that this approach is incomplete and only catches a small and limited; subset of attackable patterns which happen to resemble very closely the initial; proofs of concept. As such, while its performance is acceptable, it does not; appear to be an adequate systematic mitigation. ## Performance Overhead. The performance overhead of this style of comprehensive mitigation is very; high. However, it compares very favorably with previously recommended; approaches such as the `lfence` instruction. Just as users can restrict the; scope of `lfence` to control its performance impact, this mitigation technique; could be restricted in scope as well. However, it is important to understand what it would cost to get a fully; mitigated baseline. Here we assume targeting a Haswell (or newer) processor and; using all of the tricks to improve performance (so leaves the low 2gb; unprotected and +/- 2gb surrounding any PC in the program). We ran both; Google's microbenchmark suite and a large highly-tuned server built using; ThinLTO and PGO. All were built with `-march=haswell` to g",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:47255,Security,access,access,47255,"rns which happen to resemble very closely the initial; proofs of concept. As such, while its performance is acceptable, it does not; appear to be an adequate systematic mitigation. ## Performance Overhead. The performance overhead of this style of comprehensive mitigation is very; high. However, it compares very favorably with previously recommended; approaches such as the `lfence` instruction. Just as users can restrict the; scope of `lfence` to control its performance impact, this mitigation technique; could be restricted in scope as well. However, it is important to understand what it would cost to get a fully; mitigated baseline. Here we assume targeting a Haswell (or newer) processor and; using all of the tricks to improve performance (so leaves the low 2gb; unprotected and +/- 2gb surrounding any PC in the program). We ran both; Google's microbenchmark suite and a large highly-tuned server built using; ThinLTO and PGO. All were built with `-march=haswell` to give access to BMI2; instructions, and benchmarks were run on large Haswell servers. We collected; data both with an `lfence`-based mitigation and load hardening as presented; here. The summary is that mitigating with load hardening is 1.77x faster than; mitigating with `lfence`, and the overhead of load hardening compared to a; normal program is likely between a 10% overhead and a 50% overhead with most; large applications seeing a 30% overhead or less. | Benchmark | `lfence` | Load Hardening | Mitigated Speedup |; | -------------------------------------- | -------: | -------------: | ----------------: |; | Google microbenchmark suite | -74.8% | -36.4% | **2.5x** |; | Large server QPS (using ThinLTO & PGO) | -62% | -29% | **1.8x** |. Below is a visualization of the microbenchmark suite results which helps show; the distribution of results that is somewhat lost in the summary. The y-axis is; a log-scale speedup ratio of load hardening relative to `lfence` (up -> faster; -> better). Each box-and-whiskers rep",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:49657,Security,secur,security,49657,"We don't yet have benchmark data on SPEC or the LLVM test suite, but we can; work on getting that. Still, the above should give a pretty clear; characterization of the performance, and specific benchmarks are unlikely to; reveal especially interesting properties. ### Future Work: Fine Grained Control and API-Integration. The performance overhead of this technique is likely to be very significant and; something users wish to control or reduce. There are interesting options here; that impact the implementation strategy used. One particularly appealing option is to allow both opt-in and opt-out of this; mitigation at reasonably fine granularity such as on a per-function basis,; including intelligent handling of inlining decisions -- protected code can be; prevented from inlining into unprotected code, and unprotected code will become; protected when inlined into protected code. For systems where only a limited; set of code is reachable by externally controlled inputs, it may be possible to; limit the scope of mitigation through such mechanisms without compromising the; application's overall security. The performance impact may also be focused in a; few key functions that can be hand-mitigated in ways that have lower; performance overhead while the remainder of the application receives automatic; protection. For both limiting the scope of mitigation or manually mitigating hot functions,; there needs to be some support for mixing mitigated and unmitigated code; without completely defeating the mitigation. For the first use case, it would; be particularly desirable that mitigated code remains safe when being called; during misspeculation from unmitigated code. For the second use case, it may be important to connect the automatic; mitigation technique to explicit mitigation APIs such as what is described in; http://wg21.link/p0928 (or any other eventual API) so that there is a clean way; to switch from automatic to manual mitigation without immediately exposing a; hole. How",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:3837,Testability,log,logic,3837,"e unlikely; to scale well to large applications. We are proposing a comprehensive; mitigation approach that would apply automatically across an entire program; rather than through manual changes to the code. While this is likely to have a; high performance cost, some applications may be in a good position to take this; performance / security tradeoff. The specific technique we propose is to cause loads to be checked using; branchless code to ensure that they are executing along a valid control flow; path. Consider the following C-pseudo-code representing the core idea of a; predicate guarding potentially invalid loads:; ```; void leak(int data);; void example(int* pointer1, int* pointer2) {; if (condition) {; // ... lots of code ...; leak(*pointer1);; } else {; // ... more code ...; leak(*pointer2);; }; }; ```. This would get transformed into something resembling the following:; ```; uintptr_t all_ones_mask = std::numerical_limits<uintptr_t>::max();; uintptr_t all_zeros_mask = 0;; void leak(int data);; void example(int* pointer1, int* pointer2) {; uintptr_t predicate_state = all_ones_mask;; if (condition) {; // Assuming ?: is implemented using branchless logic...; predicate_state = !condition ? all_zeros_mask : predicate_state;; // ... lots of code ...; //; // Harden the pointer so it can't be loaded; pointer1 &= predicate_state;; leak(*pointer1);; } else {; predicate_state = condition ? all_zeros_mask : predicate_state;; // ... more code ...; //; // Alternative: Harden the loaded value; int value2 = *pointer2 & predicate_state;; leak(value2);; }; }; ```. The result should be that if the `if (condition) {` branch is mis-predicted,; there is a *data* dependency on the condition used to zero out any pointers; prior to loading through them or to zero out all of the loaded bits. Even; though this code pattern may still execute speculatively, *invalid* speculative; executions are prevented from leaking secret data from memory (but note that; this data might still be loade",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:10033,Testability,log,logic,10033,"e predicted incorrectly when returning from; a function. These code patterns are also vulnerable to Spectre variant #2, and as such are; best mitigated with a; [retpoline](https://support.google.com/faqs/answer/7625886) on x86 platforms.; When a mitigation technique like retpoline is used, speculation simply cannot; proceed through an indirect control flow edge (or it cannot be mispredicted in; the case of a filled RSB) and so it is also protected from variant #1 style; attacks. However, some architectures, micro-architectures, or vendors do not; employ the retpoline mitigation, and on future x86 hardware (both Intel and; AMD) it is expected to become unnecessary due to hardware-based mitigation. When not using a retpoline, these edges will need independent protection from; variant #1 style attacks. The analogous approach to that used for conditional; control flow should work:; ```; uintptr_t all_ones_mask = std::numerical_limits<uintptr_t>::max();; uintptr_t all_zeros_mask = 0;; void leak(int data);; void example(int* pointer1, int* pointer2) {; uintptr_t predicate_state = all_ones_mask;; switch (condition) {; case 0:; // Assuming ?: is implemented using branchless logic...; predicate_state = (condition != 0) ? all_zeros_mask : predicate_state;; // ... lots of code ...; //; // Harden the pointer so it can't be loaded; pointer1 &= predicate_state;; leak(*pointer1);; break;. case 1:; predicate_state = (condition != 1) ? all_zeros_mask : predicate_state;; // ... more code ...; //; // Alternative: Harden the loaded value; int value2 = *pointer2 & predicate_state;; leak(value2);; break;. // ...; }; }; ```. The core idea remains the same: validate the control flow using data-flow and; use that validation to check that loads cannot leak information along; misspeculated paths. Typically this involves passing the desired target of such; control flow across the edge and checking that it is correct afterwards. Note; that while it is tempting to think that this mitigates varian",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:15166,Testability,test,test,15166,"is sufficient for both of these is to harden all of the; speculative stores. However, as most stores aren't interesting and don't; inherently leak data, this is expected to be prohibitively expensive given the; attack it is defending against. ## Implementation Details. There are a number of complex details impacting the implementation of this; technique, both on a particular architecture and within a particular compiler.; We discuss proposed implementation techniques for the x86 architecture and the; LLVM compiler. These are primarily to serve as an example, as other; implementation techniques are very possible. ### x86 Implementation Details. On the x86 platform we break down the implementation into three core; components: accumulating the predicate state through the control flow graph,; checking the loads, and checking control transfers between procedures. #### Accumulating Predicate State. Consider baseline x86 instructions like the following, which test three; conditions and if all pass, loads data from memory and potentially leaks it; through some side channel:; ```; # %bb.0: # %entry; pushq %rax; testl %edi, %edi; jne .LBB0_4; # %bb.1: # %then1; testl %esi, %esi; jne .LBB0_4; # %bb.2: # %then2; testl %edx, %edx; je .LBB0_3; .LBB0_4: # %exit; popq %rax; retq; .LBB0_3: # %danger; movl (%rcx), %edi; callq leak; popq %rax; retq; ```. When we go to speculatively execute the load, we want to know whether any of; the dynamically executed predicates have been misspeculated. To track that,; along each conditional edge, we need to track the data which would allow that; edge to be taken. On x86, this data is stored in the flags register used by the; conditional jump instruction. Along both edges after this fork in control flow,; the flags register remains alive and contains data that we can use to build up; our accumulated predicate state. We accumulate it using the x86 conditional; move instruction which also reads the flag registers where the state resides.; These cond",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:15319,Testability,test,testl,15319," and don't; inherently leak data, this is expected to be prohibitively expensive given the; attack it is defending against. ## Implementation Details. There are a number of complex details impacting the implementation of this; technique, both on a particular architecture and within a particular compiler.; We discuss proposed implementation techniques for the x86 architecture and the; LLVM compiler. These are primarily to serve as an example, as other; implementation techniques are very possible. ### x86 Implementation Details. On the x86 platform we break down the implementation into three core; components: accumulating the predicate state through the control flow graph,; checking the loads, and checking control transfers between procedures. #### Accumulating Predicate State. Consider baseline x86 instructions like the following, which test three; conditions and if all pass, loads data from memory and potentially leaks it; through some side channel:; ```; # %bb.0: # %entry; pushq %rax; testl %edi, %edi; jne .LBB0_4; # %bb.1: # %then1; testl %esi, %esi; jne .LBB0_4; # %bb.2: # %then2; testl %edx, %edx; je .LBB0_3; .LBB0_4: # %exit; popq %rax; retq; .LBB0_3: # %danger; movl (%rcx), %edi; callq leak; popq %rax; retq; ```. When we go to speculatively execute the load, we want to know whether any of; the dynamically executed predicates have been misspeculated. To track that,; along each conditional edge, we need to track the data which would allow that; edge to be taken. On x86, this data is stored in the flags register used by the; conditional jump instruction. Along both edges after this fork in control flow,; the flags register remains alive and contains data that we can use to build up; our accumulated predicate state. We accumulate it using the x86 conditional; move instruction which also reads the flag registers where the state resides.; These conditional move instructions are known to not be predicted on any x86; processors, making them immune to misprediction tha",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:15369,Testability,test,testl,15369," prohibitively expensive given the; attack it is defending against. ## Implementation Details. There are a number of complex details impacting the implementation of this; technique, both on a particular architecture and within a particular compiler.; We discuss proposed implementation techniques for the x86 architecture and the; LLVM compiler. These are primarily to serve as an example, as other; implementation techniques are very possible. ### x86 Implementation Details. On the x86 platform we break down the implementation into three core; components: accumulating the predicate state through the control flow graph,; checking the loads, and checking control transfers between procedures. #### Accumulating Predicate State. Consider baseline x86 instructions like the following, which test three; conditions and if all pass, loads data from memory and potentially leaks it; through some side channel:; ```; # %bb.0: # %entry; pushq %rax; testl %edi, %edi; jne .LBB0_4; # %bb.1: # %then1; testl %esi, %esi; jne .LBB0_4; # %bb.2: # %then2; testl %edx, %edx; je .LBB0_3; .LBB0_4: # %exit; popq %rax; retq; .LBB0_3: # %danger; movl (%rcx), %edi; callq leak; popq %rax; retq; ```. When we go to speculatively execute the load, we want to know whether any of; the dynamically executed predicates have been misspeculated. To track that,; along each conditional edge, we need to track the data which would allow that; edge to be taken. On x86, this data is stored in the flags register used by the; conditional jump instruction. Along both edges after this fork in control flow,; the flags register remains alive and contains data that we can use to build up; our accumulated predicate state. We accumulate it using the x86 conditional; move instruction which also reads the flag registers where the state resides.; These conditional move instructions are known to not be predicted on any x86; processors, making them immune to misprediction that could reintroduce the; vulnerability. When we insert t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:15419,Testability,test,testl,15419,"defending against. ## Implementation Details. There are a number of complex details impacting the implementation of this; technique, both on a particular architecture and within a particular compiler.; We discuss proposed implementation techniques for the x86 architecture and the; LLVM compiler. These are primarily to serve as an example, as other; implementation techniques are very possible. ### x86 Implementation Details. On the x86 platform we break down the implementation into three core; components: accumulating the predicate state through the control flow graph,; checking the loads, and checking control transfers between procedures. #### Accumulating Predicate State. Consider baseline x86 instructions like the following, which test three; conditions and if all pass, loads data from memory and potentially leaks it; through some side channel:; ```; # %bb.0: # %entry; pushq %rax; testl %edi, %edi; jne .LBB0_4; # %bb.1: # %then1; testl %esi, %esi; jne .LBB0_4; # %bb.2: # %then2; testl %edx, %edx; je .LBB0_3; .LBB0_4: # %exit; popq %rax; retq; .LBB0_3: # %danger; movl (%rcx), %edi; callq leak; popq %rax; retq; ```. When we go to speculatively execute the load, we want to know whether any of; the dynamically executed predicates have been misspeculated. To track that,; along each conditional edge, we need to track the data which would allow that; edge to be taken. On x86, this data is stored in the flags register used by the; conditional jump instruction. Along both edges after this fork in control flow,; the flags register remains alive and contains data that we can use to build up; our accumulated predicate state. We accumulate it using the x86 conditional; move instruction which also reads the flag registers where the state resides.; These conditional move instructions are known to not be predicted on any x86; processors, making them immune to misprediction that could reintroduce the; vulnerability. When we insert the conditional moves, the code ends up looking; li",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:16584,Testability,test,testl,16584,"he load, we want to know whether any of; the dynamically executed predicates have been misspeculated. To track that,; along each conditional edge, we need to track the data which would allow that; edge to be taken. On x86, this data is stored in the flags register used by the; conditional jump instruction. Along both edges after this fork in control flow,; the flags register remains alive and contains data that we can use to build up; our accumulated predicate state. We accumulate it using the x86 conditional; move instruction which also reads the flag registers where the state resides.; These conditional move instructions are known to not be predicted on any x86; processors, making them immune to misprediction that could reintroduce the; vulnerability. When we insert the conditional moves, the code ends up looking; like the following:; ```; # %bb.0: # %entry; pushq %rax; xorl %eax, %eax # Zero out initial predicate state.; movq $-1, %r8 # Put all-ones mask into a register.; testl %edi, %edi; jne .LBB0_1; # %bb.2: # %then1; cmovneq %r8, %rax # Conditionally update predicate state.; testl %esi, %esi; jne .LBB0_1; # %bb.3: # %then2; cmovneq %r8, %rax # Conditionally update predicate state.; testl %edx, %edx; je .LBB0_4; .LBB0_1:; cmoveq %r8, %rax # Conditionally update predicate state.; popq %rax; retq; .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; ...; ```. Here we create the ""empty"" or ""correct execution"" predicate state by zeroing; `%rax`, and we create a constant ""incorrect execution"" predicate value by; putting `-1` into `%r8`. Then, along each edge coming out of a conditional; branch we do a conditional move that in a correct execution will be a no-op,; but if misspeculated, will replace the `%rax` with the value of `%r8`.; Misspeculating any one of the three predicates will cause `%rax` to hold the; ""incorrect execution"" value from `%r8` as we preserve incoming values when; execution is correct rather than overwriting it. We now ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:16693,Testability,test,testl,16693,"k that,; along each conditional edge, we need to track the data which would allow that; edge to be taken. On x86, this data is stored in the flags register used by the; conditional jump instruction. Along both edges after this fork in control flow,; the flags register remains alive and contains data that we can use to build up; our accumulated predicate state. We accumulate it using the x86 conditional; move instruction which also reads the flag registers where the state resides.; These conditional move instructions are known to not be predicted on any x86; processors, making them immune to misprediction that could reintroduce the; vulnerability. When we insert the conditional moves, the code ends up looking; like the following:; ```; # %bb.0: # %entry; pushq %rax; xorl %eax, %eax # Zero out initial predicate state.; movq $-1, %r8 # Put all-ones mask into a register.; testl %edi, %edi; jne .LBB0_1; # %bb.2: # %then1; cmovneq %r8, %rax # Conditionally update predicate state.; testl %esi, %esi; jne .LBB0_1; # %bb.3: # %then2; cmovneq %r8, %rax # Conditionally update predicate state.; testl %edx, %edx; je .LBB0_4; .LBB0_1:; cmoveq %r8, %rax # Conditionally update predicate state.; popq %rax; retq; .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; ...; ```. Here we create the ""empty"" or ""correct execution"" predicate state by zeroing; `%rax`, and we create a constant ""incorrect execution"" predicate value by; putting `-1` into `%r8`. Then, along each edge coming out of a conditional; branch we do a conditional move that in a correct execution will be a no-op,; but if misspeculated, will replace the `%rax` with the value of `%r8`.; Misspeculating any one of the three predicates will cause `%rax` to hold the; ""incorrect execution"" value from `%r8` as we preserve incoming values when; execution is correct rather than overwriting it. We now have a value in `%rax` in each basic block that indicates if at some; point previously a predicate was mispre",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:16802,Testability,test,testl,16802,"x86, this data is stored in the flags register used by the; conditional jump instruction. Along both edges after this fork in control flow,; the flags register remains alive and contains data that we can use to build up; our accumulated predicate state. We accumulate it using the x86 conditional; move instruction which also reads the flag registers where the state resides.; These conditional move instructions are known to not be predicted on any x86; processors, making them immune to misprediction that could reintroduce the; vulnerability. When we insert the conditional moves, the code ends up looking; like the following:; ```; # %bb.0: # %entry; pushq %rax; xorl %eax, %eax # Zero out initial predicate state.; movq $-1, %r8 # Put all-ones mask into a register.; testl %edi, %edi; jne .LBB0_1; # %bb.2: # %then1; cmovneq %r8, %rax # Conditionally update predicate state.; testl %esi, %esi; jne .LBB0_1; # %bb.3: # %then2; cmovneq %r8, %rax # Conditionally update predicate state.; testl %edx, %edx; je .LBB0_4; .LBB0_1:; cmoveq %r8, %rax # Conditionally update predicate state.; popq %rax; retq; .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; ...; ```. Here we create the ""empty"" or ""correct execution"" predicate state by zeroing; `%rax`, and we create a constant ""incorrect execution"" predicate value by; putting `-1` into `%r8`. Then, along each edge coming out of a conditional; branch we do a conditional move that in a correct execution will be a no-op,; but if misspeculated, will replace the `%rax` with the value of `%r8`.; Misspeculating any one of the three predicates will cause `%rax` to hold the; ""incorrect execution"" value from `%r8` as we preserve incoming values when; execution is correct rather than overwriting it. We now have a value in `%rax` in each basic block that indicates if at some; point previously a predicate was mispredicted. And we have arranged for that; value to be particularly effective when used below to harden loads. #",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:18210,Testability,test,testing,18210,"ve that in a correct execution will be a no-op,; but if misspeculated, will replace the `%rax` with the value of `%r8`.; Misspeculating any one of the three predicates will cause `%rax` to hold the; ""incorrect execution"" value from `%r8` as we preserve incoming values when; execution is correct rather than overwriting it. We now have a value in `%rax` in each basic block that indicates if at some; point previously a predicate was mispredicted. And we have arranged for that; value to be particularly effective when used below to harden loads. ##### Indirect Call, Branch, and Return Predicates. There is no analogous flag to use when tracing indirect calls, branches, and; returns. The predicate state must be accumulated through some other means.; Fundamentally, this is the reverse of the problem posed in CFI: we need to; check where we came from rather than where we are going. For function-local; jump tables, this is easily arranged by testing the input to the jump table; within each destination (not yet implemented, use retpolines):; ```; pushq %rax; xorl %eax, %eax # Zero out initial predicate state.; movq $-1, %r8 # Put all-ones mask into a register.; jmpq *.LJTI0_0(,%rdi,8) # Indirect jump through table.; .LBB0_2: # %sw.bb; testq $0, %rdi # Validate index used for jump table.; cmovneq %r8, %rax # Conditionally update predicate state.; ...; jmp _Z4leaki # TAILCALL. .LBB0_3: # %sw.bb1; testq $1, %rdi # Validate index used for jump table.; cmovneq %r8, %rax # Conditionally update predicate state.; ...; jmp _Z4leaki # TAILCALL. .LBB0_5: # %sw.bb10; testq $2, %rdi # Validate index used for jump table.; cmovneq %r8, %rax # Conditionally update predicate state.; ...; jmp _Z4leaki # TAILCALL; ... .section .rodata,""a"",@progbits; .p2align 3; .LJTI0_0:; .quad .LBB0_2; .quad .LBB0_3; .quad .LBB0_5; ...; ```. Returns have a simple mitigation technique on x86-64 (or other ABIs which have; what is called a ""red zone"" region beyond the end of the stack). This region is; guaranteed ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:18508,Testability,test,testq,18508," when; execution is correct rather than overwriting it. We now have a value in `%rax` in each basic block that indicates if at some; point previously a predicate was mispredicted. And we have arranged for that; value to be particularly effective when used below to harden loads. ##### Indirect Call, Branch, and Return Predicates. There is no analogous flag to use when tracing indirect calls, branches, and; returns. The predicate state must be accumulated through some other means.; Fundamentally, this is the reverse of the problem posed in CFI: we need to; check where we came from rather than where we are going. For function-local; jump tables, this is easily arranged by testing the input to the jump table; within each destination (not yet implemented, use retpolines):; ```; pushq %rax; xorl %eax, %eax # Zero out initial predicate state.; movq $-1, %r8 # Put all-ones mask into a register.; jmpq *.LJTI0_0(,%rdi,8) # Indirect jump through table.; .LBB0_2: # %sw.bb; testq $0, %rdi # Validate index used for jump table.; cmovneq %r8, %rax # Conditionally update predicate state.; ...; jmp _Z4leaki # TAILCALL. .LBB0_3: # %sw.bb1; testq $1, %rdi # Validate index used for jump table.; cmovneq %r8, %rax # Conditionally update predicate state.; ...; jmp _Z4leaki # TAILCALL. .LBB0_5: # %sw.bb10; testq $2, %rdi # Validate index used for jump table.; cmovneq %r8, %rax # Conditionally update predicate state.; ...; jmp _Z4leaki # TAILCALL; ... .section .rodata,""a"",@progbits; .p2align 3; .LJTI0_0:; .quad .LBB0_2; .quad .LBB0_3; .quad .LBB0_5; ...; ```. Returns have a simple mitigation technique on x86-64 (or other ABIs which have; what is called a ""red zone"" region beyond the end of the stack). This region is; guaranteed to be preserved across interrupts and context switches, making the; return address used in returning to the current code remain on the stack and; valid to read. We can emit code in the caller to verify that a return edge was; not mispredicted:; ```; callq other_functi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:18671,Testability,test,testq,18671,"was mispredicted. And we have arranged for that; value to be particularly effective when used below to harden loads. ##### Indirect Call, Branch, and Return Predicates. There is no analogous flag to use when tracing indirect calls, branches, and; returns. The predicate state must be accumulated through some other means.; Fundamentally, this is the reverse of the problem posed in CFI: we need to; check where we came from rather than where we are going. For function-local; jump tables, this is easily arranged by testing the input to the jump table; within each destination (not yet implemented, use retpolines):; ```; pushq %rax; xorl %eax, %eax # Zero out initial predicate state.; movq $-1, %r8 # Put all-ones mask into a register.; jmpq *.LJTI0_0(,%rdi,8) # Indirect jump through table.; .LBB0_2: # %sw.bb; testq $0, %rdi # Validate index used for jump table.; cmovneq %r8, %rax # Conditionally update predicate state.; ...; jmp _Z4leaki # TAILCALL. .LBB0_3: # %sw.bb1; testq $1, %rdi # Validate index used for jump table.; cmovneq %r8, %rax # Conditionally update predicate state.; ...; jmp _Z4leaki # TAILCALL. .LBB0_5: # %sw.bb10; testq $2, %rdi # Validate index used for jump table.; cmovneq %r8, %rax # Conditionally update predicate state.; ...; jmp _Z4leaki # TAILCALL; ... .section .rodata,""a"",@progbits; .p2align 3; .LJTI0_0:; .quad .LBB0_2; .quad .LBB0_3; .quad .LBB0_5; ...; ```. Returns have a simple mitigation technique on x86-64 (or other ABIs which have; what is called a ""red zone"" region beyond the end of the stack). This region is; guaranteed to be preserved across interrupts and context switches, making the; return address used in returning to the current code remain on the stack and; valid to read. We can emit code in the caller to verify that a return edge was; not mispredicted:; ```; callq other_function; return_addr:; testq -8(%rsp), return_addr # Validate return address.; cmovneq %r8, %rax # Update predicate state.; ```. For an ABI without a ""red zone"" (and th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:18835,Testability,test,testq,18835,"tes. There is no analogous flag to use when tracing indirect calls, branches, and; returns. The predicate state must be accumulated through some other means.; Fundamentally, this is the reverse of the problem posed in CFI: we need to; check where we came from rather than where we are going. For function-local; jump tables, this is easily arranged by testing the input to the jump table; within each destination (not yet implemented, use retpolines):; ```; pushq %rax; xorl %eax, %eax # Zero out initial predicate state.; movq $-1, %r8 # Put all-ones mask into a register.; jmpq *.LJTI0_0(,%rdi,8) # Indirect jump through table.; .LBB0_2: # %sw.bb; testq $0, %rdi # Validate index used for jump table.; cmovneq %r8, %rax # Conditionally update predicate state.; ...; jmp _Z4leaki # TAILCALL. .LBB0_3: # %sw.bb1; testq $1, %rdi # Validate index used for jump table.; cmovneq %r8, %rax # Conditionally update predicate state.; ...; jmp _Z4leaki # TAILCALL. .LBB0_5: # %sw.bb10; testq $2, %rdi # Validate index used for jump table.; cmovneq %r8, %rax # Conditionally update predicate state.; ...; jmp _Z4leaki # TAILCALL; ... .section .rodata,""a"",@progbits; .p2align 3; .LJTI0_0:; .quad .LBB0_2; .quad .LBB0_3; .quad .LBB0_5; ...; ```. Returns have a simple mitigation technique on x86-64 (or other ABIs which have; what is called a ""red zone"" region beyond the end of the stack). This region is; guaranteed to be preserved across interrupts and context switches, making the; return address used in returning to the current code remain on the stack and; valid to read. We can emit code in the caller to verify that a return edge was; not mispredicted:; ```; callq other_function; return_addr:; testq -8(%rsp), return_addr # Validate return address.; cmovneq %r8, %rax # Update predicate state.; ```. For an ABI without a ""red zone"" (and thus unable to read the return address; from the stack), we can compute the expected return address prior to the call; into a register preserved across the call and ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:19550,Testability,test,testq,19550,"$0, %rdi # Validate index used for jump table.; cmovneq %r8, %rax # Conditionally update predicate state.; ...; jmp _Z4leaki # TAILCALL. .LBB0_3: # %sw.bb1; testq $1, %rdi # Validate index used for jump table.; cmovneq %r8, %rax # Conditionally update predicate state.; ...; jmp _Z4leaki # TAILCALL. .LBB0_5: # %sw.bb10; testq $2, %rdi # Validate index used for jump table.; cmovneq %r8, %rax # Conditionally update predicate state.; ...; jmp _Z4leaki # TAILCALL; ... .section .rodata,""a"",@progbits; .p2align 3; .LJTI0_0:; .quad .LBB0_2; .quad .LBB0_3; .quad .LBB0_5; ...; ```. Returns have a simple mitigation technique on x86-64 (or other ABIs which have; what is called a ""red zone"" region beyond the end of the stack). This region is; guaranteed to be preserved across interrupts and context switches, making the; return address used in returning to the current code remain on the stack and; valid to read. We can emit code in the caller to verify that a return edge was; not mispredicted:; ```; callq other_function; return_addr:; testq -8(%rsp), return_addr # Validate return address.; cmovneq %r8, %rax # Update predicate state.; ```. For an ABI without a ""red zone"" (and thus unable to read the return address; from the stack), we can compute the expected return address prior to the call; into a register preserved across the call and use that similarly to the above. Indirect calls (and returns in the absence of a red zone ABI) pose the most; significant challenge to propagate. The simplest technique would be to define a; new ABI such that the intended call target is passed into the called function; and checked in the entry. Unfortunately, new ABIs are quite expensive to deploy; in C and C++. While the target function could be passed in TLS, we would still; require complex logic to handle a mixture of functions compiled with and; without this extra logic (essentially, making the ABI backwards compatible).; Currently, we suggest using retpolines here and will continue to investig",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:20305,Testability,log,logic,20305,"; return address used in returning to the current code remain on the stack and; valid to read. We can emit code in the caller to verify that a return edge was; not mispredicted:; ```; callq other_function; return_addr:; testq -8(%rsp), return_addr # Validate return address.; cmovneq %r8, %rax # Update predicate state.; ```. For an ABI without a ""red zone"" (and thus unable to read the return address; from the stack), we can compute the expected return address prior to the call; into a register preserved across the call and use that similarly to the above. Indirect calls (and returns in the absence of a red zone ABI) pose the most; significant challenge to propagate. The simplest technique would be to define a; new ABI such that the intended call target is passed into the called function; and checked in the entry. Unfortunately, new ABIs are quite expensive to deploy; in C and C++. While the target function could be passed in TLS, we would still; require complex logic to handle a mixture of functions compiled with and; without this extra logic (essentially, making the ABI backwards compatible).; Currently, we suggest using retpolines here and will continue to investigate; ways of mitigating this. ##### Optimizations, Alternatives, and Tradeoffs. Merely accumulating predicate state involves significant cost. There are; several key optimizations we employ to minimize this and various alternatives; that present different tradeoffs in the generated code. First, we work to reduce the number of instructions used to track the state:; * Rather than inserting a `cmovCC` instruction along every conditional edge in; the original program, we track each set of condition flags we need to capture; prior to entering each basic block and reuse a common `cmovCC` sequence for; those.; * We could further reuse suffixes when there are multiple `cmovCC`; instructions required to capture the set of flags. Currently this is; believed to not be worth the cost as paired flags are relatively rar",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:20382,Testability,log,logic,20382,"; return address used in returning to the current code remain on the stack and; valid to read. We can emit code in the caller to verify that a return edge was; not mispredicted:; ```; callq other_function; return_addr:; testq -8(%rsp), return_addr # Validate return address.; cmovneq %r8, %rax # Update predicate state.; ```. For an ABI without a ""red zone"" (and thus unable to read the return address; from the stack), we can compute the expected return address prior to the call; into a register preserved across the call and use that similarly to the above. Indirect calls (and returns in the absence of a red zone ABI) pose the most; significant challenge to propagate. The simplest technique would be to define a; new ABI such that the intended call target is passed into the called function; and checked in the entry. Unfortunately, new ABIs are quite expensive to deploy; in C and C++. While the target function could be passed in TLS, we would still; require complex logic to handle a mixture of functions compiled with and; without this extra logic (essentially, making the ABI backwards compatible).; Currently, we suggest using retpolines here and will continue to investigate; ways of mitigating this. ##### Optimizations, Alternatives, and Tradeoffs. Merely accumulating predicate state involves significant cost. There are; several key optimizations we employ to minimize this and various alternatives; that present different tradeoffs in the generated code. First, we work to reduce the number of instructions used to track the state:; * Rather than inserting a `cmovCC` instruction along every conditional edge in; the original program, we track each set of condition flags we need to capture; prior to entering each basic block and reuse a common `cmovCC` sequence for; those.; * We could further reuse suffixes when there are multiple `cmovCC`; instructions required to capture the set of flags. Currently this is; believed to not be worth the cost as paired flags are relatively rar",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:38796,Testability,test,test,38796,"n x86 processors may speculate into called functions and out of functions; to their return address. As a consequence, we need a way to check loads that; occur after a misspeculated predicate but where the load and the misspeculated; predicate are in different functions. In essence, we need some interprocedural; generalization of the predicate state tracking. A primary challenge to passing; the predicate state between functions is that we would like to not require a; change to the ABI or calling convention in order to make this mitigation more; deployable, and further would like code mitigated in this way to be easily; mixed with code not mitigated in this way and without completely losing the; value of the mitigation. ##### Embed the predicate state into the high bit(s) of the stack pointer. We can use the same technique that allows hardening pointers to pass the; predicate state into and out of functions. The stack pointer is trivially; passed between functions and we can test for it having the high bits set to; detect when it has been marked due to misspeculation. The callsite instruction; sequence looks like (assuming a misspeculated state value of `-1`):; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; shlq $47, %rax; orq %rax, %rsp; callq other_function; movq %rsp, %rax; sarq 63, %rax # Sign extend the high bit to all bits.; ```. This first puts the predicate state into the high bits of `%rsp` before calling; the function and then reads it back out of high bits of `%rsp` afterward. When; correctly executing (speculatively or not), these are all no-ops. When; misspeculating, the stack pointer will end up negative. We arrange for it to; remain a canonical address, but otherwise leave the low bits alone to allow; stack adjustments to proceed normally without disrupting this. Within the; called function, we can extract this predicate state and then reset it on; return:; ```; other_function:; # prolog; callq other_function; mov",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:47289,Testability,benchmark,benchmarks,47289,"rns which happen to resemble very closely the initial; proofs of concept. As such, while its performance is acceptable, it does not; appear to be an adequate systematic mitigation. ## Performance Overhead. The performance overhead of this style of comprehensive mitigation is very; high. However, it compares very favorably with previously recommended; approaches such as the `lfence` instruction. Just as users can restrict the; scope of `lfence` to control its performance impact, this mitigation technique; could be restricted in scope as well. However, it is important to understand what it would cost to get a fully; mitigated baseline. Here we assume targeting a Haswell (or newer) processor and; using all of the tricks to improve performance (so leaves the low 2gb; unprotected and +/- 2gb surrounding any PC in the program). We ran both; Google's microbenchmark suite and a large highly-tuned server built using; ThinLTO and PGO. All were built with `-march=haswell` to give access to BMI2; instructions, and benchmarks were run on large Haswell servers. We collected; data both with an `lfence`-based mitigation and load hardening as presented; here. The summary is that mitigating with load hardening is 1.77x faster than; mitigating with `lfence`, and the overhead of load hardening compared to a; normal program is likely between a 10% overhead and a 50% overhead with most; large applications seeing a 30% overhead or less. | Benchmark | `lfence` | Load Hardening | Mitigated Speedup |; | -------------------------------------- | -------: | -------------: | ----------------: |; | Google microbenchmark suite | -74.8% | -36.4% | **2.5x** |; | Large server QPS (using ThinLTO & PGO) | -62% | -29% | **1.8x** |. Below is a visualization of the microbenchmark suite results which helps show; the distribution of results that is somewhat lost in the summary. The y-axis is; a log-scale speedup ratio of load hardening relative to `lfence` (up -> faster; -> better). Each box-and-whiskers rep",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:48157,Testability,log,log-scale,48157," ThinLTO and PGO. All were built with `-march=haswell` to give access to BMI2; instructions, and benchmarks were run on large Haswell servers. We collected; data both with an `lfence`-based mitigation and load hardening as presented; here. The summary is that mitigating with load hardening is 1.77x faster than; mitigating with `lfence`, and the overhead of load hardening compared to a; normal program is likely between a 10% overhead and a 50% overhead with most; large applications seeing a 30% overhead or less. | Benchmark | `lfence` | Load Hardening | Mitigated Speedup |; | -------------------------------------- | -------: | -------------: | ----------------: |; | Google microbenchmark suite | -74.8% | -36.4% | **2.5x** |; | Large server QPS (using ThinLTO & PGO) | -62% | -29% | **1.8x** |. Below is a visualization of the microbenchmark suite results which helps show; the distribution of results that is somewhat lost in the summary. The y-axis is; a log-scale speedup ratio of load hardening relative to `lfence` (up -> faster; -> better). Each box-and-whiskers represents one microbenchmark which may have; many different metrics measured. The red line marks the median, the box marks; the first and third quartiles, and the whiskers mark the min and max. ![Microbenchmark result visualization](speculative_load_hardening_microbenchmarks.png). We don't yet have benchmark data on SPEC or the LLVM test suite, but we can; work on getting that. Still, the above should give a pretty clear; characterization of the performance, and specific benchmarks are unlikely to; reveal especially interesting properties. ### Future Work: Fine Grained Control and API-Integration. The performance overhead of this technique is likely to be very significant and; something users wish to control or reduce. There are interesting options here; that impact the implementation strategy used. One particularly appealing option is to allow both opt-in and opt-out of this; mitigation at reasonably fine gra",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:48570,Testability,benchmark,benchmark,48570,"ikely between a 10% overhead and a 50% overhead with most; large applications seeing a 30% overhead or less. | Benchmark | `lfence` | Load Hardening | Mitigated Speedup |; | -------------------------------------- | -------: | -------------: | ----------------: |; | Google microbenchmark suite | -74.8% | -36.4% | **2.5x** |; | Large server QPS (using ThinLTO & PGO) | -62% | -29% | **1.8x** |. Below is a visualization of the microbenchmark suite results which helps show; the distribution of results that is somewhat lost in the summary. The y-axis is; a log-scale speedup ratio of load hardening relative to `lfence` (up -> faster; -> better). Each box-and-whiskers represents one microbenchmark which may have; many different metrics measured. The red line marks the median, the box marks; the first and third quartiles, and the whiskers mark the min and max. ![Microbenchmark result visualization](speculative_load_hardening_microbenchmarks.png). We don't yet have benchmark data on SPEC or the LLVM test suite, but we can; work on getting that. Still, the above should give a pretty clear; characterization of the performance, and specific benchmarks are unlikely to; reveal especially interesting properties. ### Future Work: Fine Grained Control and API-Integration. The performance overhead of this technique is likely to be very significant and; something users wish to control or reduce. There are interesting options here; that impact the implementation strategy used. One particularly appealing option is to allow both opt-in and opt-out of this; mitigation at reasonably fine granularity such as on a per-function basis,; including intelligent handling of inlining decisions -- protected code can be; prevented from inlining into unprotected code, and unprotected code will become; protected when inlined into protected code. For systems where only a limited; set of code is reachable by externally controlled inputs, it may be possible to; limit the scope of mitigation through such mec",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:48605,Testability,test,test,48605,"ikely between a 10% overhead and a 50% overhead with most; large applications seeing a 30% overhead or less. | Benchmark | `lfence` | Load Hardening | Mitigated Speedup |; | -------------------------------------- | -------: | -------------: | ----------------: |; | Google microbenchmark suite | -74.8% | -36.4% | **2.5x** |; | Large server QPS (using ThinLTO & PGO) | -62% | -29% | **1.8x** |. Below is a visualization of the microbenchmark suite results which helps show; the distribution of results that is somewhat lost in the summary. The y-axis is; a log-scale speedup ratio of load hardening relative to `lfence` (up -> faster; -> better). Each box-and-whiskers represents one microbenchmark which may have; many different metrics measured. The red line marks the median, the box marks; the first and third quartiles, and the whiskers mark the min and max. ![Microbenchmark result visualization](speculative_load_hardening_microbenchmarks.png). We don't yet have benchmark data on SPEC or the LLVM test suite, but we can; work on getting that. Still, the above should give a pretty clear; characterization of the performance, and specific benchmarks are unlikely to; reveal especially interesting properties. ### Future Work: Fine Grained Control and API-Integration. The performance overhead of this technique is likely to be very significant and; something users wish to control or reduce. There are interesting options here; that impact the implementation strategy used. One particularly appealing option is to allow both opt-in and opt-out of this; mitigation at reasonably fine granularity such as on a per-function basis,; including intelligent handling of inlining decisions -- protected code can be; prevented from inlining into unprotected code, and unprotected code will become; protected when inlined into protected code. For systems where only a limited; set of code is reachable by externally controlled inputs, it may be possible to; limit the scope of mitigation through such mec",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:48746,Testability,benchmark,benchmarks,48746,"| Load Hardening | Mitigated Speedup |; | -------------------------------------- | -------: | -------------: | ----------------: |; | Google microbenchmark suite | -74.8% | -36.4% | **2.5x** |; | Large server QPS (using ThinLTO & PGO) | -62% | -29% | **1.8x** |. Below is a visualization of the microbenchmark suite results which helps show; the distribution of results that is somewhat lost in the summary. The y-axis is; a log-scale speedup ratio of load hardening relative to `lfence` (up -> faster; -> better). Each box-and-whiskers represents one microbenchmark which may have; many different metrics measured. The red line marks the median, the box marks; the first and third quartiles, and the whiskers mark the min and max. ![Microbenchmark result visualization](speculative_load_hardening_microbenchmarks.png). We don't yet have benchmark data on SPEC or the LLVM test suite, but we can; work on getting that. Still, the above should give a pretty clear; characterization of the performance, and specific benchmarks are unlikely to; reveal especially interesting properties. ### Future Work: Fine Grained Control and API-Integration. The performance overhead of this technique is likely to be very significant and; something users wish to control or reduce. There are interesting options here; that impact the implementation strategy used. One particularly appealing option is to allow both opt-in and opt-out of this; mitigation at reasonably fine granularity such as on a per-function basis,; including intelligent handling of inlining decisions -- protected code can be; prevented from inlining into unprotected code, and unprotected code will become; protected when inlined into protected code. For systems where only a limited; set of code is reachable by externally controlled inputs, it may be possible to; limit the scope of mitigation through such mechanisms without compromising the; application's overall security. The performance impact may also be focused in a; few key functions",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:1471,Usability,simpl,simplified,1471,"ranch target injection; * GPZ Variant #3 (a.k.a. Meltdown): Rogue data cache load. For more details, see the Google Project Zero blog post and the Spectre research; paper:; * https://googleprojectzero.blogspot.com/2018/01/reading-privileged-memory-with-side.html; * https://spectreattack.com/spectre.pdf. The core problem of GPZ Variant #1 is that speculative execution uses branch; prediction to select the path of instructions speculatively executed. This path; is speculatively executed with the available data, and may load from memory and; leak the loaded values through various side channels that survive even when the; speculative execution is unwound due to being incorrect. Mispredicted paths can; cause code to be executed with data inputs that never occur in correct; executions, making checks against malicious inputs ineffective and allowing; attackers to use malicious data inputs to leak secret data. Here is an example,; extracted and simplified from the Project Zero paper:; ```; struct array {; unsigned long length;; unsigned char data[];; };; struct array *arr1 = ...; // small array; struct array *arr2 = ...; // array of size 0x400; unsigned long untrusted_offset_from_caller = ...;; if (untrusted_offset_from_caller < arr1->length) {; unsigned char value = arr1->data[untrusted_offset_from_caller];; unsigned long index2 = ((value&1)*0x100)+0x200;; unsigned char value2 = arr2->data[index2];; }; ```. The key of the attack is to call this with `untrusted_offset_from_caller` that; is far outside of the bounds when the branch predictor will predict that it; will be in-bounds. In that case, the body of the `if` will be executed; speculatively, and may read secret data into `value` and leak it via a; cache-timing side channel when a dependent access is made to populate `value2`. ## High Level Mitigation Approach. While several approaches are being actively pursued to mitigate specific; branches and/or loads inside especially risky software (most notably various OS; kerne",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:7074,Usability,guid,guidelines,7074,"ndamental assumptions about the; underlying architecture other than the ability to do branchless conditional; data updates and a lack of value prediction.; * It does not require programmers to identify all possible secret data using; static source code annotations or code vulnerable to a variant #1 style; attack. Limitations of this approach:; * It requires re-compiling source code to insert hardening instruction; sequences. Only software compiled in this mode is protected.; * The performance is heavily dependent on a particular architecture's; implementation strategy. We outline a potential x86 implementation below and; characterize its performance.; * It does not defend against secret data already loaded from memory and; residing in registers or leaked through other side-channels in; non-speculative execution. Code dealing with this, e.g cryptographic; routines, already uses constant-time algorithms and code to prevent; side-channels. Such code should also scrub registers of secret data following; [these; guidelines](https://github.com/HACS-workshop/spectre-mitigations/blob/master/crypto_guidelines.md).; * To achieve reasonable performance, many loads may not be checked, such as; those with compile-time fixed addresses. This primarily consists of accesses; at compile-time constant offsets of global and local variables. Code which; needs this protection and intentionally stores secret data must ensure the; memory regions used for secret data are necessarily dynamic mappings or heap; allocations. This is an area which can be tuned to provide more comprehensive; protection at the cost of performance.; * [Hardened loads](#hardening-the-address-of-the-load) may still load data from; _valid_ addresses if not _attacker-controlled_ addresses. To prevent these; from reading secret data, the low 2gb of the address space and 2gb above and; below any executable pages should be protected. Credit:; * The core idea of tracing misspeculation through data and marking pointers to; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:9151,Usability,simpl,simply,9151,"ls.; * Core idea of masking out loaded bits was part of the original mitigation; suggested by Jann Horn when these attacks were reported. ### Indirect Branches, Calls, and Returns. It is possible to attack control flow other than conditional branches with; variant #1 style mispredictions.; * A prediction towards a hot call target of a virtual method can lead to it; being speculatively executed when an expected type is used (often called; ""type confusion"").; * A hot case may be speculatively executed due to prediction instead of the; correct case for a switch statement implemented as a jump table.; * A hot common return address may be predicted incorrectly when returning from; a function. These code patterns are also vulnerable to Spectre variant #2, and as such are; best mitigated with a; [retpoline](https://support.google.com/faqs/answer/7625886) on x86 platforms.; When a mitigation technique like retpoline is used, speculation simply cannot; proceed through an indirect control flow edge (or it cannot be mispredicted in; the case of a filled RSB) and so it is also protected from variant #1 style; attacks. However, some architectures, micro-architectures, or vendors do not; employ the retpoline mitigation, and on future x86 hardware (both Intel and; AMD) it is expected to become unnecessary due to hardware-based mitigation. When not using a retpoline, these edges will need independent protection from; variant #1 style attacks. The analogous approach to that used for conditional; control flow should work:; ```; uintptr_t all_ones_mask = std::numerical_limits<uintptr_t>::max();; uintptr_t all_zeros_mask = 0;; void leak(int data);; void example(int* pointer1, int* pointer2) {; uintptr_t predicate_state = all_ones_mask;; switch (condition) {; case 0:; // Assuming ?: is implemented using branchless logic...; predicate_state = (condition != 0) ? all_zeros_mask : predicate_state;; // ... lots of code ...; //; // Harden the pointer so it can't be loaded; pointer1 &= predica",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:19107,Usability,simpl,simple,19107,"local; jump tables, this is easily arranged by testing the input to the jump table; within each destination (not yet implemented, use retpolines):; ```; pushq %rax; xorl %eax, %eax # Zero out initial predicate state.; movq $-1, %r8 # Put all-ones mask into a register.; jmpq *.LJTI0_0(,%rdi,8) # Indirect jump through table.; .LBB0_2: # %sw.bb; testq $0, %rdi # Validate index used for jump table.; cmovneq %r8, %rax # Conditionally update predicate state.; ...; jmp _Z4leaki # TAILCALL. .LBB0_3: # %sw.bb1; testq $1, %rdi # Validate index used for jump table.; cmovneq %r8, %rax # Conditionally update predicate state.; ...; jmp _Z4leaki # TAILCALL. .LBB0_5: # %sw.bb10; testq $2, %rdi # Validate index used for jump table.; cmovneq %r8, %rax # Conditionally update predicate state.; ...; jmp _Z4leaki # TAILCALL; ... .section .rodata,""a"",@progbits; .p2align 3; .LJTI0_0:; .quad .LBB0_2; .quad .LBB0_3; .quad .LBB0_5; ...; ```. Returns have a simple mitigation technique on x86-64 (or other ABIs which have; what is called a ""red zone"" region beyond the end of the stack). This region is; guaranteed to be preserved across interrupts and context switches, making the; return address used in returning to the current code remain on the stack and; valid to read. We can emit code in the caller to verify that a return edge was; not mispredicted:; ```; callq other_function; return_addr:; testq -8(%rsp), return_addr # Validate return address.; cmovneq %r8, %rax # Update predicate state.; ```. For an ABI without a ""red zone"" (and thus unable to read the return address; from the stack), we can compute the expected return address prior to the call; into a register preserved across the call and use that similarly to the above. Indirect calls (and returns in the absence of a red zone ABI) pose the most; significant challenge to propagate. The simplest technique would be to define a; new ABI such that the intended call target is passed into the called function; and checked in the entry. Unfortunat",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:20008,Usability,simpl,simplest,20008,"_5; ...; ```. Returns have a simple mitigation technique on x86-64 (or other ABIs which have; what is called a ""red zone"" region beyond the end of the stack). This region is; guaranteed to be preserved across interrupts and context switches, making the; return address used in returning to the current code remain on the stack and; valid to read. We can emit code in the caller to verify that a return edge was; not mispredicted:; ```; callq other_function; return_addr:; testq -8(%rsp), return_addr # Validate return address.; cmovneq %r8, %rax # Update predicate state.; ```. For an ABI without a ""red zone"" (and thus unable to read the return address; from the stack), we can compute the expected return address prior to the call; into a register preserved across the call and use that similarly to the above. Indirect calls (and returns in the absence of a red zone ABI) pose the most; significant challenge to propagate. The simplest technique would be to define a; new ABI such that the intended call target is passed into the called function; and checked in the entry. Unfortunately, new ABIs are quite expensive to deploy; in C and C++. While the target function could be passed in TLS, we would still; require complex logic to handle a mixture of functions compiled with and; without this extra logic (essentially, making the ABI backwards compatible).; Currently, we suggest using retpolines here and will continue to investigate; ways of mitigating this. ##### Optimizations, Alternatives, and Tradeoffs. Merely accumulating predicate state involves significant cost. There are; several key optimizations we employ to minimize this and various alternatives; that present different tradeoffs in the generated code. First, we work to reduce the number of instructions used to track the state:; * Rather than inserting a `cmovCC` instruction along every conditional edge in; the original program, we track each set of condition flags we need to capture; prior to entering each basic block and",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:21835,Usability,simpl,simpler,21835,"s used to track the state:; * Rather than inserting a `cmovCC` instruction along every conditional edge in; the original program, we track each set of condition flags we need to capture; prior to entering each basic block and reuse a common `cmovCC` sequence for; those.; * We could further reuse suffixes when there are multiple `cmovCC`; instructions required to capture the set of flags. Currently this is; believed to not be worth the cost as paired flags are relatively rare and; suffixes of them are exceedingly rare.; * A common pattern in x86 is to have multiple conditional jump instructions; that use the same flags but handle different conditions. Naively, we could; consider each fallthrough between them an ""edge"" but this causes a much more; complex control flow graph. Instead, we accumulate the set of conditions; necessary for fallthrough and use a sequence of `cmovCC` instructions in a; single fallthrough edge to track it. Second, we trade register pressure for simpler `cmovCC` instructions by; allocating a register for the ""bad"" state. We could read that value from memory; as part of the conditional move instruction, however, this creates more; micro-ops and requires the load-store unit to be involved. Currently, we place; the value into a virtual register and allow the register allocator to decide; when the register pressure is sufficient to make it worth spilling to memory; and reloading. #### Hardening Loads. Once we have the predicate accumulated into a special value for correct vs.; misspeculated, we need to apply this to loads in a way that ensures they do not; leak secret data. There are two primary techniques for this: we can either; harden the loaded value to prevent observation, or we can harden the address; itself to prevent the load from occurring. These have significantly different; performance tradeoffs. ##### Hardening loaded values. The most appealing way to harden loads is to mask out all of the bits loaded.; The key requirement is that for e",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:31010,Usability,simpl,simply,31010,"dress space to be user accessible may need to adjust the exact sequence used; above. Additionally, the low addresses will need to be marked unreadable by the; OS to fully harden the load. ###### RIP-relative addressing is even easier to break. There is a common addressing mode idiom that is substantially harder to check:; addressing relative to the instruction pointer. We cannot change the value of; the instruction pointer register and so we have the harder problem of forcing; `%base + scale * %index + offset` to be an invalid address, by *only* changing; `%index`. The only advantage we have is that the attacker also cannot modify; `%base`. If we use the fast instruction sequence above, but only apply it to; the index, we will always access `%rip + (scale * -1) + offset`. If the; attacker can find a load which with this address happens to point to secret; data, then they can reach it. However, the loader and base libraries can also; simply refuse to map the heap, data segments, or stack within 2gb of any of the; text in the program, much like it can reserve the low 2gb of address space. ###### The flag registers again make everything hard. Unfortunately, the technique of using `orq`-instructions has a serious flaw on; x86. The very thing that makes it easy to accumulate state, the flag registers; containing predicates, causes serious problems here because they may be alive; and used by the loading instruction or subsequent instructions. On x86, the; `orq` instruction **sets** the flags and will override anything already there.; This makes inserting them into the instruction stream very hazardous.; Unfortunately, unlike when hardening the loaded value, we have no fallback here; and so we must have a fully general approach available. The first thing we must do when generating these sequences is try to analyze; the surrounding code to prove that the flags are not in fact alive or being; used. Typically, it has been set by some other instruction which just happens; to s",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:45170,Usability,simpl,simply,45170,"oads/sites/11/2018/01/Intel-Analysis-of-Speculative-Execution-Side-Channels.pdf).; On AMD systems `lfence` is currently a no-op, but can be made; dispatch-serializing by setting an MSR, and thus preclude misspeculation of the; code path ([mitigation G-2 +; V1-1](https://developer.amd.com/wp-content/resources/Managing-Speculation-on-AMD-Processors.pdf)). However, this relies on finding and enumerating all possible points in code; which could be attacked to leak information. While in some cases static; analysis is effective at doing this at scale, in many cases it still relies on; human judgement to evaluate whether code might be vulnerable. Especially for; software systems which receive less detailed scrutiny but remain sensitive to; these attacks, this seems like an impractical security model. We need an; automatic and systematic mitigation strategy. ### Automatic `lfence` on Conditional Edges. A natural way to scale up the existing hand-coded mitigations is simply to; inject an `lfence` instruction into both the target and fallthrough; destinations of every conditional branch. This ensures that no predicate or; bounds check can be bypassed speculatively. However, the performance overhead; of this approach is, simply put, catastrophic. Yet it remains the only truly; ""secure by default"" approach known prior to this effort and serves as the; baseline for performance. One attempt to address the performance overhead of this and make it more; realistic to deploy is [MSVC's /Qspectre; switch](https://blogs.msdn.microsoft.com/vcblog/2018/01/15/spectre-mitigations-in-msvc/).; Their technique is to use static analysis within the compiler to only insert; `lfence` instructions into conditional edges at risk of attack. However,; [initial](https://arstechnica.com/gadgets/2018/02/microsofts-compiler-level-spectre-fix-shows-how-hard-this-problem-will-be-to-solve/); [analysis](https://www.paulkocher.com/doc/MicrosoftCompilerSpectreMitigation.html); has shown that this approach is in",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:45427,Usability,simpl,simply,45427,"tion of the; code path ([mitigation G-2 +; V1-1](https://developer.amd.com/wp-content/resources/Managing-Speculation-on-AMD-Processors.pdf)). However, this relies on finding and enumerating all possible points in code; which could be attacked to leak information. While in some cases static; analysis is effective at doing this at scale, in many cases it still relies on; human judgement to evaluate whether code might be vulnerable. Especially for; software systems which receive less detailed scrutiny but remain sensitive to; these attacks, this seems like an impractical security model. We need an; automatic and systematic mitigation strategy. ### Automatic `lfence` on Conditional Edges. A natural way to scale up the existing hand-coded mitigations is simply to; inject an `lfence` instruction into both the target and fallthrough; destinations of every conditional branch. This ensures that no predicate or; bounds check can be bypassed speculatively. However, the performance overhead; of this approach is, simply put, catastrophic. Yet it remains the only truly; ""secure by default"" approach known prior to this effort and serves as the; baseline for performance. One attempt to address the performance overhead of this and make it more; realistic to deploy is [MSVC's /Qspectre; switch](https://blogs.msdn.microsoft.com/vcblog/2018/01/15/spectre-mitigations-in-msvc/).; Their technique is to use static analysis within the compiler to only insert; `lfence` instructions into conditional edges at risk of attack. However,; [initial](https://arstechnica.com/gadgets/2018/02/microsofts-compiler-level-spectre-fix-shows-how-hard-this-problem-will-be-to-solve/); [analysis](https://www.paulkocher.com/doc/MicrosoftCompilerSpectreMitigation.html); has shown that this approach is incomplete and only catches a small and limited; subset of attackable patterns which happen to resemble very closely the initial; proofs of concept. As such, while its performance is acceptable, it does not; appear ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:48689,Usability,clear,clear,48689,"| Load Hardening | Mitigated Speedup |; | -------------------------------------- | -------: | -------------: | ----------------: |; | Google microbenchmark suite | -74.8% | -36.4% | **2.5x** |; | Large server QPS (using ThinLTO & PGO) | -62% | -29% | **1.8x** |. Below is a visualization of the microbenchmark suite results which helps show; the distribution of results that is somewhat lost in the summary. The y-axis is; a log-scale speedup ratio of load hardening relative to `lfence` (up -> faster; -> better). Each box-and-whiskers represents one microbenchmark which may have; many different metrics measured. The red line marks the median, the box marks; the first and third quartiles, and the whiskers mark the min and max. ![Microbenchmark result visualization](speculative_load_hardening_microbenchmarks.png). We don't yet have benchmark data on SPEC or the LLVM test suite, but we can; work on getting that. Still, the above should give a pretty clear; characterization of the performance, and specific benchmarks are unlikely to; reveal especially interesting properties. ### Future Work: Fine Grained Control and API-Integration. The performance overhead of this technique is likely to be very significant and; something users wish to control or reduce. There are interesting options here; that impact the implementation strategy used. One particularly appealing option is to allow both opt-in and opt-out of this; mitigation at reasonably fine granularity such as on a per-function basis,; including intelligent handling of inlining decisions -- protected code can be; prevented from inlining into unprotected code, and unprotected code will become; protected when inlined into protected code. For systems where only a limited; set of code is reachable by externally controlled inputs, it may be possible to; limit the scope of mitigation through such mechanisms without compromising the; application's overall security. The performance impact may also be focused in a; few key functions",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:6003,Availability,reliab,reliably,6003,"ay be changed by modifying `CMAKE_C_FLAGS_OPTIMIZE` etc. See; [https://cmake.org/cmake/help/latest/variable/CMAKE_BUILD_TYPE.html](https://cmake.org/cmake/help/latest/variable/CMAKE_BUILD_TYPE.html). - `TEST_SUITE_FORTRAN`. Activate that Fortran tests. This is a work in progress. More information can be; found in the [Flang documentation](https://flang.llvm.org/docs/FortranLLVMTestSuite.html). - `TEST_SUITE_RUN_UNDER`. Prefix test invocations with the given tool. This is typically used to run; cross-compiled tests within a simulator tool. - `TEST_SUITE_BENCHMARKING_ONLY`. Disable tests that are unsuitable for performance measurements. The disabled; tests either run for a very short time or are dominated by I/O performance; making them unsuitable as compiler performance tests. - `TEST_SUITE_SUBDIRS`. Semicolon-separated list of directories to include. This can be used to only; build parts of the test-suite or to include external suites. This option; does not work reliably with deeper subdirectories as it skips intermediate; `CMakeLists.txt` files which may be required. - `TEST_SUITE_COLLECT_STATS`. Collect internal LLVM statistics. Appends `-save-stats=obj` when invoking the; compiler and makes the lit runner collect and merge the statistic files. - `TEST_SUITE_RUN_BENCHMARKS`. If this is set to `OFF` then lit will not actually run the tests but just; collect build statistics like compile time and code size. - `TEST_SUITE_USE_PERF`. Use the `perf` tool for time measurement instead of the `timeit` tool that; comes with the test-suite. The `perf` is usually available on linux systems. - `TEST_SUITE_SPEC2000_ROOT`, `TEST_SUITE_SPEC2006_ROOT`, `TEST_SUITE_SPEC2017_ROOT`, ... Specify installation directories of external benchmark suites. You can find; more information about expected versions or usage in the README files in the; `External` directory (such as `External/SPEC/README`). ### Common CMake Flags. - `-GNinja`. Generate build files for the ninja build tool. - `-Cte",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:6607,Availability,avail,available,6607,"ble tests that are unsuitable for performance measurements. The disabled; tests either run for a very short time or are dominated by I/O performance; making them unsuitable as compiler performance tests. - `TEST_SUITE_SUBDIRS`. Semicolon-separated list of directories to include. This can be used to only; build parts of the test-suite or to include external suites. This option; does not work reliably with deeper subdirectories as it skips intermediate; `CMakeLists.txt` files which may be required. - `TEST_SUITE_COLLECT_STATS`. Collect internal LLVM statistics. Appends `-save-stats=obj` when invoking the; compiler and makes the lit runner collect and merge the statistic files. - `TEST_SUITE_RUN_BENCHMARKS`. If this is set to `OFF` then lit will not actually run the tests but just; collect build statistics like compile time and code size. - `TEST_SUITE_USE_PERF`. Use the `perf` tool for time measurement instead of the `timeit` tool that; comes with the test-suite. The `perf` is usually available on linux systems. - `TEST_SUITE_SPEC2000_ROOT`, `TEST_SUITE_SPEC2006_ROOT`, `TEST_SUITE_SPEC2017_ROOT`, ... Specify installation directories of external benchmark suites. You can find; more information about expected versions or usage in the README files in the; `External` directory (such as `External/SPEC/README`). ### Common CMake Flags. - `-GNinja`. Generate build files for the ninja build tool. - `-Ctest-suite/cmake/caches/<cachefile.cmake>`. Use a CMake cache. The test-suite comes with several CMake caches which; predefine common or tricky build configurations. Displaying and Analyzing Results; --------------------------------. The `compare.py` script displays and compares result files. A result file is; produced when invoking lit with the `-o filename.json` flag. Example usage:. - Basic Usage:. ```text; % test-suite/utils/compare.py baseline.json; Warning: 'test-suite :: External/SPEC/CINT2006/403.gcc/403.gcc.test' has No metrics!; Tests: 508; Metric: exec_time. Program b",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:13053,Availability,avail,available,13053,"-compiling](https://llvm.org/docs/lnt/tests.html#cross-compiling). - [https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html](https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html). Cross compilation from macOS to iOS is possible with the; `test-suite/cmake/caches/target-target-*-iphoneos-internal.cmake` CMake cache; files; this requires an internal iOS SDK. ### Running. There are two ways to run the tests in a cross compilation setting:. - Via SSH connection to an external device: The `TEST_SUITE_REMOTE_HOST` option; should be set to the SSH hostname. The executables and data files need to be; transferred to the device after compilation. This is typically done via the; `rsync` make target. After this, the lit runner can be used on the host; machine. It will prefix the benchmark and verification command lines with an; `ssh` command. Example:. ```bash; % cmake -G Ninja -D CMAKE_C_COMPILER=path/to/clang \; -C ../test-suite/cmake/caches/target-arm64-iphoneos-internal.cmake \; -D CMAKE_BUILD_TYPE=Release \; -D TEST_SUITE_REMOTE_HOST=mydevice \; ../test-suite; % ninja; % ninja rsync; % llvm-lit -j1 -o result.json .; ```. - You can specify a simulator for the target machine with the; `TEST_SUITE_RUN_UNDER` setting. The lit runner will prefix all benchmark; invocations with it. Running the test-suite via LNT; ------------------------------. The LNT tool can run the test-suite. Use this when submitting test results to; an LNT instance. See; [https://llvm.org/docs/lnt/tests.html#llvm-cmake-test-suite](https://llvm.org/docs/lnt/tests.html#llvm-cmake-test-suite); for details. Running the test-suite via Makefiles (deprecated); -------------------------------------------------. **Note**: The test-suite comes with a set of Makefiles that are considered; deprecated. They do not support newer testing modes like `Bitcode` or; `Microbenchmarks` and are harder to use. Old documentation is available in the; [test-suite Makefile Guide](TestSuiteMakefileGuide).; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:251,Deployability,install,installing,251,"test-suite Guide; ================. Quickstart; ----------. 1. The lit test runner is required to run the tests. You can either use one; from an LLVM build:. ```bash; % <path to llvm build>/bin/llvm-lit --version; lit 0.8.0dev; ```. An alternative is installing it as a python package in a python virtual; environment:. ```bash; % mkdir venv; % virtualenv venv; % . venv/bin/activate; % pip install svn+https://llvm.org/svn/llvm-project/llvm/trunk/utils/lit; % lit --version; lit 0.8.0dev; ```. 2. Check out the `test-suite` module with:. ```bash; % git clone https://github.com/llvm/llvm-test-suite.git test-suite; ```. 3. Create a build directory and use CMake to configure the suite. Use the; `CMAKE_C_COMPILER` option to specify the compiler to test. Use a cache file; to choose a typical build configuration:. ```bash; % mkdir test-suite-build; % cd test-suite-build; % cmake -DCMAKE_C_COMPILER=<path to llvm build>/bin/clang \; -C../test-suite/cmake/caches/O3.cmake \; ../test-suite; ```. **NOTE!** if you are using your built clang, and you want to build and run the; MicroBenchmarks/XRay microbenchmarks, you need to add `compiler-rt` to your; `LLVM_ENABLE_RUNTIMES` cmake flag. 4. Build the benchmarks:. ```text; % make; Scanning dependencies of target timeit-target; [ 0%] Building C object tools/CMakeFiles/timeit-target.dir/timeit.c.o; [ 0%] Linking C executable timeit-target; ...; ```. 5. Run the tests with lit:. ```text; % llvm-lit -v -j 1 -o results.json .; -- Testing: 474 tests, 1 threads --; PASS: test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test (1 of 474); ********** TEST 'test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test' RESULTS **********; compile_time: 0.2192; exec_time: 0.0462; hash: ""59620e187c6ac38b36382685ccd2b63b""; size: 83348; **********; PASS: test-suite :: MultiSource/Applications/ALAC/encode/alacconvert-encode.test (2 of 474); ...; ```. 6. Show and compare result files (optional):. ```bash; # Make sure panda",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:391,Deployability,install,install,391,"test-suite Guide; ================. Quickstart; ----------. 1. The lit test runner is required to run the tests. You can either use one; from an LLVM build:. ```bash; % <path to llvm build>/bin/llvm-lit --version; lit 0.8.0dev; ```. An alternative is installing it as a python package in a python virtual; environment:. ```bash; % mkdir venv; % virtualenv venv; % . venv/bin/activate; % pip install svn+https://llvm.org/svn/llvm-project/llvm/trunk/utils/lit; % lit --version; lit 0.8.0dev; ```. 2. Check out the `test-suite` module with:. ```bash; % git clone https://github.com/llvm/llvm-test-suite.git test-suite; ```. 3. Create a build directory and use CMake to configure the suite. Use the; `CMAKE_C_COMPILER` option to specify the compiler to test. Use a cache file; to choose a typical build configuration:. ```bash; % mkdir test-suite-build; % cd test-suite-build; % cmake -DCMAKE_C_COMPILER=<path to llvm build>/bin/clang \; -C../test-suite/cmake/caches/O3.cmake \; ../test-suite; ```. **NOTE!** if you are using your built clang, and you want to build and run the; MicroBenchmarks/XRay microbenchmarks, you need to add `compiler-rt` to your; `LLVM_ENABLE_RUNTIMES` cmake flag. 4. Build the benchmarks:. ```text; % make; Scanning dependencies of target timeit-target; [ 0%] Building C object tools/CMakeFiles/timeit-target.dir/timeit.c.o; [ 0%] Linking C executable timeit-target; ...; ```. 5. Run the tests with lit:. ```text; % llvm-lit -v -j 1 -o results.json .; -- Testing: 474 tests, 1 threads --; PASS: test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test (1 of 474); ********** TEST 'test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test' RESULTS **********; compile_time: 0.2192; exec_time: 0.0462; hash: ""59620e187c6ac38b36382685ccd2b63b""; size: 83348; **********; PASS: test-suite :: MultiSource/Applications/ALAC/encode/alacconvert-encode.test (2 of 474); ...; ```. 6. Show and compare result files (optional):. ```bash; # Make sure panda",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:799,Deployability,configurat,configuration,799,"test-suite Guide; ================. Quickstart; ----------. 1. The lit test runner is required to run the tests. You can either use one; from an LLVM build:. ```bash; % <path to llvm build>/bin/llvm-lit --version; lit 0.8.0dev; ```. An alternative is installing it as a python package in a python virtual; environment:. ```bash; % mkdir venv; % virtualenv venv; % . venv/bin/activate; % pip install svn+https://llvm.org/svn/llvm-project/llvm/trunk/utils/lit; % lit --version; lit 0.8.0dev; ```. 2. Check out the `test-suite` module with:. ```bash; % git clone https://github.com/llvm/llvm-test-suite.git test-suite; ```. 3. Create a build directory and use CMake to configure the suite. Use the; `CMAKE_C_COMPILER` option to specify the compiler to test. Use a cache file; to choose a typical build configuration:. ```bash; % mkdir test-suite-build; % cd test-suite-build; % cmake -DCMAKE_C_COMPILER=<path to llvm build>/bin/clang \; -C../test-suite/cmake/caches/O3.cmake \; ../test-suite; ```. **NOTE!** if you are using your built clang, and you want to build and run the; MicroBenchmarks/XRay microbenchmarks, you need to add `compiler-rt` to your; `LLVM_ENABLE_RUNTIMES` cmake flag. 4. Build the benchmarks:. ```text; % make; Scanning dependencies of target timeit-target; [ 0%] Building C object tools/CMakeFiles/timeit-target.dir/timeit.c.o; [ 0%] Linking C executable timeit-target; ...; ```. 5. Run the tests with lit:. ```text; % llvm-lit -v -j 1 -o results.json .; -- Testing: 474 tests, 1 threads --; PASS: test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test (1 of 474); ********** TEST 'test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test' RESULTS **********; compile_time: 0.2192; exec_time: 0.0462; hash: ""59620e187c6ac38b36382685ccd2b63b""; size: 83348; **********; PASS: test-suite :: MultiSource/Applications/ALAC/encode/alacconvert-encode.test (2 of 474); ...; ```. 6. Show and compare result files (optional):. ```bash; # Make sure panda",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:2017,Deployability,install,installed,2017,"E!** if you are using your built clang, and you want to build and run the; MicroBenchmarks/XRay microbenchmarks, you need to add `compiler-rt` to your; `LLVM_ENABLE_RUNTIMES` cmake flag. 4. Build the benchmarks:. ```text; % make; Scanning dependencies of target timeit-target; [ 0%] Building C object tools/CMakeFiles/timeit-target.dir/timeit.c.o; [ 0%] Linking C executable timeit-target; ...; ```. 5. Run the tests with lit:. ```text; % llvm-lit -v -j 1 -o results.json .; -- Testing: 474 tests, 1 threads --; PASS: test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test (1 of 474); ********** TEST 'test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test' RESULTS **********; compile_time: 0.2192; exec_time: 0.0462; hash: ""59620e187c6ac38b36382685ccd2b63b""; size: 83348; **********; PASS: test-suite :: MultiSource/Applications/ALAC/encode/alacconvert-encode.test (2 of 474); ...; ```. 6. Show and compare result files (optional):. ```bash; # Make sure pandas and scipy are installed. Prepend `sudo` if necessary.; % pip install pandas scipy; # Show a single result file:; % test-suite/utils/compare.py results.json; # Compare two result files:; % test-suite/utils/compare.py results_a.json results_b.json; ```. Structure; ---------. The test-suite contains benchmark and test programs. The programs come with; reference outputs so that their correctness can be checked. The suite comes; with tools to collect metrics such as benchmark runtime, compilation time and; code size. The test-suite is divided into several directories:. - `SingleSource/`. Contains test programs that are only a single source file in size. A; subdirectory may contain several programs. - `MultiSource/`. Contains subdirectories which entire programs with multiple source files.; Large benchmarks and whole applications go here. - `MicroBenchmarks/`. Programs using the [google-benchmark](https://github.com/google/benchmark); library. The programs define functions that are run mul",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:2064,Deployability,install,install,2064,"robenchmarks, you need to add `compiler-rt` to your; `LLVM_ENABLE_RUNTIMES` cmake flag. 4. Build the benchmarks:. ```text; % make; Scanning dependencies of target timeit-target; [ 0%] Building C object tools/CMakeFiles/timeit-target.dir/timeit.c.o; [ 0%] Linking C executable timeit-target; ...; ```. 5. Run the tests with lit:. ```text; % llvm-lit -v -j 1 -o results.json .; -- Testing: 474 tests, 1 threads --; PASS: test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test (1 of 474); ********** TEST 'test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test' RESULTS **********; compile_time: 0.2192; exec_time: 0.0462; hash: ""59620e187c6ac38b36382685ccd2b63b""; size: 83348; **********; PASS: test-suite :: MultiSource/Applications/ALAC/encode/alacconvert-encode.test (2 of 474); ...; ```. 6. Show and compare result files (optional):. ```bash; # Make sure pandas and scipy are installed. Prepend `sudo` if necessary.; % pip install pandas scipy; # Show a single result file:; % test-suite/utils/compare.py results.json; # Compare two result files:; % test-suite/utils/compare.py results_a.json results_b.json; ```. Structure; ---------. The test-suite contains benchmark and test programs. The programs come with; reference outputs so that their correctness can be checked. The suite comes; with tools to collect metrics such as benchmark runtime, compilation time and; code size. The test-suite is divided into several directories:. - `SingleSource/`. Contains test programs that are only a single source file in size. A; subdirectory may contain several programs. - `MultiSource/`. Contains subdirectories which entire programs with multiple source files.; Large benchmarks and whole applications go here. - `MicroBenchmarks/`. Programs using the [google-benchmark](https://github.com/google/benchmark); library. The programs define functions that are run multiple times until the; measurement results are statistically significant. - `External/`. Contains d",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:3765,Deployability,configurat,configuration,3765,files.; Large benchmarks and whole applications go here. - `MicroBenchmarks/`. Programs using the [google-benchmark](https://github.com/google/benchmark); library. The programs define functions that are run multiple times until the; measurement results are statistically significant. - `External/`. Contains descriptions and test data for code that cannot be directly; distributed with the test-suite. The most prominent members of this; directory are the SPEC CPU benchmark suites.; See [External Suites](#external-suites). - `Bitcode/`. These tests are mostly written in LLVM bitcode. - `CTMark/`. Contains symbolic links to other benchmarks forming a representative sample; for compilation performance measurements. ### Benchmarks. Every program can work as a correctness test. Some programs are unsuitable for; performance measurements. Setting the `TEST_SUITE_BENCHMARKING_ONLY` CMake; option to `ON` will disable them. Configuration; -------------. The test-suite has configuration options to customize building and running the; benchmarks. CMake can print a list of them:. ```bash; % cd test-suite-build; # Print basic options:; % cmake -LH; # Print all options:; % cmake -LAH; ```. ### Common Configuration Options. - `CMAKE_C_FLAGS`. Specify extra flags to be passed to C compiler invocations. The flags are; also passed to the C++ compiler and linker invocations. See; [https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_FLAGS.html](https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_FLAGS.html). - `CMAKE_C_COMPILER`. Select the C compiler executable to be used. Note that the C++ compiler is; inferred automatically i.e. when specifying `path/to/clang` CMake will; automatically use `path/to/clang++` as the C++ compiler. See; [https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_COMPILER.html](https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_COMPILER.html). - `CMAKE_Fortran_COMPILER`. Select the Fortran compiler executable to be used. Not set by default and not; ,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:6733,Deployability,install,installation,6733,"ce; making them unsuitable as compiler performance tests. - `TEST_SUITE_SUBDIRS`. Semicolon-separated list of directories to include. This can be used to only; build parts of the test-suite or to include external suites. This option; does not work reliably with deeper subdirectories as it skips intermediate; `CMakeLists.txt` files which may be required. - `TEST_SUITE_COLLECT_STATS`. Collect internal LLVM statistics. Appends `-save-stats=obj` when invoking the; compiler and makes the lit runner collect and merge the statistic files. - `TEST_SUITE_RUN_BENCHMARKS`. If this is set to `OFF` then lit will not actually run the tests but just; collect build statistics like compile time and code size. - `TEST_SUITE_USE_PERF`. Use the `perf` tool for time measurement instead of the `timeit` tool that; comes with the test-suite. The `perf` is usually available on linux systems. - `TEST_SUITE_SPEC2000_ROOT`, `TEST_SUITE_SPEC2006_ROOT`, `TEST_SUITE_SPEC2017_ROOT`, ... Specify installation directories of external benchmark suites. You can find; more information about expected versions or usage in the README files in the; `External` directory (such as `External/SPEC/README`). ### Common CMake Flags. - `-GNinja`. Generate build files for the ninja build tool. - `-Ctest-suite/cmake/caches/<cachefile.cmake>`. Use a CMake cache. The test-suite comes with several CMake caches which; predefine common or tricky build configurations. Displaying and Analyzing Results; --------------------------------. The `compare.py` script displays and compares result files. A result file is; produced when invoking lit with the `-o filename.json` flag. Example usage:. - Basic Usage:. ```text; % test-suite/utils/compare.py baseline.json; Warning: 'test-suite :: External/SPEC/CINT2006/403.gcc/403.gcc.test' has No metrics!; Tests: 508; Metric: exec_time. Program baseline. INT2006/456.hmmer/456.hmmer 1222.90; INT2006/464.h264ref/464.h264ref 928.70; ...; baseline; count 506.000000; mean 20.563098; std 111.4233",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:7174,Deployability,configurat,configurations,7174,"S`. Collect internal LLVM statistics. Appends `-save-stats=obj` when invoking the; compiler and makes the lit runner collect and merge the statistic files. - `TEST_SUITE_RUN_BENCHMARKS`. If this is set to `OFF` then lit will not actually run the tests but just; collect build statistics like compile time and code size. - `TEST_SUITE_USE_PERF`. Use the `perf` tool for time measurement instead of the `timeit` tool that; comes with the test-suite. The `perf` is usually available on linux systems. - `TEST_SUITE_SPEC2000_ROOT`, `TEST_SUITE_SPEC2006_ROOT`, `TEST_SUITE_SPEC2017_ROOT`, ... Specify installation directories of external benchmark suites. You can find; more information about expected versions or usage in the README files in the; `External` directory (such as `External/SPEC/README`). ### Common CMake Flags. - `-GNinja`. Generate build files for the ninja build tool. - `-Ctest-suite/cmake/caches/<cachefile.cmake>`. Use a CMake cache. The test-suite comes with several CMake caches which; predefine common or tricky build configurations. Displaying and Analyzing Results; --------------------------------. The `compare.py` script displays and compares result files. A result file is; produced when invoking lit with the `-o filename.json` flag. Example usage:. - Basic Usage:. ```text; % test-suite/utils/compare.py baseline.json; Warning: 'test-suite :: External/SPEC/CINT2006/403.gcc/403.gcc.test' has No metrics!; Tests: 508; Metric: exec_time. Program baseline. INT2006/456.hmmer/456.hmmer 1222.90; INT2006/464.h264ref/464.h264ref 928.70; ...; baseline; count 506.000000; mean 20.563098; std 111.423325; min 0.003400; 25% 0.011200; 50% 0.339450; 75% 4.067200; max 1222.896800; ```. - Show compile_time or text segment size metrics:. ```bash; % test-suite/utils/compare.py -m compile_time baseline.json; % test-suite/utils/compare.py -m size.__text baseline.json; ```. - Compare two result files and filter short running tests:. ```bash; % test-suite/utils/compare.py --filter-short ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:8683,Deployability,continuous,continuously,8683,"h264ref 928.70; ...; baseline; count 506.000000; mean 20.563098; std 111.423325; min 0.003400; 25% 0.011200; 50% 0.339450; 75% 4.067200; max 1222.896800; ```. - Show compile_time or text segment size metrics:. ```bash; % test-suite/utils/compare.py -m compile_time baseline.json; % test-suite/utils/compare.py -m size.__text baseline.json; ```. - Compare two result files and filter short running tests:. ```bash; % test-suite/utils/compare.py --filter-short baseline.json experiment.json; ...; Program baseline experiment diff. SingleSour.../Benchmarks/Linpack/linpack-pc 5.16 4.30 -16.5%; MultiSourc...erolling-dbl/LoopRerolling-dbl 7.01 7.86 12.2%; SingleSour...UnitTests/Vectorizer/gcc-loops 3.89 3.54 -9.0%; ...; ```. - Merge multiple baseline and experiment result files by taking the minimum; runtime each:. ```bash; % test-suite/utils/compare.py base0.json base1.json base2.json vs exp0.json exp1.json exp2.json; ```. ### Continuous Tracking with LNT. LNT is a set of client and server tools for continuously monitoring; performance. You can find more information at; [https://llvm.org/docs/lnt](https://llvm.org/docs/lnt). The official LNT instance; of the LLVM project is hosted at [http://lnt.llvm.org](http://lnt.llvm.org). External Suites; ---------------. External suites such as SPEC can be enabled by either. - placing (or linking) them into the `test-suite/test-suite-externals/xxx` directory (example: `test-suite/test-suite-externals/speccpu2000`); - using a configuration option such as `-D TEST_SUITE_SPEC2000_ROOT=path/to/speccpu2000`. You can find further information in the respective README files such as; `test-suite/External/SPEC/README`. For the SPEC benchmarks you can switch between the `test`, `train` and; `ref` input datasets via the `TEST_SUITE_RUN_TYPE` configuration option.; The `train` dataset is used by default. Custom Suites; -------------. You can build custom suites using the test-suite infrastructure. A custom suite; has a `CMakeLists.txt` file at the to",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:9157,Deployability,configurat,configuration,9157,".py --filter-short baseline.json experiment.json; ...; Program baseline experiment diff. SingleSour.../Benchmarks/Linpack/linpack-pc 5.16 4.30 -16.5%; MultiSourc...erolling-dbl/LoopRerolling-dbl 7.01 7.86 12.2%; SingleSour...UnitTests/Vectorizer/gcc-loops 3.89 3.54 -9.0%; ...; ```. - Merge multiple baseline and experiment result files by taking the minimum; runtime each:. ```bash; % test-suite/utils/compare.py base0.json base1.json base2.json vs exp0.json exp1.json exp2.json; ```. ### Continuous Tracking with LNT. LNT is a set of client and server tools for continuously monitoring; performance. You can find more information at; [https://llvm.org/docs/lnt](https://llvm.org/docs/lnt). The official LNT instance; of the LLVM project is hosted at [http://lnt.llvm.org](http://lnt.llvm.org). External Suites; ---------------. External suites such as SPEC can be enabled by either. - placing (or linking) them into the `test-suite/test-suite-externals/xxx` directory (example: `test-suite/test-suite-externals/speccpu2000`); - using a configuration option such as `-D TEST_SUITE_SPEC2000_ROOT=path/to/speccpu2000`. You can find further information in the respective README files such as; `test-suite/External/SPEC/README`. For the SPEC benchmarks you can switch between the `test`, `train` and; `ref` input datasets via the `TEST_SUITE_RUN_TYPE` configuration option.; The `train` dataset is used by default. Custom Suites; -------------. You can build custom suites using the test-suite infrastructure. A custom suite; has a `CMakeLists.txt` file at the top directory. The `CMakeLists.txt` will be; picked up automatically if placed into a subdirectory of the test-suite or when; setting the `TEST_SUITE_SUBDIRS` variable:. ```bash; % cmake -DTEST_SUITE_SUBDIRS=path/to/my/benchmark-suite ../test-suite; ```. Profile Guided Optimization; ---------------------------. Profile guided optimization requires to compile and run twice. First the; benchmark should be compiled with profile generation ins",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:9468,Deployability,configurat,configuration,9468,"le baseline and experiment result files by taking the minimum; runtime each:. ```bash; % test-suite/utils/compare.py base0.json base1.json base2.json vs exp0.json exp1.json exp2.json; ```. ### Continuous Tracking with LNT. LNT is a set of client and server tools for continuously monitoring; performance. You can find more information at; [https://llvm.org/docs/lnt](https://llvm.org/docs/lnt). The official LNT instance; of the LLVM project is hosted at [http://lnt.llvm.org](http://lnt.llvm.org). External Suites; ---------------. External suites such as SPEC can be enabled by either. - placing (or linking) them into the `test-suite/test-suite-externals/xxx` directory (example: `test-suite/test-suite-externals/speccpu2000`); - using a configuration option such as `-D TEST_SUITE_SPEC2000_ROOT=path/to/speccpu2000`. You can find further information in the respective README files such as; `test-suite/External/SPEC/README`. For the SPEC benchmarks you can switch between the `test`, `train` and; `ref` input datasets via the `TEST_SUITE_RUN_TYPE` configuration option.; The `train` dataset is used by default. Custom Suites; -------------. You can build custom suites using the test-suite infrastructure. A custom suite; has a `CMakeLists.txt` file at the top directory. The `CMakeLists.txt` will be; picked up automatically if placed into a subdirectory of the test-suite or when; setting the `TEST_SUITE_SUBDIRS` variable:. ```bash; % cmake -DTEST_SUITE_SUBDIRS=path/to/my/benchmark-suite ../test-suite; ```. Profile Guided Optimization; ---------------------------. Profile guided optimization requires to compile and run twice. First the; benchmark should be compiled with profile generation instrumentation enabled; and setup for training data. The lit runner will merge the profile files; using `llvm-profdata` so they can be used by the second compilation run. Example:; ```bash; # Profile generation run using LLVM IR PGO:; % cmake -DTEST_SUITE_PROFILE_GENERATE=ON \; -DTEST_SUITE_USE_IR_",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:8696,Energy Efficiency,monitor,monitoring,8696,"h264ref 928.70; ...; baseline; count 506.000000; mean 20.563098; std 111.423325; min 0.003400; 25% 0.011200; 50% 0.339450; 75% 4.067200; max 1222.896800; ```. - Show compile_time or text segment size metrics:. ```bash; % test-suite/utils/compare.py -m compile_time baseline.json; % test-suite/utils/compare.py -m size.__text baseline.json; ```. - Compare two result files and filter short running tests:. ```bash; % test-suite/utils/compare.py --filter-short baseline.json experiment.json; ...; Program baseline experiment diff. SingleSour.../Benchmarks/Linpack/linpack-pc 5.16 4.30 -16.5%; MultiSourc...erolling-dbl/LoopRerolling-dbl 7.01 7.86 12.2%; SingleSour...UnitTests/Vectorizer/gcc-loops 3.89 3.54 -9.0%; ...; ```. - Merge multiple baseline and experiment result files by taking the minimum; runtime each:. ```bash; % test-suite/utils/compare.py base0.json base1.json base2.json vs exp0.json exp1.json exp2.json; ```. ### Continuous Tracking with LNT. LNT is a set of client and server tools for continuously monitoring; performance. You can find more information at; [https://llvm.org/docs/lnt](https://llvm.org/docs/lnt). The official LNT instance; of the LLVM project is hosted at [http://lnt.llvm.org](http://lnt.llvm.org). External Suites; ---------------. External suites such as SPEC can be enabled by either. - placing (or linking) them into the `test-suite/test-suite-externals/xxx` directory (example: `test-suite/test-suite-externals/speccpu2000`); - using a configuration option such as `-D TEST_SUITE_SPEC2000_ROOT=path/to/speccpu2000`. You can find further information in the respective README files such as; `test-suite/External/SPEC/README`. For the SPEC benchmarks you can switch between the `test`, `train` and; `ref` input datasets via the `TEST_SUITE_RUN_TYPE` configuration option.; The `train` dataset is used by default. Custom Suites; -------------. You can build custom suites using the test-suite infrastructure. A custom suite; has a `CMakeLists.txt` file at the to",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:1239,Integrability,depend,dependencies,1239,"thon package in a python virtual; environment:. ```bash; % mkdir venv; % virtualenv venv; % . venv/bin/activate; % pip install svn+https://llvm.org/svn/llvm-project/llvm/trunk/utils/lit; % lit --version; lit 0.8.0dev; ```. 2. Check out the `test-suite` module with:. ```bash; % git clone https://github.com/llvm/llvm-test-suite.git test-suite; ```. 3. Create a build directory and use CMake to configure the suite. Use the; `CMAKE_C_COMPILER` option to specify the compiler to test. Use a cache file; to choose a typical build configuration:. ```bash; % mkdir test-suite-build; % cd test-suite-build; % cmake -DCMAKE_C_COMPILER=<path to llvm build>/bin/clang \; -C../test-suite/cmake/caches/O3.cmake \; ../test-suite; ```. **NOTE!** if you are using your built clang, and you want to build and run the; MicroBenchmarks/XRay microbenchmarks, you need to add `compiler-rt` to your; `LLVM_ENABLE_RUNTIMES` cmake flag. 4. Build the benchmarks:. ```text; % make; Scanning dependencies of target timeit-target; [ 0%] Building C object tools/CMakeFiles/timeit-target.dir/timeit.c.o; [ 0%] Linking C executable timeit-target; ...; ```. 5. Run the tests with lit:. ```text; % llvm-lit -v -j 1 -o results.json .; -- Testing: 474 tests, 1 threads --; PASS: test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test (1 of 474); ********** TEST 'test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test' RESULTS **********; compile_time: 0.2192; exec_time: 0.0462; hash: ""59620e187c6ac38b36382685ccd2b63b""; size: 83348; **********; PASS: test-suite :: MultiSource/Applications/ALAC/encode/alacconvert-encode.test (2 of 474); ...; ```. 6. Show and compare result files (optional):. ```bash; # Make sure pandas and scipy are installed. Prepend `sudo` if necessary.; % pip install pandas scipy; # Show a single result file:; % test-suite/utils/compare.py results.json; # Compare two result files:; % test-suite/utils/compare.py results_a.json results_b.json; ```. Structure; ------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:666,Modifiability,config,configure,666,"test-suite Guide; ================. Quickstart; ----------. 1. The lit test runner is required to run the tests. You can either use one; from an LLVM build:. ```bash; % <path to llvm build>/bin/llvm-lit --version; lit 0.8.0dev; ```. An alternative is installing it as a python package in a python virtual; environment:. ```bash; % mkdir venv; % virtualenv venv; % . venv/bin/activate; % pip install svn+https://llvm.org/svn/llvm-project/llvm/trunk/utils/lit; % lit --version; lit 0.8.0dev; ```. 2. Check out the `test-suite` module with:. ```bash; % git clone https://github.com/llvm/llvm-test-suite.git test-suite; ```. 3. Create a build directory and use CMake to configure the suite. Use the; `CMAKE_C_COMPILER` option to specify the compiler to test. Use a cache file; to choose a typical build configuration:. ```bash; % mkdir test-suite-build; % cd test-suite-build; % cmake -DCMAKE_C_COMPILER=<path to llvm build>/bin/clang \; -C../test-suite/cmake/caches/O3.cmake \; ../test-suite; ```. **NOTE!** if you are using your built clang, and you want to build and run the; MicroBenchmarks/XRay microbenchmarks, you need to add `compiler-rt` to your; `LLVM_ENABLE_RUNTIMES` cmake flag. 4. Build the benchmarks:. ```text; % make; Scanning dependencies of target timeit-target; [ 0%] Building C object tools/CMakeFiles/timeit-target.dir/timeit.c.o; [ 0%] Linking C executable timeit-target; ...; ```. 5. Run the tests with lit:. ```text; % llvm-lit -v -j 1 -o results.json .; -- Testing: 474 tests, 1 threads --; PASS: test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test (1 of 474); ********** TEST 'test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test' RESULTS **********; compile_time: 0.2192; exec_time: 0.0462; hash: ""59620e187c6ac38b36382685ccd2b63b""; size: 83348; **********; PASS: test-suite :: MultiSource/Applications/ALAC/encode/alacconvert-encode.test (2 of 474); ...; ```. 6. Show and compare result files (optional):. ```bash; # Make sure panda",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:799,Modifiability,config,configuration,799,"test-suite Guide; ================. Quickstart; ----------. 1. The lit test runner is required to run the tests. You can either use one; from an LLVM build:. ```bash; % <path to llvm build>/bin/llvm-lit --version; lit 0.8.0dev; ```. An alternative is installing it as a python package in a python virtual; environment:. ```bash; % mkdir venv; % virtualenv venv; % . venv/bin/activate; % pip install svn+https://llvm.org/svn/llvm-project/llvm/trunk/utils/lit; % lit --version; lit 0.8.0dev; ```. 2. Check out the `test-suite` module with:. ```bash; % git clone https://github.com/llvm/llvm-test-suite.git test-suite; ```. 3. Create a build directory and use CMake to configure the suite. Use the; `CMAKE_C_COMPILER` option to specify the compiler to test. Use a cache file; to choose a typical build configuration:. ```bash; % mkdir test-suite-build; % cd test-suite-build; % cmake -DCMAKE_C_COMPILER=<path to llvm build>/bin/clang \; -C../test-suite/cmake/caches/O3.cmake \; ../test-suite; ```. **NOTE!** if you are using your built clang, and you want to build and run the; MicroBenchmarks/XRay microbenchmarks, you need to add `compiler-rt` to your; `LLVM_ENABLE_RUNTIMES` cmake flag. 4. Build the benchmarks:. ```text; % make; Scanning dependencies of target timeit-target; [ 0%] Building C object tools/CMakeFiles/timeit-target.dir/timeit.c.o; [ 0%] Linking C executable timeit-target; ...; ```. 5. Run the tests with lit:. ```text; % llvm-lit -v -j 1 -o results.json .; -- Testing: 474 tests, 1 threads --; PASS: test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test (1 of 474); ********** TEST 'test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test' RESULTS **********; compile_time: 0.2192; exec_time: 0.0462; hash: ""59620e187c6ac38b36382685ccd2b63b""; size: 83348; **********; PASS: test-suite :: MultiSource/Applications/ALAC/encode/alacconvert-encode.test (2 of 474); ...; ```. 6. Show and compare result files (optional):. ```bash; # Make sure panda",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:3765,Modifiability,config,configuration,3765,files.; Large benchmarks and whole applications go here. - `MicroBenchmarks/`. Programs using the [google-benchmark](https://github.com/google/benchmark); library. The programs define functions that are run multiple times until the; measurement results are statistically significant. - `External/`. Contains descriptions and test data for code that cannot be directly; distributed with the test-suite. The most prominent members of this; directory are the SPEC CPU benchmark suites.; See [External Suites](#external-suites). - `Bitcode/`. These tests are mostly written in LLVM bitcode. - `CTMark/`. Contains symbolic links to other benchmarks forming a representative sample; for compilation performance measurements. ### Benchmarks. Every program can work as a correctness test. Some programs are unsuitable for; performance measurements. Setting the `TEST_SUITE_BENCHMARKING_ONLY` CMake; option to `ON` will disable them. Configuration; -------------. The test-suite has configuration options to customize building and running the; benchmarks. CMake can print a list of them:. ```bash; % cd test-suite-build; # Print basic options:; % cmake -LH; # Print all options:; % cmake -LAH; ```. ### Common Configuration Options. - `CMAKE_C_FLAGS`. Specify extra flags to be passed to C compiler invocations. The flags are; also passed to the C++ compiler and linker invocations. See; [https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_FLAGS.html](https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_FLAGS.html). - `CMAKE_C_COMPILER`. Select the C compiler executable to be used. Note that the C++ compiler is; inferred automatically i.e. when specifying `path/to/clang` CMake will; automatically use `path/to/clang++` as the C++ compiler. See; [https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_COMPILER.html](https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_COMPILER.html). - `CMAKE_Fortran_COMPILER`. Select the Fortran compiler executable to be used. Not set by default and not; ,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:4207,Modifiability,variab,variable,4207,nt members of this; directory are the SPEC CPU benchmark suites.; See [External Suites](#external-suites). - `Bitcode/`. These tests are mostly written in LLVM bitcode. - `CTMark/`. Contains symbolic links to other benchmarks forming a representative sample; for compilation performance measurements. ### Benchmarks. Every program can work as a correctness test. Some programs are unsuitable for; performance measurements. Setting the `TEST_SUITE_BENCHMARKING_ONLY` CMake; option to `ON` will disable them. Configuration; -------------. The test-suite has configuration options to customize building and running the; benchmarks. CMake can print a list of them:. ```bash; % cd test-suite-build; # Print basic options:; % cmake -LH; # Print all options:; % cmake -LAH; ```. ### Common Configuration Options. - `CMAKE_C_FLAGS`. Specify extra flags to be passed to C compiler invocations. The flags are; also passed to the C++ compiler and linker invocations. See; [https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_FLAGS.html](https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_FLAGS.html). - `CMAKE_C_COMPILER`. Select the C compiler executable to be used. Note that the C++ compiler is; inferred automatically i.e. when specifying `path/to/clang` CMake will; automatically use `path/to/clang++` as the C++ compiler. See; [https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_COMPILER.html](https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_COMPILER.html). - `CMAKE_Fortran_COMPILER`. Select the Fortran compiler executable to be used. Not set by default and not; required unless running the Fortran Test Suite. - `CMAKE_BUILD_TYPE`. Select a build type like `OPTIMIZE` or `DEBUG` selecting a set of predefined; compiler flags. These flags are applied regardless of the `CMAKE_C_FLAGS`; option and may be changed by modifying `CMAKE_C_FLAGS_OPTIMIZE` etc. See; [https://cmake.org/cmake/help/latest/variable/CMAKE_BUILD_TYPE.html](https://cmake.org/cmake/help/latest/variable/CMAKE_B,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:4275,Modifiability,variab,variable,4275,e [External Suites](#external-suites). - `Bitcode/`. These tests are mostly written in LLVM bitcode. - `CTMark/`. Contains symbolic links to other benchmarks forming a representative sample; for compilation performance measurements. ### Benchmarks. Every program can work as a correctness test. Some programs are unsuitable for; performance measurements. Setting the `TEST_SUITE_BENCHMARKING_ONLY` CMake; option to `ON` will disable them. Configuration; -------------. The test-suite has configuration options to customize building and running the; benchmarks. CMake can print a list of them:. ```bash; % cd test-suite-build; # Print basic options:; % cmake -LH; # Print all options:; % cmake -LAH; ```. ### Common Configuration Options. - `CMAKE_C_FLAGS`. Specify extra flags to be passed to C compiler invocations. The flags are; also passed to the C++ compiler and linker invocations. See; [https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_FLAGS.html](https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_FLAGS.html). - `CMAKE_C_COMPILER`. Select the C compiler executable to be used. Note that the C++ compiler is; inferred automatically i.e. when specifying `path/to/clang` CMake will; automatically use `path/to/clang++` as the C++ compiler. See; [https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_COMPILER.html](https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_COMPILER.html). - `CMAKE_Fortran_COMPILER`. Select the Fortran compiler executable to be used. Not set by default and not; required unless running the Fortran Test Suite. - `CMAKE_BUILD_TYPE`. Select a build type like `OPTIMIZE` or `DEBUG` selecting a set of predefined; compiler flags. These flags are applied regardless of the `CMAKE_C_FLAGS`; option and may be changed by modifying `CMAKE_C_FLAGS_OPTIMIZE` etc. See; [https://cmake.org/cmake/help/latest/variable/CMAKE_BUILD_TYPE.html](https://cmake.org/cmake/help/latest/variable/CMAKE_BUILD_TYPE.html). - `TEST_SUITE_FORTRAN`. Activate that Fortran tests,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:4577,Modifiability,variab,variable,4577,grams are unsuitable for; performance measurements. Setting the `TEST_SUITE_BENCHMARKING_ONLY` CMake; option to `ON` will disable them. Configuration; -------------. The test-suite has configuration options to customize building and running the; benchmarks. CMake can print a list of them:. ```bash; % cd test-suite-build; # Print basic options:; % cmake -LH; # Print all options:; % cmake -LAH; ```. ### Common Configuration Options. - `CMAKE_C_FLAGS`. Specify extra flags to be passed to C compiler invocations. The flags are; also passed to the C++ compiler and linker invocations. See; [https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_FLAGS.html](https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_FLAGS.html). - `CMAKE_C_COMPILER`. Select the C compiler executable to be used. Note that the C++ compiler is; inferred automatically i.e. when specifying `path/to/clang` CMake will; automatically use `path/to/clang++` as the C++ compiler. See; [https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_COMPILER.html](https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_COMPILER.html). - `CMAKE_Fortran_COMPILER`. Select the Fortran compiler executable to be used. Not set by default and not; required unless running the Fortran Test Suite. - `CMAKE_BUILD_TYPE`. Select a build type like `OPTIMIZE` or `DEBUG` selecting a set of predefined; compiler flags. These flags are applied regardless of the `CMAKE_C_FLAGS`; option and may be changed by modifying `CMAKE_C_FLAGS_OPTIMIZE` etc. See; [https://cmake.org/cmake/help/latest/variable/CMAKE_BUILD_TYPE.html](https://cmake.org/cmake/help/latest/variable/CMAKE_BUILD_TYPE.html). - `TEST_SUITE_FORTRAN`. Activate that Fortran tests. This is a work in progress. More information can be; found in the [Flang documentation](https://flang.llvm.org/docs/FortranLLVMTestSuite.html). - `TEST_SUITE_RUN_UNDER`. Prefix test invocations with the given tool. This is typically used to run; cross-compiled tests within a simulator tool. - `TEST_SU,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:4648,Modifiability,variab,variable,4648,UITE_BENCHMARKING_ONLY` CMake; option to `ON` will disable them. Configuration; -------------. The test-suite has configuration options to customize building and running the; benchmarks. CMake can print a list of them:. ```bash; % cd test-suite-build; # Print basic options:; % cmake -LH; # Print all options:; % cmake -LAH; ```. ### Common Configuration Options. - `CMAKE_C_FLAGS`. Specify extra flags to be passed to C compiler invocations. The flags are; also passed to the C++ compiler and linker invocations. See; [https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_FLAGS.html](https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_FLAGS.html). - `CMAKE_C_COMPILER`. Select the C compiler executable to be used. Note that the C++ compiler is; inferred automatically i.e. when specifying `path/to/clang` CMake will; automatically use `path/to/clang++` as the C++ compiler. See; [https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_COMPILER.html](https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_COMPILER.html). - `CMAKE_Fortran_COMPILER`. Select the Fortran compiler executable to be used. Not set by default and not; required unless running the Fortran Test Suite. - `CMAKE_BUILD_TYPE`. Select a build type like `OPTIMIZE` or `DEBUG` selecting a set of predefined; compiler flags. These flags are applied regardless of the `CMAKE_C_FLAGS`; option and may be changed by modifying `CMAKE_C_FLAGS_OPTIMIZE` etc. See; [https://cmake.org/cmake/help/latest/variable/CMAKE_BUILD_TYPE.html](https://cmake.org/cmake/help/latest/variable/CMAKE_BUILD_TYPE.html). - `TEST_SUITE_FORTRAN`. Activate that Fortran tests. This is a work in progress. More information can be; found in the [Flang documentation](https://flang.llvm.org/docs/FortranLLVMTestSuite.html). - `TEST_SUITE_RUN_UNDER`. Prefix test invocations with the given tool. This is typically used to run; cross-compiled tests within a simulator tool. - `TEST_SUITE_BENCHMARKING_ONLY`. Disable tests that are unsuitable for performan,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:5125,Modifiability,variab,variable,5125, C++ compiler and linker invocations. See; [https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_FLAGS.html](https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_FLAGS.html). - `CMAKE_C_COMPILER`. Select the C compiler executable to be used. Note that the C++ compiler is; inferred automatically i.e. when specifying `path/to/clang` CMake will; automatically use `path/to/clang++` as the C++ compiler. See; [https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_COMPILER.html](https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_COMPILER.html). - `CMAKE_Fortran_COMPILER`. Select the Fortran compiler executable to be used. Not set by default and not; required unless running the Fortran Test Suite. - `CMAKE_BUILD_TYPE`. Select a build type like `OPTIMIZE` or `DEBUG` selecting a set of predefined; compiler flags. These flags are applied regardless of the `CMAKE_C_FLAGS`; option and may be changed by modifying `CMAKE_C_FLAGS_OPTIMIZE` etc. See; [https://cmake.org/cmake/help/latest/variable/CMAKE_BUILD_TYPE.html](https://cmake.org/cmake/help/latest/variable/CMAKE_BUILD_TYPE.html). - `TEST_SUITE_FORTRAN`. Activate that Fortran tests. This is a work in progress. More information can be; found in the [Flang documentation](https://flang.llvm.org/docs/FortranLLVMTestSuite.html). - `TEST_SUITE_RUN_UNDER`. Prefix test invocations with the given tool. This is typically used to run; cross-compiled tests within a simulator tool. - `TEST_SUITE_BENCHMARKING_ONLY`. Disable tests that are unsuitable for performance measurements. The disabled; tests either run for a very short time or are dominated by I/O performance; making them unsuitable as compiler performance tests. - `TEST_SUITE_SUBDIRS`. Semicolon-separated list of directories to include. This can be used to only; build parts of the test-suite or to include external suites. This option; does not work reliably with deeper subdirectories as it skips intermediate; `CMakeLists.txt` files which may be required. - `TEST_SUITE_CO,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:5193,Modifiability,variab,variable,5193,help/latest/variable/CMAKE_LANG_FLAGS.html](https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_FLAGS.html). - `CMAKE_C_COMPILER`. Select the C compiler executable to be used. Note that the C++ compiler is; inferred automatically i.e. when specifying `path/to/clang` CMake will; automatically use `path/to/clang++` as the C++ compiler. See; [https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_COMPILER.html](https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_COMPILER.html). - `CMAKE_Fortran_COMPILER`. Select the Fortran compiler executable to be used. Not set by default and not; required unless running the Fortran Test Suite. - `CMAKE_BUILD_TYPE`. Select a build type like `OPTIMIZE` or `DEBUG` selecting a set of predefined; compiler flags. These flags are applied regardless of the `CMAKE_C_FLAGS`; option and may be changed by modifying `CMAKE_C_FLAGS_OPTIMIZE` etc. See; [https://cmake.org/cmake/help/latest/variable/CMAKE_BUILD_TYPE.html](https://cmake.org/cmake/help/latest/variable/CMAKE_BUILD_TYPE.html). - `TEST_SUITE_FORTRAN`. Activate that Fortran tests. This is a work in progress. More information can be; found in the [Flang documentation](https://flang.llvm.org/docs/FortranLLVMTestSuite.html). - `TEST_SUITE_RUN_UNDER`. Prefix test invocations with the given tool. This is typically used to run; cross-compiled tests within a simulator tool. - `TEST_SUITE_BENCHMARKING_ONLY`. Disable tests that are unsuitable for performance measurements. The disabled; tests either run for a very short time or are dominated by I/O performance; making them unsuitable as compiler performance tests. - `TEST_SUITE_SUBDIRS`. Semicolon-separated list of directories to include. This can be used to only; build parts of the test-suite or to include external suites. This option; does not work reliably with deeper subdirectories as it skips intermediate; `CMakeLists.txt` files which may be required. - `TEST_SUITE_COLLECT_STATS`. Collect internal LLVM statistics. Appends `-save-stats,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:7174,Modifiability,config,configurations,7174,"S`. Collect internal LLVM statistics. Appends `-save-stats=obj` when invoking the; compiler and makes the lit runner collect and merge the statistic files. - `TEST_SUITE_RUN_BENCHMARKS`. If this is set to `OFF` then lit will not actually run the tests but just; collect build statistics like compile time and code size. - `TEST_SUITE_USE_PERF`. Use the `perf` tool for time measurement instead of the `timeit` tool that; comes with the test-suite. The `perf` is usually available on linux systems. - `TEST_SUITE_SPEC2000_ROOT`, `TEST_SUITE_SPEC2006_ROOT`, `TEST_SUITE_SPEC2017_ROOT`, ... Specify installation directories of external benchmark suites. You can find; more information about expected versions or usage in the README files in the; `External` directory (such as `External/SPEC/README`). ### Common CMake Flags. - `-GNinja`. Generate build files for the ninja build tool. - `-Ctest-suite/cmake/caches/<cachefile.cmake>`. Use a CMake cache. The test-suite comes with several CMake caches which; predefine common or tricky build configurations. Displaying and Analyzing Results; --------------------------------. The `compare.py` script displays and compares result files. A result file is; produced when invoking lit with the `-o filename.json` flag. Example usage:. - Basic Usage:. ```text; % test-suite/utils/compare.py baseline.json; Warning: 'test-suite :: External/SPEC/CINT2006/403.gcc/403.gcc.test' has No metrics!; Tests: 508; Metric: exec_time. Program baseline. INT2006/456.hmmer/456.hmmer 1222.90; INT2006/464.h264ref/464.h264ref 928.70; ...; baseline; count 506.000000; mean 20.563098; std 111.423325; min 0.003400; 25% 0.011200; 50% 0.339450; 75% 4.067200; max 1222.896800; ```. - Show compile_time or text segment size metrics:. ```bash; % test-suite/utils/compare.py -m compile_time baseline.json; % test-suite/utils/compare.py -m size.__text baseline.json; ```. - Compare two result files and filter short running tests:. ```bash; % test-suite/utils/compare.py --filter-short ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:9157,Modifiability,config,configuration,9157,".py --filter-short baseline.json experiment.json; ...; Program baseline experiment diff. SingleSour.../Benchmarks/Linpack/linpack-pc 5.16 4.30 -16.5%; MultiSourc...erolling-dbl/LoopRerolling-dbl 7.01 7.86 12.2%; SingleSour...UnitTests/Vectorizer/gcc-loops 3.89 3.54 -9.0%; ...; ```. - Merge multiple baseline and experiment result files by taking the minimum; runtime each:. ```bash; % test-suite/utils/compare.py base0.json base1.json base2.json vs exp0.json exp1.json exp2.json; ```. ### Continuous Tracking with LNT. LNT is a set of client and server tools for continuously monitoring; performance. You can find more information at; [https://llvm.org/docs/lnt](https://llvm.org/docs/lnt). The official LNT instance; of the LLVM project is hosted at [http://lnt.llvm.org](http://lnt.llvm.org). External Suites; ---------------. External suites such as SPEC can be enabled by either. - placing (or linking) them into the `test-suite/test-suite-externals/xxx` directory (example: `test-suite/test-suite-externals/speccpu2000`); - using a configuration option such as `-D TEST_SUITE_SPEC2000_ROOT=path/to/speccpu2000`. You can find further information in the respective README files such as; `test-suite/External/SPEC/README`. For the SPEC benchmarks you can switch between the `test`, `train` and; `ref` input datasets via the `TEST_SUITE_RUN_TYPE` configuration option.; The `train` dataset is used by default. Custom Suites; -------------. You can build custom suites using the test-suite infrastructure. A custom suite; has a `CMakeLists.txt` file at the top directory. The `CMakeLists.txt` will be; picked up automatically if placed into a subdirectory of the test-suite or when; setting the `TEST_SUITE_SUBDIRS` variable:. ```bash; % cmake -DTEST_SUITE_SUBDIRS=path/to/my/benchmark-suite ../test-suite; ```. Profile Guided Optimization; ---------------------------. Profile guided optimization requires to compile and run twice. First the; benchmark should be compiled with profile generation ins",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:9468,Modifiability,config,configuration,9468,"le baseline and experiment result files by taking the minimum; runtime each:. ```bash; % test-suite/utils/compare.py base0.json base1.json base2.json vs exp0.json exp1.json exp2.json; ```. ### Continuous Tracking with LNT. LNT is a set of client and server tools for continuously monitoring; performance. You can find more information at; [https://llvm.org/docs/lnt](https://llvm.org/docs/lnt). The official LNT instance; of the LLVM project is hosted at [http://lnt.llvm.org](http://lnt.llvm.org). External Suites; ---------------. External suites such as SPEC can be enabled by either. - placing (or linking) them into the `test-suite/test-suite-externals/xxx` directory (example: `test-suite/test-suite-externals/speccpu2000`); - using a configuration option such as `-D TEST_SUITE_SPEC2000_ROOT=path/to/speccpu2000`. You can find further information in the respective README files such as; `test-suite/External/SPEC/README`. For the SPEC benchmarks you can switch between the `test`, `train` and; `ref` input datasets via the `TEST_SUITE_RUN_TYPE` configuration option.; The `train` dataset is used by default. Custom Suites; -------------. You can build custom suites using the test-suite infrastructure. A custom suite; has a `CMakeLists.txt` file at the top directory. The `CMakeLists.txt` will be; picked up automatically if placed into a subdirectory of the test-suite or when; setting the `TEST_SUITE_SUBDIRS` variable:. ```bash; % cmake -DTEST_SUITE_SUBDIRS=path/to/my/benchmark-suite ../test-suite; ```. Profile Guided Optimization; ---------------------------. Profile guided optimization requires to compile and run twice. First the; benchmark should be compiled with profile generation instrumentation enabled; and setup for training data. The lit runner will merge the profile files; using `llvm-profdata` so they can be used by the second compilation run. Example:; ```bash; # Profile generation run using LLVM IR PGO:; % cmake -DTEST_SUITE_PROFILE_GENERATE=ON \; -DTEST_SUITE_USE_IR_",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:9836,Modifiability,variab,variable,9836,"/lnt](https://llvm.org/docs/lnt). The official LNT instance; of the LLVM project is hosted at [http://lnt.llvm.org](http://lnt.llvm.org). External Suites; ---------------. External suites such as SPEC can be enabled by either. - placing (or linking) them into the `test-suite/test-suite-externals/xxx` directory (example: `test-suite/test-suite-externals/speccpu2000`); - using a configuration option such as `-D TEST_SUITE_SPEC2000_ROOT=path/to/speccpu2000`. You can find further information in the respective README files such as; `test-suite/External/SPEC/README`. For the SPEC benchmarks you can switch between the `test`, `train` and; `ref` input datasets via the `TEST_SUITE_RUN_TYPE` configuration option.; The `train` dataset is used by default. Custom Suites; -------------. You can build custom suites using the test-suite infrastructure. A custom suite; has a `CMakeLists.txt` file at the top directory. The `CMakeLists.txt` will be; picked up automatically if placed into a subdirectory of the test-suite or when; setting the `TEST_SUITE_SUBDIRS` variable:. ```bash; % cmake -DTEST_SUITE_SUBDIRS=path/to/my/benchmark-suite ../test-suite; ```. Profile Guided Optimization; ---------------------------. Profile guided optimization requires to compile and run twice. First the; benchmark should be compiled with profile generation instrumentation enabled; and setup for training data. The lit runner will merge the profile files; using `llvm-profdata` so they can be used by the second compilation run. Example:; ```bash; # Profile generation run using LLVM IR PGO:; % cmake -DTEST_SUITE_PROFILE_GENERATE=ON \; -DTEST_SUITE_USE_IR_PGO=ON \; -DTEST_SUITE_RUN_TYPE=train \; ../test-suite; % make; % llvm-lit .; # Use the profile data for compilation and actual benchmark run:; % cmake -DTEST_SUITE_PROFILE_GENERATE=OFF \; -DTEST_SUITE_PROFILE_USE=ON \; -DTEST_SUITE_RUN_TYPE=ref \; .; % make; % llvm-lit -o result.json .; ```. To use Clang frontend's PGO instead of LLVM IR PGO, set `-DTEST_SU",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:761,Performance,cache,cache,761,"test-suite Guide; ================. Quickstart; ----------. 1. The lit test runner is required to run the tests. You can either use one; from an LLVM build:. ```bash; % <path to llvm build>/bin/llvm-lit --version; lit 0.8.0dev; ```. An alternative is installing it as a python package in a python virtual; environment:. ```bash; % mkdir venv; % virtualenv venv; % . venv/bin/activate; % pip install svn+https://llvm.org/svn/llvm-project/llvm/trunk/utils/lit; % lit --version; lit 0.8.0dev; ```. 2. Check out the `test-suite` module with:. ```bash; % git clone https://github.com/llvm/llvm-test-suite.git test-suite; ```. 3. Create a build directory and use CMake to configure the suite. Use the; `CMAKE_C_COMPILER` option to specify the compiler to test. Use a cache file; to choose a typical build configuration:. ```bash; % mkdir test-suite-build; % cd test-suite-build; % cmake -DCMAKE_C_COMPILER=<path to llvm build>/bin/clang \; -C../test-suite/cmake/caches/O3.cmake \; ../test-suite; ```. **NOTE!** if you are using your built clang, and you want to build and run the; MicroBenchmarks/XRay microbenchmarks, you need to add `compiler-rt` to your; `LLVM_ENABLE_RUNTIMES` cmake flag. 4. Build the benchmarks:. ```text; % make; Scanning dependencies of target timeit-target; [ 0%] Building C object tools/CMakeFiles/timeit-target.dir/timeit.c.o; [ 0%] Linking C executable timeit-target; ...; ```. 5. Run the tests with lit:. ```text; % llvm-lit -v -j 1 -o results.json .; -- Testing: 474 tests, 1 threads --; PASS: test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test (1 of 474); ********** TEST 'test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test' RESULTS **********; compile_time: 0.2192; exec_time: 0.0462; hash: ""59620e187c6ac38b36382685ccd2b63b""; size: 83348; **********; PASS: test-suite :: MultiSource/Applications/ALAC/encode/alacconvert-encode.test (2 of 474); ...; ```. 6. Show and compare result files (optional):. ```bash; # Make sure panda",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:956,Performance,cache,caches,956,"test-suite Guide; ================. Quickstart; ----------. 1. The lit test runner is required to run the tests. You can either use one; from an LLVM build:. ```bash; % <path to llvm build>/bin/llvm-lit --version; lit 0.8.0dev; ```. An alternative is installing it as a python package in a python virtual; environment:. ```bash; % mkdir venv; % virtualenv venv; % . venv/bin/activate; % pip install svn+https://llvm.org/svn/llvm-project/llvm/trunk/utils/lit; % lit --version; lit 0.8.0dev; ```. 2. Check out the `test-suite` module with:. ```bash; % git clone https://github.com/llvm/llvm-test-suite.git test-suite; ```. 3. Create a build directory and use CMake to configure the suite. Use the; `CMAKE_C_COMPILER` option to specify the compiler to test. Use a cache file; to choose a typical build configuration:. ```bash; % mkdir test-suite-build; % cd test-suite-build; % cmake -DCMAKE_C_COMPILER=<path to llvm build>/bin/clang \; -C../test-suite/cmake/caches/O3.cmake \; ../test-suite; ```. **NOTE!** if you are using your built clang, and you want to build and run the; MicroBenchmarks/XRay microbenchmarks, you need to add `compiler-rt` to your; `LLVM_ENABLE_RUNTIMES` cmake flag. 4. Build the benchmarks:. ```text; % make; Scanning dependencies of target timeit-target; [ 0%] Building C object tools/CMakeFiles/timeit-target.dir/timeit.c.o; [ 0%] Linking C executable timeit-target; ...; ```. 5. Run the tests with lit:. ```text; % llvm-lit -v -j 1 -o results.json .; -- Testing: 474 tests, 1 threads --; PASS: test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test (1 of 474); ********** TEST 'test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test' RESULTS **********; compile_time: 0.2192; exec_time: 0.0462; hash: ""59620e187c6ac38b36382685ccd2b63b""; size: 83348; **********; PASS: test-suite :: MultiSource/Applications/ALAC/encode/alacconvert-encode.test (2 of 474); ...; ```. 6. Show and compare result files (optional):. ```bash; # Make sure panda",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:3484,Performance,perform,performance,3484,"ect metrics such as benchmark runtime, compilation time and; code size. The test-suite is divided into several directories:. - `SingleSource/`. Contains test programs that are only a single source file in size. A; subdirectory may contain several programs. - `MultiSource/`. Contains subdirectories which entire programs with multiple source files.; Large benchmarks and whole applications go here. - `MicroBenchmarks/`. Programs using the [google-benchmark](https://github.com/google/benchmark); library. The programs define functions that are run multiple times until the; measurement results are statistically significant. - `External/`. Contains descriptions and test data for code that cannot be directly; distributed with the test-suite. The most prominent members of this; directory are the SPEC CPU benchmark suites.; See [External Suites](#external-suites). - `Bitcode/`. These tests are mostly written in LLVM bitcode. - `CTMark/`. Contains symbolic links to other benchmarks forming a representative sample; for compilation performance measurements. ### Benchmarks. Every program can work as a correctness test. Some programs are unsuitable for; performance measurements. Setting the `TEST_SUITE_BENCHMARKING_ONLY` CMake; option to `ON` will disable them. Configuration; -------------. The test-suite has configuration options to customize building and running the; benchmarks. CMake can print a list of them:. ```bash; % cd test-suite-build; # Print basic options:; % cmake -LH; # Print all options:; % cmake -LAH; ```. ### Common Configuration Options. - `CMAKE_C_FLAGS`. Specify extra flags to be passed to C compiler invocations. The flags are; also passed to the C++ compiler and linker invocations. See; [https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_FLAGS.html](https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_FLAGS.html). - `CMAKE_C_COMPILER`. Select the C compiler executable to be used. Note that the C++ compiler is; inferred automatically i.e. when specifying ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:3606,Performance,perform,performance,3606, test programs that are only a single source file in size. A; subdirectory may contain several programs. - `MultiSource/`. Contains subdirectories which entire programs with multiple source files.; Large benchmarks and whole applications go here. - `MicroBenchmarks/`. Programs using the [google-benchmark](https://github.com/google/benchmark); library. The programs define functions that are run multiple times until the; measurement results are statistically significant. - `External/`. Contains descriptions and test data for code that cannot be directly; distributed with the test-suite. The most prominent members of this; directory are the SPEC CPU benchmark suites.; See [External Suites](#external-suites). - `Bitcode/`. These tests are mostly written in LLVM bitcode. - `CTMark/`. Contains symbolic links to other benchmarks forming a representative sample; for compilation performance measurements. ### Benchmarks. Every program can work as a correctness test. Some programs are unsuitable for; performance measurements. Setting the `TEST_SUITE_BENCHMARKING_ONLY` CMake; option to `ON` will disable them. Configuration; -------------. The test-suite has configuration options to customize building and running the; benchmarks. CMake can print a list of them:. ```bash; % cd test-suite-build; # Print basic options:; % cmake -LH; # Print all options:; % cmake -LAH; ```. ### Common Configuration Options. - `CMAKE_C_FLAGS`. Specify extra flags to be passed to C compiler invocations. The flags are; also passed to the C++ compiler and linker invocations. See; [https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_FLAGS.html](https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_FLAGS.html). - `CMAKE_C_COMPILER`. Select the C compiler executable to be used. Note that the C++ compiler is; inferred automatically i.e. when specifying `path/to/clang` CMake will; automatically use `path/to/clang++` as the C++ compiler. See; [https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_COMP,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:5643,Performance,perform,performance,5643,help/latest/variable/CMAKE_LANG_COMPILER.html). - `CMAKE_Fortran_COMPILER`. Select the Fortran compiler executable to be used. Not set by default and not; required unless running the Fortran Test Suite. - `CMAKE_BUILD_TYPE`. Select a build type like `OPTIMIZE` or `DEBUG` selecting a set of predefined; compiler flags. These flags are applied regardless of the `CMAKE_C_FLAGS`; option and may be changed by modifying `CMAKE_C_FLAGS_OPTIMIZE` etc. See; [https://cmake.org/cmake/help/latest/variable/CMAKE_BUILD_TYPE.html](https://cmake.org/cmake/help/latest/variable/CMAKE_BUILD_TYPE.html). - `TEST_SUITE_FORTRAN`. Activate that Fortran tests. This is a work in progress. More information can be; found in the [Flang documentation](https://flang.llvm.org/docs/FortranLLVMTestSuite.html). - `TEST_SUITE_RUN_UNDER`. Prefix test invocations with the given tool. This is typically used to run; cross-compiled tests within a simulator tool. - `TEST_SUITE_BENCHMARKING_ONLY`. Disable tests that are unsuitable for performance measurements. The disabled; tests either run for a very short time or are dominated by I/O performance; making them unsuitable as compiler performance tests. - `TEST_SUITE_SUBDIRS`. Semicolon-separated list of directories to include. This can be used to only; build parts of the test-suite or to include external suites. This option; does not work reliably with deeper subdirectories as it skips intermediate; `CMakeLists.txt` files which may be required. - `TEST_SUITE_COLLECT_STATS`. Collect internal LLVM statistics. Appends `-save-stats=obj` when invoking the; compiler and makes the lit runner collect and merge the statistic files. - `TEST_SUITE_RUN_BENCHMARKS`. If this is set to `OFF` then lit will not actually run the tests but just; collect build statistics like compile time and code size. - `TEST_SUITE_USE_PERF`. Use the `perf` tool for time measurement instead of the `timeit` tool that; comes with the test-suite. The `perf` is usually available on linux systems. -,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:5746,Performance,perform,performance,5746,"executable to be used. Not set by default and not; required unless running the Fortran Test Suite. - `CMAKE_BUILD_TYPE`. Select a build type like `OPTIMIZE` or `DEBUG` selecting a set of predefined; compiler flags. These flags are applied regardless of the `CMAKE_C_FLAGS`; option and may be changed by modifying `CMAKE_C_FLAGS_OPTIMIZE` etc. See; [https://cmake.org/cmake/help/latest/variable/CMAKE_BUILD_TYPE.html](https://cmake.org/cmake/help/latest/variable/CMAKE_BUILD_TYPE.html). - `TEST_SUITE_FORTRAN`. Activate that Fortran tests. This is a work in progress. More information can be; found in the [Flang documentation](https://flang.llvm.org/docs/FortranLLVMTestSuite.html). - `TEST_SUITE_RUN_UNDER`. Prefix test invocations with the given tool. This is typically used to run; cross-compiled tests within a simulator tool. - `TEST_SUITE_BENCHMARKING_ONLY`. Disable tests that are unsuitable for performance measurements. The disabled; tests either run for a very short time or are dominated by I/O performance; making them unsuitable as compiler performance tests. - `TEST_SUITE_SUBDIRS`. Semicolon-separated list of directories to include. This can be used to only; build parts of the test-suite or to include external suites. This option; does not work reliably with deeper subdirectories as it skips intermediate; `CMakeLists.txt` files which may be required. - `TEST_SUITE_COLLECT_STATS`. Collect internal LLVM statistics. Appends `-save-stats=obj` when invoking the; compiler and makes the lit runner collect and merge the statistic files. - `TEST_SUITE_RUN_BENCHMARKS`. If this is set to `OFF` then lit will not actually run the tests but just; collect build statistics like compile time and code size. - `TEST_SUITE_USE_PERF`. Use the `perf` tool for time measurement instead of the `timeit` tool that; comes with the test-suite. The `perf` is usually available on linux systems. - `TEST_SUITE_SPEC2000_ROOT`, `TEST_SUITE_SPEC2006_ROOT`, `TEST_SUITE_SPEC2017_ROOT`, ... Specify install",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:5794,Performance,perform,performance,5794,"executable to be used. Not set by default and not; required unless running the Fortran Test Suite. - `CMAKE_BUILD_TYPE`. Select a build type like `OPTIMIZE` or `DEBUG` selecting a set of predefined; compiler flags. These flags are applied regardless of the `CMAKE_C_FLAGS`; option and may be changed by modifying `CMAKE_C_FLAGS_OPTIMIZE` etc. See; [https://cmake.org/cmake/help/latest/variable/CMAKE_BUILD_TYPE.html](https://cmake.org/cmake/help/latest/variable/CMAKE_BUILD_TYPE.html). - `TEST_SUITE_FORTRAN`. Activate that Fortran tests. This is a work in progress. More information can be; found in the [Flang documentation](https://flang.llvm.org/docs/FortranLLVMTestSuite.html). - `TEST_SUITE_RUN_UNDER`. Prefix test invocations with the given tool. This is typically used to run; cross-compiled tests within a simulator tool. - `TEST_SUITE_BENCHMARKING_ONLY`. Disable tests that are unsuitable for performance measurements. The disabled; tests either run for a very short time or are dominated by I/O performance; making them unsuitable as compiler performance tests. - `TEST_SUITE_SUBDIRS`. Semicolon-separated list of directories to include. This can be used to only; build parts of the test-suite or to include external suites. This option; does not work reliably with deeper subdirectories as it skips intermediate; `CMakeLists.txt` files which may be required. - `TEST_SUITE_COLLECT_STATS`. Collect internal LLVM statistics. Appends `-save-stats=obj` when invoking the; compiler and makes the lit runner collect and merge the statistic files. - `TEST_SUITE_RUN_BENCHMARKS`. If this is set to `OFF` then lit will not actually run the tests but just; collect build statistics like compile time and code size. - `TEST_SUITE_USE_PERF`. Use the `perf` tool for time measurement instead of the `timeit` tool that; comes with the test-suite. The `perf` is usually available on linux systems. - `TEST_SUITE_SPEC2000_ROOT`, `TEST_SUITE_SPEC2006_ROOT`, `TEST_SUITE_SPEC2017_ROOT`, ... Specify install",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:7041,Performance,cache,caches,7041," as it skips intermediate; `CMakeLists.txt` files which may be required. - `TEST_SUITE_COLLECT_STATS`. Collect internal LLVM statistics. Appends `-save-stats=obj` when invoking the; compiler and makes the lit runner collect and merge the statistic files. - `TEST_SUITE_RUN_BENCHMARKS`. If this is set to `OFF` then lit will not actually run the tests but just; collect build statistics like compile time and code size. - `TEST_SUITE_USE_PERF`. Use the `perf` tool for time measurement instead of the `timeit` tool that; comes with the test-suite. The `perf` is usually available on linux systems. - `TEST_SUITE_SPEC2000_ROOT`, `TEST_SUITE_SPEC2006_ROOT`, `TEST_SUITE_SPEC2017_ROOT`, ... Specify installation directories of external benchmark suites. You can find; more information about expected versions or usage in the README files in the; `External` directory (such as `External/SPEC/README`). ### Common CMake Flags. - `-GNinja`. Generate build files for the ninja build tool. - `-Ctest-suite/cmake/caches/<cachefile.cmake>`. Use a CMake cache. The test-suite comes with several CMake caches which; predefine common or tricky build configurations. Displaying and Analyzing Results; --------------------------------. The `compare.py` script displays and compares result files. A result file is; produced when invoking lit with the `-o filename.json` flag. Example usage:. - Basic Usage:. ```text; % test-suite/utils/compare.py baseline.json; Warning: 'test-suite :: External/SPEC/CINT2006/403.gcc/403.gcc.test' has No metrics!; Tests: 508; Metric: exec_time. Program baseline. INT2006/456.hmmer/456.hmmer 1222.90; INT2006/464.h264ref/464.h264ref 928.70; ...; baseline; count 506.000000; mean 20.563098; std 111.423325; min 0.003400; 25% 0.011200; 50% 0.339450; 75% 4.067200; max 1222.896800; ```. - Show compile_time or text segment size metrics:. ```bash; % test-suite/utils/compare.py -m compile_time baseline.json; % test-suite/utils/compare.py -m size.__text baseline.json; ```. - Compare two r",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:7049,Performance,cache,cachefile,7049," as it skips intermediate; `CMakeLists.txt` files which may be required. - `TEST_SUITE_COLLECT_STATS`. Collect internal LLVM statistics. Appends `-save-stats=obj` when invoking the; compiler and makes the lit runner collect and merge the statistic files. - `TEST_SUITE_RUN_BENCHMARKS`. If this is set to `OFF` then lit will not actually run the tests but just; collect build statistics like compile time and code size. - `TEST_SUITE_USE_PERF`. Use the `perf` tool for time measurement instead of the `timeit` tool that; comes with the test-suite. The `perf` is usually available on linux systems. - `TEST_SUITE_SPEC2000_ROOT`, `TEST_SUITE_SPEC2006_ROOT`, `TEST_SUITE_SPEC2017_ROOT`, ... Specify installation directories of external benchmark suites. You can find; more information about expected versions or usage in the README files in the; `External` directory (such as `External/SPEC/README`). ### Common CMake Flags. - `-GNinja`. Generate build files for the ninja build tool. - `-Ctest-suite/cmake/caches/<cachefile.cmake>`. Use a CMake cache. The test-suite comes with several CMake caches which; predefine common or tricky build configurations. Displaying and Analyzing Results; --------------------------------. The `compare.py` script displays and compares result files. A result file is; produced when invoking lit with the `-o filename.json` flag. Example usage:. - Basic Usage:. ```text; % test-suite/utils/compare.py baseline.json; Warning: 'test-suite :: External/SPEC/CINT2006/403.gcc/403.gcc.test' has No metrics!; Tests: 508; Metric: exec_time. Program baseline. INT2006/456.hmmer/456.hmmer 1222.90; INT2006/464.h264ref/464.h264ref 928.70; ...; baseline; count 506.000000; mean 20.563098; std 111.423325; min 0.003400; 25% 0.011200; 50% 0.339450; 75% 4.067200; max 1222.896800; ```. - Show compile_time or text segment size metrics:. ```bash; % test-suite/utils/compare.py -m compile_time baseline.json; % test-suite/utils/compare.py -m size.__text baseline.json; ```. - Compare two r",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:7080,Performance,cache,cache,7080,".txt` files which may be required. - `TEST_SUITE_COLLECT_STATS`. Collect internal LLVM statistics. Appends `-save-stats=obj` when invoking the; compiler and makes the lit runner collect and merge the statistic files. - `TEST_SUITE_RUN_BENCHMARKS`. If this is set to `OFF` then lit will not actually run the tests but just; collect build statistics like compile time and code size. - `TEST_SUITE_USE_PERF`. Use the `perf` tool for time measurement instead of the `timeit` tool that; comes with the test-suite. The `perf` is usually available on linux systems. - `TEST_SUITE_SPEC2000_ROOT`, `TEST_SUITE_SPEC2006_ROOT`, `TEST_SUITE_SPEC2017_ROOT`, ... Specify installation directories of external benchmark suites. You can find; more information about expected versions or usage in the README files in the; `External` directory (such as `External/SPEC/README`). ### Common CMake Flags. - `-GNinja`. Generate build files for the ninja build tool. - `-Ctest-suite/cmake/caches/<cachefile.cmake>`. Use a CMake cache. The test-suite comes with several CMake caches which; predefine common or tricky build configurations. Displaying and Analyzing Results; --------------------------------. The `compare.py` script displays and compares result files. A result file is; produced when invoking lit with the `-o filename.json` flag. Example usage:. - Basic Usage:. ```text; % test-suite/utils/compare.py baseline.json; Warning: 'test-suite :: External/SPEC/CINT2006/403.gcc/403.gcc.test' has No metrics!; Tests: 508; Metric: exec_time. Program baseline. INT2006/456.hmmer/456.hmmer 1222.90; INT2006/464.h264ref/464.h264ref 928.70; ...; baseline; count 506.000000; mean 20.563098; std 111.423325; min 0.003400; 25% 0.011200; 50% 0.339450; 75% 4.067200; max 1222.896800; ```. - Show compile_time or text segment size metrics:. ```bash; % test-suite/utils/compare.py -m compile_time baseline.json; % test-suite/utils/compare.py -m size.__text baseline.json; ```. - Compare two result files and filter short running t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:7127,Performance,cache,caches,7127,"S`. Collect internal LLVM statistics. Appends `-save-stats=obj` when invoking the; compiler and makes the lit runner collect and merge the statistic files. - `TEST_SUITE_RUN_BENCHMARKS`. If this is set to `OFF` then lit will not actually run the tests but just; collect build statistics like compile time and code size. - `TEST_SUITE_USE_PERF`. Use the `perf` tool for time measurement instead of the `timeit` tool that; comes with the test-suite. The `perf` is usually available on linux systems. - `TEST_SUITE_SPEC2000_ROOT`, `TEST_SUITE_SPEC2006_ROOT`, `TEST_SUITE_SPEC2017_ROOT`, ... Specify installation directories of external benchmark suites. You can find; more information about expected versions or usage in the README files in the; `External` directory (such as `External/SPEC/README`). ### Common CMake Flags. - `-GNinja`. Generate build files for the ninja build tool. - `-Ctest-suite/cmake/caches/<cachefile.cmake>`. Use a CMake cache. The test-suite comes with several CMake caches which; predefine common or tricky build configurations. Displaying and Analyzing Results; --------------------------------. The `compare.py` script displays and compares result files. A result file is; produced when invoking lit with the `-o filename.json` flag. Example usage:. - Basic Usage:. ```text; % test-suite/utils/compare.py baseline.json; Warning: 'test-suite :: External/SPEC/CINT2006/403.gcc/403.gcc.test' has No metrics!; Tests: 508; Metric: exec_time. Program baseline. INT2006/456.hmmer/456.hmmer 1222.90; INT2006/464.h264ref/464.h264ref 928.70; ...; baseline; count 506.000000; mean 20.563098; std 111.423325; min 0.003400; 25% 0.011200; 50% 0.339450; 75% 4.067200; max 1222.896800; ```. - Show compile_time or text segment size metrics:. ```bash; % test-suite/utils/compare.py -m compile_time baseline.json; % test-suite/utils/compare.py -m size.__text baseline.json; ```. - Compare two result files and filter short running tests:. ```bash; % test-suite/utils/compare.py --filter-short ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:8708,Performance,perform,performance,8708,"h264ref 928.70; ...; baseline; count 506.000000; mean 20.563098; std 111.423325; min 0.003400; 25% 0.011200; 50% 0.339450; 75% 4.067200; max 1222.896800; ```. - Show compile_time or text segment size metrics:. ```bash; % test-suite/utils/compare.py -m compile_time baseline.json; % test-suite/utils/compare.py -m size.__text baseline.json; ```. - Compare two result files and filter short running tests:. ```bash; % test-suite/utils/compare.py --filter-short baseline.json experiment.json; ...; Program baseline experiment diff. SingleSour.../Benchmarks/Linpack/linpack-pc 5.16 4.30 -16.5%; MultiSourc...erolling-dbl/LoopRerolling-dbl 7.01 7.86 12.2%; SingleSour...UnitTests/Vectorizer/gcc-loops 3.89 3.54 -9.0%; ...; ```. - Merge multiple baseline and experiment result files by taking the minimum; runtime each:. ```bash; % test-suite/utils/compare.py base0.json base1.json base2.json vs exp0.json exp1.json exp2.json; ```. ### Continuous Tracking with LNT. LNT is a set of client and server tools for continuously monitoring; performance. You can find more information at; [https://llvm.org/docs/lnt](https://llvm.org/docs/lnt). The official LNT instance; of the LLVM project is hosted at [http://lnt.llvm.org](http://lnt.llvm.org). External Suites; ---------------. External suites such as SPEC can be enabled by either. - placing (or linking) them into the `test-suite/test-suite-externals/xxx` directory (example: `test-suite/test-suite-externals/speccpu2000`); - using a configuration option such as `-D TEST_SUITE_SPEC2000_ROOT=path/to/speccpu2000`. You can find further information in the respective README files such as; `test-suite/External/SPEC/README`. For the SPEC benchmarks you can switch between the `test`, `train` and; `ref` input datasets via the `TEST_SUITE_RUN_TYPE` configuration option.; The `train` dataset is used by default. Custom Suites; -------------. You can build custom suites using the test-suite infrastructure. A custom suite; has a `CMakeLists.txt` file at the to",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:10005,Performance,optimiz,optimization,10005,"nking) them into the `test-suite/test-suite-externals/xxx` directory (example: `test-suite/test-suite-externals/speccpu2000`); - using a configuration option such as `-D TEST_SUITE_SPEC2000_ROOT=path/to/speccpu2000`. You can find further information in the respective README files such as; `test-suite/External/SPEC/README`. For the SPEC benchmarks you can switch between the `test`, `train` and; `ref` input datasets via the `TEST_SUITE_RUN_TYPE` configuration option.; The `train` dataset is used by default. Custom Suites; -------------. You can build custom suites using the test-suite infrastructure. A custom suite; has a `CMakeLists.txt` file at the top directory. The `CMakeLists.txt` will be; picked up automatically if placed into a subdirectory of the test-suite or when; setting the `TEST_SUITE_SUBDIRS` variable:. ```bash; % cmake -DTEST_SUITE_SUBDIRS=path/to/my/benchmark-suite ../test-suite; ```. Profile Guided Optimization; ---------------------------. Profile guided optimization requires to compile and run twice. First the; benchmark should be compiled with profile generation instrumentation enabled; and setup for training data. The lit runner will merge the profile files; using `llvm-profdata` so they can be used by the second compilation run. Example:; ```bash; # Profile generation run using LLVM IR PGO:; % cmake -DTEST_SUITE_PROFILE_GENERATE=ON \; -DTEST_SUITE_USE_IR_PGO=ON \; -DTEST_SUITE_RUN_TYPE=train \; ../test-suite; % make; % llvm-lit .; # Use the profile data for compilation and actual benchmark run:; % cmake -DTEST_SUITE_PROFILE_GENERATE=OFF \; -DTEST_SUITE_PROFILE_USE=ON \; -DTEST_SUITE_RUN_TYPE=ref \; .; % make; % llvm-lit -o result.json .; ```. To use Clang frontend's PGO instead of LLVM IR PGO, set `-DTEST_SUITE_USE_IR_PGO=OFF`. The `TEST_SUITE_RUN_TYPE` setting only affects the SPEC benchmark suites. Cross Compilation and External Devices; --------------------------------------. ### Compilation. CMake allows to cross compile to a different target ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:11408,Performance,cache,caches,11408,"=ON \; -DTEST_SUITE_USE_IR_PGO=ON \; -DTEST_SUITE_RUN_TYPE=train \; ../test-suite; % make; % llvm-lit .; # Use the profile data for compilation and actual benchmark run:; % cmake -DTEST_SUITE_PROFILE_GENERATE=OFF \; -DTEST_SUITE_PROFILE_USE=ON \; -DTEST_SUITE_RUN_TYPE=ref \; .; % make; % llvm-lit -o result.json .; ```. To use Clang frontend's PGO instead of LLVM IR PGO, set `-DTEST_SUITE_USE_IR_PGO=OFF`. The `TEST_SUITE_RUN_TYPE` setting only affects the SPEC benchmark suites. Cross Compilation and External Devices; --------------------------------------. ### Compilation. CMake allows to cross compile to a different target via toolchain files. More; information can be found here:. - [https://llvm.org/docs/lnt/tests.html#cross-compiling](https://llvm.org/docs/lnt/tests.html#cross-compiling). - [https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html](https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html). Cross compilation from macOS to iOS is possible with the; `test-suite/cmake/caches/target-target-*-iphoneos-internal.cmake` CMake cache; files; this requires an internal iOS SDK. ### Running. There are two ways to run the tests in a cross compilation setting:. - Via SSH connection to an external device: The `TEST_SUITE_REMOTE_HOST` option; should be set to the SSH hostname. The executables and data files need to be; transferred to the device after compilation. This is typically done via the; `rsync` make target. After this, the lit runner can be used on the host; machine. It will prefix the benchmark and verification command lines with an; `ssh` command. Example:. ```bash; % cmake -G Ninja -D CMAKE_C_COMPILER=path/to/clang \; -C ../test-suite/cmake/caches/target-arm64-iphoneos-internal.cmake \; -D CMAKE_BUILD_TYPE=Release \; -D TEST_SUITE_REMOTE_HOST=mydevice \; ../test-suite; % ninja; % ninja rsync; % llvm-lit -j1 -o result.json .; ```. - You can specify a simulator for the target machine with the; `TEST_SUITE_RUN_UNDER` setting. The lit run",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:11462,Performance,cache,cache,11462,"; % llvm-lit .; # Use the profile data for compilation and actual benchmark run:; % cmake -DTEST_SUITE_PROFILE_GENERATE=OFF \; -DTEST_SUITE_PROFILE_USE=ON \; -DTEST_SUITE_RUN_TYPE=ref \; .; % make; % llvm-lit -o result.json .; ```. To use Clang frontend's PGO instead of LLVM IR PGO, set `-DTEST_SUITE_USE_IR_PGO=OFF`. The `TEST_SUITE_RUN_TYPE` setting only affects the SPEC benchmark suites. Cross Compilation and External Devices; --------------------------------------. ### Compilation. CMake allows to cross compile to a different target via toolchain files. More; information can be found here:. - [https://llvm.org/docs/lnt/tests.html#cross-compiling](https://llvm.org/docs/lnt/tests.html#cross-compiling). - [https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html](https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html). Cross compilation from macOS to iOS is possible with the; `test-suite/cmake/caches/target-target-*-iphoneos-internal.cmake` CMake cache; files; this requires an internal iOS SDK. ### Running. There are two ways to run the tests in a cross compilation setting:. - Via SSH connection to an external device: The `TEST_SUITE_REMOTE_HOST` option; should be set to the SSH hostname. The executables and data files need to be; transferred to the device after compilation. This is typically done via the; `rsync` make target. After this, the lit runner can be used on the host; machine. It will prefix the benchmark and verification command lines with an; `ssh` command. Example:. ```bash; % cmake -G Ninja -D CMAKE_C_COMPILER=path/to/clang \; -C ../test-suite/cmake/caches/target-arm64-iphoneos-internal.cmake \; -D CMAKE_BUILD_TYPE=Release \; -D TEST_SUITE_REMOTE_HOST=mydevice \; ../test-suite; % ninja; % ninja rsync; % llvm-lit -j1 -o result.json .; ```. - You can specify a simulator for the target machine with the; `TEST_SUITE_RUN_UNDER` setting. The lit runner will prefix all benchmark; invocations with it. Running the test-suite via LNT; ------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:12091,Performance,cache,caches,12091,"ocs/lnt/tests.html#cross-compiling](https://llvm.org/docs/lnt/tests.html#cross-compiling). - [https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html](https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html). Cross compilation from macOS to iOS is possible with the; `test-suite/cmake/caches/target-target-*-iphoneos-internal.cmake` CMake cache; files; this requires an internal iOS SDK. ### Running. There are two ways to run the tests in a cross compilation setting:. - Via SSH connection to an external device: The `TEST_SUITE_REMOTE_HOST` option; should be set to the SSH hostname. The executables and data files need to be; transferred to the device after compilation. This is typically done via the; `rsync` make target. After this, the lit runner can be used on the host; machine. It will prefix the benchmark and verification command lines with an; `ssh` command. Example:. ```bash; % cmake -G Ninja -D CMAKE_C_COMPILER=path/to/clang \; -C ../test-suite/cmake/caches/target-arm64-iphoneos-internal.cmake \; -D CMAKE_BUILD_TYPE=Release \; -D TEST_SUITE_REMOTE_HOST=mydevice \; ../test-suite; % ninja; % ninja rsync; % llvm-lit -j1 -o result.json .; ```. - You can specify a simulator for the target machine with the; `TEST_SUITE_RUN_UNDER` setting. The lit runner will prefix all benchmark; invocations with it. Running the test-suite via LNT; ------------------------------. The LNT tool can run the test-suite. Use this when submitting test results to; an LNT instance. See; [https://llvm.org/docs/lnt/tests.html#llvm-cmake-test-suite](https://llvm.org/docs/lnt/tests.html#llvm-cmake-test-suite); for details. Running the test-suite via Makefiles (deprecated); -------------------------------------------------. **Note**: The test-suite comes with a set of Makefiles that are considered; deprecated. They do not support newer testing modes like `Bitcode` or; `Microbenchmarks` and are harder to use. Old documentation is available in the; [test-suite Makefile Guide](Te",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:1759,Security,hash,hash,1759,"kdir test-suite-build; % cd test-suite-build; % cmake -DCMAKE_C_COMPILER=<path to llvm build>/bin/clang \; -C../test-suite/cmake/caches/O3.cmake \; ../test-suite; ```. **NOTE!** if you are using your built clang, and you want to build and run the; MicroBenchmarks/XRay microbenchmarks, you need to add `compiler-rt` to your; `LLVM_ENABLE_RUNTIMES` cmake flag. 4. Build the benchmarks:. ```text; % make; Scanning dependencies of target timeit-target; [ 0%] Building C object tools/CMakeFiles/timeit-target.dir/timeit.c.o; [ 0%] Linking C executable timeit-target; ...; ```. 5. Run the tests with lit:. ```text; % llvm-lit -v -j 1 -o results.json .; -- Testing: 474 tests, 1 threads --; PASS: test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test (1 of 474); ********** TEST 'test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test' RESULTS **********; compile_time: 0.2192; exec_time: 0.0462; hash: ""59620e187c6ac38b36382685ccd2b63b""; size: 83348; **********; PASS: test-suite :: MultiSource/Applications/ALAC/encode/alacconvert-encode.test (2 of 474); ...; ```. 6. Show and compare result files (optional):. ```bash; # Make sure pandas and scipy are installed. Prepend `sudo` if necessary.; % pip install pandas scipy; # Show a single result file:; % test-suite/utils/compare.py results.json; # Compare two result files:; % test-suite/utils/compare.py results_a.json results_b.json; ```. Structure; ---------. The test-suite contains benchmark and test programs. The programs come with; reference outputs so that their correctness can be checked. The suite comes; with tools to collect metrics such as benchmark runtime, compilation time and; code size. The test-suite is divided into several directories:. - `SingleSource/`. Contains test programs that are only a single source file in size. A; subdirectory may contain several programs. - `MultiSource/`. Contains subdirectories which entire programs with multiple source files.; Large benchmarks and whole ap",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:0,Testability,test,test-suite,0,"test-suite Guide; ================. Quickstart; ----------. 1. The lit test runner is required to run the tests. You can either use one; from an LLVM build:. ```bash; % <path to llvm build>/bin/llvm-lit --version; lit 0.8.0dev; ```. An alternative is installing it as a python package in a python virtual; environment:. ```bash; % mkdir venv; % virtualenv venv; % . venv/bin/activate; % pip install svn+https://llvm.org/svn/llvm-project/llvm/trunk/utils/lit; % lit --version; lit 0.8.0dev; ```. 2. Check out the `test-suite` module with:. ```bash; % git clone https://github.com/llvm/llvm-test-suite.git test-suite; ```. 3. Create a build directory and use CMake to configure the suite. Use the; `CMAKE_C_COMPILER` option to specify the compiler to test. Use a cache file; to choose a typical build configuration:. ```bash; % mkdir test-suite-build; % cd test-suite-build; % cmake -DCMAKE_C_COMPILER=<path to llvm build>/bin/clang \; -C../test-suite/cmake/caches/O3.cmake \; ../test-suite; ```. **NOTE!** if you are using your built clang, and you want to build and run the; MicroBenchmarks/XRay microbenchmarks, you need to add `compiler-rt` to your; `LLVM_ENABLE_RUNTIMES` cmake flag. 4. Build the benchmarks:. ```text; % make; Scanning dependencies of target timeit-target; [ 0%] Building C object tools/CMakeFiles/timeit-target.dir/timeit.c.o; [ 0%] Linking C executable timeit-target; ...; ```. 5. Run the tests with lit:. ```text; % llvm-lit -v -j 1 -o results.json .; -- Testing: 474 tests, 1 threads --; PASS: test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test (1 of 474); ********** TEST 'test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test' RESULTS **********; compile_time: 0.2192; exec_time: 0.0462; hash: ""59620e187c6ac38b36382685ccd2b63b""; size: 83348; **********; PASS: test-suite :: MultiSource/Applications/ALAC/encode/alacconvert-encode.test (2 of 474); ...; ```. 6. Show and compare result files (optional):. ```bash; # Make sure panda",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:71,Testability,test,test,71,"test-suite Guide; ================. Quickstart; ----------. 1. The lit test runner is required to run the tests. You can either use one; from an LLVM build:. ```bash; % <path to llvm build>/bin/llvm-lit --version; lit 0.8.0dev; ```. An alternative is installing it as a python package in a python virtual; environment:. ```bash; % mkdir venv; % virtualenv venv; % . venv/bin/activate; % pip install svn+https://llvm.org/svn/llvm-project/llvm/trunk/utils/lit; % lit --version; lit 0.8.0dev; ```. 2. Check out the `test-suite` module with:. ```bash; % git clone https://github.com/llvm/llvm-test-suite.git test-suite; ```. 3. Create a build directory and use CMake to configure the suite. Use the; `CMAKE_C_COMPILER` option to specify the compiler to test. Use a cache file; to choose a typical build configuration:. ```bash; % mkdir test-suite-build; % cd test-suite-build; % cmake -DCMAKE_C_COMPILER=<path to llvm build>/bin/clang \; -C../test-suite/cmake/caches/O3.cmake \; ../test-suite; ```. **NOTE!** if you are using your built clang, and you want to build and run the; MicroBenchmarks/XRay microbenchmarks, you need to add `compiler-rt` to your; `LLVM_ENABLE_RUNTIMES` cmake flag. 4. Build the benchmarks:. ```text; % make; Scanning dependencies of target timeit-target; [ 0%] Building C object tools/CMakeFiles/timeit-target.dir/timeit.c.o; [ 0%] Linking C executable timeit-target; ...; ```. 5. Run the tests with lit:. ```text; % llvm-lit -v -j 1 -o results.json .; -- Testing: 474 tests, 1 threads --; PASS: test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test (1 of 474); ********** TEST 'test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test' RESULTS **********; compile_time: 0.2192; exec_time: 0.0462; hash: ""59620e187c6ac38b36382685ccd2b63b""; size: 83348; **********; PASS: test-suite :: MultiSource/Applications/ALAC/encode/alacconvert-encode.test (2 of 474); ...; ```. 6. Show and compare result files (optional):. ```bash; # Make sure panda",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:106,Testability,test,tests,106,"test-suite Guide; ================. Quickstart; ----------. 1. The lit test runner is required to run the tests. You can either use one; from an LLVM build:. ```bash; % <path to llvm build>/bin/llvm-lit --version; lit 0.8.0dev; ```. An alternative is installing it as a python package in a python virtual; environment:. ```bash; % mkdir venv; % virtualenv venv; % . venv/bin/activate; % pip install svn+https://llvm.org/svn/llvm-project/llvm/trunk/utils/lit; % lit --version; lit 0.8.0dev; ```. 2. Check out the `test-suite` module with:. ```bash; % git clone https://github.com/llvm/llvm-test-suite.git test-suite; ```. 3. Create a build directory and use CMake to configure the suite. Use the; `CMAKE_C_COMPILER` option to specify the compiler to test. Use a cache file; to choose a typical build configuration:. ```bash; % mkdir test-suite-build; % cd test-suite-build; % cmake -DCMAKE_C_COMPILER=<path to llvm build>/bin/clang \; -C../test-suite/cmake/caches/O3.cmake \; ../test-suite; ```. **NOTE!** if you are using your built clang, and you want to build and run the; MicroBenchmarks/XRay microbenchmarks, you need to add `compiler-rt` to your; `LLVM_ENABLE_RUNTIMES` cmake flag. 4. Build the benchmarks:. ```text; % make; Scanning dependencies of target timeit-target; [ 0%] Building C object tools/CMakeFiles/timeit-target.dir/timeit.c.o; [ 0%] Linking C executable timeit-target; ...; ```. 5. Run the tests with lit:. ```text; % llvm-lit -v -j 1 -o results.json .; -- Testing: 474 tests, 1 threads --; PASS: test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test (1 of 474); ********** TEST 'test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test' RESULTS **********; compile_time: 0.2192; exec_time: 0.0462; hash: ""59620e187c6ac38b36382685ccd2b63b""; size: 83348; **********; PASS: test-suite :: MultiSource/Applications/ALAC/encode/alacconvert-encode.test (2 of 474); ...; ```. 6. Show and compare result files (optional):. ```bash; # Make sure panda",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:513,Testability,test,test-suite,513,"test-suite Guide; ================. Quickstart; ----------. 1. The lit test runner is required to run the tests. You can either use one; from an LLVM build:. ```bash; % <path to llvm build>/bin/llvm-lit --version; lit 0.8.0dev; ```. An alternative is installing it as a python package in a python virtual; environment:. ```bash; % mkdir venv; % virtualenv venv; % . venv/bin/activate; % pip install svn+https://llvm.org/svn/llvm-project/llvm/trunk/utils/lit; % lit --version; lit 0.8.0dev; ```. 2. Check out the `test-suite` module with:. ```bash; % git clone https://github.com/llvm/llvm-test-suite.git test-suite; ```. 3. Create a build directory and use CMake to configure the suite. Use the; `CMAKE_C_COMPILER` option to specify the compiler to test. Use a cache file; to choose a typical build configuration:. ```bash; % mkdir test-suite-build; % cd test-suite-build; % cmake -DCMAKE_C_COMPILER=<path to llvm build>/bin/clang \; -C../test-suite/cmake/caches/O3.cmake \; ../test-suite; ```. **NOTE!** if you are using your built clang, and you want to build and run the; MicroBenchmarks/XRay microbenchmarks, you need to add `compiler-rt` to your; `LLVM_ENABLE_RUNTIMES` cmake flag. 4. Build the benchmarks:. ```text; % make; Scanning dependencies of target timeit-target; [ 0%] Building C object tools/CMakeFiles/timeit-target.dir/timeit.c.o; [ 0%] Linking C executable timeit-target; ...; ```. 5. Run the tests with lit:. ```text; % llvm-lit -v -j 1 -o results.json .; -- Testing: 474 tests, 1 threads --; PASS: test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test (1 of 474); ********** TEST 'test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test' RESULTS **********; compile_time: 0.2192; exec_time: 0.0462; hash: ""59620e187c6ac38b36382685ccd2b63b""; size: 83348; **********; PASS: test-suite :: MultiSource/Applications/ALAC/encode/alacconvert-encode.test (2 of 474); ...; ```. 6. Show and compare result files (optional):. ```bash; # Make sure panda",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:589,Testability,test,test-suite,589,"test-suite Guide; ================. Quickstart; ----------. 1. The lit test runner is required to run the tests. You can either use one; from an LLVM build:. ```bash; % <path to llvm build>/bin/llvm-lit --version; lit 0.8.0dev; ```. An alternative is installing it as a python package in a python virtual; environment:. ```bash; % mkdir venv; % virtualenv venv; % . venv/bin/activate; % pip install svn+https://llvm.org/svn/llvm-project/llvm/trunk/utils/lit; % lit --version; lit 0.8.0dev; ```. 2. Check out the `test-suite` module with:. ```bash; % git clone https://github.com/llvm/llvm-test-suite.git test-suite; ```. 3. Create a build directory and use CMake to configure the suite. Use the; `CMAKE_C_COMPILER` option to specify the compiler to test. Use a cache file; to choose a typical build configuration:. ```bash; % mkdir test-suite-build; % cd test-suite-build; % cmake -DCMAKE_C_COMPILER=<path to llvm build>/bin/clang \; -C../test-suite/cmake/caches/O3.cmake \; ../test-suite; ```. **NOTE!** if you are using your built clang, and you want to build and run the; MicroBenchmarks/XRay microbenchmarks, you need to add `compiler-rt` to your; `LLVM_ENABLE_RUNTIMES` cmake flag. 4. Build the benchmarks:. ```text; % make; Scanning dependencies of target timeit-target; [ 0%] Building C object tools/CMakeFiles/timeit-target.dir/timeit.c.o; [ 0%] Linking C executable timeit-target; ...; ```. 5. Run the tests with lit:. ```text; % llvm-lit -v -j 1 -o results.json .; -- Testing: 474 tests, 1 threads --; PASS: test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test (1 of 474); ********** TEST 'test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test' RESULTS **********; compile_time: 0.2192; exec_time: 0.0462; hash: ""59620e187c6ac38b36382685ccd2b63b""; size: 83348; **********; PASS: test-suite :: MultiSource/Applications/ALAC/encode/alacconvert-encode.test (2 of 474); ...; ```. 6. Show and compare result files (optional):. ```bash; # Make sure panda",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:604,Testability,test,test-suite,604,"test-suite Guide; ================. Quickstart; ----------. 1. The lit test runner is required to run the tests. You can either use one; from an LLVM build:. ```bash; % <path to llvm build>/bin/llvm-lit --version; lit 0.8.0dev; ```. An alternative is installing it as a python package in a python virtual; environment:. ```bash; % mkdir venv; % virtualenv venv; % . venv/bin/activate; % pip install svn+https://llvm.org/svn/llvm-project/llvm/trunk/utils/lit; % lit --version; lit 0.8.0dev; ```. 2. Check out the `test-suite` module with:. ```bash; % git clone https://github.com/llvm/llvm-test-suite.git test-suite; ```. 3. Create a build directory and use CMake to configure the suite. Use the; `CMAKE_C_COMPILER` option to specify the compiler to test. Use a cache file; to choose a typical build configuration:. ```bash; % mkdir test-suite-build; % cd test-suite-build; % cmake -DCMAKE_C_COMPILER=<path to llvm build>/bin/clang \; -C../test-suite/cmake/caches/O3.cmake \; ../test-suite; ```. **NOTE!** if you are using your built clang, and you want to build and run the; MicroBenchmarks/XRay microbenchmarks, you need to add `compiler-rt` to your; `LLVM_ENABLE_RUNTIMES` cmake flag. 4. Build the benchmarks:. ```text; % make; Scanning dependencies of target timeit-target; [ 0%] Building C object tools/CMakeFiles/timeit-target.dir/timeit.c.o; [ 0%] Linking C executable timeit-target; ...; ```. 5. Run the tests with lit:. ```text; % llvm-lit -v -j 1 -o results.json .; -- Testing: 474 tests, 1 threads --; PASS: test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test (1 of 474); ********** TEST 'test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test' RESULTS **********; compile_time: 0.2192; exec_time: 0.0462; hash: ""59620e187c6ac38b36382685ccd2b63b""; size: 83348; **********; PASS: test-suite :: MultiSource/Applications/ALAC/encode/alacconvert-encode.test (2 of 474); ...; ```. 6. Show and compare result files (optional):. ```bash; # Make sure panda",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:749,Testability,test,test,749,"test-suite Guide; ================. Quickstart; ----------. 1. The lit test runner is required to run the tests. You can either use one; from an LLVM build:. ```bash; % <path to llvm build>/bin/llvm-lit --version; lit 0.8.0dev; ```. An alternative is installing it as a python package in a python virtual; environment:. ```bash; % mkdir venv; % virtualenv venv; % . venv/bin/activate; % pip install svn+https://llvm.org/svn/llvm-project/llvm/trunk/utils/lit; % lit --version; lit 0.8.0dev; ```. 2. Check out the `test-suite` module with:. ```bash; % git clone https://github.com/llvm/llvm-test-suite.git test-suite; ```. 3. Create a build directory and use CMake to configure the suite. Use the; `CMAKE_C_COMPILER` option to specify the compiler to test. Use a cache file; to choose a typical build configuration:. ```bash; % mkdir test-suite-build; % cd test-suite-build; % cmake -DCMAKE_C_COMPILER=<path to llvm build>/bin/clang \; -C../test-suite/cmake/caches/O3.cmake \; ../test-suite; ```. **NOTE!** if you are using your built clang, and you want to build and run the; MicroBenchmarks/XRay microbenchmarks, you need to add `compiler-rt` to your; `LLVM_ENABLE_RUNTIMES` cmake flag. 4. Build the benchmarks:. ```text; % make; Scanning dependencies of target timeit-target; [ 0%] Building C object tools/CMakeFiles/timeit-target.dir/timeit.c.o; [ 0%] Linking C executable timeit-target; ...; ```. 5. Run the tests with lit:. ```text; % llvm-lit -v -j 1 -o results.json .; -- Testing: 474 tests, 1 threads --; PASS: test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test (1 of 474); ********** TEST 'test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test' RESULTS **********; compile_time: 0.2192; exec_time: 0.0462; hash: ""59620e187c6ac38b36382685ccd2b63b""; size: 83348; **********; PASS: test-suite :: MultiSource/Applications/ALAC/encode/alacconvert-encode.test (2 of 474); ...; ```. 6. Show and compare result files (optional):. ```bash; # Make sure panda",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:832,Testability,test,test-suite-build,832,"test-suite Guide; ================. Quickstart; ----------. 1. The lit test runner is required to run the tests. You can either use one; from an LLVM build:. ```bash; % <path to llvm build>/bin/llvm-lit --version; lit 0.8.0dev; ```. An alternative is installing it as a python package in a python virtual; environment:. ```bash; % mkdir venv; % virtualenv venv; % . venv/bin/activate; % pip install svn+https://llvm.org/svn/llvm-project/llvm/trunk/utils/lit; % lit --version; lit 0.8.0dev; ```. 2. Check out the `test-suite` module with:. ```bash; % git clone https://github.com/llvm/llvm-test-suite.git test-suite; ```. 3. Create a build directory and use CMake to configure the suite. Use the; `CMAKE_C_COMPILER` option to specify the compiler to test. Use a cache file; to choose a typical build configuration:. ```bash; % mkdir test-suite-build; % cd test-suite-build; % cmake -DCMAKE_C_COMPILER=<path to llvm build>/bin/clang \; -C../test-suite/cmake/caches/O3.cmake \; ../test-suite; ```. **NOTE!** if you are using your built clang, and you want to build and run the; MicroBenchmarks/XRay microbenchmarks, you need to add `compiler-rt` to your; `LLVM_ENABLE_RUNTIMES` cmake flag. 4. Build the benchmarks:. ```text; % make; Scanning dependencies of target timeit-target; [ 0%] Building C object tools/CMakeFiles/timeit-target.dir/timeit.c.o; [ 0%] Linking C executable timeit-target; ...; ```. 5. Run the tests with lit:. ```text; % llvm-lit -v -j 1 -o results.json .; -- Testing: 474 tests, 1 threads --; PASS: test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test (1 of 474); ********** TEST 'test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test' RESULTS **********; compile_time: 0.2192; exec_time: 0.0462; hash: ""59620e187c6ac38b36382685ccd2b63b""; size: 83348; **********; PASS: test-suite :: MultiSource/Applications/ALAC/encode/alacconvert-encode.test (2 of 474); ...; ```. 6. Show and compare result files (optional):. ```bash; # Make sure panda",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:855,Testability,test,test-suite-build,855,"test-suite Guide; ================. Quickstart; ----------. 1. The lit test runner is required to run the tests. You can either use one; from an LLVM build:. ```bash; % <path to llvm build>/bin/llvm-lit --version; lit 0.8.0dev; ```. An alternative is installing it as a python package in a python virtual; environment:. ```bash; % mkdir venv; % virtualenv venv; % . venv/bin/activate; % pip install svn+https://llvm.org/svn/llvm-project/llvm/trunk/utils/lit; % lit --version; lit 0.8.0dev; ```. 2. Check out the `test-suite` module with:. ```bash; % git clone https://github.com/llvm/llvm-test-suite.git test-suite; ```. 3. Create a build directory and use CMake to configure the suite. Use the; `CMAKE_C_COMPILER` option to specify the compiler to test. Use a cache file; to choose a typical build configuration:. ```bash; % mkdir test-suite-build; % cd test-suite-build; % cmake -DCMAKE_C_COMPILER=<path to llvm build>/bin/clang \; -C../test-suite/cmake/caches/O3.cmake \; ../test-suite; ```. **NOTE!** if you are using your built clang, and you want to build and run the; MicroBenchmarks/XRay microbenchmarks, you need to add `compiler-rt` to your; `LLVM_ENABLE_RUNTIMES` cmake flag. 4. Build the benchmarks:. ```text; % make; Scanning dependencies of target timeit-target; [ 0%] Building C object tools/CMakeFiles/timeit-target.dir/timeit.c.o; [ 0%] Linking C executable timeit-target; ...; ```. 5. Run the tests with lit:. ```text; % llvm-lit -v -j 1 -o results.json .; -- Testing: 474 tests, 1 threads --; PASS: test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test (1 of 474); ********** TEST 'test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test' RESULTS **********; compile_time: 0.2192; exec_time: 0.0462; hash: ""59620e187c6ac38b36382685ccd2b63b""; size: 83348; **********; PASS: test-suite :: MultiSource/Applications/ALAC/encode/alacconvert-encode.test (2 of 474); ...; ```. 6. Show and compare result files (optional):. ```bash; # Make sure panda",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:939,Testability,test,test-suite,939,"test-suite Guide; ================. Quickstart; ----------. 1. The lit test runner is required to run the tests. You can either use one; from an LLVM build:. ```bash; % <path to llvm build>/bin/llvm-lit --version; lit 0.8.0dev; ```. An alternative is installing it as a python package in a python virtual; environment:. ```bash; % mkdir venv; % virtualenv venv; % . venv/bin/activate; % pip install svn+https://llvm.org/svn/llvm-project/llvm/trunk/utils/lit; % lit --version; lit 0.8.0dev; ```. 2. Check out the `test-suite` module with:. ```bash; % git clone https://github.com/llvm/llvm-test-suite.git test-suite; ```. 3. Create a build directory and use CMake to configure the suite. Use the; `CMAKE_C_COMPILER` option to specify the compiler to test. Use a cache file; to choose a typical build configuration:. ```bash; % mkdir test-suite-build; % cd test-suite-build; % cmake -DCMAKE_C_COMPILER=<path to llvm build>/bin/clang \; -C../test-suite/cmake/caches/O3.cmake \; ../test-suite; ```. **NOTE!** if you are using your built clang, and you want to build and run the; MicroBenchmarks/XRay microbenchmarks, you need to add `compiler-rt` to your; `LLVM_ENABLE_RUNTIMES` cmake flag. 4. Build the benchmarks:. ```text; % make; Scanning dependencies of target timeit-target; [ 0%] Building C object tools/CMakeFiles/timeit-target.dir/timeit.c.o; [ 0%] Linking C executable timeit-target; ...; ```. 5. Run the tests with lit:. ```text; % llvm-lit -v -j 1 -o results.json .; -- Testing: 474 tests, 1 threads --; PASS: test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test (1 of 474); ********** TEST 'test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test' RESULTS **********; compile_time: 0.2192; exec_time: 0.0462; hash: ""59620e187c6ac38b36382685ccd2b63b""; size: 83348; **********; PASS: test-suite :: MultiSource/Applications/ALAC/encode/alacconvert-encode.test (2 of 474); ...; ```. 6. Show and compare result files (optional):. ```bash; # Make sure panda",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:978,Testability,test,test-suite,978,"test-suite Guide; ================. Quickstart; ----------. 1. The lit test runner is required to run the tests. You can either use one; from an LLVM build:. ```bash; % <path to llvm build>/bin/llvm-lit --version; lit 0.8.0dev; ```. An alternative is installing it as a python package in a python virtual; environment:. ```bash; % mkdir venv; % virtualenv venv; % . venv/bin/activate; % pip install svn+https://llvm.org/svn/llvm-project/llvm/trunk/utils/lit; % lit --version; lit 0.8.0dev; ```. 2. Check out the `test-suite` module with:. ```bash; % git clone https://github.com/llvm/llvm-test-suite.git test-suite; ```. 3. Create a build directory and use CMake to configure the suite. Use the; `CMAKE_C_COMPILER` option to specify the compiler to test. Use a cache file; to choose a typical build configuration:. ```bash; % mkdir test-suite-build; % cd test-suite-build; % cmake -DCMAKE_C_COMPILER=<path to llvm build>/bin/clang \; -C../test-suite/cmake/caches/O3.cmake \; ../test-suite; ```. **NOTE!** if you are using your built clang, and you want to build and run the; MicroBenchmarks/XRay microbenchmarks, you need to add `compiler-rt` to your; `LLVM_ENABLE_RUNTIMES` cmake flag. 4. Build the benchmarks:. ```text; % make; Scanning dependencies of target timeit-target; [ 0%] Building C object tools/CMakeFiles/timeit-target.dir/timeit.c.o; [ 0%] Linking C executable timeit-target; ...; ```. 5. Run the tests with lit:. ```text; % llvm-lit -v -j 1 -o results.json .; -- Testing: 474 tests, 1 threads --; PASS: test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test (1 of 474); ********** TEST 'test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test' RESULTS **********; compile_time: 0.2192; exec_time: 0.0462; hash: ""59620e187c6ac38b36382685ccd2b63b""; size: 83348; **********; PASS: test-suite :: MultiSource/Applications/ALAC/encode/alacconvert-encode.test (2 of 474); ...; ```. 6. Show and compare result files (optional):. ```bash; # Make sure panda",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:1200,Testability,benchmark,benchmarks,1200,"it --version; lit 0.8.0dev; ```. An alternative is installing it as a python package in a python virtual; environment:. ```bash; % mkdir venv; % virtualenv venv; % . venv/bin/activate; % pip install svn+https://llvm.org/svn/llvm-project/llvm/trunk/utils/lit; % lit --version; lit 0.8.0dev; ```. 2. Check out the `test-suite` module with:. ```bash; % git clone https://github.com/llvm/llvm-test-suite.git test-suite; ```. 3. Create a build directory and use CMake to configure the suite. Use the; `CMAKE_C_COMPILER` option to specify the compiler to test. Use a cache file; to choose a typical build configuration:. ```bash; % mkdir test-suite-build; % cd test-suite-build; % cmake -DCMAKE_C_COMPILER=<path to llvm build>/bin/clang \; -C../test-suite/cmake/caches/O3.cmake \; ../test-suite; ```. **NOTE!** if you are using your built clang, and you want to build and run the; MicroBenchmarks/XRay microbenchmarks, you need to add `compiler-rt` to your; `LLVM_ENABLE_RUNTIMES` cmake flag. 4. Build the benchmarks:. ```text; % make; Scanning dependencies of target timeit-target; [ 0%] Building C object tools/CMakeFiles/timeit-target.dir/timeit.c.o; [ 0%] Linking C executable timeit-target; ...; ```. 5. Run the tests with lit:. ```text; % llvm-lit -v -j 1 -o results.json .; -- Testing: 474 tests, 1 threads --; PASS: test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test (1 of 474); ********** TEST 'test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test' RESULTS **********; compile_time: 0.2192; exec_time: 0.0462; hash: ""59620e187c6ac38b36382685ccd2b63b""; size: 83348; **********; PASS: test-suite :: MultiSource/Applications/ALAC/encode/alacconvert-encode.test (2 of 474); ...; ```. 6. Show and compare result files (optional):. ```bash; # Make sure pandas and scipy are installed. Prepend `sudo` if necessary.; % pip install pandas scipy; # Show a single result file:; % test-suite/utils/compare.py results.json; # Compare two result files:; % test-suite",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:1411,Testability,test,tests,1411,"m.org/svn/llvm-project/llvm/trunk/utils/lit; % lit --version; lit 0.8.0dev; ```. 2. Check out the `test-suite` module with:. ```bash; % git clone https://github.com/llvm/llvm-test-suite.git test-suite; ```. 3. Create a build directory and use CMake to configure the suite. Use the; `CMAKE_C_COMPILER` option to specify the compiler to test. Use a cache file; to choose a typical build configuration:. ```bash; % mkdir test-suite-build; % cd test-suite-build; % cmake -DCMAKE_C_COMPILER=<path to llvm build>/bin/clang \; -C../test-suite/cmake/caches/O3.cmake \; ../test-suite; ```. **NOTE!** if you are using your built clang, and you want to build and run the; MicroBenchmarks/XRay microbenchmarks, you need to add `compiler-rt` to your; `LLVM_ENABLE_RUNTIMES` cmake flag. 4. Build the benchmarks:. ```text; % make; Scanning dependencies of target timeit-target; [ 0%] Building C object tools/CMakeFiles/timeit-target.dir/timeit.c.o; [ 0%] Linking C executable timeit-target; ...; ```. 5. Run the tests with lit:. ```text; % llvm-lit -v -j 1 -o results.json .; -- Testing: 474 tests, 1 threads --; PASS: test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test (1 of 474); ********** TEST 'test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test' RESULTS **********; compile_time: 0.2192; exec_time: 0.0462; hash: ""59620e187c6ac38b36382685ccd2b63b""; size: 83348; **********; PASS: test-suite :: MultiSource/Applications/ALAC/encode/alacconvert-encode.test (2 of 474); ...; ```. 6. Show and compare result files (optional):. ```bash; # Make sure pandas and scipy are installed. Prepend `sudo` if necessary.; % pip install pandas scipy; # Show a single result file:; % test-suite/utils/compare.py results.json; # Compare two result files:; % test-suite/utils/compare.py results_a.json results_b.json; ```. Structure; ---------. The test-suite contains benchmark and test programs. The programs come with; reference outputs so that their correctness can be checked. T",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:1491,Testability,test,tests,1491,"e with:. ```bash; % git clone https://github.com/llvm/llvm-test-suite.git test-suite; ```. 3. Create a build directory and use CMake to configure the suite. Use the; `CMAKE_C_COMPILER` option to specify the compiler to test. Use a cache file; to choose a typical build configuration:. ```bash; % mkdir test-suite-build; % cd test-suite-build; % cmake -DCMAKE_C_COMPILER=<path to llvm build>/bin/clang \; -C../test-suite/cmake/caches/O3.cmake \; ../test-suite; ```. **NOTE!** if you are using your built clang, and you want to build and run the; MicroBenchmarks/XRay microbenchmarks, you need to add `compiler-rt` to your; `LLVM_ENABLE_RUNTIMES` cmake flag. 4. Build the benchmarks:. ```text; % make; Scanning dependencies of target timeit-target; [ 0%] Building C object tools/CMakeFiles/timeit-target.dir/timeit.c.o; [ 0%] Linking C executable timeit-target; ...; ```. 5. Run the tests with lit:. ```text; % llvm-lit -v -j 1 -o results.json .; -- Testing: 474 tests, 1 threads --; PASS: test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test (1 of 474); ********** TEST 'test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test' RESULTS **********; compile_time: 0.2192; exec_time: 0.0462; hash: ""59620e187c6ac38b36382685ccd2b63b""; size: 83348; **********; PASS: test-suite :: MultiSource/Applications/ALAC/encode/alacconvert-encode.test (2 of 474); ...; ```. 6. Show and compare result files (optional):. ```bash; # Make sure pandas and scipy are installed. Prepend `sudo` if necessary.; % pip install pandas scipy; # Show a single result file:; % test-suite/utils/compare.py results.json; # Compare two result files:; % test-suite/utils/compare.py results_a.json results_b.json; ```. Structure; ---------. The test-suite contains benchmark and test programs. The programs come with; reference outputs so that their correctness can be checked. The suite comes; with tools to collect metrics such as benchmark runtime, compilation time and; code size. The test-s",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:1518,Testability,test,test-suite,1518,"e with:. ```bash; % git clone https://github.com/llvm/llvm-test-suite.git test-suite; ```. 3. Create a build directory and use CMake to configure the suite. Use the; `CMAKE_C_COMPILER` option to specify the compiler to test. Use a cache file; to choose a typical build configuration:. ```bash; % mkdir test-suite-build; % cd test-suite-build; % cmake -DCMAKE_C_COMPILER=<path to llvm build>/bin/clang \; -C../test-suite/cmake/caches/O3.cmake \; ../test-suite; ```. **NOTE!** if you are using your built clang, and you want to build and run the; MicroBenchmarks/XRay microbenchmarks, you need to add `compiler-rt` to your; `LLVM_ENABLE_RUNTIMES` cmake flag. 4. Build the benchmarks:. ```text; % make; Scanning dependencies of target timeit-target; [ 0%] Building C object tools/CMakeFiles/timeit-target.dir/timeit.c.o; [ 0%] Linking C executable timeit-target; ...; ```. 5. Run the tests with lit:. ```text; % llvm-lit -v -j 1 -o results.json .; -- Testing: 474 tests, 1 threads --; PASS: test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test (1 of 474); ********** TEST 'test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test' RESULTS **********; compile_time: 0.2192; exec_time: 0.0462; hash: ""59620e187c6ac38b36382685ccd2b63b""; size: 83348; **********; PASS: test-suite :: MultiSource/Applications/ALAC/encode/alacconvert-encode.test (2 of 474); ...; ```. 6. Show and compare result files (optional):. ```bash; # Make sure pandas and scipy are installed. Prepend `sudo` if necessary.; % pip install pandas scipy; # Show a single result file:; % test-suite/utils/compare.py results.json; # Compare two result files:; % test-suite/utils/compare.py results_a.json results_b.json; ```. Structure; ---------. The test-suite contains benchmark and test programs. The programs come with; reference outputs so that their correctness can be checked. The suite comes; with tools to collect metrics such as benchmark runtime, compilation time and; code size. The test-s",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:1588,Testability,test,test,1588,"irectory and use CMake to configure the suite. Use the; `CMAKE_C_COMPILER` option to specify the compiler to test. Use a cache file; to choose a typical build configuration:. ```bash; % mkdir test-suite-build; % cd test-suite-build; % cmake -DCMAKE_C_COMPILER=<path to llvm build>/bin/clang \; -C../test-suite/cmake/caches/O3.cmake \; ../test-suite; ```. **NOTE!** if you are using your built clang, and you want to build and run the; MicroBenchmarks/XRay microbenchmarks, you need to add `compiler-rt` to your; `LLVM_ENABLE_RUNTIMES` cmake flag. 4. Build the benchmarks:. ```text; % make; Scanning dependencies of target timeit-target; [ 0%] Building C object tools/CMakeFiles/timeit-target.dir/timeit.c.o; [ 0%] Linking C executable timeit-target; ...; ```. 5. Run the tests with lit:. ```text; % llvm-lit -v -j 1 -o results.json .; -- Testing: 474 tests, 1 threads --; PASS: test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test (1 of 474); ********** TEST 'test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test' RESULTS **********; compile_time: 0.2192; exec_time: 0.0462; hash: ""59620e187c6ac38b36382685ccd2b63b""; size: 83348; **********; PASS: test-suite :: MultiSource/Applications/ALAC/encode/alacconvert-encode.test (2 of 474); ...; ```. 6. Show and compare result files (optional):. ```bash; # Make sure pandas and scipy are installed. Prepend `sudo` if necessary.; % pip install pandas scipy; # Show a single result file:; % test-suite/utils/compare.py results.json; # Compare two result files:; % test-suite/utils/compare.py results_a.json results_b.json; ```. Structure; ---------. The test-suite contains benchmark and test programs. The programs come with; reference outputs so that their correctness can be checked. The suite comes; with tools to collect metrics such as benchmark runtime, compilation time and; code size. The test-suite is divided into several directories:. - `SingleSource/`. Contains test programs that are only a single s",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:1622,Testability,test,test-suite,1622,"irectory and use CMake to configure the suite. Use the; `CMAKE_C_COMPILER` option to specify the compiler to test. Use a cache file; to choose a typical build configuration:. ```bash; % mkdir test-suite-build; % cd test-suite-build; % cmake -DCMAKE_C_COMPILER=<path to llvm build>/bin/clang \; -C../test-suite/cmake/caches/O3.cmake \; ../test-suite; ```. **NOTE!** if you are using your built clang, and you want to build and run the; MicroBenchmarks/XRay microbenchmarks, you need to add `compiler-rt` to your; `LLVM_ENABLE_RUNTIMES` cmake flag. 4. Build the benchmarks:. ```text; % make; Scanning dependencies of target timeit-target; [ 0%] Building C object tools/CMakeFiles/timeit-target.dir/timeit.c.o; [ 0%] Linking C executable timeit-target; ...; ```. 5. Run the tests with lit:. ```text; % llvm-lit -v -j 1 -o results.json .; -- Testing: 474 tests, 1 threads --; PASS: test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test (1 of 474); ********** TEST 'test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test' RESULTS **********; compile_time: 0.2192; exec_time: 0.0462; hash: ""59620e187c6ac38b36382685ccd2b63b""; size: 83348; **********; PASS: test-suite :: MultiSource/Applications/ALAC/encode/alacconvert-encode.test (2 of 474); ...; ```. 6. Show and compare result files (optional):. ```bash; # Make sure pandas and scipy are installed. Prepend `sudo` if necessary.; % pip install pandas scipy; # Show a single result file:; % test-suite/utils/compare.py results.json; # Compare two result files:; % test-suite/utils/compare.py results_a.json results_b.json; ```. Structure; ---------. The test-suite contains benchmark and test programs. The programs come with; reference outputs so that their correctness can be checked. The suite comes; with tools to collect metrics such as benchmark runtime, compilation time and; code size. The test-suite is divided into several directories:. - `SingleSource/`. Contains test programs that are only a single s",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:1692,Testability,test,test,1692,"` option to specify the compiler to test. Use a cache file; to choose a typical build configuration:. ```bash; % mkdir test-suite-build; % cd test-suite-build; % cmake -DCMAKE_C_COMPILER=<path to llvm build>/bin/clang \; -C../test-suite/cmake/caches/O3.cmake \; ../test-suite; ```. **NOTE!** if you are using your built clang, and you want to build and run the; MicroBenchmarks/XRay microbenchmarks, you need to add `compiler-rt` to your; `LLVM_ENABLE_RUNTIMES` cmake flag. 4. Build the benchmarks:. ```text; % make; Scanning dependencies of target timeit-target; [ 0%] Building C object tools/CMakeFiles/timeit-target.dir/timeit.c.o; [ 0%] Linking C executable timeit-target; ...; ```. 5. Run the tests with lit:. ```text; % llvm-lit -v -j 1 -o results.json .; -- Testing: 474 tests, 1 threads --; PASS: test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test (1 of 474); ********** TEST 'test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test' RESULTS **********; compile_time: 0.2192; exec_time: 0.0462; hash: ""59620e187c6ac38b36382685ccd2b63b""; size: 83348; **********; PASS: test-suite :: MultiSource/Applications/ALAC/encode/alacconvert-encode.test (2 of 474); ...; ```. 6. Show and compare result files (optional):. ```bash; # Make sure pandas and scipy are installed. Prepend `sudo` if necessary.; % pip install pandas scipy; # Show a single result file:; % test-suite/utils/compare.py results.json; # Compare two result files:; % test-suite/utils/compare.py results_a.json results_b.json; ```. Structure; ---------. The test-suite contains benchmark and test programs. The programs come with; reference outputs so that their correctness can be checked. The suite comes; with tools to collect metrics such as benchmark runtime, compilation time and; code size. The test-suite is divided into several directories:. - `SingleSource/`. Contains test programs that are only a single source file in size. A; subdirectory may contain several programs. - `Mult",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:1832,Testability,test,test-suite,1832,"kdir test-suite-build; % cd test-suite-build; % cmake -DCMAKE_C_COMPILER=<path to llvm build>/bin/clang \; -C../test-suite/cmake/caches/O3.cmake \; ../test-suite; ```. **NOTE!** if you are using your built clang, and you want to build and run the; MicroBenchmarks/XRay microbenchmarks, you need to add `compiler-rt` to your; `LLVM_ENABLE_RUNTIMES` cmake flag. 4. Build the benchmarks:. ```text; % make; Scanning dependencies of target timeit-target; [ 0%] Building C object tools/CMakeFiles/timeit-target.dir/timeit.c.o; [ 0%] Linking C executable timeit-target; ...; ```. 5. Run the tests with lit:. ```text; % llvm-lit -v -j 1 -o results.json .; -- Testing: 474 tests, 1 threads --; PASS: test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test (1 of 474); ********** TEST 'test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test' RESULTS **********; compile_time: 0.2192; exec_time: 0.0462; hash: ""59620e187c6ac38b36382685ccd2b63b""; size: 83348; **********; PASS: test-suite :: MultiSource/Applications/ALAC/encode/alacconvert-encode.test (2 of 474); ...; ```. 6. Show and compare result files (optional):. ```bash; # Make sure pandas and scipy are installed. Prepend `sudo` if necessary.; % pip install pandas scipy; # Show a single result file:; % test-suite/utils/compare.py results.json; # Compare two result files:; % test-suite/utils/compare.py results_a.json results_b.json; ```. Structure; ---------. The test-suite contains benchmark and test programs. The programs come with; reference outputs so that their correctness can be checked. The suite comes; with tools to collect metrics such as benchmark runtime, compilation time and; code size. The test-suite is divided into several directories:. - `SingleSource/`. Contains test programs that are only a single source file in size. A; subdirectory may contain several programs. - `MultiSource/`. Contains subdirectories which entire programs with multiple source files.; Large benchmarks and whole ap",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:1902,Testability,test,test,1902,"vm build>/bin/clang \; -C../test-suite/cmake/caches/O3.cmake \; ../test-suite; ```. **NOTE!** if you are using your built clang, and you want to build and run the; MicroBenchmarks/XRay microbenchmarks, you need to add `compiler-rt` to your; `LLVM_ENABLE_RUNTIMES` cmake flag. 4. Build the benchmarks:. ```text; % make; Scanning dependencies of target timeit-target; [ 0%] Building C object tools/CMakeFiles/timeit-target.dir/timeit.c.o; [ 0%] Linking C executable timeit-target; ...; ```. 5. Run the tests with lit:. ```text; % llvm-lit -v -j 1 -o results.json .; -- Testing: 474 tests, 1 threads --; PASS: test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test (1 of 474); ********** TEST 'test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test' RESULTS **********; compile_time: 0.2192; exec_time: 0.0462; hash: ""59620e187c6ac38b36382685ccd2b63b""; size: 83348; **********; PASS: test-suite :: MultiSource/Applications/ALAC/encode/alacconvert-encode.test (2 of 474); ...; ```. 6. Show and compare result files (optional):. ```bash; # Make sure pandas and scipy are installed. Prepend `sudo` if necessary.; % pip install pandas scipy; # Show a single result file:; % test-suite/utils/compare.py results.json; # Compare two result files:; % test-suite/utils/compare.py results_a.json results_b.json; ```. Structure; ---------. The test-suite contains benchmark and test programs. The programs come with; reference outputs so that their correctness can be checked. The suite comes; with tools to collect metrics such as benchmark runtime, compilation time and; code size. The test-suite is divided into several directories:. - `SingleSource/`. Contains test programs that are only a single source file in size. A; subdirectory may contain several programs. - `MultiSource/`. Contains subdirectories which entire programs with multiple source files.; Large benchmarks and whole applications go here. - `MicroBenchmarks/`. Programs using the [google-benchmark](htt",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:2118,Testability,test,test-suite,2118,"robenchmarks, you need to add `compiler-rt` to your; `LLVM_ENABLE_RUNTIMES` cmake flag. 4. Build the benchmarks:. ```text; % make; Scanning dependencies of target timeit-target; [ 0%] Building C object tools/CMakeFiles/timeit-target.dir/timeit.c.o; [ 0%] Linking C executable timeit-target; ...; ```. 5. Run the tests with lit:. ```text; % llvm-lit -v -j 1 -o results.json .; -- Testing: 474 tests, 1 threads --; PASS: test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test (1 of 474); ********** TEST 'test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test' RESULTS **********; compile_time: 0.2192; exec_time: 0.0462; hash: ""59620e187c6ac38b36382685ccd2b63b""; size: 83348; **********; PASS: test-suite :: MultiSource/Applications/ALAC/encode/alacconvert-encode.test (2 of 474); ...; ```. 6. Show and compare result files (optional):. ```bash; # Make sure pandas and scipy are installed. Prepend `sudo` if necessary.; % pip install pandas scipy; # Show a single result file:; % test-suite/utils/compare.py results.json; # Compare two result files:; % test-suite/utils/compare.py results_a.json results_b.json; ```. Structure; ---------. The test-suite contains benchmark and test programs. The programs come with; reference outputs so that their correctness can be checked. The suite comes; with tools to collect metrics such as benchmark runtime, compilation time and; code size. The test-suite is divided into several directories:. - `SingleSource/`. Contains test programs that are only a single source file in size. A; subdirectory may contain several programs. - `MultiSource/`. Contains subdirectories which entire programs with multiple source files.; Large benchmarks and whole applications go here. - `MicroBenchmarks/`. Programs using the [google-benchmark](https://github.com/google/benchmark); library. The programs define functions that are run multiple times until the; measurement results are statistically significant. - `External/`. Contains d",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:2191,Testability,test,test-suite,2191,". 4. Build the benchmarks:. ```text; % make; Scanning dependencies of target timeit-target; [ 0%] Building C object tools/CMakeFiles/timeit-target.dir/timeit.c.o; [ 0%] Linking C executable timeit-target; ...; ```. 5. Run the tests with lit:. ```text; % llvm-lit -v -j 1 -o results.json .; -- Testing: 474 tests, 1 threads --; PASS: test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test (1 of 474); ********** TEST 'test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test' RESULTS **********; compile_time: 0.2192; exec_time: 0.0462; hash: ""59620e187c6ac38b36382685ccd2b63b""; size: 83348; **********; PASS: test-suite :: MultiSource/Applications/ALAC/encode/alacconvert-encode.test (2 of 474); ...; ```. 6. Show and compare result files (optional):. ```bash; # Make sure pandas and scipy are installed. Prepend `sudo` if necessary.; % pip install pandas scipy; # Show a single result file:; % test-suite/utils/compare.py results.json; # Compare two result files:; % test-suite/utils/compare.py results_a.json results_b.json; ```. Structure; ---------. The test-suite contains benchmark and test programs. The programs come with; reference outputs so that their correctness can be checked. The suite comes; with tools to collect metrics such as benchmark runtime, compilation time and; code size. The test-suite is divided into several directories:. - `SingleSource/`. Contains test programs that are only a single source file in size. A; subdirectory may contain several programs. - `MultiSource/`. Contains subdirectories which entire programs with multiple source files.; Large benchmarks and whole applications go here. - `MicroBenchmarks/`. Programs using the [google-benchmark](https://github.com/google/benchmark); library. The programs define functions that are run multiple times until the; measurement results are statistically significant. - `External/`. Contains descriptions and test data for code that cannot be directly; distributed with the test",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:2281,Testability,test,test-suite,2281,"ools/CMakeFiles/timeit-target.dir/timeit.c.o; [ 0%] Linking C executable timeit-target; ...; ```. 5. Run the tests with lit:. ```text; % llvm-lit -v -j 1 -o results.json .; -- Testing: 474 tests, 1 threads --; PASS: test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test (1 of 474); ********** TEST 'test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test' RESULTS **********; compile_time: 0.2192; exec_time: 0.0462; hash: ""59620e187c6ac38b36382685ccd2b63b""; size: 83348; **********; PASS: test-suite :: MultiSource/Applications/ALAC/encode/alacconvert-encode.test (2 of 474); ...; ```. 6. Show and compare result files (optional):. ```bash; # Make sure pandas and scipy are installed. Prepend `sudo` if necessary.; % pip install pandas scipy; # Show a single result file:; % test-suite/utils/compare.py results.json; # Compare two result files:; % test-suite/utils/compare.py results_a.json results_b.json; ```. Structure; ---------. The test-suite contains benchmark and test programs. The programs come with; reference outputs so that their correctness can be checked. The suite comes; with tools to collect metrics such as benchmark runtime, compilation time and; code size. The test-suite is divided into several directories:. - `SingleSource/`. Contains test programs that are only a single source file in size. A; subdirectory may contain several programs. - `MultiSource/`. Contains subdirectories which entire programs with multiple source files.; Large benchmarks and whole applications go here. - `MicroBenchmarks/`. Programs using the [google-benchmark](https://github.com/google/benchmark); library. The programs define functions that are run multiple times until the; measurement results are statistically significant. - `External/`. Contains descriptions and test data for code that cannot be directly; distributed with the test-suite. The most prominent members of this; directory are the SPEC CPU benchmark suites.; See [External Suites](#exter",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:2301,Testability,benchmark,benchmark,2301,"ools/CMakeFiles/timeit-target.dir/timeit.c.o; [ 0%] Linking C executable timeit-target; ...; ```. 5. Run the tests with lit:. ```text; % llvm-lit -v -j 1 -o results.json .; -- Testing: 474 tests, 1 threads --; PASS: test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test (1 of 474); ********** TEST 'test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test' RESULTS **********; compile_time: 0.2192; exec_time: 0.0462; hash: ""59620e187c6ac38b36382685ccd2b63b""; size: 83348; **********; PASS: test-suite :: MultiSource/Applications/ALAC/encode/alacconvert-encode.test (2 of 474); ...; ```. 6. Show and compare result files (optional):. ```bash; # Make sure pandas and scipy are installed. Prepend `sudo` if necessary.; % pip install pandas scipy; # Show a single result file:; % test-suite/utils/compare.py results.json; # Compare two result files:; % test-suite/utils/compare.py results_a.json results_b.json; ```. Structure; ---------. The test-suite contains benchmark and test programs. The programs come with; reference outputs so that their correctness can be checked. The suite comes; with tools to collect metrics such as benchmark runtime, compilation time and; code size. The test-suite is divided into several directories:. - `SingleSource/`. Contains test programs that are only a single source file in size. A; subdirectory may contain several programs. - `MultiSource/`. Contains subdirectories which entire programs with multiple source files.; Large benchmarks and whole applications go here. - `MicroBenchmarks/`. Programs using the [google-benchmark](https://github.com/google/benchmark); library. The programs define functions that are run multiple times until the; measurement results are statistically significant. - `External/`. Contains descriptions and test data for code that cannot be directly; distributed with the test-suite. The most prominent members of this; directory are the SPEC CPU benchmark suites.; See [External Suites](#exter",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:2315,Testability,test,test,2315,"ools/CMakeFiles/timeit-target.dir/timeit.c.o; [ 0%] Linking C executable timeit-target; ...; ```. 5. Run the tests with lit:. ```text; % llvm-lit -v -j 1 -o results.json .; -- Testing: 474 tests, 1 threads --; PASS: test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test (1 of 474); ********** TEST 'test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test' RESULTS **********; compile_time: 0.2192; exec_time: 0.0462; hash: ""59620e187c6ac38b36382685ccd2b63b""; size: 83348; **********; PASS: test-suite :: MultiSource/Applications/ALAC/encode/alacconvert-encode.test (2 of 474); ...; ```. 6. Show and compare result files (optional):. ```bash; # Make sure pandas and scipy are installed. Prepend `sudo` if necessary.; % pip install pandas scipy; # Show a single result file:; % test-suite/utils/compare.py results.json; # Compare two result files:; % test-suite/utils/compare.py results_a.json results_b.json; ```. Structure; ---------. The test-suite contains benchmark and test programs. The programs come with; reference outputs so that their correctness can be checked. The suite comes; with tools to collect metrics such as benchmark runtime, compilation time and; code size. The test-suite is divided into several directories:. - `SingleSource/`. Contains test programs that are only a single source file in size. A; subdirectory may contain several programs. - `MultiSource/`. Contains subdirectories which entire programs with multiple source files.; Large benchmarks and whole applications go here. - `MicroBenchmarks/`. Programs using the [google-benchmark](https://github.com/google/benchmark); library. The programs define functions that are run multiple times until the; measurement results are statistically significant. - `External/`. Contains descriptions and test data for code that cannot be directly; distributed with the test-suite. The most prominent members of this; directory are the SPEC CPU benchmark suites.; See [External Suites](#exter",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:2469,Testability,benchmark,benchmark,2469,".json .; -- Testing: 474 tests, 1 threads --; PASS: test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test (1 of 474); ********** TEST 'test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test' RESULTS **********; compile_time: 0.2192; exec_time: 0.0462; hash: ""59620e187c6ac38b36382685ccd2b63b""; size: 83348; **********; PASS: test-suite :: MultiSource/Applications/ALAC/encode/alacconvert-encode.test (2 of 474); ...; ```. 6. Show and compare result files (optional):. ```bash; # Make sure pandas and scipy are installed. Prepend `sudo` if necessary.; % pip install pandas scipy; # Show a single result file:; % test-suite/utils/compare.py results.json; # Compare two result files:; % test-suite/utils/compare.py results_a.json results_b.json; ```. Structure; ---------. The test-suite contains benchmark and test programs. The programs come with; reference outputs so that their correctness can be checked. The suite comes; with tools to collect metrics such as benchmark runtime, compilation time and; code size. The test-suite is divided into several directories:. - `SingleSource/`. Contains test programs that are only a single source file in size. A; subdirectory may contain several programs. - `MultiSource/`. Contains subdirectories which entire programs with multiple source files.; Large benchmarks and whole applications go here. - `MicroBenchmarks/`. Programs using the [google-benchmark](https://github.com/google/benchmark); library. The programs define functions that are run multiple times until the; measurement results are statistically significant. - `External/`. Contains descriptions and test data for code that cannot be directly; distributed with the test-suite. The most prominent members of this; directory are the SPEC CPU benchmark suites.; See [External Suites](#external-suites). - `Bitcode/`. These tests are mostly written in LLVM bitcode. - `CTMark/`. Contains symbolic links to other benchmarks forming a representative sample;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:2525,Testability,test,test-suite,2525,"plications/ALAC/decode/alacconvert-decode.test (1 of 474); ********** TEST 'test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test' RESULTS **********; compile_time: 0.2192; exec_time: 0.0462; hash: ""59620e187c6ac38b36382685ccd2b63b""; size: 83348; **********; PASS: test-suite :: MultiSource/Applications/ALAC/encode/alacconvert-encode.test (2 of 474); ...; ```. 6. Show and compare result files (optional):. ```bash; # Make sure pandas and scipy are installed. Prepend `sudo` if necessary.; % pip install pandas scipy; # Show a single result file:; % test-suite/utils/compare.py results.json; # Compare two result files:; % test-suite/utils/compare.py results_a.json results_b.json; ```. Structure; ---------. The test-suite contains benchmark and test programs. The programs come with; reference outputs so that their correctness can be checked. The suite comes; with tools to collect metrics such as benchmark runtime, compilation time and; code size. The test-suite is divided into several directories:. - `SingleSource/`. Contains test programs that are only a single source file in size. A; subdirectory may contain several programs. - `MultiSource/`. Contains subdirectories which entire programs with multiple source files.; Large benchmarks and whole applications go here. - `MicroBenchmarks/`. Programs using the [google-benchmark](https://github.com/google/benchmark); library. The programs define functions that are run multiple times until the; measurement results are statistically significant. - `External/`. Contains descriptions and test data for code that cannot be directly; distributed with the test-suite. The most prominent members of this; directory are the SPEC CPU benchmark suites.; See [External Suites](#external-suites). - `Bitcode/`. These tests are mostly written in LLVM bitcode. - `CTMark/`. Contains symbolic links to other benchmarks forming a representative sample; for compilation performance measurements. ### Benchmarks. Every program can wor",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:2602,Testability,test,test,2602,"t-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test' RESULTS **********; compile_time: 0.2192; exec_time: 0.0462; hash: ""59620e187c6ac38b36382685ccd2b63b""; size: 83348; **********; PASS: test-suite :: MultiSource/Applications/ALAC/encode/alacconvert-encode.test (2 of 474); ...; ```. 6. Show and compare result files (optional):. ```bash; # Make sure pandas and scipy are installed. Prepend `sudo` if necessary.; % pip install pandas scipy; # Show a single result file:; % test-suite/utils/compare.py results.json; # Compare two result files:; % test-suite/utils/compare.py results_a.json results_b.json; ```. Structure; ---------. The test-suite contains benchmark and test programs. The programs come with; reference outputs so that their correctness can be checked. The suite comes; with tools to collect metrics such as benchmark runtime, compilation time and; code size. The test-suite is divided into several directories:. - `SingleSource/`. Contains test programs that are only a single source file in size. A; subdirectory may contain several programs. - `MultiSource/`. Contains subdirectories which entire programs with multiple source files.; Large benchmarks and whole applications go here. - `MicroBenchmarks/`. Programs using the [google-benchmark](https://github.com/google/benchmark); library. The programs define functions that are run multiple times until the; measurement results are statistically significant. - `External/`. Contains descriptions and test data for code that cannot be directly; distributed with the test-suite. The most prominent members of this; directory are the SPEC CPU benchmark suites.; See [External Suites](#external-suites). - `Bitcode/`. These tests are mostly written in LLVM bitcode. - `CTMark/`. Contains symbolic links to other benchmarks forming a representative sample; for compilation performance measurements. ### Benchmarks. Every program can work as a correctness test. Some programs are unsuitable for; performance measurem",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:2805,Testability,benchmark,benchmarks,2805,"**; PASS: test-suite :: MultiSource/Applications/ALAC/encode/alacconvert-encode.test (2 of 474); ...; ```. 6. Show and compare result files (optional):. ```bash; # Make sure pandas and scipy are installed. Prepend `sudo` if necessary.; % pip install pandas scipy; # Show a single result file:; % test-suite/utils/compare.py results.json; # Compare two result files:; % test-suite/utils/compare.py results_a.json results_b.json; ```. Structure; ---------. The test-suite contains benchmark and test programs. The programs come with; reference outputs so that their correctness can be checked. The suite comes; with tools to collect metrics such as benchmark runtime, compilation time and; code size. The test-suite is divided into several directories:. - `SingleSource/`. Contains test programs that are only a single source file in size. A; subdirectory may contain several programs. - `MultiSource/`. Contains subdirectories which entire programs with multiple source files.; Large benchmarks and whole applications go here. - `MicroBenchmarks/`. Programs using the [google-benchmark](https://github.com/google/benchmark); library. The programs define functions that are run multiple times until the; measurement results are statistically significant. - `External/`. Contains descriptions and test data for code that cannot be directly; distributed with the test-suite. The most prominent members of this; directory are the SPEC CPU benchmark suites.; See [External Suites](#external-suites). - `Bitcode/`. These tests are mostly written in LLVM bitcode. - `CTMark/`. Contains symbolic links to other benchmarks forming a representative sample; for compilation performance measurements. ### Benchmarks. Every program can work as a correctness test. Some programs are unsuitable for; performance measurements. Setting the `TEST_SUITE_BENCHMARKING_ONLY` CMake; option to `ON` will disable them. Configuration; -------------. The test-suite has configuration options to customize building and running t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:2897,Testability,benchmark,benchmark,2897,"ncode.test (2 of 474); ...; ```. 6. Show and compare result files (optional):. ```bash; # Make sure pandas and scipy are installed. Prepend `sudo` if necessary.; % pip install pandas scipy; # Show a single result file:; % test-suite/utils/compare.py results.json; # Compare two result files:; % test-suite/utils/compare.py results_a.json results_b.json; ```. Structure; ---------. The test-suite contains benchmark and test programs. The programs come with; reference outputs so that their correctness can be checked. The suite comes; with tools to collect metrics such as benchmark runtime, compilation time and; code size. The test-suite is divided into several directories:. - `SingleSource/`. Contains test programs that are only a single source file in size. A; subdirectory may contain several programs. - `MultiSource/`. Contains subdirectories which entire programs with multiple source files.; Large benchmarks and whole applications go here. - `MicroBenchmarks/`. Programs using the [google-benchmark](https://github.com/google/benchmark); library. The programs define functions that are run multiple times until the; measurement results are statistically significant. - `External/`. Contains descriptions and test data for code that cannot be directly; distributed with the test-suite. The most prominent members of this; directory are the SPEC CPU benchmark suites.; See [External Suites](#external-suites). - `Bitcode/`. These tests are mostly written in LLVM bitcode. - `CTMark/`. Contains symbolic links to other benchmarks forming a representative sample; for compilation performance measurements. ### Benchmarks. Every program can work as a correctness test. Some programs are unsuitable for; performance measurements. Setting the `TEST_SUITE_BENCHMARKING_ONLY` CMake; option to `ON` will disable them. Configuration; -------------. The test-suite has configuration options to customize building and running the; benchmarks. CMake can print a list of them:. ```bash; % cd test-suite-",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:2934,Testability,benchmark,benchmark,2934,"nd compare result files (optional):. ```bash; # Make sure pandas and scipy are installed. Prepend `sudo` if necessary.; % pip install pandas scipy; # Show a single result file:; % test-suite/utils/compare.py results.json; # Compare two result files:; % test-suite/utils/compare.py results_a.json results_b.json; ```. Structure; ---------. The test-suite contains benchmark and test programs. The programs come with; reference outputs so that their correctness can be checked. The suite comes; with tools to collect metrics such as benchmark runtime, compilation time and; code size. The test-suite is divided into several directories:. - `SingleSource/`. Contains test programs that are only a single source file in size. A; subdirectory may contain several programs. - `MultiSource/`. Contains subdirectories which entire programs with multiple source files.; Large benchmarks and whole applications go here. - `MicroBenchmarks/`. Programs using the [google-benchmark](https://github.com/google/benchmark); library. The programs define functions that are run multiple times until the; measurement results are statistically significant. - `External/`. Contains descriptions and test data for code that cannot be directly; distributed with the test-suite. The most prominent members of this; directory are the SPEC CPU benchmark suites.; See [External Suites](#external-suites). - `Bitcode/`. These tests are mostly written in LLVM bitcode. - `CTMark/`. Contains symbolic links to other benchmarks forming a representative sample; for compilation performance measurements. ### Benchmarks. Every program can work as a correctness test. Some programs are unsuitable for; performance measurements. Setting the `TEST_SUITE_BENCHMARKING_ONLY` CMake; option to `ON` will disable them. Configuration; -------------. The test-suite has configuration options to customize building and running the; benchmarks. CMake can print a list of them:. ```bash; % cd test-suite-build; # Print basic options:; % cmake -LH;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:3116,Testability,test,test,3116,"re.py results.json; # Compare two result files:; % test-suite/utils/compare.py results_a.json results_b.json; ```. Structure; ---------. The test-suite contains benchmark and test programs. The programs come with; reference outputs so that their correctness can be checked. The suite comes; with tools to collect metrics such as benchmark runtime, compilation time and; code size. The test-suite is divided into several directories:. - `SingleSource/`. Contains test programs that are only a single source file in size. A; subdirectory may contain several programs. - `MultiSource/`. Contains subdirectories which entire programs with multiple source files.; Large benchmarks and whole applications go here. - `MicroBenchmarks/`. Programs using the [google-benchmark](https://github.com/google/benchmark); library. The programs define functions that are run multiple times until the; measurement results are statistically significant. - `External/`. Contains descriptions and test data for code that cannot be directly; distributed with the test-suite. The most prominent members of this; directory are the SPEC CPU benchmark suites.; See [External Suites](#external-suites). - `Bitcode/`. These tests are mostly written in LLVM bitcode. - `CTMark/`. Contains symbolic links to other benchmarks forming a representative sample; for compilation performance measurements. ### Benchmarks. Every program can work as a correctness test. Some programs are unsuitable for; performance measurements. Setting the `TEST_SUITE_BENCHMARKING_ONLY` CMake; option to `ON` will disable them. Configuration; -------------. The test-suite has configuration options to customize building and running the; benchmarks. CMake can print a list of them:. ```bash; % cd test-suite-build; # Print basic options:; % cmake -LH; # Print all options:; % cmake -LAH; ```. ### Common Configuration Options. - `CMAKE_C_FLAGS`. Specify extra flags to be passed to C compiler invocations. The flags are; also passed to the C++ compiler ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:3181,Testability,test,test-suite,3181,"re.py results.json; # Compare two result files:; % test-suite/utils/compare.py results_a.json results_b.json; ```. Structure; ---------. The test-suite contains benchmark and test programs. The programs come with; reference outputs so that their correctness can be checked. The suite comes; with tools to collect metrics such as benchmark runtime, compilation time and; code size. The test-suite is divided into several directories:. - `SingleSource/`. Contains test programs that are only a single source file in size. A; subdirectory may contain several programs. - `MultiSource/`. Contains subdirectories which entire programs with multiple source files.; Large benchmarks and whole applications go here. - `MicroBenchmarks/`. Programs using the [google-benchmark](https://github.com/google/benchmark); library. The programs define functions that are run multiple times until the; measurement results are statistically significant. - `External/`. Contains descriptions and test data for code that cannot be directly; distributed with the test-suite. The most prominent members of this; directory are the SPEC CPU benchmark suites.; See [External Suites](#external-suites). - `Bitcode/`. These tests are mostly written in LLVM bitcode. - `CTMark/`. Contains symbolic links to other benchmarks forming a representative sample; for compilation performance measurements. ### Benchmarks. Every program can work as a correctness test. Some programs are unsuitable for; performance measurements. Setting the `TEST_SUITE_BENCHMARKING_ONLY` CMake; option to `ON` will disable them. Configuration; -------------. The test-suite has configuration options to customize building and running the; benchmarks. CMake can print a list of them:. ```bash; % cd test-suite-build; # Print basic options:; % cmake -LH; # Print all options:; % cmake -LAH; ```. ### Common Configuration Options. - `CMAKE_C_FLAGS`. Specify extra flags to be passed to C compiler invocations. The flags are; also passed to the C++ compiler ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:3256,Testability,benchmark,benchmark,3256,"n results_b.json; ```. Structure; ---------. The test-suite contains benchmark and test programs. The programs come with; reference outputs so that their correctness can be checked. The suite comes; with tools to collect metrics such as benchmark runtime, compilation time and; code size. The test-suite is divided into several directories:. - `SingleSource/`. Contains test programs that are only a single source file in size. A; subdirectory may contain several programs. - `MultiSource/`. Contains subdirectories which entire programs with multiple source files.; Large benchmarks and whole applications go here. - `MicroBenchmarks/`. Programs using the [google-benchmark](https://github.com/google/benchmark); library. The programs define functions that are run multiple times until the; measurement results are statistically significant. - `External/`. Contains descriptions and test data for code that cannot be directly; distributed with the test-suite. The most prominent members of this; directory are the SPEC CPU benchmark suites.; See [External Suites](#external-suites). - `Bitcode/`. These tests are mostly written in LLVM bitcode. - `CTMark/`. Contains symbolic links to other benchmarks forming a representative sample; for compilation performance measurements. ### Benchmarks. Every program can work as a correctness test. Some programs are unsuitable for; performance measurements. Setting the `TEST_SUITE_BENCHMARKING_ONLY` CMake; option to `ON` will disable them. Configuration; -------------. The test-suite has configuration options to customize building and running the; benchmarks. CMake can print a list of them:. ```bash; % cd test-suite-build; # Print basic options:; % cmake -LH; # Print all options:; % cmake -LAH; ```. ### Common Configuration Options. - `CMAKE_C_FLAGS`. Specify extra flags to be passed to C compiler invocations. The flags are; also passed to the C++ compiler and linker invocations. See; [https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_FLAGS.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:3336,Testability,test,tests,3336," reference outputs so that their correctness can be checked. The suite comes; with tools to collect metrics such as benchmark runtime, compilation time and; code size. The test-suite is divided into several directories:. - `SingleSource/`. Contains test programs that are only a single source file in size. A; subdirectory may contain several programs. - `MultiSource/`. Contains subdirectories which entire programs with multiple source files.; Large benchmarks and whole applications go here. - `MicroBenchmarks/`. Programs using the [google-benchmark](https://github.com/google/benchmark); library. The programs define functions that are run multiple times until the; measurement results are statistically significant. - `External/`. Contains descriptions and test data for code that cannot be directly; distributed with the test-suite. The most prominent members of this; directory are the SPEC CPU benchmark suites.; See [External Suites](#external-suites). - `Bitcode/`. These tests are mostly written in LLVM bitcode. - `CTMark/`. Contains symbolic links to other benchmarks forming a representative sample; for compilation performance measurements. ### Benchmarks. Every program can work as a correctness test. Some programs are unsuitable for; performance measurements. Setting the `TEST_SUITE_BENCHMARKING_ONLY` CMake; option to `ON` will disable them. Configuration; -------------. The test-suite has configuration options to customize building and running the; benchmarks. CMake can print a list of them:. ```bash; % cd test-suite-build; # Print basic options:; % cmake -LH; # Print all options:; % cmake -LAH; ```. ### Common Configuration Options. - `CMAKE_C_FLAGS`. Specify extra flags to be passed to C compiler invocations. The flags are; also passed to the C++ compiler and linker invocations. See; [https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_FLAGS.html](https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_FLAGS.html). - `CMAKE_C_COMPILER`. Select the C compiler e",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:3424,Testability,benchmark,benchmarks,3424,"ect metrics such as benchmark runtime, compilation time and; code size. The test-suite is divided into several directories:. - `SingleSource/`. Contains test programs that are only a single source file in size. A; subdirectory may contain several programs. - `MultiSource/`. Contains subdirectories which entire programs with multiple source files.; Large benchmarks and whole applications go here. - `MicroBenchmarks/`. Programs using the [google-benchmark](https://github.com/google/benchmark); library. The programs define functions that are run multiple times until the; measurement results are statistically significant. - `External/`. Contains descriptions and test data for code that cannot be directly; distributed with the test-suite. The most prominent members of this; directory are the SPEC CPU benchmark suites.; See [External Suites](#external-suites). - `Bitcode/`. These tests are mostly written in LLVM bitcode. - `CTMark/`. Contains symbolic links to other benchmarks forming a representative sample; for compilation performance measurements. ### Benchmarks. Every program can work as a correctness test. Some programs are unsuitable for; performance measurements. Setting the `TEST_SUITE_BENCHMARKING_ONLY` CMake; option to `ON` will disable them. Configuration; -------------. The test-suite has configuration options to customize building and running the; benchmarks. CMake can print a list of them:. ```bash; % cd test-suite-build; # Print basic options:; % cmake -LH; # Print all options:; % cmake -LAH; ```. ### Common Configuration Options. - `CMAKE_C_FLAGS`. Specify extra flags to be passed to C compiler invocations. The flags are; also passed to the C++ compiler and linker invocations. See; [https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_FLAGS.html](https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_FLAGS.html). - `CMAKE_C_COMPILER`. Select the C compiler executable to be used. Note that the C++ compiler is; inferred automatically i.e. when specifying ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:3566,Testability,test,test,3566,nto several directories:. - `SingleSource/`. Contains test programs that are only a single source file in size. A; subdirectory may contain several programs. - `MultiSource/`. Contains subdirectories which entire programs with multiple source files.; Large benchmarks and whole applications go here. - `MicroBenchmarks/`. Programs using the [google-benchmark](https://github.com/google/benchmark); library. The programs define functions that are run multiple times until the; measurement results are statistically significant. - `External/`. Contains descriptions and test data for code that cannot be directly; distributed with the test-suite. The most prominent members of this; directory are the SPEC CPU benchmark suites.; See [External Suites](#external-suites). - `Bitcode/`. These tests are mostly written in LLVM bitcode. - `CTMark/`. Contains symbolic links to other benchmarks forming a representative sample; for compilation performance measurements. ### Benchmarks. Every program can work as a correctness test. Some programs are unsuitable for; performance measurements. Setting the `TEST_SUITE_BENCHMARKING_ONLY` CMake; option to `ON` will disable them. Configuration; -------------. The test-suite has configuration options to customize building and running the; benchmarks. CMake can print a list of them:. ```bash; % cd test-suite-build; # Print basic options:; % cmake -LH; # Print all options:; % cmake -LAH; ```. ### Common Configuration Options. - `CMAKE_C_FLAGS`. Specify extra flags to be passed to C compiler invocations. The flags are; also passed to the C++ compiler and linker invocations. See; [https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_FLAGS.html](https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_FLAGS.html). - `CMAKE_C_COMPILER`. Select the C compiler executable to be used. Note that the C++ compiler is; inferred automatically i.e. when specifying `path/to/clang` CMake will; automatically use `path/to/clang++` as the C++ compiler. See; [https:/,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:3750,Testability,test,test-suite,3750,files.; Large benchmarks and whole applications go here. - `MicroBenchmarks/`. Programs using the [google-benchmark](https://github.com/google/benchmark); library. The programs define functions that are run multiple times until the; measurement results are statistically significant. - `External/`. Contains descriptions and test data for code that cannot be directly; distributed with the test-suite. The most prominent members of this; directory are the SPEC CPU benchmark suites.; See [External Suites](#external-suites). - `Bitcode/`. These tests are mostly written in LLVM bitcode. - `CTMark/`. Contains symbolic links to other benchmarks forming a representative sample; for compilation performance measurements. ### Benchmarks. Every program can work as a correctness test. Some programs are unsuitable for; performance measurements. Setting the `TEST_SUITE_BENCHMARKING_ONLY` CMake; option to `ON` will disable them. Configuration; -------------. The test-suite has configuration options to customize building and running the; benchmarks. CMake can print a list of them:. ```bash; % cd test-suite-build; # Print basic options:; % cmake -LH; # Print all options:; % cmake -LAH; ```. ### Common Configuration Options. - `CMAKE_C_FLAGS`. Specify extra flags to be passed to C compiler invocations. The flags are; also passed to the C++ compiler and linker invocations. See; [https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_FLAGS.html](https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_FLAGS.html). - `CMAKE_C_COMPILER`. Select the C compiler executable to be used. Note that the C++ compiler is; inferred automatically i.e. when specifying `path/to/clang` CMake will; automatically use `path/to/clang++` as the C++ compiler. See; [https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_COMPILER.html](https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_COMPILER.html). - `CMAKE_Fortran_COMPILER`. Select the Fortran compiler executable to be used. Not set by default and not; ,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:3826,Testability,benchmark,benchmarks,3826,files.; Large benchmarks and whole applications go here. - `MicroBenchmarks/`. Programs using the [google-benchmark](https://github.com/google/benchmark); library. The programs define functions that are run multiple times until the; measurement results are statistically significant. - `External/`. Contains descriptions and test data for code that cannot be directly; distributed with the test-suite. The most prominent members of this; directory are the SPEC CPU benchmark suites.; See [External Suites](#external-suites). - `Bitcode/`. These tests are mostly written in LLVM bitcode. - `CTMark/`. Contains symbolic links to other benchmarks forming a representative sample; for compilation performance measurements. ### Benchmarks. Every program can work as a correctness test. Some programs are unsuitable for; performance measurements. Setting the `TEST_SUITE_BENCHMARKING_ONLY` CMake; option to `ON` will disable them. Configuration; -------------. The test-suite has configuration options to customize building and running the; benchmarks. CMake can print a list of them:. ```bash; % cd test-suite-build; # Print basic options:; % cmake -LH; # Print all options:; % cmake -LAH; ```. ### Common Configuration Options. - `CMAKE_C_FLAGS`. Specify extra flags to be passed to C compiler invocations. The flags are; also passed to the C++ compiler and linker invocations. See; [https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_FLAGS.html](https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_FLAGS.html). - `CMAKE_C_COMPILER`. Select the C compiler executable to be used. Note that the C++ compiler is; inferred automatically i.e. when specifying `path/to/clang` CMake will; automatically use `path/to/clang++` as the C++ compiler. See; [https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_COMPILER.html](https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_COMPILER.html). - `CMAKE_Fortran_COMPILER`. Select the Fortran compiler executable to be used. Not set by default and not; ,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:3885,Testability,test,test-suite-build,3885,m/google/benchmark); library. The programs define functions that are run multiple times until the; measurement results are statistically significant. - `External/`. Contains descriptions and test data for code that cannot be directly; distributed with the test-suite. The most prominent members of this; directory are the SPEC CPU benchmark suites.; See [External Suites](#external-suites). - `Bitcode/`. These tests are mostly written in LLVM bitcode. - `CTMark/`. Contains symbolic links to other benchmarks forming a representative sample; for compilation performance measurements. ### Benchmarks. Every program can work as a correctness test. Some programs are unsuitable for; performance measurements. Setting the `TEST_SUITE_BENCHMARKING_ONLY` CMake; option to `ON` will disable them. Configuration; -------------. The test-suite has configuration options to customize building and running the; benchmarks. CMake can print a list of them:. ```bash; % cd test-suite-build; # Print basic options:; % cmake -LH; # Print all options:; % cmake -LAH; ```. ### Common Configuration Options. - `CMAKE_C_FLAGS`. Specify extra flags to be passed to C compiler invocations. The flags are; also passed to the C++ compiler and linker invocations. See; [https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_FLAGS.html](https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_FLAGS.html). - `CMAKE_C_COMPILER`. Select the C compiler executable to be used. Note that the C++ compiler is; inferred automatically i.e. when specifying `path/to/clang` CMake will; automatically use `path/to/clang++` as the C++ compiler. See; [https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_COMPILER.html](https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_COMPILER.html). - `CMAKE_Fortran_COMPILER`. Select the Fortran compiler executable to be used. Not set by default and not; required unless running the Fortran Test Suite. - `CMAKE_BUILD_TYPE`. Select a build type like `OPTIMIZE` or `DEBUG` selecting a set o,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:5272,Testability,test,tests,5272,help/latest/variable/CMAKE_LANG_FLAGS.html). - `CMAKE_C_COMPILER`. Select the C compiler executable to be used. Note that the C++ compiler is; inferred automatically i.e. when specifying `path/to/clang` CMake will; automatically use `path/to/clang++` as the C++ compiler. See; [https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_COMPILER.html](https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_COMPILER.html). - `CMAKE_Fortran_COMPILER`. Select the Fortran compiler executable to be used. Not set by default and not; required unless running the Fortran Test Suite. - `CMAKE_BUILD_TYPE`. Select a build type like `OPTIMIZE` or `DEBUG` selecting a set of predefined; compiler flags. These flags are applied regardless of the `CMAKE_C_FLAGS`; option and may be changed by modifying `CMAKE_C_FLAGS_OPTIMIZE` etc. See; [https://cmake.org/cmake/help/latest/variable/CMAKE_BUILD_TYPE.html](https://cmake.org/cmake/help/latest/variable/CMAKE_BUILD_TYPE.html). - `TEST_SUITE_FORTRAN`. Activate that Fortran tests. This is a work in progress. More information can be; found in the [Flang documentation](https://flang.llvm.org/docs/FortranLLVMTestSuite.html). - `TEST_SUITE_RUN_UNDER`. Prefix test invocations with the given tool. This is typically used to run; cross-compiled tests within a simulator tool. - `TEST_SUITE_BENCHMARKING_ONLY`. Disable tests that are unsuitable for performance measurements. The disabled; tests either run for a very short time or are dominated by I/O performance; making them unsuitable as compiler performance tests. - `TEST_SUITE_SUBDIRS`. Semicolon-separated list of directories to include. This can be used to only; build parts of the test-suite or to include external suites. This option; does not work reliably with deeper subdirectories as it skips intermediate; `CMakeLists.txt` files which may be required. - `TEST_SUITE_COLLECT_STATS`. Collect internal LLVM statistics. Appends `-save-stats=obj` when invoking the; compiler and makes the lit runner collect an,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:5456,Testability,test,test,5456,e will; automatically use `path/to/clang++` as the C++ compiler. See; [https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_COMPILER.html](https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_COMPILER.html). - `CMAKE_Fortran_COMPILER`. Select the Fortran compiler executable to be used. Not set by default and not; required unless running the Fortran Test Suite. - `CMAKE_BUILD_TYPE`. Select a build type like `OPTIMIZE` or `DEBUG` selecting a set of predefined; compiler flags. These flags are applied regardless of the `CMAKE_C_FLAGS`; option and may be changed by modifying `CMAKE_C_FLAGS_OPTIMIZE` etc. See; [https://cmake.org/cmake/help/latest/variable/CMAKE_BUILD_TYPE.html](https://cmake.org/cmake/help/latest/variable/CMAKE_BUILD_TYPE.html). - `TEST_SUITE_FORTRAN`. Activate that Fortran tests. This is a work in progress. More information can be; found in the [Flang documentation](https://flang.llvm.org/docs/FortranLLVMTestSuite.html). - `TEST_SUITE_RUN_UNDER`. Prefix test invocations with the given tool. This is typically used to run; cross-compiled tests within a simulator tool. - `TEST_SUITE_BENCHMARKING_ONLY`. Disable tests that are unsuitable for performance measurements. The disabled; tests either run for a very short time or are dominated by I/O performance; making them unsuitable as compiler performance tests. - `TEST_SUITE_SUBDIRS`. Semicolon-separated list of directories to include. This can be used to only; build parts of the test-suite or to include external suites. This option; does not work reliably with deeper subdirectories as it skips intermediate; `CMakeLists.txt` files which may be required. - `TEST_SUITE_COLLECT_STATS`. Collect internal LLVM statistics. Appends `-save-stats=obj` when invoking the; compiler and makes the lit runner collect and merge the statistic files. - `TEST_SUITE_RUN_BENCHMARKS`. If this is set to `OFF` then lit will not actually run the tests but just; collect build statistics like compile time and code size. - `TEST_SUITE_,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:5540,Testability,test,tests,5540,er. See; [https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_COMPILER.html](https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_COMPILER.html). - `CMAKE_Fortran_COMPILER`. Select the Fortran compiler executable to be used. Not set by default and not; required unless running the Fortran Test Suite. - `CMAKE_BUILD_TYPE`. Select a build type like `OPTIMIZE` or `DEBUG` selecting a set of predefined; compiler flags. These flags are applied regardless of the `CMAKE_C_FLAGS`; option and may be changed by modifying `CMAKE_C_FLAGS_OPTIMIZE` etc. See; [https://cmake.org/cmake/help/latest/variable/CMAKE_BUILD_TYPE.html](https://cmake.org/cmake/help/latest/variable/CMAKE_BUILD_TYPE.html). - `TEST_SUITE_FORTRAN`. Activate that Fortran tests. This is a work in progress. More information can be; found in the [Flang documentation](https://flang.llvm.org/docs/FortranLLVMTestSuite.html). - `TEST_SUITE_RUN_UNDER`. Prefix test invocations with the given tool. This is typically used to run; cross-compiled tests within a simulator tool. - `TEST_SUITE_BENCHMARKING_ONLY`. Disable tests that are unsuitable for performance measurements. The disabled; tests either run for a very short time or are dominated by I/O performance; making them unsuitable as compiler performance tests. - `TEST_SUITE_SUBDIRS`. Semicolon-separated list of directories to include. This can be used to only; build parts of the test-suite or to include external suites. This option; does not work reliably with deeper subdirectories as it skips intermediate; `CMakeLists.txt` files which may be required. - `TEST_SUITE_COLLECT_STATS`. Collect internal LLVM statistics. Appends `-save-stats=obj` when invoking the; compiler and makes the lit runner collect and merge the statistic files. - `TEST_SUITE_RUN_BENCHMARKS`. If this is set to `OFF` then lit will not actually run the tests but just; collect build statistics like compile time and code size. - `TEST_SUITE_USE_PERF`. Use the `perf` tool for time measurement instead o,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:5613,Testability,test,tests,5613,help/latest/variable/CMAKE_LANG_COMPILER.html). - `CMAKE_Fortran_COMPILER`. Select the Fortran compiler executable to be used. Not set by default and not; required unless running the Fortran Test Suite. - `CMAKE_BUILD_TYPE`. Select a build type like `OPTIMIZE` or `DEBUG` selecting a set of predefined; compiler flags. These flags are applied regardless of the `CMAKE_C_FLAGS`; option and may be changed by modifying `CMAKE_C_FLAGS_OPTIMIZE` etc. See; [https://cmake.org/cmake/help/latest/variable/CMAKE_BUILD_TYPE.html](https://cmake.org/cmake/help/latest/variable/CMAKE_BUILD_TYPE.html). - `TEST_SUITE_FORTRAN`. Activate that Fortran tests. This is a work in progress. More information can be; found in the [Flang documentation](https://flang.llvm.org/docs/FortranLLVMTestSuite.html). - `TEST_SUITE_RUN_UNDER`. Prefix test invocations with the given tool. This is typically used to run; cross-compiled tests within a simulator tool. - `TEST_SUITE_BENCHMARKING_ONLY`. Disable tests that are unsuitable for performance measurements. The disabled; tests either run for a very short time or are dominated by I/O performance; making them unsuitable as compiler performance tests. - `TEST_SUITE_SUBDIRS`. Semicolon-separated list of directories to include. This can be used to only; build parts of the test-suite or to include external suites. This option; does not work reliably with deeper subdirectories as it skips intermediate; `CMakeLists.txt` files which may be required. - `TEST_SUITE_COLLECT_STATS`. Collect internal LLVM statistics. Appends `-save-stats=obj` when invoking the; compiler and makes the lit runner collect and merge the statistic files. - `TEST_SUITE_RUN_BENCHMARKS`. If this is set to `OFF` then lit will not actually run the tests but just; collect build statistics like compile time and code size. - `TEST_SUITE_USE_PERF`. Use the `perf` tool for time measurement instead of the `timeit` tool that; comes with the test-suite. The `perf` is usually available on linux systems. -,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:5683,Testability,test,tests,5683,"executable to be used. Not set by default and not; required unless running the Fortran Test Suite. - `CMAKE_BUILD_TYPE`. Select a build type like `OPTIMIZE` or `DEBUG` selecting a set of predefined; compiler flags. These flags are applied regardless of the `CMAKE_C_FLAGS`; option and may be changed by modifying `CMAKE_C_FLAGS_OPTIMIZE` etc. See; [https://cmake.org/cmake/help/latest/variable/CMAKE_BUILD_TYPE.html](https://cmake.org/cmake/help/latest/variable/CMAKE_BUILD_TYPE.html). - `TEST_SUITE_FORTRAN`. Activate that Fortran tests. This is a work in progress. More information can be; found in the [Flang documentation](https://flang.llvm.org/docs/FortranLLVMTestSuite.html). - `TEST_SUITE_RUN_UNDER`. Prefix test invocations with the given tool. This is typically used to run; cross-compiled tests within a simulator tool. - `TEST_SUITE_BENCHMARKING_ONLY`. Disable tests that are unsuitable for performance measurements. The disabled; tests either run for a very short time or are dominated by I/O performance; making them unsuitable as compiler performance tests. - `TEST_SUITE_SUBDIRS`. Semicolon-separated list of directories to include. This can be used to only; build parts of the test-suite or to include external suites. This option; does not work reliably with deeper subdirectories as it skips intermediate; `CMakeLists.txt` files which may be required. - `TEST_SUITE_COLLECT_STATS`. Collect internal LLVM statistics. Appends `-save-stats=obj` when invoking the; compiler and makes the lit runner collect and merge the statistic files. - `TEST_SUITE_RUN_BENCHMARKS`. If this is set to `OFF` then lit will not actually run the tests but just; collect build statistics like compile time and code size. - `TEST_SUITE_USE_PERF`. Use the `perf` tool for time measurement instead of the `timeit` tool that; comes with the test-suite. The `perf` is usually available on linux systems. - `TEST_SUITE_SPEC2000_ROOT`, `TEST_SUITE_SPEC2006_ROOT`, `TEST_SUITE_SPEC2017_ROOT`, ... Specify install",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:5806,Testability,test,tests,5806,"executable to be used. Not set by default and not; required unless running the Fortran Test Suite. - `CMAKE_BUILD_TYPE`. Select a build type like `OPTIMIZE` or `DEBUG` selecting a set of predefined; compiler flags. These flags are applied regardless of the `CMAKE_C_FLAGS`; option and may be changed by modifying `CMAKE_C_FLAGS_OPTIMIZE` etc. See; [https://cmake.org/cmake/help/latest/variable/CMAKE_BUILD_TYPE.html](https://cmake.org/cmake/help/latest/variable/CMAKE_BUILD_TYPE.html). - `TEST_SUITE_FORTRAN`. Activate that Fortran tests. This is a work in progress. More information can be; found in the [Flang documentation](https://flang.llvm.org/docs/FortranLLVMTestSuite.html). - `TEST_SUITE_RUN_UNDER`. Prefix test invocations with the given tool. This is typically used to run; cross-compiled tests within a simulator tool. - `TEST_SUITE_BENCHMARKING_ONLY`. Disable tests that are unsuitable for performance measurements. The disabled; tests either run for a very short time or are dominated by I/O performance; making them unsuitable as compiler performance tests. - `TEST_SUITE_SUBDIRS`. Semicolon-separated list of directories to include. This can be used to only; build parts of the test-suite or to include external suites. This option; does not work reliably with deeper subdirectories as it skips intermediate; `CMakeLists.txt` files which may be required. - `TEST_SUITE_COLLECT_STATS`. Collect internal LLVM statistics. Appends `-save-stats=obj` when invoking the; compiler and makes the lit runner collect and merge the statistic files. - `TEST_SUITE_RUN_BENCHMARKS`. If this is set to `OFF` then lit will not actually run the tests but just; collect build statistics like compile time and code size. - `TEST_SUITE_USE_PERF`. Use the `perf` tool for time measurement instead of the `timeit` tool that; comes with the test-suite. The `perf` is usually available on linux systems. - `TEST_SUITE_SPEC2000_ROOT`, `TEST_SUITE_SPEC2006_ROOT`, `TEST_SUITE_SPEC2017_ROOT`, ... Specify install",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:5934,Testability,test,test-suite,5934,"efined; compiler flags. These flags are applied regardless of the `CMAKE_C_FLAGS`; option and may be changed by modifying `CMAKE_C_FLAGS_OPTIMIZE` etc. See; [https://cmake.org/cmake/help/latest/variable/CMAKE_BUILD_TYPE.html](https://cmake.org/cmake/help/latest/variable/CMAKE_BUILD_TYPE.html). - `TEST_SUITE_FORTRAN`. Activate that Fortran tests. This is a work in progress. More information can be; found in the [Flang documentation](https://flang.llvm.org/docs/FortranLLVMTestSuite.html). - `TEST_SUITE_RUN_UNDER`. Prefix test invocations with the given tool. This is typically used to run; cross-compiled tests within a simulator tool. - `TEST_SUITE_BENCHMARKING_ONLY`. Disable tests that are unsuitable for performance measurements. The disabled; tests either run for a very short time or are dominated by I/O performance; making them unsuitable as compiler performance tests. - `TEST_SUITE_SUBDIRS`. Semicolon-separated list of directories to include. This can be used to only; build parts of the test-suite or to include external suites. This option; does not work reliably with deeper subdirectories as it skips intermediate; `CMakeLists.txt` files which may be required. - `TEST_SUITE_COLLECT_STATS`. Collect internal LLVM statistics. Appends `-save-stats=obj` when invoking the; compiler and makes the lit runner collect and merge the statistic files. - `TEST_SUITE_RUN_BENCHMARKS`. If this is set to `OFF` then lit will not actually run the tests but just; collect build statistics like compile time and code size. - `TEST_SUITE_USE_PERF`. Use the `perf` tool for time measurement instead of the `timeit` tool that; comes with the test-suite. The `perf` is usually available on linux systems. - `TEST_SUITE_SPEC2000_ROOT`, `TEST_SUITE_SPEC2006_ROOT`, `TEST_SUITE_SPEC2017_ROOT`, ... Specify installation directories of external benchmark suites. You can find; more information about expected versions or usage in the README files in the; `External` directory (such as `External/SPEC/README`",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:6383,Testability,test,tests,6383,"/docs/FortranLLVMTestSuite.html). - `TEST_SUITE_RUN_UNDER`. Prefix test invocations with the given tool. This is typically used to run; cross-compiled tests within a simulator tool. - `TEST_SUITE_BENCHMARKING_ONLY`. Disable tests that are unsuitable for performance measurements. The disabled; tests either run for a very short time or are dominated by I/O performance; making them unsuitable as compiler performance tests. - `TEST_SUITE_SUBDIRS`. Semicolon-separated list of directories to include. This can be used to only; build parts of the test-suite or to include external suites. This option; does not work reliably with deeper subdirectories as it skips intermediate; `CMakeLists.txt` files which may be required. - `TEST_SUITE_COLLECT_STATS`. Collect internal LLVM statistics. Appends `-save-stats=obj` when invoking the; compiler and makes the lit runner collect and merge the statistic files. - `TEST_SUITE_RUN_BENCHMARKS`. If this is set to `OFF` then lit will not actually run the tests but just; collect build statistics like compile time and code size. - `TEST_SUITE_USE_PERF`. Use the `perf` tool for time measurement instead of the `timeit` tool that; comes with the test-suite. The `perf` is usually available on linux systems. - `TEST_SUITE_SPEC2000_ROOT`, `TEST_SUITE_SPEC2006_ROOT`, `TEST_SUITE_SPEC2017_ROOT`, ... Specify installation directories of external benchmark suites. You can find; more information about expected versions or usage in the README files in the; `External` directory (such as `External/SPEC/README`). ### Common CMake Flags. - `-GNinja`. Generate build files for the ninja build tool. - `-Ctest-suite/cmake/caches/<cachefile.cmake>`. Use a CMake cache. The test-suite comes with several CMake caches which; predefine common or tricky build configurations. Displaying and Analyzing Results; --------------------------------. The `compare.py` script displays and compares result files. A result file is; produced when invoking lit with the `-o filename.json`",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:6573,Testability,test,test-suite,6573,"ompiled tests within a simulator tool. - `TEST_SUITE_BENCHMARKING_ONLY`. Disable tests that are unsuitable for performance measurements. The disabled; tests either run for a very short time or are dominated by I/O performance; making them unsuitable as compiler performance tests. - `TEST_SUITE_SUBDIRS`. Semicolon-separated list of directories to include. This can be used to only; build parts of the test-suite or to include external suites. This option; does not work reliably with deeper subdirectories as it skips intermediate; `CMakeLists.txt` files which may be required. - `TEST_SUITE_COLLECT_STATS`. Collect internal LLVM statistics. Appends `-save-stats=obj` when invoking the; compiler and makes the lit runner collect and merge the statistic files. - `TEST_SUITE_RUN_BENCHMARKS`. If this is set to `OFF` then lit will not actually run the tests but just; collect build statistics like compile time and code size. - `TEST_SUITE_USE_PERF`. Use the `perf` tool for time measurement instead of the `timeit` tool that; comes with the test-suite. The `perf` is usually available on linux systems. - `TEST_SUITE_SPEC2000_ROOT`, `TEST_SUITE_SPEC2006_ROOT`, `TEST_SUITE_SPEC2017_ROOT`, ... Specify installation directories of external benchmark suites. You can find; more information about expected versions or usage in the README files in the; `External` directory (such as `External/SPEC/README`). ### Common CMake Flags. - `-GNinja`. Generate build files for the ninja build tool. - `-Ctest-suite/cmake/caches/<cachefile.cmake>`. Use a CMake cache. The test-suite comes with several CMake caches which; predefine common or tricky build configurations. Displaying and Analyzing Results; --------------------------------. The `compare.py` script displays and compares result files. A result file is; produced when invoking lit with the `-o filename.json` flag. Example usage:. - Basic Usage:. ```text; % test-suite/utils/compare.py baseline.json; Warning: 'test-suite :: External/SPEC/CINT2006/403",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:6770,Testability,benchmark,benchmark,6770,"ce; making them unsuitable as compiler performance tests. - `TEST_SUITE_SUBDIRS`. Semicolon-separated list of directories to include. This can be used to only; build parts of the test-suite or to include external suites. This option; does not work reliably with deeper subdirectories as it skips intermediate; `CMakeLists.txt` files which may be required. - `TEST_SUITE_COLLECT_STATS`. Collect internal LLVM statistics. Appends `-save-stats=obj` when invoking the; compiler and makes the lit runner collect and merge the statistic files. - `TEST_SUITE_RUN_BENCHMARKS`. If this is set to `OFF` then lit will not actually run the tests but just; collect build statistics like compile time and code size. - `TEST_SUITE_USE_PERF`. Use the `perf` tool for time measurement instead of the `timeit` tool that; comes with the test-suite. The `perf` is usually available on linux systems. - `TEST_SUITE_SPEC2000_ROOT`, `TEST_SUITE_SPEC2006_ROOT`, `TEST_SUITE_SPEC2017_ROOT`, ... Specify installation directories of external benchmark suites. You can find; more information about expected versions or usage in the README files in the; `External` directory (such as `External/SPEC/README`). ### Common CMake Flags. - `-GNinja`. Generate build files for the ninja build tool. - `-Ctest-suite/cmake/caches/<cachefile.cmake>`. Use a CMake cache. The test-suite comes with several CMake caches which; predefine common or tricky build configurations. Displaying and Analyzing Results; --------------------------------. The `compare.py` script displays and compares result files. A result file is; produced when invoking lit with the `-o filename.json` flag. Example usage:. - Basic Usage:. ```text; % test-suite/utils/compare.py baseline.json; Warning: 'test-suite :: External/SPEC/CINT2006/403.gcc/403.gcc.test' has No metrics!; Tests: 508; Metric: exec_time. Program baseline. INT2006/456.hmmer/456.hmmer 1222.90; INT2006/464.h264ref/464.h264ref 928.70; ...; baseline; count 506.000000; mean 20.563098; std 111.4233",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:7091,Testability,test,test-suite,7091,"S`. Collect internal LLVM statistics. Appends `-save-stats=obj` when invoking the; compiler and makes the lit runner collect and merge the statistic files. - `TEST_SUITE_RUN_BENCHMARKS`. If this is set to `OFF` then lit will not actually run the tests but just; collect build statistics like compile time and code size. - `TEST_SUITE_USE_PERF`. Use the `perf` tool for time measurement instead of the `timeit` tool that; comes with the test-suite. The `perf` is usually available on linux systems. - `TEST_SUITE_SPEC2000_ROOT`, `TEST_SUITE_SPEC2006_ROOT`, `TEST_SUITE_SPEC2017_ROOT`, ... Specify installation directories of external benchmark suites. You can find; more information about expected versions or usage in the README files in the; `External` directory (such as `External/SPEC/README`). ### Common CMake Flags. - `-GNinja`. Generate build files for the ninja build tool. - `-Ctest-suite/cmake/caches/<cachefile.cmake>`. Use a CMake cache. The test-suite comes with several CMake caches which; predefine common or tricky build configurations. Displaying and Analyzing Results; --------------------------------. The `compare.py` script displays and compares result files. A result file is; produced when invoking lit with the `-o filename.json` flag. Example usage:. - Basic Usage:. ```text; % test-suite/utils/compare.py baseline.json; Warning: 'test-suite :: External/SPEC/CINT2006/403.gcc/403.gcc.test' has No metrics!; Tests: 508; Metric: exec_time. Program baseline. INT2006/456.hmmer/456.hmmer 1222.90; INT2006/464.h264ref/464.h264ref 928.70; ...; baseline; count 506.000000; mean 20.563098; std 111.423325; min 0.003400; 25% 0.011200; 50% 0.339450; 75% 4.067200; max 1222.896800; ```. - Show compile_time or text segment size metrics:. ```bash; % test-suite/utils/compare.py -m compile_time baseline.json; % test-suite/utils/compare.py -m size.__text baseline.json; ```. - Compare two result files and filter short running tests:. ```bash; % test-suite/utils/compare.py --filter-short ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:7440,Testability,test,test-suite,7440,"code size. - `TEST_SUITE_USE_PERF`. Use the `perf` tool for time measurement instead of the `timeit` tool that; comes with the test-suite. The `perf` is usually available on linux systems. - `TEST_SUITE_SPEC2000_ROOT`, `TEST_SUITE_SPEC2006_ROOT`, `TEST_SUITE_SPEC2017_ROOT`, ... Specify installation directories of external benchmark suites. You can find; more information about expected versions or usage in the README files in the; `External` directory (such as `External/SPEC/README`). ### Common CMake Flags. - `-GNinja`. Generate build files for the ninja build tool. - `-Ctest-suite/cmake/caches/<cachefile.cmake>`. Use a CMake cache. The test-suite comes with several CMake caches which; predefine common or tricky build configurations. Displaying and Analyzing Results; --------------------------------. The `compare.py` script displays and compares result files. A result file is; produced when invoking lit with the `-o filename.json` flag. Example usage:. - Basic Usage:. ```text; % test-suite/utils/compare.py baseline.json; Warning: 'test-suite :: External/SPEC/CINT2006/403.gcc/403.gcc.test' has No metrics!; Tests: 508; Metric: exec_time. Program baseline. INT2006/456.hmmer/456.hmmer 1222.90; INT2006/464.h264ref/464.h264ref 928.70; ...; baseline; count 506.000000; mean 20.563098; std 111.423325; min 0.003400; 25% 0.011200; 50% 0.339450; 75% 4.067200; max 1222.896800; ```. - Show compile_time or text segment size metrics:. ```bash; % test-suite/utils/compare.py -m compile_time baseline.json; % test-suite/utils/compare.py -m size.__text baseline.json; ```. - Compare two result files and filter short running tests:. ```bash; % test-suite/utils/compare.py --filter-short baseline.json experiment.json; ...; Program baseline experiment diff. SingleSour.../Benchmarks/Linpack/linpack-pc 5.16 4.30 -16.5%; MultiSourc...erolling-dbl/LoopRerolling-dbl 7.01 7.86 12.2%; SingleSour...UnitTests/Vectorizer/gcc-loops 3.89 3.54 -9.0%; ...; ```. - Merge multiple baseline and experiment resu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:7493,Testability,test,test-suite,7493," time measurement instead of the `timeit` tool that; comes with the test-suite. The `perf` is usually available on linux systems. - `TEST_SUITE_SPEC2000_ROOT`, `TEST_SUITE_SPEC2006_ROOT`, `TEST_SUITE_SPEC2017_ROOT`, ... Specify installation directories of external benchmark suites. You can find; more information about expected versions or usage in the README files in the; `External` directory (such as `External/SPEC/README`). ### Common CMake Flags. - `-GNinja`. Generate build files for the ninja build tool. - `-Ctest-suite/cmake/caches/<cachefile.cmake>`. Use a CMake cache. The test-suite comes with several CMake caches which; predefine common or tricky build configurations. Displaying and Analyzing Results; --------------------------------. The `compare.py` script displays and compares result files. A result file is; produced when invoking lit with the `-o filename.json` flag. Example usage:. - Basic Usage:. ```text; % test-suite/utils/compare.py baseline.json; Warning: 'test-suite :: External/SPEC/CINT2006/403.gcc/403.gcc.test' has No metrics!; Tests: 508; Metric: exec_time. Program baseline. INT2006/456.hmmer/456.hmmer 1222.90; INT2006/464.h264ref/464.h264ref 928.70; ...; baseline; count 506.000000; mean 20.563098; std 111.423325; min 0.003400; 25% 0.011200; 50% 0.339450; 75% 4.067200; max 1222.896800; ```. - Show compile_time or text segment size metrics:. ```bash; % test-suite/utils/compare.py -m compile_time baseline.json; % test-suite/utils/compare.py -m size.__text baseline.json; ```. - Compare two result files and filter short running tests:. ```bash; % test-suite/utils/compare.py --filter-short baseline.json experiment.json; ...; Program baseline experiment diff. SingleSour.../Benchmarks/Linpack/linpack-pc 5.16 4.30 -16.5%; MultiSourc...erolling-dbl/LoopRerolling-dbl 7.01 7.86 12.2%; SingleSour...UnitTests/Vectorizer/gcc-loops 3.89 3.54 -9.0%; ...; ```. - Merge multiple baseline and experiment result files by taking the minimum; runtime each:. ```bash; % t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:7546,Testability,test,test,7546," test-suite. The `perf` is usually available on linux systems. - `TEST_SUITE_SPEC2000_ROOT`, `TEST_SUITE_SPEC2006_ROOT`, `TEST_SUITE_SPEC2017_ROOT`, ... Specify installation directories of external benchmark suites. You can find; more information about expected versions or usage in the README files in the; `External` directory (such as `External/SPEC/README`). ### Common CMake Flags. - `-GNinja`. Generate build files for the ninja build tool. - `-Ctest-suite/cmake/caches/<cachefile.cmake>`. Use a CMake cache. The test-suite comes with several CMake caches which; predefine common or tricky build configurations. Displaying and Analyzing Results; --------------------------------. The `compare.py` script displays and compares result files. A result file is; produced when invoking lit with the `-o filename.json` flag. Example usage:. - Basic Usage:. ```text; % test-suite/utils/compare.py baseline.json; Warning: 'test-suite :: External/SPEC/CINT2006/403.gcc/403.gcc.test' has No metrics!; Tests: 508; Metric: exec_time. Program baseline. INT2006/456.hmmer/456.hmmer 1222.90; INT2006/464.h264ref/464.h264ref 928.70; ...; baseline; count 506.000000; mean 20.563098; std 111.423325; min 0.003400; 25% 0.011200; 50% 0.339450; 75% 4.067200; max 1222.896800; ```. - Show compile_time or text segment size metrics:. ```bash; % test-suite/utils/compare.py -m compile_time baseline.json; % test-suite/utils/compare.py -m size.__text baseline.json; ```. - Compare two result files and filter short running tests:. ```bash; % test-suite/utils/compare.py --filter-short baseline.json experiment.json; ...; Program baseline experiment diff. SingleSour.../Benchmarks/Linpack/linpack-pc 5.16 4.30 -16.5%; MultiSourc...erolling-dbl/LoopRerolling-dbl 7.01 7.86 12.2%; SingleSour...UnitTests/Vectorizer/gcc-loops 3.89 3.54 -9.0%; ...; ```. - Merge multiple baseline and experiment result files by taking the minimum; runtime each:. ```bash; % test-suite/utils/compare.py base0.json base1.json base2.json vs exp0",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:7900,Testability,test,test-suite,7900, as `External/SPEC/README`). ### Common CMake Flags. - `-GNinja`. Generate build files for the ninja build tool. - `-Ctest-suite/cmake/caches/<cachefile.cmake>`. Use a CMake cache. The test-suite comes with several CMake caches which; predefine common or tricky build configurations. Displaying and Analyzing Results; --------------------------------. The `compare.py` script displays and compares result files. A result file is; produced when invoking lit with the `-o filename.json` flag. Example usage:. - Basic Usage:. ```text; % test-suite/utils/compare.py baseline.json; Warning: 'test-suite :: External/SPEC/CINT2006/403.gcc/403.gcc.test' has No metrics!; Tests: 508; Metric: exec_time. Program baseline. INT2006/456.hmmer/456.hmmer 1222.90; INT2006/464.h264ref/464.h264ref 928.70; ...; baseline; count 506.000000; mean 20.563098; std 111.423325; min 0.003400; 25% 0.011200; 50% 0.339450; 75% 4.067200; max 1222.896800; ```. - Show compile_time or text segment size metrics:. ```bash; % test-suite/utils/compare.py -m compile_time baseline.json; % test-suite/utils/compare.py -m size.__text baseline.json; ```. - Compare two result files and filter short running tests:. ```bash; % test-suite/utils/compare.py --filter-short baseline.json experiment.json; ...; Program baseline experiment diff. SingleSour.../Benchmarks/Linpack/linpack-pc 5.16 4.30 -16.5%; MultiSourc...erolling-dbl/LoopRerolling-dbl 7.01 7.86 12.2%; SingleSour...UnitTests/Vectorizer/gcc-loops 3.89 3.54 -9.0%; ...; ```. - Merge multiple baseline and experiment result files by taking the minimum; runtime each:. ```bash; % test-suite/utils/compare.py base0.json base1.json base2.json vs exp0.json exp1.json exp2.json; ```. ### Continuous Tracking with LNT. LNT is a set of client and server tools for continuously monitoring; performance. You can find more information at; [https://llvm.org/docs/lnt](https://llvm.org/docs/lnt). The official LNT instance; of the LLVM project is hosted at [http://lnt.llvm.org](http://lnt.llv,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:7961,Testability,test,test-suite,7961,`. Generate build files for the ninja build tool. - `-Ctest-suite/cmake/caches/<cachefile.cmake>`. Use a CMake cache. The test-suite comes with several CMake caches which; predefine common or tricky build configurations. Displaying and Analyzing Results; --------------------------------. The `compare.py` script displays and compares result files. A result file is; produced when invoking lit with the `-o filename.json` flag. Example usage:. - Basic Usage:. ```text; % test-suite/utils/compare.py baseline.json; Warning: 'test-suite :: External/SPEC/CINT2006/403.gcc/403.gcc.test' has No metrics!; Tests: 508; Metric: exec_time. Program baseline. INT2006/456.hmmer/456.hmmer 1222.90; INT2006/464.h264ref/464.h264ref 928.70; ...; baseline; count 506.000000; mean 20.563098; std 111.423325; min 0.003400; 25% 0.011200; 50% 0.339450; 75% 4.067200; max 1222.896800; ```. - Show compile_time or text segment size metrics:. ```bash; % test-suite/utils/compare.py -m compile_time baseline.json; % test-suite/utils/compare.py -m size.__text baseline.json; ```. - Compare two result files and filter short running tests:. ```bash; % test-suite/utils/compare.py --filter-short baseline.json experiment.json; ...; Program baseline experiment diff. SingleSour.../Benchmarks/Linpack/linpack-pc 5.16 4.30 -16.5%; MultiSourc...erolling-dbl/LoopRerolling-dbl 7.01 7.86 12.2%; SingleSour...UnitTests/Vectorizer/gcc-loops 3.89 3.54 -9.0%; ...; ```. - Merge multiple baseline and experiment result files by taking the minimum; runtime each:. ```bash; % test-suite/utils/compare.py base0.json base1.json base2.json vs exp0.json exp1.json exp2.json; ```. ### Continuous Tracking with LNT. LNT is a set of client and server tools for continuously monitoring; performance. You can find more information at; [https://llvm.org/docs/lnt](https://llvm.org/docs/lnt). The official LNT instance; of the LLVM project is hosted at [http://lnt.llvm.org](http://lnt.llvm.org). External Suites; ---------------. External suites such ,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:8076,Testability,test,tests,8076,efile.cmake>`. Use a CMake cache. The test-suite comes with several CMake caches which; predefine common or tricky build configurations. Displaying and Analyzing Results; --------------------------------. The `compare.py` script displays and compares result files. A result file is; produced when invoking lit with the `-o filename.json` flag. Example usage:. - Basic Usage:. ```text; % test-suite/utils/compare.py baseline.json; Warning: 'test-suite :: External/SPEC/CINT2006/403.gcc/403.gcc.test' has No metrics!; Tests: 508; Metric: exec_time. Program baseline. INT2006/456.hmmer/456.hmmer 1222.90; INT2006/464.h264ref/464.h264ref 928.70; ...; baseline; count 506.000000; mean 20.563098; std 111.423325; min 0.003400; 25% 0.011200; 50% 0.339450; 75% 4.067200; max 1222.896800; ```. - Show compile_time or text segment size metrics:. ```bash; % test-suite/utils/compare.py -m compile_time baseline.json; % test-suite/utils/compare.py -m size.__text baseline.json; ```. - Compare two result files and filter short running tests:. ```bash; % test-suite/utils/compare.py --filter-short baseline.json experiment.json; ...; Program baseline experiment diff. SingleSour.../Benchmarks/Linpack/linpack-pc 5.16 4.30 -16.5%; MultiSourc...erolling-dbl/LoopRerolling-dbl 7.01 7.86 12.2%; SingleSour...UnitTests/Vectorizer/gcc-loops 3.89 3.54 -9.0%; ...; ```. - Merge multiple baseline and experiment result files by taking the minimum; runtime each:. ```bash; % test-suite/utils/compare.py base0.json base1.json base2.json vs exp0.json exp1.json exp2.json; ```. ### Continuous Tracking with LNT. LNT is a set of client and server tools for continuously monitoring; performance. You can find more information at; [https://llvm.org/docs/lnt](https://llvm.org/docs/lnt). The official LNT instance; of the LLVM project is hosted at [http://lnt.llvm.org](http://lnt.llvm.org). External Suites; ---------------. External suites such as SPEC can be enabled by either. - placing (or linking) them into the `test-suite/,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:8095,Testability,test,test-suite,8095, comes with several CMake caches which; predefine common or tricky build configurations. Displaying and Analyzing Results; --------------------------------. The `compare.py` script displays and compares result files. A result file is; produced when invoking lit with the `-o filename.json` flag. Example usage:. - Basic Usage:. ```text; % test-suite/utils/compare.py baseline.json; Warning: 'test-suite :: External/SPEC/CINT2006/403.gcc/403.gcc.test' has No metrics!; Tests: 508; Metric: exec_time. Program baseline. INT2006/456.hmmer/456.hmmer 1222.90; INT2006/464.h264ref/464.h264ref 928.70; ...; baseline; count 506.000000; mean 20.563098; std 111.423325; min 0.003400; 25% 0.011200; 50% 0.339450; 75% 4.067200; max 1222.896800; ```. - Show compile_time or text segment size metrics:. ```bash; % test-suite/utils/compare.py -m compile_time baseline.json; % test-suite/utils/compare.py -m size.__text baseline.json; ```. - Compare two result files and filter short running tests:. ```bash; % test-suite/utils/compare.py --filter-short baseline.json experiment.json; ...; Program baseline experiment diff. SingleSour.../Benchmarks/Linpack/linpack-pc 5.16 4.30 -16.5%; MultiSourc...erolling-dbl/LoopRerolling-dbl 7.01 7.86 12.2%; SingleSour...UnitTests/Vectorizer/gcc-loops 3.89 3.54 -9.0%; ...; ```. - Merge multiple baseline and experiment result files by taking the minimum; runtime each:. ```bash; % test-suite/utils/compare.py base0.json base1.json base2.json vs exp0.json exp1.json exp2.json; ```. ### Continuous Tracking with LNT. LNT is a set of client and server tools for continuously monitoring; performance. You can find more information at; [https://llvm.org/docs/lnt](https://llvm.org/docs/lnt). The official LNT instance; of the LLVM project is hosted at [http://lnt.llvm.org](http://lnt.llvm.org). External Suites; ---------------. External suites such as SPEC can be enabled by either. - placing (or linking) them into the `test-suite/test-suite-externals/xxx` directory (example: `te,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:8505,Testability,test,test-suite,8505,"rnal/SPEC/CINT2006/403.gcc/403.gcc.test' has No metrics!; Tests: 508; Metric: exec_time. Program baseline. INT2006/456.hmmer/456.hmmer 1222.90; INT2006/464.h264ref/464.h264ref 928.70; ...; baseline; count 506.000000; mean 20.563098; std 111.423325; min 0.003400; 25% 0.011200; 50% 0.339450; 75% 4.067200; max 1222.896800; ```. - Show compile_time or text segment size metrics:. ```bash; % test-suite/utils/compare.py -m compile_time baseline.json; % test-suite/utils/compare.py -m size.__text baseline.json; ```. - Compare two result files and filter short running tests:. ```bash; % test-suite/utils/compare.py --filter-short baseline.json experiment.json; ...; Program baseline experiment diff. SingleSour.../Benchmarks/Linpack/linpack-pc 5.16 4.30 -16.5%; MultiSourc...erolling-dbl/LoopRerolling-dbl 7.01 7.86 12.2%; SingleSour...UnitTests/Vectorizer/gcc-loops 3.89 3.54 -9.0%; ...; ```. - Merge multiple baseline and experiment result files by taking the minimum; runtime each:. ```bash; % test-suite/utils/compare.py base0.json base1.json base2.json vs exp0.json exp1.json exp2.json; ```. ### Continuous Tracking with LNT. LNT is a set of client and server tools for continuously monitoring; performance. You can find more information at; [https://llvm.org/docs/lnt](https://llvm.org/docs/lnt). The official LNT instance; of the LLVM project is hosted at [http://lnt.llvm.org](http://lnt.llvm.org). External Suites; ---------------. External suites such as SPEC can be enabled by either. - placing (or linking) them into the `test-suite/test-suite-externals/xxx` directory (example: `test-suite/test-suite-externals/speccpu2000`); - using a configuration option such as `-D TEST_SUITE_SPEC2000_ROOT=path/to/speccpu2000`. You can find further information in the respective README files such as; `test-suite/External/SPEC/README`. For the SPEC benchmarks you can switch between the `test`, `train` and; `ref` input datasets via the `TEST_SUITE_RUN_TYPE` configuration option.; The `train` dataset i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:9042,Testability,test,test-suite,9042,".py --filter-short baseline.json experiment.json; ...; Program baseline experiment diff. SingleSour.../Benchmarks/Linpack/linpack-pc 5.16 4.30 -16.5%; MultiSourc...erolling-dbl/LoopRerolling-dbl 7.01 7.86 12.2%; SingleSour...UnitTests/Vectorizer/gcc-loops 3.89 3.54 -9.0%; ...; ```. - Merge multiple baseline and experiment result files by taking the minimum; runtime each:. ```bash; % test-suite/utils/compare.py base0.json base1.json base2.json vs exp0.json exp1.json exp2.json; ```. ### Continuous Tracking with LNT. LNT is a set of client and server tools for continuously monitoring; performance. You can find more information at; [https://llvm.org/docs/lnt](https://llvm.org/docs/lnt). The official LNT instance; of the LLVM project is hosted at [http://lnt.llvm.org](http://lnt.llvm.org). External Suites; ---------------. External suites such as SPEC can be enabled by either. - placing (or linking) them into the `test-suite/test-suite-externals/xxx` directory (example: `test-suite/test-suite-externals/speccpu2000`); - using a configuration option such as `-D TEST_SUITE_SPEC2000_ROOT=path/to/speccpu2000`. You can find further information in the respective README files such as; `test-suite/External/SPEC/README`. For the SPEC benchmarks you can switch between the `test`, `train` and; `ref` input datasets via the `TEST_SUITE_RUN_TYPE` configuration option.; The `train` dataset is used by default. Custom Suites; -------------. You can build custom suites using the test-suite infrastructure. A custom suite; has a `CMakeLists.txt` file at the top directory. The `CMakeLists.txt` will be; picked up automatically if placed into a subdirectory of the test-suite or when; setting the `TEST_SUITE_SUBDIRS` variable:. ```bash; % cmake -DTEST_SUITE_SUBDIRS=path/to/my/benchmark-suite ../test-suite; ```. Profile Guided Optimization; ---------------------------. Profile guided optimization requires to compile and run twice. First the; benchmark should be compiled with profile generation ins",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:9053,Testability,test,test-suite-externals,9053,".py --filter-short baseline.json experiment.json; ...; Program baseline experiment diff. SingleSour.../Benchmarks/Linpack/linpack-pc 5.16 4.30 -16.5%; MultiSourc...erolling-dbl/LoopRerolling-dbl 7.01 7.86 12.2%; SingleSour...UnitTests/Vectorizer/gcc-loops 3.89 3.54 -9.0%; ...; ```. - Merge multiple baseline and experiment result files by taking the minimum; runtime each:. ```bash; % test-suite/utils/compare.py base0.json base1.json base2.json vs exp0.json exp1.json exp2.json; ```. ### Continuous Tracking with LNT. LNT is a set of client and server tools for continuously monitoring; performance. You can find more information at; [https://llvm.org/docs/lnt](https://llvm.org/docs/lnt). The official LNT instance; of the LLVM project is hosted at [http://lnt.llvm.org](http://lnt.llvm.org). External Suites; ---------------. External suites such as SPEC can be enabled by either. - placing (or linking) them into the `test-suite/test-suite-externals/xxx` directory (example: `test-suite/test-suite-externals/speccpu2000`); - using a configuration option such as `-D TEST_SUITE_SPEC2000_ROOT=path/to/speccpu2000`. You can find further information in the respective README files such as; `test-suite/External/SPEC/README`. For the SPEC benchmarks you can switch between the `test`, `train` and; `ref` input datasets via the `TEST_SUITE_RUN_TYPE` configuration option.; The `train` dataset is used by default. Custom Suites; -------------. You can build custom suites using the test-suite infrastructure. A custom suite; has a `CMakeLists.txt` file at the top directory. The `CMakeLists.txt` will be; picked up automatically if placed into a subdirectory of the test-suite or when; setting the `TEST_SUITE_SUBDIRS` variable:. ```bash; % cmake -DTEST_SUITE_SUBDIRS=path/to/my/benchmark-suite ../test-suite; ```. Profile Guided Optimization; ---------------------------. Profile guided optimization requires to compile and run twice. First the; benchmark should be compiled with profile generation ins",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:9100,Testability,test,test-suite,9100,".py --filter-short baseline.json experiment.json; ...; Program baseline experiment diff. SingleSour.../Benchmarks/Linpack/linpack-pc 5.16 4.30 -16.5%; MultiSourc...erolling-dbl/LoopRerolling-dbl 7.01 7.86 12.2%; SingleSour...UnitTests/Vectorizer/gcc-loops 3.89 3.54 -9.0%; ...; ```. - Merge multiple baseline and experiment result files by taking the minimum; runtime each:. ```bash; % test-suite/utils/compare.py base0.json base1.json base2.json vs exp0.json exp1.json exp2.json; ```. ### Continuous Tracking with LNT. LNT is a set of client and server tools for continuously monitoring; performance. You can find more information at; [https://llvm.org/docs/lnt](https://llvm.org/docs/lnt). The official LNT instance; of the LLVM project is hosted at [http://lnt.llvm.org](http://lnt.llvm.org). External Suites; ---------------. External suites such as SPEC can be enabled by either. - placing (or linking) them into the `test-suite/test-suite-externals/xxx` directory (example: `test-suite/test-suite-externals/speccpu2000`); - using a configuration option such as `-D TEST_SUITE_SPEC2000_ROOT=path/to/speccpu2000`. You can find further information in the respective README files such as; `test-suite/External/SPEC/README`. For the SPEC benchmarks you can switch between the `test`, `train` and; `ref` input datasets via the `TEST_SUITE_RUN_TYPE` configuration option.; The `train` dataset is used by default. Custom Suites; -------------. You can build custom suites using the test-suite infrastructure. A custom suite; has a `CMakeLists.txt` file at the top directory. The `CMakeLists.txt` will be; picked up automatically if placed into a subdirectory of the test-suite or when; setting the `TEST_SUITE_SUBDIRS` variable:. ```bash; % cmake -DTEST_SUITE_SUBDIRS=path/to/my/benchmark-suite ../test-suite; ```. Profile Guided Optimization; ---------------------------. Profile guided optimization requires to compile and run twice. First the; benchmark should be compiled with profile generation ins",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:9111,Testability,test,test-suite-externals,9111,".py --filter-short baseline.json experiment.json; ...; Program baseline experiment diff. SingleSour.../Benchmarks/Linpack/linpack-pc 5.16 4.30 -16.5%; MultiSourc...erolling-dbl/LoopRerolling-dbl 7.01 7.86 12.2%; SingleSour...UnitTests/Vectorizer/gcc-loops 3.89 3.54 -9.0%; ...; ```. - Merge multiple baseline and experiment result files by taking the minimum; runtime each:. ```bash; % test-suite/utils/compare.py base0.json base1.json base2.json vs exp0.json exp1.json exp2.json; ```. ### Continuous Tracking with LNT. LNT is a set of client and server tools for continuously monitoring; performance. You can find more information at; [https://llvm.org/docs/lnt](https://llvm.org/docs/lnt). The official LNT instance; of the LLVM project is hosted at [http://lnt.llvm.org](http://lnt.llvm.org). External Suites; ---------------. External suites such as SPEC can be enabled by either. - placing (or linking) them into the `test-suite/test-suite-externals/xxx` directory (example: `test-suite/test-suite-externals/speccpu2000`); - using a configuration option such as `-D TEST_SUITE_SPEC2000_ROOT=path/to/speccpu2000`. You can find further information in the respective README files such as; `test-suite/External/SPEC/README`. For the SPEC benchmarks you can switch between the `test`, `train` and; `ref` input datasets via the `TEST_SUITE_RUN_TYPE` configuration option.; The `train` dataset is used by default. Custom Suites; -------------. You can build custom suites using the test-suite infrastructure. A custom suite; has a `CMakeLists.txt` file at the top directory. The `CMakeLists.txt` will be; picked up automatically if placed into a subdirectory of the test-suite or when; setting the `TEST_SUITE_SUBDIRS` variable:. ```bash; % cmake -DTEST_SUITE_SUBDIRS=path/to/my/benchmark-suite ../test-suite; ```. Profile Guided Optimization; ---------------------------. Profile guided optimization requires to compile and run twice. First the; benchmark should be compiled with profile generation ins",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:9311,Testability,test,test-suite,9311,"g-dbl/LoopRerolling-dbl 7.01 7.86 12.2%; SingleSour...UnitTests/Vectorizer/gcc-loops 3.89 3.54 -9.0%; ...; ```. - Merge multiple baseline and experiment result files by taking the minimum; runtime each:. ```bash; % test-suite/utils/compare.py base0.json base1.json base2.json vs exp0.json exp1.json exp2.json; ```. ### Continuous Tracking with LNT. LNT is a set of client and server tools for continuously monitoring; performance. You can find more information at; [https://llvm.org/docs/lnt](https://llvm.org/docs/lnt). The official LNT instance; of the LLVM project is hosted at [http://lnt.llvm.org](http://lnt.llvm.org). External Suites; ---------------. External suites such as SPEC can be enabled by either. - placing (or linking) them into the `test-suite/test-suite-externals/xxx` directory (example: `test-suite/test-suite-externals/speccpu2000`); - using a configuration option such as `-D TEST_SUITE_SPEC2000_ROOT=path/to/speccpu2000`. You can find further information in the respective README files such as; `test-suite/External/SPEC/README`. For the SPEC benchmarks you can switch between the `test`, `train` and; `ref` input datasets via the `TEST_SUITE_RUN_TYPE` configuration option.; The `train` dataset is used by default. Custom Suites; -------------. You can build custom suites using the test-suite infrastructure. A custom suite; has a `CMakeLists.txt` file at the top directory. The `CMakeLists.txt` will be; picked up automatically if placed into a subdirectory of the test-suite or when; setting the `TEST_SUITE_SUBDIRS` variable:. ```bash; % cmake -DTEST_SUITE_SUBDIRS=path/to/my/benchmark-suite ../test-suite; ```. Profile Guided Optimization; ---------------------------. Profile guided optimization requires to compile and run twice. First the; benchmark should be compiled with profile generation instrumentation enabled; and setup for training data. The lit runner will merge the profile files; using `llvm-profdata` so they can be used by the second compilation run. E",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:9358,Testability,benchmark,benchmarks,9358,"le baseline and experiment result files by taking the minimum; runtime each:. ```bash; % test-suite/utils/compare.py base0.json base1.json base2.json vs exp0.json exp1.json exp2.json; ```. ### Continuous Tracking with LNT. LNT is a set of client and server tools for continuously monitoring; performance. You can find more information at; [https://llvm.org/docs/lnt](https://llvm.org/docs/lnt). The official LNT instance; of the LLVM project is hosted at [http://lnt.llvm.org](http://lnt.llvm.org). External Suites; ---------------. External suites such as SPEC can be enabled by either. - placing (or linking) them into the `test-suite/test-suite-externals/xxx` directory (example: `test-suite/test-suite-externals/speccpu2000`); - using a configuration option such as `-D TEST_SUITE_SPEC2000_ROOT=path/to/speccpu2000`. You can find further information in the respective README files such as; `test-suite/External/SPEC/README`. For the SPEC benchmarks you can switch between the `test`, `train` and; `ref` input datasets via the `TEST_SUITE_RUN_TYPE` configuration option.; The `train` dataset is used by default. Custom Suites; -------------. You can build custom suites using the test-suite infrastructure. A custom suite; has a `CMakeLists.txt` file at the top directory. The `CMakeLists.txt` will be; picked up automatically if placed into a subdirectory of the test-suite or when; setting the `TEST_SUITE_SUBDIRS` variable:. ```bash; % cmake -DTEST_SUITE_SUBDIRS=path/to/my/benchmark-suite ../test-suite; ```. Profile Guided Optimization; ---------------------------. Profile guided optimization requires to compile and run twice. First the; benchmark should be compiled with profile generation instrumentation enabled; and setup for training data. The lit runner will merge the profile files; using `llvm-profdata` so they can be used by the second compilation run. Example:; ```bash; # Profile generation run using LLVM IR PGO:; % cmake -DTEST_SUITE_PROFILE_GENERATE=ON \; -DTEST_SUITE_USE_IR_",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:9397,Testability,test,test,9397,"le baseline and experiment result files by taking the minimum; runtime each:. ```bash; % test-suite/utils/compare.py base0.json base1.json base2.json vs exp0.json exp1.json exp2.json; ```. ### Continuous Tracking with LNT. LNT is a set of client and server tools for continuously monitoring; performance. You can find more information at; [https://llvm.org/docs/lnt](https://llvm.org/docs/lnt). The official LNT instance; of the LLVM project is hosted at [http://lnt.llvm.org](http://lnt.llvm.org). External Suites; ---------------. External suites such as SPEC can be enabled by either. - placing (or linking) them into the `test-suite/test-suite-externals/xxx` directory (example: `test-suite/test-suite-externals/speccpu2000`); - using a configuration option such as `-D TEST_SUITE_SPEC2000_ROOT=path/to/speccpu2000`. You can find further information in the respective README files such as; `test-suite/External/SPEC/README`. For the SPEC benchmarks you can switch between the `test`, `train` and; `ref` input datasets via the `TEST_SUITE_RUN_TYPE` configuration option.; The `train` dataset is used by default. Custom Suites; -------------. You can build custom suites using the test-suite infrastructure. A custom suite; has a `CMakeLists.txt` file at the top directory. The `CMakeLists.txt` will be; picked up automatically if placed into a subdirectory of the test-suite or when; setting the `TEST_SUITE_SUBDIRS` variable:. ```bash; % cmake -DTEST_SUITE_SUBDIRS=path/to/my/benchmark-suite ../test-suite; ```. Profile Guided Optimization; ---------------------------. Profile guided optimization requires to compile and run twice. First the; benchmark should be compiled with profile generation instrumentation enabled; and setup for training data. The lit runner will merge the profile files; using `llvm-profdata` so they can be used by the second compilation run. Example:; ```bash; # Profile generation run using LLVM IR PGO:; % cmake -DTEST_SUITE_PROFILE_GENERATE=ON \; -DTEST_SUITE_USE_IR_",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:9599,Testability,test,test-suite,9599,"2.json; ```. ### Continuous Tracking with LNT. LNT is a set of client and server tools for continuously monitoring; performance. You can find more information at; [https://llvm.org/docs/lnt](https://llvm.org/docs/lnt). The official LNT instance; of the LLVM project is hosted at [http://lnt.llvm.org](http://lnt.llvm.org). External Suites; ---------------. External suites such as SPEC can be enabled by either. - placing (or linking) them into the `test-suite/test-suite-externals/xxx` directory (example: `test-suite/test-suite-externals/speccpu2000`); - using a configuration option such as `-D TEST_SUITE_SPEC2000_ROOT=path/to/speccpu2000`. You can find further information in the respective README files such as; `test-suite/External/SPEC/README`. For the SPEC benchmarks you can switch between the `test`, `train` and; `ref` input datasets via the `TEST_SUITE_RUN_TYPE` configuration option.; The `train` dataset is used by default. Custom Suites; -------------. You can build custom suites using the test-suite infrastructure. A custom suite; has a `CMakeLists.txt` file at the top directory. The `CMakeLists.txt` will be; picked up automatically if placed into a subdirectory of the test-suite or when; setting the `TEST_SUITE_SUBDIRS` variable:. ```bash; % cmake -DTEST_SUITE_SUBDIRS=path/to/my/benchmark-suite ../test-suite; ```. Profile Guided Optimization; ---------------------------. Profile guided optimization requires to compile and run twice. First the; benchmark should be compiled with profile generation instrumentation enabled; and setup for training data. The lit runner will merge the profile files; using `llvm-profdata` so they can be used by the second compilation run. Example:; ```bash; # Profile generation run using LLVM IR PGO:; % cmake -DTEST_SUITE_PROFILE_GENERATE=ON \; -DTEST_SUITE_USE_IR_PGO=ON \; -DTEST_SUITE_RUN_TYPE=train \; ../test-suite; % make; % llvm-lit .; # Use the profile data for compilation and actual benchmark run:; % cmake -DTEST_SUITE_PROFILE_GEN",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:9783,Testability,test,test-suite,9783,"/lnt](https://llvm.org/docs/lnt). The official LNT instance; of the LLVM project is hosted at [http://lnt.llvm.org](http://lnt.llvm.org). External Suites; ---------------. External suites such as SPEC can be enabled by either. - placing (or linking) them into the `test-suite/test-suite-externals/xxx` directory (example: `test-suite/test-suite-externals/speccpu2000`); - using a configuration option such as `-D TEST_SUITE_SPEC2000_ROOT=path/to/speccpu2000`. You can find further information in the respective README files such as; `test-suite/External/SPEC/README`. For the SPEC benchmarks you can switch between the `test`, `train` and; `ref` input datasets via the `TEST_SUITE_RUN_TYPE` configuration option.; The `train` dataset is used by default. Custom Suites; -------------. You can build custom suites using the test-suite infrastructure. A custom suite; has a `CMakeLists.txt` file at the top directory. The `CMakeLists.txt` will be; picked up automatically if placed into a subdirectory of the test-suite or when; setting the `TEST_SUITE_SUBDIRS` variable:. ```bash; % cmake -DTEST_SUITE_SUBDIRS=path/to/my/benchmark-suite ../test-suite; ```. Profile Guided Optimization; ---------------------------. Profile guided optimization requires to compile and run twice. First the; benchmark should be compiled with profile generation instrumentation enabled; and setup for training data. The lit runner will merge the profile files; using `llvm-profdata` so they can be used by the second compilation run. Example:; ```bash; # Profile generation run using LLVM IR PGO:; % cmake -DTEST_SUITE_PROFILE_GENERATE=ON \; -DTEST_SUITE_USE_IR_PGO=ON \; -DTEST_SUITE_RUN_TYPE=train \; ../test-suite; % make; % llvm-lit .; # Use the profile data for compilation and actual benchmark run:; % cmake -DTEST_SUITE_PROFILE_GENERATE=OFF \; -DTEST_SUITE_PROFILE_USE=ON \; -DTEST_SUITE_RUN_TYPE=ref \; .; % make; % llvm-lit -o result.json .; ```. To use Clang frontend's PGO instead of LLVM IR PGO, set `-DTEST_SU",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:9896,Testability,benchmark,benchmark-suite,9896,"lnt.llvm.org](http://lnt.llvm.org). External Suites; ---------------. External suites such as SPEC can be enabled by either. - placing (or linking) them into the `test-suite/test-suite-externals/xxx` directory (example: `test-suite/test-suite-externals/speccpu2000`); - using a configuration option such as `-D TEST_SUITE_SPEC2000_ROOT=path/to/speccpu2000`. You can find further information in the respective README files such as; `test-suite/External/SPEC/README`. For the SPEC benchmarks you can switch between the `test`, `train` and; `ref` input datasets via the `TEST_SUITE_RUN_TYPE` configuration option.; The `train` dataset is used by default. Custom Suites; -------------. You can build custom suites using the test-suite infrastructure. A custom suite; has a `CMakeLists.txt` file at the top directory. The `CMakeLists.txt` will be; picked up automatically if placed into a subdirectory of the test-suite or when; setting the `TEST_SUITE_SUBDIRS` variable:. ```bash; % cmake -DTEST_SUITE_SUBDIRS=path/to/my/benchmark-suite ../test-suite; ```. Profile Guided Optimization; ---------------------------. Profile guided optimization requires to compile and run twice. First the; benchmark should be compiled with profile generation instrumentation enabled; and setup for training data. The lit runner will merge the profile files; using `llvm-profdata` so they can be used by the second compilation run. Example:; ```bash; # Profile generation run using LLVM IR PGO:; % cmake -DTEST_SUITE_PROFILE_GENERATE=ON \; -DTEST_SUITE_USE_IR_PGO=ON \; -DTEST_SUITE_RUN_TYPE=train \; ../test-suite; % make; % llvm-lit .; # Use the profile data for compilation and actual benchmark run:; % cmake -DTEST_SUITE_PROFILE_GENERATE=OFF \; -DTEST_SUITE_PROFILE_USE=ON \; -DTEST_SUITE_RUN_TYPE=ref \; .; % make; % llvm-lit -o result.json .; ```. To use Clang frontend's PGO instead of LLVM IR PGO, set `-DTEST_SUITE_USE_IR_PGO=OFF`. The `TEST_SUITE_RUN_TYPE` setting only affects the SPEC benchmark suites. Cross Co",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:9915,Testability,test,test-suite,9915,"l Suites; ---------------. External suites such as SPEC can be enabled by either. - placing (or linking) them into the `test-suite/test-suite-externals/xxx` directory (example: `test-suite/test-suite-externals/speccpu2000`); - using a configuration option such as `-D TEST_SUITE_SPEC2000_ROOT=path/to/speccpu2000`. You can find further information in the respective README files such as; `test-suite/External/SPEC/README`. For the SPEC benchmarks you can switch between the `test`, `train` and; `ref` input datasets via the `TEST_SUITE_RUN_TYPE` configuration option.; The `train` dataset is used by default. Custom Suites; -------------. You can build custom suites using the test-suite infrastructure. A custom suite; has a `CMakeLists.txt` file at the top directory. The `CMakeLists.txt` will be; picked up automatically if placed into a subdirectory of the test-suite or when; setting the `TEST_SUITE_SUBDIRS` variable:. ```bash; % cmake -DTEST_SUITE_SUBDIRS=path/to/my/benchmark-suite ../test-suite; ```. Profile Guided Optimization; ---------------------------. Profile guided optimization requires to compile and run twice. First the; benchmark should be compiled with profile generation instrumentation enabled; and setup for training data. The lit runner will merge the profile files; using `llvm-profdata` so they can be used by the second compilation run. Example:; ```bash; # Profile generation run using LLVM IR PGO:; % cmake -DTEST_SUITE_PROFILE_GENERATE=ON \; -DTEST_SUITE_USE_IR_PGO=ON \; -DTEST_SUITE_RUN_TYPE=train \; ../test-suite; % make; % llvm-lit .; # Use the profile data for compilation and actual benchmark run:; % cmake -DTEST_SUITE_PROFILE_GENERATE=OFF \; -DTEST_SUITE_PROFILE_USE=ON \; -DTEST_SUITE_RUN_TYPE=ref \; .; % make; % llvm-lit -o result.json .; ```. To use Clang frontend's PGO instead of LLVM IR PGO, set `-DTEST_SUITE_USE_IR_PGO=OFF`. The `TEST_SUITE_RUN_TYPE` setting only affects the SPEC benchmark suites. Cross Compilation and External Devices; -----------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:10064,Testability,benchmark,benchmark,10064,"test-suite-externals/speccpu2000`); - using a configuration option such as `-D TEST_SUITE_SPEC2000_ROOT=path/to/speccpu2000`. You can find further information in the respective README files such as; `test-suite/External/SPEC/README`. For the SPEC benchmarks you can switch between the `test`, `train` and; `ref` input datasets via the `TEST_SUITE_RUN_TYPE` configuration option.; The `train` dataset is used by default. Custom Suites; -------------. You can build custom suites using the test-suite infrastructure. A custom suite; has a `CMakeLists.txt` file at the top directory. The `CMakeLists.txt` will be; picked up automatically if placed into a subdirectory of the test-suite or when; setting the `TEST_SUITE_SUBDIRS` variable:. ```bash; % cmake -DTEST_SUITE_SUBDIRS=path/to/my/benchmark-suite ../test-suite; ```. Profile Guided Optimization; ---------------------------. Profile guided optimization requires to compile and run twice. First the; benchmark should be compiled with profile generation instrumentation enabled; and setup for training data. The lit runner will merge the profile files; using `llvm-profdata` so they can be used by the second compilation run. Example:; ```bash; # Profile generation run using LLVM IR PGO:; % cmake -DTEST_SUITE_PROFILE_GENERATE=ON \; -DTEST_SUITE_USE_IR_PGO=ON \; -DTEST_SUITE_RUN_TYPE=train \; ../test-suite; % make; % llvm-lit .; # Use the profile data for compilation and actual benchmark run:; % cmake -DTEST_SUITE_PROFILE_GENERATE=OFF \; -DTEST_SUITE_PROFILE_USE=ON \; -DTEST_SUITE_RUN_TYPE=ref \; .; % make; % llvm-lit -o result.json .; ```. To use Clang frontend's PGO instead of LLVM IR PGO, set `-DTEST_SUITE_USE_IR_PGO=OFF`. The `TEST_SUITE_RUN_TYPE` setting only affects the SPEC benchmark suites. Cross Compilation and External Devices; --------------------------------------. ### Compilation. CMake allows to cross compile to a different target via toolchain files. More; information can be found here:. - [https://llvm.org/docs/lnt/te",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:10461,Testability,test,test-suite,10461,"ation option.; The `train` dataset is used by default. Custom Suites; -------------. You can build custom suites using the test-suite infrastructure. A custom suite; has a `CMakeLists.txt` file at the top directory. The `CMakeLists.txt` will be; picked up automatically if placed into a subdirectory of the test-suite or when; setting the `TEST_SUITE_SUBDIRS` variable:. ```bash; % cmake -DTEST_SUITE_SUBDIRS=path/to/my/benchmark-suite ../test-suite; ```. Profile Guided Optimization; ---------------------------. Profile guided optimization requires to compile and run twice. First the; benchmark should be compiled with profile generation instrumentation enabled; and setup for training data. The lit runner will merge the profile files; using `llvm-profdata` so they can be used by the second compilation run. Example:; ```bash; # Profile generation run using LLVM IR PGO:; % cmake -DTEST_SUITE_PROFILE_GENERATE=ON \; -DTEST_SUITE_USE_IR_PGO=ON \; -DTEST_SUITE_RUN_TYPE=train \; ../test-suite; % make; % llvm-lit .; # Use the profile data for compilation and actual benchmark run:; % cmake -DTEST_SUITE_PROFILE_GENERATE=OFF \; -DTEST_SUITE_PROFILE_USE=ON \; -DTEST_SUITE_RUN_TYPE=ref \; .; % make; % llvm-lit -o result.json .; ```. To use Clang frontend's PGO instead of LLVM IR PGO, set `-DTEST_SUITE_USE_IR_PGO=OFF`. The `TEST_SUITE_RUN_TYPE` setting only affects the SPEC benchmark suites. Cross Compilation and External Devices; --------------------------------------. ### Compilation. CMake allows to cross compile to a different target via toolchain files. More; information can be found here:. - [https://llvm.org/docs/lnt/tests.html#cross-compiling](https://llvm.org/docs/lnt/tests.html#cross-compiling). - [https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html](https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html). Cross compilation from macOS to iOS is possible with the; `test-suite/cmake/caches/target-target-*-iphoneos-internal.cmake` CMake cache; files; t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:10545,Testability,benchmark,benchmark,10545,"m suites using the test-suite infrastructure. A custom suite; has a `CMakeLists.txt` file at the top directory. The `CMakeLists.txt` will be; picked up automatically if placed into a subdirectory of the test-suite or when; setting the `TEST_SUITE_SUBDIRS` variable:. ```bash; % cmake -DTEST_SUITE_SUBDIRS=path/to/my/benchmark-suite ../test-suite; ```. Profile Guided Optimization; ---------------------------. Profile guided optimization requires to compile and run twice. First the; benchmark should be compiled with profile generation instrumentation enabled; and setup for training data. The lit runner will merge the profile files; using `llvm-profdata` so they can be used by the second compilation run. Example:; ```bash; # Profile generation run using LLVM IR PGO:; % cmake -DTEST_SUITE_PROFILE_GENERATE=ON \; -DTEST_SUITE_USE_IR_PGO=ON \; -DTEST_SUITE_RUN_TYPE=train \; ../test-suite; % make; % llvm-lit .; # Use the profile data for compilation and actual benchmark run:; % cmake -DTEST_SUITE_PROFILE_GENERATE=OFF \; -DTEST_SUITE_PROFILE_USE=ON \; -DTEST_SUITE_RUN_TYPE=ref \; .; % make; % llvm-lit -o result.json .; ```. To use Clang frontend's PGO instead of LLVM IR PGO, set `-DTEST_SUITE_USE_IR_PGO=OFF`. The `TEST_SUITE_RUN_TYPE` setting only affects the SPEC benchmark suites. Cross Compilation and External Devices; --------------------------------------. ### Compilation. CMake allows to cross compile to a different target via toolchain files. More; information can be found here:. - [https://llvm.org/docs/lnt/tests.html#cross-compiling](https://llvm.org/docs/lnt/tests.html#cross-compiling). - [https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html](https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html). Cross compilation from macOS to iOS is possible with the; `test-suite/cmake/caches/target-target-*-iphoneos-internal.cmake` CMake cache; files; this requires an internal iOS SDK. ### Running. There are two ways to run the tests in a cross compilati",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:10854,Testability,benchmark,benchmark,10854,"` variable:. ```bash; % cmake -DTEST_SUITE_SUBDIRS=path/to/my/benchmark-suite ../test-suite; ```. Profile Guided Optimization; ---------------------------. Profile guided optimization requires to compile and run twice. First the; benchmark should be compiled with profile generation instrumentation enabled; and setup for training data. The lit runner will merge the profile files; using `llvm-profdata` so they can be used by the second compilation run. Example:; ```bash; # Profile generation run using LLVM IR PGO:; % cmake -DTEST_SUITE_PROFILE_GENERATE=ON \; -DTEST_SUITE_USE_IR_PGO=ON \; -DTEST_SUITE_RUN_TYPE=train \; ../test-suite; % make; % llvm-lit .; # Use the profile data for compilation and actual benchmark run:; % cmake -DTEST_SUITE_PROFILE_GENERATE=OFF \; -DTEST_SUITE_PROFILE_USE=ON \; -DTEST_SUITE_RUN_TYPE=ref \; .; % make; % llvm-lit -o result.json .; ```. To use Clang frontend's PGO instead of LLVM IR PGO, set `-DTEST_SUITE_USE_IR_PGO=OFF`. The `TEST_SUITE_RUN_TYPE` setting only affects the SPEC benchmark suites. Cross Compilation and External Devices; --------------------------------------. ### Compilation. CMake allows to cross compile to a different target via toolchain files. More; information can be found here:. - [https://llvm.org/docs/lnt/tests.html#cross-compiling](https://llvm.org/docs/lnt/tests.html#cross-compiling). - [https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html](https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html). Cross compilation from macOS to iOS is possible with the; `test-suite/cmake/caches/target-target-*-iphoneos-internal.cmake` CMake cache; files; this requires an internal iOS SDK. ### Running. There are two ways to run the tests in a cross compilation setting:. - Via SSH connection to an external device: The `TEST_SUITE_REMOTE_HOST` option; should be set to the SSH hostname. The executables and data files need to be; transferred to the device after compilation. This is typically done via the; `rsyn",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:11109,Testability,test,tests,11109," generation instrumentation enabled; and setup for training data. The lit runner will merge the profile files; using `llvm-profdata` so they can be used by the second compilation run. Example:; ```bash; # Profile generation run using LLVM IR PGO:; % cmake -DTEST_SUITE_PROFILE_GENERATE=ON \; -DTEST_SUITE_USE_IR_PGO=ON \; -DTEST_SUITE_RUN_TYPE=train \; ../test-suite; % make; % llvm-lit .; # Use the profile data for compilation and actual benchmark run:; % cmake -DTEST_SUITE_PROFILE_GENERATE=OFF \; -DTEST_SUITE_PROFILE_USE=ON \; -DTEST_SUITE_RUN_TYPE=ref \; .; % make; % llvm-lit -o result.json .; ```. To use Clang frontend's PGO instead of LLVM IR PGO, set `-DTEST_SUITE_USE_IR_PGO=OFF`. The `TEST_SUITE_RUN_TYPE` setting only affects the SPEC benchmark suites. Cross Compilation and External Devices; --------------------------------------. ### Compilation. CMake allows to cross compile to a different target via toolchain files. More; information can be found here:. - [https://llvm.org/docs/lnt/tests.html#cross-compiling](https://llvm.org/docs/lnt/tests.html#cross-compiling). - [https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html](https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html). Cross compilation from macOS to iOS is possible with the; `test-suite/cmake/caches/target-target-*-iphoneos-internal.cmake` CMake cache; files; this requires an internal iOS SDK. ### Running. There are two ways to run the tests in a cross compilation setting:. - Via SSH connection to an external device: The `TEST_SUITE_REMOTE_HOST` option; should be set to the SSH hostname. The executables and data files need to be; transferred to the device after compilation. This is typically done via the; `rsync` make target. After this, the lit runner can be used on the host; machine. It will prefix the benchmark and verification command lines with an; `ssh` command. Example:. ```bash; % cmake -G Ninja -D CMAKE_C_COMPILER=path/to/clang \; -C ../test-suite/cmake/caches/target-a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:11163,Testability,test,tests,11163,"ining data. The lit runner will merge the profile files; using `llvm-profdata` so they can be used by the second compilation run. Example:; ```bash; # Profile generation run using LLVM IR PGO:; % cmake -DTEST_SUITE_PROFILE_GENERATE=ON \; -DTEST_SUITE_USE_IR_PGO=ON \; -DTEST_SUITE_RUN_TYPE=train \; ../test-suite; % make; % llvm-lit .; # Use the profile data for compilation and actual benchmark run:; % cmake -DTEST_SUITE_PROFILE_GENERATE=OFF \; -DTEST_SUITE_PROFILE_USE=ON \; -DTEST_SUITE_RUN_TYPE=ref \; .; % make; % llvm-lit -o result.json .; ```. To use Clang frontend's PGO instead of LLVM IR PGO, set `-DTEST_SUITE_USE_IR_PGO=OFF`. The `TEST_SUITE_RUN_TYPE` setting only affects the SPEC benchmark suites. Cross Compilation and External Devices; --------------------------------------. ### Compilation. CMake allows to cross compile to a different target via toolchain files. More; information can be found here:. - [https://llvm.org/docs/lnt/tests.html#cross-compiling](https://llvm.org/docs/lnt/tests.html#cross-compiling). - [https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html](https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html). Cross compilation from macOS to iOS is possible with the; `test-suite/cmake/caches/target-target-*-iphoneos-internal.cmake` CMake cache; files; this requires an internal iOS SDK. ### Running. There are two ways to run the tests in a cross compilation setting:. - Via SSH connection to an external device: The `TEST_SUITE_REMOTE_HOST` option; should be set to the SSH hostname. The executables and data files need to be; transferred to the device after compilation. This is typically done via the; `rsync` make target. After this, the lit runner can be used on the host; machine. It will prefix the benchmark and verification command lines with an; `ssh` command. Example:. ```bash; % cmake -G Ninja -D CMAKE_C_COMPILER=path/to/clang \; -C ../test-suite/cmake/caches/target-arm64-iphoneos-internal.cmake \; -D CMAKE_BUILD_TYPE=Re",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:11391,Testability,test,test-suite,11391,"=ON \; -DTEST_SUITE_USE_IR_PGO=ON \; -DTEST_SUITE_RUN_TYPE=train \; ../test-suite; % make; % llvm-lit .; # Use the profile data for compilation and actual benchmark run:; % cmake -DTEST_SUITE_PROFILE_GENERATE=OFF \; -DTEST_SUITE_PROFILE_USE=ON \; -DTEST_SUITE_RUN_TYPE=ref \; .; % make; % llvm-lit -o result.json .; ```. To use Clang frontend's PGO instead of LLVM IR PGO, set `-DTEST_SUITE_USE_IR_PGO=OFF`. The `TEST_SUITE_RUN_TYPE` setting only affects the SPEC benchmark suites. Cross Compilation and External Devices; --------------------------------------. ### Compilation. CMake allows to cross compile to a different target via toolchain files. More; information can be found here:. - [https://llvm.org/docs/lnt/tests.html#cross-compiling](https://llvm.org/docs/lnt/tests.html#cross-compiling). - [https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html](https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html). Cross compilation from macOS to iOS is possible with the; `test-suite/cmake/caches/target-target-*-iphoneos-internal.cmake` CMake cache; files; this requires an internal iOS SDK. ### Running. There are two ways to run the tests in a cross compilation setting:. - Via SSH connection to an external device: The `TEST_SUITE_REMOTE_HOST` option; should be set to the SSH hostname. The executables and data files need to be; transferred to the device after compilation. This is typically done via the; `rsync` make target. After this, the lit runner can be used on the host; machine. It will prefix the benchmark and verification command lines with an; `ssh` command. Example:. ```bash; % cmake -G Ninja -D CMAKE_C_COMPILER=path/to/clang \; -C ../test-suite/cmake/caches/target-arm64-iphoneos-internal.cmake \; -D CMAKE_BUILD_TYPE=Release \; -D TEST_SUITE_REMOTE_HOST=mydevice \; ../test-suite; % ninja; % ninja rsync; % llvm-lit -j1 -o result.json .; ```. - You can specify a simulator for the target machine with the; `TEST_SUITE_RUN_UNDER` setting. The lit run",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:11554,Testability,test,tests,11554,"n:; % cmake -DTEST_SUITE_PROFILE_GENERATE=OFF \; -DTEST_SUITE_PROFILE_USE=ON \; -DTEST_SUITE_RUN_TYPE=ref \; .; % make; % llvm-lit -o result.json .; ```. To use Clang frontend's PGO instead of LLVM IR PGO, set `-DTEST_SUITE_USE_IR_PGO=OFF`. The `TEST_SUITE_RUN_TYPE` setting only affects the SPEC benchmark suites. Cross Compilation and External Devices; --------------------------------------. ### Compilation. CMake allows to cross compile to a different target via toolchain files. More; information can be found here:. - [https://llvm.org/docs/lnt/tests.html#cross-compiling](https://llvm.org/docs/lnt/tests.html#cross-compiling). - [https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html](https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html). Cross compilation from macOS to iOS is possible with the; `test-suite/cmake/caches/target-target-*-iphoneos-internal.cmake` CMake cache; files; this requires an internal iOS SDK. ### Running. There are two ways to run the tests in a cross compilation setting:. - Via SSH connection to an external device: The `TEST_SUITE_REMOTE_HOST` option; should be set to the SSH hostname. The executables and data files need to be; transferred to the device after compilation. This is typically done via the; `rsync` make target. After this, the lit runner can be used on the host; machine. It will prefix the benchmark and verification command lines with an; `ssh` command. Example:. ```bash; % cmake -G Ninja -D CMAKE_C_COMPILER=path/to/clang \; -C ../test-suite/cmake/caches/target-arm64-iphoneos-internal.cmake \; -D CMAKE_BUILD_TYPE=Release \; -D TEST_SUITE_REMOTE_HOST=mydevice \; ../test-suite; % ninja; % ninja rsync; % llvm-lit -j1 -o result.json .; ```. - You can specify a simulator for the target machine with the; `TEST_SUITE_RUN_UNDER` setting. The lit runner will prefix all benchmark; invocations with it. Running the test-suite via LNT; ------------------------------. The LNT tool can run the test-suite. Use this when s",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:11930,Testability,benchmark,benchmark,11930,"### Compilation. CMake allows to cross compile to a different target via toolchain files. More; information can be found here:. - [https://llvm.org/docs/lnt/tests.html#cross-compiling](https://llvm.org/docs/lnt/tests.html#cross-compiling). - [https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html](https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html). Cross compilation from macOS to iOS is possible with the; `test-suite/cmake/caches/target-target-*-iphoneos-internal.cmake` CMake cache; files; this requires an internal iOS SDK. ### Running. There are two ways to run the tests in a cross compilation setting:. - Via SSH connection to an external device: The `TEST_SUITE_REMOTE_HOST` option; should be set to the SSH hostname. The executables and data files need to be; transferred to the device after compilation. This is typically done via the; `rsync` make target. After this, the lit runner can be used on the host; machine. It will prefix the benchmark and verification command lines with an; `ssh` command. Example:. ```bash; % cmake -G Ninja -D CMAKE_C_COMPILER=path/to/clang \; -C ../test-suite/cmake/caches/target-arm64-iphoneos-internal.cmake \; -D CMAKE_BUILD_TYPE=Release \; -D TEST_SUITE_REMOTE_HOST=mydevice \; ../test-suite; % ninja; % ninja rsync; % llvm-lit -j1 -o result.json .; ```. - You can specify a simulator for the target machine with the; `TEST_SUITE_RUN_UNDER` setting. The lit runner will prefix all benchmark; invocations with it. Running the test-suite via LNT; ------------------------------. The LNT tool can run the test-suite. Use this when submitting test results to; an LNT instance. See; [https://llvm.org/docs/lnt/tests.html#llvm-cmake-test-suite](https://llvm.org/docs/lnt/tests.html#llvm-cmake-test-suite); for details. Running the test-suite via Makefiles (deprecated); -------------------------------------------------. **Note**: The test-suite comes with a set of Makefiles that are considered; deprecated. They do not support ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:12074,Testability,test,test-suite,12074,"ocs/lnt/tests.html#cross-compiling](https://llvm.org/docs/lnt/tests.html#cross-compiling). - [https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html](https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html). Cross compilation from macOS to iOS is possible with the; `test-suite/cmake/caches/target-target-*-iphoneos-internal.cmake` CMake cache; files; this requires an internal iOS SDK. ### Running. There are two ways to run the tests in a cross compilation setting:. - Via SSH connection to an external device: The `TEST_SUITE_REMOTE_HOST` option; should be set to the SSH hostname. The executables and data files need to be; transferred to the device after compilation. This is typically done via the; `rsync` make target. After this, the lit runner can be used on the host; machine. It will prefix the benchmark and verification command lines with an; `ssh` command. Example:. ```bash; % cmake -G Ninja -D CMAKE_C_COMPILER=path/to/clang \; -C ../test-suite/cmake/caches/target-arm64-iphoneos-internal.cmake \; -D CMAKE_BUILD_TYPE=Release \; -D TEST_SUITE_REMOTE_HOST=mydevice \; ../test-suite; % ninja; % ninja rsync; % llvm-lit -j1 -o result.json .; ```. - You can specify a simulator for the target machine with the; `TEST_SUITE_RUN_UNDER` setting. The lit runner will prefix all benchmark; invocations with it. Running the test-suite via LNT; ------------------------------. The LNT tool can run the test-suite. Use this when submitting test results to; an LNT instance. See; [https://llvm.org/docs/lnt/tests.html#llvm-cmake-test-suite](https://llvm.org/docs/lnt/tests.html#llvm-cmake-test-suite); for details. Running the test-suite via Makefiles (deprecated); -------------------------------------------------. **Note**: The test-suite comes with a set of Makefiles that are considered; deprecated. They do not support newer testing modes like `Bitcode` or; `Microbenchmarks` and are harder to use. Old documentation is available in the; [test-suite Makefile Guide](Te",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:12210,Testability,test,test-suite,12210,"-compiling](https://llvm.org/docs/lnt/tests.html#cross-compiling). - [https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html](https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html). Cross compilation from macOS to iOS is possible with the; `test-suite/cmake/caches/target-target-*-iphoneos-internal.cmake` CMake cache; files; this requires an internal iOS SDK. ### Running. There are two ways to run the tests in a cross compilation setting:. - Via SSH connection to an external device: The `TEST_SUITE_REMOTE_HOST` option; should be set to the SSH hostname. The executables and data files need to be; transferred to the device after compilation. This is typically done via the; `rsync` make target. After this, the lit runner can be used on the host; machine. It will prefix the benchmark and verification command lines with an; `ssh` command. Example:. ```bash; % cmake -G Ninja -D CMAKE_C_COMPILER=path/to/clang \; -C ../test-suite/cmake/caches/target-arm64-iphoneos-internal.cmake \; -D CMAKE_BUILD_TYPE=Release \; -D TEST_SUITE_REMOTE_HOST=mydevice \; ../test-suite; % ninja; % ninja rsync; % llvm-lit -j1 -o result.json .; ```. - You can specify a simulator for the target machine with the; `TEST_SUITE_RUN_UNDER` setting. The lit runner will prefix all benchmark; invocations with it. Running the test-suite via LNT; ------------------------------. The LNT tool can run the test-suite. Use this when submitting test results to; an LNT instance. See; [https://llvm.org/docs/lnt/tests.html#llvm-cmake-test-suite](https://llvm.org/docs/lnt/tests.html#llvm-cmake-test-suite); for details. Running the test-suite via Makefiles (deprecated); -------------------------------------------------. **Note**: The test-suite comes with a set of Makefiles that are considered; deprecated. They do not support newer testing modes like `Bitcode` or; `Microbenchmarks` and are harder to use. Old documentation is available in the; [test-suite Makefile Guide](TestSuiteMakefileGuide).; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:12410,Testability,benchmark,benchmark,12410,"-compiling](https://llvm.org/docs/lnt/tests.html#cross-compiling). - [https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html](https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html). Cross compilation from macOS to iOS is possible with the; `test-suite/cmake/caches/target-target-*-iphoneos-internal.cmake` CMake cache; files; this requires an internal iOS SDK. ### Running. There are two ways to run the tests in a cross compilation setting:. - Via SSH connection to an external device: The `TEST_SUITE_REMOTE_HOST` option; should be set to the SSH hostname. The executables and data files need to be; transferred to the device after compilation. This is typically done via the; `rsync` make target. After this, the lit runner can be used on the host; machine. It will prefix the benchmark and verification command lines with an; `ssh` command. Example:. ```bash; % cmake -G Ninja -D CMAKE_C_COMPILER=path/to/clang \; -C ../test-suite/cmake/caches/target-arm64-iphoneos-internal.cmake \; -D CMAKE_BUILD_TYPE=Release \; -D TEST_SUITE_REMOTE_HOST=mydevice \; ../test-suite; % ninja; % ninja rsync; % llvm-lit -j1 -o result.json .; ```. - You can specify a simulator for the target machine with the; `TEST_SUITE_RUN_UNDER` setting. The lit runner will prefix all benchmark; invocations with it. Running the test-suite via LNT; ------------------------------. The LNT tool can run the test-suite. Use this when submitting test results to; an LNT instance. See; [https://llvm.org/docs/lnt/tests.html#llvm-cmake-test-suite](https://llvm.org/docs/lnt/tests.html#llvm-cmake-test-suite); for details. Running the test-suite via Makefiles (deprecated); -------------------------------------------------. **Note**: The test-suite comes with a set of Makefiles that are considered; deprecated. They do not support newer testing modes like `Bitcode` or; `Microbenchmarks` and are harder to use. Old documentation is available in the; [test-suite Makefile Guide](TestSuiteMakefileGuide).; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:12454,Testability,test,test-suite,12454,"-compiling](https://llvm.org/docs/lnt/tests.html#cross-compiling). - [https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html](https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html). Cross compilation from macOS to iOS is possible with the; `test-suite/cmake/caches/target-target-*-iphoneos-internal.cmake` CMake cache; files; this requires an internal iOS SDK. ### Running. There are two ways to run the tests in a cross compilation setting:. - Via SSH connection to an external device: The `TEST_SUITE_REMOTE_HOST` option; should be set to the SSH hostname. The executables and data files need to be; transferred to the device after compilation. This is typically done via the; `rsync` make target. After this, the lit runner can be used on the host; machine. It will prefix the benchmark and verification command lines with an; `ssh` command. Example:. ```bash; % cmake -G Ninja -D CMAKE_C_COMPILER=path/to/clang \; -C ../test-suite/cmake/caches/target-arm64-iphoneos-internal.cmake \; -D CMAKE_BUILD_TYPE=Release \; -D TEST_SUITE_REMOTE_HOST=mydevice \; ../test-suite; % ninja; % ninja rsync; % llvm-lit -j1 -o result.json .; ```. - You can specify a simulator for the target machine with the; `TEST_SUITE_RUN_UNDER` setting. The lit runner will prefix all benchmark; invocations with it. Running the test-suite via LNT; ------------------------------. The LNT tool can run the test-suite. Use this when submitting test results to; an LNT instance. See; [https://llvm.org/docs/lnt/tests.html#llvm-cmake-test-suite](https://llvm.org/docs/lnt/tests.html#llvm-cmake-test-suite); for details. Running the test-suite via Makefiles (deprecated); -------------------------------------------------. **Note**: The test-suite comes with a set of Makefiles that are considered; deprecated. They do not support newer testing modes like `Bitcode` or; `Microbenchmarks` and are harder to use. Old documentation is available in the; [test-suite Makefile Guide](TestSuiteMakefileGuide).; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:12531,Testability,test,test-suite,12531,"-compiling](https://llvm.org/docs/lnt/tests.html#cross-compiling). - [https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html](https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html). Cross compilation from macOS to iOS is possible with the; `test-suite/cmake/caches/target-target-*-iphoneos-internal.cmake` CMake cache; files; this requires an internal iOS SDK. ### Running. There are two ways to run the tests in a cross compilation setting:. - Via SSH connection to an external device: The `TEST_SUITE_REMOTE_HOST` option; should be set to the SSH hostname. The executables and data files need to be; transferred to the device after compilation. This is typically done via the; `rsync` make target. After this, the lit runner can be used on the host; machine. It will prefix the benchmark and verification command lines with an; `ssh` command. Example:. ```bash; % cmake -G Ninja -D CMAKE_C_COMPILER=path/to/clang \; -C ../test-suite/cmake/caches/target-arm64-iphoneos-internal.cmake \; -D CMAKE_BUILD_TYPE=Release \; -D TEST_SUITE_REMOTE_HOST=mydevice \; ../test-suite; % ninja; % ninja rsync; % llvm-lit -j1 -o result.json .; ```. - You can specify a simulator for the target machine with the; `TEST_SUITE_RUN_UNDER` setting. The lit runner will prefix all benchmark; invocations with it. Running the test-suite via LNT; ------------------------------. The LNT tool can run the test-suite. Use this when submitting test results to; an LNT instance. See; [https://llvm.org/docs/lnt/tests.html#llvm-cmake-test-suite](https://llvm.org/docs/lnt/tests.html#llvm-cmake-test-suite); for details. Running the test-suite via Makefiles (deprecated); -------------------------------------------------. **Note**: The test-suite comes with a set of Makefiles that are considered; deprecated. They do not support newer testing modes like `Bitcode` or; `Microbenchmarks` and are harder to use. Old documentation is available in the; [test-suite Makefile Guide](TestSuiteMakefileGuide).; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:12568,Testability,test,test,12568,"-compiling](https://llvm.org/docs/lnt/tests.html#cross-compiling). - [https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html](https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html). Cross compilation from macOS to iOS is possible with the; `test-suite/cmake/caches/target-target-*-iphoneos-internal.cmake` CMake cache; files; this requires an internal iOS SDK. ### Running. There are two ways to run the tests in a cross compilation setting:. - Via SSH connection to an external device: The `TEST_SUITE_REMOTE_HOST` option; should be set to the SSH hostname. The executables and data files need to be; transferred to the device after compilation. This is typically done via the; `rsync` make target. After this, the lit runner can be used on the host; machine. It will prefix the benchmark and verification command lines with an; `ssh` command. Example:. ```bash; % cmake -G Ninja -D CMAKE_C_COMPILER=path/to/clang \; -C ../test-suite/cmake/caches/target-arm64-iphoneos-internal.cmake \; -D CMAKE_BUILD_TYPE=Release \; -D TEST_SUITE_REMOTE_HOST=mydevice \; ../test-suite; % ninja; % ninja rsync; % llvm-lit -j1 -o result.json .; ```. - You can specify a simulator for the target machine with the; `TEST_SUITE_RUN_UNDER` setting. The lit runner will prefix all benchmark; invocations with it. Running the test-suite via LNT; ------------------------------. The LNT tool can run the test-suite. Use this when submitting test results to; an LNT instance. See; [https://llvm.org/docs/lnt/tests.html#llvm-cmake-test-suite](https://llvm.org/docs/lnt/tests.html#llvm-cmake-test-suite); for details. Running the test-suite via Makefiles (deprecated); -------------------------------------------------. **Note**: The test-suite comes with a set of Makefiles that are considered; deprecated. They do not support newer testing modes like `Bitcode` or; `Microbenchmarks` and are harder to use. Old documentation is available in the; [test-suite Makefile Guide](TestSuiteMakefileGuide).; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:12634,Testability,test,tests,12634,"-compiling](https://llvm.org/docs/lnt/tests.html#cross-compiling). - [https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html](https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html). Cross compilation from macOS to iOS is possible with the; `test-suite/cmake/caches/target-target-*-iphoneos-internal.cmake` CMake cache; files; this requires an internal iOS SDK. ### Running. There are two ways to run the tests in a cross compilation setting:. - Via SSH connection to an external device: The `TEST_SUITE_REMOTE_HOST` option; should be set to the SSH hostname. The executables and data files need to be; transferred to the device after compilation. This is typically done via the; `rsync` make target. After this, the lit runner can be used on the host; machine. It will prefix the benchmark and verification command lines with an; `ssh` command. Example:. ```bash; % cmake -G Ninja -D CMAKE_C_COMPILER=path/to/clang \; -C ../test-suite/cmake/caches/target-arm64-iphoneos-internal.cmake \; -D CMAKE_BUILD_TYPE=Release \; -D TEST_SUITE_REMOTE_HOST=mydevice \; ../test-suite; % ninja; % ninja rsync; % llvm-lit -j1 -o result.json .; ```. - You can specify a simulator for the target machine with the; `TEST_SUITE_RUN_UNDER` setting. The lit runner will prefix all benchmark; invocations with it. Running the test-suite via LNT; ------------------------------. The LNT tool can run the test-suite. Use this when submitting test results to; an LNT instance. See; [https://llvm.org/docs/lnt/tests.html#llvm-cmake-test-suite](https://llvm.org/docs/lnt/tests.html#llvm-cmake-test-suite); for details. Running the test-suite via Makefiles (deprecated); -------------------------------------------------. **Note**: The test-suite comes with a set of Makefiles that are considered; deprecated. They do not support newer testing modes like `Bitcode` or; `Microbenchmarks` and are harder to use. Old documentation is available in the; [test-suite Makefile Guide](TestSuiteMakefileGuide).; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:12656,Testability,test,test-suite,12656,"-compiling](https://llvm.org/docs/lnt/tests.html#cross-compiling). - [https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html](https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html). Cross compilation from macOS to iOS is possible with the; `test-suite/cmake/caches/target-target-*-iphoneos-internal.cmake` CMake cache; files; this requires an internal iOS SDK. ### Running. There are two ways to run the tests in a cross compilation setting:. - Via SSH connection to an external device: The `TEST_SUITE_REMOTE_HOST` option; should be set to the SSH hostname. The executables and data files need to be; transferred to the device after compilation. This is typically done via the; `rsync` make target. After this, the lit runner can be used on the host; machine. It will prefix the benchmark and verification command lines with an; `ssh` command. Example:. ```bash; % cmake -G Ninja -D CMAKE_C_COMPILER=path/to/clang \; -C ../test-suite/cmake/caches/target-arm64-iphoneos-internal.cmake \; -D CMAKE_BUILD_TYPE=Release \; -D TEST_SUITE_REMOTE_HOST=mydevice \; ../test-suite; % ninja; % ninja rsync; % llvm-lit -j1 -o result.json .; ```. - You can specify a simulator for the target machine with the; `TEST_SUITE_RUN_UNDER` setting. The lit runner will prefix all benchmark; invocations with it. Running the test-suite via LNT; ------------------------------. The LNT tool can run the test-suite. Use this when submitting test results to; an LNT instance. See; [https://llvm.org/docs/lnt/tests.html#llvm-cmake-test-suite](https://llvm.org/docs/lnt/tests.html#llvm-cmake-test-suite); for details. Running the test-suite via Makefiles (deprecated); -------------------------------------------------. **Note**: The test-suite comes with a set of Makefiles that are considered; deprecated. They do not support newer testing modes like `Bitcode` or; `Microbenchmarks` and are harder to use. Old documentation is available in the; [test-suite Makefile Guide](TestSuiteMakefileGuide).; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:12694,Testability,test,tests,12694,"-compiling](https://llvm.org/docs/lnt/tests.html#cross-compiling). - [https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html](https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html). Cross compilation from macOS to iOS is possible with the; `test-suite/cmake/caches/target-target-*-iphoneos-internal.cmake` CMake cache; files; this requires an internal iOS SDK. ### Running. There are two ways to run the tests in a cross compilation setting:. - Via SSH connection to an external device: The `TEST_SUITE_REMOTE_HOST` option; should be set to the SSH hostname. The executables and data files need to be; transferred to the device after compilation. This is typically done via the; `rsync` make target. After this, the lit runner can be used on the host; machine. It will prefix the benchmark and verification command lines with an; `ssh` command. Example:. ```bash; % cmake -G Ninja -D CMAKE_C_COMPILER=path/to/clang \; -C ../test-suite/cmake/caches/target-arm64-iphoneos-internal.cmake \; -D CMAKE_BUILD_TYPE=Release \; -D TEST_SUITE_REMOTE_HOST=mydevice \; ../test-suite; % ninja; % ninja rsync; % llvm-lit -j1 -o result.json .; ```. - You can specify a simulator for the target machine with the; `TEST_SUITE_RUN_UNDER` setting. The lit runner will prefix all benchmark; invocations with it. Running the test-suite via LNT; ------------------------------. The LNT tool can run the test-suite. Use this when submitting test results to; an LNT instance. See; [https://llvm.org/docs/lnt/tests.html#llvm-cmake-test-suite](https://llvm.org/docs/lnt/tests.html#llvm-cmake-test-suite); for details. Running the test-suite via Makefiles (deprecated); -------------------------------------------------. **Note**: The test-suite comes with a set of Makefiles that are considered; deprecated. They do not support newer testing modes like `Bitcode` or; `Microbenchmarks` and are harder to use. Old documentation is available in the; [test-suite Makefile Guide](TestSuiteMakefileGuide).; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:12716,Testability,test,test-suite,12716,"-compiling](https://llvm.org/docs/lnt/tests.html#cross-compiling). - [https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html](https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html). Cross compilation from macOS to iOS is possible with the; `test-suite/cmake/caches/target-target-*-iphoneos-internal.cmake` CMake cache; files; this requires an internal iOS SDK. ### Running. There are two ways to run the tests in a cross compilation setting:. - Via SSH connection to an external device: The `TEST_SUITE_REMOTE_HOST` option; should be set to the SSH hostname. The executables and data files need to be; transferred to the device after compilation. This is typically done via the; `rsync` make target. After this, the lit runner can be used on the host; machine. It will prefix the benchmark and verification command lines with an; `ssh` command. Example:. ```bash; % cmake -G Ninja -D CMAKE_C_COMPILER=path/to/clang \; -C ../test-suite/cmake/caches/target-arm64-iphoneos-internal.cmake \; -D CMAKE_BUILD_TYPE=Release \; -D TEST_SUITE_REMOTE_HOST=mydevice \; ../test-suite; % ninja; % ninja rsync; % llvm-lit -j1 -o result.json .; ```. - You can specify a simulator for the target machine with the; `TEST_SUITE_RUN_UNDER` setting. The lit runner will prefix all benchmark; invocations with it. Running the test-suite via LNT; ------------------------------. The LNT tool can run the test-suite. Use this when submitting test results to; an LNT instance. See; [https://llvm.org/docs/lnt/tests.html#llvm-cmake-test-suite](https://llvm.org/docs/lnt/tests.html#llvm-cmake-test-suite); for details. Running the test-suite via Makefiles (deprecated); -------------------------------------------------. **Note**: The test-suite comes with a set of Makefiles that are considered; deprecated. They do not support newer testing modes like `Bitcode` or; `Microbenchmarks` and are harder to use. Old documentation is available in the; [test-suite Makefile Guide](TestSuiteMakefileGuide).; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:12754,Testability,test,test-suite,12754,"-compiling](https://llvm.org/docs/lnt/tests.html#cross-compiling). - [https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html](https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html). Cross compilation from macOS to iOS is possible with the; `test-suite/cmake/caches/target-target-*-iphoneos-internal.cmake` CMake cache; files; this requires an internal iOS SDK. ### Running. There are two ways to run the tests in a cross compilation setting:. - Via SSH connection to an external device: The `TEST_SUITE_REMOTE_HOST` option; should be set to the SSH hostname. The executables and data files need to be; transferred to the device after compilation. This is typically done via the; `rsync` make target. After this, the lit runner can be used on the host; machine. It will prefix the benchmark and verification command lines with an; `ssh` command. Example:. ```bash; % cmake -G Ninja -D CMAKE_C_COMPILER=path/to/clang \; -C ../test-suite/cmake/caches/target-arm64-iphoneos-internal.cmake \; -D CMAKE_BUILD_TYPE=Release \; -D TEST_SUITE_REMOTE_HOST=mydevice \; ../test-suite; % ninja; % ninja rsync; % llvm-lit -j1 -o result.json .; ```. - You can specify a simulator for the target machine with the; `TEST_SUITE_RUN_UNDER` setting. The lit runner will prefix all benchmark; invocations with it. Running the test-suite via LNT; ------------------------------. The LNT tool can run the test-suite. Use this when submitting test results to; an LNT instance. See; [https://llvm.org/docs/lnt/tests.html#llvm-cmake-test-suite](https://llvm.org/docs/lnt/tests.html#llvm-cmake-test-suite); for details. Running the test-suite via Makefiles (deprecated); -------------------------------------------------. **Note**: The test-suite comes with a set of Makefiles that are considered; deprecated. They do not support newer testing modes like `Bitcode` or; `Microbenchmarks` and are harder to use. Old documentation is available in the; [test-suite Makefile Guide](TestSuiteMakefileGuide).; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:12858,Testability,test,test-suite,12858,"-compiling](https://llvm.org/docs/lnt/tests.html#cross-compiling). - [https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html](https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html). Cross compilation from macOS to iOS is possible with the; `test-suite/cmake/caches/target-target-*-iphoneos-internal.cmake` CMake cache; files; this requires an internal iOS SDK. ### Running. There are two ways to run the tests in a cross compilation setting:. - Via SSH connection to an external device: The `TEST_SUITE_REMOTE_HOST` option; should be set to the SSH hostname. The executables and data files need to be; transferred to the device after compilation. This is typically done via the; `rsync` make target. After this, the lit runner can be used on the host; machine. It will prefix the benchmark and verification command lines with an; `ssh` command. Example:. ```bash; % cmake -G Ninja -D CMAKE_C_COMPILER=path/to/clang \; -C ../test-suite/cmake/caches/target-arm64-iphoneos-internal.cmake \; -D CMAKE_BUILD_TYPE=Release \; -D TEST_SUITE_REMOTE_HOST=mydevice \; ../test-suite; % ninja; % ninja rsync; % llvm-lit -j1 -o result.json .; ```. - You can specify a simulator for the target machine with the; `TEST_SUITE_RUN_UNDER` setting. The lit runner will prefix all benchmark; invocations with it. Running the test-suite via LNT; ------------------------------. The LNT tool can run the test-suite. Use this when submitting test results to; an LNT instance. See; [https://llvm.org/docs/lnt/tests.html#llvm-cmake-test-suite](https://llvm.org/docs/lnt/tests.html#llvm-cmake-test-suite); for details. Running the test-suite via Makefiles (deprecated); -------------------------------------------------. **Note**: The test-suite comes with a set of Makefiles that are considered; deprecated. They do not support newer testing modes like `Bitcode` or; `Microbenchmarks` and are harder to use. Old documentation is available in the; [test-suite Makefile Guide](TestSuiteMakefileGuide).; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:12958,Testability,test,testing,12958,"-compiling](https://llvm.org/docs/lnt/tests.html#cross-compiling). - [https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html](https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html). Cross compilation from macOS to iOS is possible with the; `test-suite/cmake/caches/target-target-*-iphoneos-internal.cmake` CMake cache; files; this requires an internal iOS SDK. ### Running. There are two ways to run the tests in a cross compilation setting:. - Via SSH connection to an external device: The `TEST_SUITE_REMOTE_HOST` option; should be set to the SSH hostname. The executables and data files need to be; transferred to the device after compilation. This is typically done via the; `rsync` make target. After this, the lit runner can be used on the host; machine. It will prefix the benchmark and verification command lines with an; `ssh` command. Example:. ```bash; % cmake -G Ninja -D CMAKE_C_COMPILER=path/to/clang \; -C ../test-suite/cmake/caches/target-arm64-iphoneos-internal.cmake \; -D CMAKE_BUILD_TYPE=Release \; -D TEST_SUITE_REMOTE_HOST=mydevice \; ../test-suite; % ninja; % ninja rsync; % llvm-lit -j1 -o result.json .; ```. - You can specify a simulator for the target machine with the; `TEST_SUITE_RUN_UNDER` setting. The lit runner will prefix all benchmark; invocations with it. Running the test-suite via LNT; ------------------------------. The LNT tool can run the test-suite. Use this when submitting test results to; an LNT instance. See; [https://llvm.org/docs/lnt/tests.html#llvm-cmake-test-suite](https://llvm.org/docs/lnt/tests.html#llvm-cmake-test-suite); for details. Running the test-suite via Makefiles (deprecated); -------------------------------------------------. **Note**: The test-suite comes with a set of Makefiles that are considered; deprecated. They do not support newer testing modes like `Bitcode` or; `Microbenchmarks` and are harder to use. Old documentation is available in the; [test-suite Makefile Guide](TestSuiteMakefileGuide).; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:13072,Testability,test,test-suite,13072,"-compiling](https://llvm.org/docs/lnt/tests.html#cross-compiling). - [https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html](https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html). Cross compilation from macOS to iOS is possible with the; `test-suite/cmake/caches/target-target-*-iphoneos-internal.cmake` CMake cache; files; this requires an internal iOS SDK. ### Running. There are two ways to run the tests in a cross compilation setting:. - Via SSH connection to an external device: The `TEST_SUITE_REMOTE_HOST` option; should be set to the SSH hostname. The executables and data files need to be; transferred to the device after compilation. This is typically done via the; `rsync` make target. After this, the lit runner can be used on the host; machine. It will prefix the benchmark and verification command lines with an; `ssh` command. Example:. ```bash; % cmake -G Ninja -D CMAKE_C_COMPILER=path/to/clang \; -C ../test-suite/cmake/caches/target-arm64-iphoneos-internal.cmake \; -D CMAKE_BUILD_TYPE=Release \; -D TEST_SUITE_REMOTE_HOST=mydevice \; ../test-suite; % ninja; % ninja rsync; % llvm-lit -j1 -o result.json .; ```. - You can specify a simulator for the target machine with the; `TEST_SUITE_RUN_UNDER` setting. The lit runner will prefix all benchmark; invocations with it. Running the test-suite via LNT; ------------------------------. The LNT tool can run the test-suite. Use this when submitting test results to; an LNT instance. See; [https://llvm.org/docs/lnt/tests.html#llvm-cmake-test-suite](https://llvm.org/docs/lnt/tests.html#llvm-cmake-test-suite); for details. Running the test-suite via Makefiles (deprecated); -------------------------------------------------. **Note**: The test-suite comes with a set of Makefiles that are considered; deprecated. They do not support newer testing modes like `Bitcode` or; `Microbenchmarks` and are harder to use. Old documentation is available in the; [test-suite Makefile Guide](TestSuiteMakefileGuide).; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:9998,Usability,guid,guided,9998,"nking) them into the `test-suite/test-suite-externals/xxx` directory (example: `test-suite/test-suite-externals/speccpu2000`); - using a configuration option such as `-D TEST_SUITE_SPEC2000_ROOT=path/to/speccpu2000`. You can find further information in the respective README files such as; `test-suite/External/SPEC/README`. For the SPEC benchmarks you can switch between the `test`, `train` and; `ref` input datasets via the `TEST_SUITE_RUN_TYPE` configuration option.; The `train` dataset is used by default. Custom Suites; -------------. You can build custom suites using the test-suite infrastructure. A custom suite; has a `CMakeLists.txt` file at the top directory. The `CMakeLists.txt` will be; picked up automatically if placed into a subdirectory of the test-suite or when; setting the `TEST_SUITE_SUBDIRS` variable:. ```bash; % cmake -DTEST_SUITE_SUBDIRS=path/to/my/benchmark-suite ../test-suite; ```. Profile Guided Optimization; ---------------------------. Profile guided optimization requires to compile and run twice. First the; benchmark should be compiled with profile generation instrumentation enabled; and setup for training data. The lit runner will merge the profile files; using `llvm-profdata` so they can be used by the second compilation run. Example:; ```bash; # Profile generation run using LLVM IR PGO:; % cmake -DTEST_SUITE_PROFILE_GENERATE=ON \; -DTEST_SUITE_USE_IR_PGO=ON \; -DTEST_SUITE_RUN_TYPE=train \; ../test-suite; % make; % llvm-lit .; # Use the profile data for compilation and actual benchmark run:; % cmake -DTEST_SUITE_PROFILE_GENERATE=OFF \; -DTEST_SUITE_PROFILE_USE=ON \; -DTEST_SUITE_RUN_TYPE=ref \; .; % make; % llvm-lit -o result.json .; ```. To use Clang frontend's PGO instead of LLVM IR PGO, set `-DTEST_SUITE_USE_IR_PGO=OFF`. The `TEST_SUITE_RUN_TYPE` setting only affects the SPEC benchmark suites. Cross Compilation and External Devices; --------------------------------------. ### Compilation. CMake allows to cross compile to a different target ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md:5717,Availability,error,error,5717,"tion parameter, and afterwards input key; material should be given with `llvm_blake3_hasher_update`. The context string; is a null-terminated C string which should be **hardcoded, globally; unique, and application-specific**. The context string should not; include any dynamic input like salts, nonces, or identifiers read from a; database at runtime. A good default format for the context string is; `""[application] [commit timestamp] [purpose]""`, e.g., `""example.com; 2019-12-25 16:18:03 session tokens v1""`. This function is intended for application code written in C. For; language bindings, see `llvm_blake3_hasher_init_derive_key_raw` below. ---. ```c; void llvm_blake3_hasher_init_derive_key_raw(; llvm_blake3_hasher *self,; const void *context,; size_t context_len);; ```. As `llvm_blake3_hasher_init_derive_key` above, except that the context string; is given as a pointer to an array of arbitrary bytes with a provided; length. This is intended for writing language bindings, where C string; conversion would add unnecessary overhead and new error cases. Unicode; strings should be encoded as UTF-8. Application code in C should prefer `llvm_blake3_hasher_init_derive_key`,; which takes the context as a C string. If you need to use arbitrary; bytes as a context string in application code, consider whether you're; violating the requirement that context strings should be hardcoded. ---. ```c; void llvm_blake3_hasher_finalize_seek(; const llvm_blake3_hasher *self,; uint64_t seek,; uint8_t *out,; size_t out_len);; ```. The same as `llvm_blake3_hasher_finalize`, but with an additional `seek`; parameter for the starting byte position in the output stream. To; efficiently stream a large output without allocating memory, call this; function in a loop, incrementing `seek` by the output length each time. ---. ```c; void llvm_blake3_hasher_reset(; llvm_blake3_hasher *self);; ```. Reset the hasher to its initial state, prior to any calls to; `llvm_blake3_hasher_update`. Currently this is",MatchSource.DOCS,interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md:7159,Availability,avail,available,7159,"eek(; const llvm_blake3_hasher *self,; uint64_t seek,; uint8_t *out,; size_t out_len);; ```. The same as `llvm_blake3_hasher_finalize`, but with an additional `seek`; parameter for the starting byte position in the output stream. To; efficiently stream a large output without allocating memory, call this; function in a loop, incrementing `seek` by the output length each time. ---. ```c; void llvm_blake3_hasher_reset(; llvm_blake3_hasher *self);; ```. Reset the hasher to its initial state, prior to any calls to; `llvm_blake3_hasher_update`. Currently this is no different from calling; `llvm_blake3_hasher_init` or similar again. However, if this implementation gains; multithreading support in the future, and if `llvm_blake3_hasher` holds (optional); threading resources, this function will reuse those resources. # Building. This implementation is just C and assembly files. ## x86. Dynamic dispatch is enabled by default on x86. The implementation will; query the CPU at runtime to detect SIMD support, and it will use the; widest instruction set available. By default, `blake3_dispatch.c`; expects to be linked with code for five different instruction sets:; portable C, SSE2, SSE4.1, AVX2, and AVX-512. For each of the x86 SIMD instruction sets, four versions are available:; three flavors of assembly (Unix, Windows MSVC, and Windows GNU) and one; version using C intrinsics. The assembly versions are generally; preferred. They perform better, they perform more consistently across; different compilers, and they build more quickly. On the other hand, the; assembly versions are x86\_64-only, and you need to select the right; flavor for your target platform. ## ARM NEON. The NEON implementation is enabled by default on AArch64, but not on; other ARM targets, since not all of them support it. To enable it, set; `BLAKE3_USE_NEON=1`. To explicitiy disable using NEON instructions on AArch64, set; `BLAKE3_USE_NEON=0`. ## Other Platforms. The portable implementation should work on most o",MatchSource.DOCS,interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md:7378,Availability,avail,available,7378," as `llvm_blake3_hasher_finalize`, but with an additional `seek`; parameter for the starting byte position in the output stream. To; efficiently stream a large output without allocating memory, call this; function in a loop, incrementing `seek` by the output length each time. ---. ```c; void llvm_blake3_hasher_reset(; llvm_blake3_hasher *self);; ```. Reset the hasher to its initial state, prior to any calls to; `llvm_blake3_hasher_update`. Currently this is no different from calling; `llvm_blake3_hasher_init` or similar again. However, if this implementation gains; multithreading support in the future, and if `llvm_blake3_hasher` holds (optional); threading resources, this function will reuse those resources. # Building. This implementation is just C and assembly files. ## x86. Dynamic dispatch is enabled by default on x86. The implementation will; query the CPU at runtime to detect SIMD support, and it will use the; widest instruction set available. By default, `blake3_dispatch.c`; expects to be linked with code for five different instruction sets:; portable C, SSE2, SSE4.1, AVX2, and AVX-512. For each of the x86 SIMD instruction sets, four versions are available:; three flavors of assembly (Unix, Windows MSVC, and Windows GNU) and one; version using C intrinsics. The assembly versions are generally; preferred. They perform better, they perform more consistently across; different compilers, and they build more quickly. On the other hand, the; assembly versions are x86\_64-only, and you need to select the right; flavor for your target platform. ## ARM NEON. The NEON implementation is enabled by default on AArch64, but not on; other ARM targets, since not all of them support it. To enable it, set; `BLAKE3_USE_NEON=1`. To explicitiy disable using NEON instructions on AArch64, set; `BLAKE3_USE_NEON=0`. ## Other Platforms. The portable implementation should work on most other architectures. # Multithreading. The implementation doesn't currently support multithreading.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md:552,Deployability,update,update,552,"Implementation of BLAKE3, originating from https://github.com/BLAKE3-team/BLAKE3/tree/1.3.1/c. # Example. An example program that hashes bytes from standard input and prints the; result:. Using the C++ API:. ```c++; #include ""llvm/Support/BLAKE3.h""; #include <errno.h>; #include <stdio.h>; #include <stdlib.h>; #include <string.h>; #include <unistd.h>. int main() {; // Initialize the hasher.; llvm::BLAKE3 hasher;. // Read input bytes from stdin.; char buf[65536];; while (1) {; ssize_t n = read(STDIN_FILENO, buf, sizeof(buf));; if (n > 0) {; hasher.update(llvm::StringRef(buf, n));; } else if (n == 0) {; break; // end of file; } else {; fprintf(stderr, ""read failed: %s\n"", strerror(errno));; exit(1);; }; }. // Finalize the hash. Default output length is 32 bytes.; auto output = hasher.final();. // Print the hash as hexadecimal.; for (uint8_t byte : output) {; printf(""%02x"", byte);; }; printf(""\n"");; return 0;; }; ```. Using the C API:. ```c; #include ""llvm-c/blake3.h""; #include <errno.h>; #include <stdio.h>; #include <stdlib.h>; #include <string.h>; #include <unistd.h>. int main() {; // Initialize the hasher.; llvm_blake3_hasher hasher;; llvm_blake3_hasher_init(&hasher);. // Read input bytes from stdin.; unsigned char buf[65536];; while (1) {; ssize_t n = read(STDIN_FILENO, buf, sizeof(buf));; if (n > 0) {; llvm_blake3_hasher_update(&hasher, buf, n);; } else if (n == 0) {; break; // end of file; } else {; fprintf(stderr, ""read failed: %s\n"", strerror(errno));; exit(1);; }; }. // Finalize the hash. LLVM_BLAKE3_OUT_LEN is the default output length, 32 bytes.; uint8_t output[LLVM_BLAKE3_OUT_LEN];; llvm_blake3_hasher_finalize(&hasher, output, LLVM_BLAKE3_OUT_LEN);. // Print the hash as hexadecimal.; for (size_t i = 0; i < LLVM_BLAKE3_OUT_LEN; i++) {; printf(""%02x"", output[i]);; }; printf(""\n"");; return 0;; }; ```. # API. ## The Class/Struct. ```c++; class BLAKE3 {; // API; private:; llvm_blake3_hasher Hasher;; };; ```; ```c; typedef struct {; // private fields; } llvm_blake3",MatchSource.DOCS,interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md:2085,Deployability,update,updates,2085,"ing.h>; #include <unistd.h>. int main() {; // Initialize the hasher.; llvm_blake3_hasher hasher;; llvm_blake3_hasher_init(&hasher);. // Read input bytes from stdin.; unsigned char buf[65536];; while (1) {; ssize_t n = read(STDIN_FILENO, buf, sizeof(buf));; if (n > 0) {; llvm_blake3_hasher_update(&hasher, buf, n);; } else if (n == 0) {; break; // end of file; } else {; fprintf(stderr, ""read failed: %s\n"", strerror(errno));; exit(1);; }; }. // Finalize the hash. LLVM_BLAKE3_OUT_LEN is the default output length, 32 bytes.; uint8_t output[LLVM_BLAKE3_OUT_LEN];; llvm_blake3_hasher_finalize(&hasher, output, LLVM_BLAKE3_OUT_LEN);. // Print the hash as hexadecimal.; for (size_t i = 0; i < LLVM_BLAKE3_OUT_LEN; i++) {; printf(""%02x"", output[i]);; }; printf(""\n"");; return 0;; }; ```. # API. ## The Class/Struct. ```c++; class BLAKE3 {; // API; private:; llvm_blake3_hasher Hasher;; };; ```; ```c; typedef struct {; // private fields; } llvm_blake3_hasher;; ```. An incremental BLAKE3 hashing state, which can accept any number of; updates. This implementation doesn't allocate any heap memory, but; `sizeof(llvm_blake3_hasher)` itself is relatively large, currently 1912 bytes; on x86-64. This size can be reduced by restricting the maximum input; length, as described in Section 5.4 of [the BLAKE3; spec](https://github.com/BLAKE3-team/BLAKE3-specs/blob/master/blake3.pdf),; but this implementation doesn't currently support that strategy. ## Common API Functions. ```c++; BLAKE3::BLAKE3();. void BLAKE3::init();; ```; ```c; void llvm_blake3_hasher_init(; llvm_blake3_hasher *self);; ```. Initialize a `llvm_blake3_hasher` in the default hashing mode. ---. ```c++; void BLAKE3::update(ArrayRef<uint8_t> Data);. void BLAKE3::update(StringRef Str);; ```; ```c; void llvm_blake3_hasher_update(; llvm_blake3_hasher *self,; const void *input,; size_t input_len);; ```. Add input to the hasher. This can be called any number of times. ---. ```c++; template <size_t NumBytes = LLVM_BLAKE3_OUT_LEN>; using B",MatchSource.DOCS,interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md:2733,Deployability,update,update,2733,"; i < LLVM_BLAKE3_OUT_LEN; i++) {; printf(""%02x"", output[i]);; }; printf(""\n"");; return 0;; }; ```. # API. ## The Class/Struct. ```c++; class BLAKE3 {; // API; private:; llvm_blake3_hasher Hasher;; };; ```; ```c; typedef struct {; // private fields; } llvm_blake3_hasher;; ```. An incremental BLAKE3 hashing state, which can accept any number of; updates. This implementation doesn't allocate any heap memory, but; `sizeof(llvm_blake3_hasher)` itself is relatively large, currently 1912 bytes; on x86-64. This size can be reduced by restricting the maximum input; length, as described in Section 5.4 of [the BLAKE3; spec](https://github.com/BLAKE3-team/BLAKE3-specs/blob/master/blake3.pdf),; but this implementation doesn't currently support that strategy. ## Common API Functions. ```c++; BLAKE3::BLAKE3();. void BLAKE3::init();; ```; ```c; void llvm_blake3_hasher_init(; llvm_blake3_hasher *self);; ```. Initialize a `llvm_blake3_hasher` in the default hashing mode. ---. ```c++; void BLAKE3::update(ArrayRef<uint8_t> Data);. void BLAKE3::update(StringRef Str);; ```; ```c; void llvm_blake3_hasher_update(; llvm_blake3_hasher *self,; const void *input,; size_t input_len);; ```. Add input to the hasher. This can be called any number of times. ---. ```c++; template <size_t NumBytes = LLVM_BLAKE3_OUT_LEN>; using BLAKE3Result = std::array<uint8_t, NumBytes>;. template <size_t NumBytes = LLVM_BLAKE3_OUT_LEN>; void BLAKE3::final(BLAKE3Result<NumBytes> &Result);. template <size_t NumBytes = LLVM_BLAKE3_OUT_LEN>; BLAKE3Result<NumBytes> BLAKE3::final();; ```; ```c; void llvm_blake3_hasher_finalize(; const llvm_blake3_hasher *self,; uint8_t *out,; size_t out_len);; ```. Finalize the hasher and return an output of any length, given in bytes.; This doesn't modify the hasher itself, and it's possible to finalize; again after adding more input. The constant `LLVM_BLAKE3_OUT_LEN` provides; the default output length, 32 bytes, which is recommended for most; callers. Outputs shorter than the defaul",MatchSource.DOCS,interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md:2779,Deployability,update,update,2779,"PI. ## The Class/Struct. ```c++; class BLAKE3 {; // API; private:; llvm_blake3_hasher Hasher;; };; ```; ```c; typedef struct {; // private fields; } llvm_blake3_hasher;; ```. An incremental BLAKE3 hashing state, which can accept any number of; updates. This implementation doesn't allocate any heap memory, but; `sizeof(llvm_blake3_hasher)` itself is relatively large, currently 1912 bytes; on x86-64. This size can be reduced by restricting the maximum input; length, as described in Section 5.4 of [the BLAKE3; spec](https://github.com/BLAKE3-team/BLAKE3-specs/blob/master/blake3.pdf),; but this implementation doesn't currently support that strategy. ## Common API Functions. ```c++; BLAKE3::BLAKE3();. void BLAKE3::init();; ```; ```c; void llvm_blake3_hasher_init(; llvm_blake3_hasher *self);; ```. Initialize a `llvm_blake3_hasher` in the default hashing mode. ---. ```c++; void BLAKE3::update(ArrayRef<uint8_t> Data);. void BLAKE3::update(StringRef Str);; ```; ```c; void llvm_blake3_hasher_update(; llvm_blake3_hasher *self,; const void *input,; size_t input_len);; ```. Add input to the hasher. This can be called any number of times. ---. ```c++; template <size_t NumBytes = LLVM_BLAKE3_OUT_LEN>; using BLAKE3Result = std::array<uint8_t, NumBytes>;. template <size_t NumBytes = LLVM_BLAKE3_OUT_LEN>; void BLAKE3::final(BLAKE3Result<NumBytes> &Result);. template <size_t NumBytes = LLVM_BLAKE3_OUT_LEN>; BLAKE3Result<NumBytes> BLAKE3::final();; ```; ```c; void llvm_blake3_hasher_finalize(; const llvm_blake3_hasher *self,; uint8_t *out,; size_t out_len);; ```. Finalize the hasher and return an output of any length, given in bytes.; This doesn't modify the hasher itself, and it's possible to finalize; again after adding more input. The constant `LLVM_BLAKE3_OUT_LEN` provides; the default output length, 32 bytes, which is recommended for most; callers. Outputs shorter than the default length of 32 bytes (256 bits) provide; less security. An N-bit BLAKE3 output is intended to provide N ",MatchSource.DOCS,interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md:2122,Energy Efficiency,allocate,allocate,2122,"her_init(&hasher);. // Read input bytes from stdin.; unsigned char buf[65536];; while (1) {; ssize_t n = read(STDIN_FILENO, buf, sizeof(buf));; if (n > 0) {; llvm_blake3_hasher_update(&hasher, buf, n);; } else if (n == 0) {; break; // end of file; } else {; fprintf(stderr, ""read failed: %s\n"", strerror(errno));; exit(1);; }; }. // Finalize the hash. LLVM_BLAKE3_OUT_LEN is the default output length, 32 bytes.; uint8_t output[LLVM_BLAKE3_OUT_LEN];; llvm_blake3_hasher_finalize(&hasher, output, LLVM_BLAKE3_OUT_LEN);. // Print the hash as hexadecimal.; for (size_t i = 0; i < LLVM_BLAKE3_OUT_LEN; i++) {; printf(""%02x"", output[i]);; }; printf(""\n"");; return 0;; }; ```. # API. ## The Class/Struct. ```c++; class BLAKE3 {; // API; private:; llvm_blake3_hasher Hasher;; };; ```; ```c; typedef struct {; // private fields; } llvm_blake3_hasher;; ```. An incremental BLAKE3 hashing state, which can accept any number of; updates. This implementation doesn't allocate any heap memory, but; `sizeof(llvm_blake3_hasher)` itself is relatively large, currently 1912 bytes; on x86-64. This size can be reduced by restricting the maximum input; length, as described in Section 5.4 of [the BLAKE3; spec](https://github.com/BLAKE3-team/BLAKE3-specs/blob/master/blake3.pdf),; but this implementation doesn't currently support that strategy. ## Common API Functions. ```c++; BLAKE3::BLAKE3();. void BLAKE3::init();; ```; ```c; void llvm_blake3_hasher_init(; llvm_blake3_hasher *self);; ```. Initialize a `llvm_blake3_hasher` in the default hashing mode. ---. ```c++; void BLAKE3::update(ArrayRef<uint8_t> Data);. void BLAKE3::update(StringRef Str);; ```; ```c; void llvm_blake3_hasher_update(; llvm_blake3_hasher *self,; const void *input,; size_t input_len);; ```. Add input to the hasher. This can be called any number of times. ---. ```c++; template <size_t NumBytes = LLVM_BLAKE3_OUT_LEN>; using BLAKE3Result = std::array<uint8_t, NumBytes>;. template <size_t NumBytes = LLVM_BLAKE3_OUT_LEN>; void BLAKE3::final",MatchSource.DOCS,interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md:2260,Energy Efficiency,reduce,reduced,2260,", buf, sizeof(buf));; if (n > 0) {; llvm_blake3_hasher_update(&hasher, buf, n);; } else if (n == 0) {; break; // end of file; } else {; fprintf(stderr, ""read failed: %s\n"", strerror(errno));; exit(1);; }; }. // Finalize the hash. LLVM_BLAKE3_OUT_LEN is the default output length, 32 bytes.; uint8_t output[LLVM_BLAKE3_OUT_LEN];; llvm_blake3_hasher_finalize(&hasher, output, LLVM_BLAKE3_OUT_LEN);. // Print the hash as hexadecimal.; for (size_t i = 0; i < LLVM_BLAKE3_OUT_LEN; i++) {; printf(""%02x"", output[i]);; }; printf(""\n"");; return 0;; }; ```. # API. ## The Class/Struct. ```c++; class BLAKE3 {; // API; private:; llvm_blake3_hasher Hasher;; };; ```; ```c; typedef struct {; // private fields; } llvm_blake3_hasher;; ```. An incremental BLAKE3 hashing state, which can accept any number of; updates. This implementation doesn't allocate any heap memory, but; `sizeof(llvm_blake3_hasher)` itself is relatively large, currently 1912 bytes; on x86-64. This size can be reduced by restricting the maximum input; length, as described in Section 5.4 of [the BLAKE3; spec](https://github.com/BLAKE3-team/BLAKE3-specs/blob/master/blake3.pdf),; but this implementation doesn't currently support that strategy. ## Common API Functions. ```c++; BLAKE3::BLAKE3();. void BLAKE3::init();; ```; ```c; void llvm_blake3_hasher_init(; llvm_blake3_hasher *self);; ```. Initialize a `llvm_blake3_hasher` in the default hashing mode. ---. ```c++; void BLAKE3::update(ArrayRef<uint8_t> Data);. void BLAKE3::update(StringRef Str);; ```; ```c; void llvm_blake3_hasher_update(; llvm_blake3_hasher *self,; const void *input,; size_t input_len);; ```. Add input to the hasher. This can be called any number of times. ---. ```c++; template <size_t NumBytes = LLVM_BLAKE3_OUT_LEN>; using BLAKE3Result = std::array<uint8_t, NumBytes>;. template <size_t NumBytes = LLVM_BLAKE3_OUT_LEN>; void BLAKE3::final(BLAKE3Result<NumBytes> &Result);. template <size_t NumBytes = LLVM_BLAKE3_OUT_LEN>; BLAKE3Result<NumBytes> BLAKE3::final",MatchSource.DOCS,interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md:6338,Energy Efficiency,efficient,efficiently,6338," *context,; size_t context_len);; ```. As `llvm_blake3_hasher_init_derive_key` above, except that the context string; is given as a pointer to an array of arbitrary bytes with a provided; length. This is intended for writing language bindings, where C string; conversion would add unnecessary overhead and new error cases. Unicode; strings should be encoded as UTF-8. Application code in C should prefer `llvm_blake3_hasher_init_derive_key`,; which takes the context as a C string. If you need to use arbitrary; bytes as a context string in application code, consider whether you're; violating the requirement that context strings should be hardcoded. ---. ```c; void llvm_blake3_hasher_finalize_seek(; const llvm_blake3_hasher *self,; uint64_t seek,; uint8_t *out,; size_t out_len);; ```. The same as `llvm_blake3_hasher_finalize`, but with an additional `seek`; parameter for the starting byte position in the output stream. To; efficiently stream a large output without allocating memory, call this; function in a loop, incrementing `seek` by the output length each time. ---. ```c; void llvm_blake3_hasher_reset(; llvm_blake3_hasher *self);; ```. Reset the hasher to its initial state, prior to any calls to; `llvm_blake3_hasher_update`. Currently this is no different from calling; `llvm_blake3_hasher_init` or similar again. However, if this implementation gains; multithreading support in the future, and if `llvm_blake3_hasher` holds (optional); threading resources, this function will reuse those resources. # Building. This implementation is just C and assembly files. ## x86. Dynamic dispatch is enabled by default on x86. The implementation will; query the CPU at runtime to detect SIMD support, and it will use the; widest instruction set available. By default, `blake3_dispatch.c`; expects to be linked with code for five different instruction sets:; portable C, SSE2, SSE4.1, AVX2, and AVX-512. For each of the x86 SIMD instruction sets, four versions are available:; three flavors of ",MatchSource.DOCS,interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md:7272,Modifiability,portab,portable,7272," as `llvm_blake3_hasher_finalize`, but with an additional `seek`; parameter for the starting byte position in the output stream. To; efficiently stream a large output without allocating memory, call this; function in a loop, incrementing `seek` by the output length each time. ---. ```c; void llvm_blake3_hasher_reset(; llvm_blake3_hasher *self);; ```. Reset the hasher to its initial state, prior to any calls to; `llvm_blake3_hasher_update`. Currently this is no different from calling; `llvm_blake3_hasher_init` or similar again. However, if this implementation gains; multithreading support in the future, and if `llvm_blake3_hasher` holds (optional); threading resources, this function will reuse those resources. # Building. This implementation is just C and assembly files. ## x86. Dynamic dispatch is enabled by default on x86. The implementation will; query the CPU at runtime to detect SIMD support, and it will use the; widest instruction set available. By default, `blake3_dispatch.c`; expects to be linked with code for five different instruction sets:; portable C, SSE2, SSE4.1, AVX2, and AVX-512. For each of the x86 SIMD instruction sets, four versions are available:; three flavors of assembly (Unix, Windows MSVC, and Windows GNU) and one; version using C intrinsics. The assembly versions are generally; preferred. They perform better, they perform more consistently across; different compilers, and they build more quickly. On the other hand, the; assembly versions are x86\_64-only, and you need to select the right; flavor for your target platform. ## ARM NEON. The NEON implementation is enabled by default on AArch64, but not on; other ARM targets, since not all of them support it. To enable it, set; `BLAKE3_USE_NEON=1`. To explicitiy disable using NEON instructions on AArch64, set; `BLAKE3_USE_NEON=0`. ## Other Platforms. The portable implementation should work on most other architectures. # Multithreading. The implementation doesn't currently support multithreading.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md:8060,Modifiability,portab,portable,8060," as `llvm_blake3_hasher_finalize`, but with an additional `seek`; parameter for the starting byte position in the output stream. To; efficiently stream a large output without allocating memory, call this; function in a loop, incrementing `seek` by the output length each time. ---. ```c; void llvm_blake3_hasher_reset(; llvm_blake3_hasher *self);; ```. Reset the hasher to its initial state, prior to any calls to; `llvm_blake3_hasher_update`. Currently this is no different from calling; `llvm_blake3_hasher_init` or similar again. However, if this implementation gains; multithreading support in the future, and if `llvm_blake3_hasher` holds (optional); threading resources, this function will reuse those resources. # Building. This implementation is just C and assembly files. ## x86. Dynamic dispatch is enabled by default on x86. The implementation will; query the CPU at runtime to detect SIMD support, and it will use the; widest instruction set available. By default, `blake3_dispatch.c`; expects to be linked with code for five different instruction sets:; portable C, SSE2, SSE4.1, AVX2, and AVX-512. For each of the x86 SIMD instruction sets, four versions are available:; three flavors of assembly (Unix, Windows MSVC, and Windows GNU) and one; version using C intrinsics. The assembly versions are generally; preferred. They perform better, they perform more consistently across; different compilers, and they build more quickly. On the other hand, the; assembly versions are x86\_64-only, and you need to select the right; flavor for your target platform. ## ARM NEON. The NEON implementation is enabled by default on AArch64, but not on; other ARM targets, since not all of them support it. To enable it, set; `BLAKE3_USE_NEON=1`. To explicitiy disable using NEON instructions on AArch64, set; `BLAKE3_USE_NEON=0`. ## Other Platforms. The portable implementation should work on most other architectures. # Multithreading. The implementation doesn't currently support multithreading.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md:7544,Performance,perform,perform,7544," as `llvm_blake3_hasher_finalize`, but with an additional `seek`; parameter for the starting byte position in the output stream. To; efficiently stream a large output without allocating memory, call this; function in a loop, incrementing `seek` by the output length each time. ---. ```c; void llvm_blake3_hasher_reset(; llvm_blake3_hasher *self);; ```. Reset the hasher to its initial state, prior to any calls to; `llvm_blake3_hasher_update`. Currently this is no different from calling; `llvm_blake3_hasher_init` or similar again. However, if this implementation gains; multithreading support in the future, and if `llvm_blake3_hasher` holds (optional); threading resources, this function will reuse those resources. # Building. This implementation is just C and assembly files. ## x86. Dynamic dispatch is enabled by default on x86. The implementation will; query the CPU at runtime to detect SIMD support, and it will use the; widest instruction set available. By default, `blake3_dispatch.c`; expects to be linked with code for five different instruction sets:; portable C, SSE2, SSE4.1, AVX2, and AVX-512. For each of the x86 SIMD instruction sets, four versions are available:; three flavors of assembly (Unix, Windows MSVC, and Windows GNU) and one; version using C intrinsics. The assembly versions are generally; preferred. They perform better, they perform more consistently across; different compilers, and they build more quickly. On the other hand, the; assembly versions are x86\_64-only, and you need to select the right; flavor for your target platform. ## ARM NEON. The NEON implementation is enabled by default on AArch64, but not on; other ARM targets, since not all of them support it. To enable it, set; `BLAKE3_USE_NEON=1`. To explicitiy disable using NEON instructions on AArch64, set; `BLAKE3_USE_NEON=0`. ## Other Platforms. The portable implementation should work on most other architectures. # Multithreading. The implementation doesn't currently support multithreading.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md:7565,Performance,perform,perform,7565," as `llvm_blake3_hasher_finalize`, but with an additional `seek`; parameter for the starting byte position in the output stream. To; efficiently stream a large output without allocating memory, call this; function in a loop, incrementing `seek` by the output length each time. ---. ```c; void llvm_blake3_hasher_reset(; llvm_blake3_hasher *self);; ```. Reset the hasher to its initial state, prior to any calls to; `llvm_blake3_hasher_update`. Currently this is no different from calling; `llvm_blake3_hasher_init` or similar again. However, if this implementation gains; multithreading support in the future, and if `llvm_blake3_hasher` holds (optional); threading resources, this function will reuse those resources. # Building. This implementation is just C and assembly files. ## x86. Dynamic dispatch is enabled by default on x86. The implementation will; query the CPU at runtime to detect SIMD support, and it will use the; widest instruction set available. By default, `blake3_dispatch.c`; expects to be linked with code for five different instruction sets:; portable C, SSE2, SSE4.1, AVX2, and AVX-512. For each of the x86 SIMD instruction sets, four versions are available:; three flavors of assembly (Unix, Windows MSVC, and Windows GNU) and one; version using C intrinsics. The assembly versions are generally; preferred. They perform better, they perform more consistently across; different compilers, and they build more quickly. On the other hand, the; assembly versions are x86\_64-only, and you need to select the right; flavor for your target platform. ## ARM NEON. The NEON implementation is enabled by default on AArch64, but not on; other ARM targets, since not all of them support it. To enable it, set; `BLAKE3_USE_NEON=1`. To explicitiy disable using NEON instructions on AArch64, set; `BLAKE3_USE_NEON=0`. ## Other Platforms. The portable implementation should work on most other architectures. # Multithreading. The implementation doesn't currently support multithreading.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md:7094,Safety,detect,detect,7094,"eek(; const llvm_blake3_hasher *self,; uint64_t seek,; uint8_t *out,; size_t out_len);; ```. The same as `llvm_blake3_hasher_finalize`, but with an additional `seek`; parameter for the starting byte position in the output stream. To; efficiently stream a large output without allocating memory, call this; function in a loop, incrementing `seek` by the output length each time. ---. ```c; void llvm_blake3_hasher_reset(; llvm_blake3_hasher *self);; ```. Reset the hasher to its initial state, prior to any calls to; `llvm_blake3_hasher_update`. Currently this is no different from calling; `llvm_blake3_hasher_init` or similar again. However, if this implementation gains; multithreading support in the future, and if `llvm_blake3_hasher` holds (optional); threading resources, this function will reuse those resources. # Building. This implementation is just C and assembly files. ## x86. Dynamic dispatch is enabled by default on x86. The implementation will; query the CPU at runtime to detect SIMD support, and it will use the; widest instruction set available. By default, `blake3_dispatch.c`; expects to be linked with code for five different instruction sets:; portable C, SSE2, SSE4.1, AVX2, and AVX-512. For each of the x86 SIMD instruction sets, four versions are available:; three flavors of assembly (Unix, Windows MSVC, and Windows GNU) and one; version using C intrinsics. The assembly versions are generally; preferred. They perform better, they perform more consistently across; different compilers, and they build more quickly. On the other hand, the; assembly versions are x86\_64-only, and you need to select the right; flavor for your target platform. ## ARM NEON. The NEON implementation is enabled by default on AArch64, but not on; other ARM targets, since not all of them support it. To enable it, set; `BLAKE3_USE_NEON=1`. To explicitiy disable using NEON instructions on AArch64, set; `BLAKE3_USE_NEON=0`. ## Other Platforms. The portable implementation should work on most o",MatchSource.DOCS,interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md:130,Security,hash,hashes,130,"Implementation of BLAKE3, originating from https://github.com/BLAKE3-team/BLAKE3/tree/1.3.1/c. # Example. An example program that hashes bytes from standard input and prints the; result:. Using the C++ API:. ```c++; #include ""llvm/Support/BLAKE3.h""; #include <errno.h>; #include <stdio.h>; #include <stdlib.h>; #include <string.h>; #include <unistd.h>. int main() {; // Initialize the hasher.; llvm::BLAKE3 hasher;. // Read input bytes from stdin.; char buf[65536];; while (1) {; ssize_t n = read(STDIN_FILENO, buf, sizeof(buf));; if (n > 0) {; hasher.update(llvm::StringRef(buf, n));; } else if (n == 0) {; break; // end of file; } else {; fprintf(stderr, ""read failed: %s\n"", strerror(errno));; exit(1);; }; }. // Finalize the hash. Default output length is 32 bytes.; auto output = hasher.final();. // Print the hash as hexadecimal.; for (uint8_t byte : output) {; printf(""%02x"", byte);; }; printf(""\n"");; return 0;; }; ```. Using the C API:. ```c; #include ""llvm-c/blake3.h""; #include <errno.h>; #include <stdio.h>; #include <stdlib.h>; #include <string.h>; #include <unistd.h>. int main() {; // Initialize the hasher.; llvm_blake3_hasher hasher;; llvm_blake3_hasher_init(&hasher);. // Read input bytes from stdin.; unsigned char buf[65536];; while (1) {; ssize_t n = read(STDIN_FILENO, buf, sizeof(buf));; if (n > 0) {; llvm_blake3_hasher_update(&hasher, buf, n);; } else if (n == 0) {; break; // end of file; } else {; fprintf(stderr, ""read failed: %s\n"", strerror(errno));; exit(1);; }; }. // Finalize the hash. LLVM_BLAKE3_OUT_LEN is the default output length, 32 bytes.; uint8_t output[LLVM_BLAKE3_OUT_LEN];; llvm_blake3_hasher_finalize(&hasher, output, LLVM_BLAKE3_OUT_LEN);. // Print the hash as hexadecimal.; for (size_t i = 0; i < LLVM_BLAKE3_OUT_LEN; i++) {; printf(""%02x"", output[i]);; }; printf(""\n"");; return 0;; }; ```. # API. ## The Class/Struct. ```c++; class BLAKE3 {; // API; private:; llvm_blake3_hasher Hasher;; };; ```; ```c; typedef struct {; // private fields; } llvm_blake3",MatchSource.DOCS,interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md:385,Security,hash,hasher,385,"Implementation of BLAKE3, originating from https://github.com/BLAKE3-team/BLAKE3/tree/1.3.1/c. # Example. An example program that hashes bytes from standard input and prints the; result:. Using the C++ API:. ```c++; #include ""llvm/Support/BLAKE3.h""; #include <errno.h>; #include <stdio.h>; #include <stdlib.h>; #include <string.h>; #include <unistd.h>. int main() {; // Initialize the hasher.; llvm::BLAKE3 hasher;. // Read input bytes from stdin.; char buf[65536];; while (1) {; ssize_t n = read(STDIN_FILENO, buf, sizeof(buf));; if (n > 0) {; hasher.update(llvm::StringRef(buf, n));; } else if (n == 0) {; break; // end of file; } else {; fprintf(stderr, ""read failed: %s\n"", strerror(errno));; exit(1);; }; }. // Finalize the hash. Default output length is 32 bytes.; auto output = hasher.final();. // Print the hash as hexadecimal.; for (uint8_t byte : output) {; printf(""%02x"", byte);; }; printf(""\n"");; return 0;; }; ```. Using the C API:. ```c; #include ""llvm-c/blake3.h""; #include <errno.h>; #include <stdio.h>; #include <stdlib.h>; #include <string.h>; #include <unistd.h>. int main() {; // Initialize the hasher.; llvm_blake3_hasher hasher;; llvm_blake3_hasher_init(&hasher);. // Read input bytes from stdin.; unsigned char buf[65536];; while (1) {; ssize_t n = read(STDIN_FILENO, buf, sizeof(buf));; if (n > 0) {; llvm_blake3_hasher_update(&hasher, buf, n);; } else if (n == 0) {; break; // end of file; } else {; fprintf(stderr, ""read failed: %s\n"", strerror(errno));; exit(1);; }; }. // Finalize the hash. LLVM_BLAKE3_OUT_LEN is the default output length, 32 bytes.; uint8_t output[LLVM_BLAKE3_OUT_LEN];; llvm_blake3_hasher_finalize(&hasher, output, LLVM_BLAKE3_OUT_LEN);. // Print the hash as hexadecimal.; for (size_t i = 0; i < LLVM_BLAKE3_OUT_LEN; i++) {; printf(""%02x"", output[i]);; }; printf(""\n"");; return 0;; }; ```. # API. ## The Class/Struct. ```c++; class BLAKE3 {; // API; private:; llvm_blake3_hasher Hasher;; };; ```; ```c; typedef struct {; // private fields; } llvm_blake3",MatchSource.DOCS,interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md:407,Security,hash,hasher,407,"Implementation of BLAKE3, originating from https://github.com/BLAKE3-team/BLAKE3/tree/1.3.1/c. # Example. An example program that hashes bytes from standard input and prints the; result:. Using the C++ API:. ```c++; #include ""llvm/Support/BLAKE3.h""; #include <errno.h>; #include <stdio.h>; #include <stdlib.h>; #include <string.h>; #include <unistd.h>. int main() {; // Initialize the hasher.; llvm::BLAKE3 hasher;. // Read input bytes from stdin.; char buf[65536];; while (1) {; ssize_t n = read(STDIN_FILENO, buf, sizeof(buf));; if (n > 0) {; hasher.update(llvm::StringRef(buf, n));; } else if (n == 0) {; break; // end of file; } else {; fprintf(stderr, ""read failed: %s\n"", strerror(errno));; exit(1);; }; }. // Finalize the hash. Default output length is 32 bytes.; auto output = hasher.final();. // Print the hash as hexadecimal.; for (uint8_t byte : output) {; printf(""%02x"", byte);; }; printf(""\n"");; return 0;; }; ```. Using the C API:. ```c; #include ""llvm-c/blake3.h""; #include <errno.h>; #include <stdio.h>; #include <stdlib.h>; #include <string.h>; #include <unistd.h>. int main() {; // Initialize the hasher.; llvm_blake3_hasher hasher;; llvm_blake3_hasher_init(&hasher);. // Read input bytes from stdin.; unsigned char buf[65536];; while (1) {; ssize_t n = read(STDIN_FILENO, buf, sizeof(buf));; if (n > 0) {; llvm_blake3_hasher_update(&hasher, buf, n);; } else if (n == 0) {; break; // end of file; } else {; fprintf(stderr, ""read failed: %s\n"", strerror(errno));; exit(1);; }; }. // Finalize the hash. LLVM_BLAKE3_OUT_LEN is the default output length, 32 bytes.; uint8_t output[LLVM_BLAKE3_OUT_LEN];; llvm_blake3_hasher_finalize(&hasher, output, LLVM_BLAKE3_OUT_LEN);. // Print the hash as hexadecimal.; for (size_t i = 0; i < LLVM_BLAKE3_OUT_LEN; i++) {; printf(""%02x"", output[i]);; }; printf(""\n"");; return 0;; }; ```. # API. ## The Class/Struct. ```c++; class BLAKE3 {; // API; private:; llvm_blake3_hasher Hasher;; };; ```; ```c; typedef struct {; // private fields; } llvm_blake3",MatchSource.DOCS,interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md:545,Security,hash,hasher,545,"Implementation of BLAKE3, originating from https://github.com/BLAKE3-team/BLAKE3/tree/1.3.1/c. # Example. An example program that hashes bytes from standard input and prints the; result:. Using the C++ API:. ```c++; #include ""llvm/Support/BLAKE3.h""; #include <errno.h>; #include <stdio.h>; #include <stdlib.h>; #include <string.h>; #include <unistd.h>. int main() {; // Initialize the hasher.; llvm::BLAKE3 hasher;. // Read input bytes from stdin.; char buf[65536];; while (1) {; ssize_t n = read(STDIN_FILENO, buf, sizeof(buf));; if (n > 0) {; hasher.update(llvm::StringRef(buf, n));; } else if (n == 0) {; break; // end of file; } else {; fprintf(stderr, ""read failed: %s\n"", strerror(errno));; exit(1);; }; }. // Finalize the hash. Default output length is 32 bytes.; auto output = hasher.final();. // Print the hash as hexadecimal.; for (uint8_t byte : output) {; printf(""%02x"", byte);; }; printf(""\n"");; return 0;; }; ```. Using the C API:. ```c; #include ""llvm-c/blake3.h""; #include <errno.h>; #include <stdio.h>; #include <stdlib.h>; #include <string.h>; #include <unistd.h>. int main() {; // Initialize the hasher.; llvm_blake3_hasher hasher;; llvm_blake3_hasher_init(&hasher);. // Read input bytes from stdin.; unsigned char buf[65536];; while (1) {; ssize_t n = read(STDIN_FILENO, buf, sizeof(buf));; if (n > 0) {; llvm_blake3_hasher_update(&hasher, buf, n);; } else if (n == 0) {; break; // end of file; } else {; fprintf(stderr, ""read failed: %s\n"", strerror(errno));; exit(1);; }; }. // Finalize the hash. LLVM_BLAKE3_OUT_LEN is the default output length, 32 bytes.; uint8_t output[LLVM_BLAKE3_OUT_LEN];; llvm_blake3_hasher_finalize(&hasher, output, LLVM_BLAKE3_OUT_LEN);. // Print the hash as hexadecimal.; for (size_t i = 0; i < LLVM_BLAKE3_OUT_LEN; i++) {; printf(""%02x"", output[i]);; }; printf(""\n"");; return 0;; }; ```. # API. ## The Class/Struct. ```c++; class BLAKE3 {; // API; private:; llvm_blake3_hasher Hasher;; };; ```; ```c; typedef struct {; // private fields; } llvm_blake3",MatchSource.DOCS,interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md:729,Security,hash,hash,729,"Implementation of BLAKE3, originating from https://github.com/BLAKE3-team/BLAKE3/tree/1.3.1/c. # Example. An example program that hashes bytes from standard input and prints the; result:. Using the C++ API:. ```c++; #include ""llvm/Support/BLAKE3.h""; #include <errno.h>; #include <stdio.h>; #include <stdlib.h>; #include <string.h>; #include <unistd.h>. int main() {; // Initialize the hasher.; llvm::BLAKE3 hasher;. // Read input bytes from stdin.; char buf[65536];; while (1) {; ssize_t n = read(STDIN_FILENO, buf, sizeof(buf));; if (n > 0) {; hasher.update(llvm::StringRef(buf, n));; } else if (n == 0) {; break; // end of file; } else {; fprintf(stderr, ""read failed: %s\n"", strerror(errno));; exit(1);; }; }. // Finalize the hash. Default output length is 32 bytes.; auto output = hasher.final();. // Print the hash as hexadecimal.; for (uint8_t byte : output) {; printf(""%02x"", byte);; }; printf(""\n"");; return 0;; }; ```. Using the C API:. ```c; #include ""llvm-c/blake3.h""; #include <errno.h>; #include <stdio.h>; #include <stdlib.h>; #include <string.h>; #include <unistd.h>. int main() {; // Initialize the hasher.; llvm_blake3_hasher hasher;; llvm_blake3_hasher_init(&hasher);. // Read input bytes from stdin.; unsigned char buf[65536];; while (1) {; ssize_t n = read(STDIN_FILENO, buf, sizeof(buf));; if (n > 0) {; llvm_blake3_hasher_update(&hasher, buf, n);; } else if (n == 0) {; break; // end of file; } else {; fprintf(stderr, ""read failed: %s\n"", strerror(errno));; exit(1);; }; }. // Finalize the hash. LLVM_BLAKE3_OUT_LEN is the default output length, 32 bytes.; uint8_t output[LLVM_BLAKE3_OUT_LEN];; llvm_blake3_hasher_finalize(&hasher, output, LLVM_BLAKE3_OUT_LEN);. // Print the hash as hexadecimal.; for (size_t i = 0; i < LLVM_BLAKE3_OUT_LEN; i++) {; printf(""%02x"", output[i]);; }; printf(""\n"");; return 0;; }; ```. # API. ## The Class/Struct. ```c++; class BLAKE3 {; // API; private:; llvm_blake3_hasher Hasher;; };; ```; ```c; typedef struct {; // private fields; } llvm_blake3",MatchSource.DOCS,interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md:785,Security,hash,hasher,785,"Implementation of BLAKE3, originating from https://github.com/BLAKE3-team/BLAKE3/tree/1.3.1/c. # Example. An example program that hashes bytes from standard input and prints the; result:. Using the C++ API:. ```c++; #include ""llvm/Support/BLAKE3.h""; #include <errno.h>; #include <stdio.h>; #include <stdlib.h>; #include <string.h>; #include <unistd.h>. int main() {; // Initialize the hasher.; llvm::BLAKE3 hasher;. // Read input bytes from stdin.; char buf[65536];; while (1) {; ssize_t n = read(STDIN_FILENO, buf, sizeof(buf));; if (n > 0) {; hasher.update(llvm::StringRef(buf, n));; } else if (n == 0) {; break; // end of file; } else {; fprintf(stderr, ""read failed: %s\n"", strerror(errno));; exit(1);; }; }. // Finalize the hash. Default output length is 32 bytes.; auto output = hasher.final();. // Print the hash as hexadecimal.; for (uint8_t byte : output) {; printf(""%02x"", byte);; }; printf(""\n"");; return 0;; }; ```. Using the C API:. ```c; #include ""llvm-c/blake3.h""; #include <errno.h>; #include <stdio.h>; #include <stdlib.h>; #include <string.h>; #include <unistd.h>. int main() {; // Initialize the hasher.; llvm_blake3_hasher hasher;; llvm_blake3_hasher_init(&hasher);. // Read input bytes from stdin.; unsigned char buf[65536];; while (1) {; ssize_t n = read(STDIN_FILENO, buf, sizeof(buf));; if (n > 0) {; llvm_blake3_hasher_update(&hasher, buf, n);; } else if (n == 0) {; break; // end of file; } else {; fprintf(stderr, ""read failed: %s\n"", strerror(errno));; exit(1);; }; }. // Finalize the hash. LLVM_BLAKE3_OUT_LEN is the default output length, 32 bytes.; uint8_t output[LLVM_BLAKE3_OUT_LEN];; llvm_blake3_hasher_finalize(&hasher, output, LLVM_BLAKE3_OUT_LEN);. // Print the hash as hexadecimal.; for (size_t i = 0; i < LLVM_BLAKE3_OUT_LEN; i++) {; printf(""%02x"", output[i]);; }; printf(""\n"");; return 0;; }; ```. # API. ## The Class/Struct. ```c++; class BLAKE3 {; // API; private:; llvm_blake3_hasher Hasher;; };; ```; ```c; typedef struct {; // private fields; } llvm_blake3",MatchSource.DOCS,interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md:815,Security,hash,hash,815,"Implementation of BLAKE3, originating from https://github.com/BLAKE3-team/BLAKE3/tree/1.3.1/c. # Example. An example program that hashes bytes from standard input and prints the; result:. Using the C++ API:. ```c++; #include ""llvm/Support/BLAKE3.h""; #include <errno.h>; #include <stdio.h>; #include <stdlib.h>; #include <string.h>; #include <unistd.h>. int main() {; // Initialize the hasher.; llvm::BLAKE3 hasher;. // Read input bytes from stdin.; char buf[65536];; while (1) {; ssize_t n = read(STDIN_FILENO, buf, sizeof(buf));; if (n > 0) {; hasher.update(llvm::StringRef(buf, n));; } else if (n == 0) {; break; // end of file; } else {; fprintf(stderr, ""read failed: %s\n"", strerror(errno));; exit(1);; }; }. // Finalize the hash. Default output length is 32 bytes.; auto output = hasher.final();. // Print the hash as hexadecimal.; for (uint8_t byte : output) {; printf(""%02x"", byte);; }; printf(""\n"");; return 0;; }; ```. Using the C API:. ```c; #include ""llvm-c/blake3.h""; #include <errno.h>; #include <stdio.h>; #include <stdlib.h>; #include <string.h>; #include <unistd.h>. int main() {; // Initialize the hasher.; llvm_blake3_hasher hasher;; llvm_blake3_hasher_init(&hasher);. // Read input bytes from stdin.; unsigned char buf[65536];; while (1) {; ssize_t n = read(STDIN_FILENO, buf, sizeof(buf));; if (n > 0) {; llvm_blake3_hasher_update(&hasher, buf, n);; } else if (n == 0) {; break; // end of file; } else {; fprintf(stderr, ""read failed: %s\n"", strerror(errno));; exit(1);; }; }. // Finalize the hash. LLVM_BLAKE3_OUT_LEN is the default output length, 32 bytes.; uint8_t output[LLVM_BLAKE3_OUT_LEN];; llvm_blake3_hasher_finalize(&hasher, output, LLVM_BLAKE3_OUT_LEN);. // Print the hash as hexadecimal.; for (size_t i = 0; i < LLVM_BLAKE3_OUT_LEN; i++) {; printf(""%02x"", output[i]);; }; printf(""\n"");; return 0;; }; ```. # API. ## The Class/Struct. ```c++; class BLAKE3 {; // API; private:; llvm_blake3_hasher Hasher;; };; ```; ```c; typedef struct {; // private fields; } llvm_blake3",MatchSource.DOCS,interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md:1115,Security,hash,hasher,1115,"le. An example program that hashes bytes from standard input and prints the; result:. Using the C++ API:. ```c++; #include ""llvm/Support/BLAKE3.h""; #include <errno.h>; #include <stdio.h>; #include <stdlib.h>; #include <string.h>; #include <unistd.h>. int main() {; // Initialize the hasher.; llvm::BLAKE3 hasher;. // Read input bytes from stdin.; char buf[65536];; while (1) {; ssize_t n = read(STDIN_FILENO, buf, sizeof(buf));; if (n > 0) {; hasher.update(llvm::StringRef(buf, n));; } else if (n == 0) {; break; // end of file; } else {; fprintf(stderr, ""read failed: %s\n"", strerror(errno));; exit(1);; }; }. // Finalize the hash. Default output length is 32 bytes.; auto output = hasher.final();. // Print the hash as hexadecimal.; for (uint8_t byte : output) {; printf(""%02x"", byte);; }; printf(""\n"");; return 0;; }; ```. Using the C API:. ```c; #include ""llvm-c/blake3.h""; #include <errno.h>; #include <stdio.h>; #include <stdlib.h>; #include <string.h>; #include <unistd.h>. int main() {; // Initialize the hasher.; llvm_blake3_hasher hasher;; llvm_blake3_hasher_init(&hasher);. // Read input bytes from stdin.; unsigned char buf[65536];; while (1) {; ssize_t n = read(STDIN_FILENO, buf, sizeof(buf));; if (n > 0) {; llvm_blake3_hasher_update(&hasher, buf, n);; } else if (n == 0) {; break; // end of file; } else {; fprintf(stderr, ""read failed: %s\n"", strerror(errno));; exit(1);; }; }. // Finalize the hash. LLVM_BLAKE3_OUT_LEN is the default output length, 32 bytes.; uint8_t output[LLVM_BLAKE3_OUT_LEN];; llvm_blake3_hasher_finalize(&hasher, output, LLVM_BLAKE3_OUT_LEN);. // Print the hash as hexadecimal.; for (size_t i = 0; i < LLVM_BLAKE3_OUT_LEN; i++) {; printf(""%02x"", output[i]);; }; printf(""\n"");; return 0;; }; ```. # API. ## The Class/Struct. ```c++; class BLAKE3 {; // API; private:; llvm_blake3_hasher Hasher;; };; ```; ```c; typedef struct {; // private fields; } llvm_blake3_hasher;; ```. An incremental BLAKE3 hashing state, which can accept any number of; updates. This imp",MatchSource.DOCS,interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md:1143,Security,hash,hasher,1143,"rd input and prints the; result:. Using the C++ API:. ```c++; #include ""llvm/Support/BLAKE3.h""; #include <errno.h>; #include <stdio.h>; #include <stdlib.h>; #include <string.h>; #include <unistd.h>. int main() {; // Initialize the hasher.; llvm::BLAKE3 hasher;. // Read input bytes from stdin.; char buf[65536];; while (1) {; ssize_t n = read(STDIN_FILENO, buf, sizeof(buf));; if (n > 0) {; hasher.update(llvm::StringRef(buf, n));; } else if (n == 0) {; break; // end of file; } else {; fprintf(stderr, ""read failed: %s\n"", strerror(errno));; exit(1);; }; }. // Finalize the hash. Default output length is 32 bytes.; auto output = hasher.final();. // Print the hash as hexadecimal.; for (uint8_t byte : output) {; printf(""%02x"", byte);; }; printf(""\n"");; return 0;; }; ```. Using the C API:. ```c; #include ""llvm-c/blake3.h""; #include <errno.h>; #include <stdio.h>; #include <stdlib.h>; #include <string.h>; #include <unistd.h>. int main() {; // Initialize the hasher.; llvm_blake3_hasher hasher;; llvm_blake3_hasher_init(&hasher);. // Read input bytes from stdin.; unsigned char buf[65536];; while (1) {; ssize_t n = read(STDIN_FILENO, buf, sizeof(buf));; if (n > 0) {; llvm_blake3_hasher_update(&hasher, buf, n);; } else if (n == 0) {; break; // end of file; } else {; fprintf(stderr, ""read failed: %s\n"", strerror(errno));; exit(1);; }; }. // Finalize the hash. LLVM_BLAKE3_OUT_LEN is the default output length, 32 bytes.; uint8_t output[LLVM_BLAKE3_OUT_LEN];; llvm_blake3_hasher_finalize(&hasher, output, LLVM_BLAKE3_OUT_LEN);. // Print the hash as hexadecimal.; for (size_t i = 0; i < LLVM_BLAKE3_OUT_LEN; i++) {; printf(""%02x"", output[i]);; }; printf(""\n"");; return 0;; }; ```. # API. ## The Class/Struct. ```c++; class BLAKE3 {; // API; private:; llvm_blake3_hasher Hasher;; };; ```; ```c; typedef struct {; // private fields; } llvm_blake3_hasher;; ```. An incremental BLAKE3 hashing state, which can accept any number of; updates. This implementation doesn't allocate any heap memory, but; `",MatchSource.DOCS,interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md:1177,Security,hash,hasher,1177,"rd input and prints the; result:. Using the C++ API:. ```c++; #include ""llvm/Support/BLAKE3.h""; #include <errno.h>; #include <stdio.h>; #include <stdlib.h>; #include <string.h>; #include <unistd.h>. int main() {; // Initialize the hasher.; llvm::BLAKE3 hasher;. // Read input bytes from stdin.; char buf[65536];; while (1) {; ssize_t n = read(STDIN_FILENO, buf, sizeof(buf));; if (n > 0) {; hasher.update(llvm::StringRef(buf, n));; } else if (n == 0) {; break; // end of file; } else {; fprintf(stderr, ""read failed: %s\n"", strerror(errno));; exit(1);; }; }. // Finalize the hash. Default output length is 32 bytes.; auto output = hasher.final();. // Print the hash as hexadecimal.; for (uint8_t byte : output) {; printf(""%02x"", byte);; }; printf(""\n"");; return 0;; }; ```. Using the C API:. ```c; #include ""llvm-c/blake3.h""; #include <errno.h>; #include <stdio.h>; #include <stdlib.h>; #include <string.h>; #include <unistd.h>. int main() {; // Initialize the hasher.; llvm_blake3_hasher hasher;; llvm_blake3_hasher_init(&hasher);. // Read input bytes from stdin.; unsigned char buf[65536];; while (1) {; ssize_t n = read(STDIN_FILENO, buf, sizeof(buf));; if (n > 0) {; llvm_blake3_hasher_update(&hasher, buf, n);; } else if (n == 0) {; break; // end of file; } else {; fprintf(stderr, ""read failed: %s\n"", strerror(errno));; exit(1);; }; }. // Finalize the hash. LLVM_BLAKE3_OUT_LEN is the default output length, 32 bytes.; uint8_t output[LLVM_BLAKE3_OUT_LEN];; llvm_blake3_hasher_finalize(&hasher, output, LLVM_BLAKE3_OUT_LEN);. // Print the hash as hexadecimal.; for (size_t i = 0; i < LLVM_BLAKE3_OUT_LEN; i++) {; printf(""%02x"", output[i]);; }; printf(""\n"");; return 0;; }; ```. # API. ## The Class/Struct. ```c++; class BLAKE3 {; // API; private:; llvm_blake3_hasher Hasher;; };; ```; ```c; typedef struct {; // private fields; } llvm_blake3_hasher;; ```. An incremental BLAKE3 hashing state, which can accept any number of; updates. This implementation doesn't allocate any heap memory, but; `",MatchSource.DOCS,interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md:1352,Security,hash,hasher,1352,"main() {; // Initialize the hasher.; llvm::BLAKE3 hasher;. // Read input bytes from stdin.; char buf[65536];; while (1) {; ssize_t n = read(STDIN_FILENO, buf, sizeof(buf));; if (n > 0) {; hasher.update(llvm::StringRef(buf, n));; } else if (n == 0) {; break; // end of file; } else {; fprintf(stderr, ""read failed: %s\n"", strerror(errno));; exit(1);; }; }. // Finalize the hash. Default output length is 32 bytes.; auto output = hasher.final();. // Print the hash as hexadecimal.; for (uint8_t byte : output) {; printf(""%02x"", byte);; }; printf(""\n"");; return 0;; }; ```. Using the C API:. ```c; #include ""llvm-c/blake3.h""; #include <errno.h>; #include <stdio.h>; #include <stdlib.h>; #include <string.h>; #include <unistd.h>. int main() {; // Initialize the hasher.; llvm_blake3_hasher hasher;; llvm_blake3_hasher_init(&hasher);. // Read input bytes from stdin.; unsigned char buf[65536];; while (1) {; ssize_t n = read(STDIN_FILENO, buf, sizeof(buf));; if (n > 0) {; llvm_blake3_hasher_update(&hasher, buf, n);; } else if (n == 0) {; break; // end of file; } else {; fprintf(stderr, ""read failed: %s\n"", strerror(errno));; exit(1);; }; }. // Finalize the hash. LLVM_BLAKE3_OUT_LEN is the default output length, 32 bytes.; uint8_t output[LLVM_BLAKE3_OUT_LEN];; llvm_blake3_hasher_finalize(&hasher, output, LLVM_BLAKE3_OUT_LEN);. // Print the hash as hexadecimal.; for (size_t i = 0; i < LLVM_BLAKE3_OUT_LEN; i++) {; printf(""%02x"", output[i]);; }; printf(""\n"");; return 0;; }; ```. # API. ## The Class/Struct. ```c++; class BLAKE3 {; // API; private:; llvm_blake3_hasher Hasher;; };; ```; ```c; typedef struct {; // private fields; } llvm_blake3_hasher;; ```. An incremental BLAKE3 hashing state, which can accept any number of; updates. This implementation doesn't allocate any heap memory, but; `sizeof(llvm_blake3_hasher)` itself is relatively large, currently 1912 bytes; on x86-64. This size can be reduced by restricting the maximum input; length, as described in Section 5.4 of [the BLAKE3; spe",MatchSource.DOCS,interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md:1513,Security,hash,hash,1513,"NO, buf, sizeof(buf));; if (n > 0) {; hasher.update(llvm::StringRef(buf, n));; } else if (n == 0) {; break; // end of file; } else {; fprintf(stderr, ""read failed: %s\n"", strerror(errno));; exit(1);; }; }. // Finalize the hash. Default output length is 32 bytes.; auto output = hasher.final();. // Print the hash as hexadecimal.; for (uint8_t byte : output) {; printf(""%02x"", byte);; }; printf(""\n"");; return 0;; }; ```. Using the C API:. ```c; #include ""llvm-c/blake3.h""; #include <errno.h>; #include <stdio.h>; #include <stdlib.h>; #include <string.h>; #include <unistd.h>. int main() {; // Initialize the hasher.; llvm_blake3_hasher hasher;; llvm_blake3_hasher_init(&hasher);. // Read input bytes from stdin.; unsigned char buf[65536];; while (1) {; ssize_t n = read(STDIN_FILENO, buf, sizeof(buf));; if (n > 0) {; llvm_blake3_hasher_update(&hasher, buf, n);; } else if (n == 0) {; break; // end of file; } else {; fprintf(stderr, ""read failed: %s\n"", strerror(errno));; exit(1);; }; }. // Finalize the hash. LLVM_BLAKE3_OUT_LEN is the default output length, 32 bytes.; uint8_t output[LLVM_BLAKE3_OUT_LEN];; llvm_blake3_hasher_finalize(&hasher, output, LLVM_BLAKE3_OUT_LEN);. // Print the hash as hexadecimal.; for (size_t i = 0; i < LLVM_BLAKE3_OUT_LEN; i++) {; printf(""%02x"", output[i]);; }; printf(""\n"");; return 0;; }; ```. # API. ## The Class/Struct. ```c++; class BLAKE3 {; // API; private:; llvm_blake3_hasher Hasher;; };; ```; ```c; typedef struct {; // private fields; } llvm_blake3_hasher;; ```. An incremental BLAKE3 hashing state, which can accept any number of; updates. This implementation doesn't allocate any heap memory, but; `sizeof(llvm_blake3_hasher)` itself is relatively large, currently 1912 bytes; on x86-64. This size can be reduced by restricting the maximum input; length, as described in Section 5.4 of [the BLAKE3; spec](https://github.com/BLAKE3-team/BLAKE3-specs/blob/master/blake3.pdf),; but this implementation doesn't currently support that strategy. ## Common AP",MatchSource.DOCS,interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md:1647,Security,hash,hasher,1647,"} else {; fprintf(stderr, ""read failed: %s\n"", strerror(errno));; exit(1);; }; }. // Finalize the hash. Default output length is 32 bytes.; auto output = hasher.final();. // Print the hash as hexadecimal.; for (uint8_t byte : output) {; printf(""%02x"", byte);; }; printf(""\n"");; return 0;; }; ```. Using the C API:. ```c; #include ""llvm-c/blake3.h""; #include <errno.h>; #include <stdio.h>; #include <stdlib.h>; #include <string.h>; #include <unistd.h>. int main() {; // Initialize the hasher.; llvm_blake3_hasher hasher;; llvm_blake3_hasher_init(&hasher);. // Read input bytes from stdin.; unsigned char buf[65536];; while (1) {; ssize_t n = read(STDIN_FILENO, buf, sizeof(buf));; if (n > 0) {; llvm_blake3_hasher_update(&hasher, buf, n);; } else if (n == 0) {; break; // end of file; } else {; fprintf(stderr, ""read failed: %s\n"", strerror(errno));; exit(1);; }; }. // Finalize the hash. LLVM_BLAKE3_OUT_LEN is the default output length, 32 bytes.; uint8_t output[LLVM_BLAKE3_OUT_LEN];; llvm_blake3_hasher_finalize(&hasher, output, LLVM_BLAKE3_OUT_LEN);. // Print the hash as hexadecimal.; for (size_t i = 0; i < LLVM_BLAKE3_OUT_LEN; i++) {; printf(""%02x"", output[i]);; }; printf(""\n"");; return 0;; }; ```. # API. ## The Class/Struct. ```c++; class BLAKE3 {; // API; private:; llvm_blake3_hasher Hasher;; };; ```; ```c; typedef struct {; // private fields; } llvm_blake3_hasher;; ```. An incremental BLAKE3 hashing state, which can accept any number of; updates. This implementation doesn't allocate any heap memory, but; `sizeof(llvm_blake3_hasher)` itself is relatively large, currently 1912 bytes; on x86-64. This size can be reduced by restricting the maximum input; length, as described in Section 5.4 of [the BLAKE3; spec](https://github.com/BLAKE3-team/BLAKE3-specs/blob/master/blake3.pdf),; but this implementation doesn't currently support that strategy. ## Common API Functions. ```c++; BLAKE3::BLAKE3();. void BLAKE3::init();; ```; ```c; void llvm_blake3_hasher_init(; llvm_blake3_hasher *s",MatchSource.DOCS,interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md
