id,quality_attribute,keyword,matched_word,match_idx,sentence,source,filename,author,repo,version,wiki,url
https://root.cern/root/html532/TMultiLayerPerceptron.html:22534,Testability,test,testing,22534,"vents; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. ~TMultiLayerPerceptron(); Destructor. void SetData(TTree* ); Set the data source. void SetEventWeight(const char* ); Set the event weight. void SetTrainingDataSet(TEventList* train); Sets the Training dataset.; Those events will be used for the minimization. void SetTestDataSet(TEventList* test); Sets the Test dataset.; Those events will not be used for the minimization but for control. void SetTrainingDataSet(const char* train); Sets the Training dataset.; Those events will be used for the minimization.; Note that the tree must be already defined. void SetTestDataSet(const char* test); Sets the Test dataset.; Those events will not be used for the minimization but for control.; Note that the tree must be already defined. void SetLearningMethod(TMultiLayerPerceptron::ELearningMethod met",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:22976,Testability,test,test,22976,"output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. ~TMultiLayerPerceptron(); Destructor. void SetData(TTree* ); Set the data source. void SetEventWeight(const char* ); Set the event weight. void SetTrainingDataSet(TEventList* train); Sets the Training dataset.; Those events will be used for the minimization. void SetTestDataSet(TEventList* test); Sets the Test dataset.; Those events will not be used for the minimization but for control. void SetTrainingDataSet(const char* train); Sets the Training dataset.; Those events will be used for the minimization.; Note that the tree must be already defined. void SetTestDataSet(const char* test); Sets the Test dataset.; Those events will not be used for the minimization but for control.; Note that the tree must be already defined. void SetLearningMethod(TMultiLayerPerceptron::ELearningMethod method); Sets the learning method.; Available methods are: kStochastic, kBatch,; kSteepestDescent, kRibierePolak, kFletcherReeves and kBFGS.; (look at the constructor for the complete description; of learning methods and parameters). void SetEta(Double_t eta); Sets Eta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEpsilon(Double_t eps); Sets Epsilon - used in stochastic minimisation; (look at the constru",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:23272,Testability,test,test,23272,"!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. ~TMultiLayerPerceptron(); Destructor. void SetData(TTree* ); Set the data source. void SetEventWeight(const char* ); Set the event weight. void SetTrainingDataSet(TEventList* train); Sets the Training dataset.; Those events will be used for the minimization. void SetTestDataSet(TEventList* test); Sets the Test dataset.; Those events will not be used for the minimization but for control. void SetTrainingDataSet(const char* train); Sets the Training dataset.; Those events will be used for the minimization.; Note that the tree must be already defined. void SetTestDataSet(const char* test); Sets the Test dataset.; Those events will not be used for the minimization but for control.; Note that the tree must be already defined. void SetLearningMethod(TMultiLayerPerceptron::ELearningMethod method); Sets the learning method.; Available methods are: kStochastic, kBatch,; kSteepestDescent, kRibierePolak, kFletcherReeves and kBFGS.; (look at the constructor for the complete description; of learning methods and parameters). void SetEta(Double_t eta); Sets Eta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEpsilon(Double_t eps); Sets Epsilon - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetDelta(Double_t delta); Sets Delta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEtaDecay(Double_t ed); Sets EtaDecay - Eta *= E",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:25328,Testability,test,test,25328,"ay at each epoch; (look at the constructor for the complete description; of learning methods and parameters). void SetTau(Double_t tau); Sets Tau - used in line search; (look at the constructor for the complete description; of learning methods and parameters). void SetReset(Int_t reset); Sets number of epochs between two resets of the; search direction to the steepest descent.; (look at the constructor for the complete description; of learning methods and parameters). void GetEntry(Int_t ) const; Load an entry into the network. void Train(Int_t nEpoch, Option_t* option = ""text"", Double_t minE = 0); Train the network.; nEpoch is the number of iterations.; option can contain:; - ""text"" (simple text output); - ""graph"" (evoluting graphical training curves); - ""update=X"" (step for the text/graph output update); - ""+"" will skip the randomisation and start from the previous values.; - ""current"" (draw in the current canvas); - ""minErrorTrain"" (stop when NN error on the training sample gets below minE; - ""minErrorTest"" (stop when NN error on the test sample gets below minE; All combinations are available. Double_t Result(Int_t event, Int_t index = 0) const; Computes the output for a given event.; Look at the output neuron designed by index. Double_t GetError(Int_t event) const; Error on the output for a given event. Double_t GetError(TMultiLayerPerceptron::EDataSet set) const; Error on the whole dataset. Double_t GetSumSquareError() const; Error on the output for a given event. Double_t GetCrossEntropyBinary() const; Cross entropy error for sigmoid output neurons, for a given event. Double_t GetCrossEntropy() const; Cross entropy error for a softmax output neuron, for a given event. void ComputeDEDw() const; Compute the DEDw = sum on all training events of dedw for each weight; normalized by the number of events. void Randomize() const; Randomize the weights. void AttachData(); Connects the TTree to Neurons in input and output; layers. The formulas associated to each neuron ",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:27351,Testability,test,test,27351,"ince this would degrade; performance for classification jobs.; Normalisation can be requested by putting '@' in front of the formula. void ExpandStructure(); Expand the structure of the first layer. void BuildNetwork(); Instanciates the network from the description. void BuildFirstLayer(TString& ); Instanciates the neurons in input; Inputs are normalised and the type is set to kOff; (simple forward of the formula value). void BuildHiddenLayers(TString& ); Builds hidden layers. void BuildOneHiddenLayer(const TString& sNumNodes, Int_t& layer, Int_t& prevStart, Int_t& prevStop, Bool_t lastLayer); Builds a hidden layer, updates the number of layers. void BuildLastLayer(TString& , Int_t ); Builds the output layer; Neurons are linear combinations of input, by defaul.; If the structure ends with ""!"", neurons are set up for classification,; ie. with a sigmoid (1 neuron) or softmax (more neurons) activation function. void DrawResult(Int_t index = 0, Option_t* option = ""test"") const; Draws the neural net output; It produces an histogram with the output for the two datasets.; Index is the number of the desired output neuron.; ""option"" can contain:; - test or train to select a dataset; - comp to produce a X-Y comparison plot; - nocanv to not create a new TCanvas for the plot. void DumpWeights(Option_t* filename = ""-"") const; Dumps the weights to a text file.; Set filename to ""-"" (default) to dump to the standard output. void LoadWeights(Option_t* filename = """"); Loads the weights from a text file conforming to the format; defined by DumpWeights. Double_t Evaluate(Int_t index, Double_t* params) const; Returns the Neural Net for a given set of input parameters; #parameters must equal #input neurons. void Export(Option_t* filename = ""NNfunction"", Option_t* language = ""C++"") const; Exports the NN as a function for any non-ROOT-dependant code; Supported languages are: only C++ , FORTRAN and Python (yet); This feature is also usefull if you want to plot the NN as; a function (TF1 or T",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:27534,Testability,test,test,27534,"ldNetwork(); Instanciates the network from the description. void BuildFirstLayer(TString& ); Instanciates the neurons in input; Inputs are normalised and the type is set to kOff; (simple forward of the formula value). void BuildHiddenLayers(TString& ); Builds hidden layers. void BuildOneHiddenLayer(const TString& sNumNodes, Int_t& layer, Int_t& prevStart, Int_t& prevStop, Bool_t lastLayer); Builds a hidden layer, updates the number of layers. void BuildLastLayer(TString& , Int_t ); Builds the output layer; Neurons are linear combinations of input, by defaul.; If the structure ends with ""!"", neurons are set up for classification,; ie. with a sigmoid (1 neuron) or softmax (more neurons) activation function. void DrawResult(Int_t index = 0, Option_t* option = ""test"") const; Draws the neural net output; It produces an histogram with the output for the two datasets.; Index is the number of the desired output neuron.; ""option"" can contain:; - test or train to select a dataset; - comp to produce a X-Y comparison plot; - nocanv to not create a new TCanvas for the plot. void DumpWeights(Option_t* filename = ""-"") const; Dumps the weights to a text file.; Set filename to ""-"" (default) to dump to the standard output. void LoadWeights(Option_t* filename = """"); Loads the weights from a text file conforming to the format; defined by DumpWeights. Double_t Evaluate(Int_t index, Double_t* params) const; Returns the Neural Net for a given set of input parameters; #parameters must equal #input neurons. void Export(Option_t* filename = ""NNfunction"", Option_t* language = ""C++"") const; Exports the NN as a function for any non-ROOT-dependant code; Supported languages are: only C++ , FORTRAN and Python (yet); This feature is also usefull if you want to plot the NN as; a function (TF1 or TF2). void Shuffle(Int_t* , Int_t ) const; Shuffle the Int_t index[n] in input.; Input:; index: the array to shuffle; n: the size of the array; Output:; index: the shuffled indexes; This method is used for st",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:960,Usability,learn,learning,960,"erceptron. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » MATH; » MLP; » TMultiLayerPerceptron. class TMultiLayerPerceptron: public TObject. TMultiLayerPerceptron. This class describes a neural network.; There are facilities to train the network and use the output. The input layer is made of inactive neurons (returning the; optionaly normalized input) and output neurons are linear.; The type of hidden neurons is free, the default being sigmoids.; (One should still try to pass normalized inputs, e.g. between [0.,1]). The basic input is a TTree and two (training and test) TEventLists.; Input and output neurons are assigned a value computed for each event; with the same possibilities as for TTree::Draw().; Events may be weighted individualy or via TTree::SetWeight().; 6 learning methods are available: kStochastic, kBatch,; kSteepestDescent, kRibierePolak, kFletcherReeves and kBFGS. This implementation, written by C. Delaere, is *inspired* from; the mlpfit package from J.Schwindling et al. with some extensions:; * the algorithms are globally the same; * in TMultilayerPerceptron, there is no limitation on the number of; layers/neurons, while MLPFIT was limited to 2 hidden layers; * TMultilayerPerceptron allows you to save the network in a root file, and; provides more export functionalities; * TMultilayerPerceptron gives more flexibility regarding the normalization of; inputs/outputs; * TMultilayerPerceptron provides, thanks to Andrea Bocci, the possibility to; use cross-entropy errors, which allows to train a network for pattern; classification based on Bayesian posterior probability. . Introduction. Neural Networks are more and more used in various fields for data; analysis and classification, both for research and commercial; institutions. Some randomly choosen examples are:. image analysis; financial mo",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:2508,Usability,clear,clear,2508,"f; inputs/outputs; * TMultilayerPerceptron provides, thanks to Andrea Bocci, the possibility to; use cross-entropy errors, which allows to train a network for pattern; classification based on Bayesian posterior probability. . Introduction. Neural Networks are more and more used in various fields for data; analysis and classification, both for research and commercial; institutions. Some randomly choosen examples are:. image analysis; financial movements predictions and analysis; sales forecast and product shipping optimisation; in particles physics: mainly for classification tasks (signal; over background discrimination). More than 50% of neural networks are multilayer perceptrons. This; implementation of multilayer perceptrons is inspired from the; MLPfit; package originaly written by Jerome Schwindling. MLPfit remains; one of the fastest tool for neural networks studies, and this ROOT; add-on will not try to compete on that. A clear and flexible Object; Oriented implementation has been choosen over a faster but more; difficult to maintain code. Nevertheless, the time penalty does not; exceed a factor 2. The; MLP. The multilayer perceptron is a simple feed-forward network with; the following structure:. It is made of neurons characterized by a bias and weighted links; between them (let's call those links synapses). The input neurons; receive the inputs, normalize them and forward them to the first; hidden layer. Each neuron in any subsequent layer first computes a linear; combination of the outputs of the previous layer. The output of the; neuron is then function of that combination with f being; linear for output neurons or a sigmoid for hidden layers. This is; useful because of two theorems:. A linear combination of sigmoids can approximate any; continuous function.; Trained with output = 1 for the signal and 0 for the; background, the approximated function of inputs X is the probability; of signal, knowing X. Learning; methods. The aim of all learning methods is ",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:2729,Usability,simpl,simple,2729,"cation based on Bayesian posterior probability. . Introduction. Neural Networks are more and more used in various fields for data; analysis and classification, both for research and commercial; institutions. Some randomly choosen examples are:. image analysis; financial movements predictions and analysis; sales forecast and product shipping optimisation; in particles physics: mainly for classification tasks (signal; over background discrimination). More than 50% of neural networks are multilayer perceptrons. This; implementation of multilayer perceptrons is inspired from the; MLPfit; package originaly written by Jerome Schwindling. MLPfit remains; one of the fastest tool for neural networks studies, and this ROOT; add-on will not try to compete on that. A clear and flexible Object; Oriented implementation has been choosen over a faster but more; difficult to maintain code. Nevertheless, the time penalty does not; exceed a factor 2. The; MLP. The multilayer perceptron is a simple feed-forward network with; the following structure:. It is made of neurons characterized by a bias and weighted links; between them (let's call those links synapses). The input neurons; receive the inputs, normalize them and forward them to the first; hidden layer. Each neuron in any subsequent layer first computes a linear; combination of the outputs of the previous layer. The output of the; neuron is then function of that combination with f being; linear for output neurons or a sigmoid for hidden layers. This is; useful because of two theorems:. A linear combination of sigmoids can approximate any; continuous function.; Trained with output = 1 for the signal and 0 for the; background, the approximated function of inputs X is the probability; of signal, knowing X. Learning; methods. The aim of all learning methods is to minimize the total error on; a set of weighted examples. The error is defined as the sum in; quadrature, devided by two, of the error on each individual output; neuron.; In a",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:3546,Usability,learn,learning,3546,"ver a faster but more; difficult to maintain code. Nevertheless, the time penalty does not; exceed a factor 2. The; MLP. The multilayer perceptron is a simple feed-forward network with; the following structure:. It is made of neurons characterized by a bias and weighted links; between them (let's call those links synapses). The input neurons; receive the inputs, normalize them and forward them to the first; hidden layer. Each neuron in any subsequent layer first computes a linear; combination of the outputs of the previous layer. The output of the; neuron is then function of that combination with f being; linear for output neurons or a sigmoid for hidden layers. This is; useful because of two theorems:. A linear combination of sigmoids can approximate any; continuous function.; Trained with output = 1 for the signal and 0 for the; background, the approximated function of inputs X is the probability; of signal, knowing X. Learning; methods. The aim of all learning methods is to minimize the total error on; a set of weighted examples. The error is defined as the sum in; quadrature, devided by two, of the error on each individual output; neuron.; In all methods implemented, one needs to compute; the first derivative of that error with respect to the weights.; Exploiting the well-known properties of the derivative, especialy the; derivative of compound functions, one can write:. for a neuton: product of the local derivative with the; weighted sum on the outputs of the derivatives.; for a synapse: product of the input with the local derivative; of the output neuron. This computation is called back-propagation of the errors. A; loop over all examples is called an epoch.; Six learning methods are implemented.; Stochastic minimization: This; is the most trivial learning method. This is the Robbins-Monro; stochastic approximation applied to multilayer perceptrons. The; weights are updated after each example according to the formula:; $w_{ij}(t+1) = w_{ij}(t) + \Delta w_{ij}(t",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:4275,Usability,learn,learning,4275,". A linear combination of sigmoids can approximate any; continuous function.; Trained with output = 1 for the signal and 0 for the; background, the approximated function of inputs X is the probability; of signal, knowing X. Learning; methods. The aim of all learning methods is to minimize the total error on; a set of weighted examples. The error is defined as the sum in; quadrature, devided by two, of the error on each individual output; neuron.; In all methods implemented, one needs to compute; the first derivative of that error with respect to the weights.; Exploiting the well-known properties of the derivative, especialy the; derivative of compound functions, one can write:. for a neuton: product of the local derivative with the; weighted sum on the outputs of the derivatives.; for a synapse: product of the input with the local derivative; of the output neuron. This computation is called back-propagation of the errors. A; loop over all examples is called an epoch.; Six learning methods are implemented.; Stochastic minimization: This; is the most trivial learning method. This is the Robbins-Monro; stochastic approximation applied to multilayer perceptrons. The; weights are updated after each example according to the formula:; $w_{ij}(t+1) = w_{ij}(t) + \Delta w_{ij}(t)$. with. $\Delta w_{ij}(t) = - \eta(\d e_p / \d w_{ij} +; \delta) + \epsilon \Deltaw_{ij}(t-1)$; The parameters for this method are Eta, EtaDecay, Delta and; Epsilon.; Steepest descent with fixed step size; (batch learning): It is the same as the stochastic; minimization, but the weights are updated after considering all the; examples, with the total derivative dEdw. The parameters for this; method are Eta, EtaDecay, Delta and Epsilon.; Steepest descent algorithm: Weights; are set to the minimum along the line defined by the gradient. The; only parameter for this method is Tau. Lower tau = higher precision =; slower search. A value Tau = 3 seems reasonable.; Conjugate gradients with the; Polak-Ribiere",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:4361,Usability,learn,learning,4361,"; continuous function.; Trained with output = 1 for the signal and 0 for the; background, the approximated function of inputs X is the probability; of signal, knowing X. Learning; methods. The aim of all learning methods is to minimize the total error on; a set of weighted examples. The error is defined as the sum in; quadrature, devided by two, of the error on each individual output; neuron.; In all methods implemented, one needs to compute; the first derivative of that error with respect to the weights.; Exploiting the well-known properties of the derivative, especialy the; derivative of compound functions, one can write:. for a neuton: product of the local derivative with the; weighted sum on the outputs of the derivatives.; for a synapse: product of the input with the local derivative; of the output neuron. This computation is called back-propagation of the errors. A; loop over all examples is called an epoch.; Six learning methods are implemented.; Stochastic minimization: This; is the most trivial learning method. This is the Robbins-Monro; stochastic approximation applied to multilayer perceptrons. The; weights are updated after each example according to the formula:; $w_{ij}(t+1) = w_{ij}(t) + \Delta w_{ij}(t)$. with. $\Delta w_{ij}(t) = - \eta(\d e_p / \d w_{ij} +; \delta) + \epsilon \Deltaw_{ij}(t-1)$; The parameters for this method are Eta, EtaDecay, Delta and; Epsilon.; Steepest descent with fixed step size; (batch learning): It is the same as the stochastic; minimization, but the weights are updated after considering all the; examples, with the total derivative dEdw. The parameters for this; method are Eta, EtaDecay, Delta and Epsilon.; Steepest descent algorithm: Weights; are set to the minimum along the line defined by the gradient. The; only parameter for this method is Tau. Lower tau = higher precision =; slower search. A value Tau = 3 seems reasonable.; Conjugate gradients with the; Polak-Ribiere updating formula: Weights are set to the; minimum alo",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:4793,Usability,learn,learning,4793,"ights.; Exploiting the well-known properties of the derivative, especialy the; derivative of compound functions, one can write:. for a neuton: product of the local derivative with the; weighted sum on the outputs of the derivatives.; for a synapse: product of the input with the local derivative; of the output neuron. This computation is called back-propagation of the errors. A; loop over all examples is called an epoch.; Six learning methods are implemented.; Stochastic minimization: This; is the most trivial learning method. This is the Robbins-Monro; stochastic approximation applied to multilayer perceptrons. The; weights are updated after each example according to the formula:; $w_{ij}(t+1) = w_{ij}(t) + \Delta w_{ij}(t)$. with. $\Delta w_{ij}(t) = - \eta(\d e_p / \d w_{ij} +; \delta) + \epsilon \Deltaw_{ij}(t-1)$; The parameters for this method are Eta, EtaDecay, Delta and; Epsilon.; Steepest descent with fixed step size; (batch learning): It is the same as the stochastic; minimization, but the weights are updated after considering all the; examples, with the total derivative dEdw. The parameters for this; method are Eta, EtaDecay, Delta and Epsilon.; Steepest descent algorithm: Weights; are set to the minimum along the line defined by the gradient. The; only parameter for this method is Tau. Lower tau = higher precision =; slower search. A value Tau = 3 seems reasonable.; Conjugate gradients with the; Polak-Ribiere updating formula: Weights are set to the; minimum along the line defined by the conjugate gradient. Parameters; are Tau and Reset, which defines the epochs where the direction is; reset to the steepes descent.; Conjugate gradients with the; Fletcher-Reeves updating formula: Weights are set to the; minimum along the line defined by the conjugate gradient. Parameters; are Tau and Reset, which defines the epochs where the direction is; reset to the steepes descent.; Broyden, Fletcher, Goldfarb, Shanno; (BFGS) method: Implies the computation of a NxN matr",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:6308,Usability,simpl,simple,6308," line defined by the conjugate gradient. Parameters; are Tau and Reset, which defines the epochs where the direction is; reset to the steepes descent.; Conjugate gradients with the; Fletcher-Reeves updating formula: Weights are set to the; minimum along the line defined by the conjugate gradient. Parameters; are Tau and Reset, which defines the epochs where the direction is; reset to the steepes descent.; Broyden, Fletcher, Goldfarb, Shanno; (BFGS) method: Implies the computation of a NxN matrix; computation, but seems more powerful at least for less than 300; weights. Parameters are Tau and Reset, which defines the epochs where; the direction is reset to the steepes descent. How; to use it... TMLP is build from 3 classes: TNeuron, TSynapse and; TMultiLayerPerceptron. Only TMultiLayerPerceptron should be used; explicitely by the user.; TMultiLayerPerceptron will take examples from a TTree; given in the constructor. The network is described by a simple; string: The input/output layers are defined by giving the expression for; each neuron, separated by comas. Hidden layers are just described; by the number of neurons. The layers are separated by colons.; In addition, input/output layer formulas can be preceded by '@' (e.g ""@out""); if one wants to also normalize the data from the TTree.; Input and outputs are taken from the TTree given as second argument.; Expressions are evaluated as for TTree::Draw(), arrays are expended in; distinct neurons, one for each index.; This can only be done for fixed-size arrays.; If the formula ends with ""!"", softmax functions are used for the output layer.; One defines the training and test datasets by TEventLists. Example:; TMultiLayerPerceptron(""x,y:10:5:f"",inputTree);; Both the TTree and the TEventLists can be defined in; the constructor, or later with the suited setter method. The lists; used for training and test can be defined either explicitely, or via; a string containing the formula to be used to define them, exactly as; for a TC",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:7359,Usability,learn,learning,7359,"uron, separated by comas. Hidden layers are just described; by the number of neurons. The layers are separated by colons.; In addition, input/output layer formulas can be preceded by '@' (e.g ""@out""); if one wants to also normalize the data from the TTree.; Input and outputs are taken from the TTree given as second argument.; Expressions are evaluated as for TTree::Draw(), arrays are expended in; distinct neurons, one for each index.; This can only be done for fixed-size arrays.; If the formula ends with ""!"", softmax functions are used for the output layer.; One defines the training and test datasets by TEventLists. Example:; TMultiLayerPerceptron(""x,y:10:5:f"",inputTree);; Both the TTree and the TEventLists can be defined in; the constructor, or later with the suited setter method. The lists; used for training and test can be defined either explicitely, or via; a string containing the formula to be used to define them, exactly as; for a TCut.; The learning method is defined using the; TMultiLayerPerceptron::SetLearningMethod() . Learning methods are :; TMultiLayerPerceptron::kStochastic, ; TMultiLayerPerceptron::kBatch,; TMultiLayerPerceptron::kSteepestDescent,; TMultiLayerPerceptron::kRibierePolak,; TMultiLayerPerceptron::kFletcherReeves,; TMultiLayerPerceptron::kBFGS; A weight can be assigned to events, either in the constructor, either; with TMultiLayerPerceptron::SetEventWeight(). In addition, the TTree weight; is taken into account.; Finally, one starts the training with; TMultiLayerPerceptron::Train(Int_t nepoch, Option_t* options). The; first argument is the number of epochs while option is a string that; can contain: ""text"" (simple text output) , ""graph""; (evoluting graphical training curves), ""update=X"" (step for; the text/graph output update) or ""+"" (will skip the; randomisation and start from the previous values). All combinations; are available. . Example:; net.Train(100,""text, graph, update=10"").; When the neural net is trained, it can be used; directly",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:8058,Usability,simpl,simple,8058,"tLists can be defined in; the constructor, or later with the suited setter method. The lists; used for training and test can be defined either explicitely, or via; a string containing the formula to be used to define them, exactly as; for a TCut.; The learning method is defined using the; TMultiLayerPerceptron::SetLearningMethod() . Learning methods are :; TMultiLayerPerceptron::kStochastic, ; TMultiLayerPerceptron::kBatch,; TMultiLayerPerceptron::kSteepestDescent,; TMultiLayerPerceptron::kRibierePolak,; TMultiLayerPerceptron::kFletcherReeves,; TMultiLayerPerceptron::kBFGS; A weight can be assigned to events, either in the constructor, either; with TMultiLayerPerceptron::SetEventWeight(). In addition, the TTree weight; is taken into account.; Finally, one starts the training with; TMultiLayerPerceptron::Train(Int_t nepoch, Option_t* options). The; first argument is the number of epochs while option is a string that; can contain: ""text"" (simple text output) , ""graph""; (evoluting graphical training curves), ""update=X"" (step for; the text/graph output update) or ""+"" (will skip the; randomisation and start from the previous values). All combinations; are available. . Example:; net.Train(100,""text, graph, update=10"").; When the neural net is trained, it can be used; directly ( TMultiLayerPerceptron::Evaluate() ) or exported to a; standalone C++ code ( TMultiLayerPerceptron::Export() ).; Finaly, note that even if this implementation is inspired from the mlpfit code,; the feature lists are not exactly matching:. mlpfit hybrid learning method is not implemented; output neurons can be normalized, this is not the case for mlpfit; the neural net is exported in C++, FORTRAN or PYTHON; the drawResult() method allows a fast check of the learning procedure. In addition, the paw version of mlpfit had additional limitations on the number of neurons, hidden layers and inputs/outputs that does not apply to TMultiLayerPerceptron. Function Members (Methods); public:. TMultiLayerPerceptr",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:8652,Usability,learn,learning,8652," with TMultiLayerPerceptron::SetEventWeight(). In addition, the TTree weight; is taken into account.; Finally, one starts the training with; TMultiLayerPerceptron::Train(Int_t nepoch, Option_t* options). The; first argument is the number of epochs while option is a string that; can contain: ""text"" (simple text output) , ""graph""; (evoluting graphical training curves), ""update=X"" (step for; the text/graph output update) or ""+"" (will skip the; randomisation and start from the previous values). All combinations; are available. . Example:; net.Train(100,""text, graph, update=10"").; When the neural net is trained, it can be used; directly ( TMultiLayerPerceptron::Evaluate() ) or exported to a; standalone C++ code ( TMultiLayerPerceptron::Export() ).; Finaly, note that even if this implementation is inspired from the mlpfit code,; the feature lists are not exactly matching:. mlpfit hybrid learning method is not implemented; output neurons can be normalized, this is not the case for mlpfit; the neural net is exported in C++, FORTRAN or PYTHON; the drawResult() method allows a fast check of the learning procedure. In addition, the paw version of mlpfit had additional limitations on the number of neurons, hidden layers and inputs/outputs that does not apply to TMultiLayerPerceptron. Function Members (Methods); public:. TMultiLayerPerceptron(); TMultiLayerPerceptron(const char* layout, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); TMultiLayerPerceptron(const char* layout, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); TMultiLa",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:8860,Usability,learn,learning,8860," with TMultiLayerPerceptron::SetEventWeight(). In addition, the TTree weight; is taken into account.; Finally, one starts the training with; TMultiLayerPerceptron::Train(Int_t nepoch, Option_t* options). The; first argument is the number of epochs while option is a string that; can contain: ""text"" (simple text output) , ""graph""; (evoluting graphical training curves), ""update=X"" (step for; the text/graph output update) or ""+"" (will skip the; randomisation and start from the previous values). All combinations; are available. . Example:; net.Train(100,""text, graph, update=10"").; When the neural net is trained, it can be used; directly ( TMultiLayerPerceptron::Evaluate() ) or exported to a; standalone C++ code ( TMultiLayerPerceptron::Export() ).; Finaly, note that even if this implementation is inspired from the mlpfit code,; the feature lists are not exactly matching:. mlpfit hybrid learning method is not implemented; output neurons can be normalized, this is not the case for mlpfit; the neural net is exported in C++, FORTRAN or PYTHON; the drawResult() method allows a fast check of the learning procedure. In addition, the paw version of mlpfit had additional limitations on the number of neurons, hidden layers and inputs/outputs that does not apply to TMultiLayerPerceptron. Function Members (Methods); public:. TMultiLayerPerceptron(); TMultiLayerPerceptron(const char* layout, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); TMultiLayerPerceptron(const char* layout, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); TMultiLa",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:19090,Usability,simpl,simple,19090,"steepest descent - Default=50; TStringfStructureString containing the network structure; TObjArrayfSynapsesCollection of all the synapses in the network; Double_tfTau! Tau - used in line search - Default=3.; TEventList*fTest! EventList defining the events in the test dataset; Bool_tfTestOwner! internal flag whether one has to delete fTest or not; TEventList*fTraining! EventList defining the events in the training dataset; Bool_tfTrainingOwner! internal flag whether one has to delete fTraining or not; TNeuron::ENeuronTypefTypeType of hidden neurons; TStringfWeightString containing the event weight; TStringfextDString containing the derivative name; TStringfextFString containing the function name. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMultiLayerPerceptron(); Default constructor. TMultiLayerPerceptron(const char* layout, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:20016,Usability,simpl,simple,20016,"g, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:20947,Usability,simpl,simple,20947,"TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, con",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:21948,Usability,simpl,simple,21948,"oid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. ~TMultiLayerPerceptron(); Destructor. void SetData(TTree* ); Set the data source. void SetEventWeight(const char* ); Set the event weight. void SetTrainingDataSet(TEventList* train",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:23496,Usability,learn,learning,23496,"ormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. ~TMultiLayerPerceptron(); Destructor. void SetData(TTree* ); Set the data source. void SetEventWeight(const char* ); Set the event weight. void SetTrainingDataSet(TEventList* train); Sets the Training dataset.; Those events will be used for the minimization. void SetTestDataSet(TEventList* test); Sets the Test dataset.; Those events will not be used for the minimization but for control. void SetTrainingDataSet(const char* train); Sets the Training dataset.; Those events will be used for the minimization.; Note that the tree must be already defined. void SetTestDataSet(const char* test); Sets the Test dataset.; Those events will not be used for the minimization but for control.; Note that the tree must be already defined. void SetLearningMethod(TMultiLayerPerceptron::ELearningMethod method); Sets the learning method.; Available methods are: kStochastic, kBatch,; kSteepestDescent, kRibierePolak, kFletcherReeves and kBFGS.; (look at the constructor for the complete description; of learning methods and parameters). void SetEta(Double_t eta); Sets Eta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEpsilon(Double_t eps); Sets Epsilon - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetDelta(Double_t delta); Sets Delta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEtaDecay(Double_t ed); Sets EtaDecay - Eta *= EtaDecay at each epoch; (look at the constructor for the complete description; of learning methods and parameters). void SetTau(Double_t tau); Sets Tau - used in line search; (look at the constru",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:23678,Usability,learn,learning,23678,"uited setter method. ~TMultiLayerPerceptron(); Destructor. void SetData(TTree* ); Set the data source. void SetEventWeight(const char* ); Set the event weight. void SetTrainingDataSet(TEventList* train); Sets the Training dataset.; Those events will be used for the minimization. void SetTestDataSet(TEventList* test); Sets the Test dataset.; Those events will not be used for the minimization but for control. void SetTrainingDataSet(const char* train); Sets the Training dataset.; Those events will be used for the minimization.; Note that the tree must be already defined. void SetTestDataSet(const char* test); Sets the Test dataset.; Those events will not be used for the minimization but for control.; Note that the tree must be already defined. void SetLearningMethod(TMultiLayerPerceptron::ELearningMethod method); Sets the learning method.; Available methods are: kStochastic, kBatch,; kSteepestDescent, kRibierePolak, kFletcherReeves and kBFGS.; (look at the constructor for the complete description; of learning methods and parameters). void SetEta(Double_t eta); Sets Eta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEpsilon(Double_t eps); Sets Epsilon - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetDelta(Double_t delta); Sets Delta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEtaDecay(Double_t ed); Sets EtaDecay - Eta *= EtaDecay at each epoch; (look at the constructor for the complete description; of learning methods and parameters). void SetTau(Double_t tau); Sets Tau - used in line search; (look at the constructor for the complete description; of learning methods and parameters). void SetReset(Int_t reset); Sets number of epochs between two resets of the; search direction to the steepest descent.; (look at ",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:23841,Usability,learn,learning,23841," char* ); Set the event weight. void SetTrainingDataSet(TEventList* train); Sets the Training dataset.; Those events will be used for the minimization. void SetTestDataSet(TEventList* test); Sets the Test dataset.; Those events will not be used for the minimization but for control. void SetTrainingDataSet(const char* train); Sets the Training dataset.; Those events will be used for the minimization.; Note that the tree must be already defined. void SetTestDataSet(const char* test); Sets the Test dataset.; Those events will not be used for the minimization but for control.; Note that the tree must be already defined. void SetLearningMethod(TMultiLayerPerceptron::ELearningMethod method); Sets the learning method.; Available methods are: kStochastic, kBatch,; kSteepestDescent, kRibierePolak, kFletcherReeves and kBFGS.; (look at the constructor for the complete description; of learning methods and parameters). void SetEta(Double_t eta); Sets Eta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEpsilon(Double_t eps); Sets Epsilon - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetDelta(Double_t delta); Sets Delta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEtaDecay(Double_t ed); Sets EtaDecay - Eta *= EtaDecay at each epoch; (look at the constructor for the complete description; of learning methods and parameters). void SetTau(Double_t tau); Sets Tau - used in line search; (look at the constructor for the complete description; of learning methods and parameters). void SetReset(Int_t reset); Sets number of epochs between two resets of the; search direction to the steepest descent.; (look at the constructor for the complete description; of learning methods and parameters). void GetEntry(Int_t ) const; Load an entry in",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:24012,Usability,learn,learning,24012,"aSet(TEventList* test); Sets the Test dataset.; Those events will not be used for the minimization but for control. void SetTrainingDataSet(const char* train); Sets the Training dataset.; Those events will be used for the minimization.; Note that the tree must be already defined. void SetTestDataSet(const char* test); Sets the Test dataset.; Those events will not be used for the minimization but for control.; Note that the tree must be already defined. void SetLearningMethod(TMultiLayerPerceptron::ELearningMethod method); Sets the learning method.; Available methods are: kStochastic, kBatch,; kSteepestDescent, kRibierePolak, kFletcherReeves and kBFGS.; (look at the constructor for the complete description; of learning methods and parameters). void SetEta(Double_t eta); Sets Eta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEpsilon(Double_t eps); Sets Epsilon - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetDelta(Double_t delta); Sets Delta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEtaDecay(Double_t ed); Sets EtaDecay - Eta *= EtaDecay at each epoch; (look at the constructor for the complete description; of learning methods and parameters). void SetTau(Double_t tau); Sets Tau - used in line search; (look at the constructor for the complete description; of learning methods and parameters). void SetReset(Int_t reset); Sets number of epochs between two resets of the; search direction to the steepest descent.; (look at the constructor for the complete description; of learning methods and parameters). void GetEntry(Int_t ) const; Load an entry into the network. void Train(Int_t nEpoch, Option_t* option = ""text"", Double_t minE = 0); Train the network.; nEpoch is the number of iterations.; option can contain:; -",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:24181,Usability,learn,learning,24181,"raining dataset.; Those events will be used for the minimization.; Note that the tree must be already defined. void SetTestDataSet(const char* test); Sets the Test dataset.; Those events will not be used for the minimization but for control.; Note that the tree must be already defined. void SetLearningMethod(TMultiLayerPerceptron::ELearningMethod method); Sets the learning method.; Available methods are: kStochastic, kBatch,; kSteepestDescent, kRibierePolak, kFletcherReeves and kBFGS.; (look at the constructor for the complete description; of learning methods and parameters). void SetEta(Double_t eta); Sets Eta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEpsilon(Double_t eps); Sets Epsilon - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetDelta(Double_t delta); Sets Delta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEtaDecay(Double_t ed); Sets EtaDecay - Eta *= EtaDecay at each epoch; (look at the constructor for the complete description; of learning methods and parameters). void SetTau(Double_t tau); Sets Tau - used in line search; (look at the constructor for the complete description; of learning methods and parameters). void SetReset(Int_t reset); Sets number of epochs between two resets of the; search direction to the steepest descent.; (look at the constructor for the complete description; of learning methods and parameters). void GetEntry(Int_t ) const; Load an entry into the network. void Train(Int_t nEpoch, Option_t* option = ""text"", Double_t minE = 0); Train the network.; nEpoch is the number of iterations.; option can contain:; - ""text"" (simple text output); - ""graph"" (evoluting graphical training curves); - ""update=X"" (step for the text/graph output update); - ""+"" will skip the randomisation and",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:24351,Usability,learn,learning,24351,"t.; Those events will not be used for the minimization but for control.; Note that the tree must be already defined. void SetLearningMethod(TMultiLayerPerceptron::ELearningMethod method); Sets the learning method.; Available methods are: kStochastic, kBatch,; kSteepestDescent, kRibierePolak, kFletcherReeves and kBFGS.; (look at the constructor for the complete description; of learning methods and parameters). void SetEta(Double_t eta); Sets Eta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEpsilon(Double_t eps); Sets Epsilon - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetDelta(Double_t delta); Sets Delta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEtaDecay(Double_t ed); Sets EtaDecay - Eta *= EtaDecay at each epoch; (look at the constructor for the complete description; of learning methods and parameters). void SetTau(Double_t tau); Sets Tau - used in line search; (look at the constructor for the complete description; of learning methods and parameters). void SetReset(Int_t reset); Sets number of epochs between two resets of the; search direction to the steepest descent.; (look at the constructor for the complete description; of learning methods and parameters). void GetEntry(Int_t ) const; Load an entry into the network. void Train(Int_t nEpoch, Option_t* option = ""text"", Double_t minE = 0); Train the network.; nEpoch is the number of iterations.; option can contain:; - ""text"" (simple text output); - ""graph"" (evoluting graphical training curves); - ""update=X"" (step for the text/graph output update); - ""+"" will skip the randomisation and start from the previous values.; - ""current"" (draw in the current canvas); - ""minErrorTrain"" (stop when NN error on the training sample gets below minE; - ""minErrorTest",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:24502,Usability,learn,learning,24502,"n::ELearningMethod method); Sets the learning method.; Available methods are: kStochastic, kBatch,; kSteepestDescent, kRibierePolak, kFletcherReeves and kBFGS.; (look at the constructor for the complete description; of learning methods and parameters). void SetEta(Double_t eta); Sets Eta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEpsilon(Double_t eps); Sets Epsilon - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetDelta(Double_t delta); Sets Delta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEtaDecay(Double_t ed); Sets EtaDecay - Eta *= EtaDecay at each epoch; (look at the constructor for the complete description; of learning methods and parameters). void SetTau(Double_t tau); Sets Tau - used in line search; (look at the constructor for the complete description; of learning methods and parameters). void SetReset(Int_t reset); Sets number of epochs between two resets of the; search direction to the steepest descent.; (look at the constructor for the complete description; of learning methods and parameters). void GetEntry(Int_t ) const; Load an entry into the network. void Train(Int_t nEpoch, Option_t* option = ""text"", Double_t minE = 0); Train the network.; nEpoch is the number of iterations.; option can contain:; - ""text"" (simple text output); - ""graph"" (evoluting graphical training curves); - ""update=X"" (step for the text/graph output update); - ""+"" will skip the randomisation and start from the previous values.; - ""current"" (draw in the current canvas); - ""minErrorTrain"" (stop when NN error on the training sample gets below minE; - ""minErrorTest"" (stop when NN error on the test sample gets below minE; All combinations are available. Double_t Result(Int_t event, Int_t index = 0) const; Computes the outpu",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:24714,Usability,learn,learning,24714,"arameters). void SetEta(Double_t eta); Sets Eta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEpsilon(Double_t eps); Sets Epsilon - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetDelta(Double_t delta); Sets Delta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEtaDecay(Double_t ed); Sets EtaDecay - Eta *= EtaDecay at each epoch; (look at the constructor for the complete description; of learning methods and parameters). void SetTau(Double_t tau); Sets Tau - used in line search; (look at the constructor for the complete description; of learning methods and parameters). void SetReset(Int_t reset); Sets number of epochs between two resets of the; search direction to the steepest descent.; (look at the constructor for the complete description; of learning methods and parameters). void GetEntry(Int_t ) const; Load an entry into the network. void Train(Int_t nEpoch, Option_t* option = ""text"", Double_t minE = 0); Train the network.; nEpoch is the number of iterations.; option can contain:; - ""text"" (simple text output); - ""graph"" (evoluting graphical training curves); - ""update=X"" (step for the text/graph output update); - ""+"" will skip the randomisation and start from the previous values.; - ""current"" (draw in the current canvas); - ""minErrorTrain"" (stop when NN error on the training sample gets below minE; - ""minErrorTest"" (stop when NN error on the test sample gets below minE; All combinations are available. Double_t Result(Int_t event, Int_t index = 0) const; Computes the output for a given event.; Look at the output neuron designed by index. Double_t GetError(Int_t event) const; Error on the output for a given event. Double_t GetError(TMultiLayerPerceptron::EDataSet set) const; Error on the whole dataset. Double_",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:24969,Usability,simpl,simple,24969,"d SetDelta(Double_t delta); Sets Delta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEtaDecay(Double_t ed); Sets EtaDecay - Eta *= EtaDecay at each epoch; (look at the constructor for the complete description; of learning methods and parameters). void SetTau(Double_t tau); Sets Tau - used in line search; (look at the constructor for the complete description; of learning methods and parameters). void SetReset(Int_t reset); Sets number of epochs between two resets of the; search direction to the steepest descent.; (look at the constructor for the complete description; of learning methods and parameters). void GetEntry(Int_t ) const; Load an entry into the network. void Train(Int_t nEpoch, Option_t* option = ""text"", Double_t minE = 0); Train the network.; nEpoch is the number of iterations.; option can contain:; - ""text"" (simple text output); - ""graph"" (evoluting graphical training curves); - ""update=X"" (step for the text/graph output update); - ""+"" will skip the randomisation and start from the previous values.; - ""current"" (draw in the current canvas); - ""minErrorTrain"" (stop when NN error on the training sample gets below minE; - ""minErrorTest"" (stop when NN error on the test sample gets below minE; All combinations are available. Double_t Result(Int_t event, Int_t index = 0) const; Computes the output for a given event.; Look at the output neuron designed by index. Double_t GetError(Int_t event) const; Error on the output for a given event. Double_t GetError(TMultiLayerPerceptron::EDataSet set) const; Error on the whole dataset. Double_t GetSumSquareError() const; Error on the output for a given event. Double_t GetCrossEntropyBinary() const; Cross entropy error for sigmoid output neurons, for a given event. Double_t GetCrossEntropy() const; Cross entropy error for a softmax output neuron, for a given event. void ComputeDEDw() const; Compute the DEDw = sum on all training events",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:26763,Usability,simpl,simple,26763,") const; Error on the output for a given event. Double_t GetCrossEntropyBinary() const; Cross entropy error for sigmoid output neurons, for a given event. Double_t GetCrossEntropy() const; Cross entropy error for a softmax output neuron, for a given event. void ComputeDEDw() const; Compute the DEDw = sum on all training events of dedw for each weight; normalized by the number of events. void Randomize() const; Randomize the weights. void AttachData(); Connects the TTree to Neurons in input and output; layers. The formulas associated to each neuron are created; and reported to the network formula manager.; By default, the branch is not normalised since this would degrade; performance for classification jobs.; Normalisation can be requested by putting '@' in front of the formula. void ExpandStructure(); Expand the structure of the first layer. void BuildNetwork(); Instanciates the network from the description. void BuildFirstLayer(TString& ); Instanciates the neurons in input; Inputs are normalised and the type is set to kOff; (simple forward of the formula value). void BuildHiddenLayers(TString& ); Builds hidden layers. void BuildOneHiddenLayer(const TString& sNumNodes, Int_t& layer, Int_t& prevStart, Int_t& prevStop, Bool_t lastLayer); Builds a hidden layer, updates the number of layers. void BuildLastLayer(TString& , Int_t ); Builds the output layer; Neurons are linear combinations of input, by defaul.; If the structure ends with ""!"", neurons are set up for classification,; ie. with a sigmoid (1 neuron) or softmax (more neurons) activation function. void DrawResult(Int_t index = 0, Option_t* option = ""test"") const; Draws the neural net output; It produces an histogram with the output for the two datasets.; Index is the number of the desired output neuron.; ""option"" can contain:; - test or train to select a dataset; - comp to produce a X-Y comparison plot; - nocanv to not create a new TCanvas for the plot. void DumpWeights(Option_t* filename = ""-"") const; Dumps the ",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMutex.html:1510,Availability,error,error,1510," = kFALSE); virtual~TMutex(); voidTObject::AbstractMethod(const char* method) const; Int_tTVirtualMutex::Acquire(); virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual Int_tCleanUp(); virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual TVirtualMutex*Factory(Bool_t recursive = kFALSE); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virt",MatchSource.WIKI,root/html532/TMutex.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMutex.html
https://root.cern/root/html532/TMutex.html:1594,Availability,error,error,1594," Int_tTVirtualMutex::Acquire(); virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual Int_tCleanUp(); virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual TVirtualMutex*Factory(Bool_t recursive = kFALSE); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject:",MatchSource.WIKI,root/html532/TMutex.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMutex.html
https://root.cern/root/html532/TMutex.html:5769,Availability,error,error,5769,"onst char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTObject::MakeZombie(). private:. TMutex(const TMutex&); TMutex&operator=(const TMutex&). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. TMutexImp*fMutexImppointer to mutex implementation. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMutex(Bool_t recursive = kFALSE); Create a mutex lock. The actual mutex implementation will be; provided via the TThreadFactory. Int_t Lock(); Lock the mutex. Returns 0 when no error, EDEADLK when mutex was already; locked by this thread and this mutex is not reentrant. Int_t TryLock(); Try to lock mutex. Returns 0 when no error, EDEADLK when mutex was; already locked by this thread and this mutex is not reentrant. Int_t UnLock(); Unlock the mutex. Returns 0 when no error, EPERM when mutex was already; unlocked by this thread. Int_t CleanUp(); Clean up of mutex. TVirtualMutex * Factory(Bool_t recursive = kFALSE); Create mutex and return pointer to it. Calling function must care; about proper deletion. The function is intended to be used in connection; with the R__LOCKGUARD2 macro for local thread protection. Since ""new"" is; used the TStorage class has to be protected by gGlobalMutex. TMutex(const TMutex& ). TMutex& operator=(const TMutex& ). virtual ~TMutex(); { delete fMutexImp; }. » Author: Fons Rademakers 26/06/97 » Copyright (C) 1995-2000, Rene Brun and Fons Rademakers. *; » Last changed: root/thread:$Id: TMutex.h 29797 2009-08-17 14:35:51Z rdm $ » Last generated: 2011-11-03 20:20; This page",MatchSource.WIKI,root/html532/TMutex.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMutex.html
https://root.cern/root/html532/TMutex.html:5917,Availability,error,error,5917,"const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTObject::MakeZombie(). private:. TMutex(const TMutex&); TMutex&operator=(const TMutex&). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. TMutexImp*fMutexImppointer to mutex implementation. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMutex(Bool_t recursive = kFALSE); Create a mutex lock. The actual mutex implementation will be; provided via the TThreadFactory. Int_t Lock(); Lock the mutex. Returns 0 when no error, EDEADLK when mutex was already; locked by this thread and this mutex is not reentrant. Int_t TryLock(); Try to lock mutex. Returns 0 when no error, EDEADLK when mutex was; already locked by this thread and this mutex is not reentrant. Int_t UnLock(); Unlock the mutex. Returns 0 when no error, EPERM when mutex was already; unlocked by this thread. Int_t CleanUp(); Clean up of mutex. TVirtualMutex * Factory(Bool_t recursive = kFALSE); Create mutex and return pointer to it. Calling function must care; about proper deletion. The function is intended to be used in connection; with the R__LOCKGUARD2 macro for local thread protection. Since ""new"" is; used the TStorage class has to be protected by gGlobalMutex. TMutex(const TMutex& ). TMutex& operator=(const TMutex& ). virtual ~TMutex(); { delete fMutexImp; }. » Author: Fons Rademakers 26/06/97 » Copyright (C) 1995-2000, Rene Brun and Fons Rademakers. *; » Last changed: root/thread:$Id: TMutex.h 29797 2009-08-17 14:35:51Z rdm $ » Last generated: 2011-11-03 20:20; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMutex.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMutex.html
https://root.cern/root/html532/TMutex.html:6063,Availability,error,error,6063,"const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTObject::MakeZombie(). private:. TMutex(const TMutex&); TMutex&operator=(const TMutex&). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. TMutexImp*fMutexImppointer to mutex implementation. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMutex(Bool_t recursive = kFALSE); Create a mutex lock. The actual mutex implementation will be; provided via the TThreadFactory. Int_t Lock(); Lock the mutex. Returns 0 when no error, EDEADLK when mutex was already; locked by this thread and this mutex is not reentrant. Int_t TryLock(); Try to lock mutex. Returns 0 when no error, EDEADLK when mutex was; already locked by this thread and this mutex is not reentrant. Int_t UnLock(); Unlock the mutex. Returns 0 when no error, EPERM when mutex was already; unlocked by this thread. Int_t CleanUp(); Clean up of mutex. TVirtualMutex * Factory(Bool_t recursive = kFALSE); Create mutex and return pointer to it. Calling function must care; about proper deletion. The function is intended to be used in connection; with the R__LOCKGUARD2 macro for local thread protection. Since ""new"" is; used the TStorage class has to be protected by gGlobalMutex. TMutex(const TMutex& ). TMutex& operator=(const TMutex& ). virtual ~TMutex(); { delete fMutexImp; }. » Author: Fons Rademakers 26/06/97 » Copyright (C) 1995-2000, Rene Brun and Fons Rademakers. *; » Last changed: root/thread:$Id: TMutex.h 29797 2009-08-17 14:35:51Z rdm $ » Last generated: 2011-11-03 20:20; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMutex.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMutex.html
https://root.cern/root/html532/TMutexImp.html:543,Availability,avail,available,543,". TMutexImp. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » CORE; » THREAD; » TMutexImp. class TMutexImp: public TObject. TMutexImp. This class provides an abstract interface to the OS dependent mutex; classes (TPosixMutex and TWin32Mutex). Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~TMutexImp(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() c",MatchSource.WIKI,root/html532/TMutexImp.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMutexImp.html
https://root.cern/root/html532/TMutexImp.html:1510,Availability,error,error,1510," virtual~TMutexImp(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() c",MatchSource.WIKI,root/html532/TMutexImp.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMutexImp.html
https://root.cern/root/html532/TMutexImp.html:1594,Availability,error,error,1594," voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTObject",MatchSource.WIKI,root/html532/TMutexImp.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMutexImp.html
https://root.cern/root/html532/TMutexImp.html:333,Integrability,interface,interface,333,". TMutexImp. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » CORE; » THREAD; » TMutexImp. class TMutexImp: public TObject. TMutexImp. This class provides an abstract interface to the OS dependent mutex; classes (TPosixMutex and TWin32Mutex). Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~TMutexImp(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() c",MatchSource.WIKI,root/html532/TMutexImp.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMutexImp.html
https://root.cern/root/html532/TMutexImp.html:353,Integrability,depend,dependent,353,". TMutexImp. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » CORE; » THREAD; » TMutexImp. class TMutexImp: public TObject. TMutexImp. This class provides an abstract interface to the OS dependent mutex; classes (TPosixMutex and TWin32Mutex). Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~TMutexImp(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() c",MatchSource.WIKI,root/html532/TMutexImp.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMutexImp.html
https://root.cern/root/html532/TMVA_Index.html:742,Deployability,configurat,configuration,742," TMVA ; TMVA::BDTEventWrapper ; TMVA::BinarySearchTree Binary search tree including volume search method ; TMVA::BinarySearchTreeNode Node for the BinarySearchTree; TMVA::BinaryTree Base class for BinarySearch and Decision Trees; TMVA::CCPruner ; TMVA::CCTreeWrapper ; TMVA::Config Singleton class for global configuration settings; TMVA::Config::IONames ; TMVA::Config::VariablePlotting ; TMVA::Configurable Virtual base class for all TMVA method; TMVA::CostComplexityPruneTool ; TMVA::CrossEntropy Implementation of the CrossEntropy as separation criterion; TMVA::DecisionTree implementation of a Decision Tree; TMVA::DecisionTreeNode Node for the Decision Tree ; TMVA::Factory The factory creates all MVA methods, and performs their training and testing; TMVA::FitterBase Baseclass for fitters; TMVA::GeneticAlgorithm Genetic algorithm controller; TMVA::GeneticFitter Fitter using a Genetic Algorithm; TMVA::GeneticGenes Genes definition for genetic algorithm; TMVA::GeneticPopulation Population definition for genetic algorithm; TMVA::GeneticRange Range definition for genetic algorithm; TMVA::GiniIndex Implementation of the GiniIndex as separation criterion; TMVA::GiniIndexWithLaplace Implementation of the GiniIndexWithLaplace as separation criterion; TMVA::IFitterTarget base class for a fitter ""target""; TMVA::IMethod Method Interface; TMVA::Interval Interval definition, continous and discrete; TMVA::KDEKernel Kernel density estimator for PDF smoothing; TMVA::MCFitter Fitter using Monte Carlo sampling of parameters ; TMVA::MethodANNBase Base class for TM",MatchSource.WIKI,root/html532/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA_Index.html
https://root.cern/root/html532/TMVA_Index.html:3382,Integrability,interface,interface,3382,"gory ; TMVA::MethodCommittee Analysis of Boosted MVA methods; TMVA::MethodCompositeBase ; TMVA::MethodCuts Multivariate optimisation of signal efficiency; TMVA::MethodDT Analysis of Decision Trees ; TMVA::MethodFDA Function Discriminant Analysis; TMVA::MethodFisher Analysis of Fisher discriminant (Fisher or Mahalanobis approach) ; TMVA::MethodHMatrix H-Matrix method, a simple comparison of chi-squared estimators for signal and background; TMVA::MethodKNN k Nearest Neighbour classifier; TMVA::MethodLD Linear discriminant analysis; TMVA::MethodLikelihood Likelihood analysis (""non-parametric approach"") ; TMVA::MethodMLP Multi-layer perceptron implemented specifically for TMVA; TMVA::MethodPDEFoam Multi-dimensional probability density estimator using TFoam (PDE-Foam); TMVA::MethodPDERS Multi-dimensional probability density estimator range search (PDERS) method; TMVA::MethodRuleFit Friedman's RuleFit method; TMVA::MethodSVM Support Vector Machine; TMVA::MethodTMlpANN Implementation of interface for TMultiLayerPerceptron; TMVA::MinuitFitter Fitter using a Genetic Algorithm; TMVA::MinuitWrapper Wrapper around TMinuit; TMVA::MisClassificationError Implementation of the MisClassificationError as separation criterion; TMVA::MsgLogger Ostringstream derivative to redirect and format logging output; TMVA::Node Node for the BinarySearch or Decision Trees; TMVA::OptimizeConfigParameters Interface to different separation critiera used in training algorithms; TMVA::PDEFoam Tree of PDEFoamCells; TMVA::PDEFoamCell Single cell of FOAM; TMVA::PDEFoamDecisionTree Decision tree like PDEFoam; TMVA::PDEFoamDecisionTreeDensity Class for decision tree like PDEFoam density; TMVA::PDEFoamDensityBase PDEFoam event density interface; TMVA::PDEFoamDiscriminant Tree of PDEFoamCells; TMVA::PDEFoamDiscriminantDensity Class for Discriminant density; TMVA::PDEFoamEvent Tree of PDEFoamCells; TMVA::PDEFoamEventDensity Class for Event density; TMVA::PDEFoamKernelBase PDEFoam kernel interface; TMVA::PDEFoa",MatchSource.WIKI,root/html532/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA_Index.html
https://root.cern/root/html532/TMVA_Index.html:4109,Integrability,interface,interface,4109,ility density estimator using TFoam (PDE-Foam); TMVA::MethodPDERS Multi-dimensional probability density estimator range search (PDERS) method; TMVA::MethodRuleFit Friedman's RuleFit method; TMVA::MethodSVM Support Vector Machine; TMVA::MethodTMlpANN Implementation of interface for TMultiLayerPerceptron; TMVA::MinuitFitter Fitter using a Genetic Algorithm; TMVA::MinuitWrapper Wrapper around TMinuit; TMVA::MisClassificationError Implementation of the MisClassificationError as separation criterion; TMVA::MsgLogger Ostringstream derivative to redirect and format logging output; TMVA::Node Node for the BinarySearch or Decision Trees; TMVA::OptimizeConfigParameters Interface to different separation critiera used in training algorithms; TMVA::PDEFoam Tree of PDEFoamCells; TMVA::PDEFoamCell Single cell of FOAM; TMVA::PDEFoamDecisionTree Decision tree like PDEFoam; TMVA::PDEFoamDecisionTreeDensity Class for decision tree like PDEFoam density; TMVA::PDEFoamDensityBase PDEFoam event density interface; TMVA::PDEFoamDiscriminant Tree of PDEFoamCells; TMVA::PDEFoamDiscriminantDensity Class for Discriminant density; TMVA::PDEFoamEvent Tree of PDEFoamCells; TMVA::PDEFoamEventDensity Class for Event density; TMVA::PDEFoamKernelBase PDEFoam kernel interface; TMVA::PDEFoamKernelGauss Gaussian PDEFoam kernel estimator; TMVA::PDEFoamKernelLinN next neighbor PDEFoam kernel estimator; TMVA::PDEFoamKernelTrivial trivial PDEFoam kernel estimator; TMVA::PDEFoamMultiTarget Tree of PDEFoamCells; TMVA::PDEFoamTarget Tree of PDEFoamCells; TMVA::PDEFoamTargetDensity Class for Target density; TMVA::PDEFoamVect n-dimensional vector with dynamical allocation; TMVA::PDF PDF wrapper for histograms; TMVA::Ranking Method-specific ranking for input variables ; TMVA::Reader Interpret the trained MVAs in an analysis context; TMVA::RegressionVariance Interface to different separation critiera used in training algorithms; TMVA::RootFinder Root finding using Brents algorithm; TMVA::RuleFit Calculations for Fr,MatchSource.WIKI,root/html532/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA_Index.html
https://root.cern/root/html532/TMVA_Index.html:4364,Integrability,interface,interface,4364,mentation of interface for TMultiLayerPerceptron; TMVA::MinuitFitter Fitter using a Genetic Algorithm; TMVA::MinuitWrapper Wrapper around TMinuit; TMVA::MisClassificationError Implementation of the MisClassificationError as separation criterion; TMVA::MsgLogger Ostringstream derivative to redirect and format logging output; TMVA::Node Node for the BinarySearch or Decision Trees; TMVA::OptimizeConfigParameters Interface to different separation critiera used in training algorithms; TMVA::PDEFoam Tree of PDEFoamCells; TMVA::PDEFoamCell Single cell of FOAM; TMVA::PDEFoamDecisionTree Decision tree like PDEFoam; TMVA::PDEFoamDecisionTreeDensity Class for decision tree like PDEFoam density; TMVA::PDEFoamDensityBase PDEFoam event density interface; TMVA::PDEFoamDiscriminant Tree of PDEFoamCells; TMVA::PDEFoamDiscriminantDensity Class for Discriminant density; TMVA::PDEFoamEvent Tree of PDEFoamCells; TMVA::PDEFoamEventDensity Class for Event density; TMVA::PDEFoamKernelBase PDEFoam kernel interface; TMVA::PDEFoamKernelGauss Gaussian PDEFoam kernel estimator; TMVA::PDEFoamKernelLinN next neighbor PDEFoam kernel estimator; TMVA::PDEFoamKernelTrivial trivial PDEFoam kernel estimator; TMVA::PDEFoamMultiTarget Tree of PDEFoamCells; TMVA::PDEFoamTarget Tree of PDEFoamCells; TMVA::PDEFoamTargetDensity Class for Target density; TMVA::PDEFoamVect n-dimensional vector with dynamical allocation; TMVA::PDF PDF wrapper for histograms; TMVA::Ranking Method-specific ranking for input variables ; TMVA::Reader Interpret the trained MVAs in an analysis context; TMVA::RegressionVariance Interface to different separation critiera used in training algorithms; TMVA::RootFinder Root finding using Brents algorithm; TMVA::RuleFit Calculations for Friedman's RuleFit method; TMVA::RuleFitAPI Friedman's RuleFit method; TMVA::SVEvent Event for SVM; TMVA::SdivSqrtSplusB Implementation of the SdivSqrtSplusB as separation criterion; TMVA::SeparationBase Interface to different separation critiera used in tr,MatchSource.WIKI,root/html532/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA_Index.html
https://root.cern/root/html532/TMVA_Index.html:4782,Integrability,wrap,wrapper,4782,rface to different separation critiera used in training algorithms; TMVA::PDEFoam Tree of PDEFoamCells; TMVA::PDEFoamCell Single cell of FOAM; TMVA::PDEFoamDecisionTree Decision tree like PDEFoam; TMVA::PDEFoamDecisionTreeDensity Class for decision tree like PDEFoam density; TMVA::PDEFoamDensityBase PDEFoam event density interface; TMVA::PDEFoamDiscriminant Tree of PDEFoamCells; TMVA::PDEFoamDiscriminantDensity Class for Discriminant density; TMVA::PDEFoamEvent Tree of PDEFoamCells; TMVA::PDEFoamEventDensity Class for Event density; TMVA::PDEFoamKernelBase PDEFoam kernel interface; TMVA::PDEFoamKernelGauss Gaussian PDEFoam kernel estimator; TMVA::PDEFoamKernelLinN next neighbor PDEFoam kernel estimator; TMVA::PDEFoamKernelTrivial trivial PDEFoam kernel estimator; TMVA::PDEFoamMultiTarget Tree of PDEFoamCells; TMVA::PDEFoamTarget Tree of PDEFoamCells; TMVA::PDEFoamTargetDensity Class for Target density; TMVA::PDEFoamVect n-dimensional vector with dynamical allocation; TMVA::PDF PDF wrapper for histograms; TMVA::Ranking Method-specific ranking for input variables ; TMVA::Reader Interpret the trained MVAs in an analysis context; TMVA::RegressionVariance Interface to different separation critiera used in training algorithms; TMVA::RootFinder Root finding using Brents algorithm; TMVA::RuleFit Calculations for Friedman's RuleFit method; TMVA::RuleFitAPI Friedman's RuleFit method; TMVA::SVEvent Event for SVM; TMVA::SdivSqrtSplusB Implementation of the SdivSqrtSplusB as separation criterion; TMVA::SeparationBase Interface to different separation critiera used in training algorithms; TMVA::SimulatedAnnealing Base class for Simulated Annealing fitting; TMVA::SimulatedAnnealingFitter Fitter using a Simulated Annealing Algorithm; TMVA::TActivation Interface for TNeuron activation function classes; TMVA::TActivationChooser Class for choosing activation functions; TMVA::TActivationIdentity Identity activation function for TNeuron; TMVA::TActivationRadial Radial basis activation f,MatchSource.WIKI,root/html532/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA_Index.html
https://root.cern/root/html532/TMVA_Index.html:742,Modifiability,config,configuration,742," TMVA ; TMVA::BDTEventWrapper ; TMVA::BinarySearchTree Binary search tree including volume search method ; TMVA::BinarySearchTreeNode Node for the BinarySearchTree; TMVA::BinaryTree Base class for BinarySearch and Decision Trees; TMVA::CCPruner ; TMVA::CCTreeWrapper ; TMVA::Config Singleton class for global configuration settings; TMVA::Config::IONames ; TMVA::Config::VariablePlotting ; TMVA::Configurable Virtual base class for all TMVA method; TMVA::CostComplexityPruneTool ; TMVA::CrossEntropy Implementation of the CrossEntropy as separation criterion; TMVA::DecisionTree implementation of a Decision Tree; TMVA::DecisionTreeNode Node for the Decision Tree ; TMVA::Factory The factory creates all MVA methods, and performs their training and testing; TMVA::FitterBase Baseclass for fitters; TMVA::GeneticAlgorithm Genetic algorithm controller; TMVA::GeneticFitter Fitter using a Genetic Algorithm; TMVA::GeneticGenes Genes definition for genetic algorithm; TMVA::GeneticPopulation Population definition for genetic algorithm; TMVA::GeneticRange Range definition for genetic algorithm; TMVA::GiniIndex Implementation of the GiniIndex as separation criterion; TMVA::GiniIndexWithLaplace Implementation of the GiniIndexWithLaplace as separation criterion; TMVA::IFitterTarget base class for a fitter ""target""; TMVA::IMethod Method Interface; TMVA::Interval Interval definition, continous and discrete; TMVA::KDEKernel Kernel density estimator for PDF smoothing; TMVA::MCFitter Fitter using Monte Carlo sampling of parameters ; TMVA::MethodANNBase Base class for TM",MatchSource.WIKI,root/html532/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA_Index.html
https://root.cern/root/html532/TMVA_Index.html:4854,Modifiability,variab,variables,4854,:PDEFoam Tree of PDEFoamCells; TMVA::PDEFoamCell Single cell of FOAM; TMVA::PDEFoamDecisionTree Decision tree like PDEFoam; TMVA::PDEFoamDecisionTreeDensity Class for decision tree like PDEFoam density; TMVA::PDEFoamDensityBase PDEFoam event density interface; TMVA::PDEFoamDiscriminant Tree of PDEFoamCells; TMVA::PDEFoamDiscriminantDensity Class for Discriminant density; TMVA::PDEFoamEvent Tree of PDEFoamCells; TMVA::PDEFoamEventDensity Class for Event density; TMVA::PDEFoamKernelBase PDEFoam kernel interface; TMVA::PDEFoamKernelGauss Gaussian PDEFoam kernel estimator; TMVA::PDEFoamKernelLinN next neighbor PDEFoam kernel estimator; TMVA::PDEFoamKernelTrivial trivial PDEFoam kernel estimator; TMVA::PDEFoamMultiTarget Tree of PDEFoamCells; TMVA::PDEFoamTarget Tree of PDEFoamCells; TMVA::PDEFoamTargetDensity Class for Target density; TMVA::PDEFoamVect n-dimensional vector with dynamical allocation; TMVA::PDF PDF wrapper for histograms; TMVA::Ranking Method-specific ranking for input variables ; TMVA::Reader Interpret the trained MVAs in an analysis context; TMVA::RegressionVariance Interface to different separation critiera used in training algorithms; TMVA::RootFinder Root finding using Brents algorithm; TMVA::RuleFit Calculations for Friedman's RuleFit method; TMVA::RuleFitAPI Friedman's RuleFit method; TMVA::SVEvent Event for SVM; TMVA::SdivSqrtSplusB Implementation of the SdivSqrtSplusB as separation criterion; TMVA::SeparationBase Interface to different separation critiera used in training algorithms; TMVA::SimulatedAnnealing Base class for Simulated Annealing fitting; TMVA::SimulatedAnnealingFitter Fitter using a Simulated Annealing Algorithm; TMVA::TActivation Interface for TNeuron activation function classes; TMVA::TActivationChooser Class for choosing activation functions; TMVA::TActivationIdentity Identity activation function for TNeuron; TMVA::TActivationRadial Radial basis activation function for TNeuron; TMVA::TActivationSigmoid Sigmoid activation function,MatchSource.WIKI,root/html532/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA_Index.html
https://root.cern/root/html532/TMVA_Index.html:7132,Modifiability,variab,variable,7132,Friedman's RuleFit method; TMVA::SVEvent Event for SVM; TMVA::SdivSqrtSplusB Implementation of the SdivSqrtSplusB as separation criterion; TMVA::SeparationBase Interface to different separation critiera used in training algorithms; TMVA::SimulatedAnnealing Base class for Simulated Annealing fitting; TMVA::SimulatedAnnealingFitter Fitter using a Simulated Annealing Algorithm; TMVA::TActivation Interface for TNeuron activation function classes; TMVA::TActivationChooser Class for choosing activation functions; TMVA::TActivationIdentity Identity activation function for TNeuron; TMVA::TActivationRadial Radial basis activation function for TNeuron; TMVA::TActivationSigmoid Sigmoid activation function for TNeuron; TMVA::TActivationTanh Tanh sigmoid activation function for TNeuron; TMVA::TNeuron Neuron class used by MethodANNBase derivative ANNs; TMVA::TNeuronInput Interface for TNeuron input calculation classes; TMVA::TNeuronInputAbs Calculates the sum of the absolute values of the weighted inputs; TMVA::TNeuronInputChooser Class for choosing neuron input functions ; TMVA::TNeuronInputSqSum Calculates square of weighted sum of neuron inputs; TMVA::TNeuronInputSum Calculates weighted sum of neuron inputs; TMVA::TSpline1 Linear interpolation class; TMVA::TSpline2 Quadratic interpolation class (using quadrax); TMVA::TSynapse Synapse class used by MethodANNBase and derivatives; TMVA::Timer Timing information for training and evaluation of MVA methods; TMVA::Tools ; TMVA::Types ; TMVA::VariableDecorrTransform Variable transformation: decorrelation; TMVA::VariableGaussTransform Variable transformation: Gauss transformation; TMVA::VariableIdentityTransform Variable transformation: identity; TMVA::VariableNormalizeTransform Variable transformation: normalization; TMVA::VariablePCATransform Variable transformation: Principal Value Composition; TMVA::VariableRearrangeTransform Variable transformation: normalization; TMVA::VariableTransformBase Base class for variable transformations.,MatchSource.WIKI,root/html532/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA_Index.html
https://root.cern/root/html532/TMVA_Index.html:1154,Performance,perform,performs,1154," TMVA ; TMVA::BDTEventWrapper ; TMVA::BinarySearchTree Binary search tree including volume search method ; TMVA::BinarySearchTreeNode Node for the BinarySearchTree; TMVA::BinaryTree Base class for BinarySearch and Decision Trees; TMVA::CCPruner ; TMVA::CCTreeWrapper ; TMVA::Config Singleton class for global configuration settings; TMVA::Config::IONames ; TMVA::Config::VariablePlotting ; TMVA::Configurable Virtual base class for all TMVA method; TMVA::CostComplexityPruneTool ; TMVA::CrossEntropy Implementation of the CrossEntropy as separation criterion; TMVA::DecisionTree implementation of a Decision Tree; TMVA::DecisionTreeNode Node for the Decision Tree ; TMVA::Factory The factory creates all MVA methods, and performs their training and testing; TMVA::FitterBase Baseclass for fitters; TMVA::GeneticAlgorithm Genetic algorithm controller; TMVA::GeneticFitter Fitter using a Genetic Algorithm; TMVA::GeneticGenes Genes definition for genetic algorithm; TMVA::GeneticPopulation Population definition for genetic algorithm; TMVA::GeneticRange Range definition for genetic algorithm; TMVA::GiniIndex Implementation of the GiniIndex as separation criterion; TMVA::GiniIndexWithLaplace Implementation of the GiniIndexWithLaplace as separation criterion; TMVA::IFitterTarget base class for a fitter ""target""; TMVA::IMethod Method Interface; TMVA::Interval Interval definition, continous and discrete; TMVA::KDEKernel Kernel density estimator for PDF smoothing; TMVA::MCFitter Fitter using Monte Carlo sampling of parameters ; TMVA::MethodANNBase Base class for TM",MatchSource.WIKI,root/html532/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA_Index.html
https://root.cern/root/html532/TMVA_Index.html:1182,Testability,test,testing,1182," TMVA ; TMVA::BDTEventWrapper ; TMVA::BinarySearchTree Binary search tree including volume search method ; TMVA::BinarySearchTreeNode Node for the BinarySearchTree; TMVA::BinaryTree Base class for BinarySearch and Decision Trees; TMVA::CCPruner ; TMVA::CCTreeWrapper ; TMVA::Config Singleton class for global configuration settings; TMVA::Config::IONames ; TMVA::Config::VariablePlotting ; TMVA::Configurable Virtual base class for all TMVA method; TMVA::CostComplexityPruneTool ; TMVA::CrossEntropy Implementation of the CrossEntropy as separation criterion; TMVA::DecisionTree implementation of a Decision Tree; TMVA::DecisionTreeNode Node for the Decision Tree ; TMVA::Factory The factory creates all MVA methods, and performs their training and testing; TMVA::FitterBase Baseclass for fitters; TMVA::GeneticAlgorithm Genetic algorithm controller; TMVA::GeneticFitter Fitter using a Genetic Algorithm; TMVA::GeneticGenes Genes definition for genetic algorithm; TMVA::GeneticPopulation Population definition for genetic algorithm; TMVA::GeneticRange Range definition for genetic algorithm; TMVA::GiniIndex Implementation of the GiniIndex as separation criterion; TMVA::GiniIndexWithLaplace Implementation of the GiniIndexWithLaplace as separation criterion; TMVA::IFitterTarget base class for a fitter ""target""; TMVA::IMethod Method Interface; TMVA::Interval Interval definition, continous and discrete; TMVA::KDEKernel Kernel density estimator for PDF smoothing; TMVA::MCFitter Fitter using Monte Carlo sampling of parameters ; TMVA::MethodANNBase Base class for TM",MatchSource.WIKI,root/html532/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA_Index.html
https://root.cern/root/html532/TMVA_Index.html:3679,Testability,log,logging,3679,"t (Fisher or Mahalanobis approach) ; TMVA::MethodHMatrix H-Matrix method, a simple comparison of chi-squared estimators for signal and background; TMVA::MethodKNN k Nearest Neighbour classifier; TMVA::MethodLD Linear discriminant analysis; TMVA::MethodLikelihood Likelihood analysis (""non-parametric approach"") ; TMVA::MethodMLP Multi-layer perceptron implemented specifically for TMVA; TMVA::MethodPDEFoam Multi-dimensional probability density estimator using TFoam (PDE-Foam); TMVA::MethodPDERS Multi-dimensional probability density estimator range search (PDERS) method; TMVA::MethodRuleFit Friedman's RuleFit method; TMVA::MethodSVM Support Vector Machine; TMVA::MethodTMlpANN Implementation of interface for TMultiLayerPerceptron; TMVA::MinuitFitter Fitter using a Genetic Algorithm; TMVA::MinuitWrapper Wrapper around TMinuit; TMVA::MisClassificationError Implementation of the MisClassificationError as separation criterion; TMVA::MsgLogger Ostringstream derivative to redirect and format logging output; TMVA::Node Node for the BinarySearch or Decision Trees; TMVA::OptimizeConfigParameters Interface to different separation critiera used in training algorithms; TMVA::PDEFoam Tree of PDEFoamCells; TMVA::PDEFoamCell Single cell of FOAM; TMVA::PDEFoamDecisionTree Decision tree like PDEFoam; TMVA::PDEFoamDecisionTreeDensity Class for decision tree like PDEFoam density; TMVA::PDEFoamDensityBase PDEFoam event density interface; TMVA::PDEFoamDiscriminant Tree of PDEFoamCells; TMVA::PDEFoamDiscriminantDensity Class for Discriminant density; TMVA::PDEFoamEvent Tree of PDEFoamCells; TMVA::PDEFoamEventDensity Class for Event density; TMVA::PDEFoamKernelBase PDEFoam kernel interface; TMVA::PDEFoamKernelGauss Gaussian PDEFoam kernel estimator; TMVA::PDEFoamKernelLinN next neighbor PDEFoam kernel estimator; TMVA::PDEFoamKernelTrivial trivial PDEFoam kernel estimator; TMVA::PDEFoamMultiTarget Tree of PDEFoamCells; TMVA::PDEFoamTarget Tree of PDEFoamCells; TMVA::PDEFoamTargetDensity Class f",MatchSource.WIKI,root/html532/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA_Index.html
https://root.cern/root/html532/TMVA_Index.html:2759,Usability,simpl,simple,2759,"ethod Interface; TMVA::Interval Interval definition, continous and discrete; TMVA::KDEKernel Kernel density estimator for PDF smoothing; TMVA::MCFitter Fitter using Monte Carlo sampling of parameters ; TMVA::MethodANNBase Base class for TMVA ANNs; TMVA::MethodBDT Analysis of Boosted Decision Trees; TMVA::MethodBase Virtual base class for all TMVA method; TMVA::MethodBayesClassifier Friedman's BayesClassifier method ; TMVA::MethodBoost ; TMVA::MethodCFMlpANN Interface for Clermond-Ferrand artificial neural network; TMVA::MethodCFMlpANN_Utils Implementation of Clermond-Ferrand artificial neural network; TMVA::MethodCategory ; TMVA::MethodCommittee Analysis of Boosted MVA methods; TMVA::MethodCompositeBase ; TMVA::MethodCuts Multivariate optimisation of signal efficiency; TMVA::MethodDT Analysis of Decision Trees ; TMVA::MethodFDA Function Discriminant Analysis; TMVA::MethodFisher Analysis of Fisher discriminant (Fisher or Mahalanobis approach) ; TMVA::MethodHMatrix H-Matrix method, a simple comparison of chi-squared estimators for signal and background; TMVA::MethodKNN k Nearest Neighbour classifier; TMVA::MethodLD Linear discriminant analysis; TMVA::MethodLikelihood Likelihood analysis (""non-parametric approach"") ; TMVA::MethodMLP Multi-layer perceptron implemented specifically for TMVA; TMVA::MethodPDEFoam Multi-dimensional probability density estimator using TFoam (PDE-Foam); TMVA::MethodPDERS Multi-dimensional probability density estimator range search (PDERS) method; TMVA::MethodRuleFit Friedman's RuleFit method; TMVA::MethodSVM Support Vector Machine; TMVA::MethodTMlpANN Implementation of interface for TMultiLayerPerceptron; TMVA::MinuitFitter Fitter using a Genetic Algorithm; TMVA::MinuitWrapper Wrapper around TMinuit; TMVA::MisClassificationError Implementation of the MisClassificationError as separation criterion; TMVA::MsgLogger Ostringstream derivative to redirect and format logging output; TMVA::Node Node for the BinarySearch or Decision Trees; TMVA::Optimi",MatchSource.WIKI,root/html532/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA_Index.html
https://root.cern/root/html532/TMVA__BDTEventWrapper.html:955,Modifiability,variab,variable,955,". TMVA::BDTEventWrapper. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::BDTEventWrapper. class TMVA::BDTEventWrapper. Function Members (Methods); public:. ~BDTEventWrapper(); TMVA::BDTEventWrapperBDTEventWrapper(const TMVA::Event*); TMVA::BDTEventWrapperBDTEventWrapper(const TMVA::BDTEventWrapper&); Double_tGetCumulativeWeight(Bool_t type) const; Double_tGetVal() const; const TMVA::Event*operator*() const; Bool_toperator<(const TMVA::BDTEventWrapper& other) const; voidSetCumulativeWeight(Bool_t type, Double_t weight); static voidSetVarIndex(Int_t iVar). Data Members; private:. Double_tfBkgWeightcumulative background weight for splitting; const TMVA::Event*fEventpointer to the event; Double_tfSigWeightsame for the signal weights; static Int_tfVarIndexindex of the variable to sort on. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; BDTEventWrapper(const Event* e); constuctor. ~BDTEventWrapper(); destructor. void SetCumulativeWeight(Bool_t type, Double_t weight); Set the accumulated weight, for sorted signal/background events. * @param fType - true for signal, false for background; * @param weight - the total weight. Double_t GetCumulativeWeight(Bool_t type) const; Get the accumulated weight. Bool_t operator<(const TMVA::BDTEventWrapper& other) const. BDTEventWrapper( const Event* ). void SetVarIndex(Int_t iVar); Set the index of the variable to compare on. * @param iVar - index of the variable in fEvent to use. { if (iVar >= 0) fVarIndex = iVar; }. Double_t GetVal() const; Return the value of variable fVarIndex for this event. * @return value of variable fVarIndex for this event. { return fEvent->GetValue(fVarIndex); }. const Event* operator*() const; { return fEvent; }. » Last changed: Thu Nov 3 20:19:22 2011 » Last generated: 2011-11-03 20:19; Th",MatchSource.WIKI,root/html532/TMVA__BDTEventWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BDTEventWrapper.html
https://root.cern/root/html532/TMVA__BDTEventWrapper.html:1578,Modifiability,variab,variable,1578,". Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::BDTEventWrapper. class TMVA::BDTEventWrapper. Function Members (Methods); public:. ~BDTEventWrapper(); TMVA::BDTEventWrapperBDTEventWrapper(const TMVA::Event*); TMVA::BDTEventWrapperBDTEventWrapper(const TMVA::BDTEventWrapper&); Double_tGetCumulativeWeight(Bool_t type) const; Double_tGetVal() const; const TMVA::Event*operator*() const; Bool_toperator<(const TMVA::BDTEventWrapper& other) const; voidSetCumulativeWeight(Bool_t type, Double_t weight); static voidSetVarIndex(Int_t iVar). Data Members; private:. Double_tfBkgWeightcumulative background weight for splitting; const TMVA::Event*fEventpointer to the event; Double_tfSigWeightsame for the signal weights; static Int_tfVarIndexindex of the variable to sort on. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; BDTEventWrapper(const Event* e); constuctor. ~BDTEventWrapper(); destructor. void SetCumulativeWeight(Bool_t type, Double_t weight); Set the accumulated weight, for sorted signal/background events. * @param fType - true for signal, false for background; * @param weight - the total weight. Double_t GetCumulativeWeight(Bool_t type) const; Get the accumulated weight. Bool_t operator<(const TMVA::BDTEventWrapper& other) const. BDTEventWrapper( const Event* ). void SetVarIndex(Int_t iVar); Set the index of the variable to compare on. * @param iVar - index of the variable in fEvent to use. { if (iVar >= 0) fVarIndex = iVar; }. Double_t GetVal() const; Return the value of variable fVarIndex for this event. * @return value of variable fVarIndex for this event. { return fEvent->GetValue(fVarIndex); }. const Event* operator*() const; { return fEvent; }. » Last changed: Thu Nov 3 20:19:22 2011 » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__BDTEventWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BDTEventWrapper.html
https://root.cern/root/html532/TMVA__BDTEventWrapper.html:1631,Modifiability,variab,variable,1631,". Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::BDTEventWrapper. class TMVA::BDTEventWrapper. Function Members (Methods); public:. ~BDTEventWrapper(); TMVA::BDTEventWrapperBDTEventWrapper(const TMVA::Event*); TMVA::BDTEventWrapperBDTEventWrapper(const TMVA::BDTEventWrapper&); Double_tGetCumulativeWeight(Bool_t type) const; Double_tGetVal() const; const TMVA::Event*operator*() const; Bool_toperator<(const TMVA::BDTEventWrapper& other) const; voidSetCumulativeWeight(Bool_t type, Double_t weight); static voidSetVarIndex(Int_t iVar). Data Members; private:. Double_tfBkgWeightcumulative background weight for splitting; const TMVA::Event*fEventpointer to the event; Double_tfSigWeightsame for the signal weights; static Int_tfVarIndexindex of the variable to sort on. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; BDTEventWrapper(const Event* e); constuctor. ~BDTEventWrapper(); destructor. void SetCumulativeWeight(Bool_t type, Double_t weight); Set the accumulated weight, for sorted signal/background events. * @param fType - true for signal, false for background; * @param weight - the total weight. Double_t GetCumulativeWeight(Bool_t type) const; Get the accumulated weight. Bool_t operator<(const TMVA::BDTEventWrapper& other) const. BDTEventWrapper( const Event* ). void SetVarIndex(Int_t iVar); Set the index of the variable to compare on. * @param iVar - index of the variable in fEvent to use. { if (iVar >= 0) fVarIndex = iVar; }. Double_t GetVal() const; Return the value of variable fVarIndex for this event. * @return value of variable fVarIndex for this event. { return fEvent->GetValue(fVarIndex); }. const Event* operator*() const; { return fEvent; }. » Last changed: Thu Nov 3 20:19:22 2011 » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__BDTEventWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BDTEventWrapper.html
https://root.cern/root/html532/TMVA__BDTEventWrapper.html:1741,Modifiability,variab,variable,1741,". Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::BDTEventWrapper. class TMVA::BDTEventWrapper. Function Members (Methods); public:. ~BDTEventWrapper(); TMVA::BDTEventWrapperBDTEventWrapper(const TMVA::Event*); TMVA::BDTEventWrapperBDTEventWrapper(const TMVA::BDTEventWrapper&); Double_tGetCumulativeWeight(Bool_t type) const; Double_tGetVal() const; const TMVA::Event*operator*() const; Bool_toperator<(const TMVA::BDTEventWrapper& other) const; voidSetCumulativeWeight(Bool_t type, Double_t weight); static voidSetVarIndex(Int_t iVar). Data Members; private:. Double_tfBkgWeightcumulative background weight for splitting; const TMVA::Event*fEventpointer to the event; Double_tfSigWeightsame for the signal weights; static Int_tfVarIndexindex of the variable to sort on. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; BDTEventWrapper(const Event* e); constuctor. ~BDTEventWrapper(); destructor. void SetCumulativeWeight(Bool_t type, Double_t weight); Set the accumulated weight, for sorted signal/background events. * @param fType - true for signal, false for background; * @param weight - the total weight. Double_t GetCumulativeWeight(Bool_t type) const; Get the accumulated weight. Bool_t operator<(const TMVA::BDTEventWrapper& other) const. BDTEventWrapper( const Event* ). void SetVarIndex(Int_t iVar); Set the index of the variable to compare on. * @param iVar - index of the variable in fEvent to use. { if (iVar >= 0) fVarIndex = iVar; }. Double_t GetVal() const; Return the value of variable fVarIndex for this event. * @return value of variable fVarIndex for this event. { return fEvent->GetValue(fVarIndex); }. const Event* operator*() const; { return fEvent; }. » Last changed: Thu Nov 3 20:19:22 2011 » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__BDTEventWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BDTEventWrapper.html
https://root.cern/root/html532/TMVA__BDTEventWrapper.html:1795,Modifiability,variab,variable,1795,". Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::BDTEventWrapper. class TMVA::BDTEventWrapper. Function Members (Methods); public:. ~BDTEventWrapper(); TMVA::BDTEventWrapperBDTEventWrapper(const TMVA::Event*); TMVA::BDTEventWrapperBDTEventWrapper(const TMVA::BDTEventWrapper&); Double_tGetCumulativeWeight(Bool_t type) const; Double_tGetVal() const; const TMVA::Event*operator*() const; Bool_toperator<(const TMVA::BDTEventWrapper& other) const; voidSetCumulativeWeight(Bool_t type, Double_t weight); static voidSetVarIndex(Int_t iVar). Data Members; private:. Double_tfBkgWeightcumulative background weight for splitting; const TMVA::Event*fEventpointer to the event; Double_tfSigWeightsame for the signal weights; static Int_tfVarIndexindex of the variable to sort on. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; BDTEventWrapper(const Event* e); constuctor. ~BDTEventWrapper(); destructor. void SetCumulativeWeight(Bool_t type, Double_t weight); Set the accumulated weight, for sorted signal/background events. * @param fType - true for signal, false for background; * @param weight - the total weight. Double_t GetCumulativeWeight(Bool_t type) const; Get the accumulated weight. Bool_t operator<(const TMVA::BDTEventWrapper& other) const. BDTEventWrapper( const Event* ). void SetVarIndex(Int_t iVar); Set the index of the variable to compare on. * @param iVar - index of the variable in fEvent to use. { if (iVar >= 0) fVarIndex = iVar; }. Double_t GetVal() const; Return the value of variable fVarIndex for this event. * @return value of variable fVarIndex for this event. { return fEvent->GetValue(fVarIndex); }. const Event* operator*() const; { return fEvent; }. » Last changed: Thu Nov 3 20:19:22 2011 » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__BDTEventWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BDTEventWrapper.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:3882,Modifiability,variab,variable,3882,"terator, UInt_t); TMVA::BinarySearchTreeNode*Search(TMVA::Event*, TMVA::Node*) const; Double_tSearchVolume(TMVA::Node*, TMVA::Volume*, Int_t, vector<const TMVA::BinarySearchTreeNode*>* events). Data Members; protected:. UInt_tTMVA::BinaryTree::fDepthmaximal depth in tree reached; UInt_tTMVA::BinaryTree::fNNodestotal number of nodes in the tree (counted); TMVA::Node*TMVA::BinaryTree::fRootthe root node of the tree; static TMVA::MsgLogger*TMVA::BinaryTree::fgLoggermessage logger, static to save resources . private:. Bool_tfCanNormalizethe tree can be normalised; UInt_tfCurrentDepthinternal variable, counting the depth of the tree during insertion ; vector<Float_t>fMax[2]RMS for signal and background for each variable; vector<Float_t>fMeans[2]mean for signal and background for each variable; vector<Float_t>fMin[2]RMS for signal and background for each variable; Double_tfNEventsW[2]Number of events per class, taking into account event weights; vector<std::pair<Double_t,const TMVA::Event*> >fNormalizeTreeTable; UInt_tfPeriodperiode (number of event variables); vector<Float_t>fRMS[2]RMS for signal and background for each variable; Bool_tfStatisticsIsValidflag if last stat calculation is still valid, set to false if new node is insert; vector<Double_t>fSum[2]Sum for signal and background for each variable; Double_tfSumOfWeightsTotal number of events (weigthed) counted during filling; vector<Double_t>fSumSq[2]Squared Sum for signal and background for each variable. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; BinarySearchTree(const TMVA::BinarySearchTree& b); default constructor. BinarySearchTree(const TMVA::BinarySearchTree& b); copy constructor that creates a true copy, i.e. a completely independent tree. ~BinarySearchTree( void ); destructor. TMVA::BinarySearchTree* CreateFromXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); re-create a new tree (decision tree or search tree) from XML. void Insert(const TMVA::Eve",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:4003,Modifiability,variab,variable,4003,"terator, UInt_t); TMVA::BinarySearchTreeNode*Search(TMVA::Event*, TMVA::Node*) const; Double_tSearchVolume(TMVA::Node*, TMVA::Volume*, Int_t, vector<const TMVA::BinarySearchTreeNode*>* events). Data Members; protected:. UInt_tTMVA::BinaryTree::fDepthmaximal depth in tree reached; UInt_tTMVA::BinaryTree::fNNodestotal number of nodes in the tree (counted); TMVA::Node*TMVA::BinaryTree::fRootthe root node of the tree; static TMVA::MsgLogger*TMVA::BinaryTree::fgLoggermessage logger, static to save resources . private:. Bool_tfCanNormalizethe tree can be normalised; UInt_tfCurrentDepthinternal variable, counting the depth of the tree during insertion ; vector<Float_t>fMax[2]RMS for signal and background for each variable; vector<Float_t>fMeans[2]mean for signal and background for each variable; vector<Float_t>fMin[2]RMS for signal and background for each variable; Double_tfNEventsW[2]Number of events per class, taking into account event weights; vector<std::pair<Double_t,const TMVA::Event*> >fNormalizeTreeTable; UInt_tfPeriodperiode (number of event variables); vector<Float_t>fRMS[2]RMS for signal and background for each variable; Bool_tfStatisticsIsValidflag if last stat calculation is still valid, set to false if new node is insert; vector<Double_t>fSum[2]Sum for signal and background for each variable; Double_tfSumOfWeightsTotal number of events (weigthed) counted during filling; vector<Double_t>fSumSq[2]Squared Sum for signal and background for each variable. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; BinarySearchTree(const TMVA::BinarySearchTree& b); default constructor. BinarySearchTree(const TMVA::BinarySearchTree& b); copy constructor that creates a true copy, i.e. a completely independent tree. ~BinarySearchTree( void ); destructor. TMVA::BinarySearchTree* CreateFromXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); re-create a new tree (decision tree or search tree) from XML. void Insert(const TMVA::Eve",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:4077,Modifiability,variab,variable,4077,"terator, UInt_t); TMVA::BinarySearchTreeNode*Search(TMVA::Event*, TMVA::Node*) const; Double_tSearchVolume(TMVA::Node*, TMVA::Volume*, Int_t, vector<const TMVA::BinarySearchTreeNode*>* events). Data Members; protected:. UInt_tTMVA::BinaryTree::fDepthmaximal depth in tree reached; UInt_tTMVA::BinaryTree::fNNodestotal number of nodes in the tree (counted); TMVA::Node*TMVA::BinaryTree::fRootthe root node of the tree; static TMVA::MsgLogger*TMVA::BinaryTree::fgLoggermessage logger, static to save resources . private:. Bool_tfCanNormalizethe tree can be normalised; UInt_tfCurrentDepthinternal variable, counting the depth of the tree during insertion ; vector<Float_t>fMax[2]RMS for signal and background for each variable; vector<Float_t>fMeans[2]mean for signal and background for each variable; vector<Float_t>fMin[2]RMS for signal and background for each variable; Double_tfNEventsW[2]Number of events per class, taking into account event weights; vector<std::pair<Double_t,const TMVA::Event*> >fNormalizeTreeTable; UInt_tfPeriodperiode (number of event variables); vector<Float_t>fRMS[2]RMS for signal and background for each variable; Bool_tfStatisticsIsValidflag if last stat calculation is still valid, set to false if new node is insert; vector<Double_t>fSum[2]Sum for signal and background for each variable; Double_tfSumOfWeightsTotal number of events (weigthed) counted during filling; vector<Double_t>fSumSq[2]Squared Sum for signal and background for each variable. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; BinarySearchTree(const TMVA::BinarySearchTree& b); default constructor. BinarySearchTree(const TMVA::BinarySearchTree& b); copy constructor that creates a true copy, i.e. a completely independent tree. ~BinarySearchTree( void ); destructor. TMVA::BinarySearchTree* CreateFromXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); re-create a new tree (decision tree or search tree) from XML. void Insert(const TMVA::Eve",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:4148,Modifiability,variab,variable,4148,"terator, UInt_t); TMVA::BinarySearchTreeNode*Search(TMVA::Event*, TMVA::Node*) const; Double_tSearchVolume(TMVA::Node*, TMVA::Volume*, Int_t, vector<const TMVA::BinarySearchTreeNode*>* events). Data Members; protected:. UInt_tTMVA::BinaryTree::fDepthmaximal depth in tree reached; UInt_tTMVA::BinaryTree::fNNodestotal number of nodes in the tree (counted); TMVA::Node*TMVA::BinaryTree::fRootthe root node of the tree; static TMVA::MsgLogger*TMVA::BinaryTree::fgLoggermessage logger, static to save resources . private:. Bool_tfCanNormalizethe tree can be normalised; UInt_tfCurrentDepthinternal variable, counting the depth of the tree during insertion ; vector<Float_t>fMax[2]RMS for signal and background for each variable; vector<Float_t>fMeans[2]mean for signal and background for each variable; vector<Float_t>fMin[2]RMS for signal and background for each variable; Double_tfNEventsW[2]Number of events per class, taking into account event weights; vector<std::pair<Double_t,const TMVA::Event*> >fNormalizeTreeTable; UInt_tfPeriodperiode (number of event variables); vector<Float_t>fRMS[2]RMS for signal and background for each variable; Bool_tfStatisticsIsValidflag if last stat calculation is still valid, set to false if new node is insert; vector<Double_t>fSum[2]Sum for signal and background for each variable; Double_tfSumOfWeightsTotal number of events (weigthed) counted during filling; vector<Double_t>fSumSq[2]Squared Sum for signal and background for each variable. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; BinarySearchTree(const TMVA::BinarySearchTree& b); default constructor. BinarySearchTree(const TMVA::BinarySearchTree& b); copy constructor that creates a true copy, i.e. a completely independent tree. ~BinarySearchTree( void ); destructor. TMVA::BinarySearchTree* CreateFromXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); re-create a new tree (decision tree or search tree) from XML. void Insert(const TMVA::Eve",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:4347,Modifiability,variab,variables,4347,"terator, UInt_t); TMVA::BinarySearchTreeNode*Search(TMVA::Event*, TMVA::Node*) const; Double_tSearchVolume(TMVA::Node*, TMVA::Volume*, Int_t, vector<const TMVA::BinarySearchTreeNode*>* events). Data Members; protected:. UInt_tTMVA::BinaryTree::fDepthmaximal depth in tree reached; UInt_tTMVA::BinaryTree::fNNodestotal number of nodes in the tree (counted); TMVA::Node*TMVA::BinaryTree::fRootthe root node of the tree; static TMVA::MsgLogger*TMVA::BinaryTree::fgLoggermessage logger, static to save resources . private:. Bool_tfCanNormalizethe tree can be normalised; UInt_tfCurrentDepthinternal variable, counting the depth of the tree during insertion ; vector<Float_t>fMax[2]RMS for signal and background for each variable; vector<Float_t>fMeans[2]mean for signal and background for each variable; vector<Float_t>fMin[2]RMS for signal and background for each variable; Double_tfNEventsW[2]Number of events per class, taking into account event weights; vector<std::pair<Double_t,const TMVA::Event*> >fNormalizeTreeTable; UInt_tfPeriodperiode (number of event variables); vector<Float_t>fRMS[2]RMS for signal and background for each variable; Bool_tfStatisticsIsValidflag if last stat calculation is still valid, set to false if new node is insert; vector<Double_t>fSum[2]Sum for signal and background for each variable; Double_tfSumOfWeightsTotal number of events (weigthed) counted during filling; vector<Double_t>fSumSq[2]Squared Sum for signal and background for each variable. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; BinarySearchTree(const TMVA::BinarySearchTree& b); default constructor. BinarySearchTree(const TMVA::BinarySearchTree& b); copy constructor that creates a true copy, i.e. a completely independent tree. ~BinarySearchTree( void ); destructor. TMVA::BinarySearchTree* CreateFromXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); re-create a new tree (decision tree or search tree) from XML. void Insert(const TMVA::Eve",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:4420,Modifiability,variab,variable,4420,"terator, UInt_t); TMVA::BinarySearchTreeNode*Search(TMVA::Event*, TMVA::Node*) const; Double_tSearchVolume(TMVA::Node*, TMVA::Volume*, Int_t, vector<const TMVA::BinarySearchTreeNode*>* events). Data Members; protected:. UInt_tTMVA::BinaryTree::fDepthmaximal depth in tree reached; UInt_tTMVA::BinaryTree::fNNodestotal number of nodes in the tree (counted); TMVA::Node*TMVA::BinaryTree::fRootthe root node of the tree; static TMVA::MsgLogger*TMVA::BinaryTree::fgLoggermessage logger, static to save resources . private:. Bool_tfCanNormalizethe tree can be normalised; UInt_tfCurrentDepthinternal variable, counting the depth of the tree during insertion ; vector<Float_t>fMax[2]RMS for signal and background for each variable; vector<Float_t>fMeans[2]mean for signal and background for each variable; vector<Float_t>fMin[2]RMS for signal and background for each variable; Double_tfNEventsW[2]Number of events per class, taking into account event weights; vector<std::pair<Double_t,const TMVA::Event*> >fNormalizeTreeTable; UInt_tfPeriodperiode (number of event variables); vector<Float_t>fRMS[2]RMS for signal and background for each variable; Bool_tfStatisticsIsValidflag if last stat calculation is still valid, set to false if new node is insert; vector<Double_t>fSum[2]Sum for signal and background for each variable; Double_tfSumOfWeightsTotal number of events (weigthed) counted during filling; vector<Double_t>fSumSq[2]Squared Sum for signal and background for each variable. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; BinarySearchTree(const TMVA::BinarySearchTree& b); default constructor. BinarySearchTree(const TMVA::BinarySearchTree& b); copy constructor that creates a true copy, i.e. a completely independent tree. ~BinarySearchTree( void ); destructor. TMVA::BinarySearchTree* CreateFromXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); re-create a new tree (decision tree or search tree) from XML. void Insert(const TMVA::Eve",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:4598,Modifiability,variab,variable,4598,"terator, UInt_t); TMVA::BinarySearchTreeNode*Search(TMVA::Event*, TMVA::Node*) const; Double_tSearchVolume(TMVA::Node*, TMVA::Volume*, Int_t, vector<const TMVA::BinarySearchTreeNode*>* events). Data Members; protected:. UInt_tTMVA::BinaryTree::fDepthmaximal depth in tree reached; UInt_tTMVA::BinaryTree::fNNodestotal number of nodes in the tree (counted); TMVA::Node*TMVA::BinaryTree::fRootthe root node of the tree; static TMVA::MsgLogger*TMVA::BinaryTree::fgLoggermessage logger, static to save resources . private:. Bool_tfCanNormalizethe tree can be normalised; UInt_tfCurrentDepthinternal variable, counting the depth of the tree during insertion ; vector<Float_t>fMax[2]RMS for signal and background for each variable; vector<Float_t>fMeans[2]mean for signal and background for each variable; vector<Float_t>fMin[2]RMS for signal and background for each variable; Double_tfNEventsW[2]Number of events per class, taking into account event weights; vector<std::pair<Double_t,const TMVA::Event*> >fNormalizeTreeTable; UInt_tfPeriodperiode (number of event variables); vector<Float_t>fRMS[2]RMS for signal and background for each variable; Bool_tfStatisticsIsValidflag if last stat calculation is still valid, set to false if new node is insert; vector<Double_t>fSum[2]Sum for signal and background for each variable; Double_tfSumOfWeightsTotal number of events (weigthed) counted during filling; vector<Double_t>fSumSq[2]Squared Sum for signal and background for each variable. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; BinarySearchTree(const TMVA::BinarySearchTree& b); default constructor. BinarySearchTree(const TMVA::BinarySearchTree& b); copy constructor that creates a true copy, i.e. a completely independent tree. ~BinarySearchTree( void ); destructor. TMVA::BinarySearchTree* CreateFromXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); re-create a new tree (decision tree or search tree) from XML. void Insert(const TMVA::Eve",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:4759,Modifiability,variab,variable,4759,"terator, UInt_t); TMVA::BinarySearchTreeNode*Search(TMVA::Event*, TMVA::Node*) const; Double_tSearchVolume(TMVA::Node*, TMVA::Volume*, Int_t, vector<const TMVA::BinarySearchTreeNode*>* events). Data Members; protected:. UInt_tTMVA::BinaryTree::fDepthmaximal depth in tree reached; UInt_tTMVA::BinaryTree::fNNodestotal number of nodes in the tree (counted); TMVA::Node*TMVA::BinaryTree::fRootthe root node of the tree; static TMVA::MsgLogger*TMVA::BinaryTree::fgLoggermessage logger, static to save resources . private:. Bool_tfCanNormalizethe tree can be normalised; UInt_tfCurrentDepthinternal variable, counting the depth of the tree during insertion ; vector<Float_t>fMax[2]RMS for signal and background for each variable; vector<Float_t>fMeans[2]mean for signal and background for each variable; vector<Float_t>fMin[2]RMS for signal and background for each variable; Double_tfNEventsW[2]Number of events per class, taking into account event weights; vector<std::pair<Double_t,const TMVA::Event*> >fNormalizeTreeTable; UInt_tfPeriodperiode (number of event variables); vector<Float_t>fRMS[2]RMS for signal and background for each variable; Bool_tfStatisticsIsValidflag if last stat calculation is still valid, set to false if new node is insert; vector<Double_t>fSum[2]Sum for signal and background for each variable; Double_tfSumOfWeightsTotal number of events (weigthed) counted during filling; vector<Double_t>fSumSq[2]Squared Sum for signal and background for each variable. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; BinarySearchTree(const TMVA::BinarySearchTree& b); default constructor. BinarySearchTree(const TMVA::BinarySearchTree& b); copy constructor that creates a true copy, i.e. a completely independent tree. ~BinarySearchTree( void ); destructor. TMVA::BinarySearchTree* CreateFromXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); re-create a new tree (decision tree or search tree) from XML. void Insert(const TMVA::Eve",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:6026,Modifiability,variab,variables,6026,"::BinarySearchTree& b); copy constructor that creates a true copy, i.e. a completely independent tree. ~BinarySearchTree( void ); destructor. TMVA::BinarySearchTree* CreateFromXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); re-create a new tree (decision tree or search tree) from XML. void Insert(const TMVA::Event* ); insert a new ""event"" in the binary tree. void Insert(const TMVA::Event* , TMVA::Node* ); private internal function to insert a event (node) at the proper position. TMVA::BinarySearchTreeNode* Search(TMVA::Event* event) const; search the tree to find the node matching ""event"". TMVA::BinarySearchTreeNode* Search(TMVA::Event* , TMVA::Node* ) const; Private, recursive, function for searching. Double_t GetSumOfWeights(Int_t theType) const; return the sum of event (node) weights. Double_t GetSumOfWeights(Int_t theType) const; return the sum of event (node) weights. Double_t Fill(const vector<TMVA::Event*>& events, const vector<Int_t>& theVars, Int_t theType = -1); create the search tree from the event collection; using ONLY the variables specified in ""theVars"". Double_t Fill(const vector<TMVA::Event*>& events, Int_t theType = -1); create the search tree from the events in a TTree; using ALL the variables specified included in the Event. void NormalizeTree(vector<pair<double,const TMVA::Event*>,allocator<pair<double,const TMVA::Event*> > >::iterator , vector<pair<double,const TMVA::Event*>,allocator<pair<double,const TMVA::Event*> > >::iterator , UInt_t ). void NormalizeTree(); Normalisation of tree. void Clear(TMVA::Node* n = 0); clear nodes. Double_t SearchVolume(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0); search the whole tree and add up all weigths of events that; lie within the given voluem. Double_t SearchVolume(TMVA::Node* , TMVA::Volume* , Int_t , vector<const TMVA::BinarySearchTreeNode*>* events); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume. ",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:6196,Modifiability,variab,variables,6196,"e, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); re-create a new tree (decision tree or search tree) from XML. void Insert(const TMVA::Event* ); insert a new ""event"" in the binary tree. void Insert(const TMVA::Event* , TMVA::Node* ); private internal function to insert a event (node) at the proper position. TMVA::BinarySearchTreeNode* Search(TMVA::Event* event) const; search the tree to find the node matching ""event"". TMVA::BinarySearchTreeNode* Search(TMVA::Event* , TMVA::Node* ) const; Private, recursive, function for searching. Double_t GetSumOfWeights(Int_t theType) const; return the sum of event (node) weights. Double_t GetSumOfWeights(Int_t theType) const; return the sum of event (node) weights. Double_t Fill(const vector<TMVA::Event*>& events, const vector<Int_t>& theVars, Int_t theType = -1); create the search tree from the event collection; using ONLY the variables specified in ""theVars"". Double_t Fill(const vector<TMVA::Event*>& events, Int_t theType = -1); create the search tree from the events in a TTree; using ALL the variables specified included in the Event. void NormalizeTree(vector<pair<double,const TMVA::Event*>,allocator<pair<double,const TMVA::Event*> > >::iterator , vector<pair<double,const TMVA::Event*>,allocator<pair<double,const TMVA::Event*> > >::iterator , UInt_t ). void NormalizeTree(); Normalisation of tree. void Clear(TMVA::Node* n = 0); clear nodes. Double_t SearchVolume(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0); search the whole tree and add up all weigths of events that; lie within the given voluem. Double_t SearchVolume(TMVA::Node* , TMVA::Volume* , Int_t , vector<const TMVA::BinarySearchTreeNode*>* events); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume. Bool_t InVolume(const vector<Float_t>& , TMVA::Volume* ) const; test if the data points are in the given volume. void CalcStatistics(TMVA::Node* n = 0, Int_t signalClass = 0); calculate basi",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:7182,Modifiability,variab,variable,7182,"create the search tree from the events in a TTree; using ALL the variables specified included in the Event. void NormalizeTree(vector<pair<double,const TMVA::Event*>,allocator<pair<double,const TMVA::Event*> > >::iterator , vector<pair<double,const TMVA::Event*>,allocator<pair<double,const TMVA::Event*> > >::iterator , UInt_t ). void NormalizeTree(); Normalisation of tree. void Clear(TMVA::Node* n = 0); clear nodes. Double_t SearchVolume(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0); search the whole tree and add up all weigths of events that; lie within the given voluem. Double_t SearchVolume(TMVA::Node* , TMVA::Volume* , Int_t , vector<const TMVA::BinarySearchTreeNode*>* events); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume. Bool_t InVolume(const vector<Float_t>& , TMVA::Volume* ) const; test if the data points are in the given volume. void CalcStatistics(TMVA::Node* n = 0, Int_t signalClass = 0); calculate basic statistics (mean, rms for each variable). Int_t SearchVolumeWithMaxLimit(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0, Int_t = -1); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume a maximum number of events can be given. Node * CreateNode(UInt_t ) const; { return new BinarySearchTreeNode(); }. BinaryTree* CreateTree() const; { return new BinarySearchTree(); }. const char* ClassName() const; { return ""BinarySearchTree""; }. void SetPeriode(Int_t p); set the periode (number of variables). { fPeriod = p; }. UInt_t GetPeriode( void ); return periode (number of variables). { return fPeriod; }. Float_t Mean(TMVA::Types::ESBType sb, UInt_t var); access to mean for signal and background for each variable. { return fMeans[sb==Types::kSignal?0:1][var]; }. Float_t RMS(TMVA::Types::ESBType sb, UInt_t var); access to RMS for signal and background for each variable. { return fRMS[sb==Types::kSig",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:7718,Modifiability,variab,variables,7718,"nts that; lie within the given voluem. Double_t SearchVolume(TMVA::Node* , TMVA::Volume* , Int_t , vector<const TMVA::BinarySearchTreeNode*>* events); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume. Bool_t InVolume(const vector<Float_t>& , TMVA::Volume* ) const; test if the data points are in the given volume. void CalcStatistics(TMVA::Node* n = 0, Int_t signalClass = 0); calculate basic statistics (mean, rms for each variable). Int_t SearchVolumeWithMaxLimit(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0, Int_t = -1); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume a maximum number of events can be given. Node * CreateNode(UInt_t ) const; { return new BinarySearchTreeNode(); }. BinaryTree* CreateTree() const; { return new BinarySearchTree(); }. const char* ClassName() const; { return ""BinarySearchTree""; }. void SetPeriode(Int_t p); set the periode (number of variables). { fPeriod = p; }. UInt_t GetPeriode( void ); return periode (number of variables). { return fPeriod; }. Float_t Mean(TMVA::Types::ESBType sb, UInt_t var); access to mean for signal and background for each variable. { return fMeans[sb==Types::kSignal?0:1][var]; }. Float_t RMS(TMVA::Types::ESBType sb, UInt_t var); access to RMS for signal and background for each variable. { return fRMS[sb==Types::kSignal?0:1][var]; }. Float_t Min(TMVA::Types::ESBType sb, UInt_t var); access to Minimum for signal and background for each variable. { return fMin[sb==Types::kSignal?0:1][var]; }. Float_t Max(TMVA::Types::ESBType sb, UInt_t var); access to Maximum for signal and background for each variable. { return fMax[sb==Types::kSignal?0:1][var]; }. Float_t RMS(UInt_t var); access to RMS for each variable. { return fRMS[0][var]; }. void SetNormalize(Bool_t norm); { fCanNormalize = norm; }. void DestroyNode(TMVA::BinarySearchTreeNode* ). » Author: Andreas Hoecker, Joerg Ste",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:7801,Modifiability,variab,variables,7801,"lume* , Int_t , vector<const TMVA::BinarySearchTreeNode*>* events); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume. Bool_t InVolume(const vector<Float_t>& , TMVA::Volume* ) const; test if the data points are in the given volume. void CalcStatistics(TMVA::Node* n = 0, Int_t signalClass = 0); calculate basic statistics (mean, rms for each variable). Int_t SearchVolumeWithMaxLimit(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0, Int_t = -1); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume a maximum number of events can be given. Node * CreateNode(UInt_t ) const; { return new BinarySearchTreeNode(); }. BinaryTree* CreateTree() const; { return new BinarySearchTree(); }. const char* ClassName() const; { return ""BinarySearchTree""; }. void SetPeriode(Int_t p); set the periode (number of variables). { fPeriod = p; }. UInt_t GetPeriode( void ); return periode (number of variables). { return fPeriod; }. Float_t Mean(TMVA::Types::ESBType sb, UInt_t var); access to mean for signal and background for each variable. { return fMeans[sb==Types::kSignal?0:1][var]; }. Float_t RMS(TMVA::Types::ESBType sb, UInt_t var); access to RMS for signal and background for each variable. { return fRMS[sb==Types::kSignal?0:1][var]; }. Float_t Min(TMVA::Types::ESBType sb, UInt_t var); access to Minimum for signal and background for each variable. { return fMin[sb==Types::kSignal?0:1][var]; }. Float_t Max(TMVA::Types::ESBType sb, UInt_t var); access to Maximum for signal and background for each variable. { return fMax[sb==Types::kSignal?0:1][var]; }. Float_t RMS(UInt_t var); access to RMS for each variable. { return fRMS[0][var]; }. void SetNormalize(Bool_t norm); { fCanNormalize = norm; }. void DestroyNode(TMVA::BinarySearchTreeNode* ). » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: ",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:7935,Modifiability,variab,variable,7935,"es and add up all weigths of events that; lie within the given volume. Bool_t InVolume(const vector<Float_t>& , TMVA::Volume* ) const; test if the data points are in the given volume. void CalcStatistics(TMVA::Node* n = 0, Int_t signalClass = 0); calculate basic statistics (mean, rms for each variable). Int_t SearchVolumeWithMaxLimit(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0, Int_t = -1); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume a maximum number of events can be given. Node * CreateNode(UInt_t ) const; { return new BinarySearchTreeNode(); }. BinaryTree* CreateTree() const; { return new BinarySearchTree(); }. const char* ClassName() const; { return ""BinarySearchTree""; }. void SetPeriode(Int_t p); set the periode (number of variables). { fPeriod = p; }. UInt_t GetPeriode( void ); return periode (number of variables). { return fPeriod; }. Float_t Mean(TMVA::Types::ESBType sb, UInt_t var); access to mean for signal and background for each variable. { return fMeans[sb==Types::kSignal?0:1][var]; }. Float_t RMS(TMVA::Types::ESBType sb, UInt_t var); access to RMS for signal and background for each variable. { return fRMS[sb==Types::kSignal?0:1][var]; }. Float_t Min(TMVA::Types::ESBType sb, UInt_t var); access to Minimum for signal and background for each variable. { return fMin[sb==Types::kSignal?0:1][var]; }. Float_t Max(TMVA::Types::ESBType sb, UInt_t var); access to Maximum for signal and background for each variable. { return fMax[sb==Types::kSignal?0:1][var]; }. Float_t RMS(UInt_t var); access to RMS for each variable. { return fRMS[0][var]; }. void SetNormalize(Bool_t norm); { fCanNormalize = norm; }. void DestroyNode(TMVA::BinarySearchTreeNode* ). » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: BinarySearchTree.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has bee",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:8093,Modifiability,variab,variable,8093," if the data points are in the given volume. void CalcStatistics(TMVA::Node* n = 0, Int_t signalClass = 0); calculate basic statistics (mean, rms for each variable). Int_t SearchVolumeWithMaxLimit(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0, Int_t = -1); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume a maximum number of events can be given. Node * CreateNode(UInt_t ) const; { return new BinarySearchTreeNode(); }. BinaryTree* CreateTree() const; { return new BinarySearchTree(); }. const char* ClassName() const; { return ""BinarySearchTree""; }. void SetPeriode(Int_t p); set the periode (number of variables). { fPeriod = p; }. UInt_t GetPeriode( void ); return periode (number of variables). { return fPeriod; }. Float_t Mean(TMVA::Types::ESBType sb, UInt_t var); access to mean for signal and background for each variable. { return fMeans[sb==Types::kSignal?0:1][var]; }. Float_t RMS(TMVA::Types::ESBType sb, UInt_t var); access to RMS for signal and background for each variable. { return fRMS[sb==Types::kSignal?0:1][var]; }. Float_t Min(TMVA::Types::ESBType sb, UInt_t var); access to Minimum for signal and background for each variable. { return fMin[sb==Types::kSignal?0:1][var]; }. Float_t Max(TMVA::Types::ESBType sb, UInt_t var); access to Maximum for signal and background for each variable. { return fMax[sb==Types::kSignal?0:1][var]; }. Float_t RMS(UInt_t var); access to RMS for each variable. { return fRMS[0][var]; }. void SetNormalize(Bool_t norm); { fCanNormalize = norm; }. void DestroyNode(TMVA::BinarySearchTreeNode* ). » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: BinarySearchTree.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:8253,Modifiability,variab,variable,8253," if the data points are in the given volume. void CalcStatistics(TMVA::Node* n = 0, Int_t signalClass = 0); calculate basic statistics (mean, rms for each variable). Int_t SearchVolumeWithMaxLimit(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0, Int_t = -1); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume a maximum number of events can be given. Node * CreateNode(UInt_t ) const; { return new BinarySearchTreeNode(); }. BinaryTree* CreateTree() const; { return new BinarySearchTree(); }. const char* ClassName() const; { return ""BinarySearchTree""; }. void SetPeriode(Int_t p); set the periode (number of variables). { fPeriod = p; }. UInt_t GetPeriode( void ); return periode (number of variables). { return fPeriod; }. Float_t Mean(TMVA::Types::ESBType sb, UInt_t var); access to mean for signal and background for each variable. { return fMeans[sb==Types::kSignal?0:1][var]; }. Float_t RMS(TMVA::Types::ESBType sb, UInt_t var); access to RMS for signal and background for each variable. { return fRMS[sb==Types::kSignal?0:1][var]; }. Float_t Min(TMVA::Types::ESBType sb, UInt_t var); access to Minimum for signal and background for each variable. { return fMin[sb==Types::kSignal?0:1][var]; }. Float_t Max(TMVA::Types::ESBType sb, UInt_t var); access to Maximum for signal and background for each variable. { return fMax[sb==Types::kSignal?0:1][var]; }. Float_t RMS(UInt_t var); access to RMS for each variable. { return fRMS[0][var]; }. void SetNormalize(Bool_t norm); { fCanNormalize = norm; }. void DestroyNode(TMVA::BinarySearchTreeNode* ). » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: BinarySearchTree.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:8413,Modifiability,variab,variable,8413," if the data points are in the given volume. void CalcStatistics(TMVA::Node* n = 0, Int_t signalClass = 0); calculate basic statistics (mean, rms for each variable). Int_t SearchVolumeWithMaxLimit(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0, Int_t = -1); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume a maximum number of events can be given. Node * CreateNode(UInt_t ) const; { return new BinarySearchTreeNode(); }. BinaryTree* CreateTree() const; { return new BinarySearchTree(); }. const char* ClassName() const; { return ""BinarySearchTree""; }. void SetPeriode(Int_t p); set the periode (number of variables). { fPeriod = p; }. UInt_t GetPeriode( void ); return periode (number of variables). { return fPeriod; }. Float_t Mean(TMVA::Types::ESBType sb, UInt_t var); access to mean for signal and background for each variable. { return fMeans[sb==Types::kSignal?0:1][var]; }. Float_t RMS(TMVA::Types::ESBType sb, UInt_t var); access to RMS for signal and background for each variable. { return fRMS[sb==Types::kSignal?0:1][var]; }. Float_t Min(TMVA::Types::ESBType sb, UInt_t var); access to Minimum for signal and background for each variable. { return fMin[sb==Types::kSignal?0:1][var]; }. Float_t Max(TMVA::Types::ESBType sb, UInt_t var); access to Maximum for signal and background for each variable. { return fMax[sb==Types::kSignal?0:1][var]; }. Float_t RMS(UInt_t var); access to RMS for each variable. { return fRMS[0][var]; }. void SetNormalize(Bool_t norm); { fCanNormalize = norm; }. void DestroyNode(TMVA::BinarySearchTreeNode* ). » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: BinarySearchTree.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:8518,Modifiability,variab,variable,8518," if the data points are in the given volume. void CalcStatistics(TMVA::Node* n = 0, Int_t signalClass = 0); calculate basic statistics (mean, rms for each variable). Int_t SearchVolumeWithMaxLimit(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0, Int_t = -1); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume a maximum number of events can be given. Node * CreateNode(UInt_t ) const; { return new BinarySearchTreeNode(); }. BinaryTree* CreateTree() const; { return new BinarySearchTree(); }. const char* ClassName() const; { return ""BinarySearchTree""; }. void SetPeriode(Int_t p); set the periode (number of variables). { fPeriod = p; }. UInt_t GetPeriode( void ); return periode (number of variables). { return fPeriod; }. Float_t Mean(TMVA::Types::ESBType sb, UInt_t var); access to mean for signal and background for each variable. { return fMeans[sb==Types::kSignal?0:1][var]; }. Float_t RMS(TMVA::Types::ESBType sb, UInt_t var); access to RMS for signal and background for each variable. { return fRMS[sb==Types::kSignal?0:1][var]; }. Float_t Min(TMVA::Types::ESBType sb, UInt_t var); access to Minimum for signal and background for each variable. { return fMin[sb==Types::kSignal?0:1][var]; }. Float_t Max(TMVA::Types::ESBType sb, UInt_t var); access to Maximum for signal and background for each variable. { return fMax[sb==Types::kSignal?0:1][var]; }. Float_t RMS(UInt_t var); access to RMS for each variable. { return fRMS[0][var]; }. void SetNormalize(Bool_t norm); { fCanNormalize = norm; }. void DestroyNode(TMVA::BinarySearchTreeNode* ). » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: BinarySearchTree.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:7885,Security,access,access,7885,"es and add up all weigths of events that; lie within the given volume. Bool_t InVolume(const vector<Float_t>& , TMVA::Volume* ) const; test if the data points are in the given volume. void CalcStatistics(TMVA::Node* n = 0, Int_t signalClass = 0); calculate basic statistics (mean, rms for each variable). Int_t SearchVolumeWithMaxLimit(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0, Int_t = -1); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume a maximum number of events can be given. Node * CreateNode(UInt_t ) const; { return new BinarySearchTreeNode(); }. BinaryTree* CreateTree() const; { return new BinarySearchTree(); }. const char* ClassName() const; { return ""BinarySearchTree""; }. void SetPeriode(Int_t p); set the periode (number of variables). { fPeriod = p; }. UInt_t GetPeriode( void ); return periode (number of variables). { return fPeriod; }. Float_t Mean(TMVA::Types::ESBType sb, UInt_t var); access to mean for signal and background for each variable. { return fMeans[sb==Types::kSignal?0:1][var]; }. Float_t RMS(TMVA::Types::ESBType sb, UInt_t var); access to RMS for signal and background for each variable. { return fRMS[sb==Types::kSignal?0:1][var]; }. Float_t Min(TMVA::Types::ESBType sb, UInt_t var); access to Minimum for signal and background for each variable. { return fMin[sb==Types::kSignal?0:1][var]; }. Float_t Max(TMVA::Types::ESBType sb, UInt_t var); access to Maximum for signal and background for each variable. { return fMax[sb==Types::kSignal?0:1][var]; }. Float_t RMS(UInt_t var); access to RMS for each variable. { return fRMS[0][var]; }. void SetNormalize(Bool_t norm); { fCanNormalize = norm; }. void DestroyNode(TMVA::BinarySearchTreeNode* ). » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: BinarySearchTree.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has bee",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:8044,Security,access,access,8044," if the data points are in the given volume. void CalcStatistics(TMVA::Node* n = 0, Int_t signalClass = 0); calculate basic statistics (mean, rms for each variable). Int_t SearchVolumeWithMaxLimit(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0, Int_t = -1); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume a maximum number of events can be given. Node * CreateNode(UInt_t ) const; { return new BinarySearchTreeNode(); }. BinaryTree* CreateTree() const; { return new BinarySearchTree(); }. const char* ClassName() const; { return ""BinarySearchTree""; }. void SetPeriode(Int_t p); set the periode (number of variables). { fPeriod = p; }. UInt_t GetPeriode( void ); return periode (number of variables). { return fPeriod; }. Float_t Mean(TMVA::Types::ESBType sb, UInt_t var); access to mean for signal and background for each variable. { return fMeans[sb==Types::kSignal?0:1][var]; }. Float_t RMS(TMVA::Types::ESBType sb, UInt_t var); access to RMS for signal and background for each variable. { return fRMS[sb==Types::kSignal?0:1][var]; }. Float_t Min(TMVA::Types::ESBType sb, UInt_t var); access to Minimum for signal and background for each variable. { return fMin[sb==Types::kSignal?0:1][var]; }. Float_t Max(TMVA::Types::ESBType sb, UInt_t var); access to Maximum for signal and background for each variable. { return fMax[sb==Types::kSignal?0:1][var]; }. Float_t RMS(UInt_t var); access to RMS for each variable. { return fRMS[0][var]; }. void SetNormalize(Bool_t norm); { fCanNormalize = norm; }. void DestroyNode(TMVA::BinarySearchTreeNode* ). » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: BinarySearchTree.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:8200,Security,access,access,8200," if the data points are in the given volume. void CalcStatistics(TMVA::Node* n = 0, Int_t signalClass = 0); calculate basic statistics (mean, rms for each variable). Int_t SearchVolumeWithMaxLimit(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0, Int_t = -1); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume a maximum number of events can be given. Node * CreateNode(UInt_t ) const; { return new BinarySearchTreeNode(); }. BinaryTree* CreateTree() const; { return new BinarySearchTree(); }. const char* ClassName() const; { return ""BinarySearchTree""; }. void SetPeriode(Int_t p); set the periode (number of variables). { fPeriod = p; }. UInt_t GetPeriode( void ); return periode (number of variables). { return fPeriod; }. Float_t Mean(TMVA::Types::ESBType sb, UInt_t var); access to mean for signal and background for each variable. { return fMeans[sb==Types::kSignal?0:1][var]; }. Float_t RMS(TMVA::Types::ESBType sb, UInt_t var); access to RMS for signal and background for each variable. { return fRMS[sb==Types::kSignal?0:1][var]; }. Float_t Min(TMVA::Types::ESBType sb, UInt_t var); access to Minimum for signal and background for each variable. { return fMin[sb==Types::kSignal?0:1][var]; }. Float_t Max(TMVA::Types::ESBType sb, UInt_t var); access to Maximum for signal and background for each variable. { return fMax[sb==Types::kSignal?0:1][var]; }. Float_t RMS(UInt_t var); access to RMS for each variable. { return fRMS[0][var]; }. void SetNormalize(Bool_t norm); { fCanNormalize = norm; }. void DestroyNode(TMVA::BinarySearchTreeNode* ). » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: BinarySearchTree.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:8360,Security,access,access,8360," if the data points are in the given volume. void CalcStatistics(TMVA::Node* n = 0, Int_t signalClass = 0); calculate basic statistics (mean, rms for each variable). Int_t SearchVolumeWithMaxLimit(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0, Int_t = -1); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume a maximum number of events can be given. Node * CreateNode(UInt_t ) const; { return new BinarySearchTreeNode(); }. BinaryTree* CreateTree() const; { return new BinarySearchTree(); }. const char* ClassName() const; { return ""BinarySearchTree""; }. void SetPeriode(Int_t p); set the periode (number of variables). { fPeriod = p; }. UInt_t GetPeriode( void ); return periode (number of variables). { return fPeriod; }. Float_t Mean(TMVA::Types::ESBType sb, UInt_t var); access to mean for signal and background for each variable. { return fMeans[sb==Types::kSignal?0:1][var]; }. Float_t RMS(TMVA::Types::ESBType sb, UInt_t var); access to RMS for signal and background for each variable. { return fRMS[sb==Types::kSignal?0:1][var]; }. Float_t Min(TMVA::Types::ESBType sb, UInt_t var); access to Minimum for signal and background for each variable. { return fMin[sb==Types::kSignal?0:1][var]; }. Float_t Max(TMVA::Types::ESBType sb, UInt_t var); access to Maximum for signal and background for each variable. { return fMax[sb==Types::kSignal?0:1][var]; }. Float_t RMS(UInt_t var); access to RMS for each variable. { return fRMS[0][var]; }. void SetNormalize(Bool_t norm); { fCanNormalize = norm; }. void DestroyNode(TMVA::BinarySearchTreeNode* ). » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: BinarySearchTree.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:8495,Security,access,access,8495," if the data points are in the given volume. void CalcStatistics(TMVA::Node* n = 0, Int_t signalClass = 0); calculate basic statistics (mean, rms for each variable). Int_t SearchVolumeWithMaxLimit(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0, Int_t = -1); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume a maximum number of events can be given. Node * CreateNode(UInt_t ) const; { return new BinarySearchTreeNode(); }. BinaryTree* CreateTree() const; { return new BinarySearchTree(); }. const char* ClassName() const; { return ""BinarySearchTree""; }. void SetPeriode(Int_t p); set the periode (number of variables). { fPeriod = p; }. UInt_t GetPeriode( void ); return periode (number of variables). { return fPeriod; }. Float_t Mean(TMVA::Types::ESBType sb, UInt_t var); access to mean for signal and background for each variable. { return fMeans[sb==Types::kSignal?0:1][var]; }. Float_t RMS(TMVA::Types::ESBType sb, UInt_t var); access to RMS for signal and background for each variable. { return fRMS[sb==Types::kSignal?0:1][var]; }. Float_t Min(TMVA::Types::ESBType sb, UInt_t var); access to Minimum for signal and background for each variable. { return fMin[sb==Types::kSignal?0:1][var]; }. Float_t Max(TMVA::Types::ESBType sb, UInt_t var); access to Maximum for signal and background for each variable. { return fMax[sb==Types::kSignal?0:1][var]; }. Float_t RMS(UInt_t var); access to RMS for each variable. { return fRMS[0][var]; }. void SetNormalize(Bool_t norm); { fCanNormalize = norm; }. void DestroyNode(TMVA::BinarySearchTreeNode* ). » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: BinarySearchTree.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:3762,Testability,log,logger,3762,"aryTree::SetTotalTreeDepth(TMVA::Node* n = NULL); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). protected:. voidTMVA::BinaryTree::DeleteNode(TMVA::Node*); TMVA::MsgLogger&TMVA::BinaryTree::Log() const. private:. voidDestroyNode(TMVA::BinarySearchTreeNode*); voidInsert(const TMVA::Event*, TMVA::Node*); Bool_tInVolume(const vector<Float_t>&, TMVA::Volume*) const; voidNormalizeTree(vector<pair<double,const TMVA::Event*>,allocator<pair<double,const TMVA::Event*> > >::iterator, vector<pair<double,const TMVA::Event*>,allocator<pair<double,const TMVA::Event*> > >::iterator, UInt_t); TMVA::BinarySearchTreeNode*Search(TMVA::Event*, TMVA::Node*) const; Double_tSearchVolume(TMVA::Node*, TMVA::Volume*, Int_t, vector<const TMVA::BinarySearchTreeNode*>* events). Data Members; protected:. UInt_tTMVA::BinaryTree::fDepthmaximal depth in tree reached; UInt_tTMVA::BinaryTree::fNNodestotal number of nodes in the tree (counted); TMVA::Node*TMVA::BinaryTree::fRootthe root node of the tree; static TMVA::MsgLogger*TMVA::BinaryTree::fgLoggermessage logger, static to save resources . private:. Bool_tfCanNormalizethe tree can be normalised; UInt_tfCurrentDepthinternal variable, counting the depth of the tree during insertion ; vector<Float_t>fMax[2]RMS for signal and background for each variable; vector<Float_t>fMeans[2]mean for signal and background for each variable; vector<Float_t>fMin[2]RMS for signal and background for each variable; Double_tfNEventsW[2]Number of events per class, taking into account event weights; vector<std::pair<Double_t,const TMVA::Event*> >fNormalizeTreeTable; UInt_tfPeriodperiode (number of event variables); vector<Float_t>fRMS[2]RMS for signal and background for each variable; Bool_tfStatisticsIsValidflag if last stat calculation is still valid, set to false if new node is insert; vector<Double_t>fSum[2]Sum for signal and background for each variable; Double_tfSumOfWeightsTotal number of events",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:7023,Testability,test,test,7023,"ng ONLY the variables specified in ""theVars"". Double_t Fill(const vector<TMVA::Event*>& events, Int_t theType = -1); create the search tree from the events in a TTree; using ALL the variables specified included in the Event. void NormalizeTree(vector<pair<double,const TMVA::Event*>,allocator<pair<double,const TMVA::Event*> > >::iterator , vector<pair<double,const TMVA::Event*>,allocator<pair<double,const TMVA::Event*> > >::iterator , UInt_t ). void NormalizeTree(); Normalisation of tree. void Clear(TMVA::Node* n = 0); clear nodes. Double_t SearchVolume(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0); search the whole tree and add up all weigths of events that; lie within the given voluem. Double_t SearchVolume(TMVA::Node* , TMVA::Volume* , Int_t , vector<const TMVA::BinarySearchTreeNode*>* events); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume. Bool_t InVolume(const vector<Float_t>& , TMVA::Volume* ) const; test if the data points are in the given volume. void CalcStatistics(TMVA::Node* n = 0, Int_t signalClass = 0); calculate basic statistics (mean, rms for each variable). Int_t SearchVolumeWithMaxLimit(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0, Int_t = -1); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume a maximum number of events can be given. Node * CreateNode(UInt_t ) const; { return new BinarySearchTreeNode(); }. BinaryTree* CreateTree() const; { return new BinarySearchTree(); }. const char* ClassName() const; { return ""BinarySearchTree""; }. void SetPeriode(Int_t p); set the periode (number of variables). { fPeriod = p; }. UInt_t GetPeriode( void ); return periode (number of variables). { return fPeriod; }. Float_t Mean(TMVA::Types::ESBType sb, UInt_t var); access to mean for signal and background for each variable. { return fMeans[sb==Types::kSignal?0:1][var]; }. Float_t RMS(TMVA::Typ",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:348,Usability,simpl,simple,348,". TMVA::BinarySearchTree. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::BinarySearchTree. class TMVA::BinarySearchTree: public TMVA::BinaryTree. BinarySearchTree. A simple Binary search tree including a volume search method. Function Members (Methods); public:. virtual~BinarySearchTree(); virtual void*TMVA::BinaryTree::AddXMLTo(void* parent) const; TMVA::BinarySearchTreeBinarySearchTree(); TMVA::BinarySearchTreeBinarySearchTree(const TMVA::BinarySearchTree& b); voidCalcStatistics(TMVA::Node* n = 0, Int_t signalClass = 0); static TClass*Class(); virtual const char*ClassName() const; voidClear(TMVA::Node* n = 0); UInt_tTMVA::BinaryTree::CountNodes(TMVA::Node* n = NULL); static TMVA::BinarySearchTree*CreateFromXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); virtual TMVA::Node*CreateNode(UInt_t) const; virtual TMVA::BinaryTree*CreateTree() const; Double_tFill(const vector<TMVA::Event*>& events, Int_t theType = -1); Double_tFill(const vector<TMVA::Event*>& events, const vector<Int_t>& theVars, Int_t theType = -1); TMVA::Node*TMVA::BinaryTree::GetLeftDaughter(TMVA::Node* n); UInt_tTMVA::BinaryTree::GetNNodes() const; UInt_tGetPeriode() const; TMVA::Node*TMVA::BinaryTree::GetRightDaughter(TMVA::Node* n); virtual TMVA::Node*TMVA::BinaryTree::GetRoot() const; Double_tGetSumOfWeights() const; Double_tGetSumOfWeights(Int_t theType) const; UInt_tTMVA::BinaryTree::GetTotalTreeDepth() const; voidInsert(const TMVA::Event*); virtual TClass*IsA() const; Float_tMax(TMVA::Types::ESBType sb, UInt_t var); Float_tMean(TMVA::Types::ESBType sb, UInt_t var); Float_tMin(TMVA::Types::ESBType sb, UInt_t var); voidNormalizeTree(); TMVA::BinarySearchTree&operator=(const TMVA::BinarySearchTree&); virtual voidTMVA::BinaryTree::Print(ostream& os) const; virtual voidTMVA::BinaryTree::Read(istream& istr, UI",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:6538,Usability,clear,clear,6538,"he tree to find the node matching ""event"". TMVA::BinarySearchTreeNode* Search(TMVA::Event* , TMVA::Node* ) const; Private, recursive, function for searching. Double_t GetSumOfWeights(Int_t theType) const; return the sum of event (node) weights. Double_t GetSumOfWeights(Int_t theType) const; return the sum of event (node) weights. Double_t Fill(const vector<TMVA::Event*>& events, const vector<Int_t>& theVars, Int_t theType = -1); create the search tree from the event collection; using ONLY the variables specified in ""theVars"". Double_t Fill(const vector<TMVA::Event*>& events, Int_t theType = -1); create the search tree from the events in a TTree; using ALL the variables specified included in the Event. void NormalizeTree(vector<pair<double,const TMVA::Event*>,allocator<pair<double,const TMVA::Event*> > >::iterator , vector<pair<double,const TMVA::Event*>,allocator<pair<double,const TMVA::Event*> > >::iterator , UInt_t ). void NormalizeTree(); Normalisation of tree. void Clear(TMVA::Node* n = 0); clear nodes. Double_t SearchVolume(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0); search the whole tree and add up all weigths of events that; lie within the given voluem. Double_t SearchVolume(TMVA::Node* , TMVA::Volume* , Int_t , vector<const TMVA::BinarySearchTreeNode*>* events); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume. Bool_t InVolume(const vector<Float_t>& , TMVA::Volume* ) const; test if the data points are in the given volume. void CalcStatistics(TMVA::Node* n = 0, Int_t signalClass = 0); calculate basic statistics (mean, rms for each variable). Int_t SearchVolumeWithMaxLimit(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0, Int_t = -1); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume a maximum number of events can be given. Node * CreateNode(UInt_t ) const; { return new BinarySearchTreeNode(",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTreeNode.html:570,Modifiability,variab,variable,570,". TMVA::BinarySearchTreeNode. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::BinarySearchTreeNode. class TMVA::BinarySearchTreeNode: public TMVA::Node. Node for the BinarySearch or Decision Trees. for the binary search tree, it basically consists of the EVENT, and; pointers to the parent and daughters. in case of the Decision Tree, it specifies parent and daughters, as; well as ""which variable is used"" in the selection of this node, including; the respective cut value. Function Members (Methods); public:. virtual~BinarySearchTreeNode(); virtual voidAddAttributesToNode(void* node) const; virtual voidAddContentToNode(stringstream& s) const; void*TMVA::Node::AddXMLTo(void* parent) const; TMVA::BinarySearchTreeNodeBinarySearchTreeNode(const TMVA::Event* e = NULL, UInt_t signalClass = 0); TMVA::BinarySearchTreeNodeBinarySearchTreeNode(TMVA::BinarySearchTreeNode* parent, char pos); TMVA::BinarySearchTreeNodeBinarySearchTreeNode(const TMVA::BinarySearchTreeNode& n, TMVA::BinarySearchTreeNode* parent = NULL); static TClass*Class(); Int_tTMVA::Node::CountMeAndAllDaughters() const; virtual TMVA::Node*CreateNode() const; virtual Bool_tEqualsMe(const TMVA::Event&) const; UInt_tGetClass() const; intTMVA::Node::GetCount(); UInt_tTMVA::Node::GetDepth() const; const vector<Float_t>&GetEventV() const; virtual TMVA::Node*TMVA::Node::GetLeft() const; virtual TMVA::Node*TMVA::Node::GetParent() const; virtual TMVA::BinaryTree*TMVA::Node::GetParentTree() const; charTMVA::Node::GetPos() const; virtual TMVA::Node*TMVA::Node::GetRight() const; Short_tGetSelector() const; const vector<Float_t>&GetTargets() const; Float_tGetWeight() const; virtual Bool_tGoesLeft(const TMVA::Event&) const; virtual Bool_tGoesRight(const TMVA::Event&) const; virtual TClass*IsA() const; TMVA::BinarySearchTreeNode&operator=(const TMVA::",MatchSource.WIKI,root/html532/TMVA__BinarySearchTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTreeNode.html
https://root.cern/root/html532/TMVA__BinarySearchTreeNode.html:3376,Modifiability,variab,variable,3376,"::Node::SetPos(char s); virtual voidTMVA::Node::SetRight(TMVA::Node* r); voidSetSelector(Short_t i); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). private:. virtual voidReadAttributes(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); virtual voidReadContent(stringstream& s); virtual Bool_tReadDataRecord(istream& is, UInt_t tmva_Version_Code = TMVA_VERSION_CODE). Data Members; protected:. UInt_tTMVA::Node::fDepthdepth of the node within the tree (seen from root node); TMVA::Node*TMVA::Node::fLeftpointers to the two ""daughter"" nodes; TMVA::Node*TMVA::Node::fParentthe previous (parent) node; TMVA::BinaryTree*TMVA::Node::fParentTreepointer to the parent tree to which the Node belongs ; charTMVA::Node::fPosposition, i.e. it is a left (l) or right (r) daughter ; TMVA::Node*TMVA::Node::fRightpointers to the two ""daughter"" nodes. private:. UInt_tfClass; vector<Float_t>fEventV; Short_tfSelectorindex of variable used in node selection (decision tree) ; vector<Float_t>fTargets; Float_tfWeight. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; BinarySearchTreeNode(const TMVA::Event* e = NULL, UInt_t signalClass = 0); constructor of a node for the search tree. BinarySearchTreeNode(TMVA::BinarySearchTreeNode* parent, char pos); constructor of a daughter node as a daughter of 'p'. BinarySearchTreeNode(const TMVA::BinarySearchTreeNode& n, TMVA::BinarySearchTreeNode* parent = NULL); copy constructor of a node. It will result in an explicit copy of; the node and recursively all it's daughters. ~BinarySearchTreeNode(); node destructor. Bool_t GoesRight(const TMVA::Event& ) const; check if the event fed into the node goes/decends to the right daughter. Bool_t GoesLeft(const TMVA::Event& ) const; check if the event fed into the node goes/decends to the left daughter. Bool_t EqualsMe(const TMVA::Event& ) const; check if the event fed into the node actually equals the e",MatchSource.WIKI,root/html532/TMVA__BinarySearchTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTreeNode.html
https://root.cern/root/html532/TMVA__BinarySearchTreeNode.html:5121,Modifiability,variab,variable,5121,"e node and recursively all it's daughters. ~BinarySearchTreeNode(); node destructor. Bool_t GoesRight(const TMVA::Event& ) const; check if the event fed into the node goes/decends to the right daughter. Bool_t GoesLeft(const TMVA::Event& ) const; check if the event fed into the node goes/decends to the left daughter. Bool_t EqualsMe(const TMVA::Event& ) const; check if the event fed into the node actually equals the event; that forms the node (in case of a search tree). void Print(ostream& os) const; print the node. void PrintRec(ostream& os) const; recursively print the node and its daughters (--> print the 'tree'). Bool_t ReadDataRecord(istream& is, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); Read the data block. void ReadAttributes(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); read attributes from XML. void AddAttributesToNode(void* node) const; adding attributes to tree node. void AddContentToNode(stringstream& s) const; adding attributes to tree node. void ReadContent(stringstream& s); read events from node. Node* CreateNode() const; { return new BinarySearchTreeNode(); }. void SetSelector(Short_t i); set index of variable used for discrimination at this node. { fSelector = i; }. Short_t GetSelector() const; return index of variable used for discrimination at this node. { return fSelector; }. const std::vector<Float_t> & GetEventV() const; { return fEventV; }. Float_t GetWeight() const; { return fWeight; }. UInt_t GetClass() const; Bool_t IsSignal() const { return (fClass == fSignalClass); }. { return fClass; }. const std::vector<Float_t> & GetTargets() const; { return fTargets; }. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: BinarySearchTreeNode.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__BinarySearchTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTreeNode.html
https://root.cern/root/html532/TMVA__BinarySearchTreeNode.html:5233,Modifiability,variab,variable,5233,"e node and recursively all it's daughters. ~BinarySearchTreeNode(); node destructor. Bool_t GoesRight(const TMVA::Event& ) const; check if the event fed into the node goes/decends to the right daughter. Bool_t GoesLeft(const TMVA::Event& ) const; check if the event fed into the node goes/decends to the left daughter. Bool_t EqualsMe(const TMVA::Event& ) const; check if the event fed into the node actually equals the event; that forms the node (in case of a search tree). void Print(ostream& os) const; print the node. void PrintRec(ostream& os) const; recursively print the node and its daughters (--> print the 'tree'). Bool_t ReadDataRecord(istream& is, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); Read the data block. void ReadAttributes(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); read attributes from XML. void AddAttributesToNode(void* node) const; adding attributes to tree node. void AddContentToNode(stringstream& s) const; adding attributes to tree node. void ReadContent(stringstream& s); read events from node. Node* CreateNode() const; { return new BinarySearchTreeNode(); }. void SetSelector(Short_t i); set index of variable used for discrimination at this node. { fSelector = i; }. Short_t GetSelector() const; return index of variable used for discrimination at this node. { return fSelector; }. const std::vector<Float_t> & GetEventV() const; { return fEventV; }. Float_t GetWeight() const; { return fWeight; }. UInt_t GetClass() const; Bool_t IsSignal() const { return (fClass == fSignalClass); }. { return fClass; }. const std::vector<Float_t> & GetTargets() const; { return fTargets; }. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: BinarySearchTreeNode.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__BinarySearchTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTreeNode.html
https://root.cern/root/html532/TMVA__BinaryTree.html:479,Availability,avail,available,479,". TMVA::BinaryTree. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::BinaryTree. class TMVA::BinaryTree. BinaryTree. Base class for BinarySearch and Decision Trees. Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~BinaryTree(); virtual void*AddXMLTo(void* parent) const; static TClass*Class(); virtual const char*ClassName() const; UInt_tCountNodes(TMVA::Node* n = NULL); virtual TMVA::Node*CreateNode(UInt_t size = 0) const; virtual TMVA::BinaryTree*CreateTree() const; TMVA::Node*GetLeftDaughter(TMVA::Node* n); UInt_tGetNNodes() const; TMVA::Node*GetRightDaughter(TMVA::Node* n); virtual TMVA::Node*GetRoot() const; UInt_tGetTotalTreeDepth() const; virtual TClass*IsA() const; TMVA::BinaryTree&operator=(const TMVA::BinaryTree&); virtual voidPrint(ostream& os) const; virtual voidRead(istream& istr, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); virtual voidReadXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); voidSetRoot(TMVA::Node* r); voidSetTotalTreeDepth(Int_t depth); voidSetTotalTreeDepth(TMVA::Node* n = NULL); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). protected:. voidDeleteNode(TMVA::Node*); TMVA::MsgLogger&Log() const. Data Members; protected:. UInt_tfDepthmaximal depth in tree reached; UInt_tfNNodestotal number of nodes in the tree (counted); TMVA::Node*fRootthe root node of the tree; static TMVA::MsgLogger*fgLoggermessage logger, static to save resources . Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; ~BinaryTree( void ); destructor (deletes the nodes and ""events"" if owned by the tree. void DeleteNode(TMVA::Node* ); protected, recurs",MatchSource.WIKI,root/html532/TMVA__BinaryTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinaryTree.html
https://root.cern/root/html532/TMVA__BinaryTree.html:2706,Integrability,depend,depends,2706,"fgLoggermessage logger, static to save resources . Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; ~BinaryTree( void ); destructor (deletes the nodes and ""events"" if owned by the tree. void DeleteNode(TMVA::Node* ); protected, recursive, function used by the class destructor and when Pruning. TMVA::Node* GetLeftDaughter(TMVA::Node* n); get left daughter node current node ""n"". TMVA::Node* GetRightDaughter(TMVA::Node* n); get right daughter node current node ""n"". UInt_t CountNodes(TMVA::Node* n = NULL); return the number of nodes in the tree. (make a new count --> takes time). void Print(ostream& os) const; recursively print the tree. void* AddXMLTo(void* parent) const; add attributes to XML. void ReadXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); read attributes from XML. void Read(istream& istr, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); Read the binary tree from an input stream.; The input stream format depends on the tree type,; it is defined be the node of the tree. void SetTotalTreeDepth( Node *n); descend a tree to find all its leaf nodes, fill max depth reached in the; tree at the same time. Node* CreateNode(UInt_t size = 0) const. BinaryTree* CreateTree() const; virtual BinaryTree* CreateFromXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE) = 0;. const char* ClassName() const. void SetRoot(TMVA::Node* r); set the root node of the tree. { fRoot = r; }. Node* GetRoot() const; Retrieves the address of the root node. { return fRoot; }. UInt_t GetNNodes() const; get number of Nodes in the Tree as counted while booking the nodes;. { return fNNodes; }. UInt_t GetTotalTreeDepth() const; { return fDepth; }. void SetTotalTreeDepth(Int_t depth); { fDepth = depth; }. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss, Eckhard von Toerne » Copyright (c) 2005-2011: *; » Last changed: root/tmva $Id: BinaryTree.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This ",MatchSource.WIKI,root/html532/TMVA__BinaryTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinaryTree.html
https://root.cern/root/html532/TMVA__BinaryTree.html:1741,Testability,log,logger,1741,"* n = NULL); virtual TMVA::Node*CreateNode(UInt_t size = 0) const; virtual TMVA::BinaryTree*CreateTree() const; TMVA::Node*GetLeftDaughter(TMVA::Node* n); UInt_tGetNNodes() const; TMVA::Node*GetRightDaughter(TMVA::Node* n); virtual TMVA::Node*GetRoot() const; UInt_tGetTotalTreeDepth() const; virtual TClass*IsA() const; TMVA::BinaryTree&operator=(const TMVA::BinaryTree&); virtual voidPrint(ostream& os) const; virtual voidRead(istream& istr, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); virtual voidReadXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); voidSetRoot(TMVA::Node* r); voidSetTotalTreeDepth(Int_t depth); voidSetTotalTreeDepth(TMVA::Node* n = NULL); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). protected:. voidDeleteNode(TMVA::Node*); TMVA::MsgLogger&Log() const. Data Members; protected:. UInt_tfDepthmaximal depth in tree reached; UInt_tfNNodestotal number of nodes in the tree (counted); TMVA::Node*fRootthe root node of the tree; static TMVA::MsgLogger*fgLoggermessage logger, static to save resources . Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; ~BinaryTree( void ); destructor (deletes the nodes and ""events"" if owned by the tree. void DeleteNode(TMVA::Node* ); protected, recursive, function used by the class destructor and when Pruning. TMVA::Node* GetLeftDaughter(TMVA::Node* n); get left daughter node current node ""n"". TMVA::Node* GetRightDaughter(TMVA::Node* n); get right daughter node current node ""n"". UInt_t CountNodes(TMVA::Node* n = NULL); return the number of nodes in the tree. (make a new count --> takes time). void Print(ostream& os) const; recursively print the tree. void* AddXMLTo(void* parent) const; add attributes to XML. void ReadXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); read attributes from XML. void Read(istream& istr, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); Read the binary tree from an",MatchSource.WIKI,root/html532/TMVA__BinaryTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinaryTree.html
https://root.cern/root/html532/TMVA__CCPruner.html:459,Security,validat,validationSample,459,". TMVA::CCPruner. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::CCPruner. class TMVA::CCPruner. Function Members (Methods); public:. ~CCPruner(); TMVA::CCPrunerCCPruner(const TMVA::CCPruner&); TMVA::CCPrunerCCPruner(TMVA::DecisionTree* t_max, const TMVA::CCPruner::EventList* validationSample, TMVA::SeparationBase* qualityIndex = NULL); TMVA::CCPrunerCCPruner(TMVA::DecisionTree* t_max, const TMVA::DataSet* validationSample, TMVA::SeparationBase* qualityIndex = NULL); vector<TMVA::DecisionTreeNode*>GetOptimalPruneSequence() const; Float_tGetOptimalPruneStrength() const; Float_tGetOptimalQualityIndex() const; voidOptimize(); voidSetPruneStrength(Float_t alpha = -1.0). Data Members; private:. Float_tfAlpha! regularization parameter in CC pruning; Bool_tfDebug! debug flag; Int_tfOptimalK! index of the optimal tree in the pruned tree sequence; Bool_tfOwnQIndex! flag indicates if fQualityIndex is owned by this; vector<TMVA::DecisionTreeNode*>fPruneSequence! map of weakest links (i.e., branches to prune) -> pruning index; vector<Float_t>fPruneStrengthList! map of alpha -> pruning index; TMVA::SeparationBase*fQualityIndex! the quality index used to calculate R(t), R(T) = sum[t in ~T]{ R(t) }; vector<Float_t>fQualityIndexList! map of R(T) -> pruning index; TMVA::DecisionTree*fTree! (pruned) decision tree; const TMVA::DataSet*fValidationDataSet! the event sample to select the optimally-pruned tree; const TMVA::CCPruner::EventList*fValidationSample! the event sample to select the optimally-pruned tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CCPruner( DecisionTree* t_max, const EventList* validationSample, SeparationBase* qualityIndex ); constructor. CCPruner( DecisionTree* t_max, const DataSet* validationSample, SeparationBase* qualityIndex ); cons",MatchSource.WIKI,root/html532/TMVA__CCPruner.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CCPruner.html
https://root.cern/root/html532/TMVA__CCPruner.html:592,Security,validat,validationSample,592,". TMVA::CCPruner. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::CCPruner. class TMVA::CCPruner. Function Members (Methods); public:. ~CCPruner(); TMVA::CCPrunerCCPruner(const TMVA::CCPruner&); TMVA::CCPrunerCCPruner(TMVA::DecisionTree* t_max, const TMVA::CCPruner::EventList* validationSample, TMVA::SeparationBase* qualityIndex = NULL); TMVA::CCPrunerCCPruner(TMVA::DecisionTree* t_max, const TMVA::DataSet* validationSample, TMVA::SeparationBase* qualityIndex = NULL); vector<TMVA::DecisionTreeNode*>GetOptimalPruneSequence() const; Float_tGetOptimalPruneStrength() const; Float_tGetOptimalQualityIndex() const; voidOptimize(); voidSetPruneStrength(Float_t alpha = -1.0). Data Members; private:. Float_tfAlpha! regularization parameter in CC pruning; Bool_tfDebug! debug flag; Int_tfOptimalK! index of the optimal tree in the pruned tree sequence; Bool_tfOwnQIndex! flag indicates if fQualityIndex is owned by this; vector<TMVA::DecisionTreeNode*>fPruneSequence! map of weakest links (i.e., branches to prune) -> pruning index; vector<Float_t>fPruneStrengthList! map of alpha -> pruning index; TMVA::SeparationBase*fQualityIndex! the quality index used to calculate R(t), R(T) = sum[t in ~T]{ R(t) }; vector<Float_t>fQualityIndexList! map of R(T) -> pruning index; TMVA::DecisionTree*fTree! (pruned) decision tree; const TMVA::DataSet*fValidationDataSet! the event sample to select the optimally-pruned tree; const TMVA::CCPruner::EventList*fValidationSample! the event sample to select the optimally-pruned tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CCPruner( DecisionTree* t_max, const EventList* validationSample, SeparationBase* qualityIndex ); constructor. CCPruner( DecisionTree* t_max, const DataSet* validationSample, SeparationBase* qualityIndex ); cons",MatchSource.WIKI,root/html532/TMVA__CCPruner.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CCPruner.html
https://root.cern/root/html532/TMVA__CCPruner.html:1838,Security,validat,validationSample,1838,"uneStrength(Float_t alpha = -1.0). Data Members; private:. Float_tfAlpha! regularization parameter in CC pruning; Bool_tfDebug! debug flag; Int_tfOptimalK! index of the optimal tree in the pruned tree sequence; Bool_tfOwnQIndex! flag indicates if fQualityIndex is owned by this; vector<TMVA::DecisionTreeNode*>fPruneSequence! map of weakest links (i.e., branches to prune) -> pruning index; vector<Float_t>fPruneStrengthList! map of alpha -> pruning index; TMVA::SeparationBase*fQualityIndex! the quality index used to calculate R(t), R(T) = sum[t in ~T]{ R(t) }; vector<Float_t>fQualityIndexList! map of R(T) -> pruning index; TMVA::DecisionTree*fTree! (pruned) decision tree; const TMVA::DataSet*fValidationDataSet! the event sample to select the optimally-pruned tree; const TMVA::CCPruner::EventList*fValidationSample! the event sample to select the optimally-pruned tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CCPruner( DecisionTree* t_max, const EventList* validationSample, SeparationBase* qualityIndex ); constructor. CCPruner( DecisionTree* t_max, const DataSet* validationSample, SeparationBase* qualityIndex ); constructor. ~CCPruner(). void Optimize(); determine the pruning sequence. std::vector<DecisionTreeNode*> GetOptimalPruneSequence() const; return the prune strength (=alpha) corresponding to the prune sequence. void SetPruneStrength(Float_t alpha = -1.0). CCPruner( DecisionTree* t_max, const EventList* validationSample, SeparationBase* qualityIndex = NULL ). Float_t GetOptimalQualityIndex() const; return the quality index from the validation sample for the optimal subtree T'. Float_t GetOptimalPruneStrength() const; return the prune strength (=alpha) corresponding to the prune sequence. » Last changed: Thu Nov 3 20:19:24 2011 » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__CCPruner.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CCPruner.html
https://root.cern/root/html532/TMVA__CCPruner.html:1947,Security,validat,validationSample,1947,"uneStrength(Float_t alpha = -1.0). Data Members; private:. Float_tfAlpha! regularization parameter in CC pruning; Bool_tfDebug! debug flag; Int_tfOptimalK! index of the optimal tree in the pruned tree sequence; Bool_tfOwnQIndex! flag indicates if fQualityIndex is owned by this; vector<TMVA::DecisionTreeNode*>fPruneSequence! map of weakest links (i.e., branches to prune) -> pruning index; vector<Float_t>fPruneStrengthList! map of alpha -> pruning index; TMVA::SeparationBase*fQualityIndex! the quality index used to calculate R(t), R(T) = sum[t in ~T]{ R(t) }; vector<Float_t>fQualityIndexList! map of R(T) -> pruning index; TMVA::DecisionTree*fTree! (pruned) decision tree; const TMVA::DataSet*fValidationDataSet! the event sample to select the optimally-pruned tree; const TMVA::CCPruner::EventList*fValidationSample! the event sample to select the optimally-pruned tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CCPruner( DecisionTree* t_max, const EventList* validationSample, SeparationBase* qualityIndex ); constructor. CCPruner( DecisionTree* t_max, const DataSet* validationSample, SeparationBase* qualityIndex ); constructor. ~CCPruner(). void Optimize(); determine the pruning sequence. std::vector<DecisionTreeNode*> GetOptimalPruneSequence() const; return the prune strength (=alpha) corresponding to the prune sequence. void SetPruneStrength(Float_t alpha = -1.0). CCPruner( DecisionTree* t_max, const EventList* validationSample, SeparationBase* qualityIndex = NULL ). Float_t GetOptimalQualityIndex() const; return the quality index from the validation sample for the optimal subtree T'. Float_t GetOptimalPruneStrength() const; return the prune strength (=alpha) corresponding to the prune sequence. » Last changed: Thu Nov 3 20:19:24 2011 » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__CCPruner.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CCPruner.html
https://root.cern/root/html532/TMVA__CCPruner.html:2301,Security,validat,validationSample,2301,"uneStrength(Float_t alpha = -1.0). Data Members; private:. Float_tfAlpha! regularization parameter in CC pruning; Bool_tfDebug! debug flag; Int_tfOptimalK! index of the optimal tree in the pruned tree sequence; Bool_tfOwnQIndex! flag indicates if fQualityIndex is owned by this; vector<TMVA::DecisionTreeNode*>fPruneSequence! map of weakest links (i.e., branches to prune) -> pruning index; vector<Float_t>fPruneStrengthList! map of alpha -> pruning index; TMVA::SeparationBase*fQualityIndex! the quality index used to calculate R(t), R(T) = sum[t in ~T]{ R(t) }; vector<Float_t>fQualityIndexList! map of R(T) -> pruning index; TMVA::DecisionTree*fTree! (pruned) decision tree; const TMVA::DataSet*fValidationDataSet! the event sample to select the optimally-pruned tree; const TMVA::CCPruner::EventList*fValidationSample! the event sample to select the optimally-pruned tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CCPruner( DecisionTree* t_max, const EventList* validationSample, SeparationBase* qualityIndex ); constructor. CCPruner( DecisionTree* t_max, const DataSet* validationSample, SeparationBase* qualityIndex ); constructor. ~CCPruner(). void Optimize(); determine the pruning sequence. std::vector<DecisionTreeNode*> GetOptimalPruneSequence() const; return the prune strength (=alpha) corresponding to the prune sequence. void SetPruneStrength(Float_t alpha = -1.0). CCPruner( DecisionTree* t_max, const EventList* validationSample, SeparationBase* qualityIndex = NULL ). Float_t GetOptimalQualityIndex() const; return the quality index from the validation sample for the optimal subtree T'. Float_t GetOptimalPruneStrength() const; return the prune strength (=alpha) corresponding to the prune sequence. » Last changed: Thu Nov 3 20:19:24 2011 » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__CCPruner.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CCPruner.html
https://root.cern/root/html532/TMVA__CCPruner.html:2432,Security,validat,validation,2432,"uneStrength(Float_t alpha = -1.0). Data Members; private:. Float_tfAlpha! regularization parameter in CC pruning; Bool_tfDebug! debug flag; Int_tfOptimalK! index of the optimal tree in the pruned tree sequence; Bool_tfOwnQIndex! flag indicates if fQualityIndex is owned by this; vector<TMVA::DecisionTreeNode*>fPruneSequence! map of weakest links (i.e., branches to prune) -> pruning index; vector<Float_t>fPruneStrengthList! map of alpha -> pruning index; TMVA::SeparationBase*fQualityIndex! the quality index used to calculate R(t), R(T) = sum[t in ~T]{ R(t) }; vector<Float_t>fQualityIndexList! map of R(T) -> pruning index; TMVA::DecisionTree*fTree! (pruned) decision tree; const TMVA::DataSet*fValidationDataSet! the event sample to select the optimally-pruned tree; const TMVA::CCPruner::EventList*fValidationSample! the event sample to select the optimally-pruned tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CCPruner( DecisionTree* t_max, const EventList* validationSample, SeparationBase* qualityIndex ); constructor. CCPruner( DecisionTree* t_max, const DataSet* validationSample, SeparationBase* qualityIndex ); constructor. ~CCPruner(). void Optimize(); determine the pruning sequence. std::vector<DecisionTreeNode*> GetOptimalPruneSequence() const; return the prune strength (=alpha) corresponding to the prune sequence. void SetPruneStrength(Float_t alpha = -1.0). CCPruner( DecisionTree* t_max, const EventList* validationSample, SeparationBase* qualityIndex = NULL ). Float_t GetOptimalQualityIndex() const; return the quality index from the validation sample for the optimal subtree T'. Float_t GetOptimalPruneStrength() const; return the prune strength (=alpha) corresponding to the prune sequence. » Last changed: Thu Nov 3 20:19:24 2011 » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__CCPruner.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CCPruner.html
https://root.cern/root/html532/TMVA__CCTreeWrapper.html:1156,Integrability,wrap,wrapped,1156,"x; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::CCTreeWrapper. class TMVA::CCTreeWrapper. Function Members (Methods); public:. ~CCTreeWrapper(); TMVA::CCTreeWrapperCCTreeWrapper(const TMVA::CCTreeWrapper&); TMVA::CCTreeWrapperCCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex); Double_tCheckEvent(const TMVA::Event& e, Bool_t useYesNoLeaf = false); TMVA::CCTreeWrapper::CCTreeNode*GetRoot(); voidInitTree(TMVA::CCTreeWrapper::CCTreeNode* t); TMVA::CCTreeWrapper&operator=(const TMVA::CCTreeWrapper&); voidPruneNode(TMVA::CCTreeWrapper::CCTreeNode* t); Double_tTestTreeQuality(const TMVA::CCTreeWrapper::EventList* validationSample); Double_tTestTreeQuality(const TMVA::DataSet* validationSample). Data Members; private:. TMVA::DecisionTree*fDTParent! pointer to underlying DecisionTree; TMVA::SeparationBase*fQualityIndex! pointer to the used quality index calculator; TMVA::CCTreeWrapper::CCTreeNode*fRoot! the root node of the (wrapped) decision Tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex); constructor. ~CCTreeWrapper(); destructor. void InitTree(TMVA::CCTreeWrapper::CCTreeNode* t); initialize the node t and all its descendants. void PruneNode(TMVA::CCTreeWrapper::CCTreeNode* t); remove the branch rooted at node t. Double_t TestTreeQuality( const EventList* validationSample ); return the misclassification rate of a pruned tree for a validation event sample; using an EventList. Double_t TestTreeQuality( const DataSet* validationSample ); return the misclassification rate of a pruned tree for a validation event sample; using the DataSet. Double_t CheckEvent(const TMVA::Event& e, Bool_t useYesNoLeaf = false); return the decision tree output for an event. CCTreeWrapper(TMVA::DecisionTree* T, TMVA::S",MatchSource.WIKI,root/html532/TMVA__CCTreeWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CCTreeWrapper.html
https://root.cern/root/html532/TMVA__CCTreeWrapper.html:840,Security,validat,validationSample,840,". TMVA::CCTreeWrapper. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::CCTreeWrapper. class TMVA::CCTreeWrapper. Function Members (Methods); public:. ~CCTreeWrapper(); TMVA::CCTreeWrapperCCTreeWrapper(const TMVA::CCTreeWrapper&); TMVA::CCTreeWrapperCCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex); Double_tCheckEvent(const TMVA::Event& e, Bool_t useYesNoLeaf = false); TMVA::CCTreeWrapper::CCTreeNode*GetRoot(); voidInitTree(TMVA::CCTreeWrapper::CCTreeNode* t); TMVA::CCTreeWrapper&operator=(const TMVA::CCTreeWrapper&); voidPruneNode(TMVA::CCTreeWrapper::CCTreeNode* t); Double_tTestTreeQuality(const TMVA::CCTreeWrapper::EventList* validationSample); Double_tTestTreeQuality(const TMVA::DataSet* validationSample). Data Members; private:. TMVA::DecisionTree*fDTParent! pointer to underlying DecisionTree; TMVA::SeparationBase*fQualityIndex! pointer to the used quality index calculator; TMVA::CCTreeWrapper::CCTreeNode*fRoot! the root node of the (wrapped) decision Tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex); constructor. ~CCTreeWrapper(); destructor. void InitTree(TMVA::CCTreeWrapper::CCTreeNode* t); initialize the node t and all its descendants. void PruneNode(TMVA::CCTreeWrapper::CCTreeNode* t); remove the branch rooted at node t. Double_t TestTreeQuality( const EventList* validationSample ); return the misclassification rate of a pruned tree for a validation event sample; using an EventList. Double_t TestTreeQuality( const DataSet* validationSample ); return the misclassification rate of a pruned tree for a validation event sample; using the DataSet. Double_t CheckEvent(const TMVA::Event& e, Bool_t useYesNoLeaf = false); return the decision tree out",MatchSource.WIKI,root/html532/TMVA__CCTreeWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CCTreeWrapper.html
https://root.cern/root/html532/TMVA__CCTreeWrapper.html:904,Security,validat,validationSample,904,". TMVA::CCTreeWrapper. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::CCTreeWrapper. class TMVA::CCTreeWrapper. Function Members (Methods); public:. ~CCTreeWrapper(); TMVA::CCTreeWrapperCCTreeWrapper(const TMVA::CCTreeWrapper&); TMVA::CCTreeWrapperCCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex); Double_tCheckEvent(const TMVA::Event& e, Bool_t useYesNoLeaf = false); TMVA::CCTreeWrapper::CCTreeNode*GetRoot(); voidInitTree(TMVA::CCTreeWrapper::CCTreeNode* t); TMVA::CCTreeWrapper&operator=(const TMVA::CCTreeWrapper&); voidPruneNode(TMVA::CCTreeWrapper::CCTreeNode* t); Double_tTestTreeQuality(const TMVA::CCTreeWrapper::EventList* validationSample); Double_tTestTreeQuality(const TMVA::DataSet* validationSample). Data Members; private:. TMVA::DecisionTree*fDTParent! pointer to underlying DecisionTree; TMVA::SeparationBase*fQualityIndex! pointer to the used quality index calculator; TMVA::CCTreeWrapper::CCTreeNode*fRoot! the root node of the (wrapped) decision Tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex); constructor. ~CCTreeWrapper(); destructor. void InitTree(TMVA::CCTreeWrapper::CCTreeNode* t); initialize the node t and all its descendants. void PruneNode(TMVA::CCTreeWrapper::CCTreeNode* t); remove the branch rooted at node t. Double_t TestTreeQuality( const EventList* validationSample ); return the misclassification rate of a pruned tree for a validation event sample; using an EventList. Double_t TestTreeQuality( const DataSet* validationSample ); return the misclassification rate of a pruned tree for a validation event sample; using the DataSet. Double_t CheckEvent(const TMVA::Event& e, Bool_t useYesNoLeaf = false); return the decision tree out",MatchSource.WIKI,root/html532/TMVA__CCTreeWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CCTreeWrapper.html
https://root.cern/root/html532/TMVA__CCTreeWrapper.html:1617,Security,validat,validationSample,1617,"apper&); TMVA::CCTreeWrapperCCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex); Double_tCheckEvent(const TMVA::Event& e, Bool_t useYesNoLeaf = false); TMVA::CCTreeWrapper::CCTreeNode*GetRoot(); voidInitTree(TMVA::CCTreeWrapper::CCTreeNode* t); TMVA::CCTreeWrapper&operator=(const TMVA::CCTreeWrapper&); voidPruneNode(TMVA::CCTreeWrapper::CCTreeNode* t); Double_tTestTreeQuality(const TMVA::CCTreeWrapper::EventList* validationSample); Double_tTestTreeQuality(const TMVA::DataSet* validationSample). Data Members; private:. TMVA::DecisionTree*fDTParent! pointer to underlying DecisionTree; TMVA::SeparationBase*fQualityIndex! pointer to the used quality index calculator; TMVA::CCTreeWrapper::CCTreeNode*fRoot! the root node of the (wrapped) decision Tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex); constructor. ~CCTreeWrapper(); destructor. void InitTree(TMVA::CCTreeWrapper::CCTreeNode* t); initialize the node t and all its descendants. void PruneNode(TMVA::CCTreeWrapper::CCTreeNode* t); remove the branch rooted at node t. Double_t TestTreeQuality( const EventList* validationSample ); return the misclassification rate of a pruned tree for a validation event sample; using an EventList. Double_t TestTreeQuality( const DataSet* validationSample ); return the misclassification rate of a pruned tree for a validation event sample; using the DataSet. Double_t CheckEvent(const TMVA::Event& e, Bool_t useYesNoLeaf = false); return the decision tree output for an event. CCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex). CCTreeNode* GetRoot(); return the root node for this tree. { return fRoot; }. » Last changed: Thu Nov 3 20:19:24 2011 » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__CCTreeWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CCTreeWrapper.html
https://root.cern/root/html532/TMVA__CCTreeWrapper.html:1694,Security,validat,validation,1694,"apper&); TMVA::CCTreeWrapperCCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex); Double_tCheckEvent(const TMVA::Event& e, Bool_t useYesNoLeaf = false); TMVA::CCTreeWrapper::CCTreeNode*GetRoot(); voidInitTree(TMVA::CCTreeWrapper::CCTreeNode* t); TMVA::CCTreeWrapper&operator=(const TMVA::CCTreeWrapper&); voidPruneNode(TMVA::CCTreeWrapper::CCTreeNode* t); Double_tTestTreeQuality(const TMVA::CCTreeWrapper::EventList* validationSample); Double_tTestTreeQuality(const TMVA::DataSet* validationSample). Data Members; private:. TMVA::DecisionTree*fDTParent! pointer to underlying DecisionTree; TMVA::SeparationBase*fQualityIndex! pointer to the used quality index calculator; TMVA::CCTreeWrapper::CCTreeNode*fRoot! the root node of the (wrapped) decision Tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex); constructor. ~CCTreeWrapper(); destructor. void InitTree(TMVA::CCTreeWrapper::CCTreeNode* t); initialize the node t and all its descendants. void PruneNode(TMVA::CCTreeWrapper::CCTreeNode* t); remove the branch rooted at node t. Double_t TestTreeQuality( const EventList* validationSample ); return the misclassification rate of a pruned tree for a validation event sample; using an EventList. Double_t TestTreeQuality( const DataSet* validationSample ); return the misclassification rate of a pruned tree for a validation event sample; using the DataSet. Double_t CheckEvent(const TMVA::Event& e, Bool_t useYesNoLeaf = false); return the decision tree output for an event. CCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex). CCTreeNode* GetRoot(); return the root node for this tree. { return fRoot; }. » Last changed: Thu Nov 3 20:19:24 2011 » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__CCTreeWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CCTreeWrapper.html
https://root.cern/root/html532/TMVA__CCTreeWrapper.html:1780,Security,validat,validationSample,1780,"apper&); TMVA::CCTreeWrapperCCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex); Double_tCheckEvent(const TMVA::Event& e, Bool_t useYesNoLeaf = false); TMVA::CCTreeWrapper::CCTreeNode*GetRoot(); voidInitTree(TMVA::CCTreeWrapper::CCTreeNode* t); TMVA::CCTreeWrapper&operator=(const TMVA::CCTreeWrapper&); voidPruneNode(TMVA::CCTreeWrapper::CCTreeNode* t); Double_tTestTreeQuality(const TMVA::CCTreeWrapper::EventList* validationSample); Double_tTestTreeQuality(const TMVA::DataSet* validationSample). Data Members; private:. TMVA::DecisionTree*fDTParent! pointer to underlying DecisionTree; TMVA::SeparationBase*fQualityIndex! pointer to the used quality index calculator; TMVA::CCTreeWrapper::CCTreeNode*fRoot! the root node of the (wrapped) decision Tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex); constructor. ~CCTreeWrapper(); destructor. void InitTree(TMVA::CCTreeWrapper::CCTreeNode* t); initialize the node t and all its descendants. void PruneNode(TMVA::CCTreeWrapper::CCTreeNode* t); remove the branch rooted at node t. Double_t TestTreeQuality( const EventList* validationSample ); return the misclassification rate of a pruned tree for a validation event sample; using an EventList. Double_t TestTreeQuality( const DataSet* validationSample ); return the misclassification rate of a pruned tree for a validation event sample; using the DataSet. Double_t CheckEvent(const TMVA::Event& e, Bool_t useYesNoLeaf = false); return the decision tree output for an event. CCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex). CCTreeNode* GetRoot(); return the root node for this tree. { return fRoot; }. » Last changed: Thu Nov 3 20:19:24 2011 » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__CCTreeWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CCTreeWrapper.html
https://root.cern/root/html532/TMVA__CCTreeWrapper.html:1857,Security,validat,validation,1857,"apper&); TMVA::CCTreeWrapperCCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex); Double_tCheckEvent(const TMVA::Event& e, Bool_t useYesNoLeaf = false); TMVA::CCTreeWrapper::CCTreeNode*GetRoot(); voidInitTree(TMVA::CCTreeWrapper::CCTreeNode* t); TMVA::CCTreeWrapper&operator=(const TMVA::CCTreeWrapper&); voidPruneNode(TMVA::CCTreeWrapper::CCTreeNode* t); Double_tTestTreeQuality(const TMVA::CCTreeWrapper::EventList* validationSample); Double_tTestTreeQuality(const TMVA::DataSet* validationSample). Data Members; private:. TMVA::DecisionTree*fDTParent! pointer to underlying DecisionTree; TMVA::SeparationBase*fQualityIndex! pointer to the used quality index calculator; TMVA::CCTreeWrapper::CCTreeNode*fRoot! the root node of the (wrapped) decision Tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex); constructor. ~CCTreeWrapper(); destructor. void InitTree(TMVA::CCTreeWrapper::CCTreeNode* t); initialize the node t and all its descendants. void PruneNode(TMVA::CCTreeWrapper::CCTreeNode* t); remove the branch rooted at node t. Double_t TestTreeQuality( const EventList* validationSample ); return the misclassification rate of a pruned tree for a validation event sample; using an EventList. Double_t TestTreeQuality( const DataSet* validationSample ); return the misclassification rate of a pruned tree for a validation event sample; using the DataSet. Double_t CheckEvent(const TMVA::Event& e, Bool_t useYesNoLeaf = false); return the decision tree output for an event. CCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex). CCTreeNode* GetRoot(); return the root node for this tree. { return fRoot; }. » Last changed: Thu Nov 3 20:19:24 2011 » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__CCTreeWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CCTreeWrapper.html
https://root.cern/root/html532/TMVA__Config.html:1316,Testability,log,logger,1316,; static voidDestroyInstance(); Bool_tDrawProgressBar() const; TMVA::Config::IONames&GetIONames(); TMVA::Config::VariablePlotting&GetVariablePlotting(); static TMVA::Config&Instance(); virtual TClass*IsA() const; Bool_tIsSilent() const; TMVA::Config&operator=(const TMVA::Config&); voidSetDrawProgressBar(Bool_t d); voidSetSilent(Bool_t s); voidSetUseColor(Bool_t uc); voidSetWriteOptionsReference(Bool_t w); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); Bool_tUseColor() const; Bool_tWriteOptionsReference() const. private:. (unknown)(); TMVA::ConfigConfig(); TMVA::MsgLogger&Log() const. Data Members; public:. TMVA::Config::IONamesfIONamesCustomisable weight file properties; TMVA::Config::VariablePlottingfVariablePlottingCustomisable plotting properties. private:. Bool_tfDrawProgressBardraw progress bar to indicate training evolution; TMVA::MsgLogger*fLoggermessage logger; Bool_tfSilentno output at all; Bool_tfUseColoredConsolecoloured standard output; Bool_tfWriteOptionsReferenceif set true: Configurable objects write file with option reference; static TMVA::Config*fgConfigPtr. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Config(); constructor - set defaults. void DestroyInstance(); static function: destroy TMVA instance. TMVA::Config& Instance(); static function: returns TMVA instance. Bool_t UseColor() const; { return fUseColoredConsole; }. void SetUseColor(Bool_t uc); { fUseColoredConsole = uc; }. Bool_t IsSilent() const; { return fSilent; }. void SetSilent(Bool_t s); { fSilent = s; }. Bool_t WriteOptionsReference() const; { return fWriteOptionsReference; }. void SetWriteOptionsReference(Bool_t w); { fWriteOptionsReference = w; }. Bool_t DrawProgressBar() const; { return fDrawProgressBar; }. void SetDrawProgressBar(Bool_t d); { fDrawProgressBar = d; }. VariablePlotting& GetVariablePlotting(); { return fVariablePlotting; }. IONames& GetIONames(); { retur,MatchSource.WIKI,root/html532/TMVA__Config.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config.html
https://root.cern/root/html532/TMVA__Config.html:1240,Usability,progress bar,progress bar,1240,; static voidDestroyInstance(); Bool_tDrawProgressBar() const; TMVA::Config::IONames&GetIONames(); TMVA::Config::VariablePlotting&GetVariablePlotting(); static TMVA::Config&Instance(); virtual TClass*IsA() const; Bool_tIsSilent() const; TMVA::Config&operator=(const TMVA::Config&); voidSetDrawProgressBar(Bool_t d); voidSetSilent(Bool_t s); voidSetUseColor(Bool_t uc); voidSetWriteOptionsReference(Bool_t w); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); Bool_tUseColor() const; Bool_tWriteOptionsReference() const. private:. (unknown)(); TMVA::ConfigConfig(); TMVA::MsgLogger&Log() const. Data Members; public:. TMVA::Config::IONamesfIONamesCustomisable weight file properties; TMVA::Config::VariablePlottingfVariablePlottingCustomisable plotting properties. private:. Bool_tfDrawProgressBardraw progress bar to indicate training evolution; TMVA::MsgLogger*fLoggermessage logger; Bool_tfSilentno output at all; Bool_tfUseColoredConsolecoloured standard output; Bool_tfWriteOptionsReferenceif set true: Configurable objects write file with option reference; static TMVA::Config*fgConfigPtr. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Config(); constructor - set defaults. void DestroyInstance(); static function: destroy TMVA instance. TMVA::Config& Instance(); static function: returns TMVA instance. Bool_t UseColor() const; { return fUseColoredConsole; }. void SetUseColor(Bool_t uc); { fUseColoredConsole = uc; }. Bool_t IsSilent() const; { return fSilent; }. void SetSilent(Bool_t s); { fSilent = s; }. Bool_t WriteOptionsReference() const; { return fWriteOptionsReference; }. void SetWriteOptionsReference(Bool_t w); { fWriteOptionsReference = w; }. Bool_t DrawProgressBar() const; { return fDrawProgressBar; }. void SetDrawProgressBar(Bool_t d); { fDrawProgressBar = d; }. VariablePlotting& GetVariablePlotting(); { return fVariablePlotting; }. IONames& GetIONames(); { retur,MatchSource.WIKI,root/html532/TMVA__Config.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config.html
https://root.cern/root/html532/TMVA__Configurable.html:1474,Availability,error,error,1474," voidAddOptionsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidCheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableConfigurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*GetConfigDescription() const; const char*GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&GetOptions() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const cha",MatchSource.WIKI,root/html532/TMVA__Configurable.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Configurable.html
https://root.cern/root/html532/TMVA__Configurable.html:1558,Availability,error,error,1558,"ption = """"); virtual voidTObject::Browse(TBrowser* b); voidCheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableConfigurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*GetConfigDescription() const; const char*GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&GetOptions() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char",MatchSource.WIKI,root/html532/TMVA__Configurable.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Configurable.html
https://root.cern/root/html532/TMVA__Configurable.html:6183,Integrability,message,message,6183,"ption = 0, Int_t bufsize = 0) const; voidWriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidEnableLooseOptions(Bool_t b = kTRUE); const TString&GetReferenceFile() const; TMVA::MsgLogger&Log() const; Bool_tLooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidResetSetFlag(); voidWriteOptionsReferenceToFile(). private:. voidSplitOptions(const TString& theOpt, TList& loo) const. Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. TStringfConfigDescriptiondescription of this configurable; TStringfConfigNamethe name of this configurable; TMVA::OptionBase*fLastDeclaredOption! last declared option; TListfListOfOptions! option list; TMVA::MsgLogger*fLogger! message logger; Bool_tfLooseOptionCheckingEnabled! checker for option string; TStringfOptions! options string; TStringfReferenceFilereference file for options writing. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Configurable(const TString& theOption = """"); constructor. ~Configurable(); default destructur. void SplitOptions(const TString& theOpt, TList& loo) const; splits the option string at ':' and fills the list 'loo' with the primitive strings. void ResetSetFlag(); resets the IsSet falg for all declare options; to be called before options are read from stream. void ParseOptions(); options parser. void CheckForUnusedOptions() const; checks for unused options in option string. void PrintOptions() const; prints out the options set in the options string and the defaults. void WriteOptionsToStream(ostream& o, const TString& prefix) const; write options to output stream (e.g. in writing the MVA weight files. void",MatchSource.WIKI,root/html532/TMVA__Configurable.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Configurable.html
https://root.cern/root/html532/TMVA__Configurable.html:8136,Integrability,message,message,8136,"oid SplitOptions(const TString& theOpt, TList& loo) const; splits the option string at ':' and fills the list 'loo' with the primitive strings. void ResetSetFlag(); resets the IsSet falg for all declare options; to be called before options are read from stream. void ParseOptions(); options parser. void CheckForUnusedOptions() const; checks for unused options in option string. void PrintOptions() const; prints out the options set in the options string and the defaults. void WriteOptionsToStream(ostream& o, const TString& prefix) const; write options to output stream (e.g. in writing the MVA weight files. void AddOptionsXMLTo(void* parent) const; write options to XML file. void ReadOptionsFromXML(void* node). void WriteOptionsReferenceToFile(); write complete options to output stream. void ReadOptionsFromStream(istream& istr); read option back from the weight file. const char* GetName() const; { return GetConfigName(); }. const char* GetConfigName() const; { return fConfigName; }. const char* GetConfigDescription() const; { return fConfigDescription; }. void SetConfigName(const char* n); { fConfigName = TString(n); }. void SetConfigDescription(const char* d); { fConfigDescription = TString(d); }. const TString& GetOptions() const; { return fOptions; }. void SetOptions(const TString& s); { fOptions = s; }. Bool_t LooseOptionCheckingEnabled() const; { return fLooseOptionCheckingEnabled; }. void EnableLooseOptions(Bool_t b = kTRUE); { fLooseOptionCheckingEnabled = b; }. const TString& GetReferenceFile() const; { return fReferenceFile; }. void SetMsgType(TMVA::EMsgType t); set message type. { fLogger->SetMinType(t); }. Log(). » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: Configurable.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Configurable.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Configurable.html
https://root.cern/root/html532/TMVA__Configurable.html:6001,Modifiability,config,configurable,6001,"ption = 0, Int_t bufsize = 0) const; voidWriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidEnableLooseOptions(Bool_t b = kTRUE); const TString&GetReferenceFile() const; TMVA::MsgLogger&Log() const; Bool_tLooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidResetSetFlag(); voidWriteOptionsReferenceToFile(). private:. voidSplitOptions(const TString& theOpt, TList& loo) const. Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. TStringfConfigDescriptiondescription of this configurable; TStringfConfigNamethe name of this configurable; TMVA::OptionBase*fLastDeclaredOption! last declared option; TListfListOfOptions! option list; TMVA::MsgLogger*fLogger! message logger; Bool_tfLooseOptionCheckingEnabled! checker for option string; TStringfOptions! options string; TStringfReferenceFilereference file for options writing. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Configurable(const TString& theOption = """"); constructor. ~Configurable(); default destructur. void SplitOptions(const TString& theOpt, TList& loo) const; splits the option string at ':' and fills the list 'loo' with the primitive strings. void ResetSetFlag(); resets the IsSet falg for all declare options; to be called before options are read from stream. void ParseOptions(); options parser. void CheckForUnusedOptions() const; checks for unused options in option string. void PrintOptions() const; prints out the options set in the options string and the defaults. void WriteOptionsToStream(ostream& o, const TString& prefix) const; write options to output stream (e.g. in writing the MVA weight files. void",MatchSource.WIKI,root/html532/TMVA__Configurable.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Configurable.html
https://root.cern/root/html532/TMVA__Configurable.html:6050,Modifiability,config,configurable,6050,"ption = 0, Int_t bufsize = 0) const; voidWriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidEnableLooseOptions(Bool_t b = kTRUE); const TString&GetReferenceFile() const; TMVA::MsgLogger&Log() const; Bool_tLooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidResetSetFlag(); voidWriteOptionsReferenceToFile(). private:. voidSplitOptions(const TString& theOpt, TList& loo) const. Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. TStringfConfigDescriptiondescription of this configurable; TStringfConfigNamethe name of this configurable; TMVA::OptionBase*fLastDeclaredOption! last declared option; TListfListOfOptions! option list; TMVA::MsgLogger*fLogger! message logger; Bool_tfLooseOptionCheckingEnabled! checker for option string; TStringfOptions! options string; TStringfReferenceFilereference file for options writing. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Configurable(const TString& theOption = """"); constructor. ~Configurable(); default destructur. void SplitOptions(const TString& theOpt, TList& loo) const; splits the option string at ':' and fills the list 'loo' with the primitive strings. void ResetSetFlag(); resets the IsSet falg for all declare options; to be called before options are read from stream. void ParseOptions(); options parser. void CheckForUnusedOptions() const; checks for unused options in option string. void PrintOptions() const; prints out the options set in the options string and the defaults. void WriteOptionsToStream(ostream& o, const TString& prefix) const; write options to output stream (e.g. in writing the MVA weight files. void",MatchSource.WIKI,root/html532/TMVA__Configurable.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Configurable.html
https://root.cern/root/html532/TMVA__Configurable.html:6191,Testability,log,logger,6191,"ption = 0, Int_t bufsize = 0) const; voidWriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidEnableLooseOptions(Bool_t b = kTRUE); const TString&GetReferenceFile() const; TMVA::MsgLogger&Log() const; Bool_tLooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidResetSetFlag(); voidWriteOptionsReferenceToFile(). private:. voidSplitOptions(const TString& theOpt, TList& loo) const. Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. TStringfConfigDescriptiondescription of this configurable; TStringfConfigNamethe name of this configurable; TMVA::OptionBase*fLastDeclaredOption! last declared option; TListfListOfOptions! option list; TMVA::MsgLogger*fLogger! message logger; Bool_tfLooseOptionCheckingEnabled! checker for option string; TStringfOptions! options string; TStringfReferenceFilereference file for options writing. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Configurable(const TString& theOption = """"); constructor. ~Configurable(); default destructur. void SplitOptions(const TString& theOpt, TList& loo) const; splits the option string at ':' and fills the list 'loo' with the primitive strings. void ResetSetFlag(); resets the IsSet falg for all declare options; to be called before options are read from stream. void ParseOptions(); options parser. void CheckForUnusedOptions() const; checks for unused options in option string. void PrintOptions() const; prints out the options set in the options string and the defaults. void WriteOptionsToStream(ostream& o, const TString& prefix) const; write options to output stream (e.g. in writing the MVA weight files. void",MatchSource.WIKI,root/html532/TMVA__Configurable.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Configurable.html
https://root.cern/root/html532/TMVA__Config__IONames.html:311,Deployability,configurat,configuration,311,". TMVA::Config::IONames. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config::IONames. class TMVA::Config::IONames. Config. Singleton class for global configuration settings used by TMVA. Function Members (Methods); public:. ~IONames(); TMVA::Config::IONamesIONames(); TMVA::Config::IONamesIONames(const TMVA::Config::IONames&); TMVA::Config::IONames&operator=(const TMVA::Config::IONames&). Data Members; public:. TStringfOptionsReferenceFileDir; TStringfWeightFileDir; TStringfWeightFileExtension. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation. » Author: Andreas Hoecker, Joerg Stelzer, Fredrik Tegenfeldt, Helge Voss » Copyright (c) 2006: *; » Last changed: root/tmva $Id: Config.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Config__IONames.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config__IONames.html
https://root.cern/root/html532/TMVA__Config__IONames.html:311,Modifiability,config,configuration,311,". TMVA::Config::IONames. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config::IONames. class TMVA::Config::IONames. Config. Singleton class for global configuration settings used by TMVA. Function Members (Methods); public:. ~IONames(); TMVA::Config::IONamesIONames(); TMVA::Config::IONamesIONames(const TMVA::Config::IONames&); TMVA::Config::IONames&operator=(const TMVA::Config::IONames&). Data Members; public:. TStringfOptionsReferenceFileDir; TStringfWeightFileDir; TStringfWeightFileExtension. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation. » Author: Andreas Hoecker, Joerg Stelzer, Fredrik Tegenfeldt, Helge Voss » Copyright (c) 2006: *; » Last changed: root/tmva $Id: Config.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Config__IONames.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config__IONames.html
https://root.cern/root/html532/TMVA__Config__VariablePlotting.html:338,Deployability,configurat,configuration,338,". TMVA::Config::VariablePlotting. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config::VariablePlotting. class TMVA::Config::VariablePlotting. Config. Singleton class for global configuration settings used by TMVA. Function Members (Methods); public:. ~VariablePlotting(); TMVA::Config::VariablePlotting&operator=(const TMVA::Config::VariablePlotting&); TMVA::Config::VariablePlottingVariablePlotting(); TMVA::Config::VariablePlottingVariablePlotting(const TMVA::Config::VariablePlotting&). Data Members; public:. Int_tfMaxNumOfAllowedVariablesForScatterPlots; Int_tfNbins1D; Int_tfNbins2D; Int_tfNbinsMVAoutput; Int_tfNbinsXOfROCCurve; Float_tfTimesRMS. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation. » Author: Andreas Hoecker, Joerg Stelzer, Fredrik Tegenfeldt, Helge Voss » Copyright (c) 2006: *; » Last changed: root/tmva $Id: Config.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Config__VariablePlotting.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config__VariablePlotting.html
https://root.cern/root/html532/TMVA__Config__VariablePlotting.html:338,Modifiability,config,configuration,338,". TMVA::Config::VariablePlotting. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config::VariablePlotting. class TMVA::Config::VariablePlotting. Config. Singleton class for global configuration settings used by TMVA. Function Members (Methods); public:. ~VariablePlotting(); TMVA::Config::VariablePlotting&operator=(const TMVA::Config::VariablePlotting&); TMVA::Config::VariablePlottingVariablePlotting(); TMVA::Config::VariablePlottingVariablePlotting(const TMVA::Config::VariablePlotting&). Data Members; public:. Int_tfMaxNumOfAllowedVariablesForScatterPlots; Int_tfNbins1D; Int_tfNbins2D; Int_tfNbinsMVAoutput; Int_tfNbinsXOfROCCurve; Float_tfTimesRMS. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation. » Author: Andreas Hoecker, Joerg Stelzer, Fredrik Tegenfeldt, Helge Voss » Copyright (c) 2006: *; » Last changed: root/tmva $Id: Config.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Config__VariablePlotting.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config__VariablePlotting.html
https://root.cern/root/html532/TMVA__CostComplexityPruneTool.html:2134,Availability,down,down,2134,"). private:. voidInitTreePruningMetaData(TMVA::DecisionTreeNode* n); TMVA::MsgLogger&Log() const; voidOptimize(TMVA::DecisionTree* dt, Double_t weights). Data Members; private:. TMVA::MsgLogger*fLogger! output stream to save logging information; Int_tfOptimalK! the optimal index of the prune sequence; vector<TMVA::DecisionTreeNode*,allocator<TMVA::DecisionTreeNode*> >fPruneSequence! map of weakest links (i.e., branches to prune) -> pruning index; vector<Double_t>fPruneStrengthList! map of alpha -> pruning index; vector<Double_t>fQualityIndexList! map of R(T) -> pruning index; TMVA::SeparationBase*fQualityIndexTool! the quality index used to calculate R(t), R(T) = sum[t in ~T]{ R(t) }. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CostComplexityPruneTool( SeparationBase* qualityIndex ); the constructor for the cost complexity prunig. ~CostComplexityPruneTool(); the destructor for the cost complexity prunig. CalculatePruningInfo(TMVA::DecisionTree* dt, const vector<TMVA::Event*,allocator<TMVA::Event*> >* testEvents = NULL, Bool_t isAutomatic = kFALSE). void InitTreePruningMetaData(TMVA::DecisionTreeNode* n); initialise ""meta data"" for the pruning, like the ""costcomplexity"", the; critical alpha, the minimal alpha down the tree, etc... for each node!!. void Optimize(TMVA::DecisionTree* dt, Double_t weights); after the critical alpha values (at which the corresponding nodes would; be pruned away) had been established in the ""InitMetaData"" we need now:; automatic pruning:; find the value of ""alpha"" for which the test sample gives minimal error,; on the tree with all nodes pruned that have alpha_critital < alpha,; fixed parameter pruning. CostComplexityPruneTool( SeparationBase* qualityIndex = NULL ). » Last changed: Thu Nov 3 20:19:25 2011 » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__CostComplexityPruneTool.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CostComplexityPruneTool.html
https://root.cern/root/html532/TMVA__CostComplexityPruneTool.html:2462,Availability,error,error,2462,"). private:. voidInitTreePruningMetaData(TMVA::DecisionTreeNode* n); TMVA::MsgLogger&Log() const; voidOptimize(TMVA::DecisionTree* dt, Double_t weights). Data Members; private:. TMVA::MsgLogger*fLogger! output stream to save logging information; Int_tfOptimalK! the optimal index of the prune sequence; vector<TMVA::DecisionTreeNode*,allocator<TMVA::DecisionTreeNode*> >fPruneSequence! map of weakest links (i.e., branches to prune) -> pruning index; vector<Double_t>fPruneStrengthList! map of alpha -> pruning index; vector<Double_t>fQualityIndexList! map of R(T) -> pruning index; TMVA::SeparationBase*fQualityIndexTool! the quality index used to calculate R(t), R(T) = sum[t in ~T]{ R(t) }. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CostComplexityPruneTool( SeparationBase* qualityIndex ); the constructor for the cost complexity prunig. ~CostComplexityPruneTool(); the destructor for the cost complexity prunig. CalculatePruningInfo(TMVA::DecisionTree* dt, const vector<TMVA::Event*,allocator<TMVA::Event*> >* testEvents = NULL, Bool_t isAutomatic = kFALSE). void InitTreePruningMetaData(TMVA::DecisionTreeNode* n); initialise ""meta data"" for the pruning, like the ""costcomplexity"", the; critical alpha, the minimal alpha down the tree, etc... for each node!!. void Optimize(TMVA::DecisionTree* dt, Double_t weights); after the critical alpha values (at which the corresponding nodes would; be pruned away) had been established in the ""InitMetaData"" we need now:; automatic pruning:; find the value of ""alpha"" for which the test sample gives minimal error,; on the tree with all nodes pruned that have alpha_critital < alpha,; fixed parameter pruning. CostComplexityPruneTool( SeparationBase* qualityIndex = NULL ). » Last changed: Thu Nov 3 20:19:25 2011 » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__CostComplexityPruneTool.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CostComplexityPruneTool.html
https://root.cern/root/html532/TMVA__CostComplexityPruneTool.html:545,Testability,test,testEvents,545,". TMVA::CostComplexityPruneTool. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::CostComplexityPruneTool. class TMVA::CostComplexityPruneTool: public TMVA::IPruneTool. Function Members (Methods); public:. virtual~CostComplexityPruneTool(); virtual TMVA::PruningInfo*CalculatePruningInfo(TMVA::DecisionTree* dt, const vector<TMVA::Event*,allocator<TMVA::Event*> >* testEvents = NULL, Bool_t isAutomatic = kFALSE); TMVA::CostComplexityPruneToolCostComplexityPruneTool(TMVA::SeparationBase* qualityIndex = NULL); TMVA::CostComplexityPruneToolCostComplexityPruneTool(const TMVA::CostComplexityPruneTool&); TMVA::CostComplexityPruneTool&operator=(const TMVA::CostComplexityPruneTool&). private:. voidInitTreePruningMetaData(TMVA::DecisionTreeNode* n); TMVA::MsgLogger&Log() const; voidOptimize(TMVA::DecisionTree* dt, Double_t weights). Data Members; private:. TMVA::MsgLogger*fLogger! output stream to save logging information; Int_tfOptimalK! the optimal index of the prune sequence; vector<TMVA::DecisionTreeNode*,allocator<TMVA::DecisionTreeNode*> >fPruneSequence! map of weakest links (i.e., branches to prune) -> pruning index; vector<Double_t>fPruneStrengthList! map of alpha -> pruning index; vector<Double_t>fQualityIndexList! map of R(T) -> pruning index; TMVA::SeparationBase*fQualityIndexTool! the quality index used to calculate R(t), R(T) = sum[t in ~T]{ R(t) }. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CostComplexityPruneTool( SeparationBase* qualityIndex ); the constructor for the cost complexity prunig. ~CostComplexityPruneTool(); the destructor for the cost complexity prunig. CalculatePruningInfo(TMVA::DecisionTree* dt, const vector<TMVA::Event*,allocator<TMVA::Event*> >* testEvents = NULL, Bool_t isAutomatic = kFALSE). void InitTreePruningMetaData(T",MatchSource.WIKI,root/html532/TMVA__CostComplexityPruneTool.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CostComplexityPruneTool.html
https://root.cern/root/html532/TMVA__CostComplexityPruneTool.html:1084,Testability,log,logging,1084,"wVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::CostComplexityPruneTool. class TMVA::CostComplexityPruneTool: public TMVA::IPruneTool. Function Members (Methods); public:. virtual~CostComplexityPruneTool(); virtual TMVA::PruningInfo*CalculatePruningInfo(TMVA::DecisionTree* dt, const vector<TMVA::Event*,allocator<TMVA::Event*> >* testEvents = NULL, Bool_t isAutomatic = kFALSE); TMVA::CostComplexityPruneToolCostComplexityPruneTool(TMVA::SeparationBase* qualityIndex = NULL); TMVA::CostComplexityPruneToolCostComplexityPruneTool(const TMVA::CostComplexityPruneTool&); TMVA::CostComplexityPruneTool&operator=(const TMVA::CostComplexityPruneTool&). private:. voidInitTreePruningMetaData(TMVA::DecisionTreeNode* n); TMVA::MsgLogger&Log() const; voidOptimize(TMVA::DecisionTree* dt, Double_t weights). Data Members; private:. TMVA::MsgLogger*fLogger! output stream to save logging information; Int_tfOptimalK! the optimal index of the prune sequence; vector<TMVA::DecisionTreeNode*,allocator<TMVA::DecisionTreeNode*> >fPruneSequence! map of weakest links (i.e., branches to prune) -> pruning index; vector<Double_t>fPruneStrengthList! map of alpha -> pruning index; vector<Double_t>fQualityIndexList! map of R(T) -> pruning index; TMVA::SeparationBase*fQualityIndexTool! the quality index used to calculate R(t), R(T) = sum[t in ~T]{ R(t) }. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CostComplexityPruneTool( SeparationBase* qualityIndex ); the constructor for the cost complexity prunig. ~CostComplexityPruneTool(); the destructor for the cost complexity prunig. CalculatePruningInfo(TMVA::DecisionTree* dt, const vector<TMVA::Event*,allocator<TMVA::Event*> >* testEvents = NULL, Bool_t isAutomatic = kFALSE). void InitTreePruningMetaData(TMVA::DecisionTreeNode* n); initialise ""meta data"" for the pruning, like the ""costcomplexity"", the; critical alpha, the minimal alpha down the tree, etc.",MatchSource.WIKI,root/html532/TMVA__CostComplexityPruneTool.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CostComplexityPruneTool.html
https://root.cern/root/html532/TMVA__CostComplexityPruneTool.html:1922,Testability,test,testEvents,1922,"). private:. voidInitTreePruningMetaData(TMVA::DecisionTreeNode* n); TMVA::MsgLogger&Log() const; voidOptimize(TMVA::DecisionTree* dt, Double_t weights). Data Members; private:. TMVA::MsgLogger*fLogger! output stream to save logging information; Int_tfOptimalK! the optimal index of the prune sequence; vector<TMVA::DecisionTreeNode*,allocator<TMVA::DecisionTreeNode*> >fPruneSequence! map of weakest links (i.e., branches to prune) -> pruning index; vector<Double_t>fPruneStrengthList! map of alpha -> pruning index; vector<Double_t>fQualityIndexList! map of R(T) -> pruning index; TMVA::SeparationBase*fQualityIndexTool! the quality index used to calculate R(t), R(T) = sum[t in ~T]{ R(t) }. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CostComplexityPruneTool( SeparationBase* qualityIndex ); the constructor for the cost complexity prunig. ~CostComplexityPruneTool(); the destructor for the cost complexity prunig. CalculatePruningInfo(TMVA::DecisionTree* dt, const vector<TMVA::Event*,allocator<TMVA::Event*> >* testEvents = NULL, Bool_t isAutomatic = kFALSE). void InitTreePruningMetaData(TMVA::DecisionTreeNode* n); initialise ""meta data"" for the pruning, like the ""costcomplexity"", the; critical alpha, the minimal alpha down the tree, etc... for each node!!. void Optimize(TMVA::DecisionTree* dt, Double_t weights); after the critical alpha values (at which the corresponding nodes would; be pruned away) had been established in the ""InitMetaData"" we need now:; automatic pruning:; find the value of ""alpha"" for which the test sample gives minimal error,; on the tree with all nodes pruned that have alpha_critital < alpha,; fixed parameter pruning. CostComplexityPruneTool( SeparationBase* qualityIndex = NULL ). » Last changed: Thu Nov 3 20:19:25 2011 » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__CostComplexityPruneTool.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CostComplexityPruneTool.html
https://root.cern/root/html532/TMVA__CostComplexityPruneTool.html:2436,Testability,test,test,2436,"). private:. voidInitTreePruningMetaData(TMVA::DecisionTreeNode* n); TMVA::MsgLogger&Log() const; voidOptimize(TMVA::DecisionTree* dt, Double_t weights). Data Members; private:. TMVA::MsgLogger*fLogger! output stream to save logging information; Int_tfOptimalK! the optimal index of the prune sequence; vector<TMVA::DecisionTreeNode*,allocator<TMVA::DecisionTreeNode*> >fPruneSequence! map of weakest links (i.e., branches to prune) -> pruning index; vector<Double_t>fPruneStrengthList! map of alpha -> pruning index; vector<Double_t>fQualityIndexList! map of R(T) -> pruning index; TMVA::SeparationBase*fQualityIndexTool! the quality index used to calculate R(t), R(T) = sum[t in ~T]{ R(t) }. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CostComplexityPruneTool( SeparationBase* qualityIndex ); the constructor for the cost complexity prunig. ~CostComplexityPruneTool(); the destructor for the cost complexity prunig. CalculatePruningInfo(TMVA::DecisionTree* dt, const vector<TMVA::Event*,allocator<TMVA::Event*> >* testEvents = NULL, Bool_t isAutomatic = kFALSE). void InitTreePruningMetaData(TMVA::DecisionTreeNode* n); initialise ""meta data"" for the pruning, like the ""costcomplexity"", the; critical alpha, the minimal alpha down the tree, etc... for each node!!. void Optimize(TMVA::DecisionTree* dt, Double_t weights); after the critical alpha values (at which the corresponding nodes would; be pruned away) had been established in the ""InitMetaData"" we need now:; automatic pruning:; find the value of ""alpha"" for which the test sample gives minimal error,; on the tree with all nodes pruned that have alpha_critital < alpha,; fixed parameter pruning. CostComplexityPruneTool( SeparationBase* qualityIndex = NULL ). » Last changed: Thu Nov 3 20:19:25 2011 » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__CostComplexityPruneTool.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CostComplexityPruneTool.html
https://root.cern/root/html532/TMVA__CrossEntropy.html:383,Testability,log,log,383,". TMVA::CrossEntropy. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::CrossEntropy. class TMVA::CrossEntropy: public TMVA::SeparationBase. Implementation of the CrossEntropy as separation criterion; -p log (p) - (1-p)log(1-p); p=purity. Function Members (Methods); public:. virtual~CrossEntropy(); static TClass*Class(); TMVA::CrossEntropyCrossEntropy(); TMVA::CrossEntropyCrossEntropy(const TMVA::CrossEntropy& g); const TString&TMVA::SeparationBase::GetName(); Double_tTMVA::SeparationBase::GetSeparationGain(const Double_t& nSelS, const Double_t& nSelB, const Double_t& nTotS, const Double_t& nTotB); virtual Double_tGetSeparationIndex(const Double_t& s, const Double_t& b); virtual TClass*IsA() const; TMVA::CrossEntropy&operator=(const TMVA::CrossEntropy&); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). Data Members; protected:. TStringTMVA::SeparationBase::fNamename of the concrete Separation Index impementation; Double_tTMVA::SeparationBase::fPrecisionCut. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Double_t GetSeparationIndex(const Double_t& s, const Double_t& b); Cross Entropy defined as; -p log (p) - (1-p)log(1-p); p=purity = s/(s+b). CrossEntropy(); default constructor. { fName = ""CE""; }. CrossEntropy(const TMVA::CrossEntropy& g); copy constructor. {}. virtual ~CrossEntropy(); destructor. {}. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: CrossEntropy.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__CrossEntropy.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CrossEntropy.html
https://root.cern/root/html532/TMVA__CrossEntropy.html:398,Testability,log,log,398,". TMVA::CrossEntropy. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::CrossEntropy. class TMVA::CrossEntropy: public TMVA::SeparationBase. Implementation of the CrossEntropy as separation criterion; -p log (p) - (1-p)log(1-p); p=purity. Function Members (Methods); public:. virtual~CrossEntropy(); static TClass*Class(); TMVA::CrossEntropyCrossEntropy(); TMVA::CrossEntropyCrossEntropy(const TMVA::CrossEntropy& g); const TString&TMVA::SeparationBase::GetName(); Double_tTMVA::SeparationBase::GetSeparationGain(const Double_t& nSelS, const Double_t& nSelB, const Double_t& nTotS, const Double_t& nTotB); virtual Double_tGetSeparationIndex(const Double_t& s, const Double_t& b); virtual TClass*IsA() const; TMVA::CrossEntropy&operator=(const TMVA::CrossEntropy&); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). Data Members; protected:. TStringTMVA::SeparationBase::fNamename of the concrete Separation Index impementation; Double_tTMVA::SeparationBase::fPrecisionCut. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Double_t GetSeparationIndex(const Double_t& s, const Double_t& b); Cross Entropy defined as; -p log (p) - (1-p)log(1-p); p=purity = s/(s+b). CrossEntropy(); default constructor. { fName = ""CE""; }. CrossEntropy(const TMVA::CrossEntropy& g); copy constructor. {}. virtual ~CrossEntropy(); destructor. {}. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: CrossEntropy.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__CrossEntropy.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CrossEntropy.html
https://root.cern/root/html532/TMVA__CrossEntropy.html:1406,Testability,log,log,1406,". TMVA::CrossEntropy. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::CrossEntropy. class TMVA::CrossEntropy: public TMVA::SeparationBase. Implementation of the CrossEntropy as separation criterion; -p log (p) - (1-p)log(1-p); p=purity. Function Members (Methods); public:. virtual~CrossEntropy(); static TClass*Class(); TMVA::CrossEntropyCrossEntropy(); TMVA::CrossEntropyCrossEntropy(const TMVA::CrossEntropy& g); const TString&TMVA::SeparationBase::GetName(); Double_tTMVA::SeparationBase::GetSeparationGain(const Double_t& nSelS, const Double_t& nSelB, const Double_t& nTotS, const Double_t& nTotB); virtual Double_tGetSeparationIndex(const Double_t& s, const Double_t& b); virtual TClass*IsA() const; TMVA::CrossEntropy&operator=(const TMVA::CrossEntropy&); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). Data Members; protected:. TStringTMVA::SeparationBase::fNamename of the concrete Separation Index impementation; Double_tTMVA::SeparationBase::fPrecisionCut. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Double_t GetSeparationIndex(const Double_t& s, const Double_t& b); Cross Entropy defined as; -p log (p) - (1-p)log(1-p); p=purity = s/(s+b). CrossEntropy(); default constructor. { fName = ""CE""; }. CrossEntropy(const TMVA::CrossEntropy& g); copy constructor. {}. virtual ~CrossEntropy(); destructor. {}. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: CrossEntropy.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__CrossEntropy.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CrossEntropy.html
https://root.cern/root/html532/TMVA__CrossEntropy.html:1421,Testability,log,log,1421,". TMVA::CrossEntropy. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::CrossEntropy. class TMVA::CrossEntropy: public TMVA::SeparationBase. Implementation of the CrossEntropy as separation criterion; -p log (p) - (1-p)log(1-p); p=purity. Function Members (Methods); public:. virtual~CrossEntropy(); static TClass*Class(); TMVA::CrossEntropyCrossEntropy(); TMVA::CrossEntropyCrossEntropy(const TMVA::CrossEntropy& g); const TString&TMVA::SeparationBase::GetName(); Double_tTMVA::SeparationBase::GetSeparationGain(const Double_t& nSelS, const Double_t& nSelB, const Double_t& nTotS, const Double_t& nTotB); virtual Double_tGetSeparationIndex(const Double_t& s, const Double_t& b); virtual TClass*IsA() const; TMVA::CrossEntropy&operator=(const TMVA::CrossEntropy&); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). Data Members; protected:. TStringTMVA::SeparationBase::fNamename of the concrete Separation Index impementation; Double_tTMVA::SeparationBase::fPrecisionCut. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Double_t GetSeparationIndex(const Double_t& s, const Double_t& b); Cross Entropy defined as; -p log (p) - (1-p)log(1-p); p=purity = s/(s+b). CrossEntropy(); default constructor. { fName = ""CE""; }. CrossEntropy(const TMVA::CrossEntropy& g); copy constructor. {}. virtual ~CrossEntropy(); destructor. {}. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: CrossEntropy.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__CrossEntropy.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CrossEntropy.html
https://root.cern/root/html532/TMVA__DecisionTree.html:11858,Availability,down,down,11858,"t rid of internal nodes) the Decision tree to avoid overtraining; serveral different pruning methods can be applied as selected by the; variable ""fPruneMethod"". void ApplyValidationSample(const TMVA::DecisionTree::EventList* validationSample) const; run the validation sample through the (pruned) tree and fill in the nodes; the variables NSValidation and NBValidadtion (i.e. how many of the Signal; and Background events from the validation sample. This is then later used; when asking for the ""tree quality"" .. Double_t TestPrunedTreeQuality(const TMVA::DecisionTreeNode* dt = NULL, Int_t mode = 0) const; return the misclassification rate of a pruned tree; a ""pruned tree"" may have set the variable ""IsTerminal"" to ""arbitrary"" at; any node, hence this tree quality testing will stop there, hence test; the pruned tree (while the full tree is still in place for normal/later use). void CheckEventWithPrunedTree(const TMVA::Event& ) const; pass a single validation event throught a pruned decision tree; on the way down the tree, fill in all the ""intermediate"" information; that would normally be there from training. Double_t GetSumWeights(const TMVA::DecisionTree::EventList* validationSample) const; calculate the normalization factor for a pruning validation sample. UInt_t CountLeafNodes(TMVA::Node* n = NULL); return the number of terminal nodes in the sub-tree below Node n. void DescendTree(TMVA::Node* n = NULL); descend a tree to find all its leaf nodes. void PruneNode(TMVA::DecisionTreeNode* node); prune away the subtree below the node. void PruneNodeInPlace(TMVA::DecisionTreeNode* node); prune a node temporaily (without actually deleting its decendants; which allows testing the pruned tree quality for many different; pruning stages without ""touching"" the tree. TMVA::Node* GetNode(ULong_t sequence, UInt_t depth); retrieve node from the tree. Its position (up to a maximal tree depth of 64); is coded as a sequence of left-right moves starting from the root, coded as; 0-1 bit patt",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:526,Modifiability,variab,variable,526,". TMVA::DecisionTree. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::DecisionTree. class TMVA::DecisionTree: public TMVA::BinaryTree. Implementation of a Decision Tree. In a decision tree successive decision nodes are used to categorize the; events out of the sample as either signal or background. Each node; uses only a single discriminating variable to decide if the event is; signal-like (""goes right"") or background-like (""goes left""). This; forms a tree like structure with ""baskets"" at the end (leave nodes),; and an event is classified as either signal or background according to; whether the basket where it ends up has been classified signal or; background during the training. Training of a decision tree is the; process to define the ""cut criteria"" for each node. The training; starts with the root node. Here one takes the full training event; sample and selects the variable and corresponding cut value that gives; the best separation between signal and background at this stage. Using; this cut criterion, the sample is then divided into two subsamples, a; signal-like (right) and a background-like (left) sample. Two new nodes; are then created for each of the two sub-samples and they are; constructed using the same mechanism as described for the root; node. The devision is stopped once a certain node has reached either a; minimum number of events, or a minimum or maximum signal purity. These; leave nodes are then called ""signal"" or ""background"" if they contain; more signal respective background events from the training sample. Function Members (Methods); public:. virtual~DecisionTree(); virtual void*TMVA::BinaryTree::AddXMLTo(void* parent) const; voidApplyValidationSample(const TMVA::DecisionTree::EventList* validationSample) const; UInt_tBuildTree(const TMVA::DecisionTree::EventList& even",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:1062,Modifiability,variab,variable,1062,"h. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::DecisionTree. class TMVA::DecisionTree: public TMVA::BinaryTree. Implementation of a Decision Tree. In a decision tree successive decision nodes are used to categorize the; events out of the sample as either signal or background. Each node; uses only a single discriminating variable to decide if the event is; signal-like (""goes right"") or background-like (""goes left""). This; forms a tree like structure with ""baskets"" at the end (leave nodes),; and an event is classified as either signal or background according to; whether the basket where it ends up has been classified signal or; background during the training. Training of a decision tree is the; process to define the ""cut criteria"" for each node. The training; starts with the root node. Here one takes the full training event; sample and selects the variable and corresponding cut value that gives; the best separation between signal and background at this stage. Using; this cut criterion, the sample is then divided into two subsamples, a; signal-like (right) and a background-like (left) sample. Two new nodes; are then created for each of the two sub-samples and they are; constructed using the same mechanism as described for the root; node. The devision is stopped once a certain node has reached either a; minimum number of events, or a minimum or maximum signal purity. These; leave nodes are then called ""signal"" or ""background"" if they contain; more signal respective background events from the training sample. Function Members (Methods); public:. virtual~DecisionTree(); virtual void*TMVA::BinaryTree::AddXMLTo(void* parent) const; voidApplyValidationSample(const TMVA::DecisionTree::EventList* validationSample) const; UInt_tBuildTree(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node = NULL); Double_tCheckEvent(const TMVA::Event&, ",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:3745,Modifiability,variab,variableMap,3745,,MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:6529,Modifiability,variab,variables,6529,"ist& eventSample, TMVA::DecisionTreeNode* node). protected:. voidTMVA::BinaryTree::DeleteNode(TMVA::Node*); TMVA::MsgLogger&TMVA::BinaryTree::Log() const. private:. Double_tSamplePurity(TMVA::DecisionTree::EventList eventSample). Data Members; public:. enum EPruneMethod { kExpectedErrorPruning; kCostComplexityPruning; kNoPruning; };. protected:. UInt_tTMVA::BinaryTree::fDepthmaximal depth in tree reached; UInt_tTMVA::BinaryTree::fNNodestotal number of nodes in the tree (counted); TMVA::Node*TMVA::BinaryTree::fRootthe root node of the tree; static TMVA::MsgLogger*TMVA::BinaryTree::fgLoggermessage logger, static to save resources . private:. TMVA::Types::EAnalysisTypefAnalysisTypekClassification(=0=false) or kRegression(=1=true); UInt_tfMaxDepthmax depth; Double_tfMinLinCorrForFisherthe minimum linear correlation between two variables demanded for use in fisher criterium in node splitting; Double_tfMinSepGainmin number of separation gain to perform node splitting; Double_tfMinSizemin number of events in node; TRandom3*fMyTrandomrandom number generator for randomised trees; Int_tfNCutsnumber of grid point in variable cut scans; UInt_tfNNodesMaxmax # of nodes; Double_tfNodePurityLimitpurity limit to decide whether a node is signal; UInt_tfNvarsnumber of variables used to separate S and B; Bool_tfPairNegWeightsInNoderandomly pair miscl. ev. with neg. and pos. weights in node and don't boost them; TMVA::DecisionTree::EPruneMethodfPruneMethodmethod used for prunig ; Double_tfPruneStrengtha parameter to set the ""amount"" of pruning..needs to be adjusted ; Bool_tfRandomisedTreechoose at each node splitting a random set of variables ; TMVA::RegressionVariance*fRegTypethe separation crition used in Regression; TMVA::SeparationBase*fSepTypethe separation crition; UInt_tfSigClassclass which is treated as signal when building the tree; Int_tfTreeIDjust an ID number given to the tree.. makes debugging easier as tree knows who he is.; Bool_tfUseExclusiveVarsindividual variables alre",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:6817,Modifiability,variab,variable,6817,"ist& eventSample, TMVA::DecisionTreeNode* node). protected:. voidTMVA::BinaryTree::DeleteNode(TMVA::Node*); TMVA::MsgLogger&TMVA::BinaryTree::Log() const. private:. Double_tSamplePurity(TMVA::DecisionTree::EventList eventSample). Data Members; public:. enum EPruneMethod { kExpectedErrorPruning; kCostComplexityPruning; kNoPruning; };. protected:. UInt_tTMVA::BinaryTree::fDepthmaximal depth in tree reached; UInt_tTMVA::BinaryTree::fNNodestotal number of nodes in the tree (counted); TMVA::Node*TMVA::BinaryTree::fRootthe root node of the tree; static TMVA::MsgLogger*TMVA::BinaryTree::fgLoggermessage logger, static to save resources . private:. TMVA::Types::EAnalysisTypefAnalysisTypekClassification(=0=false) or kRegression(=1=true); UInt_tfMaxDepthmax depth; Double_tfMinLinCorrForFisherthe minimum linear correlation between two variables demanded for use in fisher criterium in node splitting; Double_tfMinSepGainmin number of separation gain to perform node splitting; Double_tfMinSizemin number of events in node; TRandom3*fMyTrandomrandom number generator for randomised trees; Int_tfNCutsnumber of grid point in variable cut scans; UInt_tfNNodesMaxmax # of nodes; Double_tfNodePurityLimitpurity limit to decide whether a node is signal; UInt_tfNvarsnumber of variables used to separate S and B; Bool_tfPairNegWeightsInNoderandomly pair miscl. ev. with neg. and pos. weights in node and don't boost them; TMVA::DecisionTree::EPruneMethodfPruneMethodmethod used for prunig ; Double_tfPruneStrengtha parameter to set the ""amount"" of pruning..needs to be adjusted ; Bool_tfRandomisedTreechoose at each node splitting a random set of variables ; TMVA::RegressionVariance*fRegTypethe separation crition used in Regression; TMVA::SeparationBase*fSepTypethe separation crition; UInt_tfSigClassclass which is treated as signal when building the tree; Int_tfTreeIDjust an ID number given to the tree.. makes debugging easier as tree knows who he is.; Bool_tfUseExclusiveVarsindividual variables alre",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:6964,Modifiability,variab,variables,6964,"ist& eventSample, TMVA::DecisionTreeNode* node). protected:. voidTMVA::BinaryTree::DeleteNode(TMVA::Node*); TMVA::MsgLogger&TMVA::BinaryTree::Log() const. private:. Double_tSamplePurity(TMVA::DecisionTree::EventList eventSample). Data Members; public:. enum EPruneMethod { kExpectedErrorPruning; kCostComplexityPruning; kNoPruning; };. protected:. UInt_tTMVA::BinaryTree::fDepthmaximal depth in tree reached; UInt_tTMVA::BinaryTree::fNNodestotal number of nodes in the tree (counted); TMVA::Node*TMVA::BinaryTree::fRootthe root node of the tree; static TMVA::MsgLogger*TMVA::BinaryTree::fgLoggermessage logger, static to save resources . private:. TMVA::Types::EAnalysisTypefAnalysisTypekClassification(=0=false) or kRegression(=1=true); UInt_tfMaxDepthmax depth; Double_tfMinLinCorrForFisherthe minimum linear correlation between two variables demanded for use in fisher criterium in node splitting; Double_tfMinSepGainmin number of separation gain to perform node splitting; Double_tfMinSizemin number of events in node; TRandom3*fMyTrandomrandom number generator for randomised trees; Int_tfNCutsnumber of grid point in variable cut scans; UInt_tfNNodesMaxmax # of nodes; Double_tfNodePurityLimitpurity limit to decide whether a node is signal; UInt_tfNvarsnumber of variables used to separate S and B; Bool_tfPairNegWeightsInNoderandomly pair miscl. ev. with neg. and pos. weights in node and don't boost them; TMVA::DecisionTree::EPruneMethodfPruneMethodmethod used for prunig ; Double_tfPruneStrengtha parameter to set the ""amount"" of pruning..needs to be adjusted ; Bool_tfRandomisedTreechoose at each node splitting a random set of variables ; TMVA::RegressionVariance*fRegTypethe separation crition used in Regression; TMVA::SeparationBase*fSepTypethe separation crition; UInt_tfSigClassclass which is treated as signal when building the tree; Int_tfTreeIDjust an ID number given to the tree.. makes debugging easier as tree knows who he is.; Bool_tfUseExclusiveVarsindividual variables alre",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:7334,Modifiability,variab,variables,7334,"on(=1=true); UInt_tfMaxDepthmax depth; Double_tfMinLinCorrForFisherthe minimum linear correlation between two variables demanded for use in fisher criterium in node splitting; Double_tfMinSepGainmin number of separation gain to perform node splitting; Double_tfMinSizemin number of events in node; TRandom3*fMyTrandomrandom number generator for randomised trees; Int_tfNCutsnumber of grid point in variable cut scans; UInt_tfNNodesMaxmax # of nodes; Double_tfNodePurityLimitpurity limit to decide whether a node is signal; UInt_tfNvarsnumber of variables used to separate S and B; Bool_tfPairNegWeightsInNoderandomly pair miscl. ev. with neg. and pos. weights in node and don't boost them; TMVA::DecisionTree::EPruneMethodfPruneMethodmethod used for prunig ; Double_tfPruneStrengtha parameter to set the ""amount"" of pruning..needs to be adjusted ; Bool_tfRandomisedTreechoose at each node splitting a random set of variables ; TMVA::RegressionVariance*fRegTypethe separation crition used in Regression; TMVA::SeparationBase*fSepTypethe separation crition; UInt_tfSigClassclass which is treated as signal when building the tree; Int_tfTreeIDjust an ID number given to the tree.. makes debugging easier as tree knows who he is.; Bool_tfUseExclusiveVarsindividual variables already used in fisher criterium are not anymore analysed individually for node splitting; Bool_tfUseFisherCutsuse multivariate splits using the Fisher criterium; Int_tfUseNvarsthe number of variables used in randomised trees;; Bool_tfUsePoissonNvarsuse ""fUseNvars"" not as fixed number but as mean of a possion distr. in each split; Bool_tfUseSearchTreecut scan done with binary trees or simple event loop.; vector<Double_t>fVariableImportancethe relative importance of the different variables ; static const Int_tfgDebugLeveldebug level determining some printout/control plots etc.; static const Int_tfgRandomSeedset nonzero for debugging and zero for random seeds. Class Charts. Inheritance; Inherited Members; Includes; Librari",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:7680,Modifiability,variab,variables,7680," cut scans; UInt_tfNNodesMaxmax # of nodes; Double_tfNodePurityLimitpurity limit to decide whether a node is signal; UInt_tfNvarsnumber of variables used to separate S and B; Bool_tfPairNegWeightsInNoderandomly pair miscl. ev. with neg. and pos. weights in node and don't boost them; TMVA::DecisionTree::EPruneMethodfPruneMethodmethod used for prunig ; Double_tfPruneStrengtha parameter to set the ""amount"" of pruning..needs to be adjusted ; Bool_tfRandomisedTreechoose at each node splitting a random set of variables ; TMVA::RegressionVariance*fRegTypethe separation crition used in Regression; TMVA::SeparationBase*fSepTypethe separation crition; UInt_tfSigClassclass which is treated as signal when building the tree; Int_tfTreeIDjust an ID number given to the tree.. makes debugging easier as tree knows who he is.; Bool_tfUseExclusiveVarsindividual variables already used in fisher criterium are not anymore analysed individually for node splitting; Bool_tfUseFisherCutsuse multivariate splits using the Fisher criterium; Int_tfUseNvarsthe number of variables used in randomised trees;; Bool_tfUsePoissonNvarsuse ""fUseNvars"" not as fixed number but as mean of a possion distr. in each split; Bool_tfUseSearchTreecut scan done with binary trees or simple event loop.; vector<Double_t>fVariableImportancethe relative importance of the different variables ; static const Int_tfgDebugLeveldebug level determining some printout/control plots etc.; static const Int_tfgRandomSeedset nonzero for debugging and zero for random seeds. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; DecisionTree(); default constructor using the GiniIndex as separation criterion,; no restrictions on minium number of events in a leave note or the; separation gain in the node splitting. DecisionTree(TMVA::SeparationBase* sepType, Int_t minSize, Int_t nCuts, UInt_t cls = 0, Bool_t randomisedTree = kFALSE, Int_t useNvars = 0, Bool_t usePoissonNvars = kFALSE, UInt_t nNodesMax ",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:7881,Modifiability,variab,variables,7881," cut scans; UInt_tfNNodesMaxmax # of nodes; Double_tfNodePurityLimitpurity limit to decide whether a node is signal; UInt_tfNvarsnumber of variables used to separate S and B; Bool_tfPairNegWeightsInNoderandomly pair miscl. ev. with neg. and pos. weights in node and don't boost them; TMVA::DecisionTree::EPruneMethodfPruneMethodmethod used for prunig ; Double_tfPruneStrengtha parameter to set the ""amount"" of pruning..needs to be adjusted ; Bool_tfRandomisedTreechoose at each node splitting a random set of variables ; TMVA::RegressionVariance*fRegTypethe separation crition used in Regression; TMVA::SeparationBase*fSepTypethe separation crition; UInt_tfSigClassclass which is treated as signal when building the tree; Int_tfTreeIDjust an ID number given to the tree.. makes debugging easier as tree knows who he is.; Bool_tfUseExclusiveVarsindividual variables already used in fisher criterium are not anymore analysed individually for node splitting; Bool_tfUseFisherCutsuse multivariate splits using the Fisher criterium; Int_tfUseNvarsthe number of variables used in randomised trees;; Bool_tfUsePoissonNvarsuse ""fUseNvars"" not as fixed number but as mean of a possion distr. in each split; Bool_tfUseSearchTreecut scan done with binary trees or simple event loop.; vector<Double_t>fVariableImportancethe relative importance of the different variables ; static const Int_tfgDebugLeveldebug level determining some printout/control plots etc.; static const Int_tfgRandomSeedset nonzero for debugging and zero for random seeds. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; DecisionTree(); default constructor using the GiniIndex as separation criterion,; no restrictions on minium number of events in a leave note or the; separation gain in the node splitting. DecisionTree(TMVA::SeparationBase* sepType, Int_t minSize, Int_t nCuts, UInt_t cls = 0, Bool_t randomisedTree = kFALSE, Int_t useNvars = 0, Bool_t usePoissonNvars = kFALSE, UInt_t nNodesMax ",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:8174,Modifiability,variab,variables,8174,"_tfPruneStrengtha parameter to set the ""amount"" of pruning..needs to be adjusted ; Bool_tfRandomisedTreechoose at each node splitting a random set of variables ; TMVA::RegressionVariance*fRegTypethe separation crition used in Regression; TMVA::SeparationBase*fSepTypethe separation crition; UInt_tfSigClassclass which is treated as signal when building the tree; Int_tfTreeIDjust an ID number given to the tree.. makes debugging easier as tree knows who he is.; Bool_tfUseExclusiveVarsindividual variables already used in fisher criterium are not anymore analysed individually for node splitting; Bool_tfUseFisherCutsuse multivariate splits using the Fisher criterium; Int_tfUseNvarsthe number of variables used in randomised trees;; Bool_tfUsePoissonNvarsuse ""fUseNvars"" not as fixed number but as mean of a possion distr. in each split; Bool_tfUseSearchTreecut scan done with binary trees or simple event loop.; vector<Double_t>fVariableImportancethe relative importance of the different variables ; static const Int_tfgDebugLeveldebug level determining some printout/control plots etc.; static const Int_tfgRandomSeedset nonzero for debugging and zero for random seeds. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; DecisionTree(); default constructor using the GiniIndex as separation criterion,; no restrictions on minium number of events in a leave note or the; separation gain in the node splitting. DecisionTree(TMVA::SeparationBase* sepType, Int_t minSize, Int_t nCuts, UInt_t cls = 0, Bool_t randomisedTree = kFALSE, Int_t useNvars = 0, Bool_t usePoissonNvars = kFALSE, UInt_t nNodesMax = 999999, UInt_t nMaxDepth = 9999999, Int_t iSeed = fgRandomSeed, Float_t purityLimit = 0.5, Int_t treeID = 0); constructor specifying the separation type, the min number of; events in a no that is still subjected to further splitting, the; number of bins in the grid used in applying the cut for the node; splitting. DecisionTree(const TMVA::DecisionTree& d",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:10978,Modifiability,variab,variable,10978,"r of nodes). void FillTree(TMVA::DecisionTree::EventList& eventSample); fill the existing the decision tree structure by filling event; in from the top node and see where they happen to end up. void FillEvent(TMVA::Event& event, TMVA::DecisionTreeNode* node); fill the existing the decision tree structure by filling event; in from the top node and see where they happen to end up. void ClearTree(); clear the tree nodes (their S/N, Nevents etc), just keep the structure of the tree. UInt_t CleanTree(TMVA::DecisionTreeNode* node = NULL); remove those last splits that result in two leaf nodes that; are both of the type (i.e. both signal or both background); this of course is only a reasonable thing to do when you use; ""YesOrNo"" leafs, while it might loose s.th. if you use the; purity information in the nodes.; --> hence I don't call it automatically in the tree building. Double_t PruneTree(TMVA::DecisionTree::EventList* validationSample = NULL); prune (get rid of internal nodes) the Decision tree to avoid overtraining; serveral different pruning methods can be applied as selected by the; variable ""fPruneMethod"". void ApplyValidationSample(const TMVA::DecisionTree::EventList* validationSample) const; run the validation sample through the (pruned) tree and fill in the nodes; the variables NSValidation and NBValidadtion (i.e. how many of the Signal; and Background events from the validation sample. This is then later used; when asking for the ""tree quality"" .. Double_t TestPrunedTreeQuality(const TMVA::DecisionTreeNode* dt = NULL, Int_t mode = 0) const; return the misclassification rate of a pruned tree; a ""pruned tree"" may have set the variable ""IsTerminal"" to ""arbitrary"" at; any node, hence this tree quality testing will stop there, hence test; the pruned tree (while the full tree is still in place for normal/later use). void CheckEventWithPrunedTree(const TMVA::Event& ) const; pass a single validation event throught a pruned decision tree; on the way down the tree, fill i",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:11171,Modifiability,variab,variables,11171,"TMVA::DecisionTreeNode* node); fill the existing the decision tree structure by filling event; in from the top node and see where they happen to end up. void ClearTree(); clear the tree nodes (their S/N, Nevents etc), just keep the structure of the tree. UInt_t CleanTree(TMVA::DecisionTreeNode* node = NULL); remove those last splits that result in two leaf nodes that; are both of the type (i.e. both signal or both background); this of course is only a reasonable thing to do when you use; ""YesOrNo"" leafs, while it might loose s.th. if you use the; purity information in the nodes.; --> hence I don't call it automatically in the tree building. Double_t PruneTree(TMVA::DecisionTree::EventList* validationSample = NULL); prune (get rid of internal nodes) the Decision tree to avoid overtraining; serveral different pruning methods can be applied as selected by the; variable ""fPruneMethod"". void ApplyValidationSample(const TMVA::DecisionTree::EventList* validationSample) const; run the validation sample through the (pruned) tree and fill in the nodes; the variables NSValidation and NBValidadtion (i.e. how many of the Signal; and Background events from the validation sample. This is then later used; when asking for the ""tree quality"" .. Double_t TestPrunedTreeQuality(const TMVA::DecisionTreeNode* dt = NULL, Int_t mode = 0) const; return the misclassification rate of a pruned tree; a ""pruned tree"" may have set the variable ""IsTerminal"" to ""arbitrary"" at; any node, hence this tree quality testing will stop there, hence test; the pruned tree (while the full tree is still in place for normal/later use). void CheckEventWithPrunedTree(const TMVA::Event& ) const; pass a single validation event throught a pruned decision tree; on the way down the tree, fill in all the ""intermediate"" information; that would normally be there from training. Double_t GetSumWeights(const TMVA::DecisionTree::EventList* validationSample) const; calculate the normalization factor for a pruning validation sam",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:11535,Modifiability,variab,variable,11535,"this of course is only a reasonable thing to do when you use; ""YesOrNo"" leafs, while it might loose s.th. if you use the; purity information in the nodes.; --> hence I don't call it automatically in the tree building. Double_t PruneTree(TMVA::DecisionTree::EventList* validationSample = NULL); prune (get rid of internal nodes) the Decision tree to avoid overtraining; serveral different pruning methods can be applied as selected by the; variable ""fPruneMethod"". void ApplyValidationSample(const TMVA::DecisionTree::EventList* validationSample) const; run the validation sample through the (pruned) tree and fill in the nodes; the variables NSValidation and NBValidadtion (i.e. how many of the Signal; and Background events from the validation sample. This is then later used; when asking for the ""tree quality"" .. Double_t TestPrunedTreeQuality(const TMVA::DecisionTreeNode* dt = NULL, Int_t mode = 0) const; return the misclassification rate of a pruned tree; a ""pruned tree"" may have set the variable ""IsTerminal"" to ""arbitrary"" at; any node, hence this tree quality testing will stop there, hence test; the pruned tree (while the full tree is still in place for normal/later use). void CheckEventWithPrunedTree(const TMVA::Event& ) const; pass a single validation event throught a pruned decision tree; on the way down the tree, fill in all the ""intermediate"" information; that would normally be there from training. Double_t GetSumWeights(const TMVA::DecisionTree::EventList* validationSample) const; calculate the normalization factor for a pruning validation sample. UInt_t CountLeafNodes(TMVA::Node* n = NULL); return the number of terminal nodes in the sub-tree below Node n. void DescendTree(TMVA::Node* n = NULL); descend a tree to find all its leaf nodes. void PruneNode(TMVA::DecisionTreeNode* node); prune away the subtree below the node. void PruneNodeInPlace(TMVA::DecisionTreeNode* node); prune a node temporaily (without actually deleting its decendants; which allows testing the p",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:12957,Modifiability,variab,variableMap,12957,"ere from training. Double_t GetSumWeights(const TMVA::DecisionTree::EventList* validationSample) const; calculate the normalization factor for a pruning validation sample. UInt_t CountLeafNodes(TMVA::Node* n = NULL); return the number of terminal nodes in the sub-tree below Node n. void DescendTree(TMVA::Node* n = NULL); descend a tree to find all its leaf nodes. void PruneNode(TMVA::DecisionTreeNode* node); prune away the subtree below the node. void PruneNodeInPlace(TMVA::DecisionTreeNode* node); prune a node temporaily (without actually deleting its decendants; which allows testing the pruned tree quality for many different; pruning stages without ""touching"" the tree. TMVA::Node* GetNode(ULong_t sequence, UInt_t depth); retrieve node from the tree. Its position (up to a maximal tree depth of 64); is coded as a sequence of left-right moves starting from the root, coded as; 0-1 bit patterns stored in the ""long-integer"" (i.e. 0:left ; 1:right. void GetRandomisedVariables(Bool_t* useVariable, UInt_t* variableMap, UInt_t& nVars). Double_t TrainNodeFast(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node); Decide how to split a node using one of the variables that gives; the best separation of signal/background. In order to do this, for each; variable a scan of the different cut values in a grid (grid = fNCuts) is; performed and the resulting separation gains are compared.; in addition to the individual variables, one can also ask for a fisher; discriminant being built out of (some) of the variables and used as a; possible multivariate split. std::vector<Double_t> GetFisherCoefficients(const TMVA::DecisionTree::EventList& eventSample, UInt_t nFisherVars, UInt_t* mapVarInFisher); calculate the fisher coefficients for the event sample and the variables used. Double_t TrainNodeFull(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node). TMVA::DecisionTreeNode* GetEventNode(const TMVA::Event& e) const; get the pointer to ",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:13134,Modifiability,variab,variables,13134,"ing validation sample. UInt_t CountLeafNodes(TMVA::Node* n = NULL); return the number of terminal nodes in the sub-tree below Node n. void DescendTree(TMVA::Node* n = NULL); descend a tree to find all its leaf nodes. void PruneNode(TMVA::DecisionTreeNode* node); prune away the subtree below the node. void PruneNodeInPlace(TMVA::DecisionTreeNode* node); prune a node temporaily (without actually deleting its decendants; which allows testing the pruned tree quality for many different; pruning stages without ""touching"" the tree. TMVA::Node* GetNode(ULong_t sequence, UInt_t depth); retrieve node from the tree. Its position (up to a maximal tree depth of 64); is coded as a sequence of left-right moves starting from the root, coded as; 0-1 bit patterns stored in the ""long-integer"" (i.e. 0:left ; 1:right. void GetRandomisedVariables(Bool_t* useVariable, UInt_t* variableMap, UInt_t& nVars). Double_t TrainNodeFast(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node); Decide how to split a node using one of the variables that gives; the best separation of signal/background. In order to do this, for each; variable a scan of the different cut values in a grid (grid = fNCuts) is; performed and the resulting separation gains are compared.; in addition to the individual variables, one can also ask for a fisher; discriminant being built out of (some) of the variables and used as a; possible multivariate split. std::vector<Double_t> GetFisherCoefficients(const TMVA::DecisionTree::EventList& eventSample, UInt_t nFisherVars, UInt_t* mapVarInFisher); calculate the fisher coefficients for the event sample and the variables used. Double_t TrainNodeFull(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node). TMVA::DecisionTreeNode* GetEventNode(const TMVA::Event& e) const; get the pointer to the leaf node where a particular event ends up in...; (used in gradient boosting). Double_t CheckEvent(const TMVA::Event& , Bool_t UseYesNoLeaf = kFA",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:13229,Modifiability,variab,variable,13229," to find all its leaf nodes. void PruneNode(TMVA::DecisionTreeNode* node); prune away the subtree below the node. void PruneNodeInPlace(TMVA::DecisionTreeNode* node); prune a node temporaily (without actually deleting its decendants; which allows testing the pruned tree quality for many different; pruning stages without ""touching"" the tree. TMVA::Node* GetNode(ULong_t sequence, UInt_t depth); retrieve node from the tree. Its position (up to a maximal tree depth of 64); is coded as a sequence of left-right moves starting from the root, coded as; 0-1 bit patterns stored in the ""long-integer"" (i.e. 0:left ; 1:right. void GetRandomisedVariables(Bool_t* useVariable, UInt_t* variableMap, UInt_t& nVars). Double_t TrainNodeFast(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node); Decide how to split a node using one of the variables that gives; the best separation of signal/background. In order to do this, for each; variable a scan of the different cut values in a grid (grid = fNCuts) is; performed and the resulting separation gains are compared.; in addition to the individual variables, one can also ask for a fisher; discriminant being built out of (some) of the variables and used as a; possible multivariate split. std::vector<Double_t> GetFisherCoefficients(const TMVA::DecisionTree::EventList& eventSample, UInt_t nFisherVars, UInt_t* mapVarInFisher); calculate the fisher coefficients for the event sample and the variables used. Double_t TrainNodeFull(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node). TMVA::DecisionTreeNode* GetEventNode(const TMVA::Event& e) const; get the pointer to the leaf node where a particular event ends up in...; (used in gradient boosting). Double_t CheckEvent(const TMVA::Event& , Bool_t UseYesNoLeaf = kFALSE) const; the event e is put into the decision tree (starting at the root node); and the output is NodeType (signal) or (background) of the final node (basket); in which the given events",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:13393,Modifiability,variab,variables,13393,"rune a node temporaily (without actually deleting its decendants; which allows testing the pruned tree quality for many different; pruning stages without ""touching"" the tree. TMVA::Node* GetNode(ULong_t sequence, UInt_t depth); retrieve node from the tree. Its position (up to a maximal tree depth of 64); is coded as a sequence of left-right moves starting from the root, coded as; 0-1 bit patterns stored in the ""long-integer"" (i.e. 0:left ; 1:right. void GetRandomisedVariables(Bool_t* useVariable, UInt_t* variableMap, UInt_t& nVars). Double_t TrainNodeFast(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node); Decide how to split a node using one of the variables that gives; the best separation of signal/background. In order to do this, for each; variable a scan of the different cut values in a grid (grid = fNCuts) is; performed and the resulting separation gains are compared.; in addition to the individual variables, one can also ask for a fisher; discriminant being built out of (some) of the variables and used as a; possible multivariate split. std::vector<Double_t> GetFisherCoefficients(const TMVA::DecisionTree::EventList& eventSample, UInt_t nFisherVars, UInt_t* mapVarInFisher); calculate the fisher coefficients for the event sample and the variables used. Double_t TrainNodeFull(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node). TMVA::DecisionTreeNode* GetEventNode(const TMVA::Event& e) const; get the pointer to the leaf node where a particular event ends up in...; (used in gradient boosting). Double_t CheckEvent(const TMVA::Event& , Bool_t UseYesNoLeaf = kFALSE) const; the event e is put into the decision tree (starting at the root node); and the output is NodeType (signal) or (background) of the final node (basket); in which the given events ends up. I.e. the result of the classification if; the event for this decision tree. Double_t SamplePurity(TMVA::DecisionTree::EventList eventSample); calculates the pu",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:13481,Modifiability,variab,variables,13481,"rune a node temporaily (without actually deleting its decendants; which allows testing the pruned tree quality for many different; pruning stages without ""touching"" the tree. TMVA::Node* GetNode(ULong_t sequence, UInt_t depth); retrieve node from the tree. Its position (up to a maximal tree depth of 64); is coded as a sequence of left-right moves starting from the root, coded as; 0-1 bit patterns stored in the ""long-integer"" (i.e. 0:left ; 1:right. void GetRandomisedVariables(Bool_t* useVariable, UInt_t* variableMap, UInt_t& nVars). Double_t TrainNodeFast(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node); Decide how to split a node using one of the variables that gives; the best separation of signal/background. In order to do this, for each; variable a scan of the different cut values in a grid (grid = fNCuts) is; performed and the resulting separation gains are compared.; in addition to the individual variables, one can also ask for a fisher; discriminant being built out of (some) of the variables and used as a; possible multivariate split. std::vector<Double_t> GetFisherCoefficients(const TMVA::DecisionTree::EventList& eventSample, UInt_t nFisherVars, UInt_t* mapVarInFisher); calculate the fisher coefficients for the event sample and the variables used. Double_t TrainNodeFull(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node). TMVA::DecisionTreeNode* GetEventNode(const TMVA::Event& e) const; get the pointer to the leaf node where a particular event ends up in...; (used in gradient boosting). Double_t CheckEvent(const TMVA::Event& , Bool_t UseYesNoLeaf = kFALSE) const; the event e is put into the decision tree (starting at the root node); and the output is NodeType (signal) or (background) of the final node (basket); in which the given events ends up. I.e. the result of the classification if; the event for this decision tree. Double_t SamplePurity(TMVA::DecisionTree::EventList eventSample); calculates the pu",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:13737,Modifiability,variab,variables,13737,"Long_t sequence, UInt_t depth); retrieve node from the tree. Its position (up to a maximal tree depth of 64); is coded as a sequence of left-right moves starting from the root, coded as; 0-1 bit patterns stored in the ""long-integer"" (i.e. 0:left ; 1:right. void GetRandomisedVariables(Bool_t* useVariable, UInt_t* variableMap, UInt_t& nVars). Double_t TrainNodeFast(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node); Decide how to split a node using one of the variables that gives; the best separation of signal/background. In order to do this, for each; variable a scan of the different cut values in a grid (grid = fNCuts) is; performed and the resulting separation gains are compared.; in addition to the individual variables, one can also ask for a fisher; discriminant being built out of (some) of the variables and used as a; possible multivariate split. std::vector<Double_t> GetFisherCoefficients(const TMVA::DecisionTree::EventList& eventSample, UInt_t nFisherVars, UInt_t* mapVarInFisher); calculate the fisher coefficients for the event sample and the variables used. Double_t TrainNodeFull(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node). TMVA::DecisionTreeNode* GetEventNode(const TMVA::Event& e) const; get the pointer to the leaf node where a particular event ends up in...; (used in gradient boosting). Double_t CheckEvent(const TMVA::Event& , Bool_t UseYesNoLeaf = kFALSE) const; the event e is put into the decision tree (starting at the root node); and the output is NodeType (signal) or (background) of the final node (basket); in which the given events ends up. I.e. the result of the classification if; the event for this decision tree. Double_t SamplePurity(TMVA::DecisionTree::EventList eventSample); calculates the purity S/(S+B) of a given event sample. vector< Double_t > GetVariableImportance(); Return the relative variable importance, normalized to all; variables together having the importance 1. The impor",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:14550,Modifiability,variab,variable,14550,"tFisherCoefficients(const TMVA::DecisionTree::EventList& eventSample, UInt_t nFisherVars, UInt_t* mapVarInFisher); calculate the fisher coefficients for the event sample and the variables used. Double_t TrainNodeFull(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node). TMVA::DecisionTreeNode* GetEventNode(const TMVA::Event& e) const; get the pointer to the leaf node where a particular event ends up in...; (used in gradient boosting). Double_t CheckEvent(const TMVA::Event& , Bool_t UseYesNoLeaf = kFALSE) const; the event e is put into the decision tree (starting at the root node); and the output is NodeType (signal) or (background) of the final node (basket); in which the given events ends up. I.e. the result of the classification if; the event for this decision tree. Double_t SamplePurity(TMVA::DecisionTree::EventList eventSample); calculates the purity S/(S+B) of a given event sample. vector< Double_t > GetVariableImportance(); Return the relative variable importance, normalized to all; variables together having the importance 1. The importance in; evaluated as the total separation-gain that this variable had in; the decision trees (weighted by the number of events). Double_t GetVariableImportance(UInt_t ivar); returns the relative improtance of variable ivar. DecisionTreeNode* GetRoot() const; Retrieves the address of the root node. { return dynamic_cast<TMVA::DecisionTreeNode*>(fRoot); }. DecisionTreeNode * CreateNode(UInt_t ) const; { return new DecisionTreeNode(); }. BinaryTree* CreateTree() const; { return new DecisionTree(); }. const char* ClassName() const; { return ""DecisionTree""; }. Double_t TrainNode(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node); determine the way how a node is split (which variable, which cut value). { return TrainNodeFast( eventSample, node ); }. void SetPruneMethod(TMVA::DecisionTree::EPruneMethod m = kCostComplexityPruning); { fPruneMethod = m; }. void SetPruneStrength(Doub",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:14590,Modifiability,variab,variables,14590,"tFisherCoefficients(const TMVA::DecisionTree::EventList& eventSample, UInt_t nFisherVars, UInt_t* mapVarInFisher); calculate the fisher coefficients for the event sample and the variables used. Double_t TrainNodeFull(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node). TMVA::DecisionTreeNode* GetEventNode(const TMVA::Event& e) const; get the pointer to the leaf node where a particular event ends up in...; (used in gradient boosting). Double_t CheckEvent(const TMVA::Event& , Bool_t UseYesNoLeaf = kFALSE) const; the event e is put into the decision tree (starting at the root node); and the output is NodeType (signal) or (background) of the final node (basket); in which the given events ends up. I.e. the result of the classification if; the event for this decision tree. Double_t SamplePurity(TMVA::DecisionTree::EventList eventSample); calculates the purity S/(S+B) of a given event sample. vector< Double_t > GetVariableImportance(); Return the relative variable importance, normalized to all; variables together having the importance 1. The importance in; evaluated as the total separation-gain that this variable had in; the decision trees (weighted by the number of events). Double_t GetVariableImportance(UInt_t ivar); returns the relative improtance of variable ivar. DecisionTreeNode* GetRoot() const; Retrieves the address of the root node. { return dynamic_cast<TMVA::DecisionTreeNode*>(fRoot); }. DecisionTreeNode * CreateNode(UInt_t ) const; { return new DecisionTreeNode(); }. BinaryTree* CreateTree() const; { return new DecisionTree(); }. const char* ClassName() const; { return ""DecisionTree""; }. Double_t TrainNode(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node); determine the way how a node is split (which variable, which cut value). { return TrainNodeFast( eventSample, node ); }. void SetPruneMethod(TMVA::DecisionTree::EPruneMethod m = kCostComplexityPruning); { fPruneMethod = m; }. void SetPruneStrength(Doub",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:14702,Modifiability,variab,variable,14702,"ents for the event sample and the variables used. Double_t TrainNodeFull(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node). TMVA::DecisionTreeNode* GetEventNode(const TMVA::Event& e) const; get the pointer to the leaf node where a particular event ends up in...; (used in gradient boosting). Double_t CheckEvent(const TMVA::Event& , Bool_t UseYesNoLeaf = kFALSE) const; the event e is put into the decision tree (starting at the root node); and the output is NodeType (signal) or (background) of the final node (basket); in which the given events ends up. I.e. the result of the classification if; the event for this decision tree. Double_t SamplePurity(TMVA::DecisionTree::EventList eventSample); calculates the purity S/(S+B) of a given event sample. vector< Double_t > GetVariableImportance(); Return the relative variable importance, normalized to all; variables together having the importance 1. The importance in; evaluated as the total separation-gain that this variable had in; the decision trees (weighted by the number of events). Double_t GetVariableImportance(UInt_t ivar); returns the relative improtance of variable ivar. DecisionTreeNode* GetRoot() const; Retrieves the address of the root node. { return dynamic_cast<TMVA::DecisionTreeNode*>(fRoot); }. DecisionTreeNode * CreateNode(UInt_t ) const; { return new DecisionTreeNode(); }. BinaryTree* CreateTree() const; { return new DecisionTree(); }. const char* ClassName() const; { return ""DecisionTree""; }. Double_t TrainNode(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node); determine the way how a node is split (which variable, which cut value). { return TrainNodeFast( eventSample, node ); }. void SetPruneMethod(TMVA::DecisionTree::EPruneMethod m = kCostComplexityPruning); { fPruneMethod = m; }. void SetPruneStrength(Double_t p); manage the pruning strength parameter (iff < 0 -> automate the pruning process). { fPruneStrength = p; }. Double_t GetPruneStrength() c",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:14854,Modifiability,variab,variable,14854,"mple, TMVA::DecisionTreeNode* node). TMVA::DecisionTreeNode* GetEventNode(const TMVA::Event& e) const; get the pointer to the leaf node where a particular event ends up in...; (used in gradient boosting). Double_t CheckEvent(const TMVA::Event& , Bool_t UseYesNoLeaf = kFALSE) const; the event e is put into the decision tree (starting at the root node); and the output is NodeType (signal) or (background) of the final node (basket); in which the given events ends up. I.e. the result of the classification if; the event for this decision tree. Double_t SamplePurity(TMVA::DecisionTree::EventList eventSample); calculates the purity S/(S+B) of a given event sample. vector< Double_t > GetVariableImportance(); Return the relative variable importance, normalized to all; variables together having the importance 1. The importance in; evaluated as the total separation-gain that this variable had in; the decision trees (weighted by the number of events). Double_t GetVariableImportance(UInt_t ivar); returns the relative improtance of variable ivar. DecisionTreeNode* GetRoot() const; Retrieves the address of the root node. { return dynamic_cast<TMVA::DecisionTreeNode*>(fRoot); }. DecisionTreeNode * CreateNode(UInt_t ) const; { return new DecisionTreeNode(); }. BinaryTree* CreateTree() const; { return new DecisionTree(); }. const char* ClassName() const; { return ""DecisionTree""; }. Double_t TrainNode(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node); determine the way how a node is split (which variable, which cut value). { return TrainNodeFast( eventSample, node ); }. void SetPruneMethod(TMVA::DecisionTree::EPruneMethod m = kCostComplexityPruning); { fPruneMethod = m; }. void SetPruneStrength(Double_t p); manage the pruning strength parameter (iff < 0 -> automate the pruning process). { fPruneStrength = p; }. Double_t GetPruneStrength() const; { return fPruneStrength; }. void SetNodePurityLimit(Double_t p); { fNodePurityLimit = p; }. Double_t GetNodePuri",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:15352,Modifiability,variab,variable,15352,". the result of the classification if; the event for this decision tree. Double_t SamplePurity(TMVA::DecisionTree::EventList eventSample); calculates the purity S/(S+B) of a given event sample. vector< Double_t > GetVariableImportance(); Return the relative variable importance, normalized to all; variables together having the importance 1. The importance in; evaluated as the total separation-gain that this variable had in; the decision trees (weighted by the number of events). Double_t GetVariableImportance(UInt_t ivar); returns the relative improtance of variable ivar. DecisionTreeNode* GetRoot() const; Retrieves the address of the root node. { return dynamic_cast<TMVA::DecisionTreeNode*>(fRoot); }. DecisionTreeNode * CreateNode(UInt_t ) const; { return new DecisionTreeNode(); }. BinaryTree* CreateTree() const; { return new DecisionTree(); }. const char* ClassName() const; { return ""DecisionTree""; }. Double_t TrainNode(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node); determine the way how a node is split (which variable, which cut value). { return TrainNodeFast( eventSample, node ); }. void SetPruneMethod(TMVA::DecisionTree::EPruneMethod m = kCostComplexityPruning); { fPruneMethod = m; }. void SetPruneStrength(Double_t p); manage the pruning strength parameter (iff < 0 -> automate the pruning process). { fPruneStrength = p; }. Double_t GetPruneStrength() const; { return fPruneStrength; }. void SetNodePurityLimit(Double_t p); { fNodePurityLimit = p; }. Double_t GetNodePurityLimit() const; { return fNodePurityLimit; }. void SetTreeID(Int_t treeID); {fTreeID = treeID;}. Int_t GetTreeID(); {return fTreeID;}. Bool_t DoRegression() const; { return fAnalysisType == Types::kRegression; }. void SetAnalysisType(TMVA::Types::EAnalysisType t); { fAnalysisType = t;}. Types::EAnalysisType GetAnalysisType( void ); { return fAnalysisType;}. void SetUseFisherCuts(Bool_t t = kTRUE); { fUseFisherCuts = t;}. void SetMinLinCorrForFisher(Double_t min); {fM",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:6647,Performance,perform,perform,6647,"ist& eventSample, TMVA::DecisionTreeNode* node). protected:. voidTMVA::BinaryTree::DeleteNode(TMVA::Node*); TMVA::MsgLogger&TMVA::BinaryTree::Log() const. private:. Double_tSamplePurity(TMVA::DecisionTree::EventList eventSample). Data Members; public:. enum EPruneMethod { kExpectedErrorPruning; kCostComplexityPruning; kNoPruning; };. protected:. UInt_tTMVA::BinaryTree::fDepthmaximal depth in tree reached; UInt_tTMVA::BinaryTree::fNNodestotal number of nodes in the tree (counted); TMVA::Node*TMVA::BinaryTree::fRootthe root node of the tree; static TMVA::MsgLogger*TMVA::BinaryTree::fgLoggermessage logger, static to save resources . private:. TMVA::Types::EAnalysisTypefAnalysisTypekClassification(=0=false) or kRegression(=1=true); UInt_tfMaxDepthmax depth; Double_tfMinLinCorrForFisherthe minimum linear correlation between two variables demanded for use in fisher criterium in node splitting; Double_tfMinSepGainmin number of separation gain to perform node splitting; Double_tfMinSizemin number of events in node; TRandom3*fMyTrandomrandom number generator for randomised trees; Int_tfNCutsnumber of grid point in variable cut scans; UInt_tfNNodesMaxmax # of nodes; Double_tfNodePurityLimitpurity limit to decide whether a node is signal; UInt_tfNvarsnumber of variables used to separate S and B; Bool_tfPairNegWeightsInNoderandomly pair miscl. ev. with neg. and pos. weights in node and don't boost them; TMVA::DecisionTree::EPruneMethodfPruneMethodmethod used for prunig ; Double_tfPruneStrengtha parameter to set the ""amount"" of pruning..needs to be adjusted ; Bool_tfRandomisedTreechoose at each node splitting a random set of variables ; TMVA::RegressionVariance*fRegTypethe separation crition used in Regression; TMVA::SeparationBase*fSepTypethe separation crition; UInt_tfSigClassclass which is treated as signal when building the tree; Int_tfTreeIDjust an ID number given to the tree.. makes debugging easier as tree knows who he is.; Bool_tfUseExclusiveVarsindividual variables alre",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:13303,Performance,perform,performed,13303," to find all its leaf nodes. void PruneNode(TMVA::DecisionTreeNode* node); prune away the subtree below the node. void PruneNodeInPlace(TMVA::DecisionTreeNode* node); prune a node temporaily (without actually deleting its decendants; which allows testing the pruned tree quality for many different; pruning stages without ""touching"" the tree. TMVA::Node* GetNode(ULong_t sequence, UInt_t depth); retrieve node from the tree. Its position (up to a maximal tree depth of 64); is coded as a sequence of left-right moves starting from the root, coded as; 0-1 bit patterns stored in the ""long-integer"" (i.e. 0:left ; 1:right. void GetRandomisedVariables(Bool_t* useVariable, UInt_t* variableMap, UInt_t& nVars). Double_t TrainNodeFast(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node); Decide how to split a node using one of the variables that gives; the best separation of signal/background. In order to do this, for each; variable a scan of the different cut values in a grid (grid = fNCuts) is; performed and the resulting separation gains are compared.; in addition to the individual variables, one can also ask for a fisher; discriminant being built out of (some) of the variables and used as a; possible multivariate split. std::vector<Double_t> GetFisherCoefficients(const TMVA::DecisionTree::EventList& eventSample, UInt_t nFisherVars, UInt_t* mapVarInFisher); calculate the fisher coefficients for the event sample and the variables used. Double_t TrainNodeFull(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node). TMVA::DecisionTreeNode* GetEventNode(const TMVA::Event& e) const; get the pointer to the leaf node where a particular event ends up in...; (used in gradient boosting). Double_t CheckEvent(const TMVA::Event& , Bool_t UseYesNoLeaf = kFALSE) const; the event e is put into the decision tree (starting at the root node); and the output is NodeType (signal) or (background) of the final node (basket); in which the given events",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:10888,Safety,avoid,avoid,10888,"r of nodes). void FillTree(TMVA::DecisionTree::EventList& eventSample); fill the existing the decision tree structure by filling event; in from the top node and see where they happen to end up. void FillEvent(TMVA::Event& event, TMVA::DecisionTreeNode* node); fill the existing the decision tree structure by filling event; in from the top node and see where they happen to end up. void ClearTree(); clear the tree nodes (their S/N, Nevents etc), just keep the structure of the tree. UInt_t CleanTree(TMVA::DecisionTreeNode* node = NULL); remove those last splits that result in two leaf nodes that; are both of the type (i.e. both signal or both background); this of course is only a reasonable thing to do when you use; ""YesOrNo"" leafs, while it might loose s.th. if you use the; purity information in the nodes.; --> hence I don't call it automatically in the tree building. Double_t PruneTree(TMVA::DecisionTree::EventList* validationSample = NULL); prune (get rid of internal nodes) the Decision tree to avoid overtraining; serveral different pruning methods can be applied as selected by the; variable ""fPruneMethod"". void ApplyValidationSample(const TMVA::DecisionTree::EventList* validationSample) const; run the validation sample through the (pruned) tree and fill in the nodes; the variables NSValidation and NBValidadtion (i.e. how many of the Signal; and Background events from the validation sample. This is then later used; when asking for the ""tree quality"" .. Double_t TestPrunedTreeQuality(const TMVA::DecisionTreeNode* dt = NULL, Int_t mode = 0) const; return the misclassification rate of a pruned tree; a ""pruned tree"" may have set the variable ""IsTerminal"" to ""arbitrary"" at; any node, hence this tree quality testing will stop there, hence test; the pruned tree (while the full tree is still in place for normal/later use). void CheckEventWithPrunedTree(const TMVA::Event& ) const; pass a single validation event throught a pruned decision tree; on the way down the tree, fill i",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:1919,Security,validat,validationSample,1919,"constructed using the same mechanism as described for the root; node. The devision is stopped once a certain node has reached either a; minimum number of events, or a minimum or maximum signal purity. These; leave nodes are then called ""signal"" or ""background"" if they contain; more signal respective background events from the training sample. Function Members (Methods); public:. virtual~DecisionTree(); virtual void*TMVA::BinaryTree::AddXMLTo(void* parent) const; voidApplyValidationSample(const TMVA::DecisionTree::EventList* validationSample) const; UInt_tBuildTree(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node = NULL); Double_tCheckEvent(const TMVA::Event&, Bool_t UseYesNoLeaf = kFALSE) const; voidCheckEventWithPrunedTree(const TMVA::Event&) const; static TClass*Class(); virtual const char*ClassName() const; UInt_tCleanTree(TMVA::DecisionTreeNode* node = NULL); voidClearTree(); UInt_tCountLeafNodes(TMVA::Node* n = NULL); UInt_tTMVA::BinaryTree::CountNodes(TMVA::Node* n = NULL); static TMVA::DecisionTree*CreateFromXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); virtual TMVA::DecisionTreeNode*CreateNode(UInt_t) const; virtual TMVA::BinaryTree*CreateTree() const; TMVA::DecisionTreeDecisionTree(); TMVA::DecisionTreeDecisionTree(const TMVA::DecisionTree& d); TMVA::DecisionTreeDecisionTree(TMVA::SeparationBase* sepType, Int_t minSize, Int_t nCuts, UInt_t cls = 0, Bool_t randomisedTree = kFALSE, Int_t useNvars = 0, Bool_t usePoissonNvars = kFALSE, UInt_t nNodesMax = 999999, UInt_t nMaxDepth = 9999999, Int_t iSeed = fgRandomSeed, Float_t purityLimit = 0.5, Int_t treeID = 0); voidDescendTree(TMVA::Node* n = NULL); Bool_tDoRegression() const; voidFillEvent(TMVA::Event& event, TMVA::DecisionTreeNode* node); voidFillTree(TMVA::DecisionTree::EventList& eventSample); TMVA::Types::EAnalysisTypeGetAnalysisType(); TMVA::DecisionTreeNode*GetEventNode(const TMVA::Event& e) const; vector<Double_t>GetFisherCoefficients(const TMVA::DecisionT",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:3943,Security,validat,validationSample,3943,,MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:4409,Security,validat,validationSample,4409," UInt_t nFisherVars, UInt_t* mapVarInFisher); TMVA::Node*TMVA::BinaryTree::GetLeftDaughter(TMVA::Node* n); UInt_tTMVA::BinaryTree::GetNNodes() const; TMVA::Node*GetNode(ULong_t sequence, UInt_t depth); Double_tGetNodePurityLimit() const; Double_tGetPruneStrength() const; voidGetRandomisedVariables(Bool_t* useVariable, UInt_t* variableMap, UInt_t& nVars); TMVA::Node*TMVA::BinaryTree::GetRightDaughter(TMVA::Node* n); virtual TMVA::DecisionTreeNode*GetRoot() const; Double_tGetSumWeights(const TMVA::DecisionTree::EventList* validationSample) const; UInt_tTMVA::BinaryTree::GetTotalTreeDepth() const; Int_tGetTreeID(); vector<Double_t>GetVariableImportance(); Double_tGetVariableImportance(UInt_t ivar); virtual TClass*IsA() const; TMVA::DecisionTree&operator=(const TMVA::DecisionTree&); virtual voidTMVA::BinaryTree::Print(ostream& os) const; voidPruneNode(TMVA::DecisionTreeNode* node); voidPruneNodeInPlace(TMVA::DecisionTreeNode* node); Double_tPruneTree(TMVA::DecisionTree::EventList* validationSample = NULL); virtual voidTMVA::BinaryTree::Read(istream& istr, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); virtual voidTMVA::BinaryTree::ReadXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); voidSetAnalysisType(TMVA::Types::EAnalysisType t); voidSetMinLinCorrForFisher(Double_t min); voidSetNodePurityLimit(Double_t p); voidSetPairNegWeightsInNode(); voidSetParentTreeInNodes(TMVA::Node* n = NULL); voidSetPruneMethod(TMVA::DecisionTree::EPruneMethod m = kCostComplexityPruning); voidSetPruneStrength(Double_t p); voidTMVA::BinaryTree::SetRoot(TMVA::Node* r); voidTMVA::BinaryTree::SetTotalTreeDepth(Int_t depth); voidTMVA::BinaryTree::SetTotalTreeDepth(TMVA::Node* n = NULL); voidSetTreeID(Int_t treeID); voidSetUseExclusiveVars(Bool_t t = kTRUE); voidSetUseFisherCuts(Bool_t t = kTRUE); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); Double_tTestPrunedTreeQuality(const TMVA::DecisionTreeNode* dt = NULL, Int",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:10807,Security,validat,validationSample,10807,"r of nodes). void FillTree(TMVA::DecisionTree::EventList& eventSample); fill the existing the decision tree structure by filling event; in from the top node and see where they happen to end up. void FillEvent(TMVA::Event& event, TMVA::DecisionTreeNode* node); fill the existing the decision tree structure by filling event; in from the top node and see where they happen to end up. void ClearTree(); clear the tree nodes (their S/N, Nevents etc), just keep the structure of the tree. UInt_t CleanTree(TMVA::DecisionTreeNode* node = NULL); remove those last splits that result in two leaf nodes that; are both of the type (i.e. both signal or both background); this of course is only a reasonable thing to do when you use; ""YesOrNo"" leafs, while it might loose s.th. if you use the; purity information in the nodes.; --> hence I don't call it automatically in the tree building. Double_t PruneTree(TMVA::DecisionTree::EventList* validationSample = NULL); prune (get rid of internal nodes) the Decision tree to avoid overtraining; serveral different pruning methods can be applied as selected by the; variable ""fPruneMethod"". void ApplyValidationSample(const TMVA::DecisionTree::EventList* validationSample) const; run the validation sample through the (pruned) tree and fill in the nodes; the variables NSValidation and NBValidadtion (i.e. how many of the Signal; and Background events from the validation sample. This is then later used; when asking for the ""tree quality"" .. Double_t TestPrunedTreeQuality(const TMVA::DecisionTreeNode* dt = NULL, Int_t mode = 0) const; return the misclassification rate of a pruned tree; a ""pruned tree"" may have set the variable ""IsTerminal"" to ""arbitrary"" at; any node, hence this tree quality testing will stop there, hence test; the pruned tree (while the full tree is still in place for normal/later use). void CheckEventWithPrunedTree(const TMVA::Event& ) const; pass a single validation event throught a pruned decision tree; on the way down the tree, fill i",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:11067,Security,validat,validationSample,11067,"TMVA::DecisionTreeNode* node); fill the existing the decision tree structure by filling event; in from the top node and see where they happen to end up. void ClearTree(); clear the tree nodes (their S/N, Nevents etc), just keep the structure of the tree. UInt_t CleanTree(TMVA::DecisionTreeNode* node = NULL); remove those last splits that result in two leaf nodes that; are both of the type (i.e. both signal or both background); this of course is only a reasonable thing to do when you use; ""YesOrNo"" leafs, while it might loose s.th. if you use the; purity information in the nodes.; --> hence I don't call it automatically in the tree building. Double_t PruneTree(TMVA::DecisionTree::EventList* validationSample = NULL); prune (get rid of internal nodes) the Decision tree to avoid overtraining; serveral different pruning methods can be applied as selected by the; variable ""fPruneMethod"". void ApplyValidationSample(const TMVA::DecisionTree::EventList* validationSample) const; run the validation sample through the (pruned) tree and fill in the nodes; the variables NSValidation and NBValidadtion (i.e. how many of the Signal; and Background events from the validation sample. This is then later used; when asking for the ""tree quality"" .. Double_t TestPrunedTreeQuality(const TMVA::DecisionTreeNode* dt = NULL, Int_t mode = 0) const; return the misclassification rate of a pruned tree; a ""pruned tree"" may have set the variable ""IsTerminal"" to ""arbitrary"" at; any node, hence this tree quality testing will stop there, hence test; the pruned tree (while the full tree is still in place for normal/later use). void CheckEventWithPrunedTree(const TMVA::Event& ) const; pass a single validation event throught a pruned decision tree; on the way down the tree, fill in all the ""intermediate"" information; that would normally be there from training. Double_t GetSumWeights(const TMVA::DecisionTree::EventList* validationSample) const; calculate the normalization factor for a pruning validation sam",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:11100,Security,validat,validation,11100,"TMVA::DecisionTreeNode* node); fill the existing the decision tree structure by filling event; in from the top node and see where they happen to end up. void ClearTree(); clear the tree nodes (their S/N, Nevents etc), just keep the structure of the tree. UInt_t CleanTree(TMVA::DecisionTreeNode* node = NULL); remove those last splits that result in two leaf nodes that; are both of the type (i.e. both signal or both background); this of course is only a reasonable thing to do when you use; ""YesOrNo"" leafs, while it might loose s.th. if you use the; purity information in the nodes.; --> hence I don't call it automatically in the tree building. Double_t PruneTree(TMVA::DecisionTree::EventList* validationSample = NULL); prune (get rid of internal nodes) the Decision tree to avoid overtraining; serveral different pruning methods can be applied as selected by the; variable ""fPruneMethod"". void ApplyValidationSample(const TMVA::DecisionTree::EventList* validationSample) const; run the validation sample through the (pruned) tree and fill in the nodes; the variables NSValidation and NBValidadtion (i.e. how many of the Signal; and Background events from the validation sample. This is then later used; when asking for the ""tree quality"" .. Double_t TestPrunedTreeQuality(const TMVA::DecisionTreeNode* dt = NULL, Int_t mode = 0) const; return the misclassification rate of a pruned tree; a ""pruned tree"" may have set the variable ""IsTerminal"" to ""arbitrary"" at; any node, hence this tree quality testing will stop there, hence test; the pruned tree (while the full tree is still in place for normal/later use). void CheckEventWithPrunedTree(const TMVA::Event& ) const; pass a single validation event throught a pruned decision tree; on the way down the tree, fill in all the ""intermediate"" information; that would normally be there from training. Double_t GetSumWeights(const TMVA::DecisionTree::EventList* validationSample) const; calculate the normalization factor for a pruning validation sam",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:11273,Security,validat,validation,11273,"nd up. void ClearTree(); clear the tree nodes (their S/N, Nevents etc), just keep the structure of the tree. UInt_t CleanTree(TMVA::DecisionTreeNode* node = NULL); remove those last splits that result in two leaf nodes that; are both of the type (i.e. both signal or both background); this of course is only a reasonable thing to do when you use; ""YesOrNo"" leafs, while it might loose s.th. if you use the; purity information in the nodes.; --> hence I don't call it automatically in the tree building. Double_t PruneTree(TMVA::DecisionTree::EventList* validationSample = NULL); prune (get rid of internal nodes) the Decision tree to avoid overtraining; serveral different pruning methods can be applied as selected by the; variable ""fPruneMethod"". void ApplyValidationSample(const TMVA::DecisionTree::EventList* validationSample) const; run the validation sample through the (pruned) tree and fill in the nodes; the variables NSValidation and NBValidadtion (i.e. how many of the Signal; and Background events from the validation sample. This is then later used; when asking for the ""tree quality"" .. Double_t TestPrunedTreeQuality(const TMVA::DecisionTreeNode* dt = NULL, Int_t mode = 0) const; return the misclassification rate of a pruned tree; a ""pruned tree"" may have set the variable ""IsTerminal"" to ""arbitrary"" at; any node, hence this tree quality testing will stop there, hence test; the pruned tree (while the full tree is still in place for normal/later use). void CheckEventWithPrunedTree(const TMVA::Event& ) const; pass a single validation event throught a pruned decision tree; on the way down the tree, fill in all the ""intermediate"" information; that would normally be there from training. Double_t GetSumWeights(const TMVA::DecisionTree::EventList* validationSample) const; calculate the normalization factor for a pruning validation sample. UInt_t CountLeafNodes(TMVA::Node* n = NULL); return the number of terminal nodes in the sub-tree below Node n. void DescendTree(TMVA::Node* ",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:11797,Security,validat,validation,11797,"t rid of internal nodes) the Decision tree to avoid overtraining; serveral different pruning methods can be applied as selected by the; variable ""fPruneMethod"". void ApplyValidationSample(const TMVA::DecisionTree::EventList* validationSample) const; run the validation sample through the (pruned) tree and fill in the nodes; the variables NSValidation and NBValidadtion (i.e. how many of the Signal; and Background events from the validation sample. This is then later used; when asking for the ""tree quality"" .. Double_t TestPrunedTreeQuality(const TMVA::DecisionTreeNode* dt = NULL, Int_t mode = 0) const; return the misclassification rate of a pruned tree; a ""pruned tree"" may have set the variable ""IsTerminal"" to ""arbitrary"" at; any node, hence this tree quality testing will stop there, hence test; the pruned tree (while the full tree is still in place for normal/later use). void CheckEventWithPrunedTree(const TMVA::Event& ) const; pass a single validation event throught a pruned decision tree; on the way down the tree, fill in all the ""intermediate"" information; that would normally be there from training. Double_t GetSumWeights(const TMVA::DecisionTree::EventList* validationSample) const; calculate the normalization factor for a pruning validation sample. UInt_t CountLeafNodes(TMVA::Node* n = NULL); return the number of terminal nodes in the sub-tree below Node n. void DescendTree(TMVA::Node* n = NULL); descend a tree to find all its leaf nodes. void PruneNode(TMVA::DecisionTreeNode* node); prune away the subtree below the node. void PruneNodeInPlace(TMVA::DecisionTreeNode* node); prune a node temporaily (without actually deleting its decendants; which allows testing the pruned tree quality for many different; pruning stages without ""touching"" the tree. TMVA::Node* GetNode(ULong_t sequence, UInt_t depth); retrieve node from the tree. Its position (up to a maximal tree depth of 64); is coded as a sequence of left-right moves starting from the root, coded as; 0-1 bit patt",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:12021,Security,validat,validationSample,12021,"TMVA::DecisionTree::EventList* validationSample) const; run the validation sample through the (pruned) tree and fill in the nodes; the variables NSValidation and NBValidadtion (i.e. how many of the Signal; and Background events from the validation sample. This is then later used; when asking for the ""tree quality"" .. Double_t TestPrunedTreeQuality(const TMVA::DecisionTreeNode* dt = NULL, Int_t mode = 0) const; return the misclassification rate of a pruned tree; a ""pruned tree"" may have set the variable ""IsTerminal"" to ""arbitrary"" at; any node, hence this tree quality testing will stop there, hence test; the pruned tree (while the full tree is still in place for normal/later use). void CheckEventWithPrunedTree(const TMVA::Event& ) const; pass a single validation event throught a pruned decision tree; on the way down the tree, fill in all the ""intermediate"" information; that would normally be there from training. Double_t GetSumWeights(const TMVA::DecisionTree::EventList* validationSample) const; calculate the normalization factor for a pruning validation sample. UInt_t CountLeafNodes(TMVA::Node* n = NULL); return the number of terminal nodes in the sub-tree below Node n. void DescendTree(TMVA::Node* n = NULL); descend a tree to find all its leaf nodes. void PruneNode(TMVA::DecisionTreeNode* node); prune away the subtree below the node. void PruneNodeInPlace(TMVA::DecisionTreeNode* node); prune a node temporaily (without actually deleting its decendants; which allows testing the pruned tree quality for many different; pruning stages without ""touching"" the tree. TMVA::Node* GetNode(ULong_t sequence, UInt_t depth); retrieve node from the tree. Its position (up to a maximal tree depth of 64); is coded as a sequence of left-right moves starting from the root, coded as; 0-1 bit patterns stored in the ""long-integer"" (i.e. 0:left ; 1:right. void GetRandomisedVariables(Bool_t* useVariable, UInt_t* variableMap, UInt_t& nVars). Double_t TrainNodeFast(const TMVA::DecisionTree::Ev",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:12095,Security,validat,validation,12095,"TMVA::DecisionTree::EventList* validationSample) const; run the validation sample through the (pruned) tree and fill in the nodes; the variables NSValidation and NBValidadtion (i.e. how many of the Signal; and Background events from the validation sample. This is then later used; when asking for the ""tree quality"" .. Double_t TestPrunedTreeQuality(const TMVA::DecisionTreeNode* dt = NULL, Int_t mode = 0) const; return the misclassification rate of a pruned tree; a ""pruned tree"" may have set the variable ""IsTerminal"" to ""arbitrary"" at; any node, hence this tree quality testing will stop there, hence test; the pruned tree (while the full tree is still in place for normal/later use). void CheckEventWithPrunedTree(const TMVA::Event& ) const; pass a single validation event throught a pruned decision tree; on the way down the tree, fill in all the ""intermediate"" information; that would normally be there from training. Double_t GetSumWeights(const TMVA::DecisionTree::EventList* validationSample) const; calculate the normalization factor for a pruning validation sample. UInt_t CountLeafNodes(TMVA::Node* n = NULL); return the number of terminal nodes in the sub-tree below Node n. void DescendTree(TMVA::Node* n = NULL); descend a tree to find all its leaf nodes. void PruneNode(TMVA::DecisionTreeNode* node); prune away the subtree below the node. void PruneNodeInPlace(TMVA::DecisionTreeNode* node); prune a node temporaily (without actually deleting its decendants; which allows testing the pruned tree quality for many different; pruning stages without ""touching"" the tree. TMVA::Node* GetNode(ULong_t sequence, UInt_t depth); retrieve node from the tree. Its position (up to a maximal tree depth of 64); is coded as a sequence of left-right moves starting from the root, coded as; 0-1 bit patterns stored in the ""long-integer"" (i.e. 0:left ; 1:right. void GetRandomisedVariables(Bool_t* useVariable, UInt_t* variableMap, UInt_t& nVars). Double_t TrainNodeFast(const TMVA::DecisionTree::Ev",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:6297,Testability,log,logger,6297," voidSetUseFisherCuts(Bool_t t = kTRUE); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); Double_tTestPrunedTreeQuality(const TMVA::DecisionTreeNode* dt = NULL, Int_t mode = 0) const; Double_tTrainNode(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node); Double_tTrainNodeFast(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node); Double_tTrainNodeFull(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node). protected:. voidTMVA::BinaryTree::DeleteNode(TMVA::Node*); TMVA::MsgLogger&TMVA::BinaryTree::Log() const. private:. Double_tSamplePurity(TMVA::DecisionTree::EventList eventSample). Data Members; public:. enum EPruneMethod { kExpectedErrorPruning; kCostComplexityPruning; kNoPruning; };. protected:. UInt_tTMVA::BinaryTree::fDepthmaximal depth in tree reached; UInt_tTMVA::BinaryTree::fNNodestotal number of nodes in the tree (counted); TMVA::Node*TMVA::BinaryTree::fRootthe root node of the tree; static TMVA::MsgLogger*TMVA::BinaryTree::fgLoggermessage logger, static to save resources . private:. TMVA::Types::EAnalysisTypefAnalysisTypekClassification(=0=false) or kRegression(=1=true); UInt_tfMaxDepthmax depth; Double_tfMinLinCorrForFisherthe minimum linear correlation between two variables demanded for use in fisher criterium in node splitting; Double_tfMinSepGainmin number of separation gain to perform node splitting; Double_tfMinSizemin number of events in node; TRandom3*fMyTrandomrandom number generator for randomised trees; Int_tfNCutsnumber of grid point in variable cut scans; UInt_tfNNodesMaxmax # of nodes; Double_tfNodePurityLimitpurity limit to decide whether a node is signal; UInt_tfNvarsnumber of variables used to separate S and B; Bool_tfPairNegWeightsInNoderandomly pair miscl. ev. with neg. and pos. weights in node and don't boost them; TMVA::DecisionTree::EPruneMethodfPruneMethodmethod used for prunig ; Double_t",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:11610,Testability,test,testing,11610,"this of course is only a reasonable thing to do when you use; ""YesOrNo"" leafs, while it might loose s.th. if you use the; purity information in the nodes.; --> hence I don't call it automatically in the tree building. Double_t PruneTree(TMVA::DecisionTree::EventList* validationSample = NULL); prune (get rid of internal nodes) the Decision tree to avoid overtraining; serveral different pruning methods can be applied as selected by the; variable ""fPruneMethod"". void ApplyValidationSample(const TMVA::DecisionTree::EventList* validationSample) const; run the validation sample through the (pruned) tree and fill in the nodes; the variables NSValidation and NBValidadtion (i.e. how many of the Signal; and Background events from the validation sample. This is then later used; when asking for the ""tree quality"" .. Double_t TestPrunedTreeQuality(const TMVA::DecisionTreeNode* dt = NULL, Int_t mode = 0) const; return the misclassification rate of a pruned tree; a ""pruned tree"" may have set the variable ""IsTerminal"" to ""arbitrary"" at; any node, hence this tree quality testing will stop there, hence test; the pruned tree (while the full tree is still in place for normal/later use). void CheckEventWithPrunedTree(const TMVA::Event& ) const; pass a single validation event throught a pruned decision tree; on the way down the tree, fill in all the ""intermediate"" information; that would normally be there from training. Double_t GetSumWeights(const TMVA::DecisionTree::EventList* validationSample) const; calculate the normalization factor for a pruning validation sample. UInt_t CountLeafNodes(TMVA::Node* n = NULL); return the number of terminal nodes in the sub-tree below Node n. void DescendTree(TMVA::Node* n = NULL); descend a tree to find all its leaf nodes. void PruneNode(TMVA::DecisionTreeNode* node); prune away the subtree below the node. void PruneNodeInPlace(TMVA::DecisionTreeNode* node); prune a node temporaily (without actually deleting its decendants; which allows testing the p",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:11641,Testability,test,test,11641,"this of course is only a reasonable thing to do when you use; ""YesOrNo"" leafs, while it might loose s.th. if you use the; purity information in the nodes.; --> hence I don't call it automatically in the tree building. Double_t PruneTree(TMVA::DecisionTree::EventList* validationSample = NULL); prune (get rid of internal nodes) the Decision tree to avoid overtraining; serveral different pruning methods can be applied as selected by the; variable ""fPruneMethod"". void ApplyValidationSample(const TMVA::DecisionTree::EventList* validationSample) const; run the validation sample through the (pruned) tree and fill in the nodes; the variables NSValidation and NBValidadtion (i.e. how many of the Signal; and Background events from the validation sample. This is then later used; when asking for the ""tree quality"" .. Double_t TestPrunedTreeQuality(const TMVA::DecisionTreeNode* dt = NULL, Int_t mode = 0) const; return the misclassification rate of a pruned tree; a ""pruned tree"" may have set the variable ""IsTerminal"" to ""arbitrary"" at; any node, hence this tree quality testing will stop there, hence test; the pruned tree (while the full tree is still in place for normal/later use). void CheckEventWithPrunedTree(const TMVA::Event& ) const; pass a single validation event throught a pruned decision tree; on the way down the tree, fill in all the ""intermediate"" information; that would normally be there from training. Double_t GetSumWeights(const TMVA::DecisionTree::EventList* validationSample) const; calculate the normalization factor for a pruning validation sample. UInt_t CountLeafNodes(TMVA::Node* n = NULL); return the number of terminal nodes in the sub-tree below Node n. void DescendTree(TMVA::Node* n = NULL); descend a tree to find all its leaf nodes. void PruneNode(TMVA::DecisionTreeNode* node); prune away the subtree below the node. void PruneNodeInPlace(TMVA::DecisionTreeNode* node); prune a node temporaily (without actually deleting its decendants; which allows testing the p",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:12526,Testability,test,testing,12526,"runed tree"" may have set the variable ""IsTerminal"" to ""arbitrary"" at; any node, hence this tree quality testing will stop there, hence test; the pruned tree (while the full tree is still in place for normal/later use). void CheckEventWithPrunedTree(const TMVA::Event& ) const; pass a single validation event throught a pruned decision tree; on the way down the tree, fill in all the ""intermediate"" information; that would normally be there from training. Double_t GetSumWeights(const TMVA::DecisionTree::EventList* validationSample) const; calculate the normalization factor for a pruning validation sample. UInt_t CountLeafNodes(TMVA::Node* n = NULL); return the number of terminal nodes in the sub-tree below Node n. void DescendTree(TMVA::Node* n = NULL); descend a tree to find all its leaf nodes. void PruneNode(TMVA::DecisionTreeNode* node); prune away the subtree below the node. void PruneNodeInPlace(TMVA::DecisionTreeNode* node); prune a node temporaily (without actually deleting its decendants; which allows testing the pruned tree quality for many different; pruning stages without ""touching"" the tree. TMVA::Node* GetNode(ULong_t sequence, UInt_t depth); retrieve node from the tree. Its position (up to a maximal tree depth of 64); is coded as a sequence of left-right moves starting from the root, coded as; 0-1 bit patterns stored in the ""long-integer"" (i.e. 0:left ; 1:right. void GetRandomisedVariables(Bool_t* useVariable, UInt_t* variableMap, UInt_t& nVars). Double_t TrainNodeFast(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node); Decide how to split a node using one of the variables that gives; the best separation of signal/background. In order to do this, for each; variable a scan of the different cut values in a grid (grid = fNCuts) is; performed and the resulting separation gains are compared.; in addition to the individual variables, one can also ask for a fisher; discriminant being built out of (some) of the variables and used as a; p",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:8078,Usability,simpl,simple,8078," with neg. and pos. weights in node and don't boost them; TMVA::DecisionTree::EPruneMethodfPruneMethodmethod used for prunig ; Double_tfPruneStrengtha parameter to set the ""amount"" of pruning..needs to be adjusted ; Bool_tfRandomisedTreechoose at each node splitting a random set of variables ; TMVA::RegressionVariance*fRegTypethe separation crition used in Regression; TMVA::SeparationBase*fSepTypethe separation crition; UInt_tfSigClassclass which is treated as signal when building the tree; Int_tfTreeIDjust an ID number given to the tree.. makes debugging easier as tree knows who he is.; Bool_tfUseExclusiveVarsindividual variables already used in fisher criterium are not anymore analysed individually for node splitting; Bool_tfUseFisherCutsuse multivariate splits using the Fisher criterium; Int_tfUseNvarsthe number of variables used in randomised trees;; Bool_tfUsePoissonNvarsuse ""fUseNvars"" not as fixed number but as mean of a possion distr. in each split; Bool_tfUseSearchTreecut scan done with binary trees or simple event loop.; vector<Double_t>fVariableImportancethe relative importance of the different variables ; static const Int_tfgDebugLeveldebug level determining some printout/control plots etc.; static const Int_tfgRandomSeedset nonzero for debugging and zero for random seeds. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; DecisionTree(); default constructor using the GiniIndex as separation criterion,; no restrictions on minium number of events in a leave note or the; separation gain in the node splitting. DecisionTree(TMVA::SeparationBase* sepType, Int_t minSize, Int_t nCuts, UInt_t cls = 0, Bool_t randomisedTree = kFALSE, Int_t useNvars = 0, Bool_t usePoissonNvars = kFALSE, UInt_t nNodesMax = 999999, UInt_t nMaxDepth = 9999999, Int_t iSeed = fgRandomSeed, Float_t purityLimit = 0.5, Int_t treeID = 0); constructor specifying the separation type, the min number of; events in a no that is still subjected to further s",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:10279,Usability,clear,clear,10279,"odes. ~DecisionTree(); destructor. void SetParentTreeInNodes(TMVA::Node* n = NULL); descend a tree to find all its leaf nodes, fill max depth reached in the; tree at the same time. TMVA::DecisionTree* CreateFromXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); re-create a new tree (decision tree or search tree) from XML. UInt_t BuildTree(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node = NULL); building the decision tree by recursively calling the splitting of; one (root-) node into two daughter nodes (returns the number of nodes). void FillTree(TMVA::DecisionTree::EventList& eventSample); fill the existing the decision tree structure by filling event; in from the top node and see where they happen to end up. void FillEvent(TMVA::Event& event, TMVA::DecisionTreeNode* node); fill the existing the decision tree structure by filling event; in from the top node and see where they happen to end up. void ClearTree(); clear the tree nodes (their S/N, Nevents etc), just keep the structure of the tree. UInt_t CleanTree(TMVA::DecisionTreeNode* node = NULL); remove those last splits that result in two leaf nodes that; are both of the type (i.e. both signal or both background); this of course is only a reasonable thing to do when you use; ""YesOrNo"" leafs, while it might loose s.th. if you use the; purity information in the nodes.; --> hence I don't call it automatically in the tree building. Double_t PruneTree(TMVA::DecisionTree::EventList* validationSample = NULL); prune (get rid of internal nodes) the Decision tree to avoid overtraining; serveral different pruning methods can be applied as selected by the; variable ""fPruneMethod"". void ApplyValidationSample(const TMVA::DecisionTree::EventList* validationSample) const; run the validation sample through the (pruned) tree and fill in the nodes; the variables NSValidation and NBValidadtion (i.e. how many of the Signal; and Background events from the validation sample. This is then later ",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTreeNode.html:373,Modifiability,variab,variable,373,". TMVA::DecisionTreeNode. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::DecisionTreeNode. class TMVA::DecisionTreeNode: public TMVA::Node. Node for the Decision Tree. The node specifies ONE variable out of the given set of selection variable; that is used to split the sample which ""arrives"" at the node, into a left; (background-enhanced) and a right (signal-enhanced) sample. Function Members (Methods); public:. virtual~DecisionTreeNode(); virtual voidAddAttributesToNode(void* node) const; virtual voidAddContentToNode(stringstream& s) const; voidAddToSumTarget(Float_t t); voidAddToSumTarget2(Float_t t2); void*TMVA::Node::AddXMLTo(void* parent) const; static TClass*Class(); voidClearNodeAndAllDaughters(); Int_tTMVA::Node::CountMeAndAllDaughters() const; virtual TMVA::Node*CreateNode() const; TMVA::DecisionTreeNodeDecisionTreeNode(); TMVA::DecisionTreeNodeDecisionTreeNode(TMVA::Node* p, char pos); TMVA::DecisionTreeNodeDecisionTreeNode(const TMVA::DecisionTreeNode& n, TMVA::DecisionTreeNode* parent = NULL); Double_tGetAlpha() const; Double_tGetAlphaMinSubtree() const; Double_tGetCC() const; intTMVA::Node::GetCount(); Bool_tGetCutType() const; Float_tGetCutValue() const; UInt_tTMVA::Node::GetDepth() const; Double_tGetFisherCoeff(Int_t ivar) const; virtual TMVA::DecisionTreeNode*GetLeft() const; Float_tGetNBkgEvents() const; Float_tGetNBkgEvents_unweighted() const; Double_tGetNBValidation() const; Float_tGetNEvents() const; Float_tGetNEvents_unweighted() const; UInt_tGetNFisherCoeff() const; Double_tGetNodeR() const; Int_tGetNodeType() const; Float_tGetNSigEvents() const; Float_tGetNSigEvents_unweighted() const; Double_tGetNSValidation() const; Int_tGetNTerminal() const; virtual TMVA::DecisionTreeNode*GetParent() const; virtual TMVA::BinaryTree*TMVA::Node::GetParentTree() const; charTMVA::Nod",MatchSource.WIKI,root/html532/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTreeNode.html
https://root.cern/root/html532/TMVA__DecisionTreeNode.html:416,Modifiability,variab,variable,416,". TMVA::DecisionTreeNode. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::DecisionTreeNode. class TMVA::DecisionTreeNode: public TMVA::Node. Node for the Decision Tree. The node specifies ONE variable out of the given set of selection variable; that is used to split the sample which ""arrives"" at the node, into a left; (background-enhanced) and a right (signal-enhanced) sample. Function Members (Methods); public:. virtual~DecisionTreeNode(); virtual voidAddAttributesToNode(void* node) const; virtual voidAddContentToNode(stringstream& s) const; voidAddToSumTarget(Float_t t); voidAddToSumTarget2(Float_t t2); void*TMVA::Node::AddXMLTo(void* parent) const; static TClass*Class(); voidClearNodeAndAllDaughters(); Int_tTMVA::Node::CountMeAndAllDaughters() const; virtual TMVA::Node*CreateNode() const; TMVA::DecisionTreeNodeDecisionTreeNode(); TMVA::DecisionTreeNodeDecisionTreeNode(TMVA::Node* p, char pos); TMVA::DecisionTreeNodeDecisionTreeNode(const TMVA::DecisionTreeNode& n, TMVA::DecisionTreeNode* parent = NULL); Double_tGetAlpha() const; Double_tGetAlphaMinSubtree() const; Double_tGetCC() const; intTMVA::Node::GetCount(); Bool_tGetCutType() const; Float_tGetCutValue() const; UInt_tTMVA::Node::GetDepth() const; Double_tGetFisherCoeff(Int_t ivar) const; virtual TMVA::DecisionTreeNode*GetLeft() const; Float_tGetNBkgEvents() const; Float_tGetNBkgEvents_unweighted() const; Double_tGetNBValidation() const; Float_tGetNEvents() const; Float_tGetNEvents_unweighted() const; UInt_tGetNFisherCoeff() const; Double_tGetNodeR() const; Int_tGetNodeType() const; Float_tGetNSigEvents() const; Float_tGetNSigEvents_unweighted() const; Double_tGetNSValidation() const; Int_tGetNTerminal() const; virtual TMVA::DecisionTreeNode*GetParent() const; virtual TMVA::BinaryTree*TMVA::Node::GetParentTree() const; charTMVA::Nod",MatchSource.WIKI,root/html532/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTreeNode.html
https://root.cern/root/html532/TMVA__DecisionTreeNode.html:513,Modifiability,enhance,enhanced,513,". TMVA::DecisionTreeNode. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::DecisionTreeNode. class TMVA::DecisionTreeNode: public TMVA::Node. Node for the Decision Tree. The node specifies ONE variable out of the given set of selection variable; that is used to split the sample which ""arrives"" at the node, into a left; (background-enhanced) and a right (signal-enhanced) sample. Function Members (Methods); public:. virtual~DecisionTreeNode(); virtual voidAddAttributesToNode(void* node) const; virtual voidAddContentToNode(stringstream& s) const; voidAddToSumTarget(Float_t t); voidAddToSumTarget2(Float_t t2); void*TMVA::Node::AddXMLTo(void* parent) const; static TClass*Class(); voidClearNodeAndAllDaughters(); Int_tTMVA::Node::CountMeAndAllDaughters() const; virtual TMVA::Node*CreateNode() const; TMVA::DecisionTreeNodeDecisionTreeNode(); TMVA::DecisionTreeNodeDecisionTreeNode(TMVA::Node* p, char pos); TMVA::DecisionTreeNodeDecisionTreeNode(const TMVA::DecisionTreeNode& n, TMVA::DecisionTreeNode* parent = NULL); Double_tGetAlpha() const; Double_tGetAlphaMinSubtree() const; Double_tGetCC() const; intTMVA::Node::GetCount(); Bool_tGetCutType() const; Float_tGetCutValue() const; UInt_tTMVA::Node::GetDepth() const; Double_tGetFisherCoeff(Int_t ivar) const; virtual TMVA::DecisionTreeNode*GetLeft() const; Float_tGetNBkgEvents() const; Float_tGetNBkgEvents_unweighted() const; Double_tGetNBValidation() const; Float_tGetNEvents() const; Float_tGetNEvents_unweighted() const; UInt_tGetNFisherCoeff() const; Double_tGetNodeR() const; Int_tGetNodeType() const; Float_tGetNSigEvents() const; Float_tGetNSigEvents_unweighted() const; Double_tGetNSValidation() const; Int_tGetNTerminal() const; virtual TMVA::DecisionTreeNode*GetParent() const; virtual TMVA::BinaryTree*TMVA::Node::GetParentTree() const; charTMVA::Nod",MatchSource.WIKI,root/html532/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTreeNode.html
https://root.cern/root/html532/TMVA__DecisionTreeNode.html:543,Modifiability,enhance,enhanced,543,". TMVA::DecisionTreeNode. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::DecisionTreeNode. class TMVA::DecisionTreeNode: public TMVA::Node. Node for the Decision Tree. The node specifies ONE variable out of the given set of selection variable; that is used to split the sample which ""arrives"" at the node, into a left; (background-enhanced) and a right (signal-enhanced) sample. Function Members (Methods); public:. virtual~DecisionTreeNode(); virtual voidAddAttributesToNode(void* node) const; virtual voidAddContentToNode(stringstream& s) const; voidAddToSumTarget(Float_t t); voidAddToSumTarget2(Float_t t2); void*TMVA::Node::AddXMLTo(void* parent) const; static TClass*Class(); voidClearNodeAndAllDaughters(); Int_tTMVA::Node::CountMeAndAllDaughters() const; virtual TMVA::Node*CreateNode() const; TMVA::DecisionTreeNodeDecisionTreeNode(); TMVA::DecisionTreeNodeDecisionTreeNode(TMVA::Node* p, char pos); TMVA::DecisionTreeNodeDecisionTreeNode(const TMVA::DecisionTreeNode& n, TMVA::DecisionTreeNode* parent = NULL); Double_tGetAlpha() const; Double_tGetAlphaMinSubtree() const; Double_tGetCC() const; intTMVA::Node::GetCount(); Bool_tGetCutType() const; Float_tGetCutValue() const; UInt_tTMVA::Node::GetDepth() const; Double_tGetFisherCoeff(Int_t ivar) const; virtual TMVA::DecisionTreeNode*GetLeft() const; Float_tGetNBkgEvents() const; Float_tGetNBkgEvents_unweighted() const; Double_tGetNBValidation() const; Float_tGetNEvents() const; Float_tGetNEvents_unweighted() const; UInt_tGetNFisherCoeff() const; Double_tGetNodeR() const; Int_tGetNodeType() const; Float_tGetNSigEvents() const; Float_tGetNSigEvents_unweighted() const; Double_tGetNSValidation() const; Int_tGetNTerminal() const; virtual TMVA::DecisionTreeNode*GetParent() const; virtual TMVA::BinaryTree*TMVA::Node::GetParentTree() const; charTMVA::Nod",MatchSource.WIKI,root/html532/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTreeNode.html
https://root.cern/root/html532/TMVA__DecisionTreeNode.html:4712,Modifiability,variab,variable,4712,"ouble_t s); voidSetNTerminal(Int_t n); virtual voidSetParent(TMVA::Node* p); virtual voidTMVA::Node::SetParentTree(TMVA::BinaryTree* t); voidTMVA::Node::SetPos(char s); voidSetPurity(); voidSetResponse(Float_t r); virtual voidSetRight(TMVA::Node* r); voidSetRMS(Float_t r); voidSetSampleMax(UInt_t ivar, Float_t xmax); voidSetSampleMin(UInt_t ivar, Float_t xmin); voidSetSelector(Short_t i); voidSetSeparationGain(Float_t sep); voidSetSeparationIndex(Float_t sep); voidSetSubTreeR(Double_t r); voidSetSumTarget(Float_t t); voidSetSumTarget2(Float_t t2); voidSetTerminal(Bool_t s = kTRUE); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). private:. virtual voidReadAttributes(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); virtual voidReadContent(stringstream& s); virtual Bool_tReadDataRecord(istream& is, UInt_t tmva_Version_Code = TMVA_VERSION_CODE). Data Members; public:. static boolfgIsTrainingstatic variable to flag training phase in which we need fTrainInfo. protected:. Bool_tfCutTypetrue: if event variable > cutValue ==> signal , false otherwise; Float_tfCutValuecut value appplied on this node to discriminate bkg against sig; UInt_tTMVA::Node::fDepthdepth of the node within the tree (seen from root node); vector<Double_t>fFisherCoeffthe fisher coeff (offset at the last element); Bool_tfIsTerminalNode! flag to set node as terminal (i.e., without deleting its descendants); TMVA::Node*TMVA::Node::fLeftpointers to the two ""daughter"" nodes; Int_tfNodeTypeType of node: -1 == Bkg-leaf, 1 == Signal-leaf, 0 = internal; TMVA::Node*TMVA::Node::fParentthe previous (parent) node; TMVA::BinaryTree*TMVA::Node::fParentTreepointer to the parent tree to which the Node belongs ; charTMVA::Node::fPosposition, i.e. it is a left (l) or right (r) daughter ; Float_tfPuritythe node purity; Float_tfRMSresponse RMS of the regression node; Float_tfResponseresponse value in case of regression; TMVA::Node*TMVA::Node::fRigh",MatchSource.WIKI,root/html532/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTreeNode.html
https://root.cern/root/html532/TMVA__DecisionTreeNode.html:4814,Modifiability,variab,variable,4814,"e* r); voidSetRMS(Float_t r); voidSetSampleMax(UInt_t ivar, Float_t xmax); voidSetSampleMin(UInt_t ivar, Float_t xmin); voidSetSelector(Short_t i); voidSetSeparationGain(Float_t sep); voidSetSeparationIndex(Float_t sep); voidSetSubTreeR(Double_t r); voidSetSumTarget(Float_t t); voidSetSumTarget2(Float_t t2); voidSetTerminal(Bool_t s = kTRUE); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). private:. virtual voidReadAttributes(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); virtual voidReadContent(stringstream& s); virtual Bool_tReadDataRecord(istream& is, UInt_t tmva_Version_Code = TMVA_VERSION_CODE). Data Members; public:. static boolfgIsTrainingstatic variable to flag training phase in which we need fTrainInfo. protected:. Bool_tfCutTypetrue: if event variable > cutValue ==> signal , false otherwise; Float_tfCutValuecut value appplied on this node to discriminate bkg against sig; UInt_tTMVA::Node::fDepthdepth of the node within the tree (seen from root node); vector<Double_t>fFisherCoeffthe fisher coeff (offset at the last element); Bool_tfIsTerminalNode! flag to set node as terminal (i.e., without deleting its descendants); TMVA::Node*TMVA::Node::fLeftpointers to the two ""daughter"" nodes; Int_tfNodeTypeType of node: -1 == Bkg-leaf, 1 == Signal-leaf, 0 = internal; TMVA::Node*TMVA::Node::fParentthe previous (parent) node; TMVA::BinaryTree*TMVA::Node::fParentTreepointer to the parent tree to which the Node belongs ; charTMVA::Node::fPosposition, i.e. it is a left (l) or right (r) daughter ; Float_tfPuritythe node purity; Float_tfRMSresponse RMS of the regression node; Float_tfResponseresponse value in case of regression; TMVA::Node*TMVA::Node::fRightpointers to the two ""daughter"" nodes; Short_tfSelectorindex of variable used in node selection (decision tree); TMVA::DTNodeTrainingInfo*fTrainInfo; static TMVA::MsgLogger*fgLoggerstatic because there is a huge number of nodes... Class Charts",MatchSource.WIKI,root/html532/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTreeNode.html
https://root.cern/root/html532/TMVA__DecisionTreeNode.html:5791,Modifiability,variab,variable,5791,"hase in which we need fTrainInfo. protected:. Bool_tfCutTypetrue: if event variable > cutValue ==> signal , false otherwise; Float_tfCutValuecut value appplied on this node to discriminate bkg against sig; UInt_tTMVA::Node::fDepthdepth of the node within the tree (seen from root node); vector<Double_t>fFisherCoeffthe fisher coeff (offset at the last element); Bool_tfIsTerminalNode! flag to set node as terminal (i.e., without deleting its descendants); TMVA::Node*TMVA::Node::fLeftpointers to the two ""daughter"" nodes; Int_tfNodeTypeType of node: -1 == Bkg-leaf, 1 == Signal-leaf, 0 = internal; TMVA::Node*TMVA::Node::fParentthe previous (parent) node; TMVA::BinaryTree*TMVA::Node::fParentTreepointer to the parent tree to which the Node belongs ; charTMVA::Node::fPosposition, i.e. it is a left (l) or right (r) daughter ; Float_tfPuritythe node purity; Float_tfRMSresponse RMS of the regression node; Float_tfResponseresponse value in case of regression; TMVA::Node*TMVA::Node::fRightpointers to the two ""daughter"" nodes; Short_tfSelectorindex of variable used in node selection (decision tree); TMVA::DTNodeTrainingInfo*fTrainInfo; static TMVA::MsgLogger*fgLoggerstatic because there is a huge number of nodes... Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; DecisionTreeNode(); constructor of an essentially ""empty"" node floating in space. DecisionTreeNode(TMVA::Node* p, char pos); constructor of a daughter node as a daughter of 'p'. DecisionTreeNode(const TMVA::DecisionTreeNode& n, TMVA::DecisionTreeNode* parent = NULL); copy constructor of a node. It will result in an explicit copy of; the node and recursively all it's daughters. ~DecisionTreeNode(); destructor. Bool_t GoesRight(const TMVA::Event& ) const; test event if it decends the tree at this node to the right. Bool_t GoesLeft(const TMVA::Event& ) const; test event if it decends the tree at this node to the left. void SetPurity( void ); return the S/(S+B) (purity) for the node; RE",MatchSource.WIKI,root/html532/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTreeNode.html
https://root.cern/root/html532/TMVA__DecisionTreeNode.html:7656,Modifiability,variab,variable,7656,"to the left. void SetPurity( void ); return the S/(S+B) (purity) for the node; REM: even if nodes with purity 0.01 are very PURE background nodes, they still; get a small value of the purity. void Print(ostream& os) const; print the node. void PrintRec(ostream& os) const; recursively print the node and its daughters (--> print the 'tree'). Bool_t ReadDataRecord(istream& is, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); Read the data block. void ClearNodeAndAllDaughters(); clear the nodes (their S/N, Nevents etc), just keep the structure of the tree. void ResetValidationData(); temporary stored node values (number of events, etc.) that originate; not from the training but from the validation data (used in pruning). void PrintPrune(ostream& os) const; printout of the node (can be read in with ReadDataRecord). void PrintRecPrune(ostream& os) const; recursive printout of the node and its daughters. void SetCC(Double_t cc). Float_t GetSampleMin(UInt_t ivar) const; return the minimum of variable ivar from the training sample; that pass/end up in this node. Float_t GetSampleMax(UInt_t ivar) const; return the maximum of variable ivar from the training sample; that pass/end up in this node. void SetSampleMin(UInt_t ivar, Float_t xmin); set the minimum of variable ivar from the training sample; that pass/end up in this node. void SetSampleMax(UInt_t ivar, Float_t xmax); set the maximum of variable ivar from the training sample; that pass/end up in this node. void ReadAttributes(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE). void AddAttributesToNode(void* node) const; add attribute to xml. void SetFisherCoeff(Int_t ivar, Double_t coeff); set fisher coefficients. void AddContentToNode(stringstream& s) const; adding attributes to tree node (well, was used in BinarySearchTree,; and somehow I guess someone programmed it such that we need this in; this tree too, although we don't..). void ReadContent(stringstream& s); reading attributes from tree node (well, was used i",MatchSource.WIKI,root/html532/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTreeNode.html
https://root.cern/root/html532/TMVA__DecisionTreeNode.html:7790,Modifiability,variab,variable,7790,"round nodes, they still; get a small value of the purity. void Print(ostream& os) const; print the node. void PrintRec(ostream& os) const; recursively print the node and its daughters (--> print the 'tree'). Bool_t ReadDataRecord(istream& is, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); Read the data block. void ClearNodeAndAllDaughters(); clear the nodes (their S/N, Nevents etc), just keep the structure of the tree. void ResetValidationData(); temporary stored node values (number of events, etc.) that originate; not from the training but from the validation data (used in pruning). void PrintPrune(ostream& os) const; printout of the node (can be read in with ReadDataRecord). void PrintRecPrune(ostream& os) const; recursive printout of the node and its daughters. void SetCC(Double_t cc). Float_t GetSampleMin(UInt_t ivar) const; return the minimum of variable ivar from the training sample; that pass/end up in this node. Float_t GetSampleMax(UInt_t ivar) const; return the maximum of variable ivar from the training sample; that pass/end up in this node. void SetSampleMin(UInt_t ivar, Float_t xmin); set the minimum of variable ivar from the training sample; that pass/end up in this node. void SetSampleMax(UInt_t ivar, Float_t xmax); set the maximum of variable ivar from the training sample; that pass/end up in this node. void ReadAttributes(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE). void AddAttributesToNode(void* node) const; add attribute to xml. void SetFisherCoeff(Int_t ivar, Double_t coeff); set fisher coefficients. void AddContentToNode(stringstream& s) const; adding attributes to tree node (well, was used in BinarySearchTree,; and somehow I guess someone programmed it such that we need this in; this tree too, although we don't..). void ReadContent(stringstream& s); reading attributes from tree node (well, was used in BinarySearchTree,; and somehow I guess someone programmed it such that we need this in; this tree too, although we don't..). Node* C",MatchSource.WIKI,root/html532/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTreeNode.html
https://root.cern/root/html532/TMVA__DecisionTreeNode.html:7926,Modifiability,variab,variable,7926,"st; recursively print the node and its daughters (--> print the 'tree'). Bool_t ReadDataRecord(istream& is, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); Read the data block. void ClearNodeAndAllDaughters(); clear the nodes (their S/N, Nevents etc), just keep the structure of the tree. void ResetValidationData(); temporary stored node values (number of events, etc.) that originate; not from the training but from the validation data (used in pruning). void PrintPrune(ostream& os) const; printout of the node (can be read in with ReadDataRecord). void PrintRecPrune(ostream& os) const; recursive printout of the node and its daughters. void SetCC(Double_t cc). Float_t GetSampleMin(UInt_t ivar) const; return the minimum of variable ivar from the training sample; that pass/end up in this node. Float_t GetSampleMax(UInt_t ivar) const; return the maximum of variable ivar from the training sample; that pass/end up in this node. void SetSampleMin(UInt_t ivar, Float_t xmin); set the minimum of variable ivar from the training sample; that pass/end up in this node. void SetSampleMax(UInt_t ivar, Float_t xmax); set the maximum of variable ivar from the training sample; that pass/end up in this node. void ReadAttributes(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE). void AddAttributesToNode(void* node) const; add attribute to xml. void SetFisherCoeff(Int_t ivar, Double_t coeff); set fisher coefficients. void AddContentToNode(stringstream& s) const; adding attributes to tree node (well, was used in BinarySearchTree,; and somehow I guess someone programmed it such that we need this in; this tree too, although we don't..). void ReadContent(stringstream& s); reading attributes from tree node (well, was used in BinarySearchTree,; and somehow I guess someone programmed it such that we need this in; this tree too, although we don't..). Node* CreateNode() const; { return new DecisionTreeNode(); }. void SetNFisherCoeff(Int_t nvars); {fFisherCoeff.resize(nvars);}. UInt_t GetNFis",MatchSource.WIKI,root/html532/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTreeNode.html
https://root.cern/root/html532/TMVA__DecisionTreeNode.html:8062,Modifiability,variab,variable,8062,"MVA_VERSION_CODE); Read the data block. void ClearNodeAndAllDaughters(); clear the nodes (their S/N, Nevents etc), just keep the structure of the tree. void ResetValidationData(); temporary stored node values (number of events, etc.) that originate; not from the training but from the validation data (used in pruning). void PrintPrune(ostream& os) const; printout of the node (can be read in with ReadDataRecord). void PrintRecPrune(ostream& os) const; recursive printout of the node and its daughters. void SetCC(Double_t cc). Float_t GetSampleMin(UInt_t ivar) const; return the minimum of variable ivar from the training sample; that pass/end up in this node. Float_t GetSampleMax(UInt_t ivar) const; return the maximum of variable ivar from the training sample; that pass/end up in this node. void SetSampleMin(UInt_t ivar, Float_t xmin); set the minimum of variable ivar from the training sample; that pass/end up in this node. void SetSampleMax(UInt_t ivar, Float_t xmax); set the maximum of variable ivar from the training sample; that pass/end up in this node. void ReadAttributes(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE). void AddAttributesToNode(void* node) const; add attribute to xml. void SetFisherCoeff(Int_t ivar, Double_t coeff); set fisher coefficients. void AddContentToNode(stringstream& s) const; adding attributes to tree node (well, was used in BinarySearchTree,; and somehow I guess someone programmed it such that we need this in; this tree too, although we don't..). void ReadContent(stringstream& s); reading attributes from tree node (well, was used in BinarySearchTree,; and somehow I guess someone programmed it such that we need this in; this tree too, although we don't..). Node* CreateNode() const; { return new DecisionTreeNode(); }. void SetNFisherCoeff(Int_t nvars); {fFisherCoeff.resize(nvars);}. UInt_t GetNFisherCoeff() const; set fisher coefficients. { return fFisherCoeff.size();}. Double_t GetFisherCoeff(Int_t ivar) const; get fisher coeffic",MatchSource.WIKI,root/html532/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTreeNode.html
https://root.cern/root/html532/TMVA__DecisionTreeNode.html:9146,Modifiability,variab,variable,9146,"butes(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE). void AddAttributesToNode(void* node) const; add attribute to xml. void SetFisherCoeff(Int_t ivar, Double_t coeff); set fisher coefficients. void AddContentToNode(stringstream& s) const; adding attributes to tree node (well, was used in BinarySearchTree,; and somehow I guess someone programmed it such that we need this in; this tree too, although we don't..). void ReadContent(stringstream& s); reading attributes from tree node (well, was used in BinarySearchTree,; and somehow I guess someone programmed it such that we need this in; this tree too, although we don't..). Node* CreateNode() const; { return new DecisionTreeNode(); }. void SetNFisherCoeff(Int_t nvars); {fFisherCoeff.resize(nvars);}. UInt_t GetNFisherCoeff() const; set fisher coefficients. { return fFisherCoeff.size();}. Double_t GetFisherCoeff(Int_t ivar) const; get fisher coefficients. {return fFisherCoeff.at(ivar);}. void SetSelector(Short_t i); set index of variable used for discrimination at this node. { fSelector = i; }. Short_t GetSelector() const; return index of variable used for discrimination at this node. { return fSelector; }. void SetCutValue(Float_t c); set the cut value applied at this node. { fCutValue = c; }. Float_t GetCutValue( void ); return the cut value applied at this node. { return fCutValue; }. void SetCutType(Bool_t t); set true: if event variable > cutValue ==> signal , false otherwise. { fCutType = t; }. Bool_t GetCutType( void ); return kTRUE: Cuts select signal, kFALSE: Cuts select bkg. { return fCutType; }. void SetNodeType(Int_t t); set node type: 1 signal node, -1 bkg leave, 0 intermediate Node. { fNodeType = t;}. Int_t GetNodeType( void ); return node type: 1 signal node, -1 bkg leave, 0 intermediate Node. { return fNodeType; }. Float_t GetPurity( void ); return S/(S+B) (purity) at this node (from training). { return fPurity;}. void SetResponse(Float_t r); set the response of the node (for regression). { fResp",MatchSource.WIKI,root/html532/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTreeNode.html
https://root.cern/root/html532/TMVA__DecisionTreeNode.html:9258,Modifiability,variab,variable,9258,"d attribute to xml. void SetFisherCoeff(Int_t ivar, Double_t coeff); set fisher coefficients. void AddContentToNode(stringstream& s) const; adding attributes to tree node (well, was used in BinarySearchTree,; and somehow I guess someone programmed it such that we need this in; this tree too, although we don't..). void ReadContent(stringstream& s); reading attributes from tree node (well, was used in BinarySearchTree,; and somehow I guess someone programmed it such that we need this in; this tree too, although we don't..). Node* CreateNode() const; { return new DecisionTreeNode(); }. void SetNFisherCoeff(Int_t nvars); {fFisherCoeff.resize(nvars);}. UInt_t GetNFisherCoeff() const; set fisher coefficients. { return fFisherCoeff.size();}. Double_t GetFisherCoeff(Int_t ivar) const; get fisher coefficients. {return fFisherCoeff.at(ivar);}. void SetSelector(Short_t i); set index of variable used for discrimination at this node. { fSelector = i; }. Short_t GetSelector() const; return index of variable used for discrimination at this node. { return fSelector; }. void SetCutValue(Float_t c); set the cut value applied at this node. { fCutValue = c; }. Float_t GetCutValue( void ); return the cut value applied at this node. { return fCutValue; }. void SetCutType(Bool_t t); set true: if event variable > cutValue ==> signal , false otherwise. { fCutType = t; }. Bool_t GetCutType( void ); return kTRUE: Cuts select signal, kFALSE: Cuts select bkg. { return fCutType; }. void SetNodeType(Int_t t); set node type: 1 signal node, -1 bkg leave, 0 intermediate Node. { fNodeType = t;}. Int_t GetNodeType( void ); return node type: 1 signal node, -1 bkg leave, 0 intermediate Node. { return fNodeType; }. Float_t GetPurity( void ); return S/(S+B) (purity) at this node (from training). { return fPurity;}. void SetResponse(Float_t r); set the response of the node (for regression). { fResponse = r;}. Float_t GetResponse( void ); return the response of the node (for regression). { return fResponse;",MatchSource.WIKI,root/html532/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTreeNode.html
https://root.cern/root/html532/TMVA__DecisionTreeNode.html:9558,Modifiability,variab,variable,9558," we don't..). void ReadContent(stringstream& s); reading attributes from tree node (well, was used in BinarySearchTree,; and somehow I guess someone programmed it such that we need this in; this tree too, although we don't..). Node* CreateNode() const; { return new DecisionTreeNode(); }. void SetNFisherCoeff(Int_t nvars); {fFisherCoeff.resize(nvars);}. UInt_t GetNFisherCoeff() const; set fisher coefficients. { return fFisherCoeff.size();}. Double_t GetFisherCoeff(Int_t ivar) const; get fisher coefficients. {return fFisherCoeff.at(ivar);}. void SetSelector(Short_t i); set index of variable used for discrimination at this node. { fSelector = i; }. Short_t GetSelector() const; return index of variable used for discrimination at this node. { return fSelector; }. void SetCutValue(Float_t c); set the cut value applied at this node. { fCutValue = c; }. Float_t GetCutValue( void ); return the cut value applied at this node. { return fCutValue; }. void SetCutType(Bool_t t); set true: if event variable > cutValue ==> signal , false otherwise. { fCutType = t; }. Bool_t GetCutType( void ); return kTRUE: Cuts select signal, kFALSE: Cuts select bkg. { return fCutType; }. void SetNodeType(Int_t t); set node type: 1 signal node, -1 bkg leave, 0 intermediate Node. { fNodeType = t;}. Int_t GetNodeType( void ); return node type: 1 signal node, -1 bkg leave, 0 intermediate Node. { return fNodeType; }. Float_t GetPurity( void ); return S/(S+B) (purity) at this node (from training). { return fPurity;}. void SetResponse(Float_t r); set the response of the node (for regression). { fResponse = r;}. Float_t GetResponse( void ); return the response of the node (for regression). { return fResponse;}. void SetRMS(Float_t r); set the RMS of the response of the node (for regression). { fRMS = r;}. Float_t GetRMS( void ); return the RMS of the response of the node (for regression). { return fRMS;}. void SetNSigEvents(Float_t s); set the sum of the signal weights in the node. { fTrainInfo->fNSigEve",MatchSource.WIKI,root/html532/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTreeNode.html
https://root.cern/root/html532/TMVA__DecisionTreeNode.html:7349,Security,validat,validation,7349,"node. It will result in an explicit copy of; the node and recursively all it's daughters. ~DecisionTreeNode(); destructor. Bool_t GoesRight(const TMVA::Event& ) const; test event if it decends the tree at this node to the right. Bool_t GoesLeft(const TMVA::Event& ) const; test event if it decends the tree at this node to the left. void SetPurity( void ); return the S/(S+B) (purity) for the node; REM: even if nodes with purity 0.01 are very PURE background nodes, they still; get a small value of the purity. void Print(ostream& os) const; print the node. void PrintRec(ostream& os) const; recursively print the node and its daughters (--> print the 'tree'). Bool_t ReadDataRecord(istream& is, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); Read the data block. void ClearNodeAndAllDaughters(); clear the nodes (their S/N, Nevents etc), just keep the structure of the tree. void ResetValidationData(); temporary stored node values (number of events, etc.) that originate; not from the training but from the validation data (used in pruning). void PrintPrune(ostream& os) const; printout of the node (can be read in with ReadDataRecord). void PrintRecPrune(ostream& os) const; recursive printout of the node and its daughters. void SetCC(Double_t cc). Float_t GetSampleMin(UInt_t ivar) const; return the minimum of variable ivar from the training sample; that pass/end up in this node. Float_t GetSampleMax(UInt_t ivar) const; return the maximum of variable ivar from the training sample; that pass/end up in this node. void SetSampleMin(UInt_t ivar, Float_t xmin); set the minimum of variable ivar from the training sample; that pass/end up in this node. void SetSampleMax(UInt_t ivar, Float_t xmax); set the maximum of variable ivar from the training sample; that pass/end up in this node. void ReadAttributes(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE). void AddAttributesToNode(void* node) const; add attribute to xml. void SetFisherCoeff(Int_t ivar, Double_t coeff); set fisher co",MatchSource.WIKI,root/html532/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTreeNode.html
https://root.cern/root/html532/TMVA__DecisionTreeNode.html:15154,Security,validat,validation,15154,"ionTreeNode*>(p);}. void SetNodeR(Double_t r); the node resubstitution estimate, R(t), for Cost Complexity pruning. { fTrainInfo->fNodeR = r; }. Double_t GetNodeR() const; { return fTrainInfo->fNodeR; }. void SetSubTreeR(Double_t r); the resubstitution estimate, R(T_t), of the tree rooted at this node. { fTrainInfo->fSubTreeR = r; }. Double_t GetSubTreeR() const; { return fTrainInfo->fSubTreeR; }. void SetAlpha(Double_t alpha); R(t) - R(T_t); the critical point alpha = -------------; |~T_t| - 1. { fTrainInfo->fAlpha = alpha; }. Double_t GetAlpha() const; { return fTrainInfo->fAlpha; }. void SetAlphaMinSubtree(Double_t g); the minimum alpha in the tree rooted at this node. { fTrainInfo->fG = g; }. Double_t GetAlphaMinSubtree() const; { return fTrainInfo->fG; }. void SetNTerminal(Int_t n); number of terminal nodes in the subtree rooted here. { fTrainInfo->fNTerminal = n; }. Int_t GetNTerminal() const; { return fTrainInfo->fNTerminal; }. void SetNBValidation(Double_t b); number of background/signal events from the pruning validation sample. { fTrainInfo->fNB = b; }. void SetNSValidation(Double_t s); { fTrainInfo->fNS = s; }. Double_t GetNBValidation() const; { return fTrainInfo->fNB; }. Double_t GetNSValidation() const; { return fTrainInfo->fNS; }. void SetSumTarget(Float_t t); {fTrainInfo->fSumTarget = t; }. void SetSumTarget2(Float_t t2); {fTrainInfo->fSumTarget2 = t2; }. void AddToSumTarget(Float_t t); {fTrainInfo->fSumTarget += t; }. void AddToSumTarget2(Float_t t2); {fTrainInfo->fSumTarget2 += t2; }. Float_t GetSumTarget() const; {return fTrainInfo? fTrainInfo->fSumTarget : -9999;}. Float_t GetSumTarget2() const; {return fTrainInfo? fTrainInfo->fSumTarget2: -9999;}. Bool_t IsTerminal() const; flag indicates whether this node is terminal. { return fIsTerminalNode; }. void SetTerminal(Bool_t s = kTRUE); { fIsTerminalNode = s; }. Double_t GetCC() const; {return (fTrainInfo? fTrainInfo->fCC : -1.);}. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss, Eckha",MatchSource.WIKI,root/html532/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTreeNode.html
https://root.cern/root/html532/TMVA__DecisionTreeNode.html:6507,Testability,test,test,6507,"tion, i.e. it is a left (l) or right (r) daughter ; Float_tfPuritythe node purity; Float_tfRMSresponse RMS of the regression node; Float_tfResponseresponse value in case of regression; TMVA::Node*TMVA::Node::fRightpointers to the two ""daughter"" nodes; Short_tfSelectorindex of variable used in node selection (decision tree); TMVA::DTNodeTrainingInfo*fTrainInfo; static TMVA::MsgLogger*fgLoggerstatic because there is a huge number of nodes... Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; DecisionTreeNode(); constructor of an essentially ""empty"" node floating in space. DecisionTreeNode(TMVA::Node* p, char pos); constructor of a daughter node as a daughter of 'p'. DecisionTreeNode(const TMVA::DecisionTreeNode& n, TMVA::DecisionTreeNode* parent = NULL); copy constructor of a node. It will result in an explicit copy of; the node and recursively all it's daughters. ~DecisionTreeNode(); destructor. Bool_t GoesRight(const TMVA::Event& ) const; test event if it decends the tree at this node to the right. Bool_t GoesLeft(const TMVA::Event& ) const; test event if it decends the tree at this node to the left. void SetPurity( void ); return the S/(S+B) (purity) for the node; REM: even if nodes with purity 0.01 are very PURE background nodes, they still; get a small value of the purity. void Print(ostream& os) const; print the node. void PrintRec(ostream& os) const; recursively print the node and its daughters (--> print the 'tree'). Bool_t ReadDataRecord(istream& is, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); Read the data block. void ClearNodeAndAllDaughters(); clear the nodes (their S/N, Nevents etc), just keep the structure of the tree. void ResetValidationData(); temporary stored node values (number of events, etc.) that originate; not from the training but from the validation data (used in pruning). void PrintPrune(ostream& os) const; printout of the node (can be read in with ReadDataRecord). void PrintRecPrune(ostream& os) con",MatchSource.WIKI,root/html532/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTreeNode.html
https://root.cern/root/html532/TMVA__DecisionTreeNode.html:6612,Testability,test,test,6612,"S of the regression node; Float_tfResponseresponse value in case of regression; TMVA::Node*TMVA::Node::fRightpointers to the two ""daughter"" nodes; Short_tfSelectorindex of variable used in node selection (decision tree); TMVA::DTNodeTrainingInfo*fTrainInfo; static TMVA::MsgLogger*fgLoggerstatic because there is a huge number of nodes... Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; DecisionTreeNode(); constructor of an essentially ""empty"" node floating in space. DecisionTreeNode(TMVA::Node* p, char pos); constructor of a daughter node as a daughter of 'p'. DecisionTreeNode(const TMVA::DecisionTreeNode& n, TMVA::DecisionTreeNode* parent = NULL); copy constructor of a node. It will result in an explicit copy of; the node and recursively all it's daughters. ~DecisionTreeNode(); destructor. Bool_t GoesRight(const TMVA::Event& ) const; test event if it decends the tree at this node to the right. Bool_t GoesLeft(const TMVA::Event& ) const; test event if it decends the tree at this node to the left. void SetPurity( void ); return the S/(S+B) (purity) for the node; REM: even if nodes with purity 0.01 are very PURE background nodes, they still; get a small value of the purity. void Print(ostream& os) const; print the node. void PrintRec(ostream& os) const; recursively print the node and its daughters (--> print the 'tree'). Bool_t ReadDataRecord(istream& is, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); Read the data block. void ClearNodeAndAllDaughters(); clear the nodes (their S/N, Nevents etc), just keep the structure of the tree. void ResetValidationData(); temporary stored node values (number of events, etc.) that originate; not from the training but from the validation data (used in pruning). void PrintPrune(ostream& os) const; printout of the node (can be read in with ReadDataRecord). void PrintRecPrune(ostream& os) const; recursive printout of the node and its daughters. void SetCC(Double_t cc). Float_t GetSampleMin(UInt_",MatchSource.WIKI,root/html532/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTreeNode.html
https://root.cern/root/html532/TMVA__DecisionTreeNode.html:7137,Usability,clear,clear,7137," p, char pos); constructor of a daughter node as a daughter of 'p'. DecisionTreeNode(const TMVA::DecisionTreeNode& n, TMVA::DecisionTreeNode* parent = NULL); copy constructor of a node. It will result in an explicit copy of; the node and recursively all it's daughters. ~DecisionTreeNode(); destructor. Bool_t GoesRight(const TMVA::Event& ) const; test event if it decends the tree at this node to the right. Bool_t GoesLeft(const TMVA::Event& ) const; test event if it decends the tree at this node to the left. void SetPurity( void ); return the S/(S+B) (purity) for the node; REM: even if nodes with purity 0.01 are very PURE background nodes, they still; get a small value of the purity. void Print(ostream& os) const; print the node. void PrintRec(ostream& os) const; recursively print the node and its daughters (--> print the 'tree'). Bool_t ReadDataRecord(istream& is, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); Read the data block. void ClearNodeAndAllDaughters(); clear the nodes (their S/N, Nevents etc), just keep the structure of the tree. void ResetValidationData(); temporary stored node values (number of events, etc.) that originate; not from the training but from the validation data (used in pruning). void PrintPrune(ostream& os) const; printout of the node (can be read in with ReadDataRecord). void PrintRecPrune(ostream& os) const; recursive printout of the node and its daughters. void SetCC(Double_t cc). Float_t GetSampleMin(UInt_t ivar) const; return the minimum of variable ivar from the training sample; that pass/end up in this node. Float_t GetSampleMax(UInt_t ivar) const; return the maximum of variable ivar from the training sample; that pass/end up in this node. void SetSampleMin(UInt_t ivar, Float_t xmin); set the minimum of variable ivar from the training sample; that pass/end up in this node. void SetSampleMax(UInt_t ivar, Float_t xmax); set the maximum of variable ivar from the training sample; that pass/end up in this node. void ReadAttributes(void* ",MatchSource.WIKI,root/html532/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTreeNode.html
https://root.cern/root/html532/TMVA__Event.html:1618,Energy Efficiency,charge,charge,1618,TRefArray *fMuons; //array of Muon tracks only; TRef fLastTrack; //pointer to last track; TRef fHistoWeb; //EXEC:GetHistoWeb reference to an histogram in a TWebFile; TH1F *fH;; TBits fTriggerBits; //Bits triggered by this event. The EventHeader class has 3 data members (integers):; public:; Int_t fEvtNum;; Int_t fRun;; Int_t fDate;. The Event data member fTracks is a pointer to a TClonesArray.; It is an array of a variable number of tracks per event.; Each element of the array is an object of class Track with the members:; private:; Float_t fPx; //X component of the momentum; Float_t fPy; //Y component of the momentum; Float_t fPz; //Z component of the momentum; Float_t fRandom; //A random track quantity; Float_t fMass2; //The mass square of this particle; Float_t fBx; //X intercept at the vertex; Float_t fBy; //Y intercept at the vertex; Float_t fMeanCharge; //Mean charge deposition of all hits of this track; Float_t fXfirst; //X coordinate of the first point; Float_t fXlast; //X coordinate of the last point; Float_t fYfirst; //Y coordinate of the first point; Float_t fYlast; //Y coordinate of the last point; Float_t fZfirst; //Z coordinate of the first point; Float_t fZlast; //Z coordinate of the last point; Double32_t fCharge; //Charge of this track; Double32_t fVertex[3]; //Track vertex position; Int_t fNpoint; //Number of points for this track; Short_t fValid; //Validity criterion; Int_t fNsp; //Number of points for this track with a special value; Double32_t *fPointValue; //[fNsp] a special quantity for some point.; TBits fTriggerBits; //Bits triggered by this track. An example of a batch program to use the Event/Track classes is given; in this directory: MainEvent.; Look also in the same directory at the following macros:; - eventa.C an example how to read the tree; - eventb.C how to read events conditionally. During the processing of the event (optionally) also a large number; of histograms can be filled. The creation and handling of the; histograms is taken,MatchSource.WIKI,root/html532/TMVA__Event.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Event.html
https://root.cern/root/html532/TMVA__Event.html:1157,Modifiability,variab,variable,1157,escription; function members; data members; class charts. ROOT; » TEST; » TMVA::Event. class TMVA::Event. Event and Track classes. The Event class is a naive/simple example of an event structure.; public:; char fType[20];; char *fEventName; //run+event number in character format; Int_t fNtrack;; Int_t fNseg;; Int_t fNvertex;; UInt_t fFlag;; Double32_t fTemperature;; Int_t fMeasures[10];; Double32_t fMatrix[4][4];; Double32_t *fClosestDistance; //[fNvertex] indexed array!; EventHeader fEvtHdr;; TClonesArray *fTracks;; TRefArray *fHighPt; //array of High Pt tracks only; TRefArray *fMuons; //array of Muon tracks only; TRef fLastTrack; //pointer to last track; TRef fHistoWeb; //EXEC:GetHistoWeb reference to an histogram in a TWebFile; TH1F *fH;; TBits fTriggerBits; //Bits triggered by this event. The EventHeader class has 3 data members (integers):; public:; Int_t fEvtNum;; Int_t fRun;; Int_t fDate;. The Event data member fTracks is a pointer to a TClonesArray.; It is an array of a variable number of tracks per event.; Each element of the array is an object of class Track with the members:; private:; Float_t fPx; //X component of the momentum; Float_t fPy; //Y component of the momentum; Float_t fPz; //Z component of the momentum; Float_t fRandom; //A random track quantity; Float_t fMass2; //The mass square of this particle; Float_t fBx; //X intercept at the vertex; Float_t fBy; //Y intercept at the vertex; Float_t fMeanCharge; //Mean charge deposition of all hits of this track; Float_t fXfirst; //X coordinate of the first point; Float_t fXlast; //X coordinate of the last point; Float_t fYfirst; //Y coordinate of the first point; Float_t fYlast; //Y coordinate of the last point; Float_t fZfirst; //Z coordinate of the first point; Float_t fZlast; //Z coordinate of the last point; Double32_t fCharge; //Charge of this track; Double32_t fVertex[3]; //Track vertex position; Int_t fNpoint; //Number of points for this track; Short_t fValid; //Validity criterion; Int_t fNsp; //N,MatchSource.WIKI,root/html532/TMVA__Event.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Event.html
https://root.cern/root/html532/TMVA__Event.html:2881,Modifiability,variab,variables,2881,"he first point; Float_t fZlast; //Z coordinate of the last point; Double32_t fCharge; //Charge of this track; Double32_t fVertex[3]; //Track vertex position; Int_t fNpoint; //Number of points for this track; Short_t fValid; //Validity criterion; Int_t fNsp; //Number of points for this track with a special value; Double32_t *fPointValue; //[fNsp] a special quantity for some point.; TBits fTriggerBits; //Bits triggered by this track. An example of a batch program to use the Event/Track classes is given; in this directory: MainEvent.; Look also in the same directory at the following macros:; - eventa.C an example how to read the tree; - eventb.C how to read events conditionally. During the processing of the event (optionally) also a large number; of histograms can be filled. The creation and handling of the; histograms is taken care of by the HistogramManager class. Note: This version of the class Event (see EventMT.h and EventMT.cxx; for an alternative) uses static variables to improve performance (by; reducing the number of memory allocations). Consequently, only one; instance of the class Event should be in use at a time (a 2nd instance; would share the array of Tracks with the first instance). Function Members (Methods); public:. ~Event(); static voidClearDynamicVariables(); voidCopyVarValues(const TMVA::Event& other); TMVA::EventEvent(); TMVA::EventEvent(const TMVA::Event&); TMVA::EventEvent(const vector<Float_t*>*&, UInt_t nvar); TMVA::EventEvent(const vector<Float_t>&, UInt_t theClass, Double_t weight = 1.0, Double_t boostweight = 1.0); TMVA::EventEvent(const vector<Float_t>& values, const vector<Float_t>& targetValues, UInt_t theClass = 0, Double_t weight = 1.0, Double_t boostweight = 1.0); TMVA::EventEvent(const vector<Float_t>& values, const vector<Float_t>& targetValues, const vector<Float_t>& spectatorValues, UInt_t theClass = 0, Double_t weight = 1.0, Double_t boostweight = 1.0); Double_tGetBoostWeight() const; UInt_tGetClass() const; UInt_tGetNSpectators(",MatchSource.WIKI,root/html532/TMVA__Event.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Event.html
https://root.cern/root/html532/TMVA__Event.html:4972,Modifiability,variab,variables,4972,"_tGetNVariables() const; Double_tGetOriginalWeight() const; Float_tGetSpectator(UInt_t ivar) const; vector<Float_t>&GetSpectators() const; Float_tGetTarget(UInt_t itgt) const; vector<Float_t>&GetTargets() const; Float_tGetValue(UInt_t ivar) const; const vector<Float_t>&GetValues() const; Double_tGetWeight() const; Bool_tIsDynamic() const; TMVA::Event&operator=(const TMVA::Event&); voidPrint(ostream& o) const; voidScaleBoostWeight(Double_t s); voidScaleWeight(Double_t s); voidSetBoostWeight(Double_t w); voidSetClass(UInt_t t); voidSetDoNotBoost(); voidSetSpectator(UInt_t ivar, Float_t value); voidSetTarget(UInt_t itgt, Float_t value); voidSetVal(UInt_t ivar, Float_t val); voidSetWeight(Double_t w). Data Members; private:. Double_tfBoostWeightinternal weight to be set by boosting algorithm; UInt_tfClassclass number; Bool_tfDoNotBoostmark event as not to be boosted (used to compensate for events with negative event weights; Bool_tfDynamicis set when the dynamic values are taken; vector<Float_t>fSpectators""visisting"" variables not used in MVAs; vector<Float_t>fTargetstarget values for regression; vector<Float_t>fValuesthe event values; vector<Float_t*>*fValuesDynamicthe event values; Double_tfWeightevent weight (product of global and individual weights). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Event(); Create an Event object.; When the constructor is invoked for the first time, the class static; variable fgTracks is 0 and the TClonesArray fgTracks is created. ~Event(). Event(); constructors. Event(const TMVA::Event& ). explicit Event(const vector<Float_t>& values, const vector<Float_t>& targetValues, const vector<Float_t>& spectatorValues, UInt_t theClass = 0, Double_t weight = 1.0, Double_t boostweight = 1.0). explicit Event(const vector<Float_t>& , UInt_t theClass, Double_t weight = 1.0, Double_t boostweight = 1.0). Bool_t IsDynamic() const; accessors. {return fDynamic; }. Double_t GetWeight() const; { return fWeight*",MatchSource.WIKI,root/html532/TMVA__Event.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Event.html
https://root.cern/root/html532/TMVA__Event.html:5409,Modifiability,variab,variable,5409,"(Double_t s); voidSetBoostWeight(Double_t w); voidSetClass(UInt_t t); voidSetDoNotBoost(); voidSetSpectator(UInt_t ivar, Float_t value); voidSetTarget(UInt_t itgt, Float_t value); voidSetVal(UInt_t ivar, Float_t val); voidSetWeight(Double_t w). Data Members; private:. Double_tfBoostWeightinternal weight to be set by boosting algorithm; UInt_tfClassclass number; Bool_tfDoNotBoostmark event as not to be boosted (used to compensate for events with negative event weights; Bool_tfDynamicis set when the dynamic values are taken; vector<Float_t>fSpectators""visisting"" variables not used in MVAs; vector<Float_t>fTargetstarget values for regression; vector<Float_t>fValuesthe event values; vector<Float_t*>*fValuesDynamicthe event values; Double_tfWeightevent weight (product of global and individual weights). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Event(); Create an Event object.; When the constructor is invoked for the first time, the class static; variable fgTracks is 0 and the TClonesArray fgTracks is created. ~Event(). Event(); constructors. Event(const TMVA::Event& ). explicit Event(const vector<Float_t>& values, const vector<Float_t>& targetValues, const vector<Float_t>& spectatorValues, UInt_t theClass = 0, Double_t weight = 1.0, Double_t boostweight = 1.0). explicit Event(const vector<Float_t>& , UInt_t theClass, Double_t weight = 1.0, Double_t boostweight = 1.0). Bool_t IsDynamic() const; accessors. {return fDynamic; }. Double_t GetWeight() const; { return fWeight*fBoostWeight; }. Double_t GetOriginalWeight() const; { return fWeight; }. Double_t GetBoostWeight() const; { return TMath::Max(Double_t(0.0001),fBoostWeight); }. UInt_t GetClass() const; { return fClass; }. UInt_t GetNVariables() const. UInt_t GetNTargets() const. UInt_t GetNSpectators() const. Float_t GetValue(UInt_t ivar) const. const std::vector<Float_t>& GetValues() const. Float_t GetTarget(UInt_t itgt) const; { return fTargets.at(itgt); }. std::vector<F",MatchSource.WIKI,root/html532/TMVA__Event.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Event.html
https://root.cern/root/html532/TMVA__Event.html:2902,Performance,perform,performance,2902,"he first point; Float_t fZlast; //Z coordinate of the last point; Double32_t fCharge; //Charge of this track; Double32_t fVertex[3]; //Track vertex position; Int_t fNpoint; //Number of points for this track; Short_t fValid; //Validity criterion; Int_t fNsp; //Number of points for this track with a special value; Double32_t *fPointValue; //[fNsp] a special quantity for some point.; TBits fTriggerBits; //Bits triggered by this track. An example of a batch program to use the Event/Track classes is given; in this directory: MainEvent.; Look also in the same directory at the following macros:; - eventa.C an example how to read the tree; - eventb.C how to read events conditionally. During the processing of the event (optionally) also a large number; of histograms can be filled. The creation and handling of the; histograms is taken care of by the HistogramManager class. Note: This version of the class Event (see EventMT.h and EventMT.cxx; for an alternative) uses static variables to improve performance (by; reducing the number of memory allocations). Consequently, only one; instance of the class Event should be in use at a time (a 2nd instance; would share the array of Tracks with the first instance). Function Members (Methods); public:. ~Event(); static voidClearDynamicVariables(); voidCopyVarValues(const TMVA::Event& other); TMVA::EventEvent(); TMVA::EventEvent(const TMVA::Event&); TMVA::EventEvent(const vector<Float_t*>*&, UInt_t nvar); TMVA::EventEvent(const vector<Float_t>&, UInt_t theClass, Double_t weight = 1.0, Double_t boostweight = 1.0); TMVA::EventEvent(const vector<Float_t>& values, const vector<Float_t>& targetValues, UInt_t theClass = 0, Double_t weight = 1.0, Double_t boostweight = 1.0); TMVA::EventEvent(const vector<Float_t>& values, const vector<Float_t>& targetValues, const vector<Float_t>& spectatorValues, UInt_t theClass = 0, Double_t weight = 1.0, Double_t boostweight = 1.0); Double_tGetBoostWeight() const; UInt_tGetClass() const; UInt_tGetNSpectators(",MatchSource.WIKI,root/html532/TMVA__Event.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Event.html
https://root.cern/root/html532/TMVA__Event.html:5866,Security,access,accessors,5866,"ative event weights; Bool_tfDynamicis set when the dynamic values are taken; vector<Float_t>fSpectators""visisting"" variables not used in MVAs; vector<Float_t>fTargetstarget values for regression; vector<Float_t>fValuesthe event values; vector<Float_t*>*fValuesDynamicthe event values; Double_tfWeightevent weight (product of global and individual weights). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Event(); Create an Event object.; When the constructor is invoked for the first time, the class static; variable fgTracks is 0 and the TClonesArray fgTracks is created. ~Event(). Event(); constructors. Event(const TMVA::Event& ). explicit Event(const vector<Float_t>& values, const vector<Float_t>& targetValues, const vector<Float_t>& spectatorValues, UInt_t theClass = 0, Double_t weight = 1.0, Double_t boostweight = 1.0). explicit Event(const vector<Float_t>& , UInt_t theClass, Double_t weight = 1.0, Double_t boostweight = 1.0). Bool_t IsDynamic() const; accessors. {return fDynamic; }. Double_t GetWeight() const; { return fWeight*fBoostWeight; }. Double_t GetOriginalWeight() const; { return fWeight; }. Double_t GetBoostWeight() const; { return TMath::Max(Double_t(0.0001),fBoostWeight); }. UInt_t GetClass() const; { return fClass; }. UInt_t GetNVariables() const. UInt_t GetNTargets() const. UInt_t GetNSpectators() const. Float_t GetValue(UInt_t ivar) const. const std::vector<Float_t>& GetValues() const. Float_t GetTarget(UInt_t itgt) const; { return fTargets.at(itgt); }. std::vector<Float_t>& GetTargets() const; { return fTargets; }. Float_t GetSpectator(UInt_t ivar) const. std::vector<Float_t>& GetSpectators() const; { return fSpectators; }. void ScaleWeight(Double_t s); { fWeight*=s; }. void SetWeight(Double_t w); { fWeight=w; }. void SetBoostWeight(Double_t w); { fDoNotBoost ? fDoNotBoost = kFALSE : fBoostWeight=w; }. void ScaleBoostWeight(Double_t s); { fDoNotBoost ? fDoNotBoost = kFALSE : fBoostWeight *= s; }. void SetClass",MatchSource.WIKI,root/html532/TMVA__Event.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Event.html
https://root.cern/root/html532/TMVA__Event.html:322,Usability,simpl,simple,322,. TMVA::Event. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TEST; » TMVA::Event. class TMVA::Event. Event and Track classes. The Event class is a naive/simple example of an event structure.; public:; char fType[20];; char *fEventName; //run+event number in character format; Int_t fNtrack;; Int_t fNseg;; Int_t fNvertex;; UInt_t fFlag;; Double32_t fTemperature;; Int_t fMeasures[10];; Double32_t fMatrix[4][4];; Double32_t *fClosestDistance; //[fNvertex] indexed array!; EventHeader fEvtHdr;; TClonesArray *fTracks;; TRefArray *fHighPt; //array of High Pt tracks only; TRefArray *fMuons; //array of Muon tracks only; TRef fLastTrack; //pointer to last track; TRef fHistoWeb; //EXEC:GetHistoWeb reference to an histogram in a TWebFile; TH1F *fH;; TBits fTriggerBits; //Bits triggered by this event. The EventHeader class has 3 data members (integers):; public:; Int_t fEvtNum;; Int_t fRun;; Int_t fDate;. The Event data member fTracks is a pointer to a TClonesArray.; It is an array of a variable number of tracks per event.; Each element of the array is an object of class Track with the members:; private:; Float_t fPx; //X component of the momentum; Float_t fPy; //Y component of the momentum; Float_t fPz; //Z component of the momentum; Float_t fRandom; //A random track quantity; Float_t fMass2; //The mass square of this particle; Float_t fBx; //X intercept at the vertex; Float_t fBy; //Y intercept at the vertex; Float_t fMeanCharge; //Mean charge deposition of all hits of this track; Float_t fXfirst; //X coordinate of the first point; Float_t fXlast; //X coordinate of the last point; Float_t fYfirst; //Y coordinate of the first point; Float_t fYlast; //Y coordinate of the last point; Float_t fZfirst; //Z coordinate of the first point; Float_t fZlast; //Z coordinate of the last point; Double32_t fCharge; //Charge of ,MatchSource.WIKI,root/html532/TMVA__Event.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Event.html
https://root.cern/root/html532/TMVA__Factory.html:4539,Availability,error,error,4539,"nst; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; TTree*CreateEventAssignTrees(const TString& name); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidDeleteAllMethods(); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; voidEvaluateAllMethods(); voidEvaluateAllVariables(TString options = """"); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); TMVA::FactoryFactory(TString theJobName, TFile* theTargetFile, TString theOption = """"); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; TMVA::IMethod*GetMethod(const TString& title) const; virtual const char*GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&TMVA::Configurable::GetOptions() const; virtual const",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:4623,Availability,error,error,4623,"oidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; TTree*CreateEventAssignTrees(const TString& name); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidDeleteAllMethods(); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; voidEvaluateAllMethods(); voidEvaluateAllVariables(TString options = """"); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); TMVA::FactoryFactory(TString theJobName, TFile* theTargetFile, TString theOption = """"); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; TMVA::IMethod*GetMethod(const TString& title) const; virtual const char*GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&TMVA::Configurable::GetOptions() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:18639,Deployability,configurat,configuration,18639," AddCut(const TCut& cut, const TString& className = """"). void PrepareTrainingAndTestTree(const TCut& cut, Int_t NsigTrain, Int_t NbkgTrain, Int_t NsigTest, Int_t NbkgTest, const TString& otherOpt = ""SplitMode=Random:!V""); prepare the training and test trees. void PrepareTrainingAndTestTree(const TCut& cut, Int_t Ntrain, Int_t Ntest = -1); prepare the training and test trees; kept for backward compatibility. void PrepareTrainingAndTestTree(const TCut& cut, const TString& splitOpt); prepare the training and test trees; -> same cuts for signal and background. void PrepareTrainingAndTestTree(TCut sigcut, TCut bkgcut, const TString& splitOpt); prepare the training and test trees. TMVA::MethodBase* BookMethod(TString theMethodName, TString methodTitle, TString theOption = """"); Book a classifier or regression method. TMVA::MethodBase* BookMethod(TMVA::Types::EMVA theMethod, TString methodTitle, TString theOption = """"); books MVA method; the option configuration string is custom for each MVA; the TString field ""theNameAppendix"" serves to define (and distinguish); several instances of a given MVA, eg, when one wants to compare the; performance of various configurations. TMVA::IMethod* GetMethod(const TString& title) const; returns pointer to MVA that corresponds to given method title. void WriteDataInformation(); put correlations of input data and a few (default + user; selected) transformations into the root file. void OptimizeAllMethods(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); iterates through all booked methods and sees if they use parameter tuning and if so..; does just that i.e. calls ""Method::Train()"" for different parameter setttings and; keeps in mind the ""optimal one""... and that's the one that will later on be used; in the main training loop. void TrainAllMethods(); iterates through all booked methods and calls training. void TestAllMethods(). void MakeClass(const TString& methodTitle = """") const; Print predefined help message of classifier; ite",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:18848,Deployability,configurat,configurations,18848," AddCut(const TCut& cut, const TString& className = """"). void PrepareTrainingAndTestTree(const TCut& cut, Int_t NsigTrain, Int_t NbkgTrain, Int_t NsigTest, Int_t NbkgTest, const TString& otherOpt = ""SplitMode=Random:!V""); prepare the training and test trees. void PrepareTrainingAndTestTree(const TCut& cut, Int_t Ntrain, Int_t Ntest = -1); prepare the training and test trees; kept for backward compatibility. void PrepareTrainingAndTestTree(const TCut& cut, const TString& splitOpt); prepare the training and test trees; -> same cuts for signal and background. void PrepareTrainingAndTestTree(TCut sigcut, TCut bkgcut, const TString& splitOpt); prepare the training and test trees. TMVA::MethodBase* BookMethod(TString theMethodName, TString methodTitle, TString theOption = """"); Book a classifier or regression method. TMVA::MethodBase* BookMethod(TMVA::Types::EMVA theMethod, TString methodTitle, TString theOption = """"); books MVA method; the option configuration string is custom for each MVA; the TString field ""theNameAppendix"" serves to define (and distinguish); several instances of a given MVA, eg, when one wants to compare the; performance of various configurations. TMVA::IMethod* GetMethod(const TString& title) const; returns pointer to MVA that corresponds to given method title. void WriteDataInformation(); put correlations of input data and a few (default + user; selected) transformations into the root file. void OptimizeAllMethods(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); iterates through all booked methods and sees if they use parameter tuning and if so..; does just that i.e. calls ""Method::Train()"" for different parameter setttings and; keeps in mind the ""optimal one""... and that's the one that will later on be used; in the main training loop. void TrainAllMethods(); iterates through all booked methods and calls training. void TestAllMethods(). void MakeClass(const TString& methodTitle = """") const; Print predefined help message of classifier; ite",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:13061,Integrability,message,message,13061,"t; TStringfJobName! jobname, used as extension in weight file names; TMVA::Factory::MVectorfMethods! all MVA methods; TStringfOptions! option string given by construction (presently only ""V""); vector<TTree*>fTestAssignTree! for each class: tmp tree if user wants to assign the events directly; vector<TTree*>fTrainAssignTree! for each class: tmp tree if user wants to assign the events directly; TStringfTransformations! List of transformations to test; Bool_tfVerbose! verbose mode; static TFile*fgTargetFile! ROOT output file. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Factory(TString theJobName, TFile* theTargetFile, TString theOption = """"); standard constructor; jobname : this name will appear in all weight file names produced by the MVAs; theTargetFile : output ROOT file; the test tree and all evaluation plots; will be stored here; theOption : option string; currently: ""V"" for verbose. void Greetings(); print welcome message; options are: kLogoWelcomeMsg, kIsometricWelcomeMsg, kLeanWelcomeMsg. ~Factory( void ); destructor; delete fATreeEvent;. void DeleteAllMethods( void ); delete methods. void SetVerbose(Bool_t v = kTRUE). TMVA::DataSetInfo& AddDataSet( DataSetInfo &dsi ). TMVA::DataSetInfo& AddDataSet(const TString& ). TTree* CreateEventAssignTrees(const TString& name); create the data assignment tree (for event-wise data assignment by user). void AddSignalTrainingEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal training event. void AddSignalTestEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal testing event. void AddBackgroundTrainingEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal training event. void AddBackgroundTestEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal training event. void AddTrainingEvent(const TString& className, const vector<Double_t>& event, Double_t weight); add signal training event. void AddTestEvent(const",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:19658,Integrability,message,message,19658,"uration string is custom for each MVA; the TString field ""theNameAppendix"" serves to define (and distinguish); several instances of a given MVA, eg, when one wants to compare the; performance of various configurations. TMVA::IMethod* GetMethod(const TString& title) const; returns pointer to MVA that corresponds to given method title. void WriteDataInformation(); put correlations of input data and a few (default + user; selected) transformations into the root file. void OptimizeAllMethods(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); iterates through all booked methods and sees if they use parameter tuning and if so..; does just that i.e. calls ""Method::Train()"" for different parameter setttings and; keeps in mind the ""optimal one""... and that's the one that will later on be used; in the main training loop. void TrainAllMethods(); iterates through all booked methods and calls training. void TestAllMethods(). void MakeClass(const TString& methodTitle = """") const; Print predefined help message of classifier; iterate over methods and test. void PrintHelpMessage(const TString& methodTitle = """") const; Print predefined help message of classifier; iterate over methods and test. void EvaluateAllVariables(TString options = """"); iterates over all MVA input varables and evaluates them. void EvaluateAllMethods( void ); iterates over all MVAs that have been booked, and calls their evaluation methods. const char* GetName() const; { return ""Factory""; }. void AddRegressionTree(TTree* tree, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); special case: regression. void AddRegressionTarget(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0). MethodBase* BookMethod(TString theMethodName, TString methodTitle, TString theOption = """"). void OptimizeAllMethodsForClassification(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); { OptimizeAllMethods(fomType,fitType); }. void",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:19796,Integrability,message,message,19796,"iven MVA, eg, when one wants to compare the; performance of various configurations. TMVA::IMethod* GetMethod(const TString& title) const; returns pointer to MVA that corresponds to given method title. void WriteDataInformation(); put correlations of input data and a few (default + user; selected) transformations into the root file. void OptimizeAllMethods(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); iterates through all booked methods and sees if they use parameter tuning and if so..; does just that i.e. calls ""Method::Train()"" for different parameter setttings and; keeps in mind the ""optimal one""... and that's the one that will later on be used; in the main training loop. void TrainAllMethods(); iterates through all booked methods and calls training. void TestAllMethods(). void MakeClass(const TString& methodTitle = """") const; Print predefined help message of classifier; iterate over methods and test. void PrintHelpMessage(const TString& methodTitle = """") const; Print predefined help message of classifier; iterate over methods and test. void EvaluateAllVariables(TString options = """"); iterates over all MVA input varables and evaluates them. void EvaluateAllMethods( void ); iterates over all MVAs that have been booked, and calls their evaluation methods. const char* GetName() const; { return ""Factory""; }. void AddRegressionTree(TTree* tree, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); special case: regression. void AddRegressionTarget(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0). MethodBase* BookMethod(TString theMethodName, TString methodTitle, TString theOption = """"). void OptimizeAllMethodsForClassification(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); { OptimizeAllMethods(fomType,fitType); }. void OptimizeAllMethodsForRegression(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); { OptimizeAllMethods(fomType,fitType); }",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:8498,Modifiability,variab,variable,8498,"al voidTObject::Print(Option_t* option = """") const; voidPrintHelpMessage(const TString& methodTitle = """") const; voidTMVA::Configurable::PrintOptions() const; virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); static TDirectory*RootBaseDir(); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidSetBackgroundTree(TTree* background, Double_t weight = 1.0); voidSetBackgroundWeightExpression(const TString& variable); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); voidSetCut(const TString& cut, const TString& className = """"); voidSetCut(const TCut& cut, const TString& className = """"); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidSetInputTrees(TTree* inputTree, const TCut& SigCut, const TCut& BgCut); voidSetInputTrees(const TString& signalFileName, const TString& backgroundFileName, Double_t signalWeight = 1.0, Double_t backgroundWeight = 1.0); voidSetInputTrees(TTree* signal, TTree* background, Double_t signalWeight = 1.0, Double_t backgroundWeight = 1.0); voidSetInputVariables(vector<TString>* theVariables); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidSetSignalTree(TTree* signal, Double_t weight = 1.0); voidSetSignalWeightExpression(const TString& variable); voidSetTree(TTree* tree, const TString& className, Double_t weight); virtual voidTObject::SetUniqueID(UInt_t uid); voidSetVerbose(Bool_t v = kTRUE); voidSetWeightExpression(const TString& va",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:9579,Modifiability,variab,variable,9579,"t signalWeight = 1.0, Double_t backgroundWeight = 1.0); voidSetInputTrees(TTree* signal, TTree* background, Double_t signalWeight = 1.0, Double_t backgroundWeight = 1.0); voidSetInputVariables(vector<TString>* theVariables); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidSetSignalTree(TTree* signal, Double_t weight = 1.0); voidSetSignalWeightExpression(const TString& variable); voidSetTree(TTree* tree, const TString& className, Double_t weight); virtual voidTObject::SetUniqueID(UInt_t uid); voidSetVerbose(Bool_t v = kTRUE); voidSetWeightExpression(const TString& variable, const TString& className = """"); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; voidTestAllMethods(); Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; voidTrainAllMethods(); voidTrainAllMethodsForClassification(); voidTrainAllMethodsForRegression(); virtual voidTObject::UseCurrentStyle(); Bool_tUserAssignEvents(UInt_t clIndex); Bool_tVerbose() const; virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&TMVA::Configurable::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable:",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:9778,Modifiability,variab,variable,9778,"t signalWeight = 1.0, Double_t backgroundWeight = 1.0); voidSetInputTrees(TTree* signal, TTree* background, Double_t signalWeight = 1.0, Double_t backgroundWeight = 1.0); voidSetInputVariables(vector<TString>* theVariables); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidSetSignalTree(TTree* signal, Double_t weight = 1.0); voidSetSignalWeightExpression(const TString& variable); voidSetTree(TTree* tree, const TString& className, Double_t weight); virtual voidTObject::SetUniqueID(UInt_t uid); voidSetVerbose(Bool_t v = kTRUE); voidSetWeightExpression(const TString& variable, const TString& className = """"); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; voidTestAllMethods(); Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; voidTrainAllMethods(); voidTrainAllMethodsForClassification(); voidTrainAllMethodsForRegression(); virtual voidTObject::UseCurrentStyle(); Bool_tUserAssignEvents(UInt_t clIndex); Bool_tVerbose() const; virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&TMVA::Configurable::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable:",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:11678,Modifiability,variab,variables,11678,"vate:. TMVA::DataInputHandler&DataInput(); TMVA::DataSetInfo&DefaultDataSetInfo(); voidGreetings(); voidSetInputTreesFromEventAssignTrees(); voidWriteDataInformation(). Data Members; public:. enum DataAssignType { kUndefined; kAssignTrees; kAssignEvents; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. Float_t*fATreeEventevent variables; Int_tfATreeTypetype of event (=classIndex); Float_tfATreeWeightweight of the event; TMVA::Types::EAnalysisTypefAnalysisType! the training type; TMVA::Factory::DataAssignTypefDataAssignType! flags for data assigning; TMVA::DataInputHandler*fDataInputHandler; TMVA::DataSetManager*fDataSetManagerDSMTEST; vector<TMVA::VariableTransformBase*>fDefaultTrfs! list of transformations on default DataSet; TStringfJobName! jobname, used as extension in weight file names; TMVA::Factory::MVectorfMethods! all MVA methods; TStringfOptions! option string given by construction (presently only ""V""); vector<TTree*>fTestAssignTree! for each class: tmp tree if user wants to assign the events directly; vector<TTree*>fTrainAssignTree! for each class: tmp tree if user wants to assign the events directly; TStringfTransformations! List of transformations to test; Bool_tfVerbose! verbose mode; static TFile*fgTargetFile! ROOT output file. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Factory(TString theJobName, TFile* theTargetFile, TString theOption = """"); standard constructor; jobname : this name will appear in all weight file names produced by the MVAs; theTargetFile : output ROOT file; the test tree and all evaluation plots; will be stored here; theOption : option string; currently: ""V"" for verbose. void Greetings(); print welcome message; options are: kLogoWelcomeMsg, kIsometricWelcomeMsg, kLeanWelco",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:14342,Modifiability,variab,variables,14342,"A::DataSetInfo& AddDataSet( DataSetInfo &dsi ). TMVA::DataSetInfo& AddDataSet(const TString& ). TTree* CreateEventAssignTrees(const TString& name); create the data assignment tree (for event-wise data assignment by user). void AddSignalTrainingEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal training event. void AddSignalTestEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal testing event. void AddBackgroundTrainingEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal training event. void AddBackgroundTestEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal training event. void AddTrainingEvent(const TString& className, const vector<Double_t>& event, Double_t weight); add signal training event. void AddTestEvent(const TString& className, const vector<Double_t>& event, Double_t weight); add signal test event. void AddEvent(const TString& className, TMVA::Types::ETreeType tt, const vector<Double_t>& event, Double_t weight); add event; vector event : the order of values is: variables + targets + spectators. Bool_t UserAssignEvents(UInt_t clIndex). void SetInputTreesFromEventAssignTrees(); assign event-wise local trees to data set. void AddTree(TTree* tree, const TString& className, Double_t weight, const TCut& cut, const TString& treeType); number of signal events (used to compute significance). void AddTree(TTree* tree, const TString& className, Double_t weight = 1.0, const TCut& cut = """", TMVA::Types::ETreeType tt = Types::kMaxTreeType). void AddSignalTree( TTree* signal, Double_t weight, Types::ETreeType treetype ); number of signal events (used to compute significance). void AddSignalTree(TString datFileS, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); add signal tree from text file. void AddSignalTree(TTree* signal, Double_t weight, const TString& treetype). void AddBackgroundTree( TTree* signal, Double_t weight, Types::ETreeType treetype ); number of s",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:16534,Modifiability,variab,variable,16534,"om text file. void AddBackgroundTree(TTree* background, Double_t weight, const TString& treetype). void SetSignalTree(TTree* signal, Double_t weight = 1.0). void SetBackgroundTree(TTree* background, Double_t weight = 1.0). void SetTree(TTree* tree, const TString& className, Double_t weight); set background tree. void SetInputTrees(TTree* signal, TTree* background, Double_t signalWeight = 1.0, Double_t backgroundWeight = 1.0); define the input trees for signal and background; no cuts are applied. void SetInputTrees(const TString& signalFileName, const TString& backgroundFileName, Double_t signalWeight = 1.0, Double_t backgroundWeight = 1.0). void SetInputTrees(TTree* inputTree, const TCut& SigCut, const TCut& BgCut); define the input trees for signal and background from single input tree,; containing both signal and background events distinguished by the type; identifiers: SigCut and BgCut. void AddVariable(const TString& expression, const TString& title, const TString& unit, char type = 'F', Double_t min = 0, Double_t max = 0); user inserts discriminating variable in data set info. void AddVariable(const TString& expression, char type = 'F', Double_t min = 0, Double_t max = 0); user inserts discriminating variable in data set info. void AddTarget(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0); user inserts target in data set info. void AddSpectator(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0); user inserts target in data set info. TMVA::DataSetInfo& DefaultDataSetInfo(); default creation. void SetInputVariables(vector<TString>* theVariables); fill input variables in data set. void SetSignalWeightExpression(const TString& variable). void SetBackgroundWeightExpression(const TString& variable). void SetWeightExpression(const TString& variable, const TString& className = """"); Log() << kWarning << DefaultDataSetInfo().GetNClasses() /",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:16687,Modifiability,variab,variable,16687,"dTree(TTree* background, Double_t weight = 1.0). void SetTree(TTree* tree, const TString& className, Double_t weight); set background tree. void SetInputTrees(TTree* signal, TTree* background, Double_t signalWeight = 1.0, Double_t backgroundWeight = 1.0); define the input trees for signal and background; no cuts are applied. void SetInputTrees(const TString& signalFileName, const TString& backgroundFileName, Double_t signalWeight = 1.0, Double_t backgroundWeight = 1.0). void SetInputTrees(TTree* inputTree, const TCut& SigCut, const TCut& BgCut); define the input trees for signal and background from single input tree,; containing both signal and background events distinguished by the type; identifiers: SigCut and BgCut. void AddVariable(const TString& expression, const TString& title, const TString& unit, char type = 'F', Double_t min = 0, Double_t max = 0); user inserts discriminating variable in data set info. void AddVariable(const TString& expression, char type = 'F', Double_t min = 0, Double_t max = 0); user inserts discriminating variable in data set info. void AddTarget(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0); user inserts target in data set info. void AddSpectator(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0); user inserts target in data set info. TMVA::DataSetInfo& DefaultDataSetInfo(); default creation. void SetInputVariables(vector<TString>* theVariables); fill input variables in data set. void SetSignalWeightExpression(const TString& variable). void SetBackgroundWeightExpression(const TString& variable). void SetWeightExpression(const TString& variable, const TString& className = """"); Log() << kWarning << DefaultDataSetInfo().GetNClasses() /*fClasses.size()*/ << Endl;. void SetCut(const TString& cut, const TString& className = """"). void SetCut(const TCut& cut, const TString& className = """"). void AddCut(const TSt",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:17182,Modifiability,variab,variables,17182," SigCut, const TCut& BgCut); define the input trees for signal and background from single input tree,; containing both signal and background events distinguished by the type; identifiers: SigCut and BgCut. void AddVariable(const TString& expression, const TString& title, const TString& unit, char type = 'F', Double_t min = 0, Double_t max = 0); user inserts discriminating variable in data set info. void AddVariable(const TString& expression, char type = 'F', Double_t min = 0, Double_t max = 0); user inserts discriminating variable in data set info. void AddTarget(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0); user inserts target in data set info. void AddSpectator(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0); user inserts target in data set info. TMVA::DataSetInfo& DefaultDataSetInfo(); default creation. void SetInputVariables(vector<TString>* theVariables); fill input variables in data set. void SetSignalWeightExpression(const TString& variable). void SetBackgroundWeightExpression(const TString& variable). void SetWeightExpression(const TString& variable, const TString& className = """"); Log() << kWarning << DefaultDataSetInfo().GetNClasses() /*fClasses.size()*/ << Endl;. void SetCut(const TString& cut, const TString& className = """"). void SetCut(const TCut& cut, const TString& className = """"). void AddCut(const TString& cut, const TString& className = """"). void AddCut(const TCut& cut, const TString& className = """"). void PrepareTrainingAndTestTree(const TCut& cut, Int_t NsigTrain, Int_t NbkgTrain, Int_t NsigTest, Int_t NbkgTest, const TString& otherOpt = ""SplitMode=Random:!V""); prepare the training and test trees. void PrepareTrainingAndTestTree(const TCut& cut, Int_t Ntrain, Int_t Ntest = -1); prepare the training and test trees; kept for backward compatibility. void PrepareTrainingAndTestTree(const TCut& cut, const TString& s",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:17251,Modifiability,variab,variable,17251,"ound from single input tree,; containing both signal and background events distinguished by the type; identifiers: SigCut and BgCut. void AddVariable(const TString& expression, const TString& title, const TString& unit, char type = 'F', Double_t min = 0, Double_t max = 0); user inserts discriminating variable in data set info. void AddVariable(const TString& expression, char type = 'F', Double_t min = 0, Double_t max = 0); user inserts discriminating variable in data set info. void AddTarget(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0); user inserts target in data set info. void AddSpectator(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0); user inserts target in data set info. TMVA::DataSetInfo& DefaultDataSetInfo(); default creation. void SetInputVariables(vector<TString>* theVariables); fill input variables in data set. void SetSignalWeightExpression(const TString& variable). void SetBackgroundWeightExpression(const TString& variable). void SetWeightExpression(const TString& variable, const TString& className = """"); Log() << kWarning << DefaultDataSetInfo().GetNClasses() /*fClasses.size()*/ << Endl;. void SetCut(const TString& cut, const TString& className = """"). void SetCut(const TCut& cut, const TString& className = """"). void AddCut(const TString& cut, const TString& className = """"). void AddCut(const TCut& cut, const TString& className = """"). void PrepareTrainingAndTestTree(const TCut& cut, Int_t NsigTrain, Int_t NbkgTrain, Int_t NsigTest, Int_t NbkgTest, const TString& otherOpt = ""SplitMode=Random:!V""); prepare the training and test trees. void PrepareTrainingAndTestTree(const TCut& cut, Int_t Ntrain, Int_t Ntest = -1); prepare the training and test trees; kept for backward compatibility. void PrepareTrainingAndTestTree(const TCut& cut, const TString& splitOpt); prepare the training and test trees; -> same cuts for signal an",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:17312,Modifiability,variab,variable,17312,"ckground events distinguished by the type; identifiers: SigCut and BgCut. void AddVariable(const TString& expression, const TString& title, const TString& unit, char type = 'F', Double_t min = 0, Double_t max = 0); user inserts discriminating variable in data set info. void AddVariable(const TString& expression, char type = 'F', Double_t min = 0, Double_t max = 0); user inserts discriminating variable in data set info. void AddTarget(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0); user inserts target in data set info. void AddSpectator(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0); user inserts target in data set info. TMVA::DataSetInfo& DefaultDataSetInfo(); default creation. void SetInputVariables(vector<TString>* theVariables); fill input variables in data set. void SetSignalWeightExpression(const TString& variable). void SetBackgroundWeightExpression(const TString& variable). void SetWeightExpression(const TString& variable, const TString& className = """"); Log() << kWarning << DefaultDataSetInfo().GetNClasses() /*fClasses.size()*/ << Endl;. void SetCut(const TString& cut, const TString& className = """"). void SetCut(const TCut& cut, const TString& className = """"). void AddCut(const TString& cut, const TString& className = """"). void AddCut(const TCut& cut, const TString& className = """"). void PrepareTrainingAndTestTree(const TCut& cut, Int_t NsigTrain, Int_t NbkgTrain, Int_t NsigTest, Int_t NbkgTest, const TString& otherOpt = ""SplitMode=Random:!V""); prepare the training and test trees. void PrepareTrainingAndTestTree(const TCut& cut, Int_t Ntrain, Int_t Ntest = -1); prepare the training and test trees; kept for backward compatibility. void PrepareTrainingAndTestTree(const TCut& cut, const TString& splitOpt); prepare the training and test trees; -> same cuts for signal and background. void PrepareTrainingAndTestTree(TCut sigcut, ",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:17363,Modifiability,variab,variable,17363,"nst TString& expression, const TString& title, const TString& unit, char type = 'F', Double_t min = 0, Double_t max = 0); user inserts discriminating variable in data set info. void AddVariable(const TString& expression, char type = 'F', Double_t min = 0, Double_t max = 0); user inserts discriminating variable in data set info. void AddTarget(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0); user inserts target in data set info. void AddSpectator(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0); user inserts target in data set info. TMVA::DataSetInfo& DefaultDataSetInfo(); default creation. void SetInputVariables(vector<TString>* theVariables); fill input variables in data set. void SetSignalWeightExpression(const TString& variable). void SetBackgroundWeightExpression(const TString& variable). void SetWeightExpression(const TString& variable, const TString& className = """"); Log() << kWarning << DefaultDataSetInfo().GetNClasses() /*fClasses.size()*/ << Endl;. void SetCut(const TString& cut, const TString& className = """"). void SetCut(const TCut& cut, const TString& className = """"). void AddCut(const TString& cut, const TString& className = """"). void AddCut(const TCut& cut, const TString& className = """"). void PrepareTrainingAndTestTree(const TCut& cut, Int_t NsigTrain, Int_t NbkgTrain, Int_t NsigTest, Int_t NbkgTest, const TString& otherOpt = ""SplitMode=Random:!V""); prepare the training and test trees. void PrepareTrainingAndTestTree(const TCut& cut, Int_t Ntrain, Int_t Ntest = -1); prepare the training and test trees; kept for backward compatibility. void PrepareTrainingAndTestTree(const TCut& cut, const TString& splitOpt); prepare the training and test trees; -> same cuts for signal and background. void PrepareTrainingAndTestTree(TCut sigcut, TCut bkgcut, const TString& splitOpt); prepare the training and test trees. TMVA::MethodBase*",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:18639,Modifiability,config,configuration,18639," AddCut(const TCut& cut, const TString& className = """"). void PrepareTrainingAndTestTree(const TCut& cut, Int_t NsigTrain, Int_t NbkgTrain, Int_t NsigTest, Int_t NbkgTest, const TString& otherOpt = ""SplitMode=Random:!V""); prepare the training and test trees. void PrepareTrainingAndTestTree(const TCut& cut, Int_t Ntrain, Int_t Ntest = -1); prepare the training and test trees; kept for backward compatibility. void PrepareTrainingAndTestTree(const TCut& cut, const TString& splitOpt); prepare the training and test trees; -> same cuts for signal and background. void PrepareTrainingAndTestTree(TCut sigcut, TCut bkgcut, const TString& splitOpt); prepare the training and test trees. TMVA::MethodBase* BookMethod(TString theMethodName, TString methodTitle, TString theOption = """"); Book a classifier or regression method. TMVA::MethodBase* BookMethod(TMVA::Types::EMVA theMethod, TString methodTitle, TString theOption = """"); books MVA method; the option configuration string is custom for each MVA; the TString field ""theNameAppendix"" serves to define (and distinguish); several instances of a given MVA, eg, when one wants to compare the; performance of various configurations. TMVA::IMethod* GetMethod(const TString& title) const; returns pointer to MVA that corresponds to given method title. void WriteDataInformation(); put correlations of input data and a few (default + user; selected) transformations into the root file. void OptimizeAllMethods(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); iterates through all booked methods and sees if they use parameter tuning and if so..; does just that i.e. calls ""Method::Train()"" for different parameter setttings and; keeps in mind the ""optimal one""... and that's the one that will later on be used; in the main training loop. void TrainAllMethods(); iterates through all booked methods and calls training. void TestAllMethods(). void MakeClass(const TString& methodTitle = """") const; Print predefined help message of classifier; ite",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:18848,Modifiability,config,configurations,18848," AddCut(const TCut& cut, const TString& className = """"). void PrepareTrainingAndTestTree(const TCut& cut, Int_t NsigTrain, Int_t NbkgTrain, Int_t NsigTest, Int_t NbkgTest, const TString& otherOpt = ""SplitMode=Random:!V""); prepare the training and test trees. void PrepareTrainingAndTestTree(const TCut& cut, Int_t Ntrain, Int_t Ntest = -1); prepare the training and test trees; kept for backward compatibility. void PrepareTrainingAndTestTree(const TCut& cut, const TString& splitOpt); prepare the training and test trees; -> same cuts for signal and background. void PrepareTrainingAndTestTree(TCut sigcut, TCut bkgcut, const TString& splitOpt); prepare the training and test trees. TMVA::MethodBase* BookMethod(TString theMethodName, TString methodTitle, TString theOption = """"); Book a classifier or regression method. TMVA::MethodBase* BookMethod(TMVA::Types::EMVA theMethod, TString methodTitle, TString theOption = """"); books MVA method; the option configuration string is custom for each MVA; the TString field ""theNameAppendix"" serves to define (and distinguish); several instances of a given MVA, eg, when one wants to compare the; performance of various configurations. TMVA::IMethod* GetMethod(const TString& title) const; returns pointer to MVA that corresponds to given method title. void WriteDataInformation(); put correlations of input data and a few (default + user; selected) transformations into the root file. void OptimizeAllMethods(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); iterates through all booked methods and sees if they use parameter tuning and if so..; does just that i.e. calls ""Method::Train()"" for different parameter setttings and; keeps in mind the ""optimal one""... and that's the one that will later on be used; in the main training loop. void TrainAllMethods(); iterates through all booked methods and calls training. void TestAllMethods(). void MakeClass(const TString& methodTitle = """") const; Print predefined help message of classifier; ite",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:18825,Performance,perform,performance,18825," AddCut(const TCut& cut, const TString& className = """"). void PrepareTrainingAndTestTree(const TCut& cut, Int_t NsigTrain, Int_t NbkgTrain, Int_t NsigTest, Int_t NbkgTest, const TString& otherOpt = ""SplitMode=Random:!V""); prepare the training and test trees. void PrepareTrainingAndTestTree(const TCut& cut, Int_t Ntrain, Int_t Ntest = -1); prepare the training and test trees; kept for backward compatibility. void PrepareTrainingAndTestTree(const TCut& cut, const TString& splitOpt); prepare the training and test trees; -> same cuts for signal and background. void PrepareTrainingAndTestTree(TCut sigcut, TCut bkgcut, const TString& splitOpt); prepare the training and test trees. TMVA::MethodBase* BookMethod(TString theMethodName, TString methodTitle, TString theOption = """"); Book a classifier or regression method. TMVA::MethodBase* BookMethod(TMVA::Types::EMVA theMethod, TString methodTitle, TString theOption = """"); books MVA method; the option configuration string is custom for each MVA; the TString field ""theNameAppendix"" serves to define (and distinguish); several instances of a given MVA, eg, when one wants to compare the; performance of various configurations. TMVA::IMethod* GetMethod(const TString& title) const; returns pointer to MVA that corresponds to given method title. void WriteDataInformation(); put correlations of input data and a few (default + user; selected) transformations into the root file. void OptimizeAllMethods(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); iterates through all booked methods and sees if they use parameter tuning and if so..; does just that i.e. calls ""Method::Train()"" for different parameter setttings and; keeps in mind the ""optimal one""... and that's the one that will later on be used; in the main training loop. void TrainAllMethods(); iterates through all booked methods and calls training. void TestAllMethods(). void MakeClass(const TString& methodTitle = """") const; Print predefined help message of classifier; ite",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:407,Testability,test,testing,407,". TMVA::Factory. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Factory. class TMVA::Factory: public TMVA::Configurable. This is the main MVA steering class: it creates all MVA methods,; and guides them through the training, testing and evaluation; phases. Function Members (Methods); public:. virtual~Factory(); voidTObject::AbstractMethod(const char* method) const; voidAddBackgroundTestEvent(const vector<Double_t>& event, Double_t weight = 1.0); voidAddBackgroundTrainingEvent(const vector<Double_t>& event, Double_t weight = 1.0); voidAddBackgroundTree(TTree* background, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); voidAddBackgroundTree(TString datFileB, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); voidAddBackgroundTree(TTree* background, Double_t weight, const TString& treetype); voidAddCut(const TString& cut, const TString& className = """"); voidAddCut(const TCut& cut, const TString& className = """"); TMVA::DataSetInfo&AddDataSet(TMVA::DataSetInfo&); TMVA::DataSetInfo&AddDataSet(const TString&); voidAddEvent(const TString& className, TMVA::Types::ETreeType tt, const vector<Double_t>& event, Double_t weight); voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidAddRegressionTarget(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0); voidAddRegressionTree(TTree* tree, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); voidAddSignalTestEvent(const vector<Double_t>& event, Double_t weight = 1.0); voidAddSignalTrainingEvent(const vector<Double_t>& event, Double_t weight = 1.0); voidAddSignalTree(TTree* signal, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); voidAddSignalTree(TString datFileS, Do",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:12531,Testability,test,test,12531,"vate:. TMVA::DataInputHandler&DataInput(); TMVA::DataSetInfo&DefaultDataSetInfo(); voidGreetings(); voidSetInputTreesFromEventAssignTrees(); voidWriteDataInformation(). Data Members; public:. enum DataAssignType { kUndefined; kAssignTrees; kAssignEvents; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. Float_t*fATreeEventevent variables; Int_tfATreeTypetype of event (=classIndex); Float_tfATreeWeightweight of the event; TMVA::Types::EAnalysisTypefAnalysisType! the training type; TMVA::Factory::DataAssignTypefDataAssignType! flags for data assigning; TMVA::DataInputHandler*fDataInputHandler; TMVA::DataSetManager*fDataSetManagerDSMTEST; vector<TMVA::VariableTransformBase*>fDefaultTrfs! list of transformations on default DataSet; TStringfJobName! jobname, used as extension in weight file names; TMVA::Factory::MVectorfMethods! all MVA methods; TStringfOptions! option string given by construction (presently only ""V""); vector<TTree*>fTestAssignTree! for each class: tmp tree if user wants to assign the events directly; vector<TTree*>fTrainAssignTree! for each class: tmp tree if user wants to assign the events directly; TStringfTransformations! List of transformations to test; Bool_tfVerbose! verbose mode; static TFile*fgTargetFile! ROOT output file. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Factory(TString theJobName, TFile* theTargetFile, TString theOption = """"); standard constructor; jobname : this name will appear in all weight file names produced by the MVAs; theTargetFile : output ROOT file; the test tree and all evaluation plots; will be stored here; theOption : option string; currently: ""V"" for verbose. void Greetings(); print welcome message; options are: kLogoWelcomeMsg, kIsometricWelcomeMsg, kLeanWelco",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:12917,Testability,test,test,12917,"ssignTypefDataAssignType! flags for data assigning; TMVA::DataInputHandler*fDataInputHandler; TMVA::DataSetManager*fDataSetManagerDSMTEST; vector<TMVA::VariableTransformBase*>fDefaultTrfs! list of transformations on default DataSet; TStringfJobName! jobname, used as extension in weight file names; TMVA::Factory::MVectorfMethods! all MVA methods; TStringfOptions! option string given by construction (presently only ""V""); vector<TTree*>fTestAssignTree! for each class: tmp tree if user wants to assign the events directly; vector<TTree*>fTrainAssignTree! for each class: tmp tree if user wants to assign the events directly; TStringfTransformations! List of transformations to test; Bool_tfVerbose! verbose mode; static TFile*fgTargetFile! ROOT output file. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Factory(TString theJobName, TFile* theTargetFile, TString theOption = """"); standard constructor; jobname : this name will appear in all weight file names produced by the MVAs; theTargetFile : output ROOT file; the test tree and all evaluation plots; will be stored here; theOption : option string; currently: ""V"" for verbose. void Greetings(); print welcome message; options are: kLogoWelcomeMsg, kIsometricWelcomeMsg, kLeanWelcomeMsg. ~Factory( void ); destructor; delete fATreeEvent;. void DeleteAllMethods( void ); delete methods. void SetVerbose(Bool_t v = kTRUE). TMVA::DataSetInfo& AddDataSet( DataSetInfo &dsi ). TMVA::DataSetInfo& AddDataSet(const TString& ). TTree* CreateEventAssignTrees(const TString& name); create the data assignment tree (for event-wise data assignment by user). void AddSignalTrainingEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal training event. void AddSignalTestEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal testing event. void AddBackgroundTrainingEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal training event. void AddBackgroundTestEvent",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:13697,Testability,test,testing,13697,"ation; Factory(TString theJobName, TFile* theTargetFile, TString theOption = """"); standard constructor; jobname : this name will appear in all weight file names produced by the MVAs; theTargetFile : output ROOT file; the test tree and all evaluation plots; will be stored here; theOption : option string; currently: ""V"" for verbose. void Greetings(); print welcome message; options are: kLogoWelcomeMsg, kIsometricWelcomeMsg, kLeanWelcomeMsg. ~Factory( void ); destructor; delete fATreeEvent;. void DeleteAllMethods( void ); delete methods. void SetVerbose(Bool_t v = kTRUE). TMVA::DataSetInfo& AddDataSet( DataSetInfo &dsi ). TMVA::DataSetInfo& AddDataSet(const TString& ). TTree* CreateEventAssignTrees(const TString& name); create the data assignment tree (for event-wise data assignment by user). void AddSignalTrainingEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal training event. void AddSignalTestEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal testing event. void AddBackgroundTrainingEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal training event. void AddBackgroundTestEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal training event. void AddTrainingEvent(const TString& className, const vector<Double_t>& event, Double_t weight); add signal training event. void AddTestEvent(const TString& className, const vector<Double_t>& event, Double_t weight); add signal test event. void AddEvent(const TString& className, TMVA::Types::ETreeType tt, const vector<Double_t>& event, Double_t weight); add event; vector event : the order of values is: variables + targets + spectators. Bool_t UserAssignEvents(UInt_t clIndex). void SetInputTreesFromEventAssignTrees(); assign event-wise local trees to data set. void AddTree(TTree* tree, const TString& className, Double_t weight, const TCut& cut, const TString& treeType); number of signal events (used to compute significance). void AddTree(TTree* tree, c",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:14164,Testability,test,test,14164,"Msg, kLeanWelcomeMsg. ~Factory( void ); destructor; delete fATreeEvent;. void DeleteAllMethods( void ); delete methods. void SetVerbose(Bool_t v = kTRUE). TMVA::DataSetInfo& AddDataSet( DataSetInfo &dsi ). TMVA::DataSetInfo& AddDataSet(const TString& ). TTree* CreateEventAssignTrees(const TString& name); create the data assignment tree (for event-wise data assignment by user). void AddSignalTrainingEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal training event. void AddSignalTestEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal testing event. void AddBackgroundTrainingEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal training event. void AddBackgroundTestEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal training event. void AddTrainingEvent(const TString& className, const vector<Double_t>& event, Double_t weight); add signal training event. void AddTestEvent(const TString& className, const vector<Double_t>& event, Double_t weight); add signal test event. void AddEvent(const TString& className, TMVA::Types::ETreeType tt, const vector<Double_t>& event, Double_t weight); add event; vector event : the order of values is: variables + targets + spectators. Bool_t UserAssignEvents(UInt_t clIndex). void SetInputTreesFromEventAssignTrees(); assign event-wise local trees to data set. void AddTree(TTree* tree, const TString& className, Double_t weight, const TCut& cut, const TString& treeType); number of signal events (used to compute significance). void AddTree(TTree* tree, const TString& className, Double_t weight = 1.0, const TCut& cut = """", TMVA::Types::ETreeType tt = Types::kMaxTreeType). void AddSignalTree( TTree* signal, Double_t weight, Types::ETreeType treetype ); number of signal events (used to compute significance). void AddSignalTree(TString datFileS, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); add signal tree from text file. void AddSignalT",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:17931,Testability,test,test,17931," 0); user inserts target in data set info. void AddSpectator(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0); user inserts target in data set info. TMVA::DataSetInfo& DefaultDataSetInfo(); default creation. void SetInputVariables(vector<TString>* theVariables); fill input variables in data set. void SetSignalWeightExpression(const TString& variable). void SetBackgroundWeightExpression(const TString& variable). void SetWeightExpression(const TString& variable, const TString& className = """"); Log() << kWarning << DefaultDataSetInfo().GetNClasses() /*fClasses.size()*/ << Endl;. void SetCut(const TString& cut, const TString& className = """"). void SetCut(const TCut& cut, const TString& className = """"). void AddCut(const TString& cut, const TString& className = """"). void AddCut(const TCut& cut, const TString& className = """"). void PrepareTrainingAndTestTree(const TCut& cut, Int_t NsigTrain, Int_t NbkgTrain, Int_t NsigTest, Int_t NbkgTest, const TString& otherOpt = ""SplitMode=Random:!V""); prepare the training and test trees. void PrepareTrainingAndTestTree(const TCut& cut, Int_t Ntrain, Int_t Ntest = -1); prepare the training and test trees; kept for backward compatibility. void PrepareTrainingAndTestTree(const TCut& cut, const TString& splitOpt); prepare the training and test trees; -> same cuts for signal and background. void PrepareTrainingAndTestTree(TCut sigcut, TCut bkgcut, const TString& splitOpt); prepare the training and test trees. TMVA::MethodBase* BookMethod(TString theMethodName, TString methodTitle, TString theOption = """"); Book a classifier or regression method. TMVA::MethodBase* BookMethod(TMVA::Types::EMVA theMethod, TString methodTitle, TString theOption = """"); books MVA method; the option configuration string is custom for each MVA; the TString field ""theNameAppendix"" serves to define (and distinguish); several instances of a given MVA, eg, when one wants to compare the; performance of v",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:18050,Testability,test,test,18050," user inserts target in data set info. TMVA::DataSetInfo& DefaultDataSetInfo(); default creation. void SetInputVariables(vector<TString>* theVariables); fill input variables in data set. void SetSignalWeightExpression(const TString& variable). void SetBackgroundWeightExpression(const TString& variable). void SetWeightExpression(const TString& variable, const TString& className = """"); Log() << kWarning << DefaultDataSetInfo().GetNClasses() /*fClasses.size()*/ << Endl;. void SetCut(const TString& cut, const TString& className = """"). void SetCut(const TCut& cut, const TString& className = """"). void AddCut(const TString& cut, const TString& className = """"). void AddCut(const TCut& cut, const TString& className = """"). void PrepareTrainingAndTestTree(const TCut& cut, Int_t NsigTrain, Int_t NbkgTrain, Int_t NsigTest, Int_t NbkgTest, const TString& otherOpt = ""SplitMode=Random:!V""); prepare the training and test trees. void PrepareTrainingAndTestTree(const TCut& cut, Int_t Ntrain, Int_t Ntest = -1); prepare the training and test trees; kept for backward compatibility. void PrepareTrainingAndTestTree(const TCut& cut, const TString& splitOpt); prepare the training and test trees; -> same cuts for signal and background. void PrepareTrainingAndTestTree(TCut sigcut, TCut bkgcut, const TString& splitOpt); prepare the training and test trees. TMVA::MethodBase* BookMethod(TString theMethodName, TString methodTitle, TString theOption = """"); Book a classifier or regression method. TMVA::MethodBase* BookMethod(TMVA::Types::EMVA theMethod, TString methodTitle, TString theOption = """"); books MVA method; the option configuration string is custom for each MVA; the TString field ""theNameAppendix"" serves to define (and distinguish); several instances of a given MVA, eg, when one wants to compare the; performance of various configurations. TMVA::IMethod* GetMethod(const TString& title) const; returns pointer to MVA that corresponds to given method title. void WriteDataInformation(); put corr",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:18195,Testability,test,test,18195," fill input variables in data set. void SetSignalWeightExpression(const TString& variable). void SetBackgroundWeightExpression(const TString& variable). void SetWeightExpression(const TString& variable, const TString& className = """"); Log() << kWarning << DefaultDataSetInfo().GetNClasses() /*fClasses.size()*/ << Endl;. void SetCut(const TString& cut, const TString& className = """"). void SetCut(const TCut& cut, const TString& className = """"). void AddCut(const TString& cut, const TString& className = """"). void AddCut(const TCut& cut, const TString& className = """"). void PrepareTrainingAndTestTree(const TCut& cut, Int_t NsigTrain, Int_t NbkgTrain, Int_t NsigTest, Int_t NbkgTest, const TString& otherOpt = ""SplitMode=Random:!V""); prepare the training and test trees. void PrepareTrainingAndTestTree(const TCut& cut, Int_t Ntrain, Int_t Ntest = -1); prepare the training and test trees; kept for backward compatibility. void PrepareTrainingAndTestTree(const TCut& cut, const TString& splitOpt); prepare the training and test trees; -> same cuts for signal and background. void PrepareTrainingAndTestTree(TCut sigcut, TCut bkgcut, const TString& splitOpt); prepare the training and test trees. TMVA::MethodBase* BookMethod(TString theMethodName, TString methodTitle, TString theOption = """"); Book a classifier or regression method. TMVA::MethodBase* BookMethod(TMVA::Types::EMVA theMethod, TString methodTitle, TString theOption = """"); books MVA method; the option configuration string is custom for each MVA; the TString field ""theNameAppendix"" serves to define (and distinguish); several instances of a given MVA, eg, when one wants to compare the; performance of various configurations. TMVA::IMethod* GetMethod(const TString& title) const; returns pointer to MVA that corresponds to given method title. void WriteDataInformation(); put correlations of input data and a few (default + user; selected) transformations into the root file. void OptimizeAllMethods(TString fomType = ""ROCIntegral"",",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:18356,Testability,test,test,18356,"ring& variable). void SetWeightExpression(const TString& variable, const TString& className = """"); Log() << kWarning << DefaultDataSetInfo().GetNClasses() /*fClasses.size()*/ << Endl;. void SetCut(const TString& cut, const TString& className = """"). void SetCut(const TCut& cut, const TString& className = """"). void AddCut(const TString& cut, const TString& className = """"). void AddCut(const TCut& cut, const TString& className = """"). void PrepareTrainingAndTestTree(const TCut& cut, Int_t NsigTrain, Int_t NbkgTrain, Int_t NsigTest, Int_t NbkgTest, const TString& otherOpt = ""SplitMode=Random:!V""); prepare the training and test trees. void PrepareTrainingAndTestTree(const TCut& cut, Int_t Ntrain, Int_t Ntest = -1); prepare the training and test trees; kept for backward compatibility. void PrepareTrainingAndTestTree(const TCut& cut, const TString& splitOpt); prepare the training and test trees; -> same cuts for signal and background. void PrepareTrainingAndTestTree(TCut sigcut, TCut bkgcut, const TString& splitOpt); prepare the training and test trees. TMVA::MethodBase* BookMethod(TString theMethodName, TString methodTitle, TString theOption = """"); Book a classifier or regression method. TMVA::MethodBase* BookMethod(TMVA::Types::EMVA theMethod, TString methodTitle, TString theOption = """"); books MVA method; the option configuration string is custom for each MVA; the TString field ""theNameAppendix"" serves to define (and distinguish); several instances of a given MVA, eg, when one wants to compare the; performance of various configurations. TMVA::IMethod* GetMethod(const TString& title) const; returns pointer to MVA that corresponds to given method title. void WriteDataInformation(); put correlations of input data and a few (default + user; selected) transformations into the root file. void OptimizeAllMethods(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); iterates through all booked methods and sees if they use parameter tuning and if so..; does just that i.e. c",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:19706,Testability,test,test,19706,"uration string is custom for each MVA; the TString field ""theNameAppendix"" serves to define (and distinguish); several instances of a given MVA, eg, when one wants to compare the; performance of various configurations. TMVA::IMethod* GetMethod(const TString& title) const; returns pointer to MVA that corresponds to given method title. void WriteDataInformation(); put correlations of input data and a few (default + user; selected) transformations into the root file. void OptimizeAllMethods(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); iterates through all booked methods and sees if they use parameter tuning and if so..; does just that i.e. calls ""Method::Train()"" for different parameter setttings and; keeps in mind the ""optimal one""... and that's the one that will later on be used; in the main training loop. void TrainAllMethods(); iterates through all booked methods and calls training. void TestAllMethods(). void MakeClass(const TString& methodTitle = """") const; Print predefined help message of classifier; iterate over methods and test. void PrintHelpMessage(const TString& methodTitle = """") const; Print predefined help message of classifier; iterate over methods and test. void EvaluateAllVariables(TString options = """"); iterates over all MVA input varables and evaluates them. void EvaluateAllMethods( void ); iterates over all MVAs that have been booked, and calls their evaluation methods. const char* GetName() const; { return ""Factory""; }. void AddRegressionTree(TTree* tree, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); special case: regression. void AddRegressionTarget(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0). MethodBase* BookMethod(TString theMethodName, TString methodTitle, TString theOption = """"). void OptimizeAllMethodsForClassification(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); { OptimizeAllMethods(fomType,fitType); }. void",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:19844,Testability,test,test,19844,"iven MVA, eg, when one wants to compare the; performance of various configurations. TMVA::IMethod* GetMethod(const TString& title) const; returns pointer to MVA that corresponds to given method title. void WriteDataInformation(); put correlations of input data and a few (default + user; selected) transformations into the root file. void OptimizeAllMethods(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); iterates through all booked methods and sees if they use parameter tuning and if so..; does just that i.e. calls ""Method::Train()"" for different parameter setttings and; keeps in mind the ""optimal one""... and that's the one that will later on be used; in the main training loop. void TrainAllMethods(); iterates through all booked methods and calls training. void TestAllMethods(). void MakeClass(const TString& methodTitle = """") const; Print predefined help message of classifier; iterate over methods and test. void PrintHelpMessage(const TString& methodTitle = """") const; Print predefined help message of classifier; iterate over methods and test. void EvaluateAllVariables(TString options = """"); iterates over all MVA input varables and evaluates them. void EvaluateAllMethods( void ); iterates over all MVAs that have been booked, and calls their evaluation methods. const char* GetName() const; { return ""Factory""; }. void AddRegressionTree(TTree* tree, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); special case: regression. void AddRegressionTarget(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0). MethodBase* BookMethod(TString theMethodName, TString methodTitle, TString theOption = """"). void OptimizeAllMethodsForClassification(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); { OptimizeAllMethods(fomType,fitType); }. void OptimizeAllMethodsForRegression(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); { OptimizeAllMethods(fomType,fitType); }",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:373,Usability,guid,guides,373,". TMVA::Factory. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Factory. class TMVA::Factory: public TMVA::Configurable. This is the main MVA steering class: it creates all MVA methods,; and guides them through the training, testing and evaluation; phases. Function Members (Methods); public:. virtual~Factory(); voidTObject::AbstractMethod(const char* method) const; voidAddBackgroundTestEvent(const vector<Double_t>& event, Double_t weight = 1.0); voidAddBackgroundTrainingEvent(const vector<Double_t>& event, Double_t weight = 1.0); voidAddBackgroundTree(TTree* background, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); voidAddBackgroundTree(TString datFileB, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); voidAddBackgroundTree(TTree* background, Double_t weight, const TString& treetype); voidAddCut(const TString& cut, const TString& className = """"); voidAddCut(const TCut& cut, const TString& className = """"); TMVA::DataSetInfo&AddDataSet(TMVA::DataSetInfo&); TMVA::DataSetInfo&AddDataSet(const TString&); voidAddEvent(const TString& className, TMVA::Types::ETreeType tt, const vector<Double_t>& event, Double_t weight); voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidAddRegressionTarget(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0); voidAddRegressionTree(TTree* tree, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); voidAddSignalTestEvent(const vector<Double_t>& event, Double_t weight = 1.0); voidAddSignalTrainingEvent(const vector<Double_t>& event, Double_t weight = 1.0); voidAddSignalTree(TTree* signal, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); voidAddSignalTree(TString datFileS, Do",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__FitterBase.html:530,Availability,avail,available,530,". TMVA::FitterBase. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::FitterBase. class TMVA::FitterBase: public TMVA::Configurable. FitterBase. Baseclass for TMVA fitters. Also defines generalised fitting interface. Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~FitterBase(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tEstimatorFunction(vector<Double_t>& parameters); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual T",MatchSource.WIKI,root/html532/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__FitterBase.html
https://root.cern/root/html532/TMVA__FitterBase.html:1754,Availability,error,error,1754,"virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tEstimatorFunction(vector<Double_t>& parameters); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TMVA::IFitterTarget&GetFitterTarget() const; virtual const char*TObject::GetIconName() const; virtual const char*GetName() const; Int_tGetNpars() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&TMVA::Configurable::GetOptions() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() con",MatchSource.WIKI,root/html532/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__FitterBase.html
https://root.cern/root/html532/TMVA__FitterBase.html:1838,Availability,error,error,1838,"ons() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tEstimatorFunction(vector<Double_t>& parameters); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TMVA::IFitterTarget&GetFitterTarget() const; virtual const char*TObject::GetIconName() const; virtual const char*GetName() const; Int_tGetNpars() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&TMVA::Configurable::GetOptions() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash(",MatchSource.WIKI,root/html532/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__FitterBase.html
https://root.cern/root/html532/TMVA__FitterBase.html:385,Integrability,interface,interface,385,". TMVA::FitterBase. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::FitterBase. class TMVA::FitterBase: public TMVA::Configurable. FitterBase. Baseclass for TMVA fitters. Also defines generalised fitting interface. Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~FitterBase(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tEstimatorFunction(vector<Double_t>& parameters); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual T",MatchSource.WIKI,root/html532/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__FitterBase.html
https://root.cern/root/html532/TMVA__FitterBase.html:7043,Integrability,interface,interface,7043,"e::WriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidDeclareOptions(); virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringfClassNameremove TMVA:: from TObject name; TMVA::IFitterTarget&fFitterTargetpointer to target of fitting procedure; TMVA::MsgLogger*fLoggermessage logger; Int_tfNparsnumber of parameters; const vector<TMVA::Interval*>fRangesallowed intervals. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Double_t Run(); estimator function interface for fitting. Double_t EstimatorFunction(vector<Double_t>& parameters); estimator function interface for fitting. virtual ~FitterBase(); {}. Double_t Run(). IFitterTarget& GetFitterTarget() const; { return fFitterTarget; }. Int_t GetNpars() const; accessor. { return fNpars; }. const char* GetName() const; remove namespace in name. { return fClassName; }. void DeclareOptions(); need to implement option declaration. » Author: Andreas Hoecker, Peter Speckmayer, Joerg Stelzer, Helge Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: FitterBase.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__FitterBase.html
https://root.cern/root/html532/TMVA__FitterBase.html:7143,Integrability,interface,interface,7143,"e::WriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidDeclareOptions(); virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringfClassNameremove TMVA:: from TObject name; TMVA::IFitterTarget&fFitterTargetpointer to target of fitting procedure; TMVA::MsgLogger*fLoggermessage logger; Int_tfNparsnumber of parameters; const vector<TMVA::Interval*>fRangesallowed intervals. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Double_t Run(); estimator function interface for fitting. Double_t EstimatorFunction(vector<Double_t>& parameters); estimator function interface for fitting. virtual ~FitterBase(); {}. Double_t Run(). IFitterTarget& GetFitterTarget() const; { return fFitterTarget; }. Int_t GetNpars() const; accessor. { return fNpars; }. const char* GetName() const; remove namespace in name. { return fClassName; }. void DeclareOptions(); need to implement option declaration. » Author: Andreas Hoecker, Peter Speckmayer, Joerg Stelzer, Helge Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: FitterBase.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__FitterBase.html
https://root.cern/root/html532/TMVA__FitterBase.html:7300,Security,access,accessor,7300,"e::WriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidDeclareOptions(); virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringfClassNameremove TMVA:: from TObject name; TMVA::IFitterTarget&fFitterTargetpointer to target of fitting procedure; TMVA::MsgLogger*fLoggermessage logger; Int_tfNparsnumber of parameters; const vector<TMVA::Interval*>fRangesallowed intervals. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Double_t Run(); estimator function interface for fitting. Double_t EstimatorFunction(vector<Double_t>& parameters); estimator function interface for fitting. virtual ~FitterBase(); {}. Double_t Run(). IFitterTarget& GetFitterTarget() const; { return fFitterTarget; }. Int_t GetNpars() const; accessor. { return fNpars; }. const char* GetName() const; remove namespace in name. { return fClassName; }. void DeclareOptions(); need to implement option declaration. » Author: Andreas Hoecker, Peter Speckmayer, Joerg Stelzer, Helge Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: FitterBase.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__FitterBase.html
https://root.cern/root/html532/TMVA__FitterBase.html:6821,Testability,log,logger,6821,"Int_t bufsize = 0) const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidDeclareOptions(); virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringfClassNameremove TMVA:: from TObject name; TMVA::IFitterTarget&fFitterTargetpointer to target of fitting procedure; TMVA::MsgLogger*fLoggermessage logger; Int_tfNparsnumber of parameters; const vector<TMVA::Interval*>fRangesallowed intervals. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Double_t Run(); estimator function interface for fitting. Double_t EstimatorFunction(vector<Double_t>& parameters); estimator function interface for fitting. virtual ~FitterBase(); {}. Double_t Run(). IFitterTarget& GetFitterTarget() const; { return fFitterTarget; }. Int_t GetNpars() const; accessor. { return fNpars; }. const char* GetName() const; remove namespace in name. { return fClassName; }. void DeclareOptions(); need to implement option declaration. » Author: Andreas Hoecker, Peter Speckmayer, Joerg Stelzer, Helge Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: FitterBase.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT ",MatchSource.WIKI,root/html532/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__FitterBase.html
https://root.cern/root/html532/TMVA__GeneticAlgorithm.html:4866,Energy Efficiency,reduce,reduce,4866,"different individuals of; the population. this function calls implicitly (many times) the ""fitnessFunction"" which; has been overridden by the user. void Evolution(); this function is called from ""init"" and controls the evolution of the; individuals.; the function can be overridden to change the parameters for mutation rate; sexual reproduction and so on. Double_t SpreadControl(Int_t steps, Int_t ofSteps, Double_t factor); this function provides the ability to change the stepSize of a mutation according to; the success of the last generations. Parameters:; int ofSteps : = if OF the number of STEPS given in this variable (ofSteps); int successSteps : >sucessSteps Generations could improve the result; double factor : than multiply the stepSize ( spread ) by this factor; (if ofSteps == successSteps nothing is changed, if ofSteps < successSteps, the spread; is divided by the factor). using this function one can increase the stepSize of the mutation when we have; good success (to pass fast through the easy phase-space) and reduce the stepSize; if we are in a difficult ""territory"" of the phase-space. Bool_t HasConverged(Int_t steps = 10, Double_t ratio = 0.1); gives back true if the last ""steps"" steps have lead to an improvement of the; ""fitness"" of the ""individuals"" of at least ""improvement"". this gives a simple measure of if the fitness of the individuals is; converging and no major improvement is to be expected soon. GeneticAlgorithm(TMVA::IFitterTarget& target, Int_t populationSize, const vector<TMVA::Interval*>& ranges, UInt_t seed = 0). GeneticPopulation& GetGeneticPopulation(); { return fPopulation; }. Double_t GetSpread() const; { return fSpread; }. void SetSpread(Double_t s); { fSpread = s; }. void SetMakeCopies(Bool_t s); { fMakeCopies = s; }. Bool_t GetMakeCopies(); { return fMakeCopies; }. » Author: Peter Speckmayer » Copyright (c) 2005: *; » Last changed: root/tmva $Id: GeneticAlgorithm.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; ",MatchSource.WIKI,root/html532/TMVA__GeneticAlgorithm.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticAlgorithm.html
https://root.cern/root/html532/TMVA__GeneticAlgorithm.html:2700,Modifiability,variab,variable,2700,"rTarget&fFitterTargetthe fitter target; Double_tfLastResultremembers the last obtained result (for internal use); TMVA::MsgLogger*fLoggermessage logger; Bool_tfMakeCopiesif true, the population will make copies of the first individuals; Bool_tfMirrornew values for mutation are mirror-mapped if outside of constraints; TMVA::GeneticPopulationfPopulationcontains and controls the ""individual""; Int_tfPopulationSizethe size of the population; const vector<TMVA::Interval*>&fRangesparameter ranges; Double_tfSpreadregulates the spread of the value change at mutation (sigma); deque<Int_t>fSuccessListto adjust the stepSize . Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; GeneticAlgorithm(TMVA::IFitterTarget& target, Int_t populationSize, const vector<TMVA::Interval*>& ranges, UInt_t seed = 0); Constructor; Parameters:; int populationSize : defines the number of ""Individuals"" which are created and tested; within one Generation (Iteration of the Evolution); vector<TMVA::Interval*> ranges : Interval holds the information of an interval, where the GetMin; gets the low and GetMax gets the high constraint of the variable; the size of ""ranges"" is the number of coefficients which are optimised; Purpose:; Creates a random population with individuals of the size ranges.size(). ~GeneticAlgorithm(); destructor; deletes fLogger. void Init(); calls evolution, but if it is not the first time.; If it's the first time, the random population created by the; constructor is still not evaluated, .. therefore we wait for the; second time init is called. Double_t NewFitness(Double_t oldValue, Double_t newValue); if the ""fitnessFunction"" is called multiple times for one set of; factors (because i.e. each event of a TTree has to be assessed with; each set of Factors proposed by the Genetic Algorithm) the value; of the current calculation has to be added(? or else) to the value; obtained up to now.; example: some chi-square is calculated for every event,; afte",MatchSource.WIKI,root/html532/TMVA__GeneticAlgorithm.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticAlgorithm.html
https://root.cern/root/html532/TMVA__GeneticAlgorithm.html:4451,Modifiability,variab,variable,4451,"event the new chi-square (newValue) has to be simply; added to the oldValue. this function has to be overridden eventually; it might contain only the following return statement.; return oldValue + newValue;. Double_t CalculateFitness(); starts the evaluation of the fitness of all different individuals of; the population. this function calls implicitly (many times) the ""fitnessFunction"" which; has been overridden by the user. void Evolution(); this function is called from ""init"" and controls the evolution of the; individuals.; the function can be overridden to change the parameters for mutation rate; sexual reproduction and so on. Double_t SpreadControl(Int_t steps, Int_t ofSteps, Double_t factor); this function provides the ability to change the stepSize of a mutation according to; the success of the last generations. Parameters:; int ofSteps : = if OF the number of STEPS given in this variable (ofSteps); int successSteps : >sucessSteps Generations could improve the result; double factor : than multiply the stepSize ( spread ) by this factor; (if ofSteps == successSteps nothing is changed, if ofSteps < successSteps, the spread; is divided by the factor). using this function one can increase the stepSize of the mutation when we have; good success (to pass fast through the easy phase-space) and reduce the stepSize; if we are in a difficult ""territory"" of the phase-space. Bool_t HasConverged(Int_t steps = 10, Double_t ratio = 0.1); gives back true if the last ""steps"" steps have lead to an improvement of the; ""fitness"" of the ""individuals"" of at least ""improvement"". this gives a simple measure of if the fitness of the individuals is; converging and no major improvement is to be expected soon. GeneticAlgorithm(TMVA::IFitterTarget& target, Int_t populationSize, const vector<TMVA::Interval*>& ranges, UInt_t seed = 0). GeneticPopulation& GetGeneticPopulation(); { return fPopulation; }. Double_t GetSpread() const; { return fSpread; }. void SetSpread(Double_t s); { fSpread = s",MatchSource.WIKI,root/html532/TMVA__GeneticAlgorithm.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticAlgorithm.html
https://root.cern/root/html532/TMVA__GeneticAlgorithm.html:1688,Testability,log,logger,1688,"pies(); Double_tGetSpread() const; virtual Bool_tHasConverged(Int_t steps = 10, Double_t ratio = 0.1); voidInit(); virtual TClass*IsA() const; virtual Double_tNewFitness(Double_t oldValue, Double_t newValue); voidSetMakeCopies(Bool_t s); voidSetSpread(Double_t s); virtual voidShowMembers(TMemberInspector& insp); virtual Double_tSpreadControl(Int_t steps, Int_t ofSteps, Double_t factor); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). protected:. TMVA::MsgLogger&Log() const. Data Members; public:. Int_tfConvCounterconverging? ... keeps track of the number of improvements. protected:. Double_tfBestFitness; Double_tfConvValuekeeps track of the quantity of improvement; Bool_tfFirstTimeif true its the first time, so no evolution yet; TMVA::IFitterTarget&fFitterTargetthe fitter target; Double_tfLastResultremembers the last obtained result (for internal use); TMVA::MsgLogger*fLoggermessage logger; Bool_tfMakeCopiesif true, the population will make copies of the first individuals; Bool_tfMirrornew values for mutation are mirror-mapped if outside of constraints; TMVA::GeneticPopulationfPopulationcontains and controls the ""individual""; Int_tfPopulationSizethe size of the population; const vector<TMVA::Interval*>&fRangesparameter ranges; Double_tfSpreadregulates the spread of the value change at mutation (sigma); deque<Int_t>fSuccessListto adjust the stepSize . Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; GeneticAlgorithm(TMVA::IFitterTarget& target, Int_t populationSize, const vector<TMVA::Interval*>& ranges, UInt_t seed = 0); Constructor; Parameters:; int populationSize : defines the number of ""Individuals"" which are created and tested; within one Generation (Iteration of the Evolution); vector<TMVA::Interval*> ranges : Interval holds the information of an interval, where the GetMin; gets the low and GetMax gets the high constraint of the variable; the size of ""ranges"" is the number of coefficients which are op",MatchSource.WIKI,root/html532/TMVA__GeneticAlgorithm.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticAlgorithm.html
https://root.cern/root/html532/TMVA__GeneticAlgorithm.html:2486,Testability,test,tested,2486,"rTarget&fFitterTargetthe fitter target; Double_tfLastResultremembers the last obtained result (for internal use); TMVA::MsgLogger*fLoggermessage logger; Bool_tfMakeCopiesif true, the population will make copies of the first individuals; Bool_tfMirrornew values for mutation are mirror-mapped if outside of constraints; TMVA::GeneticPopulationfPopulationcontains and controls the ""individual""; Int_tfPopulationSizethe size of the population; const vector<TMVA::Interval*>&fRangesparameter ranges; Double_tfSpreadregulates the spread of the value change at mutation (sigma); deque<Int_t>fSuccessListto adjust the stepSize . Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; GeneticAlgorithm(TMVA::IFitterTarget& target, Int_t populationSize, const vector<TMVA::Interval*>& ranges, UInt_t seed = 0); Constructor; Parameters:; int populationSize : defines the number of ""Individuals"" which are created and tested; within one Generation (Iteration of the Evolution); vector<TMVA::Interval*> ranges : Interval holds the information of an interval, where the GetMin; gets the low and GetMax gets the high constraint of the variable; the size of ""ranges"" is the number of coefficients which are optimised; Purpose:; Creates a random population with individuals of the size ranges.size(). ~GeneticAlgorithm(); destructor; deletes fLogger. void Init(); calls evolution, but if it is not the first time.; If it's the first time, the random population created by the; constructor is still not evaluated, .. therefore we wait for the; second time init is called. Double_t NewFitness(Double_t oldValue, Double_t newValue); if the ""fitnessFunction"" is called multiple times for one set of; factors (because i.e. each event of a TTree has to be assessed with; each set of Factors proposed by the Genetic Algorithm) the value; of the current calculation has to be added(? or else) to the value; obtained up to now.; example: some chi-square is calculated for every event,; afte",MatchSource.WIKI,root/html532/TMVA__GeneticAlgorithm.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticAlgorithm.html
https://root.cern/root/html532/TMVA__GeneticAlgorithm.html:3598,Usability,simpl,simply,3598,"MVA::Interval*> ranges : Interval holds the information of an interval, where the GetMin; gets the low and GetMax gets the high constraint of the variable; the size of ""ranges"" is the number of coefficients which are optimised; Purpose:; Creates a random population with individuals of the size ranges.size(). ~GeneticAlgorithm(); destructor; deletes fLogger. void Init(); calls evolution, but if it is not the first time.; If it's the first time, the random population created by the; constructor is still not evaluated, .. therefore we wait for the; second time init is called. Double_t NewFitness(Double_t oldValue, Double_t newValue); if the ""fitnessFunction"" is called multiple times for one set of; factors (because i.e. each event of a TTree has to be assessed with; each set of Factors proposed by the Genetic Algorithm) the value; of the current calculation has to be added(? or else) to the value; obtained up to now.; example: some chi-square is calculated for every event,; after every event the new chi-square (newValue) has to be simply; added to the oldValue. this function has to be overridden eventually; it might contain only the following return statement.; return oldValue + newValue;. Double_t CalculateFitness(); starts the evaluation of the fitness of all different individuals of; the population. this function calls implicitly (many times) the ""fitnessFunction"" which; has been overridden by the user. void Evolution(); this function is called from ""init"" and controls the evolution of the; individuals.; the function can be overridden to change the parameters for mutation rate; sexual reproduction and so on. Double_t SpreadControl(Int_t steps, Int_t ofSteps, Double_t factor); this function provides the ability to change the stepSize of a mutation according to; the success of the last generations. Parameters:; int ofSteps : = if OF the number of STEPS given in this variable (ofSteps); int successSteps : >sucessSteps Generations could improve the result; double factor ",MatchSource.WIKI,root/html532/TMVA__GeneticAlgorithm.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticAlgorithm.html
https://root.cern/root/html532/TMVA__GeneticAlgorithm.html:5154,Usability,simpl,simple,5154,"lution(); this function is called from ""init"" and controls the evolution of the; individuals.; the function can be overridden to change the parameters for mutation rate; sexual reproduction and so on. Double_t SpreadControl(Int_t steps, Int_t ofSteps, Double_t factor); this function provides the ability to change the stepSize of a mutation according to; the success of the last generations. Parameters:; int ofSteps : = if OF the number of STEPS given in this variable (ofSteps); int successSteps : >sucessSteps Generations could improve the result; double factor : than multiply the stepSize ( spread ) by this factor; (if ofSteps == successSteps nothing is changed, if ofSteps < successSteps, the spread; is divided by the factor). using this function one can increase the stepSize of the mutation when we have; good success (to pass fast through the easy phase-space) and reduce the stepSize; if we are in a difficult ""territory"" of the phase-space. Bool_t HasConverged(Int_t steps = 10, Double_t ratio = 0.1); gives back true if the last ""steps"" steps have lead to an improvement of the; ""fitness"" of the ""individuals"" of at least ""improvement"". this gives a simple measure of if the fitness of the individuals is; converging and no major improvement is to be expected soon. GeneticAlgorithm(TMVA::IFitterTarget& target, Int_t populationSize, const vector<TMVA::Interval*>& ranges, UInt_t seed = 0). GeneticPopulation& GetGeneticPopulation(); { return fPopulation; }. Double_t GetSpread() const; { return fSpread; }. void SetSpread(Double_t s); { fSpread = s; }. void SetMakeCopies(Bool_t s); { fMakeCopies = s; }. Bool_t GetMakeCopies(); { return fMakeCopies; }. » Author: Peter Speckmayer » Copyright (c) 2005: *; » Last changed: root/tmva $Id: GeneticAlgorithm.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__GeneticAlgorithm.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticAlgorithm.html
https://root.cern/root/html532/TMVA__GeneticFitter.html:1601,Availability,error,error,1601,"t::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tTMVA::FitterBase::EstimatorFunction(vector<Double_t>& parameters); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::GeneticFitterGeneticFitter(TMVA::IFitterTarget& target, const TString& name, const vector<TMVA::Interval*>& ranges, const TString& theOption); const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TMVA::IFitterTarget&TMVA::FitterBase::GetFitterTarget() const; virtual const char*TObject::GetIconName() const; virtual const char*TMVA::FitterBase::GetName() const; Int_tTMVA::FitterBase::GetNpars() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject:",MatchSource.WIKI,root/html532/TMVA__GeneticFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticFitter.html
https://root.cern/root/html532/TMVA__GeneticFitter.html:1685,Availability,error,error,1685,"c TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tTMVA::FitterBase::EstimatorFunction(vector<Double_t>& parameters); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::GeneticFitterGeneticFitter(TMVA::IFitterTarget& target, const TString& name, const vector<TMVA::Interval*>& ranges, const TString& theOption); const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TMVA::IFitterTarget&TMVA::FitterBase::GetFitterTarget() const; virtual const char*TObject::GetIconName() const; virtual const char*TMVA::FitterBase::GetName() const; Int_tTMVA::FitterBase::GetNpars() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&TMVA::C",MatchSource.WIKI,root/html532/TMVA__GeneticFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticFitter.html
https://root.cern/root/html532/TMVA__GeneticFitter.html:8899,Deployability,configurat,configuration,8899,"Nstepsconvergence criteria: if no improvements > fConvCrit was achieved within the last fNsteps: cycle has ""converged""; Int_tfPopSizenumber of individuals to start with; Double_tfSC_factor... with fSC_factor; if there were less improvements: divide by that factor; if there were exactly fSC_rate improvements, dont change anything; Int_tfSC_rate... fSC_rate improvements, than multiply the sigma of the gaussion which defines how the random numbers are generated ...; Int_tfSC_stepsregulates how strong the mutations for the coordinates are: if within fSC_steps there were more than...; Int_tfSaveBestFromCyclestore the best individuals from one cycle (these are included as ""hints"" in the last cycle of GA calculation); Int_tfSaveBestFromGenerationstore the best individuals from one generation (these are included as ""hints"" in the last cycle of GA calculation); UInt_tfSeedSeed for the random generator (0 takes random seeds); Bool_tfTrimtake care, that the number of individuals is less fPopSize (trimming is done after the fitness of the individuals is assessed). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; GeneticFitter(TMVA::IFitterTarget& target, const TString& name, const vector<TMVA::Interval*>& ranges, const TString& theOption); constructor. void DeclareOptions(); declare GA options. void SetParameters(Int_t cycles, Int_t nsteps, Int_t popSize, Int_t SC_steps, Int_t SC_rate, Double_t SC_factor, Double_t convCrit); set GA configuration parameters. Double_t Run(vector<Double_t>& pars); Execute fitting. virtual ~GeneticFitter(); {}. Double_t NewFitness(Double_t oldF, Double_t newF); { return oldF + newF; }. » Author: Peter Speckmayer » Copyright (c) 2005: *; » Last changed: root/tmva $Id: GeneticFitter.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__GeneticFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticFitter.html
https://root.cern/root/html532/TMVA__GeneticFitter.html:8899,Modifiability,config,configuration,8899,"Nstepsconvergence criteria: if no improvements > fConvCrit was achieved within the last fNsteps: cycle has ""converged""; Int_tfPopSizenumber of individuals to start with; Double_tfSC_factor... with fSC_factor; if there were less improvements: divide by that factor; if there were exactly fSC_rate improvements, dont change anything; Int_tfSC_rate... fSC_rate improvements, than multiply the sigma of the gaussion which defines how the random numbers are generated ...; Int_tfSC_stepsregulates how strong the mutations for the coordinates are: if within fSC_steps there were more than...; Int_tfSaveBestFromCyclestore the best individuals from one cycle (these are included as ""hints"" in the last cycle of GA calculation); Int_tfSaveBestFromGenerationstore the best individuals from one generation (these are included as ""hints"" in the last cycle of GA calculation); UInt_tfSeedSeed for the random generator (0 takes random seeds); Bool_tfTrimtake care, that the number of individuals is less fPopSize (trimming is done after the fitness of the individuals is assessed). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; GeneticFitter(TMVA::IFitterTarget& target, const TString& name, const vector<TMVA::Interval*>& ranges, const TString& theOption); constructor. void DeclareOptions(); declare GA options. void SetParameters(Int_t cycles, Int_t nsteps, Int_t popSize, Int_t SC_steps, Int_t SC_rate, Double_t SC_factor, Double_t convCrit); set GA configuration parameters. Double_t Run(vector<Double_t>& pars); Execute fitting. virtual ~GeneticFitter(); {}. Double_t NewFitness(Double_t oldF, Double_t newF); { return oldF + newF; }. » Author: Peter Speckmayer » Copyright (c) 2005: *; » Last changed: root/tmva $Id: GeneticFitter.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__GeneticFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticFitter.html
https://root.cern/root/html532/TMVA__GeneticFitter.html:7120,Testability,log,logger,7120,"tream& o, const TString& prefix) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&TMVA::FitterBase::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. virtual voidDeclareOptions(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringTMVA::FitterBase::fClassNameremove TMVA:: from TObject name; TMVA::IFitterTarget&TMVA::FitterBase::fFitterTargetpointer to target of fitting procedure; TMVA::MsgLogger*TMVA::FitterBase::fLoggermessage logger; Int_tTMVA::FitterBase::fNparsnumber of parameters; const vector<TMVA::Interval*>TMVA::FitterBase::fRangesallowed intervals. private:. Double_tfConvCritimprovements bigger than fConvCrit are counted as ""improvement""; Int_tfCyclesnumber of (nearly) independent calculation cycles; Int_tfNstepsconvergence criteria: if no improvements > fConvCrit was achieved within the last fNsteps: cycle has ""converged""; Int_tfPopSizenumber of individuals to start with; Double_tfSC_factor... with fSC_factor; if there were less improvements: divide by that factor; if there were exactly fSC_rate improvements, dont change anything; Int_tfSC_rate... fSC_rate improvements, than multiply the sigma of the gaussion which defines how the random numbers are generated ...; Int_tfSC_stepsregulates how strong the mutations for the coordinates are: if within fSC_steps there were more than...; Int_tfSaveBestFromCyclestore the best individuals from one cycle (these are inclu",MatchSource.WIKI,root/html532/TMVA__GeneticFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticFitter.html
https://root.cern/root/html532/TMVA__GeneticGenes.html:308,Integrability,interface,interface,308,. TMVA::GeneticGenes. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::GeneticGenes. class TMVA::GeneticGenes. Cut optimisation interface class for genetic algorithm. Function Members (Methods); public:. virtual~GeneticGenes(); static TClass*Class(); TMVA::GeneticGenesGeneticGenes(); TMVA::GeneticGenesGeneticGenes(vector<Double_t>& f); TMVA::GeneticGenesGeneticGenes(const TMVA::GeneticGenes&); vector<Double_t>&GetFactors(); Double_tGetFitness() const; virtual TClass*IsA() const; TMVA::GeneticGenes&operator=(const TMVA::GeneticGenes&); voidSetFitness(Double_t fitness); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). Data Members; private:. vector<Double_t>fFactorsstores the factors (coefficients) of one individual; Double_tfFitness. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; GeneticGenes(vector<Double_t>& f); Constructor:; set the factors of this individual. GeneticGenes(); {}. GeneticGenes(vector<Double_t>& f). virtual ~GeneticGenes(); {}. std::vector<Double_t>& GetFactors(); { return fFactors; }. void SetFitness(Double_t fitness); { fFitness = fitness; }. Double_t GetFitness() const; { return fFitness; }. » Author: Peter Speckmayer » Copyright (c) 2005: *; » Last changed: root/tmva $Id: GeneticGenes.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ,MatchSource.WIKI,root/html532/TMVA__GeneticGenes.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticGenes.html
https://root.cern/root/html532/TMVA__GeneticPopulation.html:5430,Modifiability,variab,variables,5430,"lIndex = -1); make a little printout to the stream ""out"" of the individuals up to index ""untilIndex""; this means, .. write out the best ""untilIndex"" individuals. TH1F* VariableDistribution(Int_t varNumber, Int_t bins, Int_t min, Int_t max); give back a histogram with the distribution of the coefficients; parameters:; int bins : number of bins of the histogram; int min : histogram minimum; int max : maximum value of the histogram. vector<Double_t> VariableDistribution(Int_t varNumber); gives back all the values of coefficient ""varNumber"" of the current generation. void AddPopulation( GeneticPopulation *strangers ); add another population (strangers) to the one of this GeneticPopulation. void AddPopulation( GeneticPopulation &strangers ); add another population (strangers) to the one of this GeneticPopulation. void TrimPopulation(); trim the population to the predefined size. void GiveHint(vector<Double_t>& hint, Double_t fitness = 0); add an individual (a set of variables) to the population; if there is a set of variables which is known to perform good, they can be given as a hint to the population. void Sort(); sort the genepool according to the fitness of the individuals. GeneticPopulation(const vector<TMVA::Interval*>& ranges, Int_t size, UInt_t seed = 0). Int_t GetPopulationSize() const; { return fGenePool.size(); }. Double_t GetFitness() const; { return fGenePool.size()>0? fGenePool[0].GetFitness() : 0; }. const std::vector<TMVA::GeneticGenes>& GetGenePool() const; { return fGenePool; }. const std::vector<TMVA::GeneticRange*>& GetRanges() const; { return fRanges; }. std::vector<TMVA::GeneticGenes>& GetGenePool(); { return fGenePool; }. std::vector<TMVA::GeneticRange*>& GetRanges(); { return fRanges; }. void NextGeneration(); {}. » Author: Peter Speckmayer » Copyright (c) 2005: *; » Last changed: root/tmva $Id: GeneticPopulation.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or su",MatchSource.WIKI,root/html532/TMVA__GeneticPopulation.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticPopulation.html
https://root.cern/root/html532/TMVA__GeneticPopulation.html:5481,Modifiability,variab,variables,5481,"lIndex = -1); make a little printout to the stream ""out"" of the individuals up to index ""untilIndex""; this means, .. write out the best ""untilIndex"" individuals. TH1F* VariableDistribution(Int_t varNumber, Int_t bins, Int_t min, Int_t max); give back a histogram with the distribution of the coefficients; parameters:; int bins : number of bins of the histogram; int min : histogram minimum; int max : maximum value of the histogram. vector<Double_t> VariableDistribution(Int_t varNumber); gives back all the values of coefficient ""varNumber"" of the current generation. void AddPopulation( GeneticPopulation *strangers ); add another population (strangers) to the one of this GeneticPopulation. void AddPopulation( GeneticPopulation &strangers ); add another population (strangers) to the one of this GeneticPopulation. void TrimPopulation(); trim the population to the predefined size. void GiveHint(vector<Double_t>& hint, Double_t fitness = 0); add an individual (a set of variables) to the population; if there is a set of variables which is known to perform good, they can be given as a hint to the population. void Sort(); sort the genepool according to the fitness of the individuals. GeneticPopulation(const vector<TMVA::Interval*>& ranges, Int_t size, UInt_t seed = 0). Int_t GetPopulationSize() const; { return fGenePool.size(); }. Double_t GetFitness() const; { return fGenePool.size()>0? fGenePool[0].GetFitness() : 0; }. const std::vector<TMVA::GeneticGenes>& GetGenePool() const; { return fGenePool; }. const std::vector<TMVA::GeneticRange*>& GetRanges() const; { return fRanges; }. std::vector<TMVA::GeneticGenes>& GetGenePool(); { return fGenePool; }. std::vector<TMVA::GeneticRange*>& GetRanges(); { return fRanges; }. void NextGeneration(); {}. » Author: Peter Speckmayer » Copyright (c) 2005: *; » Last changed: root/tmva $Id: GeneticPopulation.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or su",MatchSource.WIKI,root/html532/TMVA__GeneticPopulation.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticPopulation.html
https://root.cern/root/html532/TMVA__GeneticPopulation.html:5509,Performance,perform,perform,5509,"lIndex = -1); make a little printout to the stream ""out"" of the individuals up to index ""untilIndex""; this means, .. write out the best ""untilIndex"" individuals. TH1F* VariableDistribution(Int_t varNumber, Int_t bins, Int_t min, Int_t max); give back a histogram with the distribution of the coefficients; parameters:; int bins : number of bins of the histogram; int min : histogram minimum; int max : maximum value of the histogram. vector<Double_t> VariableDistribution(Int_t varNumber); gives back all the values of coefficient ""varNumber"" of the current generation. void AddPopulation( GeneticPopulation *strangers ); add another population (strangers) to the one of this GeneticPopulation. void AddPopulation( GeneticPopulation &strangers ); add another population (strangers) to the one of this GeneticPopulation. void TrimPopulation(); trim the population to the predefined size. void GiveHint(vector<Double_t>& hint, Double_t fitness = 0); add an individual (a set of variables) to the population; if there is a set of variables which is known to perform good, they can be given as a hint to the population. void Sort(); sort the genepool according to the fitness of the individuals. GeneticPopulation(const vector<TMVA::Interval*>& ranges, Int_t size, UInt_t seed = 0). Int_t GetPopulationSize() const; { return fGenePool.size(); }. Double_t GetFitness() const; { return fGenePool.size()>0? fGenePool[0].GetFitness() : 0; }. const std::vector<TMVA::GeneticGenes>& GetGenePool() const; { return fGenePool; }. const std::vector<TMVA::GeneticRange*>& GetRanges() const; { return fRanges; }. std::vector<TMVA::GeneticGenes>& GetGenePool(); { return fGenePool; }. std::vector<TMVA::GeneticRange*>& GetRanges(); { return fRanges; }. void NextGeneration(); {}. » Author: Peter Speckmayer » Copyright (c) 2005: *; » Last changed: root/tmva $Id: GeneticPopulation.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or su",MatchSource.WIKI,root/html532/TMVA__GeneticPopulation.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticPopulation.html
https://root.cern/root/html532/TMVA__GeneticPopulation.html:2065,Testability,log,logger,2065,"lass*IsA() const; voidMakeChildren(); voidMakeCopies(int number); voidMutate(Double_t probability = 20, Int_t startIndex = 0, Bool_t near = kFALSE, Double_t spread = 0.1, Bool_t mirror = kFALSE); voidNextGeneration(); TMVA::GeneticPopulation&operator=(const TMVA::GeneticPopulation&); voidPrint(Int_t untilIndex = -1); voidPrint(ostream& out, Int_t utilIndex = -1); voidSetRandomSeed(UInt_t seed = 0); virtual voidShowMembers(TMemberInspector& insp); voidSort(); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); voidTrimPopulation(); vector<Double_t>VariableDistribution(Int_t varNumber); TH1F*VariableDistribution(Int_t varNumber, Int_t bins, Int_t min, Int_t max). private:. TMVA::MsgLogger&Log() const; TMVA::GeneticGenesMakeSex(TMVA::GeneticGenes male, TMVA::GeneticGenes female). Data Members; private:. vector<TMVA::GeneticGenes>fGenePoolthe ""genePool"" where the individuals of the current generation are stored; TMVA::MsgLogger*fLoggermessage logger; Int_tfPopulationSizeLimit; TRandom3*fRandomGeneratorrandom Generator for this population; vector<TMVA::GeneticRange*>fRangescontains the ranges inbetween the values of the coefficients have to be. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; GeneticPopulation(const vector<TMVA::Interval*>& ranges, Int_t size, UInt_t seed = 0); Constructor. ~GeneticPopulation(); destructor. void SetRandomSeed(UInt_t seed = 0); the random seed of the random generator. void MakeCopies(int number); produces offspring which is are copies of their parents; Parameters:; int number : the number of the last individual to be copied. void MakeChildren(); does what the name says,... it creates children out of members of the; current generation; children have a combination of the coefficients of their parents. TMVA::GeneticGenes MakeSex(TMVA::GeneticGenes male, TMVA::GeneticGenes female); this function takes two individuals and produces offspring by mixing (recombining) their; coefficients. v",MatchSource.WIKI,root/html532/TMVA__GeneticPopulation.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticPopulation.html
https://root.cern/root/html532/TMVA__GiniIndex.html:1562,Availability,down,down,1562,"Index: public TMVA::SeparationBase. Implementation of the GiniIndex as separation criterion. Function Members (Methods); public:. virtual~GiniIndex(); static TClass*Class(); const TString&TMVA::SeparationBase::GetName(); Double_tTMVA::SeparationBase::GetSeparationGain(const Double_t& nSelS, const Double_t& nSelB, const Double_t& nTotS, const Double_t& nTotB); virtual Double_tGetSeparationIndex(const Double_t& s, const Double_t& b); TMVA::GiniIndexGiniIndex(); TMVA::GiniIndexGiniIndex(const TMVA::GiniIndex& g); virtual TClass*IsA() const; TMVA::GiniIndex&operator=(const TMVA::GiniIndex&); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). Data Members; protected:. TStringTMVA::SeparationBase::fNamename of the concrete Separation Index impementation; Double_tTMVA::SeparationBase::fPrecisionCut. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Double_t GetSeparationIndex(const Double_t& s, const Double_t& b); Gini(Sample M) = 1 - (c(1)/N)^2 - (c(2)/N)^2 .... - (c(k)/N)^2; Where: M is a smaple of whatever N elements (events); that belong to K different classes; c(k) is the number of elements that belong to class k; for just Signal and Background classes this boils down to:; Gini(Sample) = 2s*b/(s+b)^2 ( = 2 * purity * (1-purity) ). !! what we use here is 2*Gini.. as for the later use the factor; 2 is irrelevant and hence I'd like to save this calculation. GiniIndex(); construtor for the GiniIndex. { fName=""Gini""; }. GiniIndex(const TMVA::GiniIndex& g); copy constructor. {}. virtual ~GiniIndex(); destructor. {}. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: GiniIndex.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__GiniIndex.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GiniIndex.html
https://root.cern/root/html532/TMVA__GiniIndexWithLaplace.html:1761,Availability,down,down,1761,"criterion. Function Members (Methods); public:. virtual~GiniIndexWithLaplace(); static TClass*Class(); const TString&TMVA::SeparationBase::GetName(); Double_tTMVA::SeparationBase::GetSeparationGain(const Double_t& nSelS, const Double_t& nSelB, const Double_t& nTotS, const Double_t& nTotB); virtual Double_tGetSeparationIndex(const Double_t& s, const Double_t& b); TMVA::GiniIndexWithLaplaceGiniIndexWithLaplace(); TMVA::GiniIndexWithLaplaceGiniIndexWithLaplace(const TMVA::GiniIndexWithLaplace& g); virtual TClass*IsA() const; TMVA::GiniIndexWithLaplace&operator=(const TMVA::GiniIndexWithLaplace&); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). Data Members; protected:. TStringTMVA::SeparationBase::fNamename of the concrete Separation Index impementation; Double_tTMVA::SeparationBase::fPrecisionCut. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Double_t GetSeparationIndex(const Double_t& s, const Double_t& b); Gini(Sample M) = 1 - (c(1)/N)^2 - (c(2)/N)^2 .... - (c(k)/N)^2; Where: M is a smaple of whatever N elements (events); that belong to K different classes; c(k) is the number of elements that belong to class k; Laplace's correction to the prob.density c/N --> (c+1)/(N+2); for just Signal and Background classes this then boils down to:; Gini(Sample) = 2(s*b+s+b+1)/(s+b+2)^2. GiniIndexWithLaplace(); construtor for the GiniIndexWithLaplace. { fName=""GiniLaplace""; }. GiniIndexWithLaplace(const TMVA::GiniIndexWithLaplace& g); copy constructor. {}. virtual ~GiniIndexWithLaplace(); destructor. {}. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: GiniIndexWithLaplace.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__GiniIndexWithLaplace.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GiniIndexWithLaplace.html
https://root.cern/root/html532/TMVA__IFitterTarget.html:522,Availability,avail,available,522,". TMVA::IFitterTarget. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::IFitterTarget. class TMVA::IFitterTarget. IFitterTarget. Interface for a fitter 'target'. Defines interface to the estimator; function. Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~IFitterTarget(); static TClass*Class(); virtual Double_tEstimatorFunction(vector<Double_t>& parameters); virtual TClass*IsA() const; TMVA::IFitterTarget&operator=(const TMVA::IFitterTarget&); virtual voidProgressNotifier(TString, TString); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; virtual ~IFitterTarget(); {}. Double_t EstimatorFunction(vector<Double_t>& parameters). void ProgressNotifier(TString , TString ); function to notify the FitterTarget of the progress status of the fitter; sender : ""GA"", ""MC"", ...; progress : ""init"", ""iteration"", ""last"", ""stop"". {}. » Author: Andreas Hoecker, Peter Speckmayer » Copyright (c) 2005: *; » Last changed: root/tmva $Id: IFitterTarget.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__IFitterTarget.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__IFitterTarget.html
https://root.cern/root/html532/TMVA__IFitterTarget.html:350,Integrability,interface,interface,350,". TMVA::IFitterTarget. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::IFitterTarget. class TMVA::IFitterTarget. IFitterTarget. Interface for a fitter 'target'. Defines interface to the estimator; function. Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~IFitterTarget(); static TClass*Class(); virtual Double_tEstimatorFunction(vector<Double_t>& parameters); virtual TClass*IsA() const; TMVA::IFitterTarget&operator=(const TMVA::IFitterTarget&); virtual voidProgressNotifier(TString, TString); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; virtual ~IFitterTarget(); {}. Double_t EstimatorFunction(vector<Double_t>& parameters). void ProgressNotifier(TString , TString ); function to notify the FitterTarget of the progress status of the fitter; sender : ""GA"", ""MC"", ...; progress : ""init"", ""iteration"", ""last"", ""stop"". {}. » Author: Andreas Hoecker, Peter Speckmayer » Copyright (c) 2005: *; » Last changed: root/tmva $Id: IFitterTarget.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__IFitterTarget.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__IFitterTarget.html
https://root.cern/root/html532/TMVA__IMethod.html:410,Availability,avail,available,410,". TMVA::IMethod. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::IMethod. class TMVA::IMethod. Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~IMethod(); static TClass*Class(); virtual const TMVA::Ranking*CreateRanking(); virtual voidDeclareOptions(); virtual Double_tGetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); virtual const char*GetName() const; virtual Bool_tHasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); virtual voidInit(); virtual TClass*IsA() const; virtual voidMakeClass(const TString& classFileName = TString("""")) const; virtual Bool_tMonitorBoost(TMVA::MethodBoost* boost); TMVA::IMethod&operator=(const TMVA::IMethod&); virtual voidPrintHelpMessage() const; virtual voidProcessOptions(); virtual voidReadWeightsFromStream(istream&); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTrain(); virtual voidWriteMonitoringHistosToFile() const. protected:. virtual voidGetHelpMessage() const; virtual voidMakeClassSpecific(ostream&, const TString&) const. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; virtual ~IMethod(); default destructur. {}. const char * GetName() const; ------- virtual member functions to be implemented by each MVA method; the name of the method. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); calculate the MVA value - some methods may return a per-event error estimate (unless: *err = -1). void Train( void ); training method. void ReadWeightsFromStream(istream& ); read weights from output stream. void WriteMonitoringHistosToFile( void ); write method spec",MatchSource.WIKI,root/html532/TMVA__IMethod.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__IMethod.html
https://root.cern/root/html532/TMVA__IMethod.html:1797,Availability,error,error,1797,"es, UInt_t numberTargets); virtual voidInit(); virtual TClass*IsA() const; virtual voidMakeClass(const TString& classFileName = TString("""")) const; virtual Bool_tMonitorBoost(TMVA::MethodBoost* boost); TMVA::IMethod&operator=(const TMVA::IMethod&); virtual voidPrintHelpMessage() const; virtual voidProcessOptions(); virtual voidReadWeightsFromStream(istream&); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTrain(); virtual voidWriteMonitoringHistosToFile() const. protected:. virtual voidGetHelpMessage() const; virtual voidMakeClassSpecific(ostream&, const TString&) const. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; virtual ~IMethod(); default destructur. {}. const char * GetName() const; ------- virtual member functions to be implemented by each MVA method; the name of the method. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); calculate the MVA value - some methods may return a per-event error estimate (unless: *err = -1). void Train( void ); training method. void ReadWeightsFromStream(istream& ); read weights from output stream. void WriteMonitoringHistosToFile( void ); write method specific monitoring histograms to target file. void MakeClass(const TString& classFileName = TString("""")) const; make ROOT-independent C++ class for classifier response. const Ranking* CreateRanking(); create ranking. void PrintHelpMessage() const; print help message. Bool_t MonitorBoost(TMVA::MethodBoost* boost); perfrom extra actions during the boosting at different stages. void Init(). void DeclareOptions(). void ProcessOptions(). Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets). void MakeClassSpecific(ostream& , const TString& ) const; make ROOT-independent C++ class for classifier response (classifier-specific implementation). void GetHelpMessage() const; get specific help message from cla",MatchSource.WIKI,root/html532/TMVA__IMethod.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__IMethod.html
https://root.cern/root/html532/TMVA__IMethod.html:2006,Energy Efficiency,monitor,monitoring,2006,"hod&); virtual voidPrintHelpMessage() const; virtual voidProcessOptions(); virtual voidReadWeightsFromStream(istream&); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTrain(); virtual voidWriteMonitoringHistosToFile() const. protected:. virtual voidGetHelpMessage() const; virtual voidMakeClassSpecific(ostream&, const TString&) const. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; virtual ~IMethod(); default destructur. {}. const char * GetName() const; ------- virtual member functions to be implemented by each MVA method; the name of the method. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); calculate the MVA value - some methods may return a per-event error estimate (unless: *err = -1). void Train( void ); training method. void ReadWeightsFromStream(istream& ); read weights from output stream. void WriteMonitoringHistosToFile( void ); write method specific monitoring histograms to target file. void MakeClass(const TString& classFileName = TString("""")) const; make ROOT-independent C++ class for classifier response. const Ranking* CreateRanking(); create ranking. void PrintHelpMessage() const; print help message. Bool_t MonitorBoost(TMVA::MethodBoost* boost); perfrom extra actions during the boosting at different stages. void Init(). void DeclareOptions(). void ProcessOptions(). Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets). void MakeClassSpecific(ostream& , const TString& ) const; make ROOT-independent C++ class for classifier response (classifier-specific implementation). void GetHelpMessage() const; get specific help message from classifer. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: IMethod.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automaticall",MatchSource.WIKI,root/html532/TMVA__IMethod.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__IMethod.html
https://root.cern/root/html532/TMVA__IMethod.html:2257,Integrability,message,message,2257,"ual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTrain(); virtual voidWriteMonitoringHistosToFile() const. protected:. virtual voidGetHelpMessage() const; virtual voidMakeClassSpecific(ostream&, const TString&) const. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; virtual ~IMethod(); default destructur. {}. const char * GetName() const; ------- virtual member functions to be implemented by each MVA method; the name of the method. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); calculate the MVA value - some methods may return a per-event error estimate (unless: *err = -1). void Train( void ); training method. void ReadWeightsFromStream(istream& ); read weights from output stream. void WriteMonitoringHistosToFile( void ); write method specific monitoring histograms to target file. void MakeClass(const TString& classFileName = TString("""")) const; make ROOT-independent C++ class for classifier response. const Ranking* CreateRanking(); create ranking. void PrintHelpMessage() const; print help message. Bool_t MonitorBoost(TMVA::MethodBoost* boost); perfrom extra actions during the boosting at different stages. void Init(). void DeclareOptions(). void ProcessOptions(). Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets). void MakeClassSpecific(ostream& , const TString& ) const; make ROOT-independent C++ class for classifier response (classifier-specific implementation). void GetHelpMessage() const; get specific help message from classifer. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: IMethod.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__IMethod.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__IMethod.html
https://root.cern/root/html532/TMVA__IMethod.html:2735,Integrability,message,message,2735,"ual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTrain(); virtual voidWriteMonitoringHistosToFile() const. protected:. virtual voidGetHelpMessage() const; virtual voidMakeClassSpecific(ostream&, const TString&) const. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; virtual ~IMethod(); default destructur. {}. const char * GetName() const; ------- virtual member functions to be implemented by each MVA method; the name of the method. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); calculate the MVA value - some methods may return a per-event error estimate (unless: *err = -1). void Train( void ); training method. void ReadWeightsFromStream(istream& ); read weights from output stream. void WriteMonitoringHistosToFile( void ); write method specific monitoring histograms to target file. void MakeClass(const TString& classFileName = TString("""")) const; make ROOT-independent C++ class for classifier response. const Ranking* CreateRanking(); create ranking. void PrintHelpMessage() const; print help message. Bool_t MonitorBoost(TMVA::MethodBoost* boost); perfrom extra actions during the boosting at different stages. void Init(). void DeclareOptions(). void ProcessOptions(). Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets). void MakeClassSpecific(ostream& , const TString& ) const; make ROOT-independent C++ class for classifier response (classifier-specific implementation). void GetHelpMessage() const; get specific help message from classifer. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: IMethod.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__IMethod.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__IMethod.html
https://root.cern/root/html532/TMVA__Interval.html:310,Deployability,continuous,continuous,310,". TMVA::Interval. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Interval. class TMVA::Interval. Interval. Interval definition, continuous and discrete. Interval(min,max) : a continous interval [min,max]; Interval(min,max,n): a ""discrete interval"" [min,max], i.e the n numbers:; min, min+step, min+2*step,...., min+(n-1)*step, min+n*step=max; e.g.: Interval(1,5,5)=1,2,3,4,5; Interval(.5,1.,6)= .5, .6., .7, .8, .9, 1.0. Note: **bin** counting starts from ZERO unlike in ROOT histograms. the TMVA::Interval Class. Interval definition, continuous and discrete; ; Interval(min,max) : a continous interval [min,max]; Interval(min,max,n): a ""discrete interval"" [min,max], i.e the n numbers:; min, min+step, min+2*step,...., min+(n-1)*step=max ; e.g.: Interval(1,5,5)=1,2,3,4,5 ; Interval(.5,1.,6)= .5, .6., .7, .8, .9, 1.0 . Example: Interval(.5,1.,6) ; [ min max ] ; ------------------------------------------------------------; | | | | | |; .5 .6 .7 .8 .9 1.0 ; ; bin 0 1 2 3 4 5 . . Function Members (Methods); public:. virtual~Interval(); static TClass*Class(); Double_tGetElement(Int_t position) const; Double_tGetMax() const; Double_tGetMean() const; Double_tGetMin() const; Int_tGetNbins() const; Double_tGetRndm(TRandom3&) const; Double_tGetStepSize() const; Double_tGetWidth() const; TMVA::IntervalInterval(const TMVA::Interval& other); TMVA::IntervalInterval(Double_t min, Double_t max, Int_t nbins = 0); virtual TClass*IsA() const; TMVA::Interval&operator=(const TMVA::Interval&); voidSetMax(Double_t m); voidSetMin(Double_t m); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). private:. TMVA::MsgLogger&Log() const. Data Members; private:. Double_tfMaxthe constraints of the Interval; Double_tfMin; Int_tfNbinswhen >0 : number of bins (discret",MatchSource.WIKI,root/html532/TMVA__Interval.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Interval.html
https://root.cern/root/html532/TMVA__Interval.html:717,Deployability,continuous,continuous,717,". TMVA::Interval. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Interval. class TMVA::Interval. Interval. Interval definition, continuous and discrete. Interval(min,max) : a continous interval [min,max]; Interval(min,max,n): a ""discrete interval"" [min,max], i.e the n numbers:; min, min+step, min+2*step,...., min+(n-1)*step, min+n*step=max; e.g.: Interval(1,5,5)=1,2,3,4,5; Interval(.5,1.,6)= .5, .6., .7, .8, .9, 1.0. Note: **bin** counting starts from ZERO unlike in ROOT histograms. the TMVA::Interval Class. Interval definition, continuous and discrete; ; Interval(min,max) : a continous interval [min,max]; Interval(min,max,n): a ""discrete interval"" [min,max], i.e the n numbers:; min, min+step, min+2*step,...., min+(n-1)*step=max ; e.g.: Interval(1,5,5)=1,2,3,4,5 ; Interval(.5,1.,6)= .5, .6., .7, .8, .9, 1.0 . Example: Interval(.5,1.,6) ; [ min max ] ; ------------------------------------------------------------; | | | | | |; .5 .6 .7 .8 .9 1.0 ; ; bin 0 1 2 3 4 5 . . Function Members (Methods); public:. virtual~Interval(); static TClass*Class(); Double_tGetElement(Int_t position) const; Double_tGetMax() const; Double_tGetMean() const; Double_tGetMin() const; Int_tGetNbins() const; Double_tGetRndm(TRandom3&) const; Double_tGetStepSize() const; Double_tGetWidth() const; TMVA::IntervalInterval(const TMVA::Interval& other); TMVA::IntervalInterval(Double_t min, Double_t max, Int_t nbins = 0); virtual TClass*IsA() const; TMVA::Interval&operator=(const TMVA::Interval&); voidSetMax(Double_t m); voidSetMin(Double_t m); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). private:. TMVA::MsgLogger&Log() const. Data Members; private:. Double_tfMaxthe constraints of the Interval; Double_tfMin; Int_tfNbinswhen >0 : number of bins (discret",MatchSource.WIKI,root/html532/TMVA__Interval.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Interval.html
https://root.cern/root/html532/TMVA__Interval.html:2023,Deployability,continuous,continuous,2023,".9, 1.0 . Example: Interval(.5,1.,6) ; [ min max ] ; ------------------------------------------------------------; | | | | | |; .5 .6 .7 .8 .9 1.0 ; ; bin 0 1 2 3 4 5 . . Function Members (Methods); public:. virtual~Interval(); static TClass*Class(); Double_tGetElement(Int_t position) const; Double_tGetMax() const; Double_tGetMean() const; Double_tGetMin() const; Int_tGetNbins() const; Double_tGetRndm(TRandom3&) const; Double_tGetStepSize() const; Double_tGetWidth() const; TMVA::IntervalInterval(const TMVA::Interval& other); TMVA::IntervalInterval(Double_t min, Double_t max, Int_t nbins = 0); virtual TClass*IsA() const; TMVA::Interval&operator=(const TMVA::Interval&); voidSetMax(Double_t m); voidSetMin(Double_t m); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). private:. TMVA::MsgLogger&Log() const. Data Members; private:. Double_tfMaxthe constraints of the Interval; Double_tfMin; Int_tfNbinswhen >0 : number of bins (discrete interval); when ==0 continuous interval; static TMVA::MsgLogger*fgLoggermessage logger. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Interval(Double_t min, Double_t max, Int_t nbins = 0). Interval(const TMVA::Interval& other). ~Interval(); destructor. Double_t GetElement(Int_t position) const; calculates the value of the ""number"" bin in a discrete interval.; Parameters:; Double_t position. Double_t GetStepSize() const; retuns the step size between the numbers of a ""discrete Interval"". Double_t GetRndm(TRandom3& ) const; get uniformely distributed number within interval. Double_t GetMin() const; accessors. { return fMin; }. Double_t GetMax() const; { return fMax; }. Double_t GetWidth() const; { return fMax - fMin; }. Int_t GetNbins() const; { return fNbins; }. Double_t GetMean() const; { return (fMax + fMin)/2; }. void SetMax(Double_t m); { fMax = m; }. void SetMin(Double_t m); { fMin = m; }. » Author: Peter Speckmayer » Copyright (",MatchSource.WIKI,root/html532/TMVA__Interval.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Interval.html
https://root.cern/root/html532/TMVA__Interval.html:2651,Security,access,accessors,2651,"n) const; Double_tGetMax() const; Double_tGetMean() const; Double_tGetMin() const; Int_tGetNbins() const; Double_tGetRndm(TRandom3&) const; Double_tGetStepSize() const; Double_tGetWidth() const; TMVA::IntervalInterval(const TMVA::Interval& other); TMVA::IntervalInterval(Double_t min, Double_t max, Int_t nbins = 0); virtual TClass*IsA() const; TMVA::Interval&operator=(const TMVA::Interval&); voidSetMax(Double_t m); voidSetMin(Double_t m); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). private:. TMVA::MsgLogger&Log() const. Data Members; private:. Double_tfMaxthe constraints of the Interval; Double_tfMin; Int_tfNbinswhen >0 : number of bins (discrete interval); when ==0 continuous interval; static TMVA::MsgLogger*fgLoggermessage logger. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Interval(Double_t min, Double_t max, Int_t nbins = 0). Interval(const TMVA::Interval& other). ~Interval(); destructor. Double_t GetElement(Int_t position) const; calculates the value of the ""number"" bin in a discrete interval.; Parameters:; Double_t position. Double_t GetStepSize() const; retuns the step size between the numbers of a ""discrete Interval"". Double_t GetRndm(TRandom3& ) const; get uniformely distributed number within interval. Double_t GetMin() const; accessors. { return fMin; }. Double_t GetMax() const; { return fMax; }. Double_t GetWidth() const; { return fMax - fMin; }. Int_t GetNbins() const; { return fNbins; }. Double_t GetMean() const; { return (fMax + fMin)/2; }. void SetMax(Double_t m); { fMax = m; }. void SetMin(Double_t m); { fMin = m; }. » Author: Peter Speckmayer » Copyright (c) 2005: *; » Last changed: root/tmva $Id: Interval.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Interval.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Interval.html
https://root.cern/root/html532/TMVA__Interval.html:2083,Testability,log,logger,2083,".9, 1.0 . Example: Interval(.5,1.,6) ; [ min max ] ; ------------------------------------------------------------; | | | | | |; .5 .6 .7 .8 .9 1.0 ; ; bin 0 1 2 3 4 5 . . Function Members (Methods); public:. virtual~Interval(); static TClass*Class(); Double_tGetElement(Int_t position) const; Double_tGetMax() const; Double_tGetMean() const; Double_tGetMin() const; Int_tGetNbins() const; Double_tGetRndm(TRandom3&) const; Double_tGetStepSize() const; Double_tGetWidth() const; TMVA::IntervalInterval(const TMVA::Interval& other); TMVA::IntervalInterval(Double_t min, Double_t max, Int_t nbins = 0); virtual TClass*IsA() const; TMVA::Interval&operator=(const TMVA::Interval&); voidSetMax(Double_t m); voidSetMin(Double_t m); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). private:. TMVA::MsgLogger&Log() const. Data Members; private:. Double_tfMaxthe constraints of the Interval; Double_tfMin; Int_tfNbinswhen >0 : number of bins (discrete interval); when ==0 continuous interval; static TMVA::MsgLogger*fgLoggermessage logger. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Interval(Double_t min, Double_t max, Int_t nbins = 0). Interval(const TMVA::Interval& other). ~Interval(); destructor. Double_t GetElement(Int_t position) const; calculates the value of the ""number"" bin in a discrete interval.; Parameters:; Double_t position. Double_t GetStepSize() const; retuns the step size between the numbers of a ""discrete Interval"". Double_t GetRndm(TRandom3& ) const; get uniformely distributed number within interval. Double_t GetMin() const; accessors. { return fMin; }. Double_t GetMax() const; { return fMax; }. Double_t GetWidth() const; { return fMax - fMin; }. Int_t GetNbins() const; { return fNbins; }. Double_t GetMean() const; { return (fMax + fMin)/2; }. void SetMax(Double_t m); { fMax = m; }. void SetMin(Double_t m); { fMin = m; }. » Author: Peter Speckmayer » Copyright (",MatchSource.WIKI,root/html532/TMVA__Interval.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Interval.html
https://root.cern/root/html532/TMVA__KDEKernel.html:1894,Energy Efficiency,adapt,adaptive,1894,"nelIter kiter = kNonadaptiveKDE, const TH1* hist = 0, Float_t lower_edge = 0., Float_t upper_edge = 1., TMVA::KDEKernel::EKernelBorder kborder = kNoTreatment, Float_t FineFactor = 1.); TMVA::KDEKernel&operator=(const TMVA::KDEKernel&); voidSetKernelType(TMVA::KDEKernel::EKernelType ktype = kGauss); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). private:. TMVA::MsgLogger&Log() const. Data Members; public:. enum EKernelType { kNone; kGauss; };; enum EKernelIter { kNonadaptiveKDE; kAdaptiveKDE; };; enum EKernelBorder { kNoTreatment; kKernelRenorm; kSampleMirror; };. private:. Float_tfFineFactorfine tuning factor for Adaptive KDE: factor to multiply the ""width"" of the Kernel function; TH1F*fFirstIterHisthistogram to be filled in the hidden iteration; Bool_tfHiddenIterationDefines if whats currently running is the ; TH1F*fHistcopy of input histogram; TMVA::KDEKernel::EKernelIterfIteriteration number; TMVA::KDEKernel::EKernelBorderfKDEborderThe method to take care about ""border"" effects; TF1*fKernel_integthe integral of the Kernel function; TMVA::MsgLogger*fLoggermessage logger; Float_tfLowerEdgethe lower edge of the PDF; Float_tfSigmaWidth of the Kernel function; TH1F*fSigmaHistcontains the Sigmas Widths for adaptive KDE ; Float_tfUpperEdgethe upper edge of the PDF. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; KDEKernel(TMVA::KDEKernel::EKernelIter kiter = kNonadaptiveKDE, const TH1* hist = 0, Float_t lower_edge = 0., Float_t upper_edge = 1., TMVA::KDEKernel::EKernelBorder kborder = kNoTreatment, Float_t FineFactor = 1.); constructor; sanity check. ~KDEKernel(); destructor. void SetKernelType(TMVA::KDEKernel::EKernelType ktype = kGauss); fIter == 1 ---> nonadaptive KDE; fIter == 2 ---> adaptive KDE. Float_t GetBinKernelIntegral(Float_t lowr, Float_t highr, Float_t mean, Int_t binnum); calculates the integral of the Kernel. KDEKernel(TMVA::KDEKernel::EKernel",MatchSource.WIKI,root/html532/TMVA__KDEKernel.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__KDEKernel.html
https://root.cern/root/html532/TMVA__KDEKernel.html:2427,Energy Efficiency,adapt,adaptive,2427,"er { kNoTreatment; kKernelRenorm; kSampleMirror; };. private:. Float_tfFineFactorfine tuning factor for Adaptive KDE: factor to multiply the ""width"" of the Kernel function; TH1F*fFirstIterHisthistogram to be filled in the hidden iteration; Bool_tfHiddenIterationDefines if whats currently running is the ; TH1F*fHistcopy of input histogram; TMVA::KDEKernel::EKernelIterfIteriteration number; TMVA::KDEKernel::EKernelBorderfKDEborderThe method to take care about ""border"" effects; TF1*fKernel_integthe integral of the Kernel function; TMVA::MsgLogger*fLoggermessage logger; Float_tfLowerEdgethe lower edge of the PDF; Float_tfSigmaWidth of the Kernel function; TH1F*fSigmaHistcontains the Sigmas Widths for adaptive KDE ; Float_tfUpperEdgethe upper edge of the PDF. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; KDEKernel(TMVA::KDEKernel::EKernelIter kiter = kNonadaptiveKDE, const TH1* hist = 0, Float_t lower_edge = 0., Float_t upper_edge = 1., TMVA::KDEKernel::EKernelBorder kborder = kNoTreatment, Float_t FineFactor = 1.); constructor; sanity check. ~KDEKernel(); destructor. void SetKernelType(TMVA::KDEKernel::EKernelType ktype = kGauss); fIter == 1 ---> nonadaptive KDE; fIter == 2 ---> adaptive KDE. Float_t GetBinKernelIntegral(Float_t lowr, Float_t highr, Float_t mean, Int_t binnum); calculates the integral of the Kernel. KDEKernel(TMVA::KDEKernel::EKernelIter kiter = kNonadaptiveKDE, const TH1* hist = 0, Float_t lower_edge = 0., Float_t upper_edge = 1., TMVA::KDEKernel::EKernelBorder kborder = kNoTreatment, Float_t FineFactor = 1.). const char* GetName() const; modified name (remove TMVA::). { return ""KDEKernel""; }. » Author: Asen Christov » Copyright (c) 2007: *; » Last changed: root/tmva $Id: KDEKernel.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__KDEKernel.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__KDEKernel.html
https://root.cern/root/html532/TMVA__KDEKernel.html:1894,Modifiability,adapt,adaptive,1894,"nelIter kiter = kNonadaptiveKDE, const TH1* hist = 0, Float_t lower_edge = 0., Float_t upper_edge = 1., TMVA::KDEKernel::EKernelBorder kborder = kNoTreatment, Float_t FineFactor = 1.); TMVA::KDEKernel&operator=(const TMVA::KDEKernel&); voidSetKernelType(TMVA::KDEKernel::EKernelType ktype = kGauss); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). private:. TMVA::MsgLogger&Log() const. Data Members; public:. enum EKernelType { kNone; kGauss; };; enum EKernelIter { kNonadaptiveKDE; kAdaptiveKDE; };; enum EKernelBorder { kNoTreatment; kKernelRenorm; kSampleMirror; };. private:. Float_tfFineFactorfine tuning factor for Adaptive KDE: factor to multiply the ""width"" of the Kernel function; TH1F*fFirstIterHisthistogram to be filled in the hidden iteration; Bool_tfHiddenIterationDefines if whats currently running is the ; TH1F*fHistcopy of input histogram; TMVA::KDEKernel::EKernelIterfIteriteration number; TMVA::KDEKernel::EKernelBorderfKDEborderThe method to take care about ""border"" effects; TF1*fKernel_integthe integral of the Kernel function; TMVA::MsgLogger*fLoggermessage logger; Float_tfLowerEdgethe lower edge of the PDF; Float_tfSigmaWidth of the Kernel function; TH1F*fSigmaHistcontains the Sigmas Widths for adaptive KDE ; Float_tfUpperEdgethe upper edge of the PDF. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; KDEKernel(TMVA::KDEKernel::EKernelIter kiter = kNonadaptiveKDE, const TH1* hist = 0, Float_t lower_edge = 0., Float_t upper_edge = 1., TMVA::KDEKernel::EKernelBorder kborder = kNoTreatment, Float_t FineFactor = 1.); constructor; sanity check. ~KDEKernel(); destructor. void SetKernelType(TMVA::KDEKernel::EKernelType ktype = kGauss); fIter == 1 ---> nonadaptive KDE; fIter == 2 ---> adaptive KDE. Float_t GetBinKernelIntegral(Float_t lowr, Float_t highr, Float_t mean, Int_t binnum); calculates the integral of the Kernel. KDEKernel(TMVA::KDEKernel::EKernel",MatchSource.WIKI,root/html532/TMVA__KDEKernel.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__KDEKernel.html
https://root.cern/root/html532/TMVA__KDEKernel.html:2427,Modifiability,adapt,adaptive,2427,"er { kNoTreatment; kKernelRenorm; kSampleMirror; };. private:. Float_tfFineFactorfine tuning factor for Adaptive KDE: factor to multiply the ""width"" of the Kernel function; TH1F*fFirstIterHisthistogram to be filled in the hidden iteration; Bool_tfHiddenIterationDefines if whats currently running is the ; TH1F*fHistcopy of input histogram; TMVA::KDEKernel::EKernelIterfIteriteration number; TMVA::KDEKernel::EKernelBorderfKDEborderThe method to take care about ""border"" effects; TF1*fKernel_integthe integral of the Kernel function; TMVA::MsgLogger*fLoggermessage logger; Float_tfLowerEdgethe lower edge of the PDF; Float_tfSigmaWidth of the Kernel function; TH1F*fSigmaHistcontains the Sigmas Widths for adaptive KDE ; Float_tfUpperEdgethe upper edge of the PDF. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; KDEKernel(TMVA::KDEKernel::EKernelIter kiter = kNonadaptiveKDE, const TH1* hist = 0, Float_t lower_edge = 0., Float_t upper_edge = 1., TMVA::KDEKernel::EKernelBorder kborder = kNoTreatment, Float_t FineFactor = 1.); constructor; sanity check. ~KDEKernel(); destructor. void SetKernelType(TMVA::KDEKernel::EKernelType ktype = kGauss); fIter == 1 ---> nonadaptive KDE; fIter == 2 ---> adaptive KDE. Float_t GetBinKernelIntegral(Float_t lowr, Float_t highr, Float_t mean, Int_t binnum); calculates the integral of the Kernel. KDEKernel(TMVA::KDEKernel::EKernelIter kiter = kNonadaptiveKDE, const TH1* hist = 0, Float_t lower_edge = 0., Float_t upper_edge = 1., TMVA::KDEKernel::EKernelBorder kborder = kNoTreatment, Float_t FineFactor = 1.). const char* GetName() const; modified name (remove TMVA::). { return ""KDEKernel""; }. » Author: Asen Christov » Copyright (c) 2007: *; » Last changed: root/tmva $Id: KDEKernel.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__KDEKernel.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__KDEKernel.html
https://root.cern/root/html532/TMVA__KDEKernel.html:2273,Safety,sanity check,sanity check,2273,"er { kNoTreatment; kKernelRenorm; kSampleMirror; };. private:. Float_tfFineFactorfine tuning factor for Adaptive KDE: factor to multiply the ""width"" of the Kernel function; TH1F*fFirstIterHisthistogram to be filled in the hidden iteration; Bool_tfHiddenIterationDefines if whats currently running is the ; TH1F*fHistcopy of input histogram; TMVA::KDEKernel::EKernelIterfIteriteration number; TMVA::KDEKernel::EKernelBorderfKDEborderThe method to take care about ""border"" effects; TF1*fKernel_integthe integral of the Kernel function; TMVA::MsgLogger*fLoggermessage logger; Float_tfLowerEdgethe lower edge of the PDF; Float_tfSigmaWidth of the Kernel function; TH1F*fSigmaHistcontains the Sigmas Widths for adaptive KDE ; Float_tfUpperEdgethe upper edge of the PDF. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; KDEKernel(TMVA::KDEKernel::EKernelIter kiter = kNonadaptiveKDE, const TH1* hist = 0, Float_t lower_edge = 0., Float_t upper_edge = 1., TMVA::KDEKernel::EKernelBorder kborder = kNoTreatment, Float_t FineFactor = 1.); constructor; sanity check. ~KDEKernel(); destructor. void SetKernelType(TMVA::KDEKernel::EKernelType ktype = kGauss); fIter == 1 ---> nonadaptive KDE; fIter == 2 ---> adaptive KDE. Float_t GetBinKernelIntegral(Float_t lowr, Float_t highr, Float_t mean, Int_t binnum); calculates the integral of the Kernel. KDEKernel(TMVA::KDEKernel::EKernelIter kiter = kNonadaptiveKDE, const TH1* hist = 0, Float_t lower_edge = 0., Float_t upper_edge = 1., TMVA::KDEKernel::EKernelBorder kborder = kNoTreatment, Float_t FineFactor = 1.). const char* GetName() const; modified name (remove TMVA::). { return ""KDEKernel""; }. » Author: Asen Christov » Copyright (c) 2007: *; » Last changed: root/tmva $Id: KDEKernel.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__KDEKernel.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__KDEKernel.html
https://root.cern/root/html532/TMVA__KDEKernel.html:1753,Testability,log,logger,1753,"nelIter kiter = kNonadaptiveKDE, const TH1* hist = 0, Float_t lower_edge = 0., Float_t upper_edge = 1., TMVA::KDEKernel::EKernelBorder kborder = kNoTreatment, Float_t FineFactor = 1.); TMVA::KDEKernel&operator=(const TMVA::KDEKernel&); voidSetKernelType(TMVA::KDEKernel::EKernelType ktype = kGauss); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). private:. TMVA::MsgLogger&Log() const. Data Members; public:. enum EKernelType { kNone; kGauss; };; enum EKernelIter { kNonadaptiveKDE; kAdaptiveKDE; };; enum EKernelBorder { kNoTreatment; kKernelRenorm; kSampleMirror; };. private:. Float_tfFineFactorfine tuning factor for Adaptive KDE: factor to multiply the ""width"" of the Kernel function; TH1F*fFirstIterHisthistogram to be filled in the hidden iteration; Bool_tfHiddenIterationDefines if whats currently running is the ; TH1F*fHistcopy of input histogram; TMVA::KDEKernel::EKernelIterfIteriteration number; TMVA::KDEKernel::EKernelBorderfKDEborderThe method to take care about ""border"" effects; TF1*fKernel_integthe integral of the Kernel function; TMVA::MsgLogger*fLoggermessage logger; Float_tfLowerEdgethe lower edge of the PDF; Float_tfSigmaWidth of the Kernel function; TH1F*fSigmaHistcontains the Sigmas Widths for adaptive KDE ; Float_tfUpperEdgethe upper edge of the PDF. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; KDEKernel(TMVA::KDEKernel::EKernelIter kiter = kNonadaptiveKDE, const TH1* hist = 0, Float_t lower_edge = 0., Float_t upper_edge = 1., TMVA::KDEKernel::EKernelBorder kborder = kNoTreatment, Float_t FineFactor = 1.); constructor; sanity check. ~KDEKernel(); destructor. void SetKernelType(TMVA::KDEKernel::EKernelType ktype = kGauss); fIter == 1 ---> nonadaptive KDE; fIter == 2 ---> adaptive KDE. Float_t GetBinKernelIntegral(Float_t lowr, Float_t highr, Float_t mean, Int_t binnum); calculates the integral of the Kernel. KDEKernel(TMVA::KDEKernel::EKernel",MatchSource.WIKI,root/html532/TMVA__KDEKernel.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__KDEKernel.html
https://root.cern/root/html532/TMVA__kNN__Event.html:1633,Energy Efficiency,charge,charge,1633,TRefArray *fMuons; //array of Muon tracks only; TRef fLastTrack; //pointer to last track; TRef fHistoWeb; //EXEC:GetHistoWeb reference to an histogram in a TWebFile; TH1F *fH;; TBits fTriggerBits; //Bits triggered by this event. The EventHeader class has 3 data members (integers):; public:; Int_t fEvtNum;; Int_t fRun;; Int_t fDate;. The Event data member fTracks is a pointer to a TClonesArray.; It is an array of a variable number of tracks per event.; Each element of the array is an object of class Track with the members:; private:; Float_t fPx; //X component of the momentum; Float_t fPy; //Y component of the momentum; Float_t fPz; //Z component of the momentum; Float_t fRandom; //A random track quantity; Float_t fMass2; //The mass square of this particle; Float_t fBx; //X intercept at the vertex; Float_t fBy; //Y intercept at the vertex; Float_t fMeanCharge; //Mean charge deposition of all hits of this track; Float_t fXfirst; //X coordinate of the first point; Float_t fXlast; //X coordinate of the last point; Float_t fYfirst; //Y coordinate of the first point; Float_t fYlast; //Y coordinate of the last point; Float_t fZfirst; //Z coordinate of the first point; Float_t fZlast; //Z coordinate of the last point; Double32_t fCharge; //Charge of this track; Double32_t fVertex[3]; //Track vertex position; Int_t fNpoint; //Number of points for this track; Short_t fValid; //Validity criterion; Int_t fNsp; //Number of points for this track with a special value; Double32_t *fPointValue; //[fNsp] a special quantity for some point.; TBits fTriggerBits; //Bits triggered by this track. An example of a batch program to use the Event/Track classes is given; in this directory: MainEvent.; Look also in the same directory at the following macros:; - eventa.C an example how to read the tree; - eventb.C how to read events conditionally. During the processing of the event (optionally) also a large number; of histograms can be filled. The creation and handling of the; histograms is taken,MatchSource.WIKI,root/html532/TMVA__kNN__Event.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__kNN__Event.html
https://root.cern/root/html532/TMVA__kNN__Event.html:1172,Modifiability,variab,variable,1172,; function members; data members; class charts. ROOT; » TEST; » TMVA::kNN::Event. class TMVA::kNN::Event. Event and Track classes. The Event class is a naive/simple example of an event structure.; public:; char fType[20];; char *fEventName; //run+event number in character format; Int_t fNtrack;; Int_t fNseg;; Int_t fNvertex;; UInt_t fFlag;; Double32_t fTemperature;; Int_t fMeasures[10];; Double32_t fMatrix[4][4];; Double32_t *fClosestDistance; //[fNvertex] indexed array!; EventHeader fEvtHdr;; TClonesArray *fTracks;; TRefArray *fHighPt; //array of High Pt tracks only; TRefArray *fMuons; //array of Muon tracks only; TRef fLastTrack; //pointer to last track; TRef fHistoWeb; //EXEC:GetHistoWeb reference to an histogram in a TWebFile; TH1F *fH;; TBits fTriggerBits; //Bits triggered by this event. The EventHeader class has 3 data members (integers):; public:; Int_t fEvtNum;; Int_t fRun;; Int_t fDate;. The Event data member fTracks is a pointer to a TClonesArray.; It is an array of a variable number of tracks per event.; Each element of the array is an object of class Track with the members:; private:; Float_t fPx; //X component of the momentum; Float_t fPy; //Y component of the momentum; Float_t fPz; //Z component of the momentum; Float_t fRandom; //A random track quantity; Float_t fMass2; //The mass square of this particle; Float_t fBx; //X intercept at the vertex; Float_t fBy; //Y intercept at the vertex; Float_t fMeanCharge; //Mean charge deposition of all hits of this track; Float_t fXfirst; //X coordinate of the first point; Float_t fXlast; //X coordinate of the last point; Float_t fYfirst; //Y coordinate of the first point; Float_t fYlast; //Y coordinate of the last point; Float_t fZfirst; //Z coordinate of the first point; Float_t fZlast; //Z coordinate of the last point; Double32_t fCharge; //Charge of this track; Double32_t fVertex[3]; //Track vertex position; Int_t fNpoint; //Number of points for this track; Short_t fValid; //Validity criterion; Int_t fNsp; //N,MatchSource.WIKI,root/html532/TMVA__kNN__Event.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__kNN__Event.html
https://root.cern/root/html532/TMVA__kNN__Event.html:2896,Modifiability,variab,variables,2896,"he first point; Float_t fZlast; //Z coordinate of the last point; Double32_t fCharge; //Charge of this track; Double32_t fVertex[3]; //Track vertex position; Int_t fNpoint; //Number of points for this track; Short_t fValid; //Validity criterion; Int_t fNsp; //Number of points for this track with a special value; Double32_t *fPointValue; //[fNsp] a special quantity for some point.; TBits fTriggerBits; //Bits triggered by this track. An example of a batch program to use the Event/Track classes is given; in this directory: MainEvent.; Look also in the same directory at the following macros:; - eventa.C an example how to read the tree; - eventb.C how to read events conditionally. During the processing of the event (optionally) also a large number; of histograms can be filled. The creation and handling of the; histograms is taken care of by the HistogramManager class. Note: This version of the class Event (see EventMT.h and EventMT.cxx; for an alternative) uses static variables to improve performance (by; reducing the number of memory allocations). Consequently, only one; instance of the class Event should be in use at a time (a 2nd instance; would share the array of Tracks with the first instance). Function Members (Methods); public:. ~Event(); TMVA::kNN::EventEvent(); TMVA::kNN::EventEvent(const TMVA::kNN::Event&); TMVA::kNN::EventEvent(const TMVA::kNN::VarVec& vec, Double_t weight, Short_t type); TMVA::kNN::EventEvent(const TMVA::kNN::VarVec& vec, Double_t weight, Short_t type, const TMVA::kNN::VarVec& tvec); TMVA::kNN::VarTypeGetDist(const TMVA::kNN::Event& other) const; TMVA::kNN::VarTypeGetDist(TMVA::kNN::VarType var, UInt_t ivar) const; TMVA::kNN::VarTypeGetDist(const TMVA::kNN::VarType var1, const UInt_t ivar) const; UInt_tGetNTgt() const; UInt_tGetNVar() const; const TMVA::kNN::VarVec&GetTargets() const; TMVA::kNN::VarTypeGetTgt(UInt_t i) const; TMVA::kNN::VarTypeGetTgt(const UInt_t i) const; Short_tGetType() const; TMVA::kNN::VarTypeGetVar(UInt_t i) const; TMVA",MatchSource.WIKI,root/html532/TMVA__kNN__Event.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__kNN__Event.html
https://root.cern/root/html532/TMVA__kNN__Event.html:4365,Modifiability,variab,variables,4365,"t weight, Short_t type); TMVA::kNN::EventEvent(const TMVA::kNN::VarVec& vec, Double_t weight, Short_t type, const TMVA::kNN::VarVec& tvec); TMVA::kNN::VarTypeGetDist(const TMVA::kNN::Event& other) const; TMVA::kNN::VarTypeGetDist(TMVA::kNN::VarType var, UInt_t ivar) const; TMVA::kNN::VarTypeGetDist(const TMVA::kNN::VarType var1, const UInt_t ivar) const; UInt_tGetNTgt() const; UInt_tGetNVar() const; const TMVA::kNN::VarVec&GetTargets() const; TMVA::kNN::VarTypeGetTgt(UInt_t i) const; TMVA::kNN::VarTypeGetTgt(const UInt_t i) const; Short_tGetType() const; TMVA::kNN::VarTypeGetVar(UInt_t i) const; TMVA::kNN::VarTypeGetVar(const UInt_t i) const; const TMVA::kNN::VarVec&GetVars() const; Double_tGetWeight() const; TMVA::kNN::Event&operator=(const TMVA::kNN::Event&); voidPrint() const; voidPrint(ostream& os) const; voidSetTargets(const TMVA::kNN::VarVec& tvec). Data Members; private:. TMVA::kNN::VarVecfTgttargets for regression analysis; Short_tfTypeevent type ==0 or == 1, expand it to arbitrary class types? ; TMVA::kNN::VarVecfVarcoordinates (variables) for knn search; Double_tfWeightevent weight. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Event(); Create an Event object.; When the constructor is invoked for the first time, the class static; variable fgTracks is 0 and the TClonesArray fgTracks is created. ~Event(). Event(). Event(const TMVA::kNN::VarVec& vec, Double_t weight, Short_t type). Event(const TMVA::kNN::VarVec& vec, Double_t weight, Short_t type, const TMVA::kNN::VarVec& tvec). Double_t GetWeight() const. VarType GetVar(UInt_t i) const. VarType GetTgt(UInt_t i) const. UInt_t GetNVar() const. UInt_t GetNTgt() const. Short_t GetType() const. VarType GetDist(TMVA::kNN::VarType var, UInt_t ivar) const; keep these two function separate. VarType GetDist(const TMVA::kNN::Event& other) const. void SetTargets(const TMVA::kNN::VarVec& tvec). const VarVec& GetTargets() const. const VarVec& GetVars() const. void Print() const",MatchSource.WIKI,root/html532/TMVA__kNN__Event.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__kNN__Event.html
https://root.cern/root/html532/TMVA__kNN__Event.html:4616,Modifiability,variab,variable,4616,"onst TMVA::kNN::VarType var1, const UInt_t ivar) const; UInt_tGetNTgt() const; UInt_tGetNVar() const; const TMVA::kNN::VarVec&GetTargets() const; TMVA::kNN::VarTypeGetTgt(UInt_t i) const; TMVA::kNN::VarTypeGetTgt(const UInt_t i) const; Short_tGetType() const; TMVA::kNN::VarTypeGetVar(UInt_t i) const; TMVA::kNN::VarTypeGetVar(const UInt_t i) const; const TMVA::kNN::VarVec&GetVars() const; Double_tGetWeight() const; TMVA::kNN::Event&operator=(const TMVA::kNN::Event&); voidPrint() const; voidPrint(ostream& os) const; voidSetTargets(const TMVA::kNN::VarVec& tvec). Data Members; private:. TMVA::kNN::VarVecfTgttargets for regression analysis; Short_tfTypeevent type ==0 or == 1, expand it to arbitrary class types? ; TMVA::kNN::VarVecfVarcoordinates (variables) for knn search; Double_tfWeightevent weight. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Event(); Create an Event object.; When the constructor is invoked for the first time, the class static; variable fgTracks is 0 and the TClonesArray fgTracks is created. ~Event(). Event(). Event(const TMVA::kNN::VarVec& vec, Double_t weight, Short_t type). Event(const TMVA::kNN::VarVec& vec, Double_t weight, Short_t type, const TMVA::kNN::VarVec& tvec). Double_t GetWeight() const. VarType GetVar(UInt_t i) const. VarType GetTgt(UInt_t i) const. UInt_t GetNVar() const. UInt_t GetNTgt() const. Short_t GetType() const. VarType GetDist(TMVA::kNN::VarType var, UInt_t ivar) const; keep these two function separate. VarType GetDist(const TMVA::kNN::Event& other) const. void SetTargets(const TMVA::kNN::VarVec& tvec). const VarVec& GetTargets() const. const VarVec& GetVars() const. void Print() const. void Print(ostream& os) const. VarType GetDist(const TMVA::kNN::VarType var1, const UInt_t ivar) const. inlined functions for Event class. VarType GetVar(const UInt_t i) const. VarType GetTgt(const UInt_t i) const. » Author: Rustem Ospanov » Copyright (c) 2007: *; » Last changed: root/tmva $Id: Mod",MatchSource.WIKI,root/html532/TMVA__kNN__Event.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__kNN__Event.html
https://root.cern/root/html532/TMVA__kNN__Event.html:2917,Performance,perform,performance,2917,"he first point; Float_t fZlast; //Z coordinate of the last point; Double32_t fCharge; //Charge of this track; Double32_t fVertex[3]; //Track vertex position; Int_t fNpoint; //Number of points for this track; Short_t fValid; //Validity criterion; Int_t fNsp; //Number of points for this track with a special value; Double32_t *fPointValue; //[fNsp] a special quantity for some point.; TBits fTriggerBits; //Bits triggered by this track. An example of a batch program to use the Event/Track classes is given; in this directory: MainEvent.; Look also in the same directory at the following macros:; - eventa.C an example how to read the tree; - eventb.C how to read events conditionally. During the processing of the event (optionally) also a large number; of histograms can be filled. The creation and handling of the; histograms is taken care of by the HistogramManager class. Note: This version of the class Event (see EventMT.h and EventMT.cxx; for an alternative) uses static variables to improve performance (by; reducing the number of memory allocations). Consequently, only one; instance of the class Event should be in use at a time (a 2nd instance; would share the array of Tracks with the first instance). Function Members (Methods); public:. ~Event(); TMVA::kNN::EventEvent(); TMVA::kNN::EventEvent(const TMVA::kNN::Event&); TMVA::kNN::EventEvent(const TMVA::kNN::VarVec& vec, Double_t weight, Short_t type); TMVA::kNN::EventEvent(const TMVA::kNN::VarVec& vec, Double_t weight, Short_t type, const TMVA::kNN::VarVec& tvec); TMVA::kNN::VarTypeGetDist(const TMVA::kNN::Event& other) const; TMVA::kNN::VarTypeGetDist(TMVA::kNN::VarType var, UInt_t ivar) const; TMVA::kNN::VarTypeGetDist(const TMVA::kNN::VarType var1, const UInt_t ivar) const; UInt_tGetNTgt() const; UInt_tGetNVar() const; const TMVA::kNN::VarVec&GetTargets() const; TMVA::kNN::VarTypeGetTgt(UInt_t i) const; TMVA::kNN::VarTypeGetTgt(const UInt_t i) const; Short_tGetType() const; TMVA::kNN::VarTypeGetVar(UInt_t i) const; TMVA",MatchSource.WIKI,root/html532/TMVA__kNN__Event.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__kNN__Event.html
https://root.cern/root/html532/TMVA__kNN__Event.html:337,Usability,simpl,simple,337,. TMVA::kNN::Event. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TEST; » TMVA::kNN::Event. class TMVA::kNN::Event. Event and Track classes. The Event class is a naive/simple example of an event structure.; public:; char fType[20];; char *fEventName; //run+event number in character format; Int_t fNtrack;; Int_t fNseg;; Int_t fNvertex;; UInt_t fFlag;; Double32_t fTemperature;; Int_t fMeasures[10];; Double32_t fMatrix[4][4];; Double32_t *fClosestDistance; //[fNvertex] indexed array!; EventHeader fEvtHdr;; TClonesArray *fTracks;; TRefArray *fHighPt; //array of High Pt tracks only; TRefArray *fMuons; //array of Muon tracks only; TRef fLastTrack; //pointer to last track; TRef fHistoWeb; //EXEC:GetHistoWeb reference to an histogram in a TWebFile; TH1F *fH;; TBits fTriggerBits; //Bits triggered by this event. The EventHeader class has 3 data members (integers):; public:; Int_t fEvtNum;; Int_t fRun;; Int_t fDate;. The Event data member fTracks is a pointer to a TClonesArray.; It is an array of a variable number of tracks per event.; Each element of the array is an object of class Track with the members:; private:; Float_t fPx; //X component of the momentum; Float_t fPy; //Y component of the momentum; Float_t fPz; //Z component of the momentum; Float_t fRandom; //A random track quantity; Float_t fMass2; //The mass square of this particle; Float_t fBx; //X intercept at the vertex; Float_t fBy; //Y intercept at the vertex; Float_t fMeanCharge; //Mean charge deposition of all hits of this track; Float_t fXfirst; //X coordinate of the first point; Float_t fXlast; //X coordinate of the last point; Float_t fYfirst; //Y coordinate of the first point; Float_t fYlast; //Y coordinate of the last point; Float_t fZfirst; //Z coordinate of the first point; Float_t fZlast; //Z coordinate of the last point; Double32_t fCharg,MatchSource.WIKI,root/html532/TMVA__kNN__Event.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__kNN__Event.html
https://root.cern/root/html532/TMVA__MCFitter.html:1606,Availability,error,error,1606,"t::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tTMVA::FitterBase::EstimatorFunction(vector<Double_t>& parameters); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TMVA::IFitterTarget&TMVA::FitterBase::GetFitterTarget() const; virtual const char*TObject::GetIconName() const; virtual const char*TMVA::FitterBase::GetName() const; Int_tTMVA::FitterBase::GetNpars() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&TMVA::Configurable::GetOptions() const; virtual const char*TObject::GetT",MatchSource.WIKI,root/html532/TMVA__MCFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MCFitter.html
https://root.cern/root/html532/TMVA__MCFitter.html:1690,Availability,error,error,1690,"c TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tTMVA::FitterBase::EstimatorFunction(vector<Double_t>& parameters); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TMVA::IFitterTarget&TMVA::FitterBase::GetFitterTarget() const; virtual const char*TObject::GetIconName() const; virtual const char*TMVA::FitterBase::GetName() const; Int_tTMVA::FitterBase::GetNpars() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&TMVA::Configurable::GetOptions() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::Han",MatchSource.WIKI,root/html532/TMVA__MCFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MCFitter.html
https://root.cern/root/html532/TMVA__MCFitter.html:7654,Deployability,configurat,configuration,7654," b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&TMVA::FitterBase::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. virtual voidDeclareOptions(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringTMVA::FitterBase::fClassNameremove TMVA:: from TObject name; TMVA::IFitterTarget&TMVA::FitterBase::fFitterTargetpointer to target of fitting procedure; TMVA::MsgLogger*TMVA::FitterBase::fLoggermessage logger; Int_tTMVA::FitterBase::fNparsnumber of parameters; const vector<TMVA::Interval*>TMVA::FitterBase::fRangesallowed intervals. private:. Int_tfSamplesnumber of MC samples; UInt_tfSeedSeed for the random generator (0 takes random seeds); Double_tfSigmanew samples are generated randomly with a gaussian probability with fSigma around the current best value. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MCFitter(TMVA::IFitterTarget& target, const TString& name, const vector<TMVA::Interval*>& ranges, const TString& theOption); constructor. void DeclareOptions(); Declare MCFitter options. void SetParameters(Int_t cycles); set MC fitter configuration parameters. Double_t Run(vector<Double_t>& pars); Execute fitting. virtual ~MCFitter(); {}. » Author: Andreas Hoecker, Peter Speckmayer, Joerg Stelzer, Helge Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: MCFitter.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__MCFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MCFitter.html
https://root.cern/root/html532/TMVA__MCFitter.html:7654,Modifiability,config,configuration,7654," b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&TMVA::FitterBase::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. virtual voidDeclareOptions(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringTMVA::FitterBase::fClassNameremove TMVA:: from TObject name; TMVA::IFitterTarget&TMVA::FitterBase::fFitterTargetpointer to target of fitting procedure; TMVA::MsgLogger*TMVA::FitterBase::fLoggermessage logger; Int_tTMVA::FitterBase::fNparsnumber of parameters; const vector<TMVA::Interval*>TMVA::FitterBase::fRangesallowed intervals. private:. Int_tfSamplesnumber of MC samples; UInt_tfSeedSeed for the random generator (0 takes random seeds); Double_tfSigmanew samples are generated randomly with a gaussian probability with fSigma around the current best value. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MCFitter(TMVA::IFitterTarget& target, const TString& name, const vector<TMVA::Interval*>& ranges, const TString& theOption); constructor. void DeclareOptions(); Declare MCFitter options. void SetParameters(Int_t cycles); set MC fitter configuration parameters. Double_t Run(vector<Double_t>& pars); Execute fitting. virtual ~MCFitter(); {}. » Author: Andreas Hoecker, Peter Speckmayer, Joerg Stelzer, Helge Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: MCFitter.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__MCFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MCFitter.html
https://root.cern/root/html532/TMVA__MCFitter.html:6966,Testability,log,logger,6966,"tream& o, const TString& prefix) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&TMVA::FitterBase::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. virtual voidDeclareOptions(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringTMVA::FitterBase::fClassNameremove TMVA:: from TObject name; TMVA::IFitterTarget&TMVA::FitterBase::fFitterTargetpointer to target of fitting procedure; TMVA::MsgLogger*TMVA::FitterBase::fLoggermessage logger; Int_tTMVA::FitterBase::fNparsnumber of parameters; const vector<TMVA::Interval*>TMVA::FitterBase::fRangesallowed intervals. private:. Int_tfSamplesnumber of MC samples; UInt_tfSeedSeed for the random generator (0 takes random seeds); Double_tfSigmanew samples are generated randomly with a gaussian probability with fSigma around the current best value. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MCFitter(TMVA::IFitterTarget& target, const TString& name, const vector<TMVA::Interval*>& ranges, const TString& theOption); constructor. void DeclareOptions(); Declare MCFitter options. void SetParameters(Int_t cycles); set MC fitter configuration parameters. Double_t Run(vector<Double_t>& pars); Execute fitting. virtual ~MCFitter(); {}. » Author: Andreas Hoecker, Peter Speckmayer, Joerg Stelzer, Helge Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: MCFitter.h 40005 2011-06-27 15:29:10Z st",MatchSource.WIKI,root/html532/TMVA__MCFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MCFitter.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:519,Availability,avail,available,519,". TMVA::MethodANNBase. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodANNBase. class TMVA::MethodANNBase: public TMVA::MethodBase. Base class for all TMVA methods using artificial neural networks. Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~MethodANNBase(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidTMVA::MethodBase::CheckSetup(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; Bool_tDebug() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidDeclareOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Dr",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:2333,Availability,error,error,2333,"rableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; Bool_tDebug() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidDeclareOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt, TMVA::Types",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:2417,Availability,error,error,2417,"bject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; Bool_tDebug() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidDeclareOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt, TMVA::Types::ETreeType type) const; const vector<TMVA::Event*>&TMVA::MethodBase::GetEventCollec",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:16525,Energy Efficiency,monitor,monitoring,16525,,MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:16594,Energy Efficiency,monitor,monitoring,16594,,MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:16659,Energy Efficiency,monitor,monitoring,16659,,MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:14610,Integrability,message,message,14610,"onfigurable::EnableLooseOptions(Bool_t b = kTRUE); voidForceNetworkCalculations(); voidForceNetworkInputs(const TMVA::Event* ev, Int_t ignoreIndex = -1); virtual voidTMVA::IMethod::GetHelpMessage() const; TMVA::TNeuron*GetInputNeuron(Int_t index); const TString&TMVA::MethodBase::GetInternalVarName(Int_t ivar) const; Double_tGetNetworkOutput(); const TString&TMVA::MethodBase::GetOriginalVarName(Int_t ivar) const; TMVA::TNeuron*GetOutputNeuron(Int_t index = 0); const TString&TMVA::Configurable::GetReferenceFile() const; static TMVA::MethodBase*TMVA::MethodBase::GetThisBase(); Float_tTMVA::MethodBase::GetTWeight(const TMVA::Event* ev) const; const TString&TMVA::MethodBase::GetWeightFileDir() const; Bool_tTMVA::MethodBase::HasTrainingTree() const; Bool_tTMVA::MethodBase::Help() const; Bool_tTMVA::MethodBase::IgnoreEventsWithNegWeightsInTraining() const; Bool_tTMVA::MethodBase::IsConstructedFromWeightFile() const; Bool_tTMVA::MethodBase::IsNormalised() const; TMVA::MsgLogger&TMVA::Configurable::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; virtual voidMakeClassSpecific(ostream&, const TString&) const; virtual voidTMVA::MethodBase::MakeClassSpecificHeader(ostream&, const TString& = """") const; voidTObject::MakeZombie(); voidTMVA::MethodBase::NoErrorCalc(Double_t *const err, Double_t *const errUpper); Int_tNumCycles(); vector<Int_t>*ParseLayoutString(TString layerSpec); voidPrintMessage(TString message, Bool_t force = kFALSE) const; voidTMVA::Configurable::ResetSetFlag(); voidTMVA::MethodBase::SetNormalised(Bool_t norm); voidTMVA::MethodBase::SetWeightFileDir(TString fileDir); voidTMVA::MethodBase::SetWeightFileName(TString); voidTMVA::MethodBase::Statistics(TMVA::Types::ETreeType treeType, const TString& theVarName, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&); Bool_tTMVA::MethodBase::TxtWeightsOnly() const; Bool_tTMVA::MethodBase::Verbose() const; voidWaitForKeyboard(); voidTMVA::Configurable::WriteOptionsReferenceToFile().",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:17612,Integrability,depend,depending,17612,"TMVA::TActivation*fActivationactivation function to be used for hidden layers; TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TH1*>fEpochMonHistBepoch monitoring hitograms for background; vector<TH1*>fEpochMonHistSepoch monitoring hitograms for signal; vector<TH1*>fEpochMonHistWepoch monitoring hitograms for weights; TMVA::MethodANNBase::EEstimatorfEstimator; TH1F*fEstimatorHistTestmonitors convergence of independent test sample; TH1F*fEstimatorHistTrainmonitors convergence of training sample; TStringfEstimatorS; TMVA::TActivation*fIdentityactivation for input and output layers; TMVA::TNeuronInput*fInputCalculatorinput calculator for all neurons; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; TMatrixDfInvHessianzjh; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TObjArray*fNetworkTObjArray of TObjArrays representing network; TMVA::TActivation*fOutputactivation function to be used for output layers, depending on estimator; Int_tfRandomSeedrandom seed for initial synapse weights; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; vector<Int_t>fRegulatorIdxindex to different priors from every synapses; vector<Double_t>fRegulatorsthe priors as regulator; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class; TObjArray*fSynapsesarray of pointers to synapses, no structural data; boolfUseRegulatorzjh; TRandom3*frgenrandom number generator for various uses.",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:20582,Integrability,message,message,20582," Bool_t fromFile = kFALSE); build network given a layout (number of neurons in each layer); and optional weights array. void BuildLayers(vector<Int_t>* layout, Bool_t from_file = false); build the network layers. void BuildLayer(Int_t numNeurons, TObjArray* curLayer, TObjArray* prevLayer, Int_t layerIndex, Int_t numLayers, Bool_t from_file = false); build a single layer with neurons and synapses connecting this; layer to the previous layer. void AddPreLinks(TMVA::TNeuron* neuron, TObjArray* prevLayer); add synapses connecting a neuron to its preceding layer. void InitWeights(); initialize the synapse weights randomly. void ForceWeights(vector<Double_t>* weights); force the synapse weights. void ForceNetworkInputs(const TMVA::Event* ev, Int_t ignoreIndex = -1); force the input values of the input neurons; force the value for each input neuron. void ForceNetworkCalculations(); calculate input values to each neuron. void PrintMessage(TString message, Bool_t force = kFALSE) const; print messages, turn off printing by setting verbose and debug flag appropriately. void WaitForKeyboard(); wait for keyboard input, for debugging. void PrintNetwork() const; print network representation, for debugging. void PrintLayer(TObjArray* layer) const; print a single layer, for debugging. void PrintNeuron(TMVA::TNeuron* neuron) const; print a neuron, for debugging. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); get the mva value generated by the NN. const std::vector<Float_t> & GetRegressionValues(); get the regression value generated by the NN. const std::vector<Float_t> & GetMulticlassValues(); get the multiclass classification values generated by the NN. void AddWeightsXMLTo(void* parent) const; create XML description of ANN classifier. void ReadWeightsFromXML(void* wghtnode); read MLP from xml weight file. void ReadWeightsFromStream(istream& istr); destroy/clear the network then read it back in from the weights file. const TMVA::Ranking* CreateRanking(); compute ra",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:20627,Integrability,message,messages,20627," Bool_t fromFile = kFALSE); build network given a layout (number of neurons in each layer); and optional weights array. void BuildLayers(vector<Int_t>* layout, Bool_t from_file = false); build the network layers. void BuildLayer(Int_t numNeurons, TObjArray* curLayer, TObjArray* prevLayer, Int_t layerIndex, Int_t numLayers, Bool_t from_file = false); build a single layer with neurons and synapses connecting this; layer to the previous layer. void AddPreLinks(TMVA::TNeuron* neuron, TObjArray* prevLayer); add synapses connecting a neuron to its preceding layer. void InitWeights(); initialize the synapse weights randomly. void ForceWeights(vector<Double_t>* weights); force the synapse weights. void ForceNetworkInputs(const TMVA::Event* ev, Int_t ignoreIndex = -1); force the input values of the input neurons; force the value for each input neuron. void ForceNetworkCalculations(); calculate input values to each neuron. void PrintMessage(TString message, Bool_t force = kFALSE) const; print messages, turn off printing by setting verbose and debug flag appropriately. void WaitForKeyboard(); wait for keyboard input, for debugging. void PrintNetwork() const; print network representation, for debugging. void PrintLayer(TObjArray* layer) const; print a single layer, for debugging. void PrintNeuron(TMVA::TNeuron* neuron) const; print a neuron, for debugging. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); get the mva value generated by the NN. const std::vector<Float_t> & GetRegressionValues(); get the regression value generated by the NN. const std::vector<Float_t> & GetMulticlassValues(); get the multiclass classification values generated by the NN. void AddWeightsXMLTo(void* parent) const; create XML description of ANN classifier. void ReadWeightsFromXML(void* wghtnode); read MLP from xml weight file. void ReadWeightsFromStream(istream& istr); destroy/clear the network then read it back in from the weights file. const TMVA::Ranking* CreateRanking(); compute ra",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:16296,Modifiability,layers,layers,16296,,MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:16952,Modifiability,layers,layers,16952,,MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:17089,Modifiability,variab,variables,17089,,MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:17302,Modifiability,variab,variable,17302,"TMVA::TActivation*fActivationactivation function to be used for hidden layers; TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TH1*>fEpochMonHistBepoch monitoring hitograms for background; vector<TH1*>fEpochMonHistSepoch monitoring hitograms for signal; vector<TH1*>fEpochMonHistWepoch monitoring hitograms for weights; TMVA::MethodANNBase::EEstimatorfEstimator; TH1F*fEstimatorHistTestmonitors convergence of independent test sample; TH1F*fEstimatorHistTrainmonitors convergence of training sample; TStringfEstimatorS; TMVA::TActivation*fIdentityactivation for input and output layers; TMVA::TNeuronInput*fInputCalculatorinput calculator for all neurons; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; TMatrixDfInvHessianzjh; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TObjArray*fNetworkTObjArray of TObjArrays representing network; TMVA::TActivation*fOutputactivation function to be used for output layers, depending on estimator; Int_tfRandomSeedrandom seed for initial synapse weights; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; vector<Int_t>fRegulatorIdxindex to different priors from every synapses; vector<Double_t>fRegulatorsthe priors as regulator; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class; TObjArray*fSynapsesarray of pointers to synapses, no structural data; boolfUseRegulatorzjh; TRandom3*frgenrandom number generator for various uses.",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:17604,Modifiability,layers,layers,17604,"TMVA::TActivation*fActivationactivation function to be used for hidden layers; TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TH1*>fEpochMonHistBepoch monitoring hitograms for background; vector<TH1*>fEpochMonHistSepoch monitoring hitograms for signal; vector<TH1*>fEpochMonHistWepoch monitoring hitograms for weights; TMVA::MethodANNBase::EEstimatorfEstimator; TH1F*fEstimatorHistTestmonitors convergence of independent test sample; TH1F*fEstimatorHistTrainmonitors convergence of training sample; TStringfEstimatorS; TMVA::TActivation*fIdentityactivation for input and output layers; TMVA::TNeuronInput*fInputCalculatorinput calculator for all neurons; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; TMatrixDfInvHessianzjh; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TObjArray*fNetworkTObjArray of TObjArrays representing network; TMVA::TActivation*fOutputactivation function to be used for output layers, depending on estimator; Int_tfRandomSeedrandom seed for initial synapse weights; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; vector<Int_t>fRegulatorIdxindex to different priors from every synapses; vector<Double_t>fRegulatorsthe priors as regulator; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class; TObjArray*fSynapsesarray of pointers to synapses, no structural data; boolfUseRegulatorzjh; TRandom3*frgenrandom number generator for various uses.",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:18939,Modifiability,variab,variables,18939,"t>fRegulatorsthe priors as regulator; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class; TObjArray*fSynapsesarray of pointers to synapses, no structural data; boolfUseRegulatorzjh; TRandom3*frgenrandom number generator for various uses. private:. TObjArray*fInputLayercache this for fast access; TStringfLayerSpeclayout specification option; Int_tfNcyclesnumber of epochs to train; TStringfNeuronInputTypename of neuron input calculator class; TStringfNeuronTypename of neuron activation function class; vector<TNeuron*>fOutputNeuronscache this for fast access; static const Bool_tfgDEBUGdebug flag. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; void DeclareOptions(); define the options (their key words) that can be set in the option string; here the options valid for ALL MVA methods are declared.; know options: NCycles=xx :the number of training cycles; Normalize=kTRUE,kFALSe :if normalised in put variables should be used; HiddenLayser=""N-1,N-2"" :the specification of the hidden layers; NeuronType=sigmoid,tanh,radial,linar : the type of activation function; used at the neuronn. void ProcessOptions(); do nothing specific at this moment. vector<Int_t>* ParseLayoutString(TString layerSpec); parse layout specification string and return a vector, each entry; containing the number of neurons to go in each successive layer. void InitANNBase(); initialize ANNBase object. ~MethodANNBase(); destructor. void DeleteNetwork(); delete/clear network. void DeleteNetworkLayer(TObjArray*& layer); delete a network layer. void BuildNetwork(vector<Int_t>* layout, vector<Double_t>* weights = NULL, Bool_t fromFile = kFALSE); build network given a layout (number of neurons in each layer); and optional weights array. void BuildLayers(vector<Int_t>* layout, Bool_t from_file = false); build the network layers. void BuildLayer(Int_t numNeurons, TObjArray* curLayer, TObjArray* prevLayer, Int_t layerIndex, Int_t numLayers, Bool_t from_file = false",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:19021,Modifiability,layers,layers,19021,"t>fRegulatorsthe priors as regulator; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class; TObjArray*fSynapsesarray of pointers to synapses, no structural data; boolfUseRegulatorzjh; TRandom3*frgenrandom number generator for various uses. private:. TObjArray*fInputLayercache this for fast access; TStringfLayerSpeclayout specification option; Int_tfNcyclesnumber of epochs to train; TStringfNeuronInputTypename of neuron input calculator class; TStringfNeuronTypename of neuron activation function class; vector<TNeuron*>fOutputNeuronscache this for fast access; static const Bool_tfgDEBUGdebug flag. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; void DeclareOptions(); define the options (their key words) that can be set in the option string; here the options valid for ALL MVA methods are declared.; know options: NCycles=xx :the number of training cycles; Normalize=kTRUE,kFALSe :if normalised in put variables should be used; HiddenLayser=""N-1,N-2"" :the specification of the hidden layers; NeuronType=sigmoid,tanh,radial,linar : the type of activation function; used at the neuronn. void ProcessOptions(); do nothing specific at this moment. vector<Int_t>* ParseLayoutString(TString layerSpec); parse layout specification string and return a vector, each entry; containing the number of neurons to go in each successive layer. void InitANNBase(); initialize ANNBase object. ~MethodANNBase(); destructor. void DeleteNetwork(); delete/clear network. void DeleteNetworkLayer(TObjArray*& layer); delete a network layer. void BuildNetwork(vector<Int_t>* layout, vector<Double_t>* weights = NULL, Bool_t fromFile = kFALSE); build network given a layout (number of neurons in each layer); and optional weights array. void BuildLayers(vector<Int_t>* layout, Bool_t from_file = false); build the network layers. void BuildLayer(Int_t numNeurons, TObjArray* curLayer, TObjArray* prevLayer, Int_t layerIndex, Int_t numLayers, Bool_t from_file = false",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:19834,Modifiability,layers,layers,19834,"s valid for ALL MVA methods are declared.; know options: NCycles=xx :the number of training cycles; Normalize=kTRUE,kFALSe :if normalised in put variables should be used; HiddenLayser=""N-1,N-2"" :the specification of the hidden layers; NeuronType=sigmoid,tanh,radial,linar : the type of activation function; used at the neuronn. void ProcessOptions(); do nothing specific at this moment. vector<Int_t>* ParseLayoutString(TString layerSpec); parse layout specification string and return a vector, each entry; containing the number of neurons to go in each successive layer. void InitANNBase(); initialize ANNBase object. ~MethodANNBase(); destructor. void DeleteNetwork(); delete/clear network. void DeleteNetworkLayer(TObjArray*& layer); delete a network layer. void BuildNetwork(vector<Int_t>* layout, vector<Double_t>* weights = NULL, Bool_t fromFile = kFALSE); build network given a layout (number of neurons in each layer); and optional weights array. void BuildLayers(vector<Int_t>* layout, Bool_t from_file = false); build the network layers. void BuildLayer(Int_t numNeurons, TObjArray* curLayer, TObjArray* prevLayer, Int_t layerIndex, Int_t numLayers, Bool_t from_file = false); build a single layer with neurons and synapses connecting this; layer to the previous layer. void AddPreLinks(TMVA::TNeuron* neuron, TObjArray* prevLayer); add synapses connecting a neuron to its preceding layer. void InitWeights(); initialize the synapse weights randomly. void ForceWeights(vector<Double_t>* weights); force the synapse weights. void ForceNetworkInputs(const TMVA::Event* ev, Int_t ignoreIndex = -1); force the input values of the input neurons; force the value for each input neuron. void ForceNetworkCalculations(); calculate input values to each neuron. void PrintMessage(TString message, Bool_t force = kFALSE) const; print messages, turn off printing by setting verbose and debug flag appropriately. void WaitForKeyboard(); wait for keyboard input, for debugging. void PrintNetwork() const; ",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:21644,Modifiability,variab,variables,21644,"ges, turn off printing by setting verbose and debug flag appropriately. void WaitForKeyboard(); wait for keyboard input, for debugging. void PrintNetwork() const; print network representation, for debugging. void PrintLayer(TObjArray* layer) const; print a single layer, for debugging. void PrintNeuron(TMVA::TNeuron* neuron) const; print a neuron, for debugging. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); get the mva value generated by the NN. const std::vector<Float_t> & GetRegressionValues(); get the regression value generated by the NN. const std::vector<Float_t> & GetMulticlassValues(); get the multiclass classification values generated by the NN. void AddWeightsXMLTo(void* parent) const; create XML description of ANN classifier. void ReadWeightsFromXML(void* wghtnode); read MLP from xml weight file. void ReadWeightsFromStream(istream& istr); destroy/clear the network then read it back in from the weights file. const TMVA::Ranking* CreateRanking(); compute ranking of input variables by summing function of weights. void CreateWeightMonitoringHists(const TString& bulkname, vector<TH1*>* hv = 0) const. void WriteMonitoringHistosToFile() const; write histograms to file. void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. Bool_t Debug() const; who the hell makes such strange Debug flags that even use ""global pointers"".. void SetActivation(TMVA::TActivation* activation); setters for subclasses. void SetNeuronInputCalculator(TMVA::TNeuronInput* inputCalculator). void Train(); this will have to be overridden by every subclass. Double_t GetNetworkOutput(); { return GetOutputNeuron()->GetActivationValue(); }. Int_t NumCycles(); accessors. { return fNcycles; }. TNeuron* GetInputNeuron(Int_t index); { return (TNeuron*)fInputLayer->At(index); }. TNeuron* GetOutputNeuron(Int_t index = 0); { return fOutputNeurons.at(index); }. » Author: Andreas Hoecker, Peter Speckmayer, Matt Jachowski, Jan Therhaag » Copyright (c) 2",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:11530,Performance,tune,tuneParameters,11530,"SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); voidSetNeuronInputCalculator(TMVA::TNeuronInput* inputCalculator); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:18278,Security,access,access,18278,"ase::fNbinsMVAoutputnumber of bins in MVA output histograms; TObjArray*fNetworkTObjArray of TObjArrays representing network; TMVA::TActivation*fOutputactivation function to be used for output layers, depending on estimator; Int_tfRandomSeedrandom seed for initial synapse weights; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; vector<Int_t>fRegulatorIdxindex to different priors from every synapses; vector<Double_t>fRegulatorsthe priors as regulator; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class; TObjArray*fSynapsesarray of pointers to synapses, no structural data; boolfUseRegulatorzjh; TRandom3*frgenrandom number generator for various uses. private:. TObjArray*fInputLayercache this for fast access; TStringfLayerSpeclayout specification option; Int_tfNcyclesnumber of epochs to train; TStringfNeuronInputTypename of neuron input calculator class; TStringfNeuronTypename of neuron activation function class; vector<TNeuron*>fOutputNeuronscache this for fast access; static const Bool_tfgDEBUGdebug flag. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; void DeclareOptions(); define the options (their key words) that can be set in the option string; here the options valid for ALL MVA methods are declared.; know options: NCycles=xx :the number of training cycles; Normalize=kTRUE,kFALSe :if normalised in put variables should be used; HiddenLayser=""N-1,N-2"" :the specification of the hidden layers; NeuronType=sigmoid,tanh,radial,linar : the type of activation function; used at the neuronn. void ProcessOptions(); do nothing specific at this moment. vector<Int_t>* ParseLayoutString(TString layerSpec); parse layout specification string and return a vector, each entry; containing the number of neurons to go in each successive layer. void InitANNBase(); initialize ANNBase object. ",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:18544,Security,access,access,18544,"ase::fNbinsMVAoutputnumber of bins in MVA output histograms; TObjArray*fNetworkTObjArray of TObjArrays representing network; TMVA::TActivation*fOutputactivation function to be used for output layers, depending on estimator; Int_tfRandomSeedrandom seed for initial synapse weights; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; vector<Int_t>fRegulatorIdxindex to different priors from every synapses; vector<Double_t>fRegulatorsthe priors as regulator; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class; TObjArray*fSynapsesarray of pointers to synapses, no structural data; boolfUseRegulatorzjh; TRandom3*frgenrandom number generator for various uses. private:. TObjArray*fInputLayercache this for fast access; TStringfLayerSpeclayout specification option; Int_tfNcyclesnumber of epochs to train; TStringfNeuronInputTypename of neuron input calculator class; TStringfNeuronTypename of neuron activation function class; vector<TNeuron*>fOutputNeuronscache this for fast access; static const Bool_tfgDEBUGdebug flag. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; void DeclareOptions(); define the options (their key words) that can be set in the option string; here the options valid for ALL MVA methods are declared.; know options: NCycles=xx :the number of training cycles; Normalize=kTRUE,kFALSe :if normalised in put variables should be used; HiddenLayser=""N-1,N-2"" :the specification of the hidden layers; NeuronType=sigmoid,tanh,radial,linar : the type of activation function; used at the neuronn. void ProcessOptions(); do nothing specific at this moment. vector<Int_t>* ParseLayoutString(TString layerSpec); parse layout specification string and return a vector, each entry; containing the number of neurons to go in each successive layer. void InitANNBase(); initialize ANNBase object. ",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:22344,Security,access,accessors,22344,"d PrintNeuron(TMVA::TNeuron* neuron) const; print a neuron, for debugging. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); get the mva value generated by the NN. const std::vector<Float_t> & GetRegressionValues(); get the regression value generated by the NN. const std::vector<Float_t> & GetMulticlassValues(); get the multiclass classification values generated by the NN. void AddWeightsXMLTo(void* parent) const; create XML description of ANN classifier. void ReadWeightsFromXML(void* wghtnode); read MLP from xml weight file. void ReadWeightsFromStream(istream& istr); destroy/clear the network then read it back in from the weights file. const TMVA::Ranking* CreateRanking(); compute ranking of input variables by summing function of weights. void CreateWeightMonitoringHists(const TString& bulkname, vector<TH1*>* hv = 0) const. void WriteMonitoringHistosToFile() const; write histograms to file. void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. Bool_t Debug() const; who the hell makes such strange Debug flags that even use ""global pointers"".. void SetActivation(TMVA::TActivation* activation); setters for subclasses. void SetNeuronInputCalculator(TMVA::TNeuronInput* inputCalculator). void Train(); this will have to be overridden by every subclass. Double_t GetNetworkOutput(); { return GetOutputNeuron()->GetActivationValue(); }. Int_t NumCycles(); accessors. { return fNcycles; }. TNeuron* GetInputNeuron(Int_t index); { return (TNeuron*)fInputLayer->At(index); }. TNeuron* GetOutputNeuron(Int_t index = 0); { return fOutputNeurons.at(index); }. » Author: Andreas Hoecker, Peter Speckmayer, Matt Jachowski, Jan Therhaag » Copyright (c) 2005-2011: *; » Last changed: root/tmva $Id: MethodANNBase.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:11332,Testability,test,testTime,11332,"nalysisType(TMVA::Types::EAnalysisType type); voidTMVA::MethodBase::SetBaseDir(TDirectory* methodDir); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); voidSetNeuronInputCalculator(TMVA::TNeuronInput* inputCalculator); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObj",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:16164,Testability,test,testing,16164,"A::Configurable::WriteOptionsReferenceToFile(). private:. voidAddPreLinks(TMVA::TNeuron* neuron, TObjArray* prevLayer); voidBuildLayer(Int_t numNeurons, TObjArray* curLayer, TObjArray* prevLayer, Int_t layerIndex, Int_t numLayers, Bool_t from_file = false); voidBuildLayers(vector<Int_t>* layout, Bool_t from_file = false); voidDeleteNetwork(); voidDeleteNetworkLayer(TObjArray*& layer); voidForceWeights(vector<Double_t>* weights); voidInitWeights(); voidPrintLayer(TObjArray* layer) const; voidPrintNeuron(TMVA::TNeuron* neuron) const. Data Members; public:. enum EEstimator { kMSE; kCE; };; enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::TActivation*fActivationactivation function to be used for hidden layers; TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TH1*>fEpochMonHistBepoch monitoring hitograms for background; vector<TH1*>fEpochMonHistSepoch monitoring hitograms for signal; vector<TH1*>fEpochMonHistWepoch monitoring hitograms for weights; TMVA::MethodANNBase::EEstimatorfEstimator; TH1F*fEstimatorHistTestmonitors convergence of independent test sample; TH1F*fEstimatorHistTrainmonitors convergence of training sample; TStringfEstimatorS; TMVA::TActivation*fIdentityactivation for input and output layers; TMVA::TNeuronInput*fInputCalculatorinput calculator for all neurons; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; TMatrixDfInvHe",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:16795,Testability,test,test,16795,,MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:19472,Usability,clear,clear,19472,"on activation function class; vector<TNeuron*>fOutputNeuronscache this for fast access; static const Bool_tfgDEBUGdebug flag. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; void DeclareOptions(); define the options (their key words) that can be set in the option string; here the options valid for ALL MVA methods are declared.; know options: NCycles=xx :the number of training cycles; Normalize=kTRUE,kFALSe :if normalised in put variables should be used; HiddenLayser=""N-1,N-2"" :the specification of the hidden layers; NeuronType=sigmoid,tanh,radial,linar : the type of activation function; used at the neuronn. void ProcessOptions(); do nothing specific at this moment. vector<Int_t>* ParseLayoutString(TString layerSpec); parse layout specification string and return a vector, each entry; containing the number of neurons to go in each successive layer. void InitANNBase(); initialize ANNBase object. ~MethodANNBase(); destructor. void DeleteNetwork(); delete/clear network. void DeleteNetworkLayer(TObjArray*& layer); delete a network layer. void BuildNetwork(vector<Int_t>* layout, vector<Double_t>* weights = NULL, Bool_t fromFile = kFALSE); build network given a layout (number of neurons in each layer); and optional weights array. void BuildLayers(vector<Int_t>* layout, Bool_t from_file = false); build the network layers. void BuildLayer(Int_t numNeurons, TObjArray* curLayer, TObjArray* prevLayer, Int_t layerIndex, Int_t numLayers, Bool_t from_file = false); build a single layer with neurons and synapses connecting this; layer to the previous layer. void AddPreLinks(TMVA::TNeuron* neuron, TObjArray* prevLayer); add synapses connecting a neuron to its preceding layer. void InitWeights(); initialize the synapse weights randomly. void ForceWeights(vector<Double_t>* weights); force the synapse weights. void ForceNetworkInputs(const TMVA::Event* ev, Int_t ignoreIndex = -1); force the input values of the input neurons; force the value for",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:21519,Usability,clear,clear,21519,"ate input values to each neuron. void PrintMessage(TString message, Bool_t force = kFALSE) const; print messages, turn off printing by setting verbose and debug flag appropriately. void WaitForKeyboard(); wait for keyboard input, for debugging. void PrintNetwork() const; print network representation, for debugging. void PrintLayer(TObjArray* layer) const; print a single layer, for debugging. void PrintNeuron(TMVA::TNeuron* neuron) const; print a neuron, for debugging. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); get the mva value generated by the NN. const std::vector<Float_t> & GetRegressionValues(); get the regression value generated by the NN. const std::vector<Float_t> & GetMulticlassValues(); get the multiclass classification values generated by the NN. void AddWeightsXMLTo(void* parent) const; create XML description of ANN classifier. void ReadWeightsFromXML(void* wghtnode); read MLP from xml weight file. void ReadWeightsFromStream(istream& istr); destroy/clear the network then read it back in from the weights file. const TMVA::Ranking* CreateRanking(); compute ranking of input variables by summing function of weights. void CreateWeightMonitoringHists(const TString& bulkname, vector<TH1*>* hv = 0) const. void WriteMonitoringHistosToFile() const; write histograms to file. void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. Bool_t Debug() const; who the hell makes such strange Debug flags that even use ""global pointers"".. void SetActivation(TMVA::TActivation* activation); setters for subclasses. void SetNeuronInputCalculator(TMVA::TNeuronInput* inputCalculator). void Train(); this will have to be overridden by every subclass. Double_t GetNetworkOutput(); { return GetOutputNeuron()->GetActivationValue(); }. Int_t NumCycles(); accessors. { return fNcycles; }. TNeuron* GetInputNeuron(Int_t index); { return (TNeuron*)fInputLayer->At(index); }. TNeuron* GetOutputNeuron(Int_t index = 0); { return fOutputNeur",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:1973,Availability,avail,available,1973,"of their root mean squares.; The separation of an MVA x, defined by the integral; ½∫(S(x) − B(x))2/(S(x) + B(x))dx, where; S(x) and B(x) are the signal and background distributions, respectively.; The separation is zero for identical signal and background MVA shapes,; and it is one for disjunctive shapes.; ; The average, ∫x μ(S(x))dx, of the signal μ-transform.; The μ-transform of an MVA denotes the transformation that yields; a uniform background distribution. In this way, the signal distributions; S(x) can be directly compared among the various MVAs. The stronger S(x); peaks towards one, the better is the discrimination of the MVA. The; μ-transform is; documented here.; ; The MVA standard output also prints the linear correlation coefficients between; signal and background, which can be useful to eliminate variables that exhibit too; strong correlations.; ; . Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~MethodBase(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidAddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidCheckSetup(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*Data() const; TMVA::DataSetInfo&DataInfo() const; virtual voidDeclareCompatibilityOptions(); virtual vo",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:3552,Availability,error,error,3552,"al TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*Data() const; TMVA::DataSetInfo&DataInfo() const; virtual voidDeclareCompatibilityOptions(); virtual voidDeclareOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidDisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tDoMulticlass() const; Bool_tDoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeGetAnalysisType() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tGetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*GetEvent() const; const TMVA::Event*GetEvent(const TMVA::Event* ev) const; const TMVA::Event*GetEvent(Long64_t ievt) const; const TMVA::Event*GetEvent(Long64_t ievt, TMVA::Types::ETreeType type) const; const vector<TMVA::Event*>&GetEventCollection(TMVA::Types::ETreeType type); virtual",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:3636,Availability,error,error,3636,"pare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*Data() const; TMVA::DataSetInfo&DataInfo() const; virtual voidDeclareCompatibilityOptions(); virtual voidDeclareOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidDisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tDoMulticlass() const; Bool_tDoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeGetAnalysisType() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tGetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*GetEvent() const; const TMVA::Event*GetEvent(const TMVA::Event* ev) const; const TMVA::Event*GetEvent(Long64_t ievt) const; const TMVA::Event*GetEvent(Long64_t ievt, TMVA::Types::ETreeType type) const; const vector<TMVA::Event*>&GetEventCollection(TMVA::Types::ETreeType type); virtual const char*TObject::GetIconName() const; const TString&GetInputLabel(Int_t i) const",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:21603,Availability,avail,availabel,21603,"ing phase). void CheckSetup(); check may be overridden by derived class; (sometimes, eg, fitters are used which can only be implemented during training phase). void InitBase(); default initialization called by all constructors. void DeclareBaseOptions(); define the options (their key words) that can be set in the option string; here the options valid for ALL MVA methods are declared.; know options: VariableTransform=None,Decorrelated,PCA to use transformed variables; instead of the original ones; VariableTransformType=Signal,Background which decorrelation matrix to use; in the method. Only the Likelihood; Method can make proper use of independent; transformations of signal and background; fNbinsMVAPdf = 50 Number of bins used to create a PDF of MVA; fNsmoothMVAPdf = 2 Number of times a histogram is smoothed before creating the PDF; fHasMVAPdfs create PDFs for the MVA outputs; V for Verbose output (!V) for non verbos; H for Help message. void ProcessBaseOptions(); the option string is decoded, for availabel options see ""DeclareOptions"". void CreateVariableTransforms(const TString& trafoDefinition, TMVA::DataSetInfo& dataInfo, TMVA::TransformationHandler& transformationHandler, TMVA::MsgLogger& log); create variable transformations. void DeclareCompatibilityOptions(). std::map<TString,Double_t> OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); call the Optimzier with the set of paremeters and ranges that; are meant to be tuned. void SetTuneParameters(map<TString,Double_t> tuneParameters); set the tuning parameters accoding to the argument; This is just a dummy .. have a look at the MethodBDT how you could; perhaps implment the same thing for the other Classifiers.. void TrainMethod(). void GetRegressionDeviation(UInt_t tgtNum, TMVA::Types::ETreeType type, Double_t& stddev, Double_t& stddev90Percent) const. void AddRegressionOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void AddMul",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:30768,Availability,error,error,30768,"t* GetEvent(Long64_t ievt) const. const TMVA::Event* GetEvent(Long64_t ievt, TMVA::Types::ETreeType type) const. const TMVA::Event* GetTrainingEvent(Long64_t ievt) const. const TMVA::Event* GetTestingEvent(Long64_t ievt) const. void Train(). void SetTrainTime(Double_t trainTime); store and retrieve time used for training. { fTrainTime = trainTime; }. Double_t GetTrainTime() const; { return fTrainTime; }. void SetTestTime(Double_t testTime); store and retrieve time used for testing. { fTestTime = testTime; }. Double_t GetTestTime() const; { return fTestTime; }. void Init(); options treatment. void DeclareOptions(). void ProcessOptions(). void Reset(); reset the Method --> As if it was not yet trained, just instantiated; virtual void Reset() = 0;; for the moment, I provide a dummy (that would not work) default, just to make; compilation/running w/o parameter optimisation still possible. {return;}. Double_t GetMvaValue(Double_t* errLower = 0, Double_t* errUpper = 0); classifier response:; some methods may return a per-event error estimate; error calculation is skipped if err==0. const std::vector<Float_t>& GetRegressionValues(); regression response. const std::vector<Float_t>& GetMulticlassValues(); multiclass classification response. const Ranking* CreateRanking(); create ranking. Bool_t MonitorBoost(TMVA::MethodBoost* ); perfrom extra actions during the boosting at different stages. {return kFALSE;}. void AddWeightsXMLTo(void* parent) const; the actual ""weights"". void ReadWeightsFromXML(void* wghtnode). void ReadWeightsFromStream(istream& ). void ReadWeightsFromStream(TFile& ); {}. const TString& GetJobName() const; ---------- public accessors -----------------------------------------------; classifier naming (a lot of names ... aren't they ;-). { return fJobName; }. const TString& GetMethodName() const; { return fMethodName; }. TString GetMethodTypeName() const; { return Types::Instance().GetMethodName(fMethodType); }. Types::EMVA GetMethodType() const; { return fMe",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:30784,Availability,error,error,30784,"t* GetEvent(Long64_t ievt) const. const TMVA::Event* GetEvent(Long64_t ievt, TMVA::Types::ETreeType type) const. const TMVA::Event* GetTrainingEvent(Long64_t ievt) const. const TMVA::Event* GetTestingEvent(Long64_t ievt) const. void Train(). void SetTrainTime(Double_t trainTime); store and retrieve time used for training. { fTrainTime = trainTime; }. Double_t GetTrainTime() const; { return fTrainTime; }. void SetTestTime(Double_t testTime); store and retrieve time used for testing. { fTestTime = testTime; }. Double_t GetTestTime() const; { return fTestTime; }. void Init(); options treatment. void DeclareOptions(). void ProcessOptions(). void Reset(); reset the Method --> As if it was not yet trained, just instantiated; virtual void Reset() = 0;; for the moment, I provide a dummy (that would not work) default, just to make; compilation/running w/o parameter optimisation still possible. {return;}. Double_t GetMvaValue(Double_t* errLower = 0, Double_t* errUpper = 0); classifier response:; some methods may return a per-event error estimate; error calculation is skipped if err==0. const std::vector<Float_t>& GetRegressionValues(); regression response. const std::vector<Float_t>& GetMulticlassValues(); multiclass classification response. const Ranking* CreateRanking(); create ranking. Bool_t MonitorBoost(TMVA::MethodBoost* ); perfrom extra actions during the boosting at different stages. {return kFALSE;}. void AddWeightsXMLTo(void* parent) const; the actual ""weights"". void ReadWeightsFromXML(void* wghtnode). void ReadWeightsFromStream(istream& ). void ReadWeightsFromStream(TFile& ); {}. const TString& GetJobName() const; ---------- public accessors -----------------------------------------------; classifier naming (a lot of names ... aren't they ;-). { return fJobName; }. const TString& GetMethodName() const; { return fMethodName; }. TString GetMethodTypeName() const; { return Types::Instance().GetMethodName(fMethodType); }. Types::EMVA GetMethodType() const; { return fMe",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:24399,Deployability,configurat,configuration,24399,"squared> of regression output versus ""true"" value from test sample. bias = average deviation; dev = average absolute deviation; rms = rms of deviation. void TestMulticlass(); test multiclass classification. void TestClassification(); initialization. void WriteStateToStream(ostream& tf) const; general method used in writing the header of the weight files where; the used variables, variable transformation type etc. is specified. void AddInfoItem(void* gi, const TString& name, const TString& value) const; xml writing. void AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType). void WriteStateToXML(void* parent) const; general method used in writing the header of the weight files where; the used variables, variable transformation type etc. is specified. void ReadStateFromStream(TFile& rf); write reference MVA distributions (and other information); to a ROOT type weight file. void WriteStateToFile() const; write options and weights to file; note that each one text file for the main configuration information; and one ROOT file for ROOT objects are created. void ReadStateFromFile(); Function to write options and weights to file. void ReadStateFromXMLString(const char* xmlstr); for reading from memory. void ReadStateFromXML(void* parent). void ReadStateFromStream(istream& tf); read the header from the weight files of the different MVA methods. void WriteVarsToStream(ostream& tf, const TString& prefix = """") const; write the list of variables (name, min, max) for a given data; transformation method to the stream. void ReadVarsFromStream(istream& istr); Read the variables (name, min, max) for a given data; transformation method from the stream. In the stream we only; expect the limits which will be set. void AddVarsXMLTo(void* parent) const; write variable info to XML. void AddSpectatorsXMLTo(void* parent) const; write spectator info to XML. void AddClassesXMLTo(void* parent) const; write class info to XML. void AddTargetsXMLTo(void* parent) const; wri",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:34713,Deployability,update,update,34713," }. void SetBaseDir(TDirectory* methodDir); { fBaseDir = methodDir; }. void SetMethodBaseDir(TDirectory* methodDir); { fMethodBaseDir = methodDir; }. UInt_t GetTrainingTMVAVersionCode() const; the TMVA version can be obtained and checked using; if (GetTrainingTMVAVersionCode()>TMVA_VERSION(3,7,2)) {...}; or; if (GetTrainingROOTVersionCode()>ROOT_VERSION(5,15,5)) {...}. { return fTMVATrainingVersion; }. UInt_t GetTrainingROOTVersionCode() const; { return fROOTTrainingVersion; }. TransformationHandler& GetTransformationHandler(Bool_t takeReroutedIfAvailable = true). const TransformationHandler& GetTransformationHandler(Bool_t takeReroutedIfAvailable = true) const. void RerouteTransformationHandler(TMVA::TransformationHandler* fTargetTransformation); { fTransformationPointer=fTargetTransformation; }. DataSetInfo& DataInfo() const; ---------- event accessors ------------------------------------------------; returns reference to data set. { return fDataSetInfo; }. UInt_t GetNEvents() const; event reference and update. { return Data()->GetNEvents(); }. Bool_t HasMVAPdfs() const; { return fHasMVAPdfs; }. void SetAnalysisType(TMVA::Types::EAnalysisType type); { fAnalysisType = type; }. Types::EAnalysisType GetAnalysisType() const; { return fAnalysisType; }. Bool_t DoRegression() const; { return fAnalysisType == Types::kRegression; }. Bool_t DoMulticlass() const; { return fAnalysisType == Types::kMulticlass; }. void DisableWriting(Bool_t setter); setter method for suppressing writing to XML and writing of standalone classes. { fDisableWriting = setter; }. const TString& GetWeightFileDir() const; { return fFileDir; }. Bool_t IsNormalised() const; are input variables normalised ?. { return fNormalise; }. void SetNormalised(Bool_t norm); { fNormalise = norm; }. Bool_t Verbose() const; set number of input variables (only used by MethodCuts, could perhaps be removed); void SetNvar( Int_t n ) { fNvar = n; }; verbose and help flags. { return fVerbose; }. Bool_t Help() const; { retur",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:26328,Energy Efficiency,monitor,monitoring,26328,"void AddTargetsXMLTo(void* parent) const; write target info to XML. void ReadVariablesFromXML(void* varnode); read variable info from XML. void ReadSpectatorsFromXML(void* specnode); read spectator info from XML. void ReadClassesFromXML(void* clsnode); read number of classes from XML. void ReadTargetsFromXML(void* tarnode); read target info from XML. TDirectory* BaseDir() const; returns the ROOT directory where info/histograms etc of the; corresponding MVA method instance are stored. TDirectory* MethodBaseDir() const; returns the ROOT directory where all instances of the; corresponding MVA method are stored. void SetWeightFileDir(TString fileDir); set directory of weight file. void SetWeightFileName(TString ); set the weight file name (depreciated). TString GetWeightFileName() const; retrieve weight file name. void WriteEvaluationHistosToFile(TMVA::Types::ETreeType treetype); writes all MVA evaluation histograms to file. void WriteMonitoringHistosToFile( void ); write special monitoring histograms to file; dummy implementation here -----------------. Bool_t GetLine(istream& fin, char* buf); reads one line from the input stream; checks for certain keywords and interprets; the line if keywords are found. void CreateMVAPdfs(); Create PDFs of the MVA output variables. Double_t GetProba(Double_t mvaVal, Double_t ap_sig); compute likelihood ratio. Double_t GetRarity(Double_t mvaVal, TMVA::Types::ESBType reftype = Types::kBackground) const; compute rarity:; R(x) = Integrate_[-oo..x] { PDF(x') dx' }; where PDF(x) is the PDF of the classifier's signal or background distribution. Double_t GetEfficiency(const TString& , TMVA::Types::ETreeType , Double_t& err); fill background efficiency (resp. rejection) versus signal efficiency plots; returns signal efficiency at background efficiency indicated in theString. Double_t GetTrainingEfficiency(const TString& ). std::vector<Float_t> GetMulticlassEfficiency(vector<std::vector<Float_t> >& purity). std::vector<Float_t> GetMulticlassTr",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:503,Integrability,depend,depends,503,". TMVA::MethodBase. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodBase. class TMVA::MethodBase: public TMVA::IMethod, public TMVA::Configurable. Virtual base Class for all MVA method; MethodBase hosts several specific evaluation methods.; The kind of MVA that provides optimal performance in an analysis strongly; depends on the particular application. The evaluation factory provides a; number of numerical benchmark results to directly assess the performance; of the MVA training on the independent test sample. These are:; ; The signal efficiency at three representative background efficiencies; (which is 1 − rejection).; The significance of an MVA estimator, defined by the difference; between the MVA mean values for signal and background, divided by the; quadratic sum of their root mean squares.; The separation of an MVA x, defined by the integral; ½∫(S(x) − B(x))2/(S(x) + B(x))dx, where; S(x) and B(x) are the signal and background distributions, respectively.; The separation is zero for identical signal and background MVA shapes,; and it is one for disjunctive shapes.; ; The average, ∫x μ(S(x))dx, of the signal μ-transform.; The μ-transform of an MVA denotes the transformation that yields; a uniform background distribution. In this way, the signal distributions; S(x) can be directly compared among the various MVAs. The stronger S(x); peaks towards one, the better is the discrimination of the MVA. The; μ-transform is; documented here.; ; The MVA standard output also prints the linear correlation coefficients between; signal and background, which can be useful to eliminate variables that exhibit too; strong correlations.; ; . Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; pub",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:21533,Integrability,message,message,21533,"ethods. void ProcessSetup(); process all options; the ""CheckForUnusedOptions"" is done in an independent call, since it may be overridden by derived class; (sometimes, eg, fitters are used which can only be implemented during training phase). void CheckSetup(); check may be overridden by derived class; (sometimes, eg, fitters are used which can only be implemented during training phase). void InitBase(); default initialization called by all constructors. void DeclareBaseOptions(); define the options (their key words) that can be set in the option string; here the options valid for ALL MVA methods are declared.; know options: VariableTransform=None,Decorrelated,PCA to use transformed variables; instead of the original ones; VariableTransformType=Signal,Background which decorrelation matrix to use; in the method. Only the Likelihood; Method can make proper use of independent; transformations of signal and background; fNbinsMVAPdf = 50 Number of bins used to create a PDF of MVA; fNsmoothMVAPdf = 2 Number of times a histogram is smoothed before creating the PDF; fHasMVAPdfs create PDFs for the MVA outputs; V for Verbose output (!V) for non verbos; H for Help message. void ProcessBaseOptions(); the option string is decoded, for availabel options see ""DeclareOptions"". void CreateVariableTransforms(const TString& trafoDefinition, TMVA::DataSetInfo& dataInfo, TMVA::TransformationHandler& transformationHandler, TMVA::MsgLogger& log); create variable transformations. void DeclareCompatibilityOptions(). std::map<TString,Double_t> OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); call the Optimzier with the set of paremeters and ranges that; are meant to be tuned. void SetTuneParameters(map<TString,Double_t> tuneParameters); set the tuning parameters accoding to the argument; This is just a dummy .. have a look at the MethodBDT how you could; perhaps implment the same thing for the other Classifiers.. void TrainMethod(). void GetRegressionDevia",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:29056,Integrability,interface,interface,29056,"= 0) const; calculate the area (integral) under the ROC curve as a; overall quality measure of the classification. Double_t GetMaximumSignificance(Double_t SignalEvents, Double_t BackgroundEvents, Double_t& optimal_significance_value) const; plot significance, S/Sqrt(S^2 + B^2), curve for given number; of signal and background events; returns cut for maximum significance; also returned via reference is the maximum significance. void Statistics(TMVA::Types::ETreeType treeType, const TString& theVarName, Double_t& , Double_t& , Double_t& , Double_t& , Double_t& , Double_t& ); calculates rms,mean, xmin, xmax of the event variable; this can be either done for the variables as they are or for; normalised variables (in the range of 0-1) if ""norm"" is set to kTRUE. void MakeClass(const TString& classFileName = TString("""")) const; create reader class for method (classification only at present). void PrintHelpMessage() const; prints out method-specific help method. Double_t IGetEffForRoot(Double_t ); interface for RootFinder. Double_t GetEffForRoot(Double_t ); returns efficiency as function of cut. const std::vector<TMVA::Event*>& GetEventCollection(TMVA::Types::ETreeType type). TString GetTrainingTMVAVersionString() const; calculates the TMVA version string from the training version code on the fly. TString GetTrainingROOTVersionString() const; calculates the ROOT version string from the training version code on the fly. TMVA::MethodBase* GetThisBase(); return a pointer the base class of this method. void ResetThisBase(); reset required for RootFinder. const TMVA::Event* GetEvent(const TMVA::Event* ev) const. const TMVA::Event* GetEvent() const. const TMVA::Event* GetEvent(Long64_t ievt) const. const TMVA::Event* GetEvent(Long64_t ievt, TMVA::Types::ETreeType type) const. const TMVA::Event* GetTrainingEvent(Long64_t ievt) const. const TMVA::Event* GetTestingEvent(Long64_t ievt) const. void Train(). void SetTrainTime(Double_t trainTime); store and retrieve time used for train",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:1785,Modifiability,variab,variables,1785," at three representative background efficiencies; (which is 1 − rejection).; The significance of an MVA estimator, defined by the difference; between the MVA mean values for signal and background, divided by the; quadratic sum of their root mean squares.; The separation of an MVA x, defined by the integral; ½∫(S(x) − B(x))2/(S(x) + B(x))dx, where; S(x) and B(x) are the signal and background distributions, respectively.; The separation is zero for identical signal and background MVA shapes,; and it is one for disjunctive shapes.; ; The average, ∫x μ(S(x))dx, of the signal μ-transform.; The μ-transform of an MVA denotes the transformation that yields; a uniform background distribution. In this way, the signal distributions; S(x) can be directly compared among the various MVAs. The stronger S(x); peaks towards one, the better is the discrimination of the MVA. The; μ-transform is; documented here.; ; The MVA standard output also prints the linear correlation coefficients between; signal and background, which can be useful to eliminate variables that exhibit too; strong correlations.; ; . Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~MethodBase(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidAddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidCheckSetup(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& th",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:16070,Modifiability,variab,variables,16070,"(ostream& tf) const; voidWriteStateToXML(void* parent) const; voidWriteVarsToStream(ostream& tf, const TString& prefix = """") const. Data Members; public:. enum EWeightFileType { kROOT; kTEXT; };; enum ECutOrientation { kNegative; kPositive; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tfSetupCompletedis method setup; const TMVA::Event*fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypefAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tfBackgroundClassindex of the Background-class; vector<TString>*fInputVarsvector of input variables used in MVA; vector<Float_t>*fMulticlassReturnValholds the return-values for the multiclass classification; Int_tfNbinsnumber of bins in input variable histograms; Int_tfNbinsHnumber of bins in evaluation histograms; Int_tfNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*fRegressionReturnValholds the return-values for the regression; UInt_tfSignalClassindex of the Signal-class. private:. TDirectory*fBaseDirbase directory for the instance, needed to know where to jump back from localDir; Bool_tfConstructedFromWeightFileis it obtained from weight file?; TMVA::MethodBase::ECutOrientationfCutOrientation+1 if Sig>Bkg, -1 otherwise; TMVA::DataSetInfo&fDataSetInfo! the data set information (sometimes needed); TMVA::PDF*fDefaultPDFdefault PDF definitions; Bool_tfDisableWriting! set to true in order to suppress writing to XML; TH1*fEffSefficiency histogram for rootfinder; vector<const std::vector<TMVA::Event*>*>fEventCollectionsif the method needs the complete event-collection, the transformed event coll. ist stored here.; TStri",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:16223,Modifiability,variab,variable,16223,"(ostream& tf) const; voidWriteStateToXML(void* parent) const; voidWriteVarsToStream(ostream& tf, const TString& prefix = """") const. Data Members; public:. enum EWeightFileType { kROOT; kTEXT; };; enum ECutOrientation { kNegative; kPositive; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tfSetupCompletedis method setup; const TMVA::Event*fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypefAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tfBackgroundClassindex of the Background-class; vector<TString>*fInputVarsvector of input variables used in MVA; vector<Float_t>*fMulticlassReturnValholds the return-values for the multiclass classification; Int_tfNbinsnumber of bins in input variable histograms; Int_tfNbinsHnumber of bins in evaluation histograms; Int_tfNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*fRegressionReturnValholds the return-values for the regression; UInt_tfSignalClassindex of the Signal-class. private:. TDirectory*fBaseDirbase directory for the instance, needed to know where to jump back from localDir; Bool_tfConstructedFromWeightFileis it obtained from weight file?; TMVA::MethodBase::ECutOrientationfCutOrientation+1 if Sig>Bkg, -1 otherwise; TMVA::DataSetInfo&fDataSetInfo! the data set information (sometimes needed); TMVA::PDF*fDefaultPDFdefault PDF definitions; Bool_tfDisableWriting! set to true in order to suppress writing to XML; TH1*fEffSefficiency histogram for rootfinder; vector<const std::vector<TMVA::Event*>*>fEventCollectionsif the method needs the complete event-collection, the transformed event coll. ist stored here.; TStri",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:17952,Modifiability,variab,variables,17952,"writing to XML; TH1*fEffSefficiency histogram for rootfinder; vector<const std::vector<TMVA::Event*>*>fEventCollectionsif the method needs the complete event-collection, the transformed event coll. ist stored here.; TStringfFileDirunix sub-directory for weight files (default: ""weights""); Bool_tfHasMVAPdfsMVA Pdfs are created for this classifier; Bool_tfHelphelp flag; Bool_tfIgnoreNegWeightsInTrainingIf true, events with negative weights are not used in training; TStringfJobNamename of job -> user defined, appears in weight files; TMVA::PDF*fMVAPdfBbackground MVA PDF; TMVA::PDF*fMVAPdfSsignal MVA PDF; Double_tfMeanBmean (background); Double_tfMeanSmean (signal); TDirectory*fMethodBaseDirbase directory for the method; TStringfMethodNamename of the method (set in derived class); TMVA::Types::EMVAfMethodTypetype of method (set in derived class); Int_tfNbinsMVAPdfnumber of bins used in histogram that creates PDF; Bool_tfNormalisenormalise input variables; Int_tfNsmoothMVAPdfnumber of times a histogram is smoothed before creating the PDF; TStringfParentDirmethod parent name, like booster name; UInt_tfROOTTrainingVersionROOT version used for training; Double_tfRmsBRMS (background); Double_tfRmsSRMS (signal); Double_tfSignalReferenceCutminimum requirement on the MVA output to declare an event signal-like; Double_tfSignalReferenceCutOrientationminimum requirement on the MVA output to declare an event signal-like; TMVA::PDF*fSplBPDFs of MVA distribution (background); TMVA::TSpline1*fSplRefBhelper splines for RootFinder (background); TMVA::TSpline1*fSplRefShelper splines for RootFinder (signal); TMVA::PDF*fSplSPDFs of MVA distribution (signal); TMVA::PDF*fSplTrainBPDFs of training MVA distribution (background); TSpline*fSplTrainEffBvsSsplines for training signal eff. versus background eff.; TMVA::TSpline1*fSplTrainRefBhelper splines for RootFinder (background); TMVA::TSpline1*fSplTrainRefShelper splines for RootFinder (signal); TMVA::PDF*fSplTrainSPDFs of training MVA distribu",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:19594,Modifiability,variab,variable,19594,"ibution (signal); TMVA::PDF*fSplTrainBPDFs of training MVA distribution (background); TSpline*fSplTrainEffBvsSsplines for training signal eff. versus background eff.; TMVA::TSpline1*fSplTrainRefBhelper splines for RootFinder (background); TMVA::TSpline1*fSplTrainRefShelper splines for RootFinder (signal); TMVA::PDF*fSplTrainSPDFs of training MVA distribution (signal); TSpline*fSpleffBvsSsplines for signal eff. versus background eff.; UInt_tfTMVATrainingVersionTMVA version used for training; Double_tfTestTimefor timing measurements; TStringfTestvarvariable used in evaluation, etc (mostly the MVA); Double_tfTrainTimefor timing measurements; TMVA::TransformationHandlerfTransformationthe list of transformations; TMVA::TransformationHandler*fTransformationPointerpointer to the rest of transformations; Bool_tfTxtWeightsOnlyif TRUE, write weights only to text files ; Bool_tfUseDecorrsynonymous for decorrelation; TStringfVarTransformStringlabels variable transform method; TMVA::Types::ESBTypefVariableTransformTypethis is the event type (sig or bgd) assumed for variable transform; TStringfVariableTransformTypeStringlabels variable transform type; Bool_tfVerboseverbose flag; TMVA::EMsgTypefVerbosityLevelverbosity level; TStringfVerbosityLevelStringverbosity level (user input string); TStringfWeightFileweight file name; Double_tfXmaxmaximum (signal and background); Double_tfXminminimum (signal and background); static TMVA::MethodBase*fgThisBasethis pointer; TH1F*fmvaBPDFs of MVA distribution (background); TH1F*fmvaSPDFs of MVA distribution (signal). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; ~MethodBase( void ); destructor. void SetupMethod(); setup of methods. void ProcessSetup(); process all options; the ""CheckForUnusedOptions"" is done in an independent call, since it may be overridden by derived class; (sometimes, eg, fitters are used which can only be implemented during training phase). void CheckSetup(); check may be overrid",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:19711,Modifiability,variab,variable,19711,"ibution (signal); TMVA::PDF*fSplTrainBPDFs of training MVA distribution (background); TSpline*fSplTrainEffBvsSsplines for training signal eff. versus background eff.; TMVA::TSpline1*fSplTrainRefBhelper splines for RootFinder (background); TMVA::TSpline1*fSplTrainRefShelper splines for RootFinder (signal); TMVA::PDF*fSplTrainSPDFs of training MVA distribution (signal); TSpline*fSpleffBvsSsplines for signal eff. versus background eff.; UInt_tfTMVATrainingVersionTMVA version used for training; Double_tfTestTimefor timing measurements; TStringfTestvarvariable used in evaluation, etc (mostly the MVA); Double_tfTrainTimefor timing measurements; TMVA::TransformationHandlerfTransformationthe list of transformations; TMVA::TransformationHandler*fTransformationPointerpointer to the rest of transformations; Bool_tfTxtWeightsOnlyif TRUE, write weights only to text files ; Bool_tfUseDecorrsynonymous for decorrelation; TStringfVarTransformStringlabels variable transform method; TMVA::Types::ESBTypefVariableTransformTypethis is the event type (sig or bgd) assumed for variable transform; TStringfVariableTransformTypeStringlabels variable transform type; Bool_tfVerboseverbose flag; TMVA::EMsgTypefVerbosityLevelverbosity level; TStringfVerbosityLevelStringverbosity level (user input string); TStringfWeightFileweight file name; Double_tfXmaxmaximum (signal and background); Double_tfXminminimum (signal and background); static TMVA::MethodBase*fgThisBasethis pointer; TH1F*fmvaBPDFs of MVA distribution (background); TH1F*fmvaSPDFs of MVA distribution (signal). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; ~MethodBase( void ); destructor. void SetupMethod(); setup of methods. void ProcessSetup(); process all options; the ""CheckForUnusedOptions"" is done in an independent call, since it may be overridden by derived class; (sometimes, eg, fitters are used which can only be implemented during training phase). void CheckSetup(); check may be overrid",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:19773,Modifiability,variab,variable,19773,"ibution (signal); TMVA::PDF*fSplTrainBPDFs of training MVA distribution (background); TSpline*fSplTrainEffBvsSsplines for training signal eff. versus background eff.; TMVA::TSpline1*fSplTrainRefBhelper splines for RootFinder (background); TMVA::TSpline1*fSplTrainRefShelper splines for RootFinder (signal); TMVA::PDF*fSplTrainSPDFs of training MVA distribution (signal); TSpline*fSpleffBvsSsplines for signal eff. versus background eff.; UInt_tfTMVATrainingVersionTMVA version used for training; Double_tfTestTimefor timing measurements; TStringfTestvarvariable used in evaluation, etc (mostly the MVA); Double_tfTrainTimefor timing measurements; TMVA::TransformationHandlerfTransformationthe list of transformations; TMVA::TransformationHandler*fTransformationPointerpointer to the rest of transformations; Bool_tfTxtWeightsOnlyif TRUE, write weights only to text files ; Bool_tfUseDecorrsynonymous for decorrelation; TStringfVarTransformStringlabels variable transform method; TMVA::Types::ESBTypefVariableTransformTypethis is the event type (sig or bgd) assumed for variable transform; TStringfVariableTransformTypeStringlabels variable transform type; Bool_tfVerboseverbose flag; TMVA::EMsgTypefVerbosityLevelverbosity level; TStringfVerbosityLevelStringverbosity level (user input string); TStringfWeightFileweight file name; Double_tfXmaxmaximum (signal and background); Double_tfXminminimum (signal and background); static TMVA::MethodBase*fgThisBasethis pointer; TH1F*fmvaBPDFs of MVA distribution (background); TH1F*fmvaSPDFs of MVA distribution (signal). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; ~MethodBase( void ); destructor. void SetupMethod(); setup of methods. void ProcessSetup(); process all options; the ""CheckForUnusedOptions"" is done in an independent call, since it may be overridden by derived class; (sometimes, eg, fitters are used which can only be implemented during training phase). void CheckSetup(); check may be overrid",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:21052,Modifiability,variab,variables,21052,"ethodBase*fgThisBasethis pointer; TH1F*fmvaBPDFs of MVA distribution (background); TH1F*fmvaSPDFs of MVA distribution (signal). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; ~MethodBase( void ); destructor. void SetupMethod(); setup of methods. void ProcessSetup(); process all options; the ""CheckForUnusedOptions"" is done in an independent call, since it may be overridden by derived class; (sometimes, eg, fitters are used which can only be implemented during training phase). void CheckSetup(); check may be overridden by derived class; (sometimes, eg, fitters are used which can only be implemented during training phase). void InitBase(); default initialization called by all constructors. void DeclareBaseOptions(); define the options (their key words) that can be set in the option string; here the options valid for ALL MVA methods are declared.; know options: VariableTransform=None,Decorrelated,PCA to use transformed variables; instead of the original ones; VariableTransformType=Signal,Background which decorrelation matrix to use; in the method. Only the Likelihood; Method can make proper use of independent; transformations of signal and background; fNbinsMVAPdf = 50 Number of bins used to create a PDF of MVA; fNsmoothMVAPdf = 2 Number of times a histogram is smoothed before creating the PDF; fHasMVAPdfs create PDFs for the MVA outputs; V for Verbose output (!V) for non verbos; H for Help message. void ProcessBaseOptions(); the option string is decoded, for availabel options see ""DeclareOptions"". void CreateVariableTransforms(const TString& trafoDefinition, TMVA::DataSetInfo& dataInfo, TMVA::TransformationHandler& transformationHandler, TMVA::MsgLogger& log); create variable transformations. void DeclareCompatibilityOptions(). std::map<TString,Double_t> OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); call the Optimzier with the set of paremeters and ranges that; are meant to be tuned. voi",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:21816,Modifiability,variab,variable,21816,"g phase). void InitBase(); default initialization called by all constructors. void DeclareBaseOptions(); define the options (their key words) that can be set in the option string; here the options valid for ALL MVA methods are declared.; know options: VariableTransform=None,Decorrelated,PCA to use transformed variables; instead of the original ones; VariableTransformType=Signal,Background which decorrelation matrix to use; in the method. Only the Likelihood; Method can make proper use of independent; transformations of signal and background; fNbinsMVAPdf = 50 Number of bins used to create a PDF of MVA; fNsmoothMVAPdf = 2 Number of times a histogram is smoothed before creating the PDF; fHasMVAPdfs create PDFs for the MVA outputs; V for Verbose output (!V) for non verbos; H for Help message. void ProcessBaseOptions(); the option string is decoded, for availabel options see ""DeclareOptions"". void CreateVariableTransforms(const TString& trafoDefinition, TMVA::DataSetInfo& dataInfo, TMVA::TransformationHandler& transformationHandler, TMVA::MsgLogger& log); create variable transformations. void DeclareCompatibilityOptions(). std::map<TString,Double_t> OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); call the Optimzier with the set of paremeters and ranges that; are meant to be tuned. void SetTuneParameters(map<TString,Double_t> tuneParameters); set the tuning parameters accoding to the argument; This is just a dummy .. have a look at the MethodBDT how you could; perhaps implment the same thing for the other Classifiers.. void TrainMethod(). void GetRegressionDeviation(UInt_t tgtNum, TMVA::Types::ETreeType type, Double_t& stddev, Double_t& stddev90Percent) const. void AddRegressionOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void AddMulticlassOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void NoErrorCalc(Double_t *const err, Doubl",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:22571,Modifiability,variab,variable,22571," H for Help message. void ProcessBaseOptions(); the option string is decoded, for availabel options see ""DeclareOptions"". void CreateVariableTransforms(const TString& trafoDefinition, TMVA::DataSetInfo& dataInfo, TMVA::TransformationHandler& transformationHandler, TMVA::MsgLogger& log); create variable transformations. void DeclareCompatibilityOptions(). std::map<TString,Double_t> OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); call the Optimzier with the set of paremeters and ranges that; are meant to be tuned. void SetTuneParameters(map<TString,Double_t> tuneParameters); set the tuning parameters accoding to the argument; This is just a dummy .. have a look at the MethodBDT how you could; perhaps implment the same thing for the other Classifiers.. void TrainMethod(). void GetRegressionDeviation(UInt_t tgtNum, TMVA::Types::ETreeType type, Double_t& stddev, Double_t& stddev90Percent) const. void AddRegressionOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void AddMulticlassOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void NoErrorCalc(Double_t *const err, Double_t *const errUpper). Double_t GetMvaValue(const TMVA::Event *const ev, Double_t* err = 0, Double_t* errUpper = 0). Bool_t IsSignalLike(). Bool_t IsSignalLike(Double_t mvaVal). void AddClassifierOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void AddClassifierOutputProb(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); calculate <sum-of-deviation-squared> of regression output versus ""true"" value from test sample. bias = average deviation; dev = average absolute deviation; rms = rms of",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:22689,Modifiability,variab,variable,22689,"s"". void CreateVariableTransforms(const TString& trafoDefinition, TMVA::DataSetInfo& dataInfo, TMVA::TransformationHandler& transformationHandler, TMVA::MsgLogger& log); create variable transformations. void DeclareCompatibilityOptions(). std::map<TString,Double_t> OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); call the Optimzier with the set of paremeters and ranges that; are meant to be tuned. void SetTuneParameters(map<TString,Double_t> tuneParameters); set the tuning parameters accoding to the argument; This is just a dummy .. have a look at the MethodBDT how you could; perhaps implment the same thing for the other Classifiers.. void TrainMethod(). void GetRegressionDeviation(UInt_t tgtNum, TMVA::Types::ETreeType type, Double_t& stddev, Double_t& stddev90Percent) const. void AddRegressionOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void AddMulticlassOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void NoErrorCalc(Double_t *const err, Double_t *const errUpper). Double_t GetMvaValue(const TMVA::Event *const ev, Double_t* err = 0, Double_t* errUpper = 0). Bool_t IsSignalLike(). Bool_t IsSignalLike(Double_t mvaVal). void AddClassifierOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void AddClassifierOutputProb(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); calculate <sum-of-deviation-squared> of regression output versus ""true"" value from test sample. bias = average deviation; dev = average absolute deviation; rms = rms of deviation. void TestMulticlass(); test multiclass classification. void TestClassification(); initialization. void Wri",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:23027,Modifiability,variab,variable,23027,"e = ""FitGA""); call the Optimzier with the set of paremeters and ranges that; are meant to be tuned. void SetTuneParameters(map<TString,Double_t> tuneParameters); set the tuning parameters accoding to the argument; This is just a dummy .. have a look at the MethodBDT how you could; perhaps implment the same thing for the other Classifiers.. void TrainMethod(). void GetRegressionDeviation(UInt_t tgtNum, TMVA::Types::ETreeType type, Double_t& stddev, Double_t& stddev90Percent) const. void AddRegressionOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void AddMulticlassOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void NoErrorCalc(Double_t *const err, Double_t *const errUpper). Double_t GetMvaValue(const TMVA::Event *const ev, Double_t* err = 0, Double_t* errUpper = 0). Bool_t IsSignalLike(). Bool_t IsSignalLike(Double_t mvaVal). void AddClassifierOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void AddClassifierOutputProb(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); calculate <sum-of-deviation-squared> of regression output versus ""true"" value from test sample. bias = average deviation; dev = average absolute deviation; rms = rms of deviation. void TestMulticlass(); test multiclass classification. void TestClassification(); initialization. void WriteStateToStream(ostream& tf) const; general method used in writing the header of the weight files where; the used variables, variable transformation type etc. is specified. void AddInfoItem(void* gi, const TString& name, const TString& value) const; xml writing. void AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType anal",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:23149,Modifiability,variab,variable,23149,"rs(map<TString,Double_t> tuneParameters); set the tuning parameters accoding to the argument; This is just a dummy .. have a look at the MethodBDT how you could; perhaps implment the same thing for the other Classifiers.. void TrainMethod(). void GetRegressionDeviation(UInt_t tgtNum, TMVA::Types::ETreeType type, Double_t& stddev, Double_t& stddev90Percent) const. void AddRegressionOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void AddMulticlassOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void NoErrorCalc(Double_t *const err, Double_t *const errUpper). Double_t GetMvaValue(const TMVA::Event *const ev, Double_t* err = 0, Double_t* errUpper = 0). Bool_t IsSignalLike(). Bool_t IsSignalLike(Double_t mvaVal). void AddClassifierOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void AddClassifierOutputProb(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); calculate <sum-of-deviation-squared> of regression output versus ""true"" value from test sample. bias = average deviation; dev = average absolute deviation; rms = rms of deviation. void TestMulticlass(); test multiclass classification. void TestClassification(); initialization. void WriteStateToStream(ostream& tf) const; general method used in writing the header of the weight files where; the used variables, variable transformation type etc. is specified. void AddInfoItem(void* gi, const TString& name, const TString& value) const; xml writing. void AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType). void WriteStateToXML(void* parent) const; general method used in writing the header of the weight files where",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:23753,Modifiability,variab,variables,23753,"lc(Double_t *const err, Double_t *const errUpper). Double_t GetMvaValue(const TMVA::Event *const ev, Double_t* err = 0, Double_t* errUpper = 0). Bool_t IsSignalLike(). Bool_t IsSignalLike(Double_t mvaVal). void AddClassifierOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void AddClassifierOutputProb(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); calculate <sum-of-deviation-squared> of regression output versus ""true"" value from test sample. bias = average deviation; dev = average absolute deviation; rms = rms of deviation. void TestMulticlass(); test multiclass classification. void TestClassification(); initialization. void WriteStateToStream(ostream& tf) const; general method used in writing the header of the weight files where; the used variables, variable transformation type etc. is specified. void AddInfoItem(void* gi, const TString& name, const TString& value) const; xml writing. void AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType). void WriteStateToXML(void* parent) const; general method used in writing the header of the weight files where; the used variables, variable transformation type etc. is specified. void ReadStateFromStream(TFile& rf); write reference MVA distributions (and other information); to a ROOT type weight file. void WriteStateToFile() const; write options and weights to file; note that each one text file for the main configuration information; and one ROOT file for ROOT objects are created. void ReadStateFromFile(); Function to write options and weights to file. void ReadStateFromXMLString(const char* xmlstr); for reading from memory. void ReadStateFromXML(void* parent). void ReadStateFromStream(istream& tf); read the header f",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:23764,Modifiability,variab,variable,23764,"lc(Double_t *const err, Double_t *const errUpper). Double_t GetMvaValue(const TMVA::Event *const ev, Double_t* err = 0, Double_t* errUpper = 0). Bool_t IsSignalLike(). Bool_t IsSignalLike(Double_t mvaVal). void AddClassifierOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void AddClassifierOutputProb(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); calculate <sum-of-deviation-squared> of regression output versus ""true"" value from test sample. bias = average deviation; dev = average absolute deviation; rms = rms of deviation. void TestMulticlass(); test multiclass classification. void TestClassification(); initialization. void WriteStateToStream(ostream& tf) const; general method used in writing the header of the weight files where; the used variables, variable transformation type etc. is specified. void AddInfoItem(void* gi, const TString& name, const TString& value) const; xml writing. void AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType). void WriteStateToXML(void* parent) const; general method used in writing the header of the weight files where; the used variables, variable transformation type etc. is specified. void ReadStateFromStream(TFile& rf); write reference MVA distributions (and other information); to a ROOT type weight file. void WriteStateToFile() const; write options and weights to file; note that each one text file for the main configuration information; and one ROOT file for ROOT objects are created. void ReadStateFromFile(); Function to write options and weights to file. void ReadStateFromXMLString(const char* xmlstr); for reading from memory. void ReadStateFromXML(void* parent). void ReadStateFromStream(istream& tf); read the header f",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:24108,Modifiability,variab,variables,24108,"A::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); calculate <sum-of-deviation-squared> of regression output versus ""true"" value from test sample. bias = average deviation; dev = average absolute deviation; rms = rms of deviation. void TestMulticlass(); test multiclass classification. void TestClassification(); initialization. void WriteStateToStream(ostream& tf) const; general method used in writing the header of the weight files where; the used variables, variable transformation type etc. is specified. void AddInfoItem(void* gi, const TString& name, const TString& value) const; xml writing. void AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType). void WriteStateToXML(void* parent) const; general method used in writing the header of the weight files where; the used variables, variable transformation type etc. is specified. void ReadStateFromStream(TFile& rf); write reference MVA distributions (and other information); to a ROOT type weight file. void WriteStateToFile() const; write options and weights to file; note that each one text file for the main configuration information; and one ROOT file for ROOT objects are created. void ReadStateFromFile(); Function to write options and weights to file. void ReadStateFromXMLString(const char* xmlstr); for reading from memory. void ReadStateFromXML(void* parent). void ReadStateFromStream(istream& tf); read the header from the weight files of the different MVA methods. void WriteVarsToStream(ostream& tf, const TString& prefix = """") const; write the list of variables (name, min, max) for a given data; transformation method to the stream. void ReadVarsFromStream(istream& istr); Read the variables (name, min, max) for a given data; transformation method from the stream. I",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:24119,Modifiability,variab,variable,24119,"A::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); calculate <sum-of-deviation-squared> of regression output versus ""true"" value from test sample. bias = average deviation; dev = average absolute deviation; rms = rms of deviation. void TestMulticlass(); test multiclass classification. void TestClassification(); initialization. void WriteStateToStream(ostream& tf) const; general method used in writing the header of the weight files where; the used variables, variable transformation type etc. is specified. void AddInfoItem(void* gi, const TString& name, const TString& value) const; xml writing. void AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType). void WriteStateToXML(void* parent) const; general method used in writing the header of the weight files where; the used variables, variable transformation type etc. is specified. void ReadStateFromStream(TFile& rf); write reference MVA distributions (and other information); to a ROOT type weight file. void WriteStateToFile() const; write options and weights to file; note that each one text file for the main configuration information; and one ROOT file for ROOT objects are created. void ReadStateFromFile(); Function to write options and weights to file. void ReadStateFromXMLString(const char* xmlstr); for reading from memory. void ReadStateFromXML(void* parent). void ReadStateFromStream(istream& tf); read the header from the weight files of the different MVA methods. void WriteVarsToStream(ostream& tf, const TString& prefix = """") const; write the list of variables (name, min, max) for a given data; transformation method to the stream. void ReadVarsFromStream(istream& istr); Read the variables (name, min, max) for a given data; transformation method from the stream. I",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:24399,Modifiability,config,configuration,24399,"squared> of regression output versus ""true"" value from test sample. bias = average deviation; dev = average absolute deviation; rms = rms of deviation. void TestMulticlass(); test multiclass classification. void TestClassification(); initialization. void WriteStateToStream(ostream& tf) const; general method used in writing the header of the weight files where; the used variables, variable transformation type etc. is specified. void AddInfoItem(void* gi, const TString& name, const TString& value) const; xml writing. void AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType). void WriteStateToXML(void* parent) const; general method used in writing the header of the weight files where; the used variables, variable transformation type etc. is specified. void ReadStateFromStream(TFile& rf); write reference MVA distributions (and other information); to a ROOT type weight file. void WriteStateToFile() const; write options and weights to file; note that each one text file for the main configuration information; and one ROOT file for ROOT objects are created. void ReadStateFromFile(); Function to write options and weights to file. void ReadStateFromXMLString(const char* xmlstr); for reading from memory. void ReadStateFromXML(void* parent). void ReadStateFromStream(istream& tf); read the header from the weight files of the different MVA methods. void WriteVarsToStream(ostream& tf, const TString& prefix = """") const; write the list of variables (name, min, max) for a given data; transformation method to the stream. void ReadVarsFromStream(istream& istr); Read the variables (name, min, max) for a given data; transformation method from the stream. In the stream we only; expect the limits which will be set. void AddVarsXMLTo(void* parent) const; write variable info to XML. void AddSpectatorsXMLTo(void* parent) const; write spectator info to XML. void AddClassesXMLTo(void* parent) const; write class info to XML. void AddTargetsXMLTo(void* parent) const; wri",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:24854,Modifiability,variab,variables,24854,"ing& name, const TString& value) const; xml writing. void AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType). void WriteStateToXML(void* parent) const; general method used in writing the header of the weight files where; the used variables, variable transformation type etc. is specified. void ReadStateFromStream(TFile& rf); write reference MVA distributions (and other information); to a ROOT type weight file. void WriteStateToFile() const; write options and weights to file; note that each one text file for the main configuration information; and one ROOT file for ROOT objects are created. void ReadStateFromFile(); Function to write options and weights to file. void ReadStateFromXMLString(const char* xmlstr); for reading from memory. void ReadStateFromXML(void* parent). void ReadStateFromStream(istream& tf); read the header from the weight files of the different MVA methods. void WriteVarsToStream(ostream& tf, const TString& prefix = """") const; write the list of variables (name, min, max) for a given data; transformation method to the stream. void ReadVarsFromStream(istream& istr); Read the variables (name, min, max) for a given data; transformation method from the stream. In the stream we only; expect the limits which will be set. void AddVarsXMLTo(void* parent) const; write variable info to XML. void AddSpectatorsXMLTo(void* parent) const; write spectator info to XML. void AddClassesXMLTo(void* parent) const; write class info to XML. void AddTargetsXMLTo(void* parent) const; write target info to XML. void ReadVariablesFromXML(void* varnode); read variable info from XML. void ReadSpectatorsFromXML(void* specnode); read spectator info from XML. void ReadClassesFromXML(void* clsnode); read number of classes from XML. void ReadTargetsFromXML(void* tarnode); read target info from XML. TDirectory* BaseDir() const; returns the ROOT directory where info/histograms etc of the; corresponding MVA method instance are stored. TDirectory* MethodBaseDi",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:24985,Modifiability,variab,variables,24985,"teToXML(void* parent) const; general method used in writing the header of the weight files where; the used variables, variable transformation type etc. is specified. void ReadStateFromStream(TFile& rf); write reference MVA distributions (and other information); to a ROOT type weight file. void WriteStateToFile() const; write options and weights to file; note that each one text file for the main configuration information; and one ROOT file for ROOT objects are created. void ReadStateFromFile(); Function to write options and weights to file. void ReadStateFromXMLString(const char* xmlstr); for reading from memory. void ReadStateFromXML(void* parent). void ReadStateFromStream(istream& tf); read the header from the weight files of the different MVA methods. void WriteVarsToStream(ostream& tf, const TString& prefix = """") const; write the list of variables (name, min, max) for a given data; transformation method to the stream. void ReadVarsFromStream(istream& istr); Read the variables (name, min, max) for a given data; transformation method from the stream. In the stream we only; expect the limits which will be set. void AddVarsXMLTo(void* parent) const; write variable info to XML. void AddSpectatorsXMLTo(void* parent) const; write spectator info to XML. void AddClassesXMLTo(void* parent) const; write class info to XML. void AddTargetsXMLTo(void* parent) const; write target info to XML. void ReadVariablesFromXML(void* varnode); read variable info from XML. void ReadSpectatorsFromXML(void* specnode); read spectator info from XML. void ReadClassesFromXML(void* clsnode); read number of classes from XML. void ReadTargetsFromXML(void* tarnode); read target info from XML. TDirectory* BaseDir() const; returns the ROOT directory where info/histograms etc of the; corresponding MVA method instance are stored. TDirectory* MethodBaseDir() const; returns the ROOT directory where all instances of the; corresponding MVA method are stored. void SetWeightFileDir(TString fileDir); set direc",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:25174,Modifiability,variab,variable,25174,"fied. void ReadStateFromStream(TFile& rf); write reference MVA distributions (and other information); to a ROOT type weight file. void WriteStateToFile() const; write options and weights to file; note that each one text file for the main configuration information; and one ROOT file for ROOT objects are created. void ReadStateFromFile(); Function to write options and weights to file. void ReadStateFromXMLString(const char* xmlstr); for reading from memory. void ReadStateFromXML(void* parent). void ReadStateFromStream(istream& tf); read the header from the weight files of the different MVA methods. void WriteVarsToStream(ostream& tf, const TString& prefix = """") const; write the list of variables (name, min, max) for a given data; transformation method to the stream. void ReadVarsFromStream(istream& istr); Read the variables (name, min, max) for a given data; transformation method from the stream. In the stream we only; expect the limits which will be set. void AddVarsXMLTo(void* parent) const; write variable info to XML. void AddSpectatorsXMLTo(void* parent) const; write spectator info to XML. void AddClassesXMLTo(void* parent) const; write class info to XML. void AddTargetsXMLTo(void* parent) const; write target info to XML. void ReadVariablesFromXML(void* varnode); read variable info from XML. void ReadSpectatorsFromXML(void* specnode); read spectator info from XML. void ReadClassesFromXML(void* clsnode); read number of classes from XML. void ReadTargetsFromXML(void* tarnode); read target info from XML. TDirectory* BaseDir() const; returns the ROOT directory where info/histograms etc of the; corresponding MVA method instance are stored. TDirectory* MethodBaseDir() const; returns the ROOT directory where all instances of the; corresponding MVA method are stored. void SetWeightFileDir(TString fileDir); set directory of weight file. void SetWeightFileName(TString ); set the weight file name (depreciated). TString GetWeightFileName() const; retrieve weight file name. voi",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:25452,Modifiability,variab,variable,25452,"file for ROOT objects are created. void ReadStateFromFile(); Function to write options and weights to file. void ReadStateFromXMLString(const char* xmlstr); for reading from memory. void ReadStateFromXML(void* parent). void ReadStateFromStream(istream& tf); read the header from the weight files of the different MVA methods. void WriteVarsToStream(ostream& tf, const TString& prefix = """") const; write the list of variables (name, min, max) for a given data; transformation method to the stream. void ReadVarsFromStream(istream& istr); Read the variables (name, min, max) for a given data; transformation method from the stream. In the stream we only; expect the limits which will be set. void AddVarsXMLTo(void* parent) const; write variable info to XML. void AddSpectatorsXMLTo(void* parent) const; write spectator info to XML. void AddClassesXMLTo(void* parent) const; write class info to XML. void AddTargetsXMLTo(void* parent) const; write target info to XML. void ReadVariablesFromXML(void* varnode); read variable info from XML. void ReadSpectatorsFromXML(void* specnode); read spectator info from XML. void ReadClassesFromXML(void* clsnode); read number of classes from XML. void ReadTargetsFromXML(void* tarnode); read target info from XML. TDirectory* BaseDir() const; returns the ROOT directory where info/histograms etc of the; corresponding MVA method instance are stored. TDirectory* MethodBaseDir() const; returns the ROOT directory where all instances of the; corresponding MVA method are stored. void SetWeightFileDir(TString fileDir); set directory of weight file. void SetWeightFileName(TString ); set the weight file name (depreciated). TString GetWeightFileName() const; retrieve weight file name. void WriteEvaluationHistosToFile(TMVA::Types::ETreeType treetype); writes all MVA evaluation histograms to file. void WriteMonitoringHistosToFile( void ); write special monitoring histograms to file; dummy implementation here -----------------. Bool_t GetLine(istream& fin, char* b",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:26611,Modifiability,variab,variables,26611," read number of classes from XML. void ReadTargetsFromXML(void* tarnode); read target info from XML. TDirectory* BaseDir() const; returns the ROOT directory where info/histograms etc of the; corresponding MVA method instance are stored. TDirectory* MethodBaseDir() const; returns the ROOT directory where all instances of the; corresponding MVA method are stored. void SetWeightFileDir(TString fileDir); set directory of weight file. void SetWeightFileName(TString ); set the weight file name (depreciated). TString GetWeightFileName() const; retrieve weight file name. void WriteEvaluationHistosToFile(TMVA::Types::ETreeType treetype); writes all MVA evaluation histograms to file. void WriteMonitoringHistosToFile( void ); write special monitoring histograms to file; dummy implementation here -----------------. Bool_t GetLine(istream& fin, char* buf); reads one line from the input stream; checks for certain keywords and interprets; the line if keywords are found. void CreateMVAPdfs(); Create PDFs of the MVA output variables. Double_t GetProba(Double_t mvaVal, Double_t ap_sig); compute likelihood ratio. Double_t GetRarity(Double_t mvaVal, TMVA::Types::ESBType reftype = Types::kBackground) const; compute rarity:; R(x) = Integrate_[-oo..x] { PDF(x') dx' }; where PDF(x) is the PDF of the classifier's signal or background distribution. Double_t GetEfficiency(const TString& , TMVA::Types::ETreeType , Double_t& err); fill background efficiency (resp. rejection) versus signal efficiency plots; returns signal efficiency at background efficiency indicated in theString. Double_t GetTrainingEfficiency(const TString& ). std::vector<Float_t> GetMulticlassEfficiency(vector<std::vector<Float_t> >& purity). std::vector<Float_t> GetMulticlassTrainingEfficiency(vector<std::vector<Float_t> >& purity). Double_t GetSignificance( void ); compute significance of mean difference; significance = |<S> - <B>|/Sqrt(RMS_S2 + RMS_B2). Double_t GetSeparation(TH1* , TH1* ) const; compute ""separation"" define",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:28676,Modifiability,variab,variable,28676,"(x)) dx }. Double_t GetSeparation(TMVA::PDF* pdfS = 0, TMVA::PDF* pdfB = 0) const; compute ""separation"" defined as; <s2> = (1/2) Int_-oo..+oo { (S(x)2 - B(x)2)/(S(x) + B(x)) dx }. Double_t GetROCIntegral(TH1F* histS, TH1F* histB) const; calculate the area (integral) under the ROC curve as a; overall quality measure of the classification. Double_t GetROCIntegral(TMVA::PDF* pdfS = 0, TMVA::PDF* pdfB = 0) const; calculate the area (integral) under the ROC curve as a; overall quality measure of the classification. Double_t GetMaximumSignificance(Double_t SignalEvents, Double_t BackgroundEvents, Double_t& optimal_significance_value) const; plot significance, S/Sqrt(S^2 + B^2), curve for given number; of signal and background events; returns cut for maximum significance; also returned via reference is the maximum significance. void Statistics(TMVA::Types::ETreeType treeType, const TString& theVarName, Double_t& , Double_t& , Double_t& , Double_t& , Double_t& , Double_t& ); calculates rms,mean, xmin, xmax of the event variable; this can be either done for the variables as they are or for; normalised variables (in the range of 0-1) if ""norm"" is set to kTRUE. void MakeClass(const TString& classFileName = TString("""")) const; create reader class for method (classification only at present). void PrintHelpMessage() const; prints out method-specific help method. Double_t IGetEffForRoot(Double_t ); interface for RootFinder. Double_t GetEffForRoot(Double_t ); returns efficiency as function of cut. const std::vector<TMVA::Event*>& GetEventCollection(TMVA::Types::ETreeType type). TString GetTrainingTMVAVersionString() const; calculates the TMVA version string from the training version code on the fly. TString GetTrainingROOTVersionString() const; calculates the ROOT version string from the training version code on the fly. TMVA::MethodBase* GetThisBase(); return a pointer the base class of this method. void ResetThisBase(); reset required for RootFinder. const TMVA::Event* GetEvent(c",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:28718,Modifiability,variab,variables,28718,"(x)) dx }. Double_t GetSeparation(TMVA::PDF* pdfS = 0, TMVA::PDF* pdfB = 0) const; compute ""separation"" defined as; <s2> = (1/2) Int_-oo..+oo { (S(x)2 - B(x)2)/(S(x) + B(x)) dx }. Double_t GetROCIntegral(TH1F* histS, TH1F* histB) const; calculate the area (integral) under the ROC curve as a; overall quality measure of the classification. Double_t GetROCIntegral(TMVA::PDF* pdfS = 0, TMVA::PDF* pdfB = 0) const; calculate the area (integral) under the ROC curve as a; overall quality measure of the classification. Double_t GetMaximumSignificance(Double_t SignalEvents, Double_t BackgroundEvents, Double_t& optimal_significance_value) const; plot significance, S/Sqrt(S^2 + B^2), curve for given number; of signal and background events; returns cut for maximum significance; also returned via reference is the maximum significance. void Statistics(TMVA::Types::ETreeType treeType, const TString& theVarName, Double_t& , Double_t& , Double_t& , Double_t& , Double_t& , Double_t& ); calculates rms,mean, xmin, xmax of the event variable; this can be either done for the variables as they are or for; normalised variables (in the range of 0-1) if ""norm"" is set to kTRUE. void MakeClass(const TString& classFileName = TString("""")) const; create reader class for method (classification only at present). void PrintHelpMessage() const; prints out method-specific help method. Double_t IGetEffForRoot(Double_t ); interface for RootFinder. Double_t GetEffForRoot(Double_t ); returns efficiency as function of cut. const std::vector<TMVA::Event*>& GetEventCollection(TMVA::Types::ETreeType type). TString GetTrainingTMVAVersionString() const; calculates the TMVA version string from the training version code on the fly. TString GetTrainingROOTVersionString() const; calculates the ROOT version string from the training version code on the fly. TMVA::MethodBase* GetThisBase(); return a pointer the base class of this method. void ResetThisBase(); reset required for RootFinder. const TMVA::Event* GetEvent(c",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:28759,Modifiability,variab,variables,28759,"(x)) dx }. Double_t GetSeparation(TMVA::PDF* pdfS = 0, TMVA::PDF* pdfB = 0) const; compute ""separation"" defined as; <s2> = (1/2) Int_-oo..+oo { (S(x)2 - B(x)2)/(S(x) + B(x)) dx }. Double_t GetROCIntegral(TH1F* histS, TH1F* histB) const; calculate the area (integral) under the ROC curve as a; overall quality measure of the classification. Double_t GetROCIntegral(TMVA::PDF* pdfS = 0, TMVA::PDF* pdfB = 0) const; calculate the area (integral) under the ROC curve as a; overall quality measure of the classification. Double_t GetMaximumSignificance(Double_t SignalEvents, Double_t BackgroundEvents, Double_t& optimal_significance_value) const; plot significance, S/Sqrt(S^2 + B^2), curve for given number; of signal and background events; returns cut for maximum significance; also returned via reference is the maximum significance. void Statistics(TMVA::Types::ETreeType treeType, const TString& theVarName, Double_t& , Double_t& , Double_t& , Double_t& , Double_t& , Double_t& ); calculates rms,mean, xmin, xmax of the event variable; this can be either done for the variables as they are or for; normalised variables (in the range of 0-1) if ""norm"" is set to kTRUE. void MakeClass(const TString& classFileName = TString("""")) const; create reader class for method (classification only at present). void PrintHelpMessage() const; prints out method-specific help method. Double_t IGetEffForRoot(Double_t ); interface for RootFinder. Double_t GetEffForRoot(Double_t ); returns efficiency as function of cut. const std::vector<TMVA::Event*>& GetEventCollection(TMVA::Types::ETreeType type). TString GetTrainingTMVAVersionString() const; calculates the TMVA version string from the training version code on the fly. TString GetTrainingROOTVersionString() const; calculates the ROOT version string from the training version code on the fly. TMVA::MethodBase* GetThisBase(); return a pointer the base class of this method. void ResetThisBase(); reset required for RootFinder. const TMVA::Event* GetEvent(c",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:32141,Modifiability,variab,variable,32141,". {return kFALSE;}. void AddWeightsXMLTo(void* parent) const; the actual ""weights"". void ReadWeightsFromXML(void* wghtnode). void ReadWeightsFromStream(istream& ). void ReadWeightsFromStream(TFile& ); {}. const TString& GetJobName() const; ---------- public accessors -----------------------------------------------; classifier naming (a lot of names ... aren't they ;-). { return fJobName; }. const TString& GetMethodName() const; { return fMethodName; }. TString GetMethodTypeName() const; { return Types::Instance().GetMethodName(fMethodType); }. Types::EMVA GetMethodType() const; { return fMethodType; }. const char* GetName() const; { return fMethodName.Data(); }. const TString& GetTestvarName() const; { return fTestvar; }. const TString GetProbaName() const; { return fTestvar + ""_Proba""; }. void SetTestvarName(const TString& v = """"); build classifier name in Test tree; MVA prefix (e.g., ""TMVA_""). { fTestvar = (v=="""") ? (""MVA_"" + GetMethodName()) : v; }. UInt_t GetNvar() const; number of input variable used by classifier. { return DataInfo().GetNVariables(); }. UInt_t GetNVariables() const; { return DataInfo().GetNVariables(); }. UInt_t GetNTargets() const; { return DataInfo().GetNTargets(); }. const TString& GetInputVar(Int_t i) const; internal names and expressions of input variables. { return DataInfo().GetVariableInfo(i).GetInternalName(); }. const TString& GetInputLabel(Int_t i) const; { return DataInfo().GetVariableInfo(i).GetLabel(); }. const TString& GetInputTitle(Int_t i) const; { return DataInfo().GetVariableInfo(i).GetTitle(); }. Double_t GetMean(Int_t ivar) const; normalisation and limit accessors. { return GetTransformationHandler().GetMean(ivar); }. Double_t GetRMS(Int_t ivar) const; { return GetTransformationHandler().GetRMS(ivar); }. Double_t GetXmin(Int_t ivar) const; { return GetTransformationHandler().GetMin(ivar); }. Double_t GetXmax(Int_t ivar) const; { return GetTransformationHandler().GetMax(ivar); }. Double_t GetSignalReferenceCut() const; sets ",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:32429,Modifiability,variab,variables,32429,"accessors -----------------------------------------------; classifier naming (a lot of names ... aren't they ;-). { return fJobName; }. const TString& GetMethodName() const; { return fMethodName; }. TString GetMethodTypeName() const; { return Types::Instance().GetMethodName(fMethodType); }. Types::EMVA GetMethodType() const; { return fMethodType; }. const char* GetName() const; { return fMethodName.Data(); }. const TString& GetTestvarName() const; { return fTestvar; }. const TString GetProbaName() const; { return fTestvar + ""_Proba""; }. void SetTestvarName(const TString& v = """"); build classifier name in Test tree; MVA prefix (e.g., ""TMVA_""). { fTestvar = (v=="""") ? (""MVA_"" + GetMethodName()) : v; }. UInt_t GetNvar() const; number of input variable used by classifier. { return DataInfo().GetNVariables(); }. UInt_t GetNVariables() const; { return DataInfo().GetNVariables(); }. UInt_t GetNTargets() const; { return DataInfo().GetNTargets(); }. const TString& GetInputVar(Int_t i) const; internal names and expressions of input variables. { return DataInfo().GetVariableInfo(i).GetInternalName(); }. const TString& GetInputLabel(Int_t i) const; { return DataInfo().GetVariableInfo(i).GetLabel(); }. const TString& GetInputTitle(Int_t i) const; { return DataInfo().GetVariableInfo(i).GetTitle(); }. Double_t GetMean(Int_t ivar) const; normalisation and limit accessors. { return GetTransformationHandler().GetMean(ivar); }. Double_t GetRMS(Int_t ivar) const; { return GetTransformationHandler().GetRMS(ivar); }. Double_t GetXmin(Int_t ivar) const; { return GetTransformationHandler().GetMin(ivar); }. Double_t GetXmax(Int_t ivar) const; { return GetTransformationHandler().GetMax(ivar); }. Double_t GetSignalReferenceCut() const; sets the minimum requirement on the MVA output to declare an event signal-like. { return fSignalReferenceCut; }. Double_t GetSignalReferenceCutOrientation() const; { return fSignalReferenceCutOrientation; }. void SetSignalReferenceCut(Double_t cut); sets the min",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:35367,Modifiability,variab,variables,35367,"nst. void RerouteTransformationHandler(TMVA::TransformationHandler* fTargetTransformation); { fTransformationPointer=fTargetTransformation; }. DataSetInfo& DataInfo() const; ---------- event accessors ------------------------------------------------; returns reference to data set. { return fDataSetInfo; }. UInt_t GetNEvents() const; event reference and update. { return Data()->GetNEvents(); }. Bool_t HasMVAPdfs() const; { return fHasMVAPdfs; }. void SetAnalysisType(TMVA::Types::EAnalysisType type); { fAnalysisType = type; }. Types::EAnalysisType GetAnalysisType() const; { return fAnalysisType; }. Bool_t DoRegression() const; { return fAnalysisType == Types::kRegression; }. Bool_t DoMulticlass() const; { return fAnalysisType == Types::kMulticlass; }. void DisableWriting(Bool_t setter); setter method for suppressing writing to XML and writing of standalone classes. { fDisableWriting = setter; }. const TString& GetWeightFileDir() const; { return fFileDir; }. Bool_t IsNormalised() const; are input variables normalised ?. { return fNormalise; }. void SetNormalised(Bool_t norm); { fNormalise = norm; }. Bool_t Verbose() const; set number of input variables (only used by MethodCuts, could perhaps be removed); void SetNvar( Int_t n ) { fNvar = n; }; verbose and help flags. { return fVerbose; }. Bool_t Help() const; { return fHelp; }. const TString& GetInternalVarName(Int_t ivar) const; ---------- protected event and tree accessors -----------------------------; names of input variables (if the original names are expressions, they are; transformed into regexps). { return (*fInputVars)[ivar]; }. const TString& GetOriginalVarName(Int_t ivar) const; { return DataInfo().GetVariableInfo(ivar).GetExpression(); }. Bool_t HasTrainingTree() const; { return Data()->GetNTrainingEvents() != 0; }. void MakeClassSpecific(ostream& , const TString& = """") const; ---------- protected auxiliary methods ------------------------------------; make ROOT-independent C++ class for classifier response ",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:35516,Modifiability,variab,variables,35516,"rs ------------------------------------------------; returns reference to data set. { return fDataSetInfo; }. UInt_t GetNEvents() const; event reference and update. { return Data()->GetNEvents(); }. Bool_t HasMVAPdfs() const; { return fHasMVAPdfs; }. void SetAnalysisType(TMVA::Types::EAnalysisType type); { fAnalysisType = type; }. Types::EAnalysisType GetAnalysisType() const; { return fAnalysisType; }. Bool_t DoRegression() const; { return fAnalysisType == Types::kRegression; }. Bool_t DoMulticlass() const; { return fAnalysisType == Types::kMulticlass; }. void DisableWriting(Bool_t setter); setter method for suppressing writing to XML and writing of standalone classes. { fDisableWriting = setter; }. const TString& GetWeightFileDir() const; { return fFileDir; }. Bool_t IsNormalised() const; are input variables normalised ?. { return fNormalise; }. void SetNormalised(Bool_t norm); { fNormalise = norm; }. Bool_t Verbose() const; set number of input variables (only used by MethodCuts, could perhaps be removed); void SetNvar( Int_t n ) { fNvar = n; }; verbose and help flags. { return fVerbose; }. Bool_t Help() const; { return fHelp; }. const TString& GetInternalVarName(Int_t ivar) const; ---------- protected event and tree accessors -----------------------------; names of input variables (if the original names are expressions, they are; transformed into regexps). { return (*fInputVars)[ivar]; }. const TString& GetOriginalVarName(Int_t ivar) const; { return DataInfo().GetVariableInfo(ivar).GetExpression(); }. Bool_t HasTrainingTree() const; { return Data()->GetNTrainingEvents() != 0; }. void MakeClassSpecific(ostream& , const TString& = """") const; ---------- protected auxiliary methods ------------------------------------; make ROOT-independent C++ class for classifier response (classifier-specific implementation). {}. void MakeClassSpecificHeader(ostream& , const TString& = """") const; header and auxiliary classes. {}. Bool_t TxtWeightsOnly() const; if TRUE, write weights ",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:35850,Modifiability,variab,variables,35850,"sisType(TMVA::Types::EAnalysisType type); { fAnalysisType = type; }. Types::EAnalysisType GetAnalysisType() const; { return fAnalysisType; }. Bool_t DoRegression() const; { return fAnalysisType == Types::kRegression; }. Bool_t DoMulticlass() const; { return fAnalysisType == Types::kMulticlass; }. void DisableWriting(Bool_t setter); setter method for suppressing writing to XML and writing of standalone classes. { fDisableWriting = setter; }. const TString& GetWeightFileDir() const; { return fFileDir; }. Bool_t IsNormalised() const; are input variables normalised ?. { return fNormalise; }. void SetNormalised(Bool_t norm); { fNormalise = norm; }. Bool_t Verbose() const; set number of input variables (only used by MethodCuts, could perhaps be removed); void SetNvar( Int_t n ) { fNvar = n; }; verbose and help flags. { return fVerbose; }. Bool_t Help() const; { return fHelp; }. const TString& GetInternalVarName(Int_t ivar) const; ---------- protected event and tree accessors -----------------------------; names of input variables (if the original names are expressions, they are; transformed into regexps). { return (*fInputVars)[ivar]; }. const TString& GetOriginalVarName(Int_t ivar) const; { return DataInfo().GetVariableInfo(ivar).GetExpression(); }. Bool_t HasTrainingTree() const; { return Data()->GetNTrainingEvents() != 0; }. void MakeClassSpecific(ostream& , const TString& = """") const; ---------- protected auxiliary methods ------------------------------------; make ROOT-independent C++ class for classifier response (classifier-specific implementation). {}. void MakeClassSpecificHeader(ostream& , const TString& = """") const; header and auxiliary classes. {}. Bool_t TxtWeightsOnly() const; if TRUE, write weights only to text files. { return kTRUE; }. Float_t GetTWeight(const TMVA::Event* ev) const; access to event information that needs method-specific information. Bool_t IsConstructedFromWeightFile() const; { return fConstructedFromWeightFile; }. void SetCurrentEvent(Lo",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:466,Performance,perform,performance,466,". TMVA::MethodBase. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodBase. class TMVA::MethodBase: public TMVA::IMethod, public TMVA::Configurable. Virtual base Class for all MVA method; MethodBase hosts several specific evaluation methods.; The kind of MVA that provides optimal performance in an analysis strongly; depends on the particular application. The evaluation factory provides a; number of numerical benchmark results to directly assess the performance; of the MVA training on the independent test sample. These are:; ; The signal efficiency at three representative background efficiencies; (which is 1 − rejection).; The significance of an MVA estimator, defined by the difference; between the MVA mean values for signal and background, divided by the; quadratic sum of their root mean squares.; The separation of an MVA x, defined by the integral; ½∫(S(x) − B(x))2/(S(x) + B(x))dx, where; S(x) and B(x) are the signal and background distributions, respectively.; The separation is zero for identical signal and background MVA shapes,; and it is one for disjunctive shapes.; ; The average, ∫x μ(S(x))dx, of the signal μ-transform.; The μ-transform of an MVA denotes the transformation that yields; a uniform background distribution. In this way, the signal distributions; S(x) can be directly compared among the various MVAs. The stronger S(x); peaks towards one, the better is the discrimination of the MVA. The; μ-transform is; documented here.; ; The MVA standard output also prints the linear correlation coefficients between; signal and background, which can be useful to eliminate variables that exhibit too; strong correlations.; ; . Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; pub",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:638,Performance,perform,performance,638,". TMVA::MethodBase. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodBase. class TMVA::MethodBase: public TMVA::IMethod, public TMVA::Configurable. Virtual base Class for all MVA method; MethodBase hosts several specific evaluation methods.; The kind of MVA that provides optimal performance in an analysis strongly; depends on the particular application. The evaluation factory provides a; number of numerical benchmark results to directly assess the performance; of the MVA training on the independent test sample. These are:; ; The signal efficiency at three representative background efficiencies; (which is 1 − rejection).; The significance of an MVA estimator, defined by the difference; between the MVA mean values for signal and background, divided by the; quadratic sum of their root mean squares.; The separation of an MVA x, defined by the integral; ½∫(S(x) − B(x))2/(S(x) + B(x))dx, where; S(x) and B(x) are the signal and background distributions, respectively.; The separation is zero for identical signal and background MVA shapes,; and it is one for disjunctive shapes.; ; The average, ∫x μ(S(x))dx, of the signal μ-transform.; The μ-transform of an MVA denotes the transformation that yields; a uniform background distribution. In this way, the signal distributions; S(x) can be directly compared among the various MVAs. The stronger S(x); peaks towards one, the better is the discrimination of the MVA. The; μ-transform is; documented here.; ; The MVA standard output also prints the linear correlation coefficients between; signal and background, which can be useful to eliminate variables that exhibit too; strong correlations.; ; . Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; pub",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:11193,Performance,tune,tuneParameters,11193," out, Option_t* option = """"); virtual voidSetAnalysisType(TMVA::Types::EAnalysisType type); voidSetBaseDir(TDirectory* methodDir); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidSetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidSetMethodBaseDir(TDirectory* methodDir); voidSetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidSetSignalReferenceCut(Double_t cut); voidSetSignalReferenceCutOrientation(Double_t cutOrientation); voidSetTestTime(Double_t testTime); voidSetTestvarName(const TString& v = """"); voidSetTrainTime(Double_t trainTime); virtual voidSetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidSetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTestClassification(); virtual voidTestMulticlass(); virtual voidTestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; virtual voidWriteEvaluationHistosToFile(TMVA::Typ",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:22070,Performance,tune,tuned,22070,".; know options: VariableTransform=None,Decorrelated,PCA to use transformed variables; instead of the original ones; VariableTransformType=Signal,Background which decorrelation matrix to use; in the method. Only the Likelihood; Method can make proper use of independent; transformations of signal and background; fNbinsMVAPdf = 50 Number of bins used to create a PDF of MVA; fNsmoothMVAPdf = 2 Number of times a histogram is smoothed before creating the PDF; fHasMVAPdfs create PDFs for the MVA outputs; V for Verbose output (!V) for non verbos; H for Help message. void ProcessBaseOptions(); the option string is decoded, for availabel options see ""DeclareOptions"". void CreateVariableTransforms(const TString& trafoDefinition, TMVA::DataSetInfo& dataInfo, TMVA::TransformationHandler& transformationHandler, TMVA::MsgLogger& log); create variable transformations. void DeclareCompatibilityOptions(). std::map<TString,Double_t> OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); call the Optimzier with the set of paremeters and ranges that; are meant to be tuned. void SetTuneParameters(map<TString,Double_t> tuneParameters); set the tuning parameters accoding to the argument; This is just a dummy .. have a look at the MethodBDT how you could; perhaps implment the same thing for the other Classifiers.. void TrainMethod(). void GetRegressionDeviation(UInt_t tgtNum, TMVA::Types::ETreeType type, Double_t& stddev, Double_t& stddev90Percent) const. void AddRegressionOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void AddMulticlassOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void NoErrorCalc(Double_t *const err, Double_t *const errUpper). Double_t GetMvaValue(const TMVA::Event *const ev, Double_t* err = 0, Double_t* errUpper = 0). Bool_t IsSignalLike(). Bool_t IsSignalLike(Double_t mvaVal). void AddClassifierOutput(TMVA::Types::ETreeType type); pre",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:22122,Performance,tune,tuneParameters,22122,"relation matrix to use; in the method. Only the Likelihood; Method can make proper use of independent; transformations of signal and background; fNbinsMVAPdf = 50 Number of bins used to create a PDF of MVA; fNsmoothMVAPdf = 2 Number of times a histogram is smoothed before creating the PDF; fHasMVAPdfs create PDFs for the MVA outputs; V for Verbose output (!V) for non verbos; H for Help message. void ProcessBaseOptions(); the option string is decoded, for availabel options see ""DeclareOptions"". void CreateVariableTransforms(const TString& trafoDefinition, TMVA::DataSetInfo& dataInfo, TMVA::TransformationHandler& transformationHandler, TMVA::MsgLogger& log); create variable transformations. void DeclareCompatibilityOptions(). std::map<TString,Double_t> OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); call the Optimzier with the set of paremeters and ranges that; are meant to be tuned. void SetTuneParameters(map<TString,Double_t> tuneParameters); set the tuning parameters accoding to the argument; This is just a dummy .. have a look at the MethodBDT how you could; perhaps implment the same thing for the other Classifiers.. void TrainMethod(). void GetRegressionDeviation(UInt_t tgtNum, TMVA::Types::ETreeType type, Double_t& stddev, Double_t& stddev90Percent) const. void AddRegressionOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void AddMulticlassOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void NoErrorCalc(Double_t *const err, Double_t *const errUpper). Double_t GetMvaValue(const TMVA::Event *const ev, Double_t* err = 0, Double_t* errUpper = 0). Bool_t IsSignalLike(). Bool_t IsSignalLike(Double_t mvaVal). void AddClassifierOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void AddClassifierOutputProb(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminat",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:31392,Security,access,accessors,31392,"s if it was not yet trained, just instantiated; virtual void Reset() = 0;; for the moment, I provide a dummy (that would not work) default, just to make; compilation/running w/o parameter optimisation still possible. {return;}. Double_t GetMvaValue(Double_t* errLower = 0, Double_t* errUpper = 0); classifier response:; some methods may return a per-event error estimate; error calculation is skipped if err==0. const std::vector<Float_t>& GetRegressionValues(); regression response. const std::vector<Float_t>& GetMulticlassValues(); multiclass classification response. const Ranking* CreateRanking(); create ranking. Bool_t MonitorBoost(TMVA::MethodBoost* ); perfrom extra actions during the boosting at different stages. {return kFALSE;}. void AddWeightsXMLTo(void* parent) const; the actual ""weights"". void ReadWeightsFromXML(void* wghtnode). void ReadWeightsFromStream(istream& ). void ReadWeightsFromStream(TFile& ); {}. const TString& GetJobName() const; ---------- public accessors -----------------------------------------------; classifier naming (a lot of names ... aren't they ;-). { return fJobName; }. const TString& GetMethodName() const; { return fMethodName; }. TString GetMethodTypeName() const; { return Types::Instance().GetMethodName(fMethodType); }. Types::EMVA GetMethodType() const; { return fMethodType; }. const char* GetName() const; { return fMethodName.Data(); }. const TString& GetTestvarName() const; { return fTestvar; }. const TString GetProbaName() const; { return fTestvar + ""_Proba""; }. void SetTestvarName(const TString& v = """"); build classifier name in Test tree; MVA prefix (e.g., ""TMVA_""). { fTestvar = (v=="""") ? (""MVA_"" + GetMethodName()) : v; }. UInt_t GetNvar() const; number of input variable used by classifier. { return DataInfo().GetNVariables(); }. UInt_t GetNVariables() const; { return DataInfo().GetNVariables(); }. UInt_t GetNTargets() const; { return DataInfo().GetNTargets(); }. const TString& GetInputVar(Int_t i) const; internal names and expr",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:32759,Security,access,accessors,32759,"odType; }. const char* GetName() const; { return fMethodName.Data(); }. const TString& GetTestvarName() const; { return fTestvar; }. const TString GetProbaName() const; { return fTestvar + ""_Proba""; }. void SetTestvarName(const TString& v = """"); build classifier name in Test tree; MVA prefix (e.g., ""TMVA_""). { fTestvar = (v=="""") ? (""MVA_"" + GetMethodName()) : v; }. UInt_t GetNvar() const; number of input variable used by classifier. { return DataInfo().GetNVariables(); }. UInt_t GetNVariables() const; { return DataInfo().GetNVariables(); }. UInt_t GetNTargets() const; { return DataInfo().GetNTargets(); }. const TString& GetInputVar(Int_t i) const; internal names and expressions of input variables. { return DataInfo().GetVariableInfo(i).GetInternalName(); }. const TString& GetInputLabel(Int_t i) const; { return DataInfo().GetVariableInfo(i).GetLabel(); }. const TString& GetInputTitle(Int_t i) const; { return DataInfo().GetVariableInfo(i).GetTitle(); }. Double_t GetMean(Int_t ivar) const; normalisation and limit accessors. { return GetTransformationHandler().GetMean(ivar); }. Double_t GetRMS(Int_t ivar) const; { return GetTransformationHandler().GetRMS(ivar); }. Double_t GetXmin(Int_t ivar) const; { return GetTransformationHandler().GetMin(ivar); }. Double_t GetXmax(Int_t ivar) const; { return GetTransformationHandler().GetMax(ivar); }. Double_t GetSignalReferenceCut() const; sets the minimum requirement on the MVA output to declare an event signal-like. { return fSignalReferenceCut; }. Double_t GetSignalReferenceCutOrientation() const; { return fSignalReferenceCutOrientation; }. void SetSignalReferenceCut(Double_t cut); sets the minimum requirement on the MVA output to declare an event signal-like. { fSignalReferenceCut = cut; }. void SetSignalReferenceCutOrientation(Double_t cutOrientation); { fSignalReferenceCutOrientation = cutOrientation; }. void SetMethodDir(TDirectory* methodDir); { fBaseDir = fMethodBaseDir = methodDir; }. void SetBaseDir(TDirectory* methodDir)",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:34549,Security,access,accessors,34549,"renceCutOrientation = cutOrientation; }. void SetMethodDir(TDirectory* methodDir); { fBaseDir = fMethodBaseDir = methodDir; }. void SetBaseDir(TDirectory* methodDir); { fBaseDir = methodDir; }. void SetMethodBaseDir(TDirectory* methodDir); { fMethodBaseDir = methodDir; }. UInt_t GetTrainingTMVAVersionCode() const; the TMVA version can be obtained and checked using; if (GetTrainingTMVAVersionCode()>TMVA_VERSION(3,7,2)) {...}; or; if (GetTrainingROOTVersionCode()>ROOT_VERSION(5,15,5)) {...}. { return fTMVATrainingVersion; }. UInt_t GetTrainingROOTVersionCode() const; { return fROOTTrainingVersion; }. TransformationHandler& GetTransformationHandler(Bool_t takeReroutedIfAvailable = true). const TransformationHandler& GetTransformationHandler(Bool_t takeReroutedIfAvailable = true) const. void RerouteTransformationHandler(TMVA::TransformationHandler* fTargetTransformation); { fTransformationPointer=fTargetTransformation; }. DataSetInfo& DataInfo() const; ---------- event accessors ------------------------------------------------; returns reference to data set. { return fDataSetInfo; }. UInt_t GetNEvents() const; event reference and update. { return Data()->GetNEvents(); }. Bool_t HasMVAPdfs() const; { return fHasMVAPdfs; }. void SetAnalysisType(TMVA::Types::EAnalysisType type); { fAnalysisType = type; }. Types::EAnalysisType GetAnalysisType() const; { return fAnalysisType; }. Bool_t DoRegression() const; { return fAnalysisType == Types::kRegression; }. Bool_t DoMulticlass() const; { return fAnalysisType == Types::kMulticlass; }. void DisableWriting(Bool_t setter); setter method for suppressing writing to XML and writing of standalone classes. { fDisableWriting = setter; }. const TString& GetWeightFileDir() const; { return fFileDir; }. Bool_t IsNormalised() const; are input variables normalised ?. { return fNormalise; }. void SetNormalised(Bool_t norm); { fNormalise = norm; }. Bool_t Verbose() const; set number of input variables (only used by MethodCuts, could perhaps be r",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:35794,Security,access,accessors,35794,"sisType(TMVA::Types::EAnalysisType type); { fAnalysisType = type; }. Types::EAnalysisType GetAnalysisType() const; { return fAnalysisType; }. Bool_t DoRegression() const; { return fAnalysisType == Types::kRegression; }. Bool_t DoMulticlass() const; { return fAnalysisType == Types::kMulticlass; }. void DisableWriting(Bool_t setter); setter method for suppressing writing to XML and writing of standalone classes. { fDisableWriting = setter; }. const TString& GetWeightFileDir() const; { return fFileDir; }. Bool_t IsNormalised() const; are input variables normalised ?. { return fNormalise; }. void SetNormalised(Bool_t norm); { fNormalise = norm; }. Bool_t Verbose() const; set number of input variables (only used by MethodCuts, could perhaps be removed); void SetNvar( Int_t n ) { fNvar = n; }; verbose and help flags. { return fVerbose; }. Bool_t Help() const; { return fHelp; }. const TString& GetInternalVarName(Int_t ivar) const; ---------- protected event and tree accessors -----------------------------; names of input variables (if the original names are expressions, they are; transformed into regexps). { return (*fInputVars)[ivar]; }. const TString& GetOriginalVarName(Int_t ivar) const; { return DataInfo().GetVariableInfo(ivar).GetExpression(); }. Bool_t HasTrainingTree() const; { return Data()->GetNTrainingEvents() != 0; }. void MakeClassSpecific(ostream& , const TString& = """") const; ---------- protected auxiliary methods ------------------------------------; make ROOT-independent C++ class for classifier response (classifier-specific implementation). {}. void MakeClassSpecificHeader(ostream& , const TString& = """") const; header and auxiliary classes. {}. Bool_t TxtWeightsOnly() const; if TRUE, write weights only to text files. { return kTRUE; }. Float_t GetTWeight(const TMVA::Event* ev) const; access to event information that needs method-specific information. Bool_t IsConstructedFromWeightFile() const; { return fConstructedFromWeightFile; }. void SetCurrentEvent(Lo",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:36645,Security,access,access,36645,"ed(Bool_t norm); { fNormalise = norm; }. Bool_t Verbose() const; set number of input variables (only used by MethodCuts, could perhaps be removed); void SetNvar( Int_t n ) { fNvar = n; }; verbose and help flags. { return fVerbose; }. Bool_t Help() const; { return fHelp; }. const TString& GetInternalVarName(Int_t ivar) const; ---------- protected event and tree accessors -----------------------------; names of input variables (if the original names are expressions, they are; transformed into regexps). { return (*fInputVars)[ivar]; }. const TString& GetOriginalVarName(Int_t ivar) const; { return DataInfo().GetVariableInfo(ivar).GetExpression(); }. Bool_t HasTrainingTree() const; { return Data()->GetNTrainingEvents() != 0; }. void MakeClassSpecific(ostream& , const TString& = """") const; ---------- protected auxiliary methods ------------------------------------; make ROOT-independent C++ class for classifier response (classifier-specific implementation). {}. void MakeClassSpecificHeader(ostream& , const TString& = """") const; header and auxiliary classes. {}. Bool_t TxtWeightsOnly() const; if TRUE, write weights only to text files. { return kTRUE; }. Float_t GetTWeight(const TMVA::Event* ev) const; access to event information that needs method-specific information. Bool_t IsConstructedFromWeightFile() const; { return fConstructedFromWeightFile; }. void SetCurrentEvent(Long64_t ievt) const. Data(). ECutOrientation GetCutOrientation() const; { return fCutOrientation; }. Bool_t IgnoreEventsWithNegWeightsInTraining() const; { return fIgnoreNegWeightsInTraining; }. » Author: Andreas Hoecker, Peter Speckmayer, Joerg Stelzer, Helge Voss, Kai Voss, Eckhard von Toerne, Jan Therhaag » Copyright (c) 2005-2011: *; » Last changed: root/tmva $Id: MethodBase.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:597,Testability,benchmark,benchmark,597,". TMVA::MethodBase. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodBase. class TMVA::MethodBase: public TMVA::IMethod, public TMVA::Configurable. Virtual base Class for all MVA method; MethodBase hosts several specific evaluation methods.; The kind of MVA that provides optimal performance in an analysis strongly; depends on the particular application. The evaluation factory provides a; number of numerical benchmark results to directly assess the performance; of the MVA training on the independent test sample. These are:; ; The signal efficiency at three representative background efficiencies; (which is 1 − rejection).; The significance of an MVA estimator, defined by the difference; between the MVA mean values for signal and background, divided by the; quadratic sum of their root mean squares.; The separation of an MVA x, defined by the integral; ½∫(S(x) − B(x))2/(S(x) + B(x))dx, where; S(x) and B(x) are the signal and background distributions, respectively.; The separation is zero for identical signal and background MVA shapes,; and it is one for disjunctive shapes.; ; The average, ∫x μ(S(x))dx, of the signal μ-transform.; The μ-transform of an MVA denotes the transformation that yields; a uniform background distribution. In this way, the signal distributions; S(x) can be directly compared among the various MVAs. The stronger S(x); peaks towards one, the better is the discrimination of the MVA. The; μ-transform is; documented here.; ; The MVA standard output also prints the linear correlation coefficients between; signal and background, which can be useful to eliminate variables that exhibit too; strong correlations.; ; . Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; pub",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:690,Testability,test,test,690,". TMVA::MethodBase. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodBase. class TMVA::MethodBase: public TMVA::IMethod, public TMVA::Configurable. Virtual base Class for all MVA method; MethodBase hosts several specific evaluation methods.; The kind of MVA that provides optimal performance in an analysis strongly; depends on the particular application. The evaluation factory provides a; number of numerical benchmark results to directly assess the performance; of the MVA training on the independent test sample. These are:; ; The signal efficiency at three representative background efficiencies; (which is 1 − rejection).; The significance of an MVA estimator, defined by the difference; between the MVA mean values for signal and background, divided by the; quadratic sum of their root mean squares.; The separation of an MVA x, defined by the integral; ½∫(S(x) − B(x))2/(S(x) + B(x))dx, where; S(x) and B(x) are the signal and background distributions, respectively.; The separation is zero for identical signal and background MVA shapes,; and it is one for disjunctive shapes.; ; The average, ∫x μ(S(x))dx, of the signal μ-transform.; The μ-transform of an MVA denotes the transformation that yields; a uniform background distribution. In this way, the signal distributions; S(x) can be directly compared among the various MVAs. The stronger S(x); peaks towards one, the better is the discrimination of the MVA. The; μ-transform is; documented here.; ; The MVA standard output also prints the linear correlation coefficients between; signal and background, which can be useful to eliminate variables that exhibit too; strong correlations.; ; . Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; pub",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:11049,Testability,test,testTime,11049,"it(UInt_t f); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); virtual voidSetAnalysisType(TMVA::Types::EAnalysisType type); voidSetBaseDir(TDirectory* methodDir); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidSetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidSetMethodBaseDir(TDirectory* methodDir); voidSetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidSetSignalReferenceCut(Double_t cut); voidSetSignalReferenceCutOrientation(Double_t cutOrientation); voidSetTestTime(Double_t testTime); voidSetTestvarName(const TString& v = """"); voidSetTrainTime(Double_t trainTime); virtual voidSetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidSetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTestClassification(); virtual voidTestMulticlass(); virtual voidTestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = ",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:14691,Testability,log,log,14691," voidSetWeightFileDir(TString fileDir); voidSetWeightFileName(TString); voidStatistics(TMVA::Types::ETreeType treeType, const TString& theVarName, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&); Bool_tTxtWeightsOnly() const; Bool_tVerbose() const; voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. voidAddClassesXMLTo(void* parent) const; virtual voidAddClassifierOutput(TMVA::Types::ETreeType type); virtual voidAddClassifierOutputProb(TMVA::Types::ETreeType type); voidAddInfoItem(void* gi, const TString& name, const TString& value) const; virtual voidAddMulticlassOutput(TMVA::Types::ETreeType type); virtual voidAddRegressionOutput(TMVA::Types::ETreeType type); voidAddSpectatorsXMLTo(void* parent) const; voidAddTargetsXMLTo(void* parent) const; voidAddVarsXMLTo(void* parent) const; voidCreateMVAPdfs(); static voidCreateVariableTransforms(const TString& trafoDefinition, TMVA::DataSetInfo& dataInfo, TMVA::TransformationHandler& transformationHandler, TMVA::MsgLogger& log); voidDeclareBaseOptions(); TMVA::MethodBase::ECutOrientationGetCutOrientation() const; Double_tGetEffForRoot(Double_t); Bool_tGetLine(istream& fin, char* buf); static Double_tIGetEffForRoot(Double_t); voidInitBase(); voidProcessBaseOptions(); voidReadClassesFromXML(void* clsnode); voidReadSpectatorsFromXML(void* specnode); voidReadStateFromXML(void* parent); voidReadTargetsFromXML(void* tarnode); voidReadVariablesFromXML(void* varnode); voidReadVarsFromStream(istream& istr); voidResetThisBase(); voidWriteStateToStream(ostream& tf) const; voidWriteStateToXML(void* parent) const; voidWriteVarsToStream(ostream& tf, const TString& prefix = """") const. Data Members; public:. enum EWeightFileType { kROOT; kTEXT; };; enum ECutOrientation { kNegative; kPositive; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingl",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:15814,Testability,test,testing,15814,"tEffForRoot(Double_t); Bool_tGetLine(istream& fin, char* buf); static Double_tIGetEffForRoot(Double_t); voidInitBase(); voidProcessBaseOptions(); voidReadClassesFromXML(void* clsnode); voidReadSpectatorsFromXML(void* specnode); voidReadStateFromXML(void* parent); voidReadTargetsFromXML(void* tarnode); voidReadVariablesFromXML(void* varnode); voidReadVarsFromStream(istream& istr); voidResetThisBase(); voidWriteStateToStream(ostream& tf) const; voidWriteStateToXML(void* parent) const; voidWriteVarsToStream(ostream& tf, const TString& prefix = """") const. Data Members; public:. enum EWeightFileType { kROOT; kTEXT; };; enum ECutOrientation { kNegative; kPositive; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tfSetupCompletedis method setup; const TMVA::Event*fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypefAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tfBackgroundClassindex of the Background-class; vector<TString>*fInputVarsvector of input variables used in MVA; vector<Float_t>*fMulticlassReturnValholds the return-values for the multiclass classification; Int_tfNbinsnumber of bins in input variable histograms; Int_tfNbinsHnumber of bins in evaluation histograms; Int_tfNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*fRegressionReturnValholds the return-values for the regression; UInt_tfSignalClassindex of the Signal-class. private:. TDirectory*fBaseDirbase directory for the instance, needed to know where to jump back from localDir; Bool_tfConstructedFromWeightFileis it obtained from weight file?; TMVA::MethodBase::ECutOrientationfCutOrientation+1 i",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:21803,Testability,log,log,21803,"g phase). void InitBase(); default initialization called by all constructors. void DeclareBaseOptions(); define the options (their key words) that can be set in the option string; here the options valid for ALL MVA methods are declared.; know options: VariableTransform=None,Decorrelated,PCA to use transformed variables; instead of the original ones; VariableTransformType=Signal,Background which decorrelation matrix to use; in the method. Only the Likelihood; Method can make proper use of independent; transformations of signal and background; fNbinsMVAPdf = 50 Number of bins used to create a PDF of MVA; fNsmoothMVAPdf = 2 Number of times a histogram is smoothed before creating the PDF; fHasMVAPdfs create PDFs for the MVA outputs; V for Verbose output (!V) for non verbos; H for Help message. void ProcessBaseOptions(); the option string is decoded, for availabel options see ""DeclareOptions"". void CreateVariableTransforms(const TString& trafoDefinition, TMVA::DataSetInfo& dataInfo, TMVA::TransformationHandler& transformationHandler, TMVA::MsgLogger& log); create variable transformations. void DeclareCompatibilityOptions(). std::map<TString,Double_t> OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); call the Optimzier with the set of paremeters and ranges that; are meant to be tuned. void SetTuneParameters(map<TString,Double_t> tuneParameters); set the tuning parameters accoding to the argument; This is just a dummy .. have a look at the MethodBDT how you could; perhaps implment the same thing for the other Classifiers.. void TrainMethod(). void GetRegressionDeviation(UInt_t tgtNum, TMVA::Types::ETreeType type, Double_t& stddev, Double_t& stddev90Percent) const. void AddRegressionOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void AddMulticlassOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void NoErrorCalc(Double_t *const err, Doubl",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:23436,Testability,test,test,23436,"r Classifiers.. void TrainMethod(). void GetRegressionDeviation(UInt_t tgtNum, TMVA::Types::ETreeType type, Double_t& stddev, Double_t& stddev90Percent) const. void AddRegressionOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void AddMulticlassOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void NoErrorCalc(Double_t *const err, Double_t *const errUpper). Double_t GetMvaValue(const TMVA::Event *const ev, Double_t* err = 0, Double_t* errUpper = 0). Bool_t IsSignalLike(). Bool_t IsSignalLike(Double_t mvaVal). void AddClassifierOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void AddClassifierOutputProb(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); calculate <sum-of-deviation-squared> of regression output versus ""true"" value from test sample. bias = average deviation; dev = average absolute deviation; rms = rms of deviation. void TestMulticlass(); test multiclass classification. void TestClassification(); initialization. void WriteStateToStream(ostream& tf) const; general method used in writing the header of the weight files where; the used variables, variable transformation type etc. is specified. void AddInfoItem(void* gi, const TString& name, const TString& value) const; xml writing. void AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType). void WriteStateToXML(void* parent) const; general method used in writing the header of the weight files where; the used variables, variable transformation type etc. is specified. void ReadStateFromStream(TFile& rf); write reference MVA distributions (and other information); to a ROOT type weight file. void WriteSt",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:23556,Testability,test,test,23556,"criminating variable. void AddMulticlassOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void NoErrorCalc(Double_t *const err, Double_t *const errUpper). Double_t GetMvaValue(const TMVA::Event *const ev, Double_t* err = 0, Double_t* errUpper = 0). Bool_t IsSignalLike(). Bool_t IsSignalLike(Double_t mvaVal). void AddClassifierOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void AddClassifierOutputProb(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); calculate <sum-of-deviation-squared> of regression output versus ""true"" value from test sample. bias = average deviation; dev = average absolute deviation; rms = rms of deviation. void TestMulticlass(); test multiclass classification. void TestClassification(); initialization. void WriteStateToStream(ostream& tf) const; general method used in writing the header of the weight files where; the used variables, variable transformation type etc. is specified. void AddInfoItem(void* gi, const TString& name, const TString& value) const; xml writing. void AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType). void WriteStateToXML(void* parent) const; general method used in writing the header of the weight files where; the used variables, variable transformation type etc. is specified. void ReadStateFromStream(TFile& rf); write reference MVA distributions (and other information); to a ROOT type weight file. void WriteStateToFile() const; write options and weights to file; note that each one text file for the main configuration information; and one ROOT file for ROOT objects are created. void ReadStateFromFile(); Function to write options and weights to file. void ReadStat",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:30165,Testability,test,testTime,30165,"A::Event*>& GetEventCollection(TMVA::Types::ETreeType type). TString GetTrainingTMVAVersionString() const; calculates the TMVA version string from the training version code on the fly. TString GetTrainingROOTVersionString() const; calculates the ROOT version string from the training version code on the fly. TMVA::MethodBase* GetThisBase(); return a pointer the base class of this method. void ResetThisBase(); reset required for RootFinder. const TMVA::Event* GetEvent(const TMVA::Event* ev) const. const TMVA::Event* GetEvent() const. const TMVA::Event* GetEvent(Long64_t ievt) const. const TMVA::Event* GetEvent(Long64_t ievt, TMVA::Types::ETreeType type) const. const TMVA::Event* GetTrainingEvent(Long64_t ievt) const. const TMVA::Event* GetTestingEvent(Long64_t ievt) const. void Train(). void SetTrainTime(Double_t trainTime); store and retrieve time used for training. { fTrainTime = trainTime; }. Double_t GetTrainTime() const; { return fTrainTime; }. void SetTestTime(Double_t testTime); store and retrieve time used for testing. { fTestTime = testTime; }. Double_t GetTestTime() const; { return fTestTime; }. void Init(); options treatment. void DeclareOptions(). void ProcessOptions(). void Reset(); reset the Method --> As if it was not yet trained, just instantiated; virtual void Reset() = 0;; for the moment, I provide a dummy (that would not work) default, just to make; compilation/running w/o parameter optimisation still possible. {return;}. Double_t GetMvaValue(Double_t* errLower = 0, Double_t* errUpper = 0); classifier response:; some methods may return a per-event error estimate; error calculation is skipped if err==0. const std::vector<Float_t>& GetRegressionValues(); regression response. const std::vector<Float_t>& GetMulticlassValues(); multiclass classification response. const Ranking* CreateRanking(); create ranking. Bool_t MonitorBoost(TMVA::MethodBoost* ); perfrom extra actions during the boosting at different stages. {return kFALSE;}. void AddWeightsXMLTo(voi",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:30209,Testability,test,testing,30209,"A::Event*>& GetEventCollection(TMVA::Types::ETreeType type). TString GetTrainingTMVAVersionString() const; calculates the TMVA version string from the training version code on the fly. TString GetTrainingROOTVersionString() const; calculates the ROOT version string from the training version code on the fly. TMVA::MethodBase* GetThisBase(); return a pointer the base class of this method. void ResetThisBase(); reset required for RootFinder. const TMVA::Event* GetEvent(const TMVA::Event* ev) const. const TMVA::Event* GetEvent() const. const TMVA::Event* GetEvent(Long64_t ievt) const. const TMVA::Event* GetEvent(Long64_t ievt, TMVA::Types::ETreeType type) const. const TMVA::Event* GetTrainingEvent(Long64_t ievt) const. const TMVA::Event* GetTestingEvent(Long64_t ievt) const. void Train(). void SetTrainTime(Double_t trainTime); store and retrieve time used for training. { fTrainTime = trainTime; }. Double_t GetTrainTime() const; { return fTrainTime; }. void SetTestTime(Double_t testTime); store and retrieve time used for testing. { fTestTime = testTime; }. Double_t GetTestTime() const; { return fTestTime; }. void Init(); options treatment. void DeclareOptions(). void ProcessOptions(). void Reset(); reset the Method --> As if it was not yet trained, just instantiated; virtual void Reset() = 0;; for the moment, I provide a dummy (that would not work) default, just to make; compilation/running w/o parameter optimisation still possible. {return;}. Double_t GetMvaValue(Double_t* errLower = 0, Double_t* errUpper = 0); classifier response:; some methods may return a per-event error estimate; error calculation is skipped if err==0. const std::vector<Float_t>& GetRegressionValues(); regression response. const std::vector<Float_t>& GetMulticlassValues(); multiclass classification response. const Ranking* CreateRanking(); create ranking. Bool_t MonitorBoost(TMVA::MethodBoost* ); perfrom extra actions during the boosting at different stages. {return kFALSE;}. void AddWeightsXMLTo(voi",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:30232,Testability,test,testTime,30232," type). TString GetTrainingTMVAVersionString() const; calculates the TMVA version string from the training version code on the fly. TString GetTrainingROOTVersionString() const; calculates the ROOT version string from the training version code on the fly. TMVA::MethodBase* GetThisBase(); return a pointer the base class of this method. void ResetThisBase(); reset required for RootFinder. const TMVA::Event* GetEvent(const TMVA::Event* ev) const. const TMVA::Event* GetEvent() const. const TMVA::Event* GetEvent(Long64_t ievt) const. const TMVA::Event* GetEvent(Long64_t ievt, TMVA::Types::ETreeType type) const. const TMVA::Event* GetTrainingEvent(Long64_t ievt) const. const TMVA::Event* GetTestingEvent(Long64_t ievt) const. void Train(). void SetTrainTime(Double_t trainTime); store and retrieve time used for training. { fTrainTime = trainTime; }. Double_t GetTrainTime() const; { return fTrainTime; }. void SetTestTime(Double_t testTime); store and retrieve time used for testing. { fTestTime = testTime; }. Double_t GetTestTime() const; { return fTestTime; }. void Init(); options treatment. void DeclareOptions(). void ProcessOptions(). void Reset(); reset the Method --> As if it was not yet trained, just instantiated; virtual void Reset() = 0;; for the moment, I provide a dummy (that would not work) default, just to make; compilation/running w/o parameter optimisation still possible. {return;}. Double_t GetMvaValue(Double_t* errLower = 0, Double_t* errUpper = 0); classifier response:; some methods may return a per-event error estimate; error calculation is skipped if err==0. const std::vector<Float_t>& GetRegressionValues(); regression response. const std::vector<Float_t>& GetMulticlassValues(); multiclass classification response. const Ranking* CreateRanking(); create ranking. Bool_t MonitorBoost(TMVA::MethodBoost* ); perfrom extra actions during the boosting at different stages. {return kFALSE;}. void AddWeightsXMLTo(void* parent) const; the actual ""weights"". void ReadWeig",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:2161,Availability,error,error,2161,"t::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt, TMVA::Types",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:2245,Availability,error,error,2245,"able(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt, TMVA::Types::ETreeType type) const; const vector<TMVA::Event*>&TMVA::MethodBase::GetEventCollec",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:16796,Availability,avail,availabel,16796,"thodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodBayesClassifier(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = """", TDirectory* theTargetDir = 0); standard constructor. MethodBayesClassifier(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL); constructor from weight file. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); Variable can handle classification with 2 classes. void Init( void ); default initialisation. void DeclareOptions(); define the options (their key words) that can be set in the option string. void ProcessOptions(); the option string is decoded, for availabel options see ""DeclareOptions"". ~MethodBayesClassifier( void ); destructor. void Train( void ); some training. void AddWeightsXMLTo(void* parent) const. void ReadWeightsFromStream(istream& istr); read back the training results from a file (stream). Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); returns MVA value for given event. void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". void ReadWeightsFromXML(void* ); {}. const Ranking* CreateRanking(); ranking of input variables. { return 0; }. » Author: Abhishek Narain » Copyright (c) 2005-2006: *; » Last changed: root/tmva $Id: MethodBayesClassifier.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the document",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:17285,Integrability,message,message,17285,"d classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodBayesClassifier(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = """", TDirectory* theTargetDir = 0); standard constructor. MethodBayesClassifier(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL); constructor from weight file. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); Variable can handle classification with 2 classes. void Init( void ); default initialisation. void DeclareOptions(); define the options (their key words) that can be set in the option string. void ProcessOptions(); the option string is decoded, for availabel options see ""DeclareOptions"". ~MethodBayesClassifier( void ); destructor. void Train( void ); some training. void AddWeightsXMLTo(void* parent) const. void ReadWeightsFromStream(istream& istr); read back the training results from a file (stream). Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); returns MVA value for given event. void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". void ReadWeightsFromXML(void* ); {}. const Ranking* CreateRanking(); ranking of input variables. { return 0; }. » Author: Abhishek Narain » Copyright (c) 2005-2006: *; » Last changed: root/tmva $Id: MethodBayesClassifier.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:15404,Modifiability,variab,variables,15404,"ons(); virtual voidProcessOptions(). Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodBayesClassifier(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = """", TDirectory* theTargetDir = 0); standard constructor. MethodBayesClassifier(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL); constructor from weight file. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); Variable can handle classification with 2 ",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:15593,Modifiability,variab,variable,15593,"ons(); virtual voidProcessOptions(). Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodBayesClassifier(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = """", TDirectory* theTargetDir = 0); standard constructor. MethodBayesClassifier(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL); constructor from weight file. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); Variable can handle classification with 2 ",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:17483,Modifiability,variab,variables,17483,"d classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodBayesClassifier(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = """", TDirectory* theTargetDir = 0); standard constructor. MethodBayesClassifier(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL); constructor from weight file. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); Variable can handle classification with 2 classes. void Init( void ); default initialisation. void DeclareOptions(); define the options (their key words) that can be set in the option string. void ProcessOptions(); the option string is decoded, for availabel options see ""DeclareOptions"". ~MethodBayesClassifier( void ); destructor. void Train( void ); some training. void AddWeightsXMLTo(void* parent) const. void ReadWeightsFromStream(istream& istr); read back the training results from a file (stream). Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); returns MVA value for given event. void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". void ReadWeightsFromXML(void* ); {}. const Ranking* CreateRanking(); ranking of input variables. { return 0; }. » Author: Abhishek Narain » Copyright (c) 2005-2006: *; » Last changed: root/tmva $Id: MethodBayesClassifier.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:11484,Performance,tune,tuneParameters,11484,"voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:11286,Testability,test,testTime,11286,"am& out, Option_t* option = """"); virtual voidTMVA::MethodBase::SetAnalysisType(TMVA::Types::EAnalysisType type); voidTMVA::MethodBase::SetBaseDir(TDirectory* methodDir); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObj",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:15094,Testability,test,testing,15094,"voidTMVA::Configurable::ResetSetFlag(); voidTMVA::MethodBase::SetNormalised(Bool_t norm); voidTMVA::MethodBase::SetWeightFileDir(TString fileDir); voidTMVA::MethodBase::SetWeightFileName(TString); voidTMVA::MethodBase::Statistics(TMVA::Types::ETreeType treeType, const TString& theVarName, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&); Bool_tTMVA::MethodBase::TxtWeightsOnly() const; Bool_tTMVA::MethodBase::Verbose() const; voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. virtual voidDeclareOptions(); virtual voidProcessOptions(). Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. Class Charts. Inheritance; Inhe",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBDT.html:2759,Availability,error,error,2759,"ructed using the same mechanism as described for the root; node. The devision is stopped once a certain node has reached either a; minimum number of events, or a minimum or maximum signal purity. These; leave nodes are then called ""signal"" or ""background"" if they contain; more signal respective background events from the training sample. Boosting:. The idea behind adaptive boosting (AdaBoost) is, that signal events; from the training sample, that end up in a background node; (and vice versa) are given a larger weight than events that are in; the correct leave node. This results in a re-weighed training event; sample, with which then a new decision tree can be developed.; The boosting can be applied several times (typically 100-500 times); and one ends up with a set of decision trees (a forest).; Gradient boosting works more like a function expansion approach, where; each tree corresponds to a summand. The parameters for each summand (tree); are determined by the minimization of a error function (binomial log-; likelihood for classification and Huber loss for regression).; A greedy algorithm is used, which means, that only one tree is modified; at a time, while the other trees stay fixed. Bagging:. In this particular variant of the Boosted Decision Trees the boosting; is not done on the basis of previous training results, but by a simple; stochastic re-sampling of the initial training event sample. Random Trees:; Similar to the ""Random Forests"" from Leo Breiman and Adele Cutler, it; uses the bagging algorithm together and bases the determination of the; best node-split during the training on a random subset of variables only; which is individually chosen for each split. Analysis:. Applying an individual decision tree to a test event results in a; classification of the event as either signal or background. For the; boosted decision tree selection, an event is successively subjected to; the whole set of decision trees and depending on how often it is; classified as sign",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:5865,Availability,error,error,5865," """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidDeclareOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const vector<double>&GetBoostWeights() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt) const; const TMVA::Event*TMVA::M",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:5949,Availability,error,error,5949,"bleTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidDeclareOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const vector<double>&GetBoostWeights() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt, TMVA::Types::ETreeType type) const; const vector<",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:21807,Availability,error,error,21807,"values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. Double_tfAdaBoostBetabeta parameter for AdaBoost algorithm; TStringfAdaBoostR2Lossloss type used in AdaBoostR2 (Linear,Quadratic or Exponential); Bool_tfAutomaticuse user given prune strength or automatically determined one using a validation sample; Bool_tfBaggedGradBoostturn bagging in combination with grad boost on/off; TStringfBoostTypestring specifying the boost type; Double_tfBoostWeightntuple var: boost weight; vector<double>fBoostWeightsthe weights applied in the individual boosts; Bool_tfDoBoostMonitorcreate control plot with ROC integral vs tree number; Double_tfErrorFractionntuple var: misclassification error fraction; vector<TMVA::Event*>fEventSamplethe training events; Double_tfFValidationEventsfraction of events to use for pruning; vector<TMVA::DecisionTree*,allocator<TMVA::DecisionTree*> >fForestthe collection of decision trees; Int_tfITreentuple var: ith tree; Bool_tfInverseBoostNegWeightsboost ev. with neg. weights with 1/boostweight rathre than boostweight; UInt_tfMaxDepthmax depth; Double_tfMinLinCorrForFisherthe minimum linear correlation between two variables demanded for use in fisher criterium in node splitting; TTree*fMonitorNtuplemonitoring ntuple; Int_tfNCutsgrid used in cut applied in node splitting; UInt_tfNNodesMaxmax # of nodes; Int_tfNTreesnumber of decision trees requested; TStringfNegWeightTreatmentvariable that holds the option of how to treat negative event weights in training; Bool_tfNoNegWeightsInTraini",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:24150,Availability,down,down,24150,". with neg. and pos. weights in node and don't boost them; Bool_tfPruneBeforeBoostflag to prune before boosting; TMVA::DecisionTree::EPruneMethodfPruneMethodmethod used for prunig; TStringfPruneMethodSprune method option String; Double_tfPruneStrengtha parameter to set the ""amount"" of pruning..needs to be adjusted; Bool_tfRandomisedTreeschoose a random subset of possible cut variables at each node during training; Bool_tfRenormByClassindividually re-normalize each event class to the original size after boosting; map<TMVA::Event*,std::vector<double> >fResidualsindividual event residuals for gradient boost; Double_tfSampleFractionfraction of events used for bagged grad boost; Double_tfSampleSizeFractionrelative size of bagged event sample to original sample size; TMVA::SeparationBase*fSepTypethe separation used in node splitting; TStringfSepTypeSthe separation (option string) used in node splitting; Double_tfShrinkagelearning rate for gradient boost;; vector<TMVA::Event*>fSubSamplesubsample for bagged grad boost; Double_tfSumOfWeightssum of all event weights; Bool_tfTrainWithNegWeightsyes there are negative event weights and we don't ignore them; Double_tfTransitionPointbreak-down point for gradient regression; Bool_tfUseExclusiveVarsindividual variables already used in fisher criterium are not anymore analysed individually for node splitting; Bool_tfUseFisherCutsuse multivariate splits using the Fisher criterium; UInt_tfUseNTrainEventsnumber of randomly picked training events used in randomised (and bagged) trees; UInt_tfUseNvarsthe number of variables used in the randomised tree splitting; Bool_tfUsePoissonNvarsuse ""fUseNvars"" not as fixed number but as mean of a possion distr. in each split; Bool_tfUseWeightedTreesuse average classification from the trees, or have the individual trees trees in the forest weighted (e.g. log(boostweight) from AdaBoost; Bool_tfUseYesNoLeafuse sig or bkg classification in leave nodes or sig/bkg; vector<TMVA::Event*>fValidationSamplethe ",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:27196,Availability,error,error,27196,"Int_t numberClasses, UInt_t numberTargets); BDT can handle classification with multiple classes and regression with one regression-target. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options:; nTrees number of trees in the forest to be created; BoostType the boosting type for the trees in the forest (AdaBoost e.t.c..); known: AdaBoost; AdaBoostR2 (Adaboost for regression); Bagging; GradBoost; AdaBoostBeta the boosting parameter, beta, for AdaBoost; UseRandomisedTrees choose at each node splitting a random set of variables; UseNvars use UseNvars variables in randomised trees; UsePoission Nvars use UseNvars not as fixed number but as mean of a possion distribution; UseNTrainEvents number of training events used in randomised (and bagged) trees; SeparationType the separation criterion applied in the node splitting; known: GiniIndex; MisClassificationError; CrossEntropy; SDivSqrtSPlusB; nEventsMin: the minimum number of events in a node (leaf criteria, stop splitting); nCuts: the number of steps in the optimisation of the cut for a node (if < 0, then; step size is determined by the events); UseFisherCuts: use multivariate splits using the Fisher criterion; UseYesNoLeaf decide if the classification is done simply by the node type, or the S/B; (from the training) in the leaf node; NodePurityLimit the minimum purity to classify a node as a signal node (used in pruning and boosting to determine; misclassification error rate); UseWeightedTrees use average classification from the trees, or have the individual trees; trees in the forest weighted (e.g. log(boostweight) from AdaBoost; PruneMethod The Pruning method:; known: NoPruning // switch off pruning completely; ExpectedError; CostComplexity; PruneStrength a parameter to adjust the amount of pruning. Should be large enough such that overtraining is avoided.; PruneBeforeBoost flag to prune the tree before applying boosting algorithm; PruningValFraction number of even",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:28441,Availability,avail,available,28441,"runing completely; ExpectedError; CostComplexity; PruneStrength a parameter to adjust the amount of pruning. Should be large enough such that overtraining is avoided.; PruneBeforeBoost flag to prune the tree before applying boosting algorithm; PruningValFraction number of events to use for optimizing pruning (only if PruneStrength < 0, i.e. automatic pruning); NegWeightTreatment IgnoreNegWeightsInTraining Ignore negative weight events in the training.; DecreaseBoostWeight Boost ev. with neg. weight with 1/boostweight instead of boostweight; PairNegWeightsGlobal Pair ev. with neg. and pos. weights in traning sample and ""annihilate"" them; PairNegWeightsInNode Randomly pair miscl. ev. with neg. and pos. weights in node and don't boost them; NNodesMax maximum number of nodes allwed in the tree splitting, then it stops.; MaxDepth maximum depth of the decision tree allowed before further splitting is stopped. void DeclareCompatibilityOptions(). void ProcessOptions(); the option string is decoded, for available options see ""DeclareOptions"". void Init( void ); common initialisation with defaults for the BDT-Method. void Reset( void ); reset the method, as if it had just been instantiated (forget all training etc.). ~MethodBDT( void ); destructor. void InitEventSample( void ); Write all Events from the Tree into a vector of Events, that are; more easily manipulated. This method should never be called without; existing trainingTree, as it the vector of events from the ROOT training tree. void PreProcessNegativeEventWeights(); o.k. you know there are events with negative event weights. This routine will remove; them by pairing them with the closest event(s) of the same event class with positive; weights; A first attempt is ""brute force"", I dont' try to be clever using search trees etc,; just quick and dirty to see if the result is any good. std::map<TString,Double_t> OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); call the Optimzier with th",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:30059,Deployability,update,update,30059,"ive event weights. This routine will remove; them by pairing them with the closest event(s) of the same event class with positive; weights; A first attempt is ""brute force"", I dont' try to be clever using search trees etc,; just quick and dirty to see if the result is any good. std::map<TString,Double_t> OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); call the Optimzier with the set of paremeters and ranges that; are meant to be tuned. void SetTuneParameters(map<TString,Double_t> tuneParameters); set the tuning parameters accoding to the argument. void Train(); BDT training. void GetRandomSubSample(); fills fEventSample with fSampleFraction*NEvents random training events. Double_t GetGradBoostMVA(TMVA::Event& e, UInt_t nTrees); returns MVA value: -1 for background, 1 for signal. void UpdateTargets(vector<TMVA::Event*> , UInt_t cls = 0); Calculate residua for all events;. void UpdateTargetsRegression(vector<TMVA::Event*> , Bool_t first = kFALSE); Calculate current residuals for all events and update targets for next iteration. Double_t GetWeightedQuantile(vector<std::pair<Double_t,Double_t> > vec, const Double_t quantile, const Double_t SumOfWeights = 0.0); calculates the quantile of the distribution of the first pair entries weighted with the values in the second pair entries. Double_t GradBoost(vector<TMVA::Event*> , TMVA::DecisionTree* dt, UInt_t cls = 0); Calculate the desired response value for each region. Double_t GradBoostRegression(vector<TMVA::Event*> , TMVA::DecisionTree* dt); Implementation of M_TreeBoost using a Huber loss function as desribed by Friedman 1999. void InitGradBoost(vector<TMVA::Event*> ); initialize targets for first tree. Double_t TestTreeQuality(TMVA::DecisionTree* dt); test the tree quality.. in terms of Miscalssification. Double_t Boost(vector<TMVA::Event*> , TMVA::DecisionTree* dt, Int_t iTree, UInt_t cls = 0); apply the boosting alogrithim (the algorithm is selecte via the the ""option"" given; in ",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:2131,Energy Efficiency,adapt,adaptive,2131,"g the training. Training of a decision tree is the; process to define the ""cut criteria"" for each node. The training; starts with the root node. Here one takes the full training event; sample and selects the variable and corresponding cut value that gives; the best separation between signal and background at this stage. Using; this cut criterion, the sample is then divided into two subsamples, a; signal-like (right) and a background-like (left) sample. Two new nodes; are then created for each of the two sub-samples and they are; constructed using the same mechanism as described for the root; node. The devision is stopped once a certain node has reached either a; minimum number of events, or a minimum or maximum signal purity. These; leave nodes are then called ""signal"" or ""background"" if they contain; more signal respective background events from the training sample. Boosting:. The idea behind adaptive boosting (AdaBoost) is, that signal events; from the training sample, that end up in a background node; (and vice versa) are given a larger weight than events that are in; the correct leave node. This results in a re-weighed training event; sample, with which then a new decision tree can be developed.; The boosting can be applied several times (typically 100-500 times); and one ends up with a set of decision trees (a forest).; Gradient boosting works more like a function expansion approach, where; each tree corresponds to a summand. The parameters for each summand (tree); are determined by the minimization of a error function (binomial log-; likelihood for classification and Huber loss for regression).; A greedy algorithm is used, which means, that only one tree is modified; at a time, while the other trees stay fixed. Bagging:. In this particular variant of the Boosted Decision Trees the boosting; is not done on the basis of previous training results, but by a simple; stochastic re-sampling of the initial training event sample. Random Trees:; Similar to the ""Random Fo",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:31163,Energy Efficiency,monitor,monitoring,31163,"air<Double_t,Double_t> > vec, const Double_t quantile, const Double_t SumOfWeights = 0.0); calculates the quantile of the distribution of the first pair entries weighted with the values in the second pair entries. Double_t GradBoost(vector<TMVA::Event*> , TMVA::DecisionTree* dt, UInt_t cls = 0); Calculate the desired response value for each region. Double_t GradBoostRegression(vector<TMVA::Event*> , TMVA::DecisionTree* dt); Implementation of M_TreeBoost using a Huber loss function as desribed by Friedman 1999. void InitGradBoost(vector<TMVA::Event*> ); initialize targets for first tree. Double_t TestTreeQuality(TMVA::DecisionTree* dt); test the tree quality.. in terms of Miscalssification. Double_t Boost(vector<TMVA::Event*> , TMVA::DecisionTree* dt, Int_t iTree, UInt_t cls = 0); apply the boosting alogrithim (the algorithm is selecte via the the ""option"" given; in the constructor. The return value is the boosting weight. void BoostMonitor(Int_t iTree); fills the ROCIntegral vs Itree from the testSample for the monitoring plots; during the training .. but using the testing events. Double_t AdaBoost(vector<TMVA::Event*> , TMVA::DecisionTree* dt); the AdaBoost implementation.; a new training sample is generated by weighting; events that are misclassified by the decision tree. The weight; applied is w = (1-err)/err or more general:; w = ((1-err)/err)^beta; where err is the fraction of misclassified events in the tree ( <0.5 assuming; demanding the that previous selection was better than random guessing); and ""beta"" being a free parameter (standard: beta = 1) that modifies the; boosting. Double_t Bagging(vector<TMVA::Event*> , Int_t iTree); call it boot-strapping, re-sampling or whatever you like, in the end it is nothing; else but applying ""random"" weights to each event. Double_t RegBoost(vector<TMVA::Event*> , TMVA::DecisionTree* dt); a special boosting only for Regression ...; maybe I'll implement it later... Double_t AdaBoostR2(vector<TMVA::Event*> , TMVA::DecisionTr",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:32146,Energy Efficiency,adapt,adaption,32146," the testSample for the monitoring plots; during the training .. but using the testing events. Double_t AdaBoost(vector<TMVA::Event*> , TMVA::DecisionTree* dt); the AdaBoost implementation.; a new training sample is generated by weighting; events that are misclassified by the decision tree. The weight; applied is w = (1-err)/err or more general:; w = ((1-err)/err)^beta; where err is the fraction of misclassified events in the tree ( <0.5 assuming; demanding the that previous selection was better than random guessing); and ""beta"" being a free parameter (standard: beta = 1) that modifies the; boosting. Double_t Bagging(vector<TMVA::Event*> , Int_t iTree); call it boot-strapping, re-sampling or whatever you like, in the end it is nothing; else but applying ""random"" weights to each event. Double_t RegBoost(vector<TMVA::Event*> , TMVA::DecisionTree* dt); a special boosting only for Regression ...; maybe I'll implement it later... Double_t AdaBoostR2(vector<TMVA::Event*> , TMVA::DecisionTree* dt); adaption of the AdaBoost to regression problems (see H.Drucker 1997). void AddWeightsXMLTo(void* parent) const; write weights to XML. void ReadWeightsFromXML(void* parent); reads the BDT from the xml file. void ReadWeightsFromStream(istream& istr); read the weights (BDT coefficients). Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0). Double_t GetMvaValue(Double_t* err, Double_t* errUpper, UInt_t useNTrees); Return the MVA value (range [-1;1]) that classifies the; event according to the majority vote from the total number of; decision trees. Double_t PrivateGetMvaValue(TMVA::Event& ev, Double_t* err = 0, Double_t* errUpper = 0, UInt_t useNTrees = 0); Return the MVA value (range [-1;1]) that classifies the; event according to the majority vote from the total number of; decision trees. const std::vector<Float_t>& GetMulticlassValues(); get the multiclass MVA response for the BDT classifier. const std::vector<Float_t> & GetRegressionValues(); get the regression value ",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:3717,Integrability,depend,depending,3717,"termined by the minimization of a error function (binomial log-; likelihood for classification and Huber loss for regression).; A greedy algorithm is used, which means, that only one tree is modified; at a time, while the other trees stay fixed. Bagging:. In this particular variant of the Boosted Decision Trees the boosting; is not done on the basis of previous training results, but by a simple; stochastic re-sampling of the initial training event sample. Random Trees:; Similar to the ""Random Forests"" from Leo Breiman and Adele Cutler, it; uses the bagging algorithm together and bases the determination of the; best node-split during the training on a random subset of variables only; which is individually chosen for each split. Analysis:. Applying an individual decision tree to a test event results in a; classification of the event as either signal or background. For the; boosted decision tree selection, an event is successively subjected to; the whole set of decision trees and depending on how often it is; classified as signal, a ""likelihood"" estimator is constructed for the; event being signal or background. The value of this estimator is the; one which is then used to select the events from an event sample, and; the cut value on this estimator defines the efficiency and purity of; the selection. Function Members (Methods); public:. virtual~MethodBDT(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; Double_tBoost(vector<TMVA::Event*>, TMVA::DecisionTree* dt, Int_t iTree, UInt_t cls = 0); virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidTMVA::MethodBase::CheckSetup(); static TClass*Class(); ",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:29038,Integrability,rout,routine,29038,"on't boost them; NNodesMax maximum number of nodes allwed in the tree splitting, then it stops.; MaxDepth maximum depth of the decision tree allowed before further splitting is stopped. void DeclareCompatibilityOptions(). void ProcessOptions(); the option string is decoded, for available options see ""DeclareOptions"". void Init( void ); common initialisation with defaults for the BDT-Method. void Reset( void ); reset the method, as if it had just been instantiated (forget all training etc.). ~MethodBDT( void ); destructor. void InitEventSample( void ); Write all Events from the Tree into a vector of Events, that are; more easily manipulated. This method should never be called without; existing trainingTree, as it the vector of events from the ROOT training tree. void PreProcessNegativeEventWeights(); o.k. you know there are events with negative event weights. This routine will remove; them by pairing them with the closest event(s) of the same event class with positive; weights; A first attempt is ""brute force"", I dont' try to be clever using search trees etc,; just quick and dirty to see if the result is any good. std::map<TString,Double_t> OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); call the Optimzier with the set of paremeters and ranges that; are meant to be tuned. void SetTuneParameters(map<TString,Double_t> tuneParameters); set the tuning parameters accoding to the argument. void Train(); BDT training. void GetRandomSubSample(); fills fEventSample with fSampleFraction*NEvents random training events. Double_t GetGradBoostMVA(TMVA::Event& e, UInt_t nTrees); returns MVA value: -1 for background, 1 for signal. void UpdateTargets(vector<TMVA::Event*> , UInt_t cls = 0); Calculate residua for all events;. void UpdateTargetsRegression(vector<TMVA::Event*> , Bool_t first = kFALSE); Calculate current residuals for all events and update targets for next iteration. Double_t GetWeightedQuantile(vector<std::pair<Double_t,Double_t> > v",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:33900,Integrability,message,message,33900,"ding to the majority vote from the total number of; decision trees. const std::vector<Float_t>& GetMulticlassValues(); get the multiclass MVA response for the BDT classifier. const std::vector<Float_t> & GetRegressionValues(); get the regression value generated by the BDTs. void WriteMonitoringHistosToFile( void ); Here we could write some histograms created during the processing; to the output file. vector< Double_t > GetVariableImportance(); Return the relative variable importance, normalized to all; variables together having the importance 1. The importance in; evaluated as the total separation-gain that this variable had in; the decision trees (weighted by the number of events). Double_t GetVariableImportance(UInt_t ivar); Returns the measure for the variable importance of variable ""ivar""; which is later used in GetVariableImportance() to calculate the; relative variable importances. const TMVA::Ranking* CreateRanking(); Compute ranking of input variables. void GetHelpMessage() const; Get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". void MakeClassSpecific(ostream& , const TString& ) const; make ROOT-independent C++ class for classifier response (classifier-specific implementation). void MakeClassSpecificHeader(ostream& , const TString& ) const; specific class header. void MakeClassInstantiateNode(TMVA::DecisionTreeNode* n, ostream& fout, const TString& className) const; recursively descends a tree and writes the node instance to the output streem. const std::vector<TMVA::DecisionTree*>& GetForest() const; { return fForest; }. const std::vector<TMVA::Event*>& GetTrainingEvents() const; { return fEventSample; }. const std::vector<double>& GetBoostWeights() const; { return fBoostWeights; }. void SetMaxDepth(Int_t d); {fMaxDepth = d;}. void SetNodeMinEvents(Int_t d); {fNodeMinEvents = d;}. void SetNTrees(Int_t d); {fNTrees = d;}. void SetAdaBoostBeta(Double_t b); {fAdaBoostBeta = b;}. void SetNo",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:896,Modifiability,variab,variable,896,". TMVA::MethodBDT. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodBDT. class TMVA::MethodBDT: public TMVA::MethodBase. Analysis of Boosted Decision Trees. Boosted decision trees have been successfully used in High Energy; Physics analysis for example by the MiniBooNE experiment; (Yang-Roe-Zhu, physics/0508045). In Boosted Decision Trees, the; selection is done on a majority vote on the result of several decision; trees, which are all derived from the same training sample by; supplying different event weights during the training. Decision trees:. Successive decision nodes are used to categorize the; events out of the sample as either signal or background. Each node; uses only a single discriminating variable to decide if the event is; signal-like (""goes right"") or background-like (""goes left""). This; forms a tree like structure with ""baskets"" at the end (leave nodes),; and an event is classified as either signal or background according to; whether the basket where it ends up has been classified signal or; background during the training. Training of a decision tree is the; process to define the ""cut criteria"" for each node. The training; starts with the root node. Here one takes the full training event; sample and selects the variable and corresponding cut value that gives; the best separation between signal and background at this stage. Using; this cut criterion, the sample is then divided into two subsamples, a; signal-like (right) and a background-like (left) sample. Two new nodes; are then created for each of the two sub-samples and they are; constructed using the same mechanism as described for the root; node. The devision is stopped once a certain node has reached either a; minimum number of events, or a minimum or maximum signal purity. These; leave nodes are then called ""signa",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:1432,Modifiability,variab,variable,1432,"experiment; (Yang-Roe-Zhu, physics/0508045). In Boosted Decision Trees, the; selection is done on a majority vote on the result of several decision; trees, which are all derived from the same training sample by; supplying different event weights during the training. Decision trees:. Successive decision nodes are used to categorize the; events out of the sample as either signal or background. Each node; uses only a single discriminating variable to decide if the event is; signal-like (""goes right"") or background-like (""goes left""). This; forms a tree like structure with ""baskets"" at the end (leave nodes),; and an event is classified as either signal or background according to; whether the basket where it ends up has been classified signal or; background during the training. Training of a decision tree is the; process to define the ""cut criteria"" for each node. The training; starts with the root node. Here one takes the full training event; sample and selects the variable and corresponding cut value that gives; the best separation between signal and background at this stage. Using; this cut criterion, the sample is then divided into two subsamples, a; signal-like (right) and a background-like (left) sample. Two new nodes; are then created for each of the two sub-samples and they are; constructed using the same mechanism as described for the root; node. The devision is stopped once a certain node has reached either a; minimum number of events, or a minimum or maximum signal purity. These; leave nodes are then called ""signal"" or ""background"" if they contain; more signal respective background events from the training sample. Boosting:. The idea behind adaptive boosting (AdaBoost) is, that signal events; from the training sample, that end up in a background node; (and vice versa) are given a larger weight than events that are in; the correct leave node. This results in a re-weighed training event; sample, with which then a new decision tree can be developed.; The boosting ",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:2131,Modifiability,adapt,adaptive,2131,"g the training. Training of a decision tree is the; process to define the ""cut criteria"" for each node. The training; starts with the root node. Here one takes the full training event; sample and selects the variable and corresponding cut value that gives; the best separation between signal and background at this stage. Using; this cut criterion, the sample is then divided into two subsamples, a; signal-like (right) and a background-like (left) sample. Two new nodes; are then created for each of the two sub-samples and they are; constructed using the same mechanism as described for the root; node. The devision is stopped once a certain node has reached either a; minimum number of events, or a minimum or maximum signal purity. These; leave nodes are then called ""signal"" or ""background"" if they contain; more signal respective background events from the training sample. Boosting:. The idea behind adaptive boosting (AdaBoost) is, that signal events; from the training sample, that end up in a background node; (and vice versa) are given a larger weight than events that are in; the correct leave node. This results in a re-weighed training event; sample, with which then a new decision tree can be developed.; The boosting can be applied several times (typically 100-500 times); and one ends up with a set of decision trees (a forest).; Gradient boosting works more like a function expansion approach, where; each tree corresponds to a summand. The parameters for each summand (tree); are determined by the minimization of a error function (binomial log-; likelihood for classification and Huber loss for regression).; A greedy algorithm is used, which means, that only one tree is modified; at a time, while the other trees stay fixed. Bagging:. In this particular variant of the Boosted Decision Trees the boosting; is not done on the basis of previous training results, but by a simple; stochastic re-sampling of the initial training event sample. Random Trees:; Similar to the ""Random Fo",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:3401,Modifiability,variab,variables,3401,"t leave node. This results in a re-weighed training event; sample, with which then a new decision tree can be developed.; The boosting can be applied several times (typically 100-500 times); and one ends up with a set of decision trees (a forest).; Gradient boosting works more like a function expansion approach, where; each tree corresponds to a summand. The parameters for each summand (tree); are determined by the minimization of a error function (binomial log-; likelihood for classification and Huber loss for regression).; A greedy algorithm is used, which means, that only one tree is modified; at a time, while the other trees stay fixed. Bagging:. In this particular variant of the Boosted Decision Trees the boosting; is not done on the basis of previous training results, but by a simple; stochastic re-sampling of the initial training event sample. Random Trees:; Similar to the ""Random Forests"" from Leo Breiman and Adele Cutler, it; uses the bagging algorithm together and bases the determination of the; best node-split during the training on a random subset of variables only; which is individually chosen for each split. Analysis:. Applying an individual decision tree to a test event results in a; classification of the event as either signal or background. For the; boosted decision tree selection, an event is successively subjected to; the whole set of decision trees and depending on how often it is; classified as signal, a ""likelihood"" estimator is constructed for the; event being signal or background. The value of this estimator is the; one which is then used to select the events from an event sample, and; the cut value on this estimator defines the efficiency and purity of; the selection. Function Members (Methods); public:. virtual~MethodBDT(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); vi",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:20554,Modifiability,variab,variables,20554,"VA::Event*>, Bool_t first = kFALSE). Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. Double_tfAdaBoostBetabeta parameter for AdaBoost algorithm; TStringfAdaBoostR2Lossloss type used in AdaBoostR2 (Linear,Quadratic or Exponential); Bool_tfAutomaticuse user given prune strength or automatically determined one using a validation sample; Bool_tfBaggedGradBoostturn bagging in combination with grad boost on/off; TStringfBoostTypestring specifying the boost type; Double_tfBoostWeightntuple var: boost weight; vector<double>fBoostWeightsthe weights applied in the individual boosts; Bool_tfDoBoostMonitorcreate control plot with ROC integral ",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:20743,Modifiability,variab,variable,20743,"VA::Event*>, Bool_t first = kFALSE). Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. Double_tfAdaBoostBetabeta parameter for AdaBoost algorithm; TStringfAdaBoostR2Lossloss type used in AdaBoostR2 (Linear,Quadratic or Exponential); Bool_tfAutomaticuse user given prune strength or automatically determined one using a validation sample; Bool_tfBaggedGradBoostturn bagging in combination with grad boost on/off; TStringfBoostTypestring specifying the boost type; Double_tfBoostWeightntuple var: boost weight; vector<double>fBoostWeightsthe weights applied in the individual boosts; Bool_tfDoBoostMonitorcreate control plot with ROC integral ",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:22272,Modifiability,variab,variables,22272,"nation with grad boost on/off; TStringfBoostTypestring specifying the boost type; Double_tfBoostWeightntuple var: boost weight; vector<double>fBoostWeightsthe weights applied in the individual boosts; Bool_tfDoBoostMonitorcreate control plot with ROC integral vs tree number; Double_tfErrorFractionntuple var: misclassification error fraction; vector<TMVA::Event*>fEventSamplethe training events; Double_tfFValidationEventsfraction of events to use for pruning; vector<TMVA::DecisionTree*,allocator<TMVA::DecisionTree*> >fForestthe collection of decision trees; Int_tfITreentuple var: ith tree; Bool_tfInverseBoostNegWeightsboost ev. with neg. weights with 1/boostweight rathre than boostweight; UInt_tfMaxDepthmax depth; Double_tfMinLinCorrForFisherthe minimum linear correlation between two variables demanded for use in fisher criterium in node splitting; TTree*fMonitorNtuplemonitoring ntuple; Int_tfNCutsgrid used in cut applied in node splitting; UInt_tfNNodesMaxmax # of nodes; Int_tfNTreesnumber of decision trees requested; TStringfNegWeightTreatmentvariable that holds the option of how to treat negative event weights in training; Bool_tfNoNegWeightsInTrainingignore negative event weights in the training; Int_tfNodeMinEventsmin number of events in node; Double_tfNodePurityLimitpurity limit for sig/bkg nodes; Bool_tfPairNegWeightsGlobalpair ev. with neg. and pos. weights in traning sample and ""annihilate"" them ; Bool_tfPairNegWeightsInNoderandomly pair miscl. ev. with neg. and pos. weights in node and don't boost them; Bool_tfPruneBeforeBoostflag to prune before boosting; TMVA::DecisionTree::EPruneMethodfPruneMethodmethod used for prunig; TStringfPruneMethodSprune method option String; Double_tfPruneStrengtha parameter to set the ""amount"" of pruning..needs to be adjusted; Bool_tfRandomisedTreeschoose a random subset of possible cut variables at each node during training; Bool_tfRenormByClassindividually re-normalize each event class to the original size after boosting; map<T",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:23335,Modifiability,variab,variables,23335,". with neg. and pos. weights in node and don't boost them; Bool_tfPruneBeforeBoostflag to prune before boosting; TMVA::DecisionTree::EPruneMethodfPruneMethodmethod used for prunig; TStringfPruneMethodSprune method option String; Double_tfPruneStrengtha parameter to set the ""amount"" of pruning..needs to be adjusted; Bool_tfRandomisedTreeschoose a random subset of possible cut variables at each node during training; Bool_tfRenormByClassindividually re-normalize each event class to the original size after boosting; map<TMVA::Event*,std::vector<double> >fResidualsindividual event residuals for gradient boost; Double_tfSampleFractionfraction of events used for bagged grad boost; Double_tfSampleSizeFractionrelative size of bagged event sample to original sample size; TMVA::SeparationBase*fSepTypethe separation used in node splitting; TStringfSepTypeSthe separation (option string) used in node splitting; Double_tfShrinkagelearning rate for gradient boost;; vector<TMVA::Event*>fSubSamplesubsample for bagged grad boost; Double_tfSumOfWeightssum of all event weights; Bool_tfTrainWithNegWeightsyes there are negative event weights and we don't ignore them; Double_tfTransitionPointbreak-down point for gradient regression; Bool_tfUseExclusiveVarsindividual variables already used in fisher criterium are not anymore analysed individually for node splitting; Bool_tfUseFisherCutsuse multivariate splits using the Fisher criterium; UInt_tfUseNTrainEventsnumber of randomly picked training events used in randomised (and bagged) trees; UInt_tfUseNvarsthe number of variables used in the randomised tree splitting; Bool_tfUsePoissonNvarsuse ""fUseNvars"" not as fixed number but as mean of a possion distr. in each split; Bool_tfUseWeightedTreesuse average classification from the trees, or have the individual trees trees in the forest weighted (e.g. log(boostweight) from AdaBoost; Bool_tfUseYesNoLeafuse sig or bkg classification in leave nodes or sig/bkg; vector<TMVA::Event*>fValidationSamplethe ",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:24220,Modifiability,variab,variables,24220,". with neg. and pos. weights in node and don't boost them; Bool_tfPruneBeforeBoostflag to prune before boosting; TMVA::DecisionTree::EPruneMethodfPruneMethodmethod used for prunig; TStringfPruneMethodSprune method option String; Double_tfPruneStrengtha parameter to set the ""amount"" of pruning..needs to be adjusted; Bool_tfRandomisedTreeschoose a random subset of possible cut variables at each node during training; Bool_tfRenormByClassindividually re-normalize each event class to the original size after boosting; map<TMVA::Event*,std::vector<double> >fResidualsindividual event residuals for gradient boost; Double_tfSampleFractionfraction of events used for bagged grad boost; Double_tfSampleSizeFractionrelative size of bagged event sample to original sample size; TMVA::SeparationBase*fSepTypethe separation used in node splitting; TStringfSepTypeSthe separation (option string) used in node splitting; Double_tfShrinkagelearning rate for gradient boost;; vector<TMVA::Event*>fSubSamplesubsample for bagged grad boost; Double_tfSumOfWeightssum of all event weights; Bool_tfTrainWithNegWeightsyes there are negative event weights and we don't ignore them; Double_tfTransitionPointbreak-down point for gradient regression; Bool_tfUseExclusiveVarsindividual variables already used in fisher criterium are not anymore analysed individually for node splitting; Bool_tfUseFisherCutsuse multivariate splits using the Fisher criterium; UInt_tfUseNTrainEventsnumber of randomly picked training events used in randomised (and bagged) trees; UInt_tfUseNvarsthe number of variables used in the randomised tree splitting; Bool_tfUsePoissonNvarsuse ""fUseNvars"" not as fixed number but as mean of a possion distr. in each split; Bool_tfUseWeightedTreesuse average classification from the trees, or have the individual trees trees in the forest weighted (e.g. log(boostweight) from AdaBoost; Bool_tfUseYesNoLeafuse sig or bkg classification in leave nodes or sig/bkg; vector<TMVA::Event*>fValidationSamplethe ",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:24525,Modifiability,variab,variables,24525,". with neg. and pos. weights in node and don't boost them; Bool_tfPruneBeforeBoostflag to prune before boosting; TMVA::DecisionTree::EPruneMethodfPruneMethodmethod used for prunig; TStringfPruneMethodSprune method option String; Double_tfPruneStrengtha parameter to set the ""amount"" of pruning..needs to be adjusted; Bool_tfRandomisedTreeschoose a random subset of possible cut variables at each node during training; Bool_tfRenormByClassindividually re-normalize each event class to the original size after boosting; map<TMVA::Event*,std::vector<double> >fResidualsindividual event residuals for gradient boost; Double_tfSampleFractionfraction of events used for bagged grad boost; Double_tfSampleSizeFractionrelative size of bagged event sample to original sample size; TMVA::SeparationBase*fSepTypethe separation used in node splitting; TStringfSepTypeSthe separation (option string) used in node splitting; Double_tfShrinkagelearning rate for gradient boost;; vector<TMVA::Event*>fSubSamplesubsample for bagged grad boost; Double_tfSumOfWeightssum of all event weights; Bool_tfTrainWithNegWeightsyes there are negative event weights and we don't ignore them; Double_tfTransitionPointbreak-down point for gradient regression; Bool_tfUseExclusiveVarsindividual variables already used in fisher criterium are not anymore analysed individually for node splitting; Bool_tfUseFisherCutsuse multivariate splits using the Fisher criterium; UInt_tfUseNTrainEventsnumber of randomly picked training events used in randomised (and bagged) trees; UInt_tfUseNvarsthe number of variables used in the randomised tree splitting; Bool_tfUsePoissonNvarsuse ""fUseNvars"" not as fixed number but as mean of a possion distr. in each split; Bool_tfUseWeightedTreesuse average classification from the trees, or have the individual trees trees in the forest weighted (e.g. log(boostweight) from AdaBoost; Bool_tfUseYesNoLeafuse sig or bkg classification in leave nodes or sig/bkg; vector<TMVA::Event*>fValidationSamplethe ",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:25053,Modifiability,variab,variables,25053,"ts; Bool_tfTrainWithNegWeightsyes there are negative event weights and we don't ignore them; Double_tfTransitionPointbreak-down point for gradient regression; Bool_tfUseExclusiveVarsindividual variables already used in fisher criterium are not anymore analysed individually for node splitting; Bool_tfUseFisherCutsuse multivariate splits using the Fisher criterium; UInt_tfUseNTrainEventsnumber of randomly picked training events used in randomised (and bagged) trees; UInt_tfUseNvarsthe number of variables used in the randomised tree splitting; Bool_tfUsePoissonNvarsuse ""fUseNvars"" not as fixed number but as mean of a possion distr. in each split; Bool_tfUseWeightedTreesuse average classification from the trees, or have the individual trees trees in the forest weighted (e.g. log(boostweight) from AdaBoost; Bool_tfUseYesNoLeafuse sig or bkg classification in leave nodes or sig/bkg; vector<TMVA::Event*>fValidationSamplethe Validation events; vector<Double_t>fVariableImportancethe relative importance of the different variables; map<TMVA::Event*,std::pair<Double_t,Double_t> >fWeightedResidualsweighted regression residuals; static const Int_tfgDebugLeveldebug level determining some printout/control plots etc. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodBDT(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = """", TDirectory* theTargetDir = 0); the standard constructor for the ""boosted decision trees"". MethodBDT(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL). Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); BDT can handle classification with multiple classes and regression with one regression-target. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options:; nTrees number of trees in the forest to be created; BoostType the b",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:26285,Modifiability,variab,variables,26285,"Int_t numberClasses, UInt_t numberTargets); BDT can handle classification with multiple classes and regression with one regression-target. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options:; nTrees number of trees in the forest to be created; BoostType the boosting type for the trees in the forest (AdaBoost e.t.c..); known: AdaBoost; AdaBoostR2 (Adaboost for regression); Bagging; GradBoost; AdaBoostBeta the boosting parameter, beta, for AdaBoost; UseRandomisedTrees choose at each node splitting a random set of variables; UseNvars use UseNvars variables in randomised trees; UsePoission Nvars use UseNvars not as fixed number but as mean of a possion distribution; UseNTrainEvents number of training events used in randomised (and bagged) trees; SeparationType the separation criterion applied in the node splitting; known: GiniIndex; MisClassificationError; CrossEntropy; SDivSqrtSPlusB; nEventsMin: the minimum number of events in a node (leaf criteria, stop splitting); nCuts: the number of steps in the optimisation of the cut for a node (if < 0, then; step size is determined by the events); UseFisherCuts: use multivariate splits using the Fisher criterion; UseYesNoLeaf decide if the classification is done simply by the node type, or the S/B; (from the training) in the leaf node; NodePurityLimit the minimum purity to classify a node as a signal node (used in pruning and boosting to determine; misclassification error rate); UseWeightedTrees use average classification from the trees, or have the individual trees; trees in the forest weighted (e.g. log(boostweight) from AdaBoost; PruneMethod The Pruning method:; known: NoPruning // switch off pruning completely; ExpectedError; CostComplexity; PruneStrength a parameter to adjust the amount of pruning. Should be large enough such that overtraining is avoided.; PruneBeforeBoost flag to prune the tree before applying boosting algorithm; PruningValFraction number of even",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:26318,Modifiability,variab,variables,26318,"Int_t numberClasses, UInt_t numberTargets); BDT can handle classification with multiple classes and regression with one regression-target. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options:; nTrees number of trees in the forest to be created; BoostType the boosting type for the trees in the forest (AdaBoost e.t.c..); known: AdaBoost; AdaBoostR2 (Adaboost for regression); Bagging; GradBoost; AdaBoostBeta the boosting parameter, beta, for AdaBoost; UseRandomisedTrees choose at each node splitting a random set of variables; UseNvars use UseNvars variables in randomised trees; UsePoission Nvars use UseNvars not as fixed number but as mean of a possion distribution; UseNTrainEvents number of training events used in randomised (and bagged) trees; SeparationType the separation criterion applied in the node splitting; known: GiniIndex; MisClassificationError; CrossEntropy; SDivSqrtSPlusB; nEventsMin: the minimum number of events in a node (leaf criteria, stop splitting); nCuts: the number of steps in the optimisation of the cut for a node (if < 0, then; step size is determined by the events); UseFisherCuts: use multivariate splits using the Fisher criterion; UseYesNoLeaf decide if the classification is done simply by the node type, or the S/B; (from the training) in the leaf node; NodePurityLimit the minimum purity to classify a node as a signal node (used in pruning and boosting to determine; misclassification error rate); UseWeightedTrees use average classification from the trees, or have the individual trees; trees in the forest weighted (e.g. log(boostweight) from AdaBoost; PruneMethod The Pruning method:; known: NoPruning // switch off pruning completely; ExpectedError; CostComplexity; PruneStrength a parameter to adjust the amount of pruning. Should be large enough such that overtraining is avoided.; PruneBeforeBoost flag to prune the tree before applying boosting algorithm; PruningValFraction number of even",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:32146,Modifiability,adapt,adaption,32146," the testSample for the monitoring plots; during the training .. but using the testing events. Double_t AdaBoost(vector<TMVA::Event*> , TMVA::DecisionTree* dt); the AdaBoost implementation.; a new training sample is generated by weighting; events that are misclassified by the decision tree. The weight; applied is w = (1-err)/err or more general:; w = ((1-err)/err)^beta; where err is the fraction of misclassified events in the tree ( <0.5 assuming; demanding the that previous selection was better than random guessing); and ""beta"" being a free parameter (standard: beta = 1) that modifies the; boosting. Double_t Bagging(vector<TMVA::Event*> , Int_t iTree); call it boot-strapping, re-sampling or whatever you like, in the end it is nothing; else but applying ""random"" weights to each event. Double_t RegBoost(vector<TMVA::Event*> , TMVA::DecisionTree* dt); a special boosting only for Regression ...; maybe I'll implement it later... Double_t AdaBoostR2(vector<TMVA::Event*> , TMVA::DecisionTree* dt); adaption of the AdaBoost to regression problems (see H.Drucker 1997). void AddWeightsXMLTo(void* parent) const; write weights to XML. void ReadWeightsFromXML(void* parent); reads the BDT from the xml file. void ReadWeightsFromStream(istream& istr); read the weights (BDT coefficients). Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0). Double_t GetMvaValue(Double_t* err, Double_t* errUpper, UInt_t useNTrees); Return the MVA value (range [-1;1]) that classifies the; event according to the majority vote from the total number of; decision trees. Double_t PrivateGetMvaValue(TMVA::Event& ev, Double_t* err = 0, Double_t* errUpper = 0, UInt_t useNTrees = 0); Return the MVA value (range [-1;1]) that classifies the; event according to the majority vote from the total number of; decision trees. const std::vector<Float_t>& GetMulticlassValues(); get the multiclass MVA response for the BDT classifier. const std::vector<Float_t> & GetRegressionValues(); get the regression value ",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:33355,Modifiability,variab,variable,33355,"ghtsFromStream(istream& istr); read the weights (BDT coefficients). Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0). Double_t GetMvaValue(Double_t* err, Double_t* errUpper, UInt_t useNTrees); Return the MVA value (range [-1;1]) that classifies the; event according to the majority vote from the total number of; decision trees. Double_t PrivateGetMvaValue(TMVA::Event& ev, Double_t* err = 0, Double_t* errUpper = 0, UInt_t useNTrees = 0); Return the MVA value (range [-1;1]) that classifies the; event according to the majority vote from the total number of; decision trees. const std::vector<Float_t>& GetMulticlassValues(); get the multiclass MVA response for the BDT classifier. const std::vector<Float_t> & GetRegressionValues(); get the regression value generated by the BDTs. void WriteMonitoringHistosToFile( void ); Here we could write some histograms created during the processing; to the output file. vector< Double_t > GetVariableImportance(); Return the relative variable importance, normalized to all; variables together having the importance 1. The importance in; evaluated as the total separation-gain that this variable had in; the decision trees (weighted by the number of events). Double_t GetVariableImportance(UInt_t ivar); Returns the measure for the variable importance of variable ""ivar""; which is later used in GetVariableImportance() to calculate the; relative variable importances. const TMVA::Ranking* CreateRanking(); Compute ranking of input variables. void GetHelpMessage() const; Get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". void MakeClassSpecific(ostream& , const TString& ) const; make ROOT-independent C++ class for classifier response (classifier-specific implementation). void MakeClassSpecificHeader(ostream& , const TString& ) const; specific class header. void MakeClassInstantiateNode(TMVA::DecisionTreeNode* n, ostream& fout, const TString& className) const; recursiv",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:33395,Modifiability,variab,variables,33395,"ghtsFromStream(istream& istr); read the weights (BDT coefficients). Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0). Double_t GetMvaValue(Double_t* err, Double_t* errUpper, UInt_t useNTrees); Return the MVA value (range [-1;1]) that classifies the; event according to the majority vote from the total number of; decision trees. Double_t PrivateGetMvaValue(TMVA::Event& ev, Double_t* err = 0, Double_t* errUpper = 0, UInt_t useNTrees = 0); Return the MVA value (range [-1;1]) that classifies the; event according to the majority vote from the total number of; decision trees. const std::vector<Float_t>& GetMulticlassValues(); get the multiclass MVA response for the BDT classifier. const std::vector<Float_t> & GetRegressionValues(); get the regression value generated by the BDTs. void WriteMonitoringHistosToFile( void ); Here we could write some histograms created during the processing; to the output file. vector< Double_t > GetVariableImportance(); Return the relative variable importance, normalized to all; variables together having the importance 1. The importance in; evaluated as the total separation-gain that this variable had in; the decision trees (weighted by the number of events). Double_t GetVariableImportance(UInt_t ivar); Returns the measure for the variable importance of variable ""ivar""; which is later used in GetVariableImportance() to calculate the; relative variable importances. const TMVA::Ranking* CreateRanking(); Compute ranking of input variables. void GetHelpMessage() const; Get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". void MakeClassSpecific(ostream& , const TString& ) const; make ROOT-independent C++ class for classifier response (classifier-specific implementation). void MakeClassSpecificHeader(ostream& , const TString& ) const; specific class header. void MakeClassInstantiateNode(TMVA::DecisionTreeNode* n, ostream& fout, const TString& className) const; recursiv",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:33507,Modifiability,variab,variable,33507,"tMvaValue(Double_t* err, Double_t* errUpper, UInt_t useNTrees); Return the MVA value (range [-1;1]) that classifies the; event according to the majority vote from the total number of; decision trees. Double_t PrivateGetMvaValue(TMVA::Event& ev, Double_t* err = 0, Double_t* errUpper = 0, UInt_t useNTrees = 0); Return the MVA value (range [-1;1]) that classifies the; event according to the majority vote from the total number of; decision trees. const std::vector<Float_t>& GetMulticlassValues(); get the multiclass MVA response for the BDT classifier. const std::vector<Float_t> & GetRegressionValues(); get the regression value generated by the BDTs. void WriteMonitoringHistosToFile( void ); Here we could write some histograms created during the processing; to the output file. vector< Double_t > GetVariableImportance(); Return the relative variable importance, normalized to all; variables together having the importance 1. The importance in; evaluated as the total separation-gain that this variable had in; the decision trees (weighted by the number of events). Double_t GetVariableImportance(UInt_t ivar); Returns the measure for the variable importance of variable ""ivar""; which is later used in GetVariableImportance() to calculate the; relative variable importances. const TMVA::Ranking* CreateRanking(); Compute ranking of input variables. void GetHelpMessage() const; Get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". void MakeClassSpecific(ostream& , const TString& ) const; make ROOT-independent C++ class for classifier response (classifier-specific implementation). void MakeClassSpecificHeader(ostream& , const TString& ) const; specific class header. void MakeClassInstantiateNode(TMVA::DecisionTreeNode* n, ostream& fout, const TString& className) const; recursively descends a tree and writes the node instance to the output streem. const std::vector<TMVA::DecisionTree*>& GetForest() const; { return fFore",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:33652,Modifiability,variab,variable,33652,"umber of; decision trees. Double_t PrivateGetMvaValue(TMVA::Event& ev, Double_t* err = 0, Double_t* errUpper = 0, UInt_t useNTrees = 0); Return the MVA value (range [-1;1]) that classifies the; event according to the majority vote from the total number of; decision trees. const std::vector<Float_t>& GetMulticlassValues(); get the multiclass MVA response for the BDT classifier. const std::vector<Float_t> & GetRegressionValues(); get the regression value generated by the BDTs. void WriteMonitoringHistosToFile( void ); Here we could write some histograms created during the processing; to the output file. vector< Double_t > GetVariableImportance(); Return the relative variable importance, normalized to all; variables together having the importance 1. The importance in; evaluated as the total separation-gain that this variable had in; the decision trees (weighted by the number of events). Double_t GetVariableImportance(UInt_t ivar); Returns the measure for the variable importance of variable ""ivar""; which is later used in GetVariableImportance() to calculate the; relative variable importances. const TMVA::Ranking* CreateRanking(); Compute ranking of input variables. void GetHelpMessage() const; Get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". void MakeClassSpecific(ostream& , const TString& ) const; make ROOT-independent C++ class for classifier response (classifier-specific implementation). void MakeClassSpecificHeader(ostream& , const TString& ) const; specific class header. void MakeClassInstantiateNode(TMVA::DecisionTreeNode* n, ostream& fout, const TString& className) const; recursively descends a tree and writes the node instance to the output streem. const std::vector<TMVA::DecisionTree*>& GetForest() const; { return fForest; }. const std::vector<TMVA::Event*>& GetTrainingEvents() const; { return fEventSample; }. const std::vector<double>& GetBoostWeights() const; { return fBoostWeights; }. voi",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:33675,Modifiability,variab,variable,33675,"umber of; decision trees. Double_t PrivateGetMvaValue(TMVA::Event& ev, Double_t* err = 0, Double_t* errUpper = 0, UInt_t useNTrees = 0); Return the MVA value (range [-1;1]) that classifies the; event according to the majority vote from the total number of; decision trees. const std::vector<Float_t>& GetMulticlassValues(); get the multiclass MVA response for the BDT classifier. const std::vector<Float_t> & GetRegressionValues(); get the regression value generated by the BDTs. void WriteMonitoringHistosToFile( void ); Here we could write some histograms created during the processing; to the output file. vector< Double_t > GetVariableImportance(); Return the relative variable importance, normalized to all; variables together having the importance 1. The importance in; evaluated as the total separation-gain that this variable had in; the decision trees (weighted by the number of events). Double_t GetVariableImportance(UInt_t ivar); Returns the measure for the variable importance of variable ""ivar""; which is later used in GetVariableImportance() to calculate the; relative variable importances. const TMVA::Ranking* CreateRanking(); Compute ranking of input variables. void GetHelpMessage() const; Get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". void MakeClassSpecific(ostream& , const TString& ) const; make ROOT-independent C++ class for classifier response (classifier-specific implementation). void MakeClassSpecificHeader(ostream& , const TString& ) const; specific class header. void MakeClassInstantiateNode(TMVA::DecisionTreeNode* n, ostream& fout, const TString& className) const; recursively descends a tree and writes the node instance to the output streem. const std::vector<TMVA::DecisionTree*>& GetForest() const; { return fForest; }. const std::vector<TMVA::Event*>& GetTrainingEvents() const; { return fEventSample; }. const std::vector<double>& GetBoostWeights() const; { return fBoostWeights; }. voi",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:33766,Modifiability,variab,variable,33766,"umber of; decision trees. Double_t PrivateGetMvaValue(TMVA::Event& ev, Double_t* err = 0, Double_t* errUpper = 0, UInt_t useNTrees = 0); Return the MVA value (range [-1;1]) that classifies the; event according to the majority vote from the total number of; decision trees. const std::vector<Float_t>& GetMulticlassValues(); get the multiclass MVA response for the BDT classifier. const std::vector<Float_t> & GetRegressionValues(); get the regression value generated by the BDTs. void WriteMonitoringHistosToFile( void ); Here we could write some histograms created during the processing; to the output file. vector< Double_t > GetVariableImportance(); Return the relative variable importance, normalized to all; variables together having the importance 1. The importance in; evaluated as the total separation-gain that this variable had in; the decision trees (weighted by the number of events). Double_t GetVariableImportance(UInt_t ivar); Returns the measure for the variable importance of variable ""ivar""; which is later used in GetVariableImportance() to calculate the; relative variable importances. const TMVA::Ranking* CreateRanking(); Compute ranking of input variables. void GetHelpMessage() const; Get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". void MakeClassSpecific(ostream& , const TString& ) const; make ROOT-independent C++ class for classifier response (classifier-specific implementation). void MakeClassSpecificHeader(ostream& , const TString& ) const; specific class header. void MakeClassInstantiateNode(TMVA::DecisionTreeNode* n, ostream& fout, const TString& className) const; recursively descends a tree and writes the node instance to the output streem. const std::vector<TMVA::DecisionTree*>& GetForest() const; { return fForest; }. const std::vector<TMVA::Event*>& GetTrainingEvents() const; { return fEventSample; }. const std::vector<double>& GetBoostWeights() const; { return fBoostWeights; }. voi",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:33851,Modifiability,variab,variables,33851,"n the MVA value (range [-1;1]) that classifies the; event according to the majority vote from the total number of; decision trees. const std::vector<Float_t>& GetMulticlassValues(); get the multiclass MVA response for the BDT classifier. const std::vector<Float_t> & GetRegressionValues(); get the regression value generated by the BDTs. void WriteMonitoringHistosToFile( void ); Here we could write some histograms created during the processing; to the output file. vector< Double_t > GetVariableImportance(); Return the relative variable importance, normalized to all; variables together having the importance 1. The importance in; evaluated as the total separation-gain that this variable had in; the decision trees (weighted by the number of events). Double_t GetVariableImportance(UInt_t ivar); Returns the measure for the variable importance of variable ""ivar""; which is later used in GetVariableImportance() to calculate the; relative variable importances. const TMVA::Ranking* CreateRanking(); Compute ranking of input variables. void GetHelpMessage() const; Get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". void MakeClassSpecific(ostream& , const TString& ) const; make ROOT-independent C++ class for classifier response (classifier-specific implementation). void MakeClassSpecificHeader(ostream& , const TString& ) const; specific class header. void MakeClassInstantiateNode(TMVA::DecisionTreeNode* n, ostream& fout, const TString& className) const; recursively descends a tree and writes the node instance to the output streem. const std::vector<TMVA::DecisionTree*>& GetForest() const; { return fForest; }. const std::vector<TMVA::Event*>& GetTrainingEvents() const; { return fEventSample; }. const std::vector<double>& GetBoostWeights() const; { return fBoostWeights; }. void SetMaxDepth(Int_t d); {fMaxDepth = d;}. void SetNodeMinEvents(Int_t d); {fNodeMinEvents = d;}. void SetNTrees(Int_t d); {fNTrees = d;}. voi",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:15750,Performance,tune,tuneParameters,15750," d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidSetMaxDepth(Int_t d); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); voidSetNodeMinEvents(Int_t d); voidSetNodePurityLimit(Double_t l); voidSetNTrees(Int_t d); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidSetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); Double_tTestTreeQuality(TMVA::DecisionTree* dt); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virt",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:27722,Performance,optimiz,optimizing,27722,"um number of events in a node (leaf criteria, stop splitting); nCuts: the number of steps in the optimisation of the cut for a node (if < 0, then; step size is determined by the events); UseFisherCuts: use multivariate splits using the Fisher criterion; UseYesNoLeaf decide if the classification is done simply by the node type, or the S/B; (from the training) in the leaf node; NodePurityLimit the minimum purity to classify a node as a signal node (used in pruning and boosting to determine; misclassification error rate); UseWeightedTrees use average classification from the trees, or have the individual trees; trees in the forest weighted (e.g. log(boostweight) from AdaBoost; PruneMethod The Pruning method:; known: NoPruning // switch off pruning completely; ExpectedError; CostComplexity; PruneStrength a parameter to adjust the amount of pruning. Should be large enough such that overtraining is avoided.; PruneBeforeBoost flag to prune the tree before applying boosting algorithm; PruningValFraction number of events to use for optimizing pruning (only if PruneStrength < 0, i.e. automatic pruning); NegWeightTreatment IgnoreNegWeightsInTraining Ignore negative weight events in the training.; DecreaseBoostWeight Boost ev. with neg. weight with 1/boostweight instead of boostweight; PairNegWeightsGlobal Pair ev. with neg. and pos. weights in traning sample and ""annihilate"" them; PairNegWeightsInNode Randomly pair miscl. ev. with neg. and pos. weights in node and don't boost them; NNodesMax maximum number of nodes allwed in the tree splitting, then it stops.; MaxDepth maximum depth of the decision tree allowed before further splitting is stopped. void DeclareCompatibilityOptions(). void ProcessOptions(); the option string is decoded, for available options see ""DeclareOptions"". void Init( void ); common initialisation with defaults for the BDT-Method. void Reset( void ); reset the method, as if it had just been instantiated (forget all training etc.). ~MethodBDT( void ); destru",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:29485,Performance,tune,tuned,29485,"ocessOptions(); the option string is decoded, for available options see ""DeclareOptions"". void Init( void ); common initialisation with defaults for the BDT-Method. void Reset( void ); reset the method, as if it had just been instantiated (forget all training etc.). ~MethodBDT( void ); destructor. void InitEventSample( void ); Write all Events from the Tree into a vector of Events, that are; more easily manipulated. This method should never be called without; existing trainingTree, as it the vector of events from the ROOT training tree. void PreProcessNegativeEventWeights(); o.k. you know there are events with negative event weights. This routine will remove; them by pairing them with the closest event(s) of the same event class with positive; weights; A first attempt is ""brute force"", I dont' try to be clever using search trees etc,; just quick and dirty to see if the result is any good. std::map<TString,Double_t> OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); call the Optimzier with the set of paremeters and ranges that; are meant to be tuned. void SetTuneParameters(map<TString,Double_t> tuneParameters); set the tuning parameters accoding to the argument. void Train(); BDT training. void GetRandomSubSample(); fills fEventSample with fSampleFraction*NEvents random training events. Double_t GetGradBoostMVA(TMVA::Event& e, UInt_t nTrees); returns MVA value: -1 for background, 1 for signal. void UpdateTargets(vector<TMVA::Event*> , UInt_t cls = 0); Calculate residua for all events;. void UpdateTargetsRegression(vector<TMVA::Event*> , Bool_t first = kFALSE); Calculate current residuals for all events and update targets for next iteration. Double_t GetWeightedQuantile(vector<std::pair<Double_t,Double_t> > vec, const Double_t quantile, const Double_t SumOfWeights = 0.0); calculates the quantile of the distribution of the first pair entries weighted with the values in the second pair entries. Double_t GradBoost(vector<TMVA::Event*> , ",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:29537,Performance,tune,tuneParameters,29537,"Method. void Reset( void ); reset the method, as if it had just been instantiated (forget all training etc.). ~MethodBDT( void ); destructor. void InitEventSample( void ); Write all Events from the Tree into a vector of Events, that are; more easily manipulated. This method should never be called without; existing trainingTree, as it the vector of events from the ROOT training tree. void PreProcessNegativeEventWeights(); o.k. you know there are events with negative event weights. This routine will remove; them by pairing them with the closest event(s) of the same event class with positive; weights; A first attempt is ""brute force"", I dont' try to be clever using search trees etc,; just quick and dirty to see if the result is any good. std::map<TString,Double_t> OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); call the Optimzier with the set of paremeters and ranges that; are meant to be tuned. void SetTuneParameters(map<TString,Double_t> tuneParameters); set the tuning parameters accoding to the argument. void Train(); BDT training. void GetRandomSubSample(); fills fEventSample with fSampleFraction*NEvents random training events. Double_t GetGradBoostMVA(TMVA::Event& e, UInt_t nTrees); returns MVA value: -1 for background, 1 for signal. void UpdateTargets(vector<TMVA::Event*> , UInt_t cls = 0); Calculate residua for all events;. void UpdateTargetsRegression(vector<TMVA::Event*> , Bool_t first = kFALSE); Calculate current residuals for all events and update targets for next iteration. Double_t GetWeightedQuantile(vector<std::pair<Double_t,Double_t> > vec, const Double_t quantile, const Double_t SumOfWeights = 0.0); calculates the quantile of the distribution of the first pair entries weighted with the values in the second pair entries. Double_t GradBoost(vector<TMVA::Event*> , TMVA::DecisionTree* dt, UInt_t cls = 0); Calculate the desired response value for each region. Double_t GradBoostRegression(vector<TMVA::Event*> , TMVA::Dec",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:27589,Safety,avoid,avoided,27589,"in the node splitting; known: GiniIndex; MisClassificationError; CrossEntropy; SDivSqrtSPlusB; nEventsMin: the minimum number of events in a node (leaf criteria, stop splitting); nCuts: the number of steps in the optimisation of the cut for a node (if < 0, then; step size is determined by the events); UseFisherCuts: use multivariate splits using the Fisher criterion; UseYesNoLeaf decide if the classification is done simply by the node type, or the S/B; (from the training) in the leaf node; NodePurityLimit the minimum purity to classify a node as a signal node (used in pruning and boosting to determine; misclassification error rate); UseWeightedTrees use average classification from the trees, or have the individual trees; trees in the forest weighted (e.g. log(boostweight) from AdaBoost; PruneMethod The Pruning method:; known: NoPruning // switch off pruning completely; ExpectedError; CostComplexity; PruneStrength a parameter to adjust the amount of pruning. Should be large enough such that overtraining is avoided.; PruneBeforeBoost flag to prune the tree before applying boosting algorithm; PruningValFraction number of events to use for optimizing pruning (only if PruneStrength < 0, i.e. automatic pruning); NegWeightTreatment IgnoreNegWeightsInTraining Ignore negative weight events in the training.; DecreaseBoostWeight Boost ev. with neg. weight with 1/boostweight instead of boostweight; PairNegWeightsGlobal Pair ev. with neg. and pos. weights in traning sample and ""annihilate"" them; PairNegWeightsInNode Randomly pair miscl. ev. with neg. and pos. weights in node and don't boost them; NNodesMax maximum number of nodes allwed in the tree splitting, then it stops.; MaxDepth maximum depth of the decision tree allowed before further splitting is stopped. void DeclareCompatibilityOptions(). void ProcessOptions(); the option string is decoded, for available options see ""DeclareOptions"". void Init( void ); common initialisation with defaults for the BDT-Method. void Reset( ",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:21417,Security,validat,validation,21417,"values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. Double_tfAdaBoostBetabeta parameter for AdaBoost algorithm; TStringfAdaBoostR2Lossloss type used in AdaBoostR2 (Linear,Quadratic or Exponential); Bool_tfAutomaticuse user given prune strength or automatically determined one using a validation sample; Bool_tfBaggedGradBoostturn bagging in combination with grad boost on/off; TStringfBoostTypestring specifying the boost type; Double_tfBoostWeightntuple var: boost weight; vector<double>fBoostWeightsthe weights applied in the individual boosts; Bool_tfDoBoostMonitorcreate control plot with ROC integral vs tree number; Double_tfErrorFractionntuple var: misclassification error fraction; vector<TMVA::Event*>fEventSamplethe training events; Double_tfFValidationEventsfraction of events to use for pruning; vector<TMVA::DecisionTree*,allocator<TMVA::DecisionTree*> >fForestthe collection of decision trees; Int_tfITreentuple var: ith tree; Bool_tfInverseBoostNegWeightsboost ev. with neg. weights with 1/boostweight rathre than boostweight; UInt_tfMaxDepthmax depth; Double_tfMinLinCorrForFisherthe minimum linear correlation between two variables demanded for use in fisher criterium in node splitting; TTree*fMonitorNtuplemonitoring ntuple; Int_tfNCutsgrid used in cut applied in node splitting; UInt_tfNNodesMaxmax # of nodes; Int_tfNTreesnumber of decision trees requested; TStringfNegWeightTreatmentvariable that holds the option of how to treat negative event weights in training; Bool_tfNoNegWeightsInTraini",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:2784,Testability,log,log,2784,"ructed using the same mechanism as described for the root; node. The devision is stopped once a certain node has reached either a; minimum number of events, or a minimum or maximum signal purity. These; leave nodes are then called ""signal"" or ""background"" if they contain; more signal respective background events from the training sample. Boosting:. The idea behind adaptive boosting (AdaBoost) is, that signal events; from the training sample, that end up in a background node; (and vice versa) are given a larger weight than events that are in; the correct leave node. This results in a re-weighed training event; sample, with which then a new decision tree can be developed.; The boosting can be applied several times (typically 100-500 times); and one ends up with a set of decision trees (a forest).; Gradient boosting works more like a function expansion approach, where; each tree corresponds to a summand. The parameters for each summand (tree); are determined by the minimization of a error function (binomial log-; likelihood for classification and Huber loss for regression).; A greedy algorithm is used, which means, that only one tree is modified; at a time, while the other trees stay fixed. Bagging:. In this particular variant of the Boosted Decision Trees the boosting; is not done on the basis of previous training results, but by a simple; stochastic re-sampling of the initial training event sample. Random Trees:; Similar to the ""Random Forests"" from Leo Breiman and Adele Cutler, it; uses the bagging algorithm together and bases the determination of the; best node-split during the training on a random subset of variables only; which is individually chosen for each split. Analysis:. Applying an individual decision tree to a test event results in a; classification of the event as either signal or background. For the; boosted decision tree selection, an event is successively subjected to; the whole set of decision trees and depending on how often it is; classified as sign",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:3515,Testability,test,test,3515," set of decision trees (a forest).; Gradient boosting works more like a function expansion approach, where; each tree corresponds to a summand. The parameters for each summand (tree); are determined by the minimization of a error function (binomial log-; likelihood for classification and Huber loss for regression).; A greedy algorithm is used, which means, that only one tree is modified; at a time, while the other trees stay fixed. Bagging:. In this particular variant of the Boosted Decision Trees the boosting; is not done on the basis of previous training results, but by a simple; stochastic re-sampling of the initial training event sample. Random Trees:; Similar to the ""Random Forests"" from Leo Breiman and Adele Cutler, it; uses the bagging algorithm together and bases the determination of the; best node-split during the training on a random subset of variables only; which is individually chosen for each split. Analysis:. Applying an individual decision tree to a test event results in a; classification of the event as either signal or background. For the; boosted decision tree selection, an event is successively subjected to; the whole set of decision trees and depending on how often it is; classified as signal, a ""likelihood"" estimator is constructed for the; event being signal or background. The value of this estimator is the; one which is then used to select the events from an event sample, and; the cut value on this estimator defines the efficiency and purity of; the selection. Function Members (Methods); public:. virtual~MethodBDT(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; Double_tBoost(vector<TMVA::Event*>, TMVA::DecisionTree* dt, Int_t",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:15570,Testability,test,testTime,15570,"TMVA::MethodBase::SetBaseDir(TDirectory* methodDir); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidSetMaxDepth(Int_t d); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); voidSetNodeMinEvents(Int_t d); voidSetNodePurityLimit(Double_t l); voidSetNTrees(Int_t d); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidSetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); Double_tTestTreeQuality(TMVA::DecisionTree* dt); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseC",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:20244,Testability,test,testing,20244,"ts = 0.0); Double_tGradBoost(vector<TMVA::Event*>, TMVA::DecisionTree* dt, UInt_t cls = 0); Double_tGradBoostRegression(vector<TMVA::Event*>, TMVA::DecisionTree* dt); virtual voidInit(); voidInitGradBoost(vector<TMVA::Event*>); voidPreProcessNegativeEventWeights(); Double_tPrivateGetMvaValue(TMVA::Event& ev, Double_t* err = 0, Double_t* errUpper = 0, UInt_t useNTrees = 0); Double_tRegBoost(vector<TMVA::Event*>, TMVA::DecisionTree* dt); voidUpdateTargets(vector<TMVA::Event*>, UInt_t cls = 0); voidUpdateTargetsRegression(vector<TMVA::Event*>, Bool_t first = kFALSE). Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. Double_tfAdaBoostBeta",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:24809,Testability,log,log,24809,"ts; Bool_tfTrainWithNegWeightsyes there are negative event weights and we don't ignore them; Double_tfTransitionPointbreak-down point for gradient regression; Bool_tfUseExclusiveVarsindividual variables already used in fisher criterium are not anymore analysed individually for node splitting; Bool_tfUseFisherCutsuse multivariate splits using the Fisher criterium; UInt_tfUseNTrainEventsnumber of randomly picked training events used in randomised (and bagged) trees; UInt_tfUseNvarsthe number of variables used in the randomised tree splitting; Bool_tfUsePoissonNvarsuse ""fUseNvars"" not as fixed number but as mean of a possion distr. in each split; Bool_tfUseWeightedTreesuse average classification from the trees, or have the individual trees trees in the forest weighted (e.g. log(boostweight) from AdaBoost; Bool_tfUseYesNoLeafuse sig or bkg classification in leave nodes or sig/bkg; vector<TMVA::Event*>fValidationSamplethe Validation events; vector<Double_t>fVariableImportancethe relative importance of the different variables; map<TMVA::Event*,std::pair<Double_t,Double_t> >fWeightedResidualsweighted regression residuals; static const Int_tfgDebugLeveldebug level determining some printout/control plots etc. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodBDT(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = """", TDirectory* theTargetDir = 0); the standard constructor for the ""boosted decision trees"". MethodBDT(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL). Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); BDT can handle classification with multiple classes and regression with one regression-target. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options:; nTrees number of trees in the forest to be created; BoostType the b",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:27334,Testability,log,log,27334,"n; UseNTrainEvents number of training events used in randomised (and bagged) trees; SeparationType the separation criterion applied in the node splitting; known: GiniIndex; MisClassificationError; CrossEntropy; SDivSqrtSPlusB; nEventsMin: the minimum number of events in a node (leaf criteria, stop splitting); nCuts: the number of steps in the optimisation of the cut for a node (if < 0, then; step size is determined by the events); UseFisherCuts: use multivariate splits using the Fisher criterion; UseYesNoLeaf decide if the classification is done simply by the node type, or the S/B; (from the training) in the leaf node; NodePurityLimit the minimum purity to classify a node as a signal node (used in pruning and boosting to determine; misclassification error rate); UseWeightedTrees use average classification from the trees, or have the individual trees; trees in the forest weighted (e.g. log(boostweight) from AdaBoost; PruneMethod The Pruning method:; known: NoPruning // switch off pruning completely; ExpectedError; CostComplexity; PruneStrength a parameter to adjust the amount of pruning. Should be large enough such that overtraining is avoided.; PruneBeforeBoost flag to prune the tree before applying boosting algorithm; PruningValFraction number of events to use for optimizing pruning (only if PruneStrength < 0, i.e. automatic pruning); NegWeightTreatment IgnoreNegWeightsInTraining Ignore negative weight events in the training.; DecreaseBoostWeight Boost ev. with neg. weight with 1/boostweight instead of boostweight; PairNegWeightsGlobal Pair ev. with neg. and pos. weights in traning sample and ""annihilate"" them; PairNegWeightsInNode Randomly pair miscl. ev. with neg. and pos. weights in node and don't boost them; NNodesMax maximum number of nodes allwed in the tree splitting, then it stops.; MaxDepth maximum depth of the decision tree allowed before further splitting is stopped. void DeclareCompatibilityOptions(). void ProcessOptions(); the option string is decoded,",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:30780,Testability,test,test,30780,"vent& e, UInt_t nTrees); returns MVA value: -1 for background, 1 for signal. void UpdateTargets(vector<TMVA::Event*> , UInt_t cls = 0); Calculate residua for all events;. void UpdateTargetsRegression(vector<TMVA::Event*> , Bool_t first = kFALSE); Calculate current residuals for all events and update targets for next iteration. Double_t GetWeightedQuantile(vector<std::pair<Double_t,Double_t> > vec, const Double_t quantile, const Double_t SumOfWeights = 0.0); calculates the quantile of the distribution of the first pair entries weighted with the values in the second pair entries. Double_t GradBoost(vector<TMVA::Event*> , TMVA::DecisionTree* dt, UInt_t cls = 0); Calculate the desired response value for each region. Double_t GradBoostRegression(vector<TMVA::Event*> , TMVA::DecisionTree* dt); Implementation of M_TreeBoost using a Huber loss function as desribed by Friedman 1999. void InitGradBoost(vector<TMVA::Event*> ); initialize targets for first tree. Double_t TestTreeQuality(TMVA::DecisionTree* dt); test the tree quality.. in terms of Miscalssification. Double_t Boost(vector<TMVA::Event*> , TMVA::DecisionTree* dt, Int_t iTree, UInt_t cls = 0); apply the boosting alogrithim (the algorithm is selecte via the the ""option"" given; in the constructor. The return value is the boosting weight. void BoostMonitor(Int_t iTree); fills the ROCIntegral vs Itree from the testSample for the monitoring plots; during the training .. but using the testing events. Double_t AdaBoost(vector<TMVA::Event*> , TMVA::DecisionTree* dt); the AdaBoost implementation.; a new training sample is generated by weighting; events that are misclassified by the decision tree. The weight; applied is w = (1-err)/err or more general:; w = ((1-err)/err)^beta; where err is the fraction of misclassified events in the tree ( <0.5 assuming; demanding the that previous selection was better than random guessing); and ""beta"" being a free parameter (standard: beta = 1) that modifies the; boosting. Double_t Bagging(ve",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:31144,Testability,test,testSample,31144,"air<Double_t,Double_t> > vec, const Double_t quantile, const Double_t SumOfWeights = 0.0); calculates the quantile of the distribution of the first pair entries weighted with the values in the second pair entries. Double_t GradBoost(vector<TMVA::Event*> , TMVA::DecisionTree* dt, UInt_t cls = 0); Calculate the desired response value for each region. Double_t GradBoostRegression(vector<TMVA::Event*> , TMVA::DecisionTree* dt); Implementation of M_TreeBoost using a Huber loss function as desribed by Friedman 1999. void InitGradBoost(vector<TMVA::Event*> ); initialize targets for first tree. Double_t TestTreeQuality(TMVA::DecisionTree* dt); test the tree quality.. in terms of Miscalssification. Double_t Boost(vector<TMVA::Event*> , TMVA::DecisionTree* dt, Int_t iTree, UInt_t cls = 0); apply the boosting alogrithim (the algorithm is selecte via the the ""option"" given; in the constructor. The return value is the boosting weight. void BoostMonitor(Int_t iTree); fills the ROCIntegral vs Itree from the testSample for the monitoring plots; during the training .. but using the testing events. Double_t AdaBoost(vector<TMVA::Event*> , TMVA::DecisionTree* dt); the AdaBoost implementation.; a new training sample is generated by weighting; events that are misclassified by the decision tree. The weight; applied is w = (1-err)/err or more general:; w = ((1-err)/err)^beta; where err is the fraction of misclassified events in the tree ( <0.5 assuming; demanding the that previous selection was better than random guessing); and ""beta"" being a free parameter (standard: beta = 1) that modifies the; boosting. Double_t Bagging(vector<TMVA::Event*> , Int_t iTree); call it boot-strapping, re-sampling or whatever you like, in the end it is nothing; else but applying ""random"" weights to each event. Double_t RegBoost(vector<TMVA::Event*> , TMVA::DecisionTree* dt); a special boosting only for Regression ...; maybe I'll implement it later... Double_t AdaBoostR2(vector<TMVA::Event*> , TMVA::DecisionTr",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:31218,Testability,test,testing,31218," = 0.0); calculates the quantile of the distribution of the first pair entries weighted with the values in the second pair entries. Double_t GradBoost(vector<TMVA::Event*> , TMVA::DecisionTree* dt, UInt_t cls = 0); Calculate the desired response value for each region. Double_t GradBoostRegression(vector<TMVA::Event*> , TMVA::DecisionTree* dt); Implementation of M_TreeBoost using a Huber loss function as desribed by Friedman 1999. void InitGradBoost(vector<TMVA::Event*> ); initialize targets for first tree. Double_t TestTreeQuality(TMVA::DecisionTree* dt); test the tree quality.. in terms of Miscalssification. Double_t Boost(vector<TMVA::Event*> , TMVA::DecisionTree* dt, Int_t iTree, UInt_t cls = 0); apply the boosting alogrithim (the algorithm is selecte via the the ""option"" given; in the constructor. The return value is the boosting weight. void BoostMonitor(Int_t iTree); fills the ROCIntegral vs Itree from the testSample for the monitoring plots; during the training .. but using the testing events. Double_t AdaBoost(vector<TMVA::Event*> , TMVA::DecisionTree* dt); the AdaBoost implementation.; a new training sample is generated by weighting; events that are misclassified by the decision tree. The weight; applied is w = (1-err)/err or more general:; w = ((1-err)/err)^beta; where err is the fraction of misclassified events in the tree ( <0.5 assuming; demanding the that previous selection was better than random guessing); and ""beta"" being a free parameter (standard: beta = 1) that modifies the; boosting. Double_t Bagging(vector<TMVA::Event*> , Int_t iTree); call it boot-strapping, re-sampling or whatever you like, in the end it is nothing; else but applying ""random"" weights to each event. Double_t RegBoost(vector<TMVA::Event*> , TMVA::DecisionTree* dt); a special boosting only for Regression ...; maybe I'll implement it later... Double_t AdaBoostR2(vector<TMVA::Event*> , TMVA::DecisionTree* dt); adaption of the AdaBoost to regression problems (see H.Drucker 1997). vo",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:3116,Usability,simpl,simple,3116," the training sample. Boosting:. The idea behind adaptive boosting (AdaBoost) is, that signal events; from the training sample, that end up in a background node; (and vice versa) are given a larger weight than events that are in; the correct leave node. This results in a re-weighed training event; sample, with which then a new decision tree can be developed.; The boosting can be applied several times (typically 100-500 times); and one ends up with a set of decision trees (a forest).; Gradient boosting works more like a function expansion approach, where; each tree corresponds to a summand. The parameters for each summand (tree); are determined by the minimization of a error function (binomial log-; likelihood for classification and Huber loss for regression).; A greedy algorithm is used, which means, that only one tree is modified; at a time, while the other trees stay fixed. Bagging:. In this particular variant of the Boosted Decision Trees the boosting; is not done on the basis of previous training results, but by a simple; stochastic re-sampling of the initial training event sample. Random Trees:; Similar to the ""Random Forests"" from Leo Breiman and Adele Cutler, it; uses the bagging algorithm together and bases the determination of the; best node-split during the training on a random subset of variables only; which is individually chosen for each split. Analysis:. Applying an individual decision tree to a test event results in a; classification of the event as either signal or background. For the; boosted decision tree selection, an event is successively subjected to; the whole set of decision trees and depending on how often it is; classified as signal, a ""likelihood"" estimator is constructed for the; event being signal or background. The value of this estimator is the; one which is then used to select the events from an event sample, and; the cut value on this estimator defines the efficiency and purity of; the selection. Function Members (Methods); public:. v",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:26988,Usability,simpl,simply,26988,"Int_t numberClasses, UInt_t numberTargets); BDT can handle classification with multiple classes and regression with one regression-target. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options:; nTrees number of trees in the forest to be created; BoostType the boosting type for the trees in the forest (AdaBoost e.t.c..); known: AdaBoost; AdaBoostR2 (Adaboost for regression); Bagging; GradBoost; AdaBoostBeta the boosting parameter, beta, for AdaBoost; UseRandomisedTrees choose at each node splitting a random set of variables; UseNvars use UseNvars variables in randomised trees; UsePoission Nvars use UseNvars not as fixed number but as mean of a possion distribution; UseNTrainEvents number of training events used in randomised (and bagged) trees; SeparationType the separation criterion applied in the node splitting; known: GiniIndex; MisClassificationError; CrossEntropy; SDivSqrtSPlusB; nEventsMin: the minimum number of events in a node (leaf criteria, stop splitting); nCuts: the number of steps in the optimisation of the cut for a node (if < 0, then; step size is determined by the events); UseFisherCuts: use multivariate splits using the Fisher criterion; UseYesNoLeaf decide if the classification is done simply by the node type, or the S/B; (from the training) in the leaf node; NodePurityLimit the minimum purity to classify a node as a signal node (used in pruning and boosting to determine; misclassification error rate); UseWeightedTrees use average classification from the trees, or have the individual trees; trees in the forest weighted (e.g. log(boostweight) from AdaBoost; PruneMethod The Pruning method:; known: NoPruning // switch off pruning completely; ExpectedError; CostComplexity; PruneStrength a parameter to adjust the amount of pruning. Should be large enough such that overtraining is avoided.; PruneBeforeBoost flag to prune the tree before applying boosting algorithm; PruningValFraction number of even",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBoost.html:2436,Availability,error,error,2436,"t::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; Int_tGetBoostNum(); TMVA::Types::EBoostStageGetBoostStage(); const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; TMVA::IMethod*TMVA::MethodCompositeBase::GetCurrentMethod(); virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Even",MatchSource.WIKI,root/html532/TMVA__MethodBoost.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBoost.html
https://root.cern/root/html532/TMVA__MethodBoost.html:2520,Availability,error,error,2520,"able(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; Int_tGetBoostNum(); TMVA::Types::EBoostStageGetBoostStage(); const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; TMVA::IMethod*TMVA::MethodCompositeBase::GetCurrentMethod(); virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt) const; const TMVA::Event*TMVA::MethodBas",MatchSource.WIKI,root/html532/TMVA__MethodBoost.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBoost.html
https://root.cern/root/html532/TMVA__MethodBoost.html:18255,Availability,error,error,18255,"ived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. Double_tfADABoostBetaADA boost parameter, default is 1 ; vector<TH1*>fBTrainBgdMVAHist; vector<TH1*>fBTrainSigMVAHist; Int_tfBoostNumNumber of times the classifier is boosted; TMVA::Types::EBoostStagefBoostStagestage of the boosting ; TStringfBoostTypestring specifying the boost type ; Double_tfBoostWeightthe weight used to boost the next classifier ; TStringfBoostedMethodNamedetails of the boosted classifier; TStringfBoostedMethodOptionsoptions; TStringfBoostedMethodTitletitle ; TMVA::DataSetManager*fDataSetManagerDSMTEST; Int_tfDefaultHistNumnumber of histogram filled for every type of boosted classifier ; Bool_tfDetailedMonitoringproduce detailed monitoring histograms (boost-wise); vector<Float_t>*fMVAvaluesmva values for the last trained method; Double_tfMethodErrorestimation of the level error of the classifier ; TStringfMethodWeightTypestring specifying the boost type; Bool_tfMonitorBoostedMethodmonitor the MVA response of every classifier; vector<TH1*>*fMonitorHisthistograms to monitor values during the boosting ; TTree*fMonitorTreetree to monitor values during the boosting ; Double_tfOrigMethodErrorestimation of the level error of the classifier ; Double_tfOverlap_integral; Double_tfROC_trainingroc integral of last trained method (on training sample); UInt_tfRandomSeedseed for random number generator used for bagging; Bool_tfRecalculateMVACutwhether to recalculate the MVA cut at every boosting step ; vector<TH1*>fTestBgdMVAHist; vector<TH1*>fTestSigMVAHist; vector<TH1*>fTrainBgdMVAHist; vector<TH1*>fTrainSigMVAHist; TStringfTransformStringmin and max values for the classifier response . Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodBoost(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const",MatchSource.WIKI,root/html532/TMVA__MethodBoost.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBoost.html
https://root.cern/root/html532/TMVA__MethodBoost.html:18599,Availability,error,error,18599,"ived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. Double_tfADABoostBetaADA boost parameter, default is 1 ; vector<TH1*>fBTrainBgdMVAHist; vector<TH1*>fBTrainSigMVAHist; Int_tfBoostNumNumber of times the classifier is boosted; TMVA::Types::EBoostStagefBoostStagestage of the boosting ; TStringfBoostTypestring specifying the boost type ; Double_tfBoostWeightthe weight used to boost the next classifier ; TStringfBoostedMethodNamedetails of the boosted classifier; TStringfBoostedMethodOptionsoptions; TStringfBoostedMethodTitletitle ; TMVA::DataSetManager*fDataSetManagerDSMTEST; Int_tfDefaultHistNumnumber of histogram filled for every type of boosted classifier ; Bool_tfDetailedMonitoringproduce detailed monitoring histograms (boost-wise); vector<Float_t>*fMVAvaluesmva values for the last trained method; Double_tfMethodErrorestimation of the level error of the classifier ; TStringfMethodWeightTypestring specifying the boost type; Bool_tfMonitorBoostedMethodmonitor the MVA response of every classifier; vector<TH1*>*fMonitorHisthistograms to monitor values during the boosting ; TTree*fMonitorTreetree to monitor values during the boosting ; Double_tfOrigMethodErrorestimation of the level error of the classifier ; Double_tfOverlap_integral; Double_tfROC_trainingroc integral of last trained method (on training sample); UInt_tfRandomSeedseed for random number generator used for bagging; Bool_tfRecalculateMVACutwhether to recalculate the MVA cut at every boosting step ; vector<TH1*>fTestBgdMVAHist; vector<TH1*>fTestSigMVAHist; vector<TH1*>fTrainBgdMVAHist; vector<TH1*>fTrainSigMVAHist; TStringfTransformStringmin and max values for the classifier response . Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodBoost(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const",MatchSource.WIKI,root/html532/TMVA__MethodBoost.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBoost.html
https://root.cern/root/html532/TMVA__MethodBoost.html:18109,Energy Efficiency,monitor,monitoring,18109,"ived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. Double_tfADABoostBetaADA boost parameter, default is 1 ; vector<TH1*>fBTrainBgdMVAHist; vector<TH1*>fBTrainSigMVAHist; Int_tfBoostNumNumber of times the classifier is boosted; TMVA::Types::EBoostStagefBoostStagestage of the boosting ; TStringfBoostTypestring specifying the boost type ; Double_tfBoostWeightthe weight used to boost the next classifier ; TStringfBoostedMethodNamedetails of the boosted classifier; TStringfBoostedMethodOptionsoptions; TStringfBoostedMethodTitletitle ; TMVA::DataSetManager*fDataSetManagerDSMTEST; Int_tfDefaultHistNumnumber of histogram filled for every type of boosted classifier ; Bool_tfDetailedMonitoringproduce detailed monitoring histograms (boost-wise); vector<Float_t>*fMVAvaluesmva values for the last trained method; Double_tfMethodErrorestimation of the level error of the classifier ; TStringfMethodWeightTypestring specifying the boost type; Bool_tfMonitorBoostedMethodmonitor the MVA response of every classifier; vector<TH1*>*fMonitorHisthistograms to monitor values during the boosting ; TTree*fMonitorTreetree to monitor values during the boosting ; Double_tfOrigMethodErrorestimation of the level error of the classifier ; Double_tfOverlap_integral; Double_tfROC_trainingroc integral of last trained method (on training sample); UInt_tfRandomSeedseed for random number generator used for bagging; Bool_tfRecalculateMVACutwhether to recalculate the MVA cut at every boosting step ; vector<TH1*>fTestBgdMVAHist; vector<TH1*>fTestSigMVAHist; vector<TH1*>fTrainBgdMVAHist; vector<TH1*>fTrainSigMVAHist; TStringfTransformStringmin and max values for the classifier response . Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodBoost(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const",MatchSource.WIKI,root/html532/TMVA__MethodBoost.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBoost.html
https://root.cern/root/html532/TMVA__MethodBoost.html:18451,Energy Efficiency,monitor,monitor,18451,"ived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. Double_tfADABoostBetaADA boost parameter, default is 1 ; vector<TH1*>fBTrainBgdMVAHist; vector<TH1*>fBTrainSigMVAHist; Int_tfBoostNumNumber of times the classifier is boosted; TMVA::Types::EBoostStagefBoostStagestage of the boosting ; TStringfBoostTypestring specifying the boost type ; Double_tfBoostWeightthe weight used to boost the next classifier ; TStringfBoostedMethodNamedetails of the boosted classifier; TStringfBoostedMethodOptionsoptions; TStringfBoostedMethodTitletitle ; TMVA::DataSetManager*fDataSetManagerDSMTEST; Int_tfDefaultHistNumnumber of histogram filled for every type of boosted classifier ; Bool_tfDetailedMonitoringproduce detailed monitoring histograms (boost-wise); vector<Float_t>*fMVAvaluesmva values for the last trained method; Double_tfMethodErrorestimation of the level error of the classifier ; TStringfMethodWeightTypestring specifying the boost type; Bool_tfMonitorBoostedMethodmonitor the MVA response of every classifier; vector<TH1*>*fMonitorHisthistograms to monitor values during the boosting ; TTree*fMonitorTreetree to monitor values during the boosting ; Double_tfOrigMethodErrorestimation of the level error of the classifier ; Double_tfOverlap_integral; Double_tfROC_trainingroc integral of last trained method (on training sample); UInt_tfRandomSeedseed for random number generator used for bagging; Bool_tfRecalculateMVACutwhether to recalculate the MVA cut at every boosting step ; vector<TH1*>fTestBgdMVAHist; vector<TH1*>fTestSigMVAHist; vector<TH1*>fTrainBgdMVAHist; vector<TH1*>fTrainSigMVAHist; TStringfTransformStringmin and max values for the classifier response . Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodBoost(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const",MatchSource.WIKI,root/html532/TMVA__MethodBoost.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBoost.html
https://root.cern/root/html532/TMVA__MethodBoost.html:18514,Energy Efficiency,monitor,monitor,18514,"ived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. Double_tfADABoostBetaADA boost parameter, default is 1 ; vector<TH1*>fBTrainBgdMVAHist; vector<TH1*>fBTrainSigMVAHist; Int_tfBoostNumNumber of times the classifier is boosted; TMVA::Types::EBoostStagefBoostStagestage of the boosting ; TStringfBoostTypestring specifying the boost type ; Double_tfBoostWeightthe weight used to boost the next classifier ; TStringfBoostedMethodNamedetails of the boosted classifier; TStringfBoostedMethodOptionsoptions; TStringfBoostedMethodTitletitle ; TMVA::DataSetManager*fDataSetManagerDSMTEST; Int_tfDefaultHistNumnumber of histogram filled for every type of boosted classifier ; Bool_tfDetailedMonitoringproduce detailed monitoring histograms (boost-wise); vector<Float_t>*fMVAvaluesmva values for the last trained method; Double_tfMethodErrorestimation of the level error of the classifier ; TStringfMethodWeightTypestring specifying the boost type; Bool_tfMonitorBoostedMethodmonitor the MVA response of every classifier; vector<TH1*>*fMonitorHisthistograms to monitor values during the boosting ; TTree*fMonitorTreetree to monitor values during the boosting ; Double_tfOrigMethodErrorestimation of the level error of the classifier ; Double_tfOverlap_integral; Double_tfROC_trainingroc integral of last trained method (on training sample); UInt_tfRandomSeedseed for random number generator used for bagging; Bool_tfRecalculateMVACutwhether to recalculate the MVA cut at every boosting step ; vector<TH1*>fTestBgdMVAHist; vector<TH1*>fTestSigMVAHist; vector<TH1*>fTrainBgdMVAHist; vector<TH1*>fTrainSigMVAHist; TStringfTransformStringmin and max values for the classifier response . Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodBoost(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const",MatchSource.WIKI,root/html532/TMVA__MethodBoost.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBoost.html
https://root.cern/root/html532/TMVA__MethodBoost.html:21808,Energy Efficiency,monitor,monitoring,21808,"uble_t* err = 0, Double_t* errUpper = 0); return boosted MVA response. Double_t GetBoostROCIntegral(Bool_t , TMVA::Types::ETreeType , Bool_t CalcOverlapIntergral = kFALSE); Calculate the ROC integral of a single classifier or even the; whole boosted classifier. The tree type (training or testing; sample) is specified by 'eTT'. If tree type kTraining is set, the original training sample is; used to compute the ROC integral (original weights). - singleMethod - if kTRUE, return ROC integral of single (last; trained) classifier; if kFALSE, return ROC; integral of full classifier. - eTT - tree type (Types::kTraining / Types::kTesting). - CalcOverlapIntergral - if kTRUE, the overlap integral of the; signal/background MVA distributions; is calculated and stored in; 'fOverlap_integral'. void CalcMVAValues(); Calculate MVA values of current method fMethods.back() on; training sample. void SetBoostedMethodName(TString methodName); { fBoostedMethodName = methodName; }. Int_t GetBoostNum(); { return fBoostNum; }. TH1* GetMonitoringHist(Int_t histInd); gives the monitoring historgram from the vector according to index of the; histrogram added in the MonitorBoost function. { return (*fMonitorHist)[fDefaultHistNum+histInd]; }. void AddMonitoringHist(TH1* hist); { return fMonitorHist->push_back(hist); }. Types::EBoostStage GetBoostStage(); { return fBoostStage; }. void ClearAll(); clean up. void PrintResults(const TString& , vector<Double_t>& , const Double_t ) const; print fit results. MethodBoost* SetStage(TMVA::Types::EBoostStage stage); { fBoostStage = stage; return this; }. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss, Or Cohen, Jan Therhaag, Eckhard von Toerne » Copyright (c) 2005-2011: *; » Last changed: root/tmva $Id: MethodBoost.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__MethodBoost.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBoost.html
https://root.cern/root/html532/TMVA__MethodBoost.html:19870,Integrability,rout,routine,19870,"t at every boosting step ; vector<TH1*>fTestBgdMVAHist; vector<TH1*>fTestSigMVAHist; vector<TH1*>fTrainBgdMVAHist; vector<TH1*>fTrainSigMVAHist; TStringfTransformStringmin and max values for the classifier response . Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodBoost(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = """", TDirectory* theTargetDir = NULL). MethodBoost(TMVA::DataSetInfo& dsi, const TString& theWeightFile, TDirectory* theTargetDir = NULL). ~MethodBoost( void ); destructor. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t ); Boost can handle classification with 2 classes and regression with one regression-target. void DeclareOptions(). Bool_t BookMethod(TMVA::Types::EMVA theMethod, TString methodTitle, TString theOption); just registering the string from which the boosted classifier will be created. void Init(). void InitHistos(); initialisation routine. void CheckSetup(). void Train(). void CleanBoostOptions(). void CreateMVAHistorgrams(). void ResetBoostWeights(); resetting back the boosted weights of the events to 1. void WriteMonitoringHistosToFile( void ). void TestClassification(). void WriteEvaluationHistosToFile(TMVA::Types::ETreeType treetype). void ProcessOptions(); process user options. void SingleTrain(); initialization. void FindMVACut(); find the CUT on the individual MVA that defines an event as; correct or misclassified (to be used in the boosting process). void SingleBoost(). void CalcMethodWeight(); Calculate weight of single method.; This is no longer done in SingleBoost();. void GetHelpMessage() const; Get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". const TMVA::Ranking* CreateRanking(). Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); return boosted MVA response. Double_t GetBoostROCIntegral(Bool_t , TMVA::",MatchSource.WIKI,root/html532/TMVA__MethodBoost.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBoost.html
https://root.cern/root/html532/TMVA__MethodBoost.html:20569,Integrability,message,message,20569,"dle classification with 2 classes and regression with one regression-target. void DeclareOptions(). Bool_t BookMethod(TMVA::Types::EMVA theMethod, TString methodTitle, TString theOption); just registering the string from which the boosted classifier will be created. void Init(). void InitHistos(); initialisation routine. void CheckSetup(). void Train(). void CleanBoostOptions(). void CreateMVAHistorgrams(). void ResetBoostWeights(); resetting back the boosted weights of the events to 1. void WriteMonitoringHistosToFile( void ). void TestClassification(). void WriteEvaluationHistosToFile(TMVA::Types::ETreeType treetype). void ProcessOptions(); process user options. void SingleTrain(); initialization. void FindMVACut(); find the CUT on the individual MVA that defines an event as; correct or misclassified (to be used in the boosting process). void SingleBoost(). void CalcMethodWeight(); Calculate weight of single method.; This is no longer done in SingleBoost();. void GetHelpMessage() const; Get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". const TMVA::Ranking* CreateRanking(). Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); return boosted MVA response. Double_t GetBoostROCIntegral(Bool_t , TMVA::Types::ETreeType , Bool_t CalcOverlapIntergral = kFALSE); Calculate the ROC integral of a single classifier or even the; whole boosted classifier. The tree type (training or testing; sample) is specified by 'eTT'. If tree type kTraining is set, the original training sample is; used to compute the ROC integral (original weights). - singleMethod - if kTRUE, return ROC integral of single (last; trained) classifier; if kFALSE, return ROC; integral of full classifier. - eTT - tree type (Types::kTraining / Types::kTesting). - CalcOverlapIntergral - if kTRUE, the overlap integral of the; signal/background MVA distributions; is calculated and stored in; 'fOverlap_integral'. void CalcMVAValues(); Ca",MatchSource.WIKI,root/html532/TMVA__MethodBoost.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBoost.html
https://root.cern/root/html532/TMVA__MethodBoost.html:16638,Modifiability,variab,variables,16638,"ileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; Int_tTMVA::MethodCompositeBase::fMethodIndex; vector<Double_t>TMVA::MethodCompositeBase::fMethodWeight; vector<IMethod*>TMVA::MethodCompositeBase::fMethodsvector of all classifiers; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. Double_tfADABoostBetaADA boost parameter, default is 1 ; vector<TH1*>fBTrainBgdMVAHist; vector<TH1*>fBTrainSigMVAHist; Int_tfBoostNumNumber of times the classifier is boosted; TMVA::Types::EBoostStagefBoostStagestage of the boosting ; TStringfBoostTypestring specifying the boost type ; Double_tfBoostWeightthe weight used to boost the next classifier ; TStringfBoostedMethodNamedetails of the boosted classifier; TStringfBoostedMethodOptionsoptions; TStringfBoos",MatchSource.WIKI,root/html532/TMVA__MethodBoost.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBoost.html
https://root.cern/root/html532/TMVA__MethodBoost.html:17009,Modifiability,variab,variable,17009,"ileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; Int_tTMVA::MethodCompositeBase::fMethodIndex; vector<Double_t>TMVA::MethodCompositeBase::fMethodWeight; vector<IMethod*>TMVA::MethodCompositeBase::fMethodsvector of all classifiers; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. Double_tfADABoostBetaADA boost parameter, default is 1 ; vector<TH1*>fBTrainBgdMVAHist; vector<TH1*>fBTrainSigMVAHist; Int_tfBoostNumNumber of times the classifier is boosted; TMVA::Types::EBoostStagefBoostStagestage of the boosting ; TStringfBoostTypestring specifying the boost type ; Double_tfBoostWeightthe weight used to boost the next classifier ; TStringfBoostedMethodNamedetails of the boosted classifier; TStringfBoostedMethodOptionsoptions; TStringfBoos",MatchSource.WIKI,root/html532/TMVA__MethodBoost.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBoost.html
https://root.cern/root/html532/TMVA__MethodBoost.html:512,Performance,perform,performed,512,". TMVA::MethodBoost. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodBoost. class TMVA::MethodBoost: public TMVA::MethodCompositeBase. This class is meant to boost a single classifier. Boosting means; training the classifier a few times. Everytime the wieghts of the; events are modified according to how well the classifier performed; on the test sample. Function Members (Methods); public:. virtual~MethodBoost(); voidTObject::AbstractMethod(const char* method) const; voidAddMonitoringHist(TH1* hist); voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidTMVA::MethodCompositeBase::AddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; Bool_tBookMethod(TMVA::Types::EMVA theMethod, TString methodTitle, TString theOption); virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; voidCleanBoostOptions(); virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::",MatchSource.WIKI,root/html532/TMVA__MethodBoost.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBoost.html
https://root.cern/root/html532/TMVA__MethodBoost.html:12124,Performance,tune,tuneParameters,12124,"dSetBoostedMethodName(TString methodName); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidTMVA::C",MatchSource.WIKI,root/html532/TMVA__MethodBoost.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBoost.html
https://root.cern/root/html532/TMVA__MethodBoost.html:530,Testability,test,test,530,". TMVA::MethodBoost. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodBoost. class TMVA::MethodBoost: public TMVA::MethodCompositeBase. This class is meant to boost a single classifier. Boosting means; training the classifier a few times. Everytime the wieghts of the; events are modified according to how well the classifier performed; on the test sample. Function Members (Methods); public:. virtual~MethodBoost(); voidTObject::AbstractMethod(const char* method) const; voidAddMonitoringHist(TH1* hist); voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidTMVA::MethodCompositeBase::AddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; Bool_tBookMethod(TMVA::Types::EMVA theMethod, TString methodTitle, TString theOption); virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; voidCleanBoostOptions(); virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::",MatchSource.WIKI,root/html532/TMVA__MethodBoost.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBoost.html
https://root.cern/root/html532/TMVA__MethodBoost.html:11926,Testability,test,testTime,11926,"MVA::MethodBase::SetAnalysisType(TMVA::Types::EAnalysisType type); voidTMVA::MethodBase::SetBaseDir(TDirectory* methodDir); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidSetBoostedMethodName(TString methodName); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt)",MatchSource.WIKI,root/html532/TMVA__MethodBoost.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBoost.html
https://root.cern/root/html532/TMVA__MethodBoost.html:16328,Testability,test,testing,16328," virtual voidDeclareOptions(); voidFindMVACut(); Double_tGetBoostROCIntegral(Bool_t, TMVA::Types::ETreeType, Bool_t CalcOverlapIntergral = kFALSE); virtual voidInit(); voidInitHistos(); voidPrintResults(const TString&, vector<Double_t>&, const Double_t) const; virtual voidProcessOptions(); voidResetBoostWeights(); TMVA::MethodBoost*SetStage(TMVA::Types::EBoostStage stage); voidSingleBoost(); voidSingleTrain(); virtual voidTestClassification(); virtual voidWriteEvaluationHistosToFile(TMVA::Types::ETreeType treetype); virtual voidWriteMonitoringHistosToFile() const. Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; Int_tTMVA::MethodCompositeBase::fMethodIndex; vector<Double_t>TMVA::MethodCompositeBase::fMethodWeight; vector<IMethod*>TMVA::MethodCompositeBase::fMethodsvector of all classifiers; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Flo",MatchSource.WIKI,root/html532/TMVA__MethodBoost.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBoost.html
https://root.cern/root/html532/TMVA__MethodBoost.html:21031,Testability,test,testing,21031,"vents to 1. void WriteMonitoringHistosToFile( void ). void TestClassification(). void WriteEvaluationHistosToFile(TMVA::Types::ETreeType treetype). void ProcessOptions(); process user options. void SingleTrain(); initialization. void FindMVACut(); find the CUT on the individual MVA that defines an event as; correct or misclassified (to be used in the boosting process). void SingleBoost(). void CalcMethodWeight(); Calculate weight of single method.; This is no longer done in SingleBoost();. void GetHelpMessage() const; Get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". const TMVA::Ranking* CreateRanking(). Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); return boosted MVA response. Double_t GetBoostROCIntegral(Bool_t , TMVA::Types::ETreeType , Bool_t CalcOverlapIntergral = kFALSE); Calculate the ROC integral of a single classifier or even the; whole boosted classifier. The tree type (training or testing; sample) is specified by 'eTT'. If tree type kTraining is set, the original training sample is; used to compute the ROC integral (original weights). - singleMethod - if kTRUE, return ROC integral of single (last; trained) classifier; if kFALSE, return ROC; integral of full classifier. - eTT - tree type (Types::kTraining / Types::kTesting). - CalcOverlapIntergral - if kTRUE, the overlap integral of the; signal/background MVA distributions; is calculated and stored in; 'fOverlap_integral'. void CalcMVAValues(); Calculate MVA values of current method fMethods.back() on; training sample. void SetBoostedMethodName(TString methodName); { fBoostedMethodName = methodName; }. Int_t GetBoostNum(); { return fBoostNum; }. TH1* GetMonitoringHist(Int_t histInd); gives the monitoring historgram from the vector according to index of the; histrogram added in the MonitorBoost function. { return (*fMonitorHist)[fDefaultHistNum+histInd]; }. void AddMonitoringHist(TH1* hist); { return fMonitorHist->push_",MatchSource.WIKI,root/html532/TMVA__MethodBoost.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBoost.html
https://root.cern/root/html532/TMVA__MethodCategory.html:2497,Availability,error,error,2497,"t::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; TMVA::IMethod*TMVA::MethodCompositeBase::GetCurrentMethod(); virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt) const; const TMVA",MatchSource.WIKI,root/html532/TMVA__MethodCategory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCategory.html
https://root.cern/root/html532/TMVA__MethodCategory.html:2581,Availability,error,error,2581,"able(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; TMVA::IMethod*TMVA::MethodCompositeBase::GetCurrentMethod(); virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt, TMVA::Types::ETreeType type) const",MatchSource.WIKI,root/html532/TMVA__MethodCategory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCategory.html
https://root.cern/root/html532/TMVA__MethodCategory.html:18870,Integrability,message,message,18870,"ring& theWeightFile, TDirectory* theTargetDir = NULL); constructor from weight file. ~MethodCategory( void ); destructor. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t ); check whether method category has analysis type; the method type has to be the same for all sub-methods. void DeclareOptions(); options for this method. TMVA::IMethod* AddMethod(const TCut& , const TString& theVariables, TMVA::Types::EMVA theMethod, const TString& theTitle, const TString& theOptions); adds sub-classifier for a category. TMVA::DataSetInfo& CreateCategoryDSI(const TCut& , const TString& , const TString& ); create a DataSetInfo object for a sub-classifier. void Init(); initialize the method. void InitCircularTree(const TMVA::DataSetInfo& dsi); initialize the circular tree. void Train(); train all sub-classifiers. void AddWeightsXMLTo(void* parent) const; create XML description of Category classifier. void ReadWeightsFromXML(void* wghtnode); read weights of sub-classifiers of MethodCategory from xml weight file. void ProcessOptions(); process user options. void GetHelpMessage() const; Get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". const TMVA::Ranking* CreateRanking(); no ranking. Bool_t PassesCut(const TMVA::Event* ev, UInt_t methodIdx). Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); returns the mva value of the right sub-classifier. const std::vector<Float_t> & GetRegressionValues(); returns the mva value of the right sub-classifier. void MakeClass(const TString& = TString("""")) const; {}. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss, Or Cohen » Copyright (c) 2005: *; » Last changed: root/tmva $Id: MethodCategory.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__MethodCategory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCategory.html
https://root.cern/root/html532/TMVA__MethodCategory.html:465,Modifiability,variab,variab,465,". TMVA::MethodCategory. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodCategory. class TMVA::MethodCategory: public TMVA::MethodCompositeBase. This class is meant to allow categorisation of the data. For different; categories, different classifiers may be booked and different variab-; les may be considered. The aim is to account for the difference that; is due to different locations/angles. Function Members (Methods); public:. virtual~MethodCategory(); voidTObject::AbstractMethod(const char* method) const; TMVA::IMethod*AddMethod(const TCut&, const TString& theVariables, TMVA::Types::EMVA theMethod, const TString& theTitle, const TString& theOptions); voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidTMVA::MethodBase::CheckSetup(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tT",MatchSource.WIKI,root/html532/TMVA__MethodCategory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCategory.html
https://root.cern/root/html532/TMVA__MethodCategory.html:16346,Modifiability,variab,variables,16346,"tCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TCut>fCategoryCuts; vector<UInt_t>fCategorySpecIdx; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; Int_tTMVA::MethodCompositeBase::fMethodIndex; vector<Double_t>TMVA::MethodCompositeBase::fMethodWeight; vector<IMethod*>fMethods; vector<IMethod*>TMVA::MethodCompositeBase::fMethodsvector of all classifiers; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class; vector<std::vector<UInt_t> >fVarMaps; vector<TString>fVars. private:. vector<TTreeFormula*>fCatFormulas; TTree*fCatTree! needed in conjunction with TTreeFormulas for evaluation category expressions; TMVA::DataSetManager*fDataSetManagerDSMTEST. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodCategory(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = """", ",MatchSource.WIKI,root/html532/TMVA__MethodCategory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCategory.html
https://root.cern/root/html532/TMVA__MethodCategory.html:16743,Modifiability,variab,variable,16743,"tCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TCut>fCategoryCuts; vector<UInt_t>fCategorySpecIdx; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; Int_tTMVA::MethodCompositeBase::fMethodIndex; vector<Double_t>TMVA::MethodCompositeBase::fMethodWeight; vector<IMethod*>fMethods; vector<IMethod*>TMVA::MethodCompositeBase::fMethodsvector of all classifiers; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class; vector<std::vector<UInt_t> >fVarMaps; vector<TString>fVars. private:. vector<TTreeFormula*>fCatFormulas; TTree*fCatTree! needed in conjunction with TTreeFormulas for evaluation category expressions; TMVA::DataSetManager*fDataSetManagerDSMTEST. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodCategory(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = """", ",MatchSource.WIKI,root/html532/TMVA__MethodCategory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCategory.html
https://root.cern/root/html532/TMVA__MethodCategory.html:11975,Performance,tune,tuneParameters,11975,"voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int",MatchSource.WIKI,root/html532/TMVA__MethodCategory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCategory.html
https://root.cern/root/html532/TMVA__MethodCategory.html:11777,Testability,test,testTime,11777,"am& out, Option_t* option = """"); virtual voidTMVA::MethodBase::SetAnalysisType(TMVA::Types::EAnalysisType type); voidTMVA::MethodBase::SetBaseDir(TDirectory* methodDir); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObj",MatchSource.WIKI,root/html532/TMVA__MethodCategory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCategory.html
https://root.cern/root/html532/TMVA__MethodCategory.html:15977,Testability,test,testing,15977,"String fileDir); voidTMVA::MethodBase::SetWeightFileName(TString); voidTMVA::MethodBase::Statistics(TMVA::Types::ETreeType treeType, const TString& theVarName, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&); Bool_tTMVA::MethodBase::TxtWeightsOnly() const; Bool_tTMVA::MethodBase::Verbose() const; voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. virtual voidDeclareOptions(); virtual voidInit(); voidInitCircularTree(const TMVA::DataSetInfo& dsi); Bool_tPassesCut(const TMVA::Event* ev, UInt_t methodIdx); virtual voidProcessOptions(). Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TCut>fCategoryCuts; vector<UInt_t>fCategorySpecIdx; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; Int_tTMVA::MethodCompositeBase::fMethodIndex; vector<Double_t>TMVA::MethodCompositeBase::fMethodWeight; vector<IMethod*>fMethods; vector<IMethod*>TMVA::MethodCompositeBase::fMethodsvector of all classifiers; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::Metho",MatchSource.WIKI,root/html532/TMVA__MethodCategory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCategory.html
https://root.cern/root/html532/TMVA__MethodCFMlpANN.html:3534,Availability,error,error,3534,"t::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; Int_tGetClass(Int_t ivar) const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; Double_tGetData(Int_t isel, Int_t ivar) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt",MatchSource.WIKI,root/html532/TMVA__MethodCFMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCFMlpANN.html
https://root.cern/root/html532/TMVA__MethodCFMlpANN.html:3618,Availability,error,error,3618,"able(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; Int_tGetClass(Int_t ivar) const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; Double_tGetData(Int_t isel, Int_t ivar) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt, TMVA::Types::ET",MatchSource.WIKI,root/html532/TMVA__MethodCFMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCFMlpANN.html
https://root.cern/root/html532/TMVA__MethodCFMlpANN.html:1566,Energy Efficiency,power,power,1566,"ropagation schema:. The input layer contains as many neurons as input variables used in the MVA.; The output layer contains two neurons for the signal and background; event classes. In between the input and output layers are a variable number; of k hidden layers with arbitrary numbers of neurons. (While the; structure of the input and output layers is determined by the problem, the; hidden layers can be configured by the user through the option string; of the method booking.) ; As indicated in the sketch, all neuron inputs to a layer are linear; combinations of the neuron output of the previous layer. The transfer; from input to output within a neuron is performed by means of an ""activation; function"". In general, the activation function of a neuron can be; zero (deactivated), one (linear), or non-linear. The above example uses; a sigmoid activation function. The transfer function of the output layer; is usually linear. As a consequence: an ANN without hidden layer should; give identical discrimination power as a linear discriminant analysis (Fisher).; In case of one hidden layer, the ANN computes a linear combination of; sigmoid. ; The learning method used by the CFMlpANN is only stochastic.; */; . Function Members (Methods); public:. virtual~MethodCFMlpANN(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidTMVA::MethodBase::CheckSetup(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(",MatchSource.WIKI,root/html532/TMVA__MethodCFMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCFMlpANN.html
https://root.cern/root/html532/TMVA__MethodCFMlpANN.html:22274,Energy Efficiency,reduce,reduced,22274,"cycles = 5000, n_layers = 4. * note that the number of hidden layers in the NN is:; n_hidden_layers = n_layers - 2. * since there is one input and one output layer. The number of; nodes (neurons) is predefined to be:; n_nodes[i] = nvars + 1 - i (where i=1..n_layers). with nvars being the number of variables used in the NN. Hence, the default case is: n_neurons(layer 1 (input)) : nvars; n_neurons(layer 2 (hidden)): nvars-1; n_neurons(layer 3 (hidden)): nvars-1; n_neurons(layer 4 (out)) : 2. This artificial neural network usually needs a relatively large; number of cycles to converge (8000 and more). Overtraining can; be efficienctly tested by comparing the signal and background; output of the NN for the events that were used for training and; an independent data sample (with equal properties). If the separation; performance is significantly better for the training sample, the; NN interprets statistical effects, and is hence overtrained. In; this case, the number of cycles should be reduced, or the size; of the training sample increased. MethodCFMlpANN(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL); constructor from weight file. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t ); CFMlpANN can handle classification with 2 classes. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options: NCycles=xx :the number of training cycles; HiddenLayser=""N-1,N-2"" :the specification of the hidden layers. void ProcessOptions(); decode the options in the option string. void Init( void ); default initialisation called by all constructors. ~MethodCFMlpANN( void ); destructor. void Train( void ); training of the Clement-Ferrand NN classifier. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); returns CFMlpANN output (normalised within [0,1]). Double_t EvalANN(vector<Double_t>& , Bool_t& isOK); evaluates NN value as function of input variabl",MatchSource.WIKI,root/html532/TMVA__MethodCFMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCFMlpANN.html
https://root.cern/root/html532/TMVA__MethodCFMlpANN.html:23610,Integrability,interface,interface,23610,"NN can handle classification with 2 classes. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options: NCycles=xx :the number of training cycles; HiddenLayser=""N-1,N-2"" :the specification of the hidden layers. void ProcessOptions(); decode the options in the option string. void Init( void ); default initialisation called by all constructors. ~MethodCFMlpANN( void ); destructor. void Train( void ); training of the Clement-Ferrand NN classifier. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); returns CFMlpANN output (normalised within [0,1]). Double_t EvalANN(vector<Double_t>& , Bool_t& isOK); evaluates NN value as function of input variables. void NN_ava(Double_t* ); auxiliary functions. Double_t NN_fonc(Int_t , Double_t ) const; activation function. void ReadWeightsFromStream(istream& istr); read back the weight from the training from file (stream). Int_t DataInterface(Double_t* , Double_t* , Int_t* , Int_t* , Int_t* , Int_t* , Double_t* , Int_t* , Int_t* ); data interface function. void AddWeightsXMLTo(void* parent) const; write weights to xml file. void ReadWeightsFromXML(void* wghtnode); read weights from xml file. void PrintWeights(ostream& o) const; write the weights of the neural net. TMVA::MethodCFMlpANN* This( void ); static pointer to this object (required for external functions. void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. void MakeClassSpecificHeader(ostream& , const TString& = """") const; write specific classifier response for header. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". Double_t GetData(Int_t isel, Int_t ivar) const; data accessors for external functions. { return (*fData)(isel, ivar); }. Int_t GetClass(Int_t ivar) const; { return (*fClass)[ivar]; }. const Ranking* CreateRanking(); ranking of input variables. { return 0; }. »",MatchSource.WIKI,root/html532/TMVA__MethodCFMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCFMlpANN.html
https://root.cern/root/html532/TMVA__MethodCFMlpANN.html:24189,Integrability,message,message,24189,"sation called by all constructors. ~MethodCFMlpANN( void ); destructor. void Train( void ); training of the Clement-Ferrand NN classifier. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); returns CFMlpANN output (normalised within [0,1]). Double_t EvalANN(vector<Double_t>& , Bool_t& isOK); evaluates NN value as function of input variables. void NN_ava(Double_t* ); auxiliary functions. Double_t NN_fonc(Int_t , Double_t ) const; activation function. void ReadWeightsFromStream(istream& istr); read back the weight from the training from file (stream). Int_t DataInterface(Double_t* , Double_t* , Int_t* , Int_t* , Int_t* , Int_t* , Double_t* , Int_t* , Int_t* ); data interface function. void AddWeightsXMLTo(void* parent) const; write weights to xml file. void ReadWeightsFromXML(void* wghtnode); read weights from xml file. void PrintWeights(ostream& o) const; write the weights of the neural net. TMVA::MethodCFMlpANN* This( void ); static pointer to this object (required for external functions. void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. void MakeClassSpecificHeader(ostream& , const TString& = """") const; write specific classifier response for header. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". Double_t GetData(Int_t isel, Int_t ivar) const; data accessors for external functions. { return (*fData)(isel, ivar); }. Int_t GetClass(Int_t ivar) const; { return (*fClass)[ivar]; }. const Ranking* CreateRanking(); ranking of input variables. { return 0; }. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: MethodCFMlpANN.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__MethodCFMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCFMlpANN.html
https://root.cern/root/html532/TMVA__MethodCFMlpANN.html:618,Modifiability,variab,variables,618,". TMVA::MethodCFMlpANN. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodCFMlpANN. class TMVA::MethodCFMlpANN: public TMVA::MethodBase, private TMVA::MethodCFMlpANN_Utils. /*; Interface to Clermond-Ferrand artificial neural network; ; The CFMlpANN belong to the class of Multilayer Perceptrons (MLP), which are; feed-forward networks according to the following propagation schema:. The input layer contains as many neurons as input variables used in the MVA.; The output layer contains two neurons for the signal and background; event classes. In between the input and output layers are a variable number; of k hidden layers with arbitrary numbers of neurons. (While the; structure of the input and output layers is determined by the problem, the; hidden layers can be configured by the user through the option string; of the method booking.) ; As indicated in the sketch, all neuron inputs to a layer are linear; combinations of the neuron output of the previous layer. The transfer; from input to output within a neuron is performed by means of an ""activation; function"". In general, the activation function of a neuron can be; zero (deactivated), one (linear), or non-linear. The above example uses; a sigmoid activation function. The transfer function of the output layer; is usually linear. As a consequence: an ANN without hidden layer should; give identical discrimination power as a linear discriminant analysis (Fisher).; In case of one hidden layer, the ANN computes a linear combination of; sigmoid. ; The learning method used by the CFMlpANN is only stochastic.; */; . Function Members (Methods); public:. virtual~MethodCFMlpANN(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType ",MatchSource.WIKI,root/html532/TMVA__MethodCFMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCFMlpANN.html
https://root.cern/root/html532/TMVA__MethodCFMlpANN.html:762,Modifiability,layers,layers,762,". TMVA::MethodCFMlpANN. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodCFMlpANN. class TMVA::MethodCFMlpANN: public TMVA::MethodBase, private TMVA::MethodCFMlpANN_Utils. /*; Interface to Clermond-Ferrand artificial neural network; ; The CFMlpANN belong to the class of Multilayer Perceptrons (MLP), which are; feed-forward networks according to the following propagation schema:. The input layer contains as many neurons as input variables used in the MVA.; The output layer contains two neurons for the signal and background; event classes. In between the input and output layers are a variable number; of k hidden layers with arbitrary numbers of neurons. (While the; structure of the input and output layers is determined by the problem, the; hidden layers can be configured by the user through the option string; of the method booking.) ; As indicated in the sketch, all neuron inputs to a layer are linear; combinations of the neuron output of the previous layer. The transfer; from input to output within a neuron is performed by means of an ""activation; function"". In general, the activation function of a neuron can be; zero (deactivated), one (linear), or non-linear. The above example uses; a sigmoid activation function. The transfer function of the output layer; is usually linear. As a consequence: an ANN without hidden layer should; give identical discrimination power as a linear discriminant analysis (Fisher).; In case of one hidden layer, the ANN computes a linear combination of; sigmoid. ; The learning method used by the CFMlpANN is only stochastic.; */; . Function Members (Methods); public:. virtual~MethodCFMlpANN(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType ",MatchSource.WIKI,root/html532/TMVA__MethodCFMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCFMlpANN.html
https://root.cern/root/html532/TMVA__MethodCFMlpANN.html:775,Modifiability,variab,variable,775,". TMVA::MethodCFMlpANN. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodCFMlpANN. class TMVA::MethodCFMlpANN: public TMVA::MethodBase, private TMVA::MethodCFMlpANN_Utils. /*; Interface to Clermond-Ferrand artificial neural network; ; The CFMlpANN belong to the class of Multilayer Perceptrons (MLP), which are; feed-forward networks according to the following propagation schema:. The input layer contains as many neurons as input variables used in the MVA.; The output layer contains two neurons for the signal and background; event classes. In between the input and output layers are a variable number; of k hidden layers with arbitrary numbers of neurons. (While the; structure of the input and output layers is determined by the problem, the; hidden layers can be configured by the user through the option string; of the method booking.) ; As indicated in the sketch, all neuron inputs to a layer are linear; combinations of the neuron output of the previous layer. The transfer; from input to output within a neuron is performed by means of an ""activation; function"". In general, the activation function of a neuron can be; zero (deactivated), one (linear), or non-linear. The above example uses; a sigmoid activation function. The transfer function of the output layer; is usually linear. As a consequence: an ANN without hidden layer should; give identical discrimination power as a linear discriminant analysis (Fisher).; In case of one hidden layer, the ANN computes a linear combination of; sigmoid. ; The learning method used by the CFMlpANN is only stochastic.; */; . Function Members (Methods); public:. virtual~MethodCFMlpANN(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType ",MatchSource.WIKI,root/html532/TMVA__MethodCFMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCFMlpANN.html
https://root.cern/root/html532/TMVA__MethodCFMlpANN.html:804,Modifiability,layers,layers,804,". TMVA::MethodCFMlpANN. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodCFMlpANN. class TMVA::MethodCFMlpANN: public TMVA::MethodBase, private TMVA::MethodCFMlpANN_Utils. /*; Interface to Clermond-Ferrand artificial neural network; ; The CFMlpANN belong to the class of Multilayer Perceptrons (MLP), which are; feed-forward networks according to the following propagation schema:. The input layer contains as many neurons as input variables used in the MVA.; The output layer contains two neurons for the signal and background; event classes. In between the input and output layers are a variable number; of k hidden layers with arbitrary numbers of neurons. (While the; structure of the input and output layers is determined by the problem, the; hidden layers can be configured by the user through the option string; of the method booking.) ; As indicated in the sketch, all neuron inputs to a layer are linear; combinations of the neuron output of the previous layer. The transfer; from input to output within a neuron is performed by means of an ""activation; function"". In general, the activation function of a neuron can be; zero (deactivated), one (linear), or non-linear. The above example uses; a sigmoid activation function. The transfer function of the output layer; is usually linear. As a consequence: an ANN without hidden layer should; give identical discrimination power as a linear discriminant analysis (Fisher).; In case of one hidden layer, the ANN computes a linear combination of; sigmoid. ; The learning method used by the CFMlpANN is only stochastic.; */; . Function Members (Methods); public:. virtual~MethodCFMlpANN(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType ",MatchSource.WIKI,root/html532/TMVA__MethodCFMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCFMlpANN.html
https://root.cern/root/html532/TMVA__MethodCFMlpANN.html:892,Modifiability,layers,layers,892,". TMVA::MethodCFMlpANN. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodCFMlpANN. class TMVA::MethodCFMlpANN: public TMVA::MethodBase, private TMVA::MethodCFMlpANN_Utils. /*; Interface to Clermond-Ferrand artificial neural network; ; The CFMlpANN belong to the class of Multilayer Perceptrons (MLP), which are; feed-forward networks according to the following propagation schema:. The input layer contains as many neurons as input variables used in the MVA.; The output layer contains two neurons for the signal and background; event classes. In between the input and output layers are a variable number; of k hidden layers with arbitrary numbers of neurons. (While the; structure of the input and output layers is determined by the problem, the; hidden layers can be configured by the user through the option string; of the method booking.) ; As indicated in the sketch, all neuron inputs to a layer are linear; combinations of the neuron output of the previous layer. The transfer; from input to output within a neuron is performed by means of an ""activation; function"". In general, the activation function of a neuron can be; zero (deactivated), one (linear), or non-linear. The above example uses; a sigmoid activation function. The transfer function of the output layer; is usually linear. As a consequence: an ANN without hidden layer should; give identical discrimination power as a linear discriminant analysis (Fisher).; In case of one hidden layer, the ANN computes a linear combination of; sigmoid. ; The learning method used by the CFMlpANN is only stochastic.; */; . Function Members (Methods); public:. virtual~MethodCFMlpANN(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType ",MatchSource.WIKI,root/html532/TMVA__MethodCFMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCFMlpANN.html
https://root.cern/root/html532/TMVA__MethodCFMlpANN.html:941,Modifiability,layers,layers,941,". TMVA::MethodCFMlpANN. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodCFMlpANN. class TMVA::MethodCFMlpANN: public TMVA::MethodBase, private TMVA::MethodCFMlpANN_Utils. /*; Interface to Clermond-Ferrand artificial neural network; ; The CFMlpANN belong to the class of Multilayer Perceptrons (MLP), which are; feed-forward networks according to the following propagation schema:. The input layer contains as many neurons as input variables used in the MVA.; The output layer contains two neurons for the signal and background; event classes. In between the input and output layers are a variable number; of k hidden layers with arbitrary numbers of neurons. (While the; structure of the input and output layers is determined by the problem, the; hidden layers can be configured by the user through the option string; of the method booking.) ; As indicated in the sketch, all neuron inputs to a layer are linear; combinations of the neuron output of the previous layer. The transfer; from input to output within a neuron is performed by means of an ""activation; function"". In general, the activation function of a neuron can be; zero (deactivated), one (linear), or non-linear. The above example uses; a sigmoid activation function. The transfer function of the output layer; is usually linear. As a consequence: an ANN without hidden layer should; give identical discrimination power as a linear discriminant analysis (Fisher).; In case of one hidden layer, the ANN computes a linear combination of; sigmoid. ; The learning method used by the CFMlpANN is only stochastic.; */; . Function Members (Methods); public:. virtual~MethodCFMlpANN(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType ",MatchSource.WIKI,root/html532/TMVA__MethodCFMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCFMlpANN.html
https://root.cern/root/html532/TMVA__MethodCFMlpANN.html:955,Modifiability,config,configured,955,". TMVA::MethodCFMlpANN. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodCFMlpANN. class TMVA::MethodCFMlpANN: public TMVA::MethodBase, private TMVA::MethodCFMlpANN_Utils. /*; Interface to Clermond-Ferrand artificial neural network; ; The CFMlpANN belong to the class of Multilayer Perceptrons (MLP), which are; feed-forward networks according to the following propagation schema:. The input layer contains as many neurons as input variables used in the MVA.; The output layer contains two neurons for the signal and background; event classes. In between the input and output layers are a variable number; of k hidden layers with arbitrary numbers of neurons. (While the; structure of the input and output layers is determined by the problem, the; hidden layers can be configured by the user through the option string; of the method booking.) ; As indicated in the sketch, all neuron inputs to a layer are linear; combinations of the neuron output of the previous layer. The transfer; from input to output within a neuron is performed by means of an ""activation; function"". In general, the activation function of a neuron can be; zero (deactivated), one (linear), or non-linear. The above example uses; a sigmoid activation function. The transfer function of the output layer; is usually linear. As a consequence: an ANN without hidden layer should; give identical discrimination power as a linear discriminant analysis (Fisher).; In case of one hidden layer, the ANN computes a linear combination of; sigmoid. ; The learning method used by the CFMlpANN is only stochastic.; */; . Function Members (Methods); public:. virtual~MethodCFMlpANN(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType ",MatchSource.WIKI,root/html532/TMVA__MethodCFMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCFMlpANN.html
https://root.cern/root/html532/TMVA__MethodCFMlpANN.html:19017,Modifiability,variab,variables,19017,"uble_t* wwNN, Int_t a_1, Int_t a_2). Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. vector<Int_t>*fClassthe event class (1=signal, 2=background); TMVA::MethodCFMlpANN_Utils::TMVA::MethodCFMlpANN_Utils::fCost_1; TMatrixF*fDatathe (data,var) string; TMVA::MethodCFMlpANN_Utils::TMVA::MethodCFMlpANN_Utils::fDel_1; TStringfLayerSpecthe hidden layer specification string; Int_tfNcyclesnumber of training cycles; TMVA::MethodCFMlpANN_Utils::TMVA::MethodCFMlpANN_Utils::fNeur_1; Int_tfNlayersnumber of layers (including input and output layers); Int_t*fNodesnumber of nodes per layer; TMVA::MethodCFMlpANN_Utils::TMVA::MethodCFMlpANN_Utils::fPa",MatchSource.WIKI,root/html532/TMVA__MethodCFMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCFMlpANN.html
https://root.cern/root/html532/TMVA__MethodCFMlpANN.html:19206,Modifiability,variab,variable,19206,"uble_t* wwNN, Int_t a_1, Int_t a_2). Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. vector<Int_t>*fClassthe event class (1=signal, 2=background); TMVA::MethodCFMlpANN_Utils::TMVA::MethodCFMlpANN_Utils::fCost_1; TMatrixF*fDatathe (data,var) string; TMVA::MethodCFMlpANN_Utils::TMVA::MethodCFMlpANN_Utils::fDel_1; TStringfLayerSpecthe hidden layer specification string; Int_tfNcyclesnumber of training cycles; TMVA::MethodCFMlpANN_Utils::TMVA::MethodCFMlpANN_Utils::fNeur_1; Int_tfNlayersnumber of layers (including input and output layers); Int_t*fNodesnumber of nodes per layer; TMVA::MethodCFMlpANN_Utils::TMVA::MethodCFMlpANN_Utils::fPa",MatchSource.WIKI,root/html532/TMVA__MethodCFMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCFMlpANN.html
https://root.cern/root/html532/TMVA__MethodCFMlpANN.html:20060,Modifiability,layers,layers,20060,"on histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. vector<Int_t>*fClassthe event class (1=signal, 2=background); TMVA::MethodCFMlpANN_Utils::TMVA::MethodCFMlpANN_Utils::fCost_1; TMatrixF*fDatathe (data,var) string; TMVA::MethodCFMlpANN_Utils::TMVA::MethodCFMlpANN_Utils::fDel_1; TStringfLayerSpecthe hidden layer specification string; Int_tfNcyclesnumber of training cycles; TMVA::MethodCFMlpANN_Utils::TMVA::MethodCFMlpANN_Utils::fNeur_1; Int_tfNlayersnumber of layers (including input and output layers); Int_t*fNodesnumber of nodes per layer; TMVA::MethodCFMlpANN_Utils::TMVA::MethodCFMlpANN_Utils::fParam_1; TMVA::MethodCFMlpANN_Utils::VARn2TMVA::MethodCFMlpANN_Utils::fVarn2_1; TMVA::MethodCFMlpANN_Utils::VARn2TMVA::MethodCFMlpANN_Utils::fVarn3_1; TMVA::MethodCFMlpANN_Utils::TMVA::MethodCFMlpANN_Utils::fVarn_1; Double_t**fYNNweights; static TMVA::MethodCFMlpANN*fgThisthis carrier; static Int_tTMVA::MethodCFMlpANN_Utils::fg_0constant; static Int_tTMVA::MethodCFMlpANN_Utils::fg_100constant; static Int_tTMVA::MethodCFMlpANN_Utils::fg_999constant; static const char*TMVA::MethodCFMlpANN_Utils::fg_MethodNamemethod name for print; static Int_tTMVA::MethodCFMlpANN_Utils::fg_max_nNodes_maximum number of nodes per variable; static Int_tTMVA::MethodCFMlpANN_Utils::fg_max_nVar_static maximum number of input variables. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodCFMlpANN(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = ""3000:N-1:N-2"", TDirectory* theTargetDir = 0); standard constructor; option string: ""n_training_cycles:n_hidden_layers""; default is: n_training_cycles",MatchSource.WIKI,root/html532/TMVA__MethodCFMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCFMlpANN.html
https://root.cern/root/html532/TMVA__MethodCFMlpANN.html:20095,Modifiability,layers,layers,20095,"on histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. vector<Int_t>*fClassthe event class (1=signal, 2=background); TMVA::MethodCFMlpANN_Utils::TMVA::MethodCFMlpANN_Utils::fCost_1; TMatrixF*fDatathe (data,var) string; TMVA::MethodCFMlpANN_Utils::TMVA::MethodCFMlpANN_Utils::fDel_1; TStringfLayerSpecthe hidden layer specification string; Int_tfNcyclesnumber of training cycles; TMVA::MethodCFMlpANN_Utils::TMVA::MethodCFMlpANN_Utils::fNeur_1; Int_tfNlayersnumber of layers (including input and output layers); Int_t*fNodesnumber of nodes per layer; TMVA::MethodCFMlpANN_Utils::TMVA::MethodCFMlpANN_Utils::fParam_1; TMVA::MethodCFMlpANN_Utils::VARn2TMVA::MethodCFMlpANN_Utils::fVarn2_1; TMVA::MethodCFMlpANN_Utils::VARn2TMVA::MethodCFMlpANN_Utils::fVarn3_1; TMVA::MethodCFMlpANN_Utils::TMVA::MethodCFMlpANN_Utils::fVarn_1; Double_t**fYNNweights; static TMVA::MethodCFMlpANN*fgThisthis carrier; static Int_tTMVA::MethodCFMlpANN_Utils::fg_0constant; static Int_tTMVA::MethodCFMlpANN_Utils::fg_100constant; static Int_tTMVA::MethodCFMlpANN_Utils::fg_999constant; static const char*TMVA::MethodCFMlpANN_Utils::fg_MethodNamemethod name for print; static Int_tTMVA::MethodCFMlpANN_Utils::fg_max_nNodes_maximum number of nodes per variable; static Int_tTMVA::MethodCFMlpANN_Utils::fg_max_nVar_static maximum number of input variables. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodCFMlpANN(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = ""3000:N-1:N-2"", TDirectory* theTargetDir = 0); standard constructor; option string: ""n_training_cycles:n_hidden_layers""; default is: n_training_cycles",MatchSource.WIKI,root/html532/TMVA__MethodCFMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCFMlpANN.html
https://root.cern/root/html532/TMVA__MethodCFMlpANN.html:20817,Modifiability,variab,variable,20817,"on histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. vector<Int_t>*fClassthe event class (1=signal, 2=background); TMVA::MethodCFMlpANN_Utils::TMVA::MethodCFMlpANN_Utils::fCost_1; TMatrixF*fDatathe (data,var) string; TMVA::MethodCFMlpANN_Utils::TMVA::MethodCFMlpANN_Utils::fDel_1; TStringfLayerSpecthe hidden layer specification string; Int_tfNcyclesnumber of training cycles; TMVA::MethodCFMlpANN_Utils::TMVA::MethodCFMlpANN_Utils::fNeur_1; Int_tfNlayersnumber of layers (including input and output layers); Int_t*fNodesnumber of nodes per layer; TMVA::MethodCFMlpANN_Utils::TMVA::MethodCFMlpANN_Utils::fParam_1; TMVA::MethodCFMlpANN_Utils::VARn2TMVA::MethodCFMlpANN_Utils::fVarn2_1; TMVA::MethodCFMlpANN_Utils::VARn2TMVA::MethodCFMlpANN_Utils::fVarn3_1; TMVA::MethodCFMlpANN_Utils::TMVA::MethodCFMlpANN_Utils::fVarn_1; Double_t**fYNNweights; static TMVA::MethodCFMlpANN*fgThisthis carrier; static Int_tTMVA::MethodCFMlpANN_Utils::fg_0constant; static Int_tTMVA::MethodCFMlpANN_Utils::fg_100constant; static Int_tTMVA::MethodCFMlpANN_Utils::fg_999constant; static const char*TMVA::MethodCFMlpANN_Utils::fg_MethodNamemethod name for print; static Int_tTMVA::MethodCFMlpANN_Utils::fg_max_nNodes_maximum number of nodes per variable; static Int_tTMVA::MethodCFMlpANN_Utils::fg_max_nVar_static maximum number of input variables. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodCFMlpANN(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = ""3000:N-1:N-2"", TDirectory* theTargetDir = 0); standard constructor; option string: ""n_training_cycles:n_hidden_layers""; default is: n_training_cycles",MatchSource.WIKI,root/html532/TMVA__MethodCFMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCFMlpANN.html
https://root.cern/root/html532/TMVA__MethodCFMlpANN.html:20910,Modifiability,variab,variables,20910,"on histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. vector<Int_t>*fClassthe event class (1=signal, 2=background); TMVA::MethodCFMlpANN_Utils::TMVA::MethodCFMlpANN_Utils::fCost_1; TMatrixF*fDatathe (data,var) string; TMVA::MethodCFMlpANN_Utils::TMVA::MethodCFMlpANN_Utils::fDel_1; TStringfLayerSpecthe hidden layer specification string; Int_tfNcyclesnumber of training cycles; TMVA::MethodCFMlpANN_Utils::TMVA::MethodCFMlpANN_Utils::fNeur_1; Int_tfNlayersnumber of layers (including input and output layers); Int_t*fNodesnumber of nodes per layer; TMVA::MethodCFMlpANN_Utils::TMVA::MethodCFMlpANN_Utils::fParam_1; TMVA::MethodCFMlpANN_Utils::VARn2TMVA::MethodCFMlpANN_Utils::fVarn2_1; TMVA::MethodCFMlpANN_Utils::VARn2TMVA::MethodCFMlpANN_Utils::fVarn3_1; TMVA::MethodCFMlpANN_Utils::TMVA::MethodCFMlpANN_Utils::fVarn_1; Double_t**fYNNweights; static TMVA::MethodCFMlpANN*fgThisthis carrier; static Int_tTMVA::MethodCFMlpANN_Utils::fg_0constant; static Int_tTMVA::MethodCFMlpANN_Utils::fg_100constant; static Int_tTMVA::MethodCFMlpANN_Utils::fg_999constant; static const char*TMVA::MethodCFMlpANN_Utils::fg_MethodNamemethod name for print; static Int_tTMVA::MethodCFMlpANN_Utils::fg_max_nNodes_maximum number of nodes per variable; static Int_tTMVA::MethodCFMlpANN_Utils::fg_max_nVar_static maximum number of input variables. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodCFMlpANN(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = ""3000:N-1:N-2"", TDirectory* theTargetDir = 0); standard constructor; option string: ""n_training_cycles:n_hidden_layers""; default is: n_training_cycles",MatchSource.WIKI,root/html532/TMVA__MethodCFMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCFMlpANN.html
https://root.cern/root/html532/TMVA__MethodCFMlpANN.html:21340,Modifiability,layers,layers,21340,"; TMVA::MethodCFMlpANN_Utils::TMVA::MethodCFMlpANN_Utils::fVarn_1; Double_t**fYNNweights; static TMVA::MethodCFMlpANN*fgThisthis carrier; static Int_tTMVA::MethodCFMlpANN_Utils::fg_0constant; static Int_tTMVA::MethodCFMlpANN_Utils::fg_100constant; static Int_tTMVA::MethodCFMlpANN_Utils::fg_999constant; static const char*TMVA::MethodCFMlpANN_Utils::fg_MethodNamemethod name for print; static Int_tTMVA::MethodCFMlpANN_Utils::fg_max_nNodes_maximum number of nodes per variable; static Int_tTMVA::MethodCFMlpANN_Utils::fg_max_nVar_static maximum number of input variables. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodCFMlpANN(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = ""3000:N-1:N-2"", TDirectory* theTargetDir = 0); standard constructor; option string: ""n_training_cycles:n_hidden_layers""; default is: n_training_cycles = 5000, n_layers = 4. * note that the number of hidden layers in the NN is:; n_hidden_layers = n_layers - 2. * since there is one input and one output layer. The number of; nodes (neurons) is predefined to be:; n_nodes[i] = nvars + 1 - i (where i=1..n_layers). with nvars being the number of variables used in the NN. Hence, the default case is: n_neurons(layer 1 (input)) : nvars; n_neurons(layer 2 (hidden)): nvars-1; n_neurons(layer 3 (hidden)): nvars-1; n_neurons(layer 4 (out)) : 2. This artificial neural network usually needs a relatively large; number of cycles to converge (8000 and more). Overtraining can; be efficienctly tested by comparing the signal and background; output of the NN for the events that were used for training and; an independent data sample (with equal properties). If the separation; performance is significantly better for the training sample, the; NN interprets statistical effects, and is hence overtrained. In; this case, the number of cycles should be reduced, or the size; of the training sample increased. MethodCFMlpANN(TMVA:",MatchSource.WIKI,root/html532/TMVA__MethodCFMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCFMlpANN.html
https://root.cern/root/html532/TMVA__MethodCFMlpANN.html:21577,Modifiability,variab,variables,21577,"_Utils::fg_100constant; static Int_tTMVA::MethodCFMlpANN_Utils::fg_999constant; static const char*TMVA::MethodCFMlpANN_Utils::fg_MethodNamemethod name for print; static Int_tTMVA::MethodCFMlpANN_Utils::fg_max_nNodes_maximum number of nodes per variable; static Int_tTMVA::MethodCFMlpANN_Utils::fg_max_nVar_static maximum number of input variables. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodCFMlpANN(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = ""3000:N-1:N-2"", TDirectory* theTargetDir = 0); standard constructor; option string: ""n_training_cycles:n_hidden_layers""; default is: n_training_cycles = 5000, n_layers = 4. * note that the number of hidden layers in the NN is:; n_hidden_layers = n_layers - 2. * since there is one input and one output layer. The number of; nodes (neurons) is predefined to be:; n_nodes[i] = nvars + 1 - i (where i=1..n_layers). with nvars being the number of variables used in the NN. Hence, the default case is: n_neurons(layer 1 (input)) : nvars; n_neurons(layer 2 (hidden)): nvars-1; n_neurons(layer 3 (hidden)): nvars-1; n_neurons(layer 4 (out)) : 2. This artificial neural network usually needs a relatively large; number of cycles to converge (8000 and more). Overtraining can; be efficienctly tested by comparing the signal and background; output of the NN for the events that were used for training and; an independent data sample (with equal properties). If the separation; performance is significantly better for the training sample, the; NN interprets statistical effects, and is hence overtrained. In; this case, the number of cycles should be reduced, or the size; of the training sample increased. MethodCFMlpANN(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL); constructor from weight file. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t ); CFMlpANN can handle",MatchSource.WIKI,root/html532/TMVA__MethodCFMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCFMlpANN.html
https://root.cern/root/html532/TMVA__MethodCFMlpANN.html:22817,Modifiability,layers,layers,22817,"(layer 3 (hidden)): nvars-1; n_neurons(layer 4 (out)) : 2. This artificial neural network usually needs a relatively large; number of cycles to converge (8000 and more). Overtraining can; be efficienctly tested by comparing the signal and background; output of the NN for the events that were used for training and; an independent data sample (with equal properties). If the separation; performance is significantly better for the training sample, the; NN interprets statistical effects, and is hence overtrained. In; this case, the number of cycles should be reduced, or the size; of the training sample increased. MethodCFMlpANN(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL); constructor from weight file. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t ); CFMlpANN can handle classification with 2 classes. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options: NCycles=xx :the number of training cycles; HiddenLayser=""N-1,N-2"" :the specification of the hidden layers. void ProcessOptions(); decode the options in the option string. void Init( void ); default initialisation called by all constructors. ~MethodCFMlpANN( void ); destructor. void Train( void ); training of the Clement-Ferrand NN classifier. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); returns CFMlpANN output (normalised within [0,1]). Double_t EvalANN(vector<Double_t>& , Bool_t& isOK); evaluates NN value as function of input variables. void NN_ava(Double_t* ); auxiliary functions. Double_t NN_fonc(Int_t , Double_t ) const; activation function. void ReadWeightsFromStream(istream& istr); read back the weight from the training from file (stream). Int_t DataInterface(Double_t* , Double_t* , Int_t* , Int_t* , Int_t* , Int_t* , Double_t* , Int_t* , Int_t* ); data interface function. void AddWeightsXMLTo(void* parent) const; write weights to xml file. void ReadWeights",MatchSource.WIKI,root/html532/TMVA__MethodCFMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCFMlpANN.html
https://root.cern/root/html532/TMVA__MethodCFMlpANN.html:23271,Modifiability,variab,variables,23271,"n; this case, the number of cycles should be reduced, or the size; of the training sample increased. MethodCFMlpANN(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL); constructor from weight file. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t ); CFMlpANN can handle classification with 2 classes. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options: NCycles=xx :the number of training cycles; HiddenLayser=""N-1,N-2"" :the specification of the hidden layers. void ProcessOptions(); decode the options in the option string. void Init( void ); default initialisation called by all constructors. ~MethodCFMlpANN( void ); destructor. void Train( void ); training of the Clement-Ferrand NN classifier. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); returns CFMlpANN output (normalised within [0,1]). Double_t EvalANN(vector<Double_t>& , Bool_t& isOK); evaluates NN value as function of input variables. void NN_ava(Double_t* ); auxiliary functions. Double_t NN_fonc(Int_t , Double_t ) const; activation function. void ReadWeightsFromStream(istream& istr); read back the weight from the training from file (stream). Int_t DataInterface(Double_t* , Double_t* , Int_t* , Int_t* , Int_t* , Int_t* , Double_t* , Int_t* , Int_t* ); data interface function. void AddWeightsXMLTo(void* parent) const; write weights to xml file. void ReadWeightsFromXML(void* wghtnode); read weights from xml file. void PrintWeights(ostream& o) const; write the weights of the neural net. TMVA::MethodCFMlpANN* This( void ); static pointer to this object (required for external functions. void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. void MakeClassSpecificHeader(ostream& , const TString& = """") const; write specific classifier response for header. void GetHelpMessage() const; get help message text. typical length of text line",MatchSource.WIKI,root/html532/TMVA__MethodCFMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCFMlpANN.html
https://root.cern/root/html532/TMVA__MethodCFMlpANN.html:24534,Modifiability,variab,variables,24534,"sation called by all constructors. ~MethodCFMlpANN( void ); destructor. void Train( void ); training of the Clement-Ferrand NN classifier. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); returns CFMlpANN output (normalised within [0,1]). Double_t EvalANN(vector<Double_t>& , Bool_t& isOK); evaluates NN value as function of input variables. void NN_ava(Double_t* ); auxiliary functions. Double_t NN_fonc(Int_t , Double_t ) const; activation function. void ReadWeightsFromStream(istream& istr); read back the weight from the training from file (stream). Int_t DataInterface(Double_t* , Double_t* , Int_t* , Int_t* , Int_t* , Int_t* , Double_t* , Int_t* , Int_t* ); data interface function. void AddWeightsXMLTo(void* parent) const; write weights to xml file. void ReadWeightsFromXML(void* wghtnode); read weights from xml file. void PrintWeights(ostream& o) const; write the weights of the neural net. TMVA::MethodCFMlpANN* This( void ); static pointer to this object (required for external functions. void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. void MakeClassSpecificHeader(ostream& , const TString& = """") const; write specific classifier response for header. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". Double_t GetData(Int_t isel, Int_t ivar) const; data accessors for external functions. { return (*fData)(isel, ivar); }. Int_t GetClass(Int_t ivar) const; { return (*fClass)[ivar]; }. const Ranking* CreateRanking(); ranking of input variables. { return 0; }. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: MethodCFMlpANN.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__MethodCFMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCFMlpANN.html
https://root.cern/root/html532/TMVA__MethodCFMlpANN.html:1211,Performance,perform,performed,1211," members; class charts. ROOT; » TMVA; » TMVA::MethodCFMlpANN. class TMVA::MethodCFMlpANN: public TMVA::MethodBase, private TMVA::MethodCFMlpANN_Utils. /*; Interface to Clermond-Ferrand artificial neural network; ; The CFMlpANN belong to the class of Multilayer Perceptrons (MLP), which are; feed-forward networks according to the following propagation schema:. The input layer contains as many neurons as input variables used in the MVA.; The output layer contains two neurons for the signal and background; event classes. In between the input and output layers are a variable number; of k hidden layers with arbitrary numbers of neurons. (While the; structure of the input and output layers is determined by the problem, the; hidden layers can be configured by the user through the option string; of the method booking.) ; As indicated in the sketch, all neuron inputs to a layer are linear; combinations of the neuron output of the previous layer. The transfer; from input to output within a neuron is performed by means of an ""activation; function"". In general, the activation function of a neuron can be; zero (deactivated), one (linear), or non-linear. The above example uses; a sigmoid activation function. The transfer function of the output layer; is usually linear. As a consequence: an ANN without hidden layer should; give identical discrimination power as a linear discriminant analysis (Fisher).; In case of one hidden layer, the ANN computes a linear combination of; sigmoid. ; The learning method used by the CFMlpANN is only stochastic.; */; . Function Members (Methods); public:. virtual~MethodCFMlpANN(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virtual v",MatchSource.WIKI,root/html532/TMVA__MethodCFMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCFMlpANN.html
https://root.cern/root/html532/TMVA__MethodCFMlpANN.html:12896,Performance,tune,tuneParameters,12896,"voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); static TMVA::MethodCFMlpANN*This(); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObj",MatchSource.WIKI,root/html532/TMVA__MethodCFMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCFMlpANN.html
https://root.cern/root/html532/TMVA__MethodCFMlpANN.html:22101,Performance,perform,performance,22101,"ectory* theTargetDir = 0); standard constructor; option string: ""n_training_cycles:n_hidden_layers""; default is: n_training_cycles = 5000, n_layers = 4. * note that the number of hidden layers in the NN is:; n_hidden_layers = n_layers - 2. * since there is one input and one output layer. The number of; nodes (neurons) is predefined to be:; n_nodes[i] = nvars + 1 - i (where i=1..n_layers). with nvars being the number of variables used in the NN. Hence, the default case is: n_neurons(layer 1 (input)) : nvars; n_neurons(layer 2 (hidden)): nvars-1; n_neurons(layer 3 (hidden)): nvars-1; n_neurons(layer 4 (out)) : 2. This artificial neural network usually needs a relatively large; number of cycles to converge (8000 and more). Overtraining can; be efficienctly tested by comparing the signal and background; output of the NN for the events that were used for training and; an independent data sample (with equal properties). If the separation; performance is significantly better for the training sample, the; NN interprets statistical effects, and is hence overtrained. In; this case, the number of cycles should be reduced, or the size; of the training sample increased. MethodCFMlpANN(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL); constructor from weight file. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t ); CFMlpANN can handle classification with 2 classes. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options: NCycles=xx :the number of training cycles; HiddenLayser=""N-1,N-2"" :the specification of the hidden layers. void ProcessOptions(); decode the options in the option string. void Init( void ); default initialisation called by all constructors. ~MethodCFMlpANN( void ); destructor. void Train( void ); training of the Clement-Ferrand NN classifier. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); returns CFMlpANN output (n",MatchSource.WIKI,root/html532/TMVA__MethodCFMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCFMlpANN.html
https://root.cern/root/html532/TMVA__MethodCFMlpANN.html:24354,Security,access,accessors,24354,"sation called by all constructors. ~MethodCFMlpANN( void ); destructor. void Train( void ); training of the Clement-Ferrand NN classifier. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); returns CFMlpANN output (normalised within [0,1]). Double_t EvalANN(vector<Double_t>& , Bool_t& isOK); evaluates NN value as function of input variables. void NN_ava(Double_t* ); auxiliary functions. Double_t NN_fonc(Int_t , Double_t ) const; activation function. void ReadWeightsFromStream(istream& istr); read back the weight from the training from file (stream). Int_t DataInterface(Double_t* , Double_t* , Int_t* , Int_t* , Int_t* , Int_t* , Double_t* , Int_t* , Int_t* ); data interface function. void AddWeightsXMLTo(void* parent) const; write weights to xml file. void ReadWeightsFromXML(void* wghtnode); read weights from xml file. void PrintWeights(ostream& o) const; write the weights of the neural net. TMVA::MethodCFMlpANN* This( void ); static pointer to this object (required for external functions. void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. void MakeClassSpecificHeader(ostream& , const TString& = """") const; write specific classifier response for header. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". Double_t GetData(Int_t isel, Int_t ivar) const; data accessors for external functions. { return (*fData)(isel, ivar); }. Int_t GetClass(Int_t ivar) const; { return (*fClass)[ivar]; }. const Ranking* CreateRanking(); ranking of input variables. { return 0; }. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: MethodCFMlpANN.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__MethodCFMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCFMlpANN.html
https://root.cern/root/html532/TMVA__MethodCFMlpANN.html:12698,Testability,test,testTime,12698,"am& out, Option_t* option = """"); virtual voidTMVA::MethodBase::SetAnalysisType(TMVA::Types::EAnalysisType type); voidTMVA::MethodBase::SetBaseDir(TDirectory* methodDir); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); static TMVA::MethodCFMlpANN*This(); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject:",MatchSource.WIKI,root/html532/TMVA__MethodCFMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCFMlpANN.html
https://root.cern/root/html532/TMVA__MethodCFMlpANN.html:18707,Testability,test,testing,18707,"dTMVA::MethodCFMlpANN_Utils::Train_nn(Double_t* tin2, Double_t* tout2, Int_t* ntrain, Int_t* ntest, Int_t* nvar2, Int_t* nlayer, Int_t* nodes, Int_t* ncycle); Double_tTMVA::MethodCFMlpANN_Utils::W_ref(const Double_t* wNN, Int_t a_1, Int_t a_2, Int_t a_3) const; Double_t&TMVA::MethodCFMlpANN_Utils::W_ref(Double_t* wNN, Int_t a_1, Int_t a_2, Int_t a_3); voidTMVA::MethodCFMlpANN_Utils::Wini(); Double_tTMVA::MethodCFMlpANN_Utils::Ww_ref(const Double_t* wwNN, Int_t a_1, Int_t a_2) const; Double_t&TMVA::MethodCFMlpANN_Utils::Ww_ref(Double_t* wwNN, Int_t a_1, Int_t a_2). Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. vector<Int_t>*fClasst",MatchSource.WIKI,root/html532/TMVA__MethodCFMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCFMlpANN.html
https://root.cern/root/html532/TMVA__MethodCFMlpANN.html:21918,Testability,test,tested,21918,"ries. Function documentation; MethodCFMlpANN(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = ""3000:N-1:N-2"", TDirectory* theTargetDir = 0); standard constructor; option string: ""n_training_cycles:n_hidden_layers""; default is: n_training_cycles = 5000, n_layers = 4. * note that the number of hidden layers in the NN is:; n_hidden_layers = n_layers - 2. * since there is one input and one output layer. The number of; nodes (neurons) is predefined to be:; n_nodes[i] = nvars + 1 - i (where i=1..n_layers). with nvars being the number of variables used in the NN. Hence, the default case is: n_neurons(layer 1 (input)) : nvars; n_neurons(layer 2 (hidden)): nvars-1; n_neurons(layer 3 (hidden)): nvars-1; n_neurons(layer 4 (out)) : 2. This artificial neural network usually needs a relatively large; number of cycles to converge (8000 and more). Overtraining can; be efficienctly tested by comparing the signal and background; output of the NN for the events that were used for training and; an independent data sample (with equal properties). If the separation; performance is significantly better for the training sample, the; NN interprets statistical effects, and is hence overtrained. In; this case, the number of cycles should be reduced, or the size; of the training sample increased. MethodCFMlpANN(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL); constructor from weight file. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t ); CFMlpANN can handle classification with 2 classes. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options: NCycles=xx :the number of training cycles; HiddenLayser=""N-1,N-2"" :the specification of the hidden layers. void ProcessOptions(); decode the options in the option string. void Init( void ); default initialisation called by all constructors. ~MethodCFMlpANN( void )",MatchSource.WIKI,root/html532/TMVA__MethodCFMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCFMlpANN.html
https://root.cern/root/html532/TMVA__MethodCFMlpANN.html:1703,Usability,learn,learning,1703,"s. In between the input and output layers are a variable number; of k hidden layers with arbitrary numbers of neurons. (While the; structure of the input and output layers is determined by the problem, the; hidden layers can be configured by the user through the option string; of the method booking.) ; As indicated in the sketch, all neuron inputs to a layer are linear; combinations of the neuron output of the previous layer. The transfer; from input to output within a neuron is performed by means of an ""activation; function"". In general, the activation function of a neuron can be; zero (deactivated), one (linear), or non-linear. The above example uses; a sigmoid activation function. The transfer function of the output layer; is usually linear. As a consequence: an ANN without hidden layer should; give identical discrimination power as a linear discriminant analysis (Fisher).; In case of one hidden layer, the ANN computes a linear combination of; sigmoid. ; The learning method used by the CFMlpANN is only stochastic.; */; . Function Members (Methods); public:. virtual~MethodCFMlpANN(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidTMVA::MethodBase::CheckSetup(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::",MatchSource.WIKI,root/html532/TMVA__MethodCFMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCFMlpANN.html
https://root.cern/root/html532/TMVA__MethodCFMlpANN_Utils.html:736,Availability,avail,available,736,". TMVA::MethodCFMlpANN_Utils. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodCFMlpANN_Utils. class TMVA::MethodCFMlpANN_Utils. Implementation of Clermond-Ferrand artificial neural network. Reference for the original FORTRAN version ""mlpl3.F"":; Authors : J. Proriol and contributions from ALEPH-Clermont-Ferrand; Team members; Copyright: Laboratoire Physique Corpusculaire; Universite de Blaise Pascal, IN2P3/CNRS. Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~MethodCFMlpANN_Utils(); static TClass*Class(); virtual TClass*IsA() const; TMVA::MethodCFMlpANN_Utils&operator=(const TMVA::MethodCFMlpANN_Utils&); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). protected:. voidArret(const char* mot); voidCollectVar(Int_t* nvar, Int_t* class__, Double_t* xpg); voidCout(Int_t*, Double_t* xxx); voidCout2(Int_t*, Double_t* yyy); virtual Int_tDataInterface(Double_t*, Double_t*, Int_t*, Int_t*, Int_t*, Int_t*, Double_t*, Int_t*, Int_t*); voidEn_arriere(Int_t* ievent); voidEn_avant(Int_t* ievent); voidEn_avant2(Int_t* ievent); voidEntree_new(Int_t*, char*, Int_t* ntrain, Int_t* ntest, Int_t* numlayer, Int_t* nodes, Int_t* numcycle, Int_t); Double_tFdecroi(Int_t* i__); voidFoncf(Int_t* i__, Double_t* u, Double_t* f); voidGraphNN(Int_t* ilearn, Double_t*, Double_t*, char*, Int_t); voidInl(); voidInnit(char* det, Double_t* tout2, Double_t* tin2, Int_t); voidLecev2(Int_t* ktest, Double_t* tout2, Double_t* tin2); voidLeclearn(Int_t* ktest, Double_t* tout2, Double_t* tin2); voidOut(Int_t* iii, Int_t* maxcycle); Double_tSen3a(); voidSetLogger(TMVA::MsgLogger* l); voidTestNN(); voidTrain_nn(Double_t* tin2, Double_t*",MatchSource.WIKI,root/html532/TMVA__MethodCFMlpANN_Utils.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCFMlpANN_Utils.html
https://root.cern/root/html532/TMVA__MethodCFMlpANN_Utils.html:4563,Availability,error,error,4563,"ts to be added]. void Leclearn(Int_t* ktest, Double_t* tout2, Double_t* tin2); [smart comments to be added]. void En_arriere(Int_t* ievent); [smart comments to be added]. void Out(Int_t* iii, Int_t* maxcycle); write weights to file. void Innit(char* det, Double_t* tout2, Double_t* tin2, Int_t ); Initialization. void TestNN(); [smart comments to be added]. void Cout(Int_t* , Double_t* xxx); [smart comments to be added]. void Inl(); [smart comments to be added]. Double_t Fdecroi(Int_t* i__); [smart comments to be added]. void GraphNN(Int_t* ilearn, Double_t* , Double_t* , char* , Int_t ); [smart comments to be added]. Double_t Sen3a( void ); [smart comments to be added]. void Foncf(Int_t* i__, Double_t* u, Double_t* f); [needs to be checked]. void Cout2(Int_t* , Double_t* yyy); [smart comments to be added]. void Lecev2(Int_t* ktest, Double_t* tout2, Double_t* tin2); [smart comments to be added]. void En_avant2(Int_t* ievent); [smart comments to be added]. void Arret(const char* mot); fatal error occurred: stop execution. void CollectVar(Int_t* nvar, Int_t* class__, Double_t* xpg); // [smart comments to be added]; Int_t i__1;. Int_t DataInterface(Double_t* , Double_t* , Int_t* , Int_t* , Int_t* , Int_t* , Double_t* , Int_t* , Int_t* ). Double_t W_ref(const Double_t* wNN, Int_t a_1, Int_t a_2, Int_t a_3) const. Double_t& W_ref(Double_t* wNN, Int_t a_1, Int_t a_2, Int_t a_3). Double_t Ww_ref(const Double_t* wwNN, Int_t a_1, Int_t a_2) const. Double_t& Ww_ref(Double_t* wwNN, Int_t a_1, Int_t a_2). Double_t operator=(const TMVA::MethodCFMlpANN_Utils& ); { return val; }. void SetLogger(TMVA::MsgLogger* l); { fLogger = l; }. MsgLogger& ULog(); { if (fLogger) return *fLogger; return *(fLogger = new MsgLogger(""CFMLP_Utils"")); }. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: MethodCFMlpANN_Utils.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-12-02 14:28; This page has been automatically gener",MatchSource.WIKI,root/html532/TMVA__MethodCFMlpANN_Utils.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCFMlpANN_Utils.html
https://root.cern/root/html532/TMVA__MethodCFMlpANN_Utils.html:3273,Integrability,interface,interface,3273,"t_t a_3); voidWini(); Double_tWw_ref(const Double_t* wwNN, Int_t a_1, Int_t a_2) const; Double_t&Ww_ref(Double_t* wwNN, Int_t a_1, Int_t a_2). private:. TMVA::MsgLogger&ULog(). Data Members; protected:. TMVA::MethodCFMlpANN_Utils::fCost_1; TMVA::MethodCFMlpANN_Utils::fDel_1; TMVA::MethodCFMlpANN_Utils::fNeur_1; TMVA::MethodCFMlpANN_Utils::fParam_1; TMVA::MethodCFMlpANN_Utils::VARn2fVarn2_1; TMVA::MethodCFMlpANN_Utils::VARn2fVarn3_1; TMVA::MethodCFMlpANN_Utils::fVarn_1; static Int_tfg_0constant; static Int_tfg_100constant; static Int_tfg_999constant; static const char*fg_MethodNamemethod name for print; static Int_tfg_max_nNodes_maximum number of nodes per variable; static Int_tfg_max_nVar_static maximum number of input variables. private:. TMVA::MsgLogger*fLogger. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; ~MethodCFMlpANN_Utils(); destructor. void Train_nn(Double_t* tin2, Double_t* tout2, Int_t* ntrain, Int_t* ntest, Int_t* nvar2, Int_t* nlayer, Int_t* nodes, Int_t* ncycle); training interface - called from MethodCFMlpANN class object. void Entree_new(Int_t* , char* , Int_t* ntrain, Int_t* ntest, Int_t* numlayer, Int_t* nodes, Int_t* numcycle, Int_t ); first initialisation of ANN. void Wini(); [smart comments to be added]. void En_avant(Int_t* ievent); [smart comments to be added]. void Leclearn(Int_t* ktest, Double_t* tout2, Double_t* tin2); [smart comments to be added]. void En_arriere(Int_t* ievent); [smart comments to be added]. void Out(Int_t* iii, Int_t* maxcycle); write weights to file. void Innit(char* det, Double_t* tout2, Double_t* tin2, Int_t ); Initialization. void TestNN(); [smart comments to be added]. void Cout(Int_t* , Double_t* xxx); [smart comments to be added]. void Inl(); [smart comments to be added]. Double_t Fdecroi(Int_t* i__); [smart comments to be added]. void GraphNN(Int_t* ilearn, Double_t* , Double_t* , char* , Int_t ); [smart comments to be added]. Double_t Sen3a( void ); [smart comments to ",MatchSource.WIKI,root/html532/TMVA__MethodCFMlpANN_Utils.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCFMlpANN_Utils.html
https://root.cern/root/html532/TMVA__MethodCFMlpANN_Utils.html:2890,Modifiability,variab,variable,2890,", Double_t* tout2, Double_t* tin2, Int_t); voidLecev2(Int_t* ktest, Double_t* tout2, Double_t* tin2); voidLeclearn(Int_t* ktest, Double_t* tout2, Double_t* tin2); voidOut(Int_t* iii, Int_t* maxcycle); Double_tSen3a(); voidSetLogger(TMVA::MsgLogger* l); voidTestNN(); voidTrain_nn(Double_t* tin2, Double_t* tout2, Int_t* ntrain, Int_t* ntest, Int_t* nvar2, Int_t* nlayer, Int_t* nodes, Int_t* ncycle); Double_tW_ref(const Double_t* wNN, Int_t a_1, Int_t a_2, Int_t a_3) const; Double_t&W_ref(Double_t* wNN, Int_t a_1, Int_t a_2, Int_t a_3); voidWini(); Double_tWw_ref(const Double_t* wwNN, Int_t a_1, Int_t a_2) const; Double_t&Ww_ref(Double_t* wwNN, Int_t a_1, Int_t a_2). private:. TMVA::MsgLogger&ULog(). Data Members; protected:. TMVA::MethodCFMlpANN_Utils::fCost_1; TMVA::MethodCFMlpANN_Utils::fDel_1; TMVA::MethodCFMlpANN_Utils::fNeur_1; TMVA::MethodCFMlpANN_Utils::fParam_1; TMVA::MethodCFMlpANN_Utils::VARn2fVarn2_1; TMVA::MethodCFMlpANN_Utils::VARn2fVarn3_1; TMVA::MethodCFMlpANN_Utils::fVarn_1; static Int_tfg_0constant; static Int_tfg_100constant; static Int_tfg_999constant; static const char*fg_MethodNamemethod name for print; static Int_tfg_max_nNodes_maximum number of nodes per variable; static Int_tfg_max_nVar_static maximum number of input variables. private:. TMVA::MsgLogger*fLogger. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; ~MethodCFMlpANN_Utils(); destructor. void Train_nn(Double_t* tin2, Double_t* tout2, Int_t* ntrain, Int_t* ntest, Int_t* nvar2, Int_t* nlayer, Int_t* nodes, Int_t* ncycle); training interface - called from MethodCFMlpANN class object. void Entree_new(Int_t* , char* , Int_t* ntrain, Int_t* ntest, Int_t* numlayer, Int_t* nodes, Int_t* numcycle, Int_t ); first initialisation of ANN. void Wini(); [smart comments to be added]. void En_avant(Int_t* ievent); [smart comments to be added]. void Leclearn(Int_t* ktest, Double_t* tout2, Double_t* tin2); [smart comments to be added]. void En_arriere(Int_t* ieven",MatchSource.WIKI,root/html532/TMVA__MethodCFMlpANN_Utils.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCFMlpANN_Utils.html
https://root.cern/root/html532/TMVA__MethodCFMlpANN_Utils.html:2955,Modifiability,variab,variables,2955,", Double_t* tout2, Double_t* tin2, Int_t); voidLecev2(Int_t* ktest, Double_t* tout2, Double_t* tin2); voidLeclearn(Int_t* ktest, Double_t* tout2, Double_t* tin2); voidOut(Int_t* iii, Int_t* maxcycle); Double_tSen3a(); voidSetLogger(TMVA::MsgLogger* l); voidTestNN(); voidTrain_nn(Double_t* tin2, Double_t* tout2, Int_t* ntrain, Int_t* ntest, Int_t* nvar2, Int_t* nlayer, Int_t* nodes, Int_t* ncycle); Double_tW_ref(const Double_t* wNN, Int_t a_1, Int_t a_2, Int_t a_3) const; Double_t&W_ref(Double_t* wNN, Int_t a_1, Int_t a_2, Int_t a_3); voidWini(); Double_tWw_ref(const Double_t* wwNN, Int_t a_1, Int_t a_2) const; Double_t&Ww_ref(Double_t* wwNN, Int_t a_1, Int_t a_2). private:. TMVA::MsgLogger&ULog(). Data Members; protected:. TMVA::MethodCFMlpANN_Utils::fCost_1; TMVA::MethodCFMlpANN_Utils::fDel_1; TMVA::MethodCFMlpANN_Utils::fNeur_1; TMVA::MethodCFMlpANN_Utils::fParam_1; TMVA::MethodCFMlpANN_Utils::VARn2fVarn2_1; TMVA::MethodCFMlpANN_Utils::VARn2fVarn3_1; TMVA::MethodCFMlpANN_Utils::fVarn_1; static Int_tfg_0constant; static Int_tfg_100constant; static Int_tfg_999constant; static const char*fg_MethodNamemethod name for print; static Int_tfg_max_nNodes_maximum number of nodes per variable; static Int_tfg_max_nVar_static maximum number of input variables. private:. TMVA::MsgLogger*fLogger. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; ~MethodCFMlpANN_Utils(); destructor. void Train_nn(Double_t* tin2, Double_t* tout2, Int_t* ntrain, Int_t* ntest, Int_t* nvar2, Int_t* nlayer, Int_t* nodes, Int_t* ncycle); training interface - called from MethodCFMlpANN class object. void Entree_new(Int_t* , char* , Int_t* ntrain, Int_t* ntest, Int_t* numlayer, Int_t* nodes, Int_t* numcycle, Int_t ); first initialisation of ANN. void Wini(); [smart comments to be added]. void En_avant(Int_t* ievent); [smart comments to be added]. void Leclearn(Int_t* ktest, Double_t* tout2, Double_t* tin2); [smart comments to be added]. void En_arriere(Int_t* ieven",MatchSource.WIKI,root/html532/TMVA__MethodCFMlpANN_Utils.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCFMlpANN_Utils.html
https://root.cern/root/html532/TMVA__MethodCommittee.html:2837,Availability,error,error,2837," const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidDeclareOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const vector<Double_t>&GetBoostWeights() const; const vector<TMVA::IMethod*>&GetCommittee() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::Get",MatchSource.WIKI,root/html532/TMVA__MethodCommittee.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCommittee.html
https://root.cern/root/html532/TMVA__MethodCommittee.html:2921,Availability,error,error,2921,"= """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidDeclareOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const vector<Double_t>&GetBoostWeights() const; const vector<TMVA::IMethod*>&GetCommittee() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ie",MatchSource.WIKI,root/html532/TMVA__MethodCommittee.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCommittee.html
https://root.cern/root/html532/TMVA__MethodCommittee.html:17310,Availability,error,error,17310,"lassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. Double_tfBoostFactorntuple var: boost weight; TH1F*fBoostFactorHistweights applied in boosting; TStringfBoostTypestring specifying the boost type; vector<Double_t>fBoostWeightsthe weights applied in the individual boosts; vector<IMethod*>fCommitteethe collection of members; TH2F*fErrFractHisterror fraction vs member number; Double_tfErrorFractionntuple var: misclassification error fraction ; Int_tfITreentuple var: ith member; TStringfMemberOptionthe options for that method; TMVA::Types::EMVAfMemberTypethe MVA method to be boosted; TTree*fMonitorNtuplemonitoring ntuple; UInt_tfNMembersnumber of members requested; Int_tfNnodesntuple var: nNodes; Bool_tfUseMemberDecisionuse binary information from IsSignal; Bool_tfUseWeightedMembersin the committee weighted from AdaBoost; vector<Double_t>fVariableImportancethe relative importance of the different variables . Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodCommittee(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& dsi, const TString& theOption, TDirectory* theTargetDir = 0); constructor. MethodCommittee(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = 0); constructor for calculating Committee-MVA using previously generatad decision trees; the result of the previous training (the decision trees) are read in via the; weightfile. Make sure the ""theVariables"" cor",MatchSource.WIKI,root/html532/TMVA__MethodCommittee.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCommittee.html
https://root.cern/root/html532/TMVA__MethodCommittee.html:18996,Availability,avail,available,18996,"tion, TDirectory* theTargetDir = 0); constructor. MethodCommittee(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = 0); constructor for calculating Committee-MVA using previously generatad decision trees; the result of the previous training (the decision trees) are read in via the; weightfile. Make sure the ""theVariables"" correspond to the ones used in; creating the ""weight""-file. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); FDA can handle classification with 2 classes and regression with one regression-target. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options:; NMembers <string> number of members in the committee; UseMemberDecision <bool> use signal information from event (otherwise assume signal); UseWeightedMembers <bool> use weighted trees or simple average in classification from the forest. BoostType <string> boosting type; available values are: AdaBoost <default>; Bagging. void ProcessOptions(); process user options. void Init( void ); common initialisation with defaults for the Committee-Method. ~MethodCommittee( void ); destructor. void WriteStateToFile() const; Function to write options and weights to file. void Train( void ); training. Double_t Boost(TMVA::MethodBase* , UInt_t imember); apply the boosting alogrithim (the algorithm is selecte via the the ""option"" given; in the constructor. The return value is the boosting weight. Double_t AdaBoost(TMVA::MethodBase* ); the AdaBoost implementation.; a new training sample is generated by weighting; events that are misclassified by the decision tree. The weight; applied is w = (1-err)/err or more general:; w = ((1-err)/err)^beta; where err is the fracthin of misclassified events in the tree ( <0.5 assuming; demanding the that previous selection was better than random guessing); and ""beta"" beeing a free parameter (standard: beta = 1) that modifies the; boosting. D",MatchSource.WIKI,root/html532/TMVA__MethodCommittee.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCommittee.html
https://root.cern/root/html532/TMVA__MethodCommittee.html:21412,Integrability,message,message,21412,"sFromStream(istream& istr); read the state of the method from an input stream. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); return the MVA value (range [-1;1]) that classifies the; event.according to the majority vote from the total number of; decision trees; In the literature I found that people actually use the; weighted majority vote (using the boost weights) .. However I; did not see any improvement in doing so :(; --> this is currently switched off. void WriteMonitoringHistosToFile( void ); here we could write some histograms created during the processing; to the output file. vector< Double_t > GetVariableImportance(); return the relative variable importance, normalized to all; variables together having the importance 1. The importance in; evaluated as the total separation-gain that this variable had in; the decision trees (weighted by the number of events). Double_t GetVariableImportance(UInt_t ivar); return the variable importance. const TMVA::Ranking* CreateRanking(); computes ranking of input variables. void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". void ReadWeightsFromXML(void* ); {}. const std::vector<TMVA::IMethod*>& GetCommittee() const; accessors. { return fCommittee; }. const std::vector<Double_t>& GetBoostWeights() const; { return fBoostWeights; }. std::vector<IMethod*>& GetCommittee(); accessors. { return fCommittee; }. std::vector<Double_t>& GetBoostWeights(); { return fBoostWeights; }. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: MethodCommittee.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__MethodCommittee.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCommittee.html
https://root.cern/root/html532/TMVA__MethodCommittee.html:16301,Modifiability,variab,variables,16301,"&GetCommittee(); virtual voidInit(). Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. Double_tfBoostFactorntuple var: boost weight; TH1F*fBoostFactorHistweights applied in boosting; TStringfBoostTypestring specifying the boost type; vector<Double_t>fBoostWeightsthe weights applied in the individual boosts; vector<IMethod*>fCommitteethe collection of members; TH2F*fErrFractHisterror fraction vs member number; Double_tfErrorFractionntuple var: misclassification error fraction ; Int_tfITreentuple var: ith member; TStringfMemberOptionthe options for that method; TMVA::Types::EMVAfMemberTypethe MVA method to be boosted; TTree*fMonitorNtu",MatchSource.WIKI,root/html532/TMVA__MethodCommittee.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCommittee.html
https://root.cern/root/html532/TMVA__MethodCommittee.html:16490,Modifiability,variab,variable,16490,"&GetCommittee(); virtual voidInit(). Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. Double_tfBoostFactorntuple var: boost weight; TH1F*fBoostFactorHistweights applied in boosting; TStringfBoostTypestring specifying the boost type; vector<Double_t>fBoostWeightsthe weights applied in the individual boosts; vector<IMethod*>fCommitteethe collection of members; TH2F*fErrFractHisterror fraction vs member number; Double_tfErrorFractionntuple var: misclassification error fraction ; Int_tfITreentuple var: ith member; TStringfMemberOptionthe options for that method; TMVA::Types::EMVAfMemberTypethe MVA method to be boosted; TTree*fMonitorNtu",MatchSource.WIKI,root/html532/TMVA__MethodCommittee.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCommittee.html
https://root.cern/root/html532/TMVA__MethodCommittee.html:17788,Modifiability,variab,variables,17788,"lassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. Double_tfBoostFactorntuple var: boost weight; TH1F*fBoostFactorHistweights applied in boosting; TStringfBoostTypestring specifying the boost type; vector<Double_t>fBoostWeightsthe weights applied in the individual boosts; vector<IMethod*>fCommitteethe collection of members; TH2F*fErrFractHisterror fraction vs member number; Double_tfErrorFractionntuple var: misclassification error fraction ; Int_tfITreentuple var: ith member; TStringfMemberOptionthe options for that method; TMVA::Types::EMVAfMemberTypethe MVA method to be boosted; TTree*fMonitorNtuplemonitoring ntuple; UInt_tfNMembersnumber of members requested; Int_tfNnodesntuple var: nNodes; Bool_tfUseMemberDecisionuse binary information from IsSignal; Bool_tfUseWeightedMembersin the committee weighted from AdaBoost; vector<Double_t>fVariableImportancethe relative importance of the different variables . Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodCommittee(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& dsi, const TString& theOption, TDirectory* theTargetDir = 0); constructor. MethodCommittee(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = 0); constructor for calculating Committee-MVA using previously generatad decision trees; the result of the previous training (the decision trees) are read in via the; weightfile. Make sure the ""theVariables"" cor",MatchSource.WIKI,root/html532/TMVA__MethodCommittee.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCommittee.html
https://root.cern/root/html532/TMVA__MethodCommittee.html:20904,Modifiability,variab,variable,20904,"ng); and ""beta"" beeing a free parameter (standard: beta = 1) that modifies the; boosting. Double_t Bagging(UInt_t imember); call it Bootstrapping, re-sampling or whatever you like, in the end it is nothing; else but applying ""random boostweights"" to each event. void AddWeightsXMLTo(void* parent) const. void ReadWeightsFromStream(istream& istr); read the state of the method from an input stream. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); return the MVA value (range [-1;1]) that classifies the; event.according to the majority vote from the total number of; decision trees; In the literature I found that people actually use the; weighted majority vote (using the boost weights) .. However I; did not see any improvement in doing so :(; --> this is currently switched off. void WriteMonitoringHistosToFile( void ); here we could write some histograms created during the processing; to the output file. vector< Double_t > GetVariableImportance(); return the relative variable importance, normalized to all; variables together having the importance 1. The importance in; evaluated as the total separation-gain that this variable had in; the decision trees (weighted by the number of events). Double_t GetVariableImportance(UInt_t ivar); return the variable importance. const TMVA::Ranking* CreateRanking(); computes ranking of input variables. void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". void ReadWeightsFromXML(void* ); {}. const std::vector<TMVA::IMethod*>& GetCommittee() const; accessors. { return fCommittee; }. const std::vector<Double_t>& GetBoostWeights() const; { return fBoostWeights; }. std::vector<IMethod*>& GetCommittee(); accessors. { return fCommittee; }. std::vector<Double_t>& GetBoostWeights(); { return fBoostWeights; }. » Author: Andreas Hoecker, Joerg Ste",MatchSource.WIKI,root/html532/TMVA__MethodCommittee.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCommittee.html
https://root.cern/root/html532/TMVA__MethodCommittee.html:20944,Modifiability,variab,variables,20944,"ng); and ""beta"" beeing a free parameter (standard: beta = 1) that modifies the; boosting. Double_t Bagging(UInt_t imember); call it Bootstrapping, re-sampling or whatever you like, in the end it is nothing; else but applying ""random boostweights"" to each event. void AddWeightsXMLTo(void* parent) const. void ReadWeightsFromStream(istream& istr); read the state of the method from an input stream. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); return the MVA value (range [-1;1]) that classifies the; event.according to the majority vote from the total number of; decision trees; In the literature I found that people actually use the; weighted majority vote (using the boost weights) .. However I; did not see any improvement in doing so :(; --> this is currently switched off. void WriteMonitoringHistosToFile( void ); here we could write some histograms created during the processing; to the output file. vector< Double_t > GetVariableImportance(); return the relative variable importance, normalized to all; variables together having the importance 1. The importance in; evaluated as the total separation-gain that this variable had in; the decision trees (weighted by the number of events). Double_t GetVariableImportance(UInt_t ivar); return the variable importance. const TMVA::Ranking* CreateRanking(); computes ranking of input variables. void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". void ReadWeightsFromXML(void* ); {}. const std::vector<TMVA::IMethod*>& GetCommittee() const; accessors. { return fCommittee; }. const std::vector<Double_t>& GetBoostWeights() const; { return fBoostWeights; }. std::vector<IMethod*>& GetCommittee(); accessors. { return fCommittee; }. std::vector<Double_t>& GetBoostWeights(); { return fBoostWeights; }. » Author: Andreas Hoecker, Joerg Ste",MatchSource.WIKI,root/html532/TMVA__MethodCommittee.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCommittee.html
https://root.cern/root/html532/TMVA__MethodCommittee.html:21056,Modifiability,variab,variable,21056,"g, re-sampling or whatever you like, in the end it is nothing; else but applying ""random boostweights"" to each event. void AddWeightsXMLTo(void* parent) const. void ReadWeightsFromStream(istream& istr); read the state of the method from an input stream. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); return the MVA value (range [-1;1]) that classifies the; event.according to the majority vote from the total number of; decision trees; In the literature I found that people actually use the; weighted majority vote (using the boost weights) .. However I; did not see any improvement in doing so :(; --> this is currently switched off. void WriteMonitoringHistosToFile( void ); here we could write some histograms created during the processing; to the output file. vector< Double_t > GetVariableImportance(); return the relative variable importance, normalized to all; variables together having the importance 1. The importance in; evaluated as the total separation-gain that this variable had in; the decision trees (weighted by the number of events). Double_t GetVariableImportance(UInt_t ivar); return the variable importance. const TMVA::Ranking* CreateRanking(); computes ranking of input variables. void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". void ReadWeightsFromXML(void* ); {}. const std::vector<TMVA::IMethod*>& GetCommittee() const; accessors. { return fCommittee; }. const std::vector<Double_t>& GetBoostWeights() const; { return fBoostWeights; }. std::vector<IMethod*>& GetCommittee(); accessors. { return fCommittee; }. std::vector<Double_t>& GetBoostWeights(); { return fBoostWeights; }. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: MethodCommittee.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated",MatchSource.WIKI,root/html532/TMVA__MethodCommittee.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCommittee.html
https://root.cern/root/html532/TMVA__MethodCommittee.html:21184,Modifiability,variab,variable,21184,"ch event. void AddWeightsXMLTo(void* parent) const. void ReadWeightsFromStream(istream& istr); read the state of the method from an input stream. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); return the MVA value (range [-1;1]) that classifies the; event.according to the majority vote from the total number of; decision trees; In the literature I found that people actually use the; weighted majority vote (using the boost weights) .. However I; did not see any improvement in doing so :(; --> this is currently switched off. void WriteMonitoringHistosToFile( void ); here we could write some histograms created during the processing; to the output file. vector< Double_t > GetVariableImportance(); return the relative variable importance, normalized to all; variables together having the importance 1. The importance in; evaluated as the total separation-gain that this variable had in; the decision trees (weighted by the number of events). Double_t GetVariableImportance(UInt_t ivar); return the variable importance. const TMVA::Ranking* CreateRanking(); computes ranking of input variables. void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". void ReadWeightsFromXML(void* ); {}. const std::vector<TMVA::IMethod*>& GetCommittee() const; accessors. { return fCommittee; }. const std::vector<Double_t>& GetBoostWeights() const; { return fBoostWeights; }. std::vector<IMethod*>& GetCommittee(); accessors. { return fCommittee; }. std::vector<Double_t>& GetBoostWeights(); { return fBoostWeights; }. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: MethodCommittee.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the doc",MatchSource.WIKI,root/html532/TMVA__MethodCommittee.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCommittee.html
https://root.cern/root/html532/TMVA__MethodCommittee.html:21269,Modifiability,variab,variables,21269,"sFromStream(istream& istr); read the state of the method from an input stream. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); return the MVA value (range [-1;1]) that classifies the; event.according to the majority vote from the total number of; decision trees; In the literature I found that people actually use the; weighted majority vote (using the boost weights) .. However I; did not see any improvement in doing so :(; --> this is currently switched off. void WriteMonitoringHistosToFile( void ); here we could write some histograms created during the processing; to the output file. vector< Double_t > GetVariableImportance(); return the relative variable importance, normalized to all; variables together having the importance 1. The importance in; evaluated as the total separation-gain that this variable had in; the decision trees (weighted by the number of events). Double_t GetVariableImportance(UInt_t ivar); return the variable importance. const TMVA::Ranking* CreateRanking(); computes ranking of input variables. void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". void ReadWeightsFromXML(void* ); {}. const std::vector<TMVA::IMethod*>& GetCommittee() const; accessors. { return fCommittee; }. const std::vector<Double_t>& GetBoostWeights() const; { return fBoostWeights; }. std::vector<IMethod*>& GetCommittee(); accessors. { return fCommittee; }. std::vector<Double_t>& GetBoostWeights(); { return fBoostWeights; }. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: MethodCommittee.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__MethodCommittee.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCommittee.html
https://root.cern/root/html532/TMVA__MethodCommittee.html:12318,Performance,tune,tuneParameters,12318,"voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int",MatchSource.WIKI,root/html532/TMVA__MethodCommittee.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCommittee.html
https://root.cern/root/html532/TMVA__MethodCommittee.html:21618,Security,access,accessors,21618,"sFromStream(istream& istr); read the state of the method from an input stream. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); return the MVA value (range [-1;1]) that classifies the; event.according to the majority vote from the total number of; decision trees; In the literature I found that people actually use the; weighted majority vote (using the boost weights) .. However I; did not see any improvement in doing so :(; --> this is currently switched off. void WriteMonitoringHistosToFile( void ); here we could write some histograms created during the processing; to the output file. vector< Double_t > GetVariableImportance(); return the relative variable importance, normalized to all; variables together having the importance 1. The importance in; evaluated as the total separation-gain that this variable had in; the decision trees (weighted by the number of events). Double_t GetVariableImportance(UInt_t ivar); return the variable importance. const TMVA::Ranking* CreateRanking(); computes ranking of input variables. void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". void ReadWeightsFromXML(void* ); {}. const std::vector<TMVA::IMethod*>& GetCommittee() const; accessors. { return fCommittee; }. const std::vector<Double_t>& GetBoostWeights() const; { return fBoostWeights; }. std::vector<IMethod*>& GetCommittee(); accessors. { return fCommittee; }. std::vector<Double_t>& GetBoostWeights(); { return fBoostWeights; }. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: MethodCommittee.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__MethodCommittee.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCommittee.html
https://root.cern/root/html532/TMVA__MethodCommittee.html:21773,Security,access,accessors,21773,"sFromStream(istream& istr); read the state of the method from an input stream. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); return the MVA value (range [-1;1]) that classifies the; event.according to the majority vote from the total number of; decision trees; In the literature I found that people actually use the; weighted majority vote (using the boost weights) .. However I; did not see any improvement in doing so :(; --> this is currently switched off. void WriteMonitoringHistosToFile( void ); here we could write some histograms created during the processing; to the output file. vector< Double_t > GetVariableImportance(); return the relative variable importance, normalized to all; variables together having the importance 1. The importance in; evaluated as the total separation-gain that this variable had in; the decision trees (weighted by the number of events). Double_t GetVariableImportance(UInt_t ivar); return the variable importance. const TMVA::Ranking* CreateRanking(); computes ranking of input variables. void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". void ReadWeightsFromXML(void* ); {}. const std::vector<TMVA::IMethod*>& GetCommittee() const; accessors. { return fCommittee; }. const std::vector<Double_t>& GetBoostWeights() const; { return fBoostWeights; }. std::vector<IMethod*>& GetCommittee(); accessors. { return fCommittee; }. std::vector<Double_t>& GetBoostWeights(); { return fBoostWeights; }. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: MethodCommittee.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__MethodCommittee.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCommittee.html
https://root.cern/root/html532/TMVA__MethodCommittee.html:12120,Testability,test,testTime,12120,"am& out, Option_t* option = """"); virtual voidTMVA::MethodBase::SetAnalysisType(TMVA::Types::EAnalysisType type); voidTMVA::MethodBase::SetBaseDir(TDirectory* methodDir); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObj",MatchSource.WIKI,root/html532/TMVA__MethodCommittee.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCommittee.html
https://root.cern/root/html532/TMVA__MethodCommittee.html:15991,Testability,test,testing,15991,":MethodBase::SetWeightFileDir(TString fileDir); voidTMVA::MethodBase::SetWeightFileName(TString); voidTMVA::MethodBase::Statistics(TMVA::Types::ETreeType treeType, const TString& theVarName, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&); Bool_tTMVA::MethodBase::TxtWeightsOnly() const; Bool_tTMVA::MethodBase::Verbose() const; voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. Double_tAdaBoost(TMVA::MethodBase*); Double_tBagging(UInt_t imember); vector<Double_t>&GetBoostWeights(); vector<IMethod*>&GetCommittee(); virtual voidInit(). Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. Double_tfBoostFactorn",MatchSource.WIKI,root/html532/TMVA__MethodCommittee.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCommittee.html
https://root.cern/root/html532/TMVA__MethodCommittee.html:920,Usability,simpl,simple,920,". TMVA::MethodCommittee. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodCommittee. class TMVA::MethodCommittee: public TMVA::MethodBase. Boosting:. the idea behind the boosting is, that signal events from the training; sample, that end up in a background node (and vice versa) are given a; larger weight than events that are in the correct leave node. This; results in a re-weighed training event sample, with which then a new; decision tree can be developed. The boosting can be applied several; times (typically 100-500 times) and one ends up with a set of decision; trees (a forest). Bagging:. In this particular variant of the Boosted Decision Trees the boosting; is not done on the basis of previous training results, but by a simple; stochasitc re-sampling of the initial training event sample. Function Members (Methods); public:. virtual~MethodCommittee(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; Double_tBoost(TMVA::MethodBase*, UInt_t imember); virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidTMVA::MethodBase::CheckSetup(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::",MatchSource.WIKI,root/html532/TMVA__MethodCommittee.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCommittee.html
https://root.cern/root/html532/TMVA__MethodCommittee.html:18912,Usability,simpl,simple,18912,"nt variables . Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodCommittee(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& dsi, const TString& theOption, TDirectory* theTargetDir = 0); constructor. MethodCommittee(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = 0); constructor for calculating Committee-MVA using previously generatad decision trees; the result of the previous training (the decision trees) are read in via the; weightfile. Make sure the ""theVariables"" correspond to the ones used in; creating the ""weight""-file. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); FDA can handle classification with 2 classes and regression with one regression-target. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options:; NMembers <string> number of members in the committee; UseMemberDecision <bool> use signal information from event (otherwise assume signal); UseWeightedMembers <bool> use weighted trees or simple average in classification from the forest. BoostType <string> boosting type; available values are: AdaBoost <default>; Bagging. void ProcessOptions(); process user options. void Init( void ); common initialisation with defaults for the Committee-Method. ~MethodCommittee( void ); destructor. void WriteStateToFile() const; Function to write options and weights to file. void Train( void ); training. Double_t Boost(TMVA::MethodBase* , UInt_t imember); apply the boosting alogrithim (the algorithm is selecte via the the ""option"" given; in the constructor. The return value is the boosting weight. Double_t AdaBoost(TMVA::MethodBase* ); the AdaBoost implementation.; a new training sample is generated by weighting; events that are misclassified by the decision tree. The weight; applied is w = (1-err)/err or more general:; w = ((1-err)/err)^beta; where err is the fr",MatchSource.WIKI,root/html532/TMVA__MethodCommittee.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCommittee.html
https://root.cern/root/html532/TMVA__MethodCompositeBase.html:715,Availability,avail,available,715,". TMVA::MethodCompositeBase. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodCompositeBase. class TMVA::MethodCompositeBase: public TMVA::MethodBase. This class is virtual class meant to combine more than one classifier; together. The training of the classifiers is done by classes that are; derived from this one, while the saving and loading of weights file; and the evaluation is done here. Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~MethodCompositeBase(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidTMVA::MethodBase::CheckSetup(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::Dista",MatchSource.WIKI,root/html532/TMVA__MethodCompositeBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCompositeBase.html
https://root.cern/root/html532/TMVA__MethodCompositeBase.html:2484,Availability,error,error,2484,"t::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; TMVA::IMethod*GetCurrentMethod(); virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt) const; const TMVA::Event*TMVA::MethodBase::G",MatchSource.WIKI,root/html532/TMVA__MethodCompositeBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCompositeBase.html
https://root.cern/root/html532/TMVA__MethodCompositeBase.html:2568,Availability,error,error,2568,"able(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; TMVA::IMethod*GetCurrentMethod(); virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt, TMVA::Types::ETreeType type) const; const vector<TMVA::Event*",MatchSource.WIKI,root/html532/TMVA__MethodCompositeBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCompositeBase.html
https://root.cern/root/html532/TMVA__MethodCompositeBase.html:15692,Modifiability,variab,variables,15692," public:. enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; Int_tfMethodIndex; vector<Double_t>fMethodWeight; vector<IMethod*>fMethodsvector of all classifiers; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMVA::IMethod* GetMethod(const TString& title) const; returns pointer to MVA that corresponds to given method title. TMVA::IMethod* GetMethod(const Int_t index) const; returns pointer to MVA that corresponds to given method index. void AddWeightsXMLTo(void* parent) const. ~MethodCompositeBase( void ); delete methods. void ReadWeightsFromXML(void* wghtnode); XML streamer. void ReadWeightsFromStream(istream& istr); text s",MatchSource.WIKI,root/html532/TMVA__MethodCompositeBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCompositeBase.html
https://root.cern/root/html532/TMVA__MethodCompositeBase.html:15982,Modifiability,variab,variable,15982," public:. enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; Int_tfMethodIndex; vector<Double_t>fMethodWeight; vector<IMethod*>fMethodsvector of all classifiers; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMVA::IMethod* GetMethod(const TString& title) const; returns pointer to MVA that corresponds to given method title. TMVA::IMethod* GetMethod(const Int_t index) const; returns pointer to MVA that corresponds to given method index. void AddWeightsXMLTo(void* parent) const. ~MethodCompositeBase( void ); delete methods. void ReadWeightsFromXML(void* wghtnode); XML streamer. void ReadWeightsFromStream(istream& istr); text s",MatchSource.WIKI,root/html532/TMVA__MethodCompositeBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCompositeBase.html
https://root.cern/root/html532/TMVA__MethodCompositeBase.html:523,Performance,load,loading,523,". TMVA::MethodCompositeBase. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodCompositeBase. class TMVA::MethodCompositeBase: public TMVA::MethodBase. This class is virtual class meant to combine more than one classifier; together. The training of the classifiers is done by classes that are; derived from this one, while the saving and loading of weights file; and the evaluation is done here. Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~MethodCompositeBase(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidTMVA::MethodBase::CheckSetup(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::Dista",MatchSource.WIKI,root/html532/TMVA__MethodCompositeBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCompositeBase.html
https://root.cern/root/html532/TMVA__MethodCompositeBase.html:11641,Performance,tune,tuneParameters,11641,"voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int",MatchSource.WIKI,root/html532/TMVA__MethodCompositeBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCompositeBase.html
https://root.cern/root/html532/TMVA__MethodCompositeBase.html:17047,Performance,perform,performs,17047,"t_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMVA::IMethod* GetMethod(const TString& title) const; returns pointer to MVA that corresponds to given method title. TMVA::IMethod* GetMethod(const Int_t index) const; returns pointer to MVA that corresponds to given method index. void AddWeightsXMLTo(void* parent) const. ~MethodCompositeBase( void ); delete methods. void ReadWeightsFromXML(void* wghtnode); XML streamer. void ReadWeightsFromStream(istream& istr); text streamer. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); return composite MVA response. void Train(); performs classifier training. const Ranking* CreateRanking(); create ranking. UInt_t GetMethodIndex(); { return fMethodIndex; }. IMethod* GetLastMethod(); { return fMethods.back(); }. IMethod* GetPreviousMethod(); { return (fMethodIndex>0)?fMethods[fMethodIndex-1]:0; }. IMethod* GetCurrentMethod(); { return (fMethodIndex>0)?fMethods[fMethodIndex]:0; }. void DeclareOptions(). void ProcessOptions(). » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss, Or Cohen » Copyright (c) 2005: *; » Last changed: root/tmva $Id: MethodCompositeBase.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-12-02 14:28; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__MethodCompositeBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCompositeBase.html
https://root.cern/root/html532/TMVA__MethodCompositeBase.html:11443,Testability,test,testTime,11443,"am& out, Option_t* option = """"); virtual voidTMVA::MethodBase::SetAnalysisType(TMVA::Types::EAnalysisType type); voidTMVA::MethodBase::SetBaseDir(TDirectory* methodDir); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObj",MatchSource.WIKI,root/html532/TMVA__MethodCompositeBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCompositeBase.html
https://root.cern/root/html532/TMVA__MethodCompositeBase.html:15382,Testability,test,testing,15382," *const err, Double_t *const errUpper); virtual voidProcessOptions(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::MethodBase::SetNormalised(Bool_t norm); voidTMVA::MethodBase::SetWeightFileDir(TString fileDir); voidTMVA::MethodBase::SetWeightFileName(TString); voidTMVA::MethodBase::Statistics(TMVA::Types::ETreeType treeType, const TString& theVarName, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&); Bool_tTMVA::MethodBase::TxtWeightsOnly() const; Bool_tTMVA::MethodBase::Verbose() const; voidTMVA::Configurable::WriteOptionsReferenceToFile(). Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; Int_tfMethodIndex; vector<Double_t>fMethodWeight; vector<IMethod*>fMethodsvector of all classifiers; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regre",MatchSource.WIKI,root/html532/TMVA__MethodCompositeBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCompositeBase.html
https://root.cern/root/html532/TMVA__MethodCuts.html:4332,Availability,error,error,4332,"g*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidDeclareOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; static TMVA::MethodCuts*DynamicCast(TMVA::IMethod* method); virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual Double_tEstimatorFunction(vector<Double_t>&); Double_tEstimatorFunction(Int_t ievt1, Int_t ievt2); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; Double_tGetCuts(Double_t effS, vector<Double_t>& cutMin, vector<Double_t>& cutMax) const; Double_tGetCuts(Double_t effS, Double_t* cutMin, Double_t* cutMax) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tGetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t&); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) con",MatchSource.WIKI,root/html532/TMVA__MethodCuts.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCuts.html
https://root.cern/root/html532/TMVA__MethodCuts.html:4416,Availability,error,error,4416,"MVA::MethodBase::DataInfo() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidDeclareOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; static TMVA::MethodCuts*DynamicCast(TMVA::IMethod* method); virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual Double_tEstimatorFunction(vector<Double_t>&); Double_tEstimatorFunction(Int_t ievt1, Int_t ievt2); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; Double_tGetCuts(Double_t effS, vector<Double_t>& cutMin, vector<Double_t>& cutMax) const; Double_tGetCuts(Double_t effS, Double_t* cutMin, Double_t* cutMax) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tGetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t&); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt) const; const TMVA::E",MatchSource.WIKI,root/html532/TMVA__MethodCuts.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCuts.html
https://root.cern/root/html532/TMVA__MethodCuts.html:21783,Availability,avail,available,21783,"*>*fVarHistSreference histograms (signal); vector<TH1*>*fVarHistS_smoothsmoothed reference histograms (signal) ; vector<PDF*>*fVarPdfBreference PDFs (background); vector<PDF*>*fVarPdfSreference PDFs (signal). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodCuts(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = ""MC:150:10000:"", TDirectory* theTargetFile = 0); standard constructor. MethodCuts(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL); construction from weight file. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); Cuts can only handle classification with 2 classes. void Init( void ); default initialisation called by all constructors. ~MethodCuts( void ); destructor. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options:; Method <string> Minimisation method; available values are: MC Monte Carlo <default>; GA Genetic Algorithm; SA Simulated annealing. EffMethod <string> Efficiency selection method; available values are: EffSel <default>; EffPDF. VarProp <string> Property of variable 1 for the MC method (taking precedence over the; globale setting. The same values as for the global option are available. Variables 1..10 can be; set this way. CutRangeMin/Max <float> user-defined ranges in which cuts are varied. void ProcessOptions(); process user options; sanity check, do not allow the input variables to be normalised, because this; only creates problems when interpreting the cuts. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); cut evaluation: returns 1.0 if event passed, 0.0 otherwise. void PrintCuts(Double_t effS) const; print cuts. Double_t GetCuts(Double_t effS, Double_t* cutMin, Double_t* cutMax) const; retrieve cut values for given signal efficiency; assume vector of correct size !!. Double_",MatchSource.WIKI,root/html532/TMVA__MethodCuts.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCuts.html
https://root.cern/root/html532/TMVA__MethodCuts.html:21925,Availability,avail,available,21925,"PDF*>*fVarPdfSreference PDFs (signal). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodCuts(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = ""MC:150:10000:"", TDirectory* theTargetFile = 0); standard constructor. MethodCuts(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL); construction from weight file. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); Cuts can only handle classification with 2 classes. void Init( void ); default initialisation called by all constructors. ~MethodCuts( void ); destructor. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options:; Method <string> Minimisation method; available values are: MC Monte Carlo <default>; GA Genetic Algorithm; SA Simulated annealing. EffMethod <string> Efficiency selection method; available values are: EffSel <default>; EffPDF. VarProp <string> Property of variable 1 for the MC method (taking precedence over the; globale setting. The same values as for the global option are available. Variables 1..10 can be; set this way. CutRangeMin/Max <float> user-defined ranges in which cuts are varied. void ProcessOptions(); process user options; sanity check, do not allow the input variables to be normalised, because this; only creates problems when interpreting the cuts. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); cut evaluation: returns 1.0 if event passed, 0.0 otherwise. void PrintCuts(Double_t effS) const; print cuts. Double_t GetCuts(Double_t effS, Double_t* cutMin, Double_t* cutMax) const; retrieve cut values for given signal efficiency; assume vector of correct size !!. Double_t GetCuts(Double_t effS, vector<Double_t>& cutMin, vector<Double_t>& cutMax) const; retrieve cut values for given signal efficiency. void Train( void ); training method: ",MatchSource.WIKI,root/html532/TMVA__MethodCuts.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCuts.html
https://root.cern/root/html532/TMVA__MethodCuts.html:22122,Availability,avail,available,22122,"methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = ""MC:150:10000:"", TDirectory* theTargetFile = 0); standard constructor. MethodCuts(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL); construction from weight file. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); Cuts can only handle classification with 2 classes. void Init( void ); default initialisation called by all constructors. ~MethodCuts( void ); destructor. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options:; Method <string> Minimisation method; available values are: MC Monte Carlo <default>; GA Genetic Algorithm; SA Simulated annealing. EffMethod <string> Efficiency selection method; available values are: EffSel <default>; EffPDF. VarProp <string> Property of variable 1 for the MC method (taking precedence over the; globale setting. The same values as for the global option are available. Variables 1..10 can be; set this way. CutRangeMin/Max <float> user-defined ranges in which cuts are varied. void ProcessOptions(); process user options; sanity check, do not allow the input variables to be normalised, because this; only creates problems when interpreting the cuts. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); cut evaluation: returns 1.0 if event passed, 0.0 otherwise. void PrintCuts(Double_t effS) const; print cuts. Double_t GetCuts(Double_t effS, Double_t* cutMin, Double_t* cutMax) const; retrieve cut values for given signal efficiency; assume vector of correct size !!. Double_t GetCuts(Double_t effS, vector<Double_t>& cutMin, vector<Double_t>& cutMax) const; retrieve cut values for given signal efficiency. void Train( void ); training method: here the cuts are optimised for the training sample. void TestClassification(); nothing to test. Double_t EstimatorFunction(Int_t ievt1, Int_t ievt2); for full event scan. Double_t",MatchSource.WIKI,root/html532/TMVA__MethodCuts.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCuts.html
https://root.cern/root/html532/TMVA__MethodCuts.html:26575,Availability,avail,available,26575,"nd efficiency (rejection) versus; signal efficiency plot (first call of this function); - the function returns the signal efficiency at background efficiency; indicated in theString. ""theString"" must have two entries:; [0]: ""Efficiency""; [1]: the value of background efficiency at which the signal efficiency; is to be returned. void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". MethodCuts* DynamicCast(TMVA::IMethod* method); this is a workaround which is necessary since CINT is not capable of handling dynamic casts. { return dynamic_cast<MethodCuts*>(method); }. Double_t GetSeparation(TH1* , TH1* ) const; also overwrite --> not computed for cuts. { return -1; }. Double_t GetSeparation(TMVA::PDF* = 0, TMVA::PDF* = 0) const; { return -1; }. Double_t GetSignificance( void ); { return -1; }. Double_t GetmuTransform(TTree* ); { return -1; }. Double_t GetRarity(Double_t , TMVA::Types::ESBType ) const; rarity distributions (signal or background (default) is uniform in [0,1]). { return 0; }. void SetTestSignalEfficiency(Double_t effS); { fTestSignalEff = effS; }. const Ranking* CreateRanking(); ranking of input variables (not available for cuts). { return 0; }. void CheckSetup(); no check of options at this place. {}. void MatchParsToCuts( const std::vector<Double_t>&, Double_t*, Double_t* ); the definition of fit parameters can be different from the actual; cut requirements; these functions provide the matching. » Author: Andreas Hoecker, Matt Jachowski, Peter Speckmayer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: MethodCuts.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__MethodCuts.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCuts.html
https://root.cern/root/html532/TMVA__MethodCuts.html:24690,Energy Efficiency,monitor,monitoring,24690,"uble_t>& , Double_t** , Double_t** , Int_t ibin); translate the cuts into parameters (obsolete function). void MatchCutsToPars(vector<Double_t>& , Double_t* , Double_t* ); translates cuts into parameters. void GetEffsfromPDFs(Double_t* cutMin, Double_t* cutMax, Double_t& effS, Double_t& effB); compute signal and background efficiencies from PDFs; for given cut sample. void GetEffsfromSelection(Double_t* cutMin, Double_t* cutMax, Double_t& effS, Double_t& effB); compute signal and background efficiencies from event counting; for given cut sample. void CreateVariablePDFs( void ); for PDF method: create efficiency reference histograms and PDFs. void ReadWeightsFromStream(istream& i); read the cuts from stream. void AddWeightsXMLTo(void* parent) const; create XML description for LD classification and regression; (for arbitrary number of output classes/targets). void ReadWeightsFromXML(void* wghtnode); read coefficients from xml weight file. void WriteMonitoringHistosToFile( void ); write histograms and PDFs to file for monitoring purposes. Double_t GetTrainingEfficiency(const TString& ); - overloaded function to create background efficiency (rejection) versus; signal efficiency plot (first call of this function); - the function returns the signal efficiency at background efficiency; indicated in theString. ""theString"" must have two entries:; [0]: ""Efficiency""; [1]: the value of background efficiency at which the signal efficiency; is to be returned. Double_t GetEfficiency(const TString& , TMVA::Types::ETreeType , Double_t& ); - overloaded function to create background efficiency (rejection) versus; signal efficiency plot (first call of this function); - the function returns the signal efficiency at background efficiency; indicated in theString. ""theString"" must have two entries:; [0]: ""Efficiency""; [1]: the value of background efficiency at which the signal efficiency; is to be returned. void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier ",MatchSource.WIKI,root/html532/TMVA__MethodCuts.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCuts.html
https://root.cern/root/html532/TMVA__MethodCuts.html:1394,Integrability,depend,depending,1394," efficiency for given background; efficiency, applying rectangular minimum and maximum requirements.; ; Also implemented is a ""decorrelate/diagonlized cuts approach"",; which improves over the uncorrelated cuts ansatz by; transforming linearly the input variables into a diagonal space,; using the square-root of the covariance matrix.; . Other optimisation criteria, such as maximising the signal significance-; squared, S^2/(S+B), with S and B being the signal and background yields,; correspond to a particular point in the optimised background rejection; versus signal efficiency curve. This working point requires the knowledge; of the expected yields, which is not the case in general. Note also that; for rare signals, Poissonian statistics should be used, which modifies; the significance criterion.; . The rectangular cut of a volume in the variable space is performed using; a binary tree to sort the training events. This provides a significant; reduction in computing time (up to several orders of magnitudes, depending; on the complexity of the problem at hand).; ; Technically, optimisation is achieved in TMVA by two methods:; ; Monte Carlo generation using uniform priors for the lower cut value,; and the cut width, thrown within the variable ranges.; A Genetic Algorithm (GA) searches for the optimal (""fittest"") cut sample.; The GA is configurable by many external settings through the option; string. For difficult cases (such as many variables), some tuning; may be necessary to achieve satisfying results; . Attempts to use Minuit fits (Simplex ot Migrad) instead have not shown; superior results, and often failed due to convergence at local minima.; . The tests we have performed so far showed that in generic applications,; the GA is superior to MC sampling, and hence GA is the default method.; It is worthwhile trying both anyway.; Decorrelated (or ""diagonalized"") Cuts. See class description for Method Likelihood for a detailed explanation.; . Function Members (Methods); ",MatchSource.WIKI,root/html532/TMVA__MethodCuts.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCuts.html
https://root.cern/root/html532/TMVA__MethodCuts.html:25708,Integrability,message,message,25708,"oring purposes. Double_t GetTrainingEfficiency(const TString& ); - overloaded function to create background efficiency (rejection) versus; signal efficiency plot (first call of this function); - the function returns the signal efficiency at background efficiency; indicated in theString. ""theString"" must have two entries:; [0]: ""Efficiency""; [1]: the value of background efficiency at which the signal efficiency; is to be returned. Double_t GetEfficiency(const TString& , TMVA::Types::ETreeType , Double_t& ); - overloaded function to create background efficiency (rejection) versus; signal efficiency plot (first call of this function); - the function returns the signal efficiency at background efficiency; indicated in theString. ""theString"" must have two entries:; [0]: ""Efficiency""; [1]: the value of background efficiency at which the signal efficiency; is to be returned. void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". MethodCuts* DynamicCast(TMVA::IMethod* method); this is a workaround which is necessary since CINT is not capable of handling dynamic casts. { return dynamic_cast<MethodCuts*>(method); }. Double_t GetSeparation(TH1* , TH1* ) const; also overwrite --> not computed for cuts. { return -1; }. Double_t GetSeparation(TMVA::PDF* = 0, TMVA::PDF* = 0) const; { return -1; }. Double_t GetSignificance( void ); { return -1; }. Double_t GetmuTransform(TTree* ); { return -1; }. Double_t GetRarity(Double_t , TMVA::Types::ESBType ) const; rarity distributions (signal or background (default) is uniform in [0,1]). { return 0; }. void SetTestSignalEfficiency(Double_t effS); { fTestSignalEff = effS; }. const Ranking* CreateRanking(); ranking of input variables (not available for cuts). { return 0; }. void CheckSetup(); no check of options at this place. {}. void MatchParsToCuts( cons",MatchSource.WIKI,root/html532/TMVA__MethodCuts.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCuts.html
https://root.cern/root/html532/TMVA__MethodCuts.html:626,Modifiability,variab,variables,626,". TMVA::MethodCuts. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodCuts. class TMVA::MethodCuts: public TMVA::MethodBase, public TMVA::IFitterTarget. Multivariate optimisation of signal efficiency for given background; efficiency, applying rectangular minimum and maximum requirements.; ; Also implemented is a ""decorrelate/diagonlized cuts approach"",; which improves over the uncorrelated cuts ansatz by; transforming linearly the input variables into a diagonal space,; using the square-root of the covariance matrix.; . Other optimisation criteria, such as maximising the signal significance-; squared, S^2/(S+B), with S and B being the signal and background yields,; correspond to a particular point in the optimised background rejection; versus signal efficiency curve. This working point requires the knowledge; of the expected yields, which is not the case in general. Note also that; for rare signals, Poissonian statistics should be used, which modifies; the significance criterion.; . The rectangular cut of a volume in the variable space is performed using; a binary tree to sort the training events. This provides a significant; reduction in computing time (up to several orders of magnitudes, depending; on the complexity of the problem at hand).; ; Technically, optimisation is achieved in TMVA by two methods:; ; Monte Carlo generation using uniform priors for the lower cut value,; and the cut width, thrown within the variable ranges.; A Genetic Algorithm (GA) searches for the optimal (""fittest"") cut sample.; The GA is configurable by many external settings through the option; string. For difficult cases (such as many variables), some tuning; may be necessary to achieve satisfying results; . Attempts to use Minuit fits (Simplex ot Migrad) instead have not shown; superior results, and often",MatchSource.WIKI,root/html532/TMVA__MethodCuts.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCuts.html
https://root.cern/root/html532/TMVA__MethodCuts.html:1222,Modifiability,variab,variable,1222," » TMVA::MethodCuts. class TMVA::MethodCuts: public TMVA::MethodBase, public TMVA::IFitterTarget. Multivariate optimisation of signal efficiency for given background; efficiency, applying rectangular minimum and maximum requirements.; ; Also implemented is a ""decorrelate/diagonlized cuts approach"",; which improves over the uncorrelated cuts ansatz by; transforming linearly the input variables into a diagonal space,; using the square-root of the covariance matrix.; . Other optimisation criteria, such as maximising the signal significance-; squared, S^2/(S+B), with S and B being the signal and background yields,; correspond to a particular point in the optimised background rejection; versus signal efficiency curve. This working point requires the knowledge; of the expected yields, which is not the case in general. Note also that; for rare signals, Poissonian statistics should be used, which modifies; the significance criterion.; . The rectangular cut of a volume in the variable space is performed using; a binary tree to sort the training events. This provides a significant; reduction in computing time (up to several orders of magnitudes, depending; on the complexity of the problem at hand).; ; Technically, optimisation is achieved in TMVA by two methods:; ; Monte Carlo generation using uniform priors for the lower cut value,; and the cut width, thrown within the variable ranges.; A Genetic Algorithm (GA) searches for the optimal (""fittest"") cut sample.; The GA is configurable by many external settings through the option; string. For difficult cases (such as many variables), some tuning; may be necessary to achieve satisfying results; . Attempts to use Minuit fits (Simplex ot Migrad) instead have not shown; superior results, and often failed due to convergence at local minima.; . The tests we have performed so far showed that in generic applications,; the GA is superior to MC sampling, and hence GA is the default method.; It is worthwhile trying both anyway.; Decorrelat",MatchSource.WIKI,root/html532/TMVA__MethodCuts.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCuts.html
https://root.cern/root/html532/TMVA__MethodCuts.html:1623,Modifiability,variab,variable,1623,"ich improves over the uncorrelated cuts ansatz by; transforming linearly the input variables into a diagonal space,; using the square-root of the covariance matrix.; . Other optimisation criteria, such as maximising the signal significance-; squared, S^2/(S+B), with S and B being the signal and background yields,; correspond to a particular point in the optimised background rejection; versus signal efficiency curve. This working point requires the knowledge; of the expected yields, which is not the case in general. Note also that; for rare signals, Poissonian statistics should be used, which modifies; the significance criterion.; . The rectangular cut of a volume in the variable space is performed using; a binary tree to sort the training events. This provides a significant; reduction in computing time (up to several orders of magnitudes, depending; on the complexity of the problem at hand).; ; Technically, optimisation is achieved in TMVA by two methods:; ; Monte Carlo generation using uniform priors for the lower cut value,; and the cut width, thrown within the variable ranges.; A Genetic Algorithm (GA) searches for the optimal (""fittest"") cut sample.; The GA is configurable by many external settings through the option; string. For difficult cases (such as many variables), some tuning; may be necessary to achieve satisfying results; . Attempts to use Minuit fits (Simplex ot Migrad) instead have not shown; superior results, and often failed due to convergence at local minima.; . The tests we have performed so far showed that in generic applications,; the GA is superior to MC sampling, and hence GA is the default method.; It is worthwhile trying both anyway.; Decorrelated (or ""diagonalized"") Cuts. See class description for Method Likelihood for a detailed explanation.; . Function Members (Methods); public:. virtual~MethodCuts(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::A",MatchSource.WIKI,root/html532/TMVA__MethodCuts.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCuts.html
https://root.cern/root/html532/TMVA__MethodCuts.html:1726,Modifiability,config,configurable,1726,"ising the signal significance-; squared, S^2/(S+B), with S and B being the signal and background yields,; correspond to a particular point in the optimised background rejection; versus signal efficiency curve. This working point requires the knowledge; of the expected yields, which is not the case in general. Note also that; for rare signals, Poissonian statistics should be used, which modifies; the significance criterion.; . The rectangular cut of a volume in the variable space is performed using; a binary tree to sort the training events. This provides a significant; reduction in computing time (up to several orders of magnitudes, depending; on the complexity of the problem at hand).; ; Technically, optimisation is achieved in TMVA by two methods:; ; Monte Carlo generation using uniform priors for the lower cut value,; and the cut width, thrown within the variable ranges.; A Genetic Algorithm (GA) searches for the optimal (""fittest"") cut sample.; The GA is configurable by many external settings through the option; string. For difficult cases (such as many variables), some tuning; may be necessary to achieve satisfying results; . Attempts to use Minuit fits (Simplex ot Migrad) instead have not shown; superior results, and often failed due to convergence at local minima.; . The tests we have performed so far showed that in generic applications,; the GA is superior to MC sampling, and hence GA is the default method.; It is worthwhile trying both anyway.; Decorrelated (or ""diagonalized"") Cuts. See class description for Method Likelihood for a detailed explanation.; . Function Members (Methods); public:. virtual~MethodCuts(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBas",MatchSource.WIKI,root/html532/TMVA__MethodCuts.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCuts.html
https://root.cern/root/html532/TMVA__MethodCuts.html:1827,Modifiability,variab,variables,1827,"und yields,; correspond to a particular point in the optimised background rejection; versus signal efficiency curve. This working point requires the knowledge; of the expected yields, which is not the case in general. Note also that; for rare signals, Poissonian statistics should be used, which modifies; the significance criterion.; . The rectangular cut of a volume in the variable space is performed using; a binary tree to sort the training events. This provides a significant; reduction in computing time (up to several orders of magnitudes, depending; on the complexity of the problem at hand).; ; Technically, optimisation is achieved in TMVA by two methods:; ; Monte Carlo generation using uniform priors for the lower cut value,; and the cut width, thrown within the variable ranges.; A Genetic Algorithm (GA) searches for the optimal (""fittest"") cut sample.; The GA is configurable by many external settings through the option; string. For difficult cases (such as many variables), some tuning; may be necessary to achieve satisfying results; . Attempts to use Minuit fits (Simplex ot Migrad) instead have not shown; superior results, and often failed due to convergence at local minima.; . The tests we have performed so far showed that in generic applications,; the GA is superior to MC sampling, and hence GA is the default method.; It is worthwhile trying both anyway.; Decorrelated (or ""diagonalized"") Cuts. See class description for Method Likelihood for a detailed explanation.; . Function Members (Methods); public:. virtual~MethodCuts(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckFor",MatchSource.WIKI,root/html532/TMVA__MethodCuts.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCuts.html
https://root.cern/root/html532/TMVA__MethodCuts.html:18442,Modifiability,variab,variables,18442,"eMax; kForceSmart; };; enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one; static const Double_tfgMaxAbsCutVal. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. TString*fAllVarsIwhat to do with variables; TMVA::BinarySearchTree*fBinaryTreeB; TMVA::BinarySearchTree*fBinaryTreeS; Double_t**fCutMaxmaximum requirement; Double_t**fCutMinminimum requirement; vector<Interval*>fCutRangeallowed ranges for cut optimisation; Double_t*fCutRangeMaxmaximum of allowed cut range; Double_t*fCutRangeMinminimum of allowed cut range; TH1*fEffBvsSLocalintermediate eff. background versus eff signal histo; TMVA::MethodCuts::EEffMethodfEffMethodchosen efficiency calculation method; TStringfEffMethodSchosen efficiency calculation ",MatchSource.WIKI,root/html532/TMVA__MethodCuts.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCuts.html
https://root.cern/root/html532/TMVA__MethodCuts.html:18631,Modifiability,variab,variable,18631,"eMax; kForceSmart; };; enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one; static const Double_tfgMaxAbsCutVal. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. TString*fAllVarsIwhat to do with variables; TMVA::BinarySearchTree*fBinaryTreeB; TMVA::BinarySearchTree*fBinaryTreeS; Double_t**fCutMaxmaximum requirement; Double_t**fCutMinminimum requirement; vector<Interval*>fCutRangeallowed ranges for cut optimisation; Double_t*fCutRangeMaxmaximum of allowed cut range; Double_t*fCutRangeMinminimum of allowed cut range; TH1*fEffBvsSLocalintermediate eff. background versus eff signal histo; TMVA::MethodCuts::EEffMethodfEffMethodchosen efficiency calculation method; TStringfEffMethodSchosen efficiency calculation ",MatchSource.WIKI,root/html532/TMVA__MethodCuts.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCuts.html
https://root.cern/root/html532/TMVA__MethodCuts.html:19106,Modifiability,variab,variables,19106,"--> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. TString*fAllVarsIwhat to do with variables; TMVA::BinarySearchTree*fBinaryTreeB; TMVA::BinarySearchTree*fBinaryTreeS; Double_t**fCutMaxmaximum requirement; Double_t**fCutMinminimum requirement; vector<Interval*>fCutRangeallowed ranges for cut optimisation; Double_t*fCutRangeMaxmaximum of allowed cut range; Double_t*fCutRangeMinminimum of allowed cut range; TH1*fEffBvsSLocalintermediate eff. background versus eff signal histo; TMVA::MethodCuts::EEffMethodfEffMethodchosen efficiency calculation method; TStringfEffMethodSchosen efficiency calculation method (string); Double_tfEffRefreference efficiency; Double_tfEffSMaxused to test optimized signal efficiency; Double_tfEffSMinused to test optimized signal efficiency; TMVA::MethodCuts::EFitMethodTypefFitMethodchosen fit method; TStringfFitMethodSchosen fit method (string); vector<EFitParameters>*fFitParamsvector for series of fit methods; vector<Double_t>*fMeanBmeans of variables (background); vector<Double_t>*fMeanSmeans of variables (signal); Bool_tfNegEffWarningflag risen in case of negative efficiency warning; Int_tfNparnumber of parameters in fit (default: 2*Nvar); TRandom*fRandomrandom generator for MC optimisation method; ve",MatchSource.WIKI,root/html532/TMVA__MethodCuts.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCuts.html
https://root.cern/root/html532/TMVA__MethodCuts.html:20003,Modifiability,variab,variables,20003,"m requirement; Double_t**fCutMinminimum requirement; vector<Interval*>fCutRangeallowed ranges for cut optimisation; Double_t*fCutRangeMaxmaximum of allowed cut range; Double_t*fCutRangeMinminimum of allowed cut range; TH1*fEffBvsSLocalintermediate eff. background versus eff signal histo; TMVA::MethodCuts::EEffMethodfEffMethodchosen efficiency calculation method; TStringfEffMethodSchosen efficiency calculation method (string); Double_tfEffRefreference efficiency; Double_tfEffSMaxused to test optimized signal efficiency; Double_tfEffSMinused to test optimized signal efficiency; TMVA::MethodCuts::EFitMethodTypefFitMethodchosen fit method; TStringfFitMethodSchosen fit method (string); vector<EFitParameters>*fFitParamsvector for series of fit methods; vector<Double_t>*fMeanBmeans of variables (background); vector<Double_t>*fMeanSmeans of variables (signal); Bool_tfNegEffWarningflag risen in case of negative efficiency warning; Int_tfNparnumber of parameters in fit (default: 2*Nvar); TRandom*fRandomrandom generator for MC optimisation method; vector<Int_t>*fRangeSignused to match cuts to fit parameters (and vice versa); vector<Double_t>*fRmsBRMSs of variables (background); vector<Double_t>*fRmsSRMSs of variables (signal); Double_tfTestSignalEffused to test optimized signal efficiency; Double_t*fTmpCutMaxtemporary maximum requirement; Double_t*fTmpCutMintemporary minimum requirement; vector<TH1*>*fVarHistBreference histograms (background); vector<TH1*>*fVarHistB_smoothsmoothed reference histograms (background); vector<TH1*>*fVarHistSreference histograms (signal); vector<TH1*>*fVarHistS_smoothsmoothed reference histograms (signal) ; vector<PDF*>*fVarPdfBreference PDFs (background); vector<PDF*>*fVarPdfSreference PDFs (signal). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodCuts(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = ""MC:150:10000:"", TDirectory* theTargetFile",MatchSource.WIKI,root/html532/TMVA__MethodCuts.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCuts.html
https://root.cern/root/html532/TMVA__MethodCuts.html:20059,Modifiability,variab,variables,20059,"m requirement; Double_t**fCutMinminimum requirement; vector<Interval*>fCutRangeallowed ranges for cut optimisation; Double_t*fCutRangeMaxmaximum of allowed cut range; Double_t*fCutRangeMinminimum of allowed cut range; TH1*fEffBvsSLocalintermediate eff. background versus eff signal histo; TMVA::MethodCuts::EEffMethodfEffMethodchosen efficiency calculation method; TStringfEffMethodSchosen efficiency calculation method (string); Double_tfEffRefreference efficiency; Double_tfEffSMaxused to test optimized signal efficiency; Double_tfEffSMinused to test optimized signal efficiency; TMVA::MethodCuts::EFitMethodTypefFitMethodchosen fit method; TStringfFitMethodSchosen fit method (string); vector<EFitParameters>*fFitParamsvector for series of fit methods; vector<Double_t>*fMeanBmeans of variables (background); vector<Double_t>*fMeanSmeans of variables (signal); Bool_tfNegEffWarningflag risen in case of negative efficiency warning; Int_tfNparnumber of parameters in fit (default: 2*Nvar); TRandom*fRandomrandom generator for MC optimisation method; vector<Int_t>*fRangeSignused to match cuts to fit parameters (and vice versa); vector<Double_t>*fRmsBRMSs of variables (background); vector<Double_t>*fRmsSRMSs of variables (signal); Double_tfTestSignalEffused to test optimized signal efficiency; Double_t*fTmpCutMaxtemporary maximum requirement; Double_t*fTmpCutMintemporary minimum requirement; vector<TH1*>*fVarHistBreference histograms (background); vector<TH1*>*fVarHistB_smoothsmoothed reference histograms (background); vector<TH1*>*fVarHistSreference histograms (signal); vector<TH1*>*fVarHistS_smoothsmoothed reference histograms (signal) ; vector<PDF*>*fVarPdfBreference PDFs (background); vector<PDF*>*fVarPdfSreference PDFs (signal). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodCuts(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = ""MC:150:10000:"", TDirectory* theTargetFile",MatchSource.WIKI,root/html532/TMVA__MethodCuts.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCuts.html
https://root.cern/root/html532/TMVA__MethodCuts.html:20376,Modifiability,variab,variables,20376,"m requirement; Double_t**fCutMinminimum requirement; vector<Interval*>fCutRangeallowed ranges for cut optimisation; Double_t*fCutRangeMaxmaximum of allowed cut range; Double_t*fCutRangeMinminimum of allowed cut range; TH1*fEffBvsSLocalintermediate eff. background versus eff signal histo; TMVA::MethodCuts::EEffMethodfEffMethodchosen efficiency calculation method; TStringfEffMethodSchosen efficiency calculation method (string); Double_tfEffRefreference efficiency; Double_tfEffSMaxused to test optimized signal efficiency; Double_tfEffSMinused to test optimized signal efficiency; TMVA::MethodCuts::EFitMethodTypefFitMethodchosen fit method; TStringfFitMethodSchosen fit method (string); vector<EFitParameters>*fFitParamsvector for series of fit methods; vector<Double_t>*fMeanBmeans of variables (background); vector<Double_t>*fMeanSmeans of variables (signal); Bool_tfNegEffWarningflag risen in case of negative efficiency warning; Int_tfNparnumber of parameters in fit (default: 2*Nvar); TRandom*fRandomrandom generator for MC optimisation method; vector<Int_t>*fRangeSignused to match cuts to fit parameters (and vice versa); vector<Double_t>*fRmsBRMSs of variables (background); vector<Double_t>*fRmsSRMSs of variables (signal); Double_tfTestSignalEffused to test optimized signal efficiency; Double_t*fTmpCutMaxtemporary maximum requirement; Double_t*fTmpCutMintemporary minimum requirement; vector<TH1*>*fVarHistBreference histograms (background); vector<TH1*>*fVarHistB_smoothsmoothed reference histograms (background); vector<TH1*>*fVarHistSreference histograms (signal); vector<TH1*>*fVarHistS_smoothsmoothed reference histograms (signal) ; vector<PDF*>*fVarPdfBreference PDFs (background); vector<PDF*>*fVarPdfSreference PDFs (signal). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodCuts(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = ""MC:150:10000:"", TDirectory* theTargetFile",MatchSource.WIKI,root/html532/TMVA__MethodCuts.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCuts.html
https://root.cern/root/html532/TMVA__MethodCuts.html:20430,Modifiability,variab,variables,20430,"m requirement; Double_t**fCutMinminimum requirement; vector<Interval*>fCutRangeallowed ranges for cut optimisation; Double_t*fCutRangeMaxmaximum of allowed cut range; Double_t*fCutRangeMinminimum of allowed cut range; TH1*fEffBvsSLocalintermediate eff. background versus eff signal histo; TMVA::MethodCuts::EEffMethodfEffMethodchosen efficiency calculation method; TStringfEffMethodSchosen efficiency calculation method (string); Double_tfEffRefreference efficiency; Double_tfEffSMaxused to test optimized signal efficiency; Double_tfEffSMinused to test optimized signal efficiency; TMVA::MethodCuts::EFitMethodTypefFitMethodchosen fit method; TStringfFitMethodSchosen fit method (string); vector<EFitParameters>*fFitParamsvector for series of fit methods; vector<Double_t>*fMeanBmeans of variables (background); vector<Double_t>*fMeanSmeans of variables (signal); Bool_tfNegEffWarningflag risen in case of negative efficiency warning; Int_tfNparnumber of parameters in fit (default: 2*Nvar); TRandom*fRandomrandom generator for MC optimisation method; vector<Int_t>*fRangeSignused to match cuts to fit parameters (and vice versa); vector<Double_t>*fRmsBRMSs of variables (background); vector<Double_t>*fRmsSRMSs of variables (signal); Double_tfTestSignalEffused to test optimized signal efficiency; Double_t*fTmpCutMaxtemporary maximum requirement; Double_t*fTmpCutMintemporary minimum requirement; vector<TH1*>*fVarHistBreference histograms (background); vector<TH1*>*fVarHistB_smoothsmoothed reference histograms (background); vector<TH1*>*fVarHistSreference histograms (signal); vector<TH1*>*fVarHistS_smoothsmoothed reference histograms (signal) ; vector<PDF*>*fVarPdfBreference PDFs (background); vector<PDF*>*fVarPdfSreference PDFs (signal). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodCuts(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = ""MC:150:10000:"", TDirectory* theTargetFile",MatchSource.WIKI,root/html532/TMVA__MethodCuts.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCuts.html
https://root.cern/root/html532/TMVA__MethodCuts.html:22002,Modifiability,variab,variable,22002,"ries. Function documentation; MethodCuts(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = ""MC:150:10000:"", TDirectory* theTargetFile = 0); standard constructor. MethodCuts(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL); construction from weight file. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); Cuts can only handle classification with 2 classes. void Init( void ); default initialisation called by all constructors. ~MethodCuts( void ); destructor. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options:; Method <string> Minimisation method; available values are: MC Monte Carlo <default>; GA Genetic Algorithm; SA Simulated annealing. EffMethod <string> Efficiency selection method; available values are: EffSel <default>; EffPDF. VarProp <string> Property of variable 1 for the MC method (taking precedence over the; globale setting. The same values as for the global option are available. Variables 1..10 can be; set this way. CutRangeMin/Max <float> user-defined ranges in which cuts are varied. void ProcessOptions(); process user options; sanity check, do not allow the input variables to be normalised, because this; only creates problems when interpreting the cuts. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); cut evaluation: returns 1.0 if event passed, 0.0 otherwise. void PrintCuts(Double_t effS) const; print cuts. Double_t GetCuts(Double_t effS, Double_t* cutMin, Double_t* cutMax) const; retrieve cut values for given signal efficiency; assume vector of correct size !!. Double_t GetCuts(Double_t effS, vector<Double_t>& cutMin, vector<Double_t>& cutMax) const; retrieve cut values for given signal efficiency. void Train( void ); training method: here the cuts are optimised for the training sample. void TestClassification(); nothing to test. Dou",MatchSource.WIKI,root/html532/TMVA__MethodCuts.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCuts.html
https://root.cern/root/html532/TMVA__MethodCuts.html:22323,Modifiability,variab,variables,22323,"TargetDir = NULL); construction from weight file. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); Cuts can only handle classification with 2 classes. void Init( void ); default initialisation called by all constructors. ~MethodCuts( void ); destructor. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options:; Method <string> Minimisation method; available values are: MC Monte Carlo <default>; GA Genetic Algorithm; SA Simulated annealing. EffMethod <string> Efficiency selection method; available values are: EffSel <default>; EffPDF. VarProp <string> Property of variable 1 for the MC method (taking precedence over the; globale setting. The same values as for the global option are available. Variables 1..10 can be; set this way. CutRangeMin/Max <float> user-defined ranges in which cuts are varied. void ProcessOptions(); process user options; sanity check, do not allow the input variables to be normalised, because this; only creates problems when interpreting the cuts. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); cut evaluation: returns 1.0 if event passed, 0.0 otherwise. void PrintCuts(Double_t effS) const; print cuts. Double_t GetCuts(Double_t effS, Double_t* cutMin, Double_t* cutMax) const; retrieve cut values for given signal efficiency; assume vector of correct size !!. Double_t GetCuts(Double_t effS, vector<Double_t>& cutMin, vector<Double_t>& cutMax) const; retrieve cut values for given signal efficiency. void Train( void ); training method: here the cuts are optimised for the training sample. void TestClassification(); nothing to test. Double_t EstimatorFunction(Int_t ievt1, Int_t ievt2); for full event scan. Double_t EstimatorFunction(vector<Double_t>& ); returns estimator for ""cut fitness"" used by GA. Double_t ComputeEstimator(vector<Double_t>& ); returns estimator for ""cut fitness"" used by GA; there are two requirements:; 1) the sign",MatchSource.WIKI,root/html532/TMVA__MethodCuts.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCuts.html
https://root.cern/root/html532/TMVA__MethodCuts.html:26560,Modifiability,variab,variables,26560,"nd efficiency (rejection) versus; signal efficiency plot (first call of this function); - the function returns the signal efficiency at background efficiency; indicated in theString. ""theString"" must have two entries:; [0]: ""Efficiency""; [1]: the value of background efficiency at which the signal efficiency; is to be returned. void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". MethodCuts* DynamicCast(TMVA::IMethod* method); this is a workaround which is necessary since CINT is not capable of handling dynamic casts. { return dynamic_cast<MethodCuts*>(method); }. Double_t GetSeparation(TH1* , TH1* ) const; also overwrite --> not computed for cuts. { return -1; }. Double_t GetSeparation(TMVA::PDF* = 0, TMVA::PDF* = 0) const; { return -1; }. Double_t GetSignificance( void ); { return -1; }. Double_t GetmuTransform(TTree* ); { return -1; }. Double_t GetRarity(Double_t , TMVA::Types::ESBType ) const; rarity distributions (signal or background (default) is uniform in [0,1]). { return 0; }. void SetTestSignalEfficiency(Double_t effS); { fTestSignalEff = effS; }. const Ranking* CreateRanking(); ranking of input variables (not available for cuts). { return 0; }. void CheckSetup(); no check of options at this place. {}. void MatchParsToCuts( const std::vector<Double_t>&, Double_t*, Double_t* ); the definition of fit parameters can be different from the actual; cut requirements; these functions provide the matching. » Author: Andreas Hoecker, Matt Jachowski, Peter Speckmayer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: MethodCuts.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__MethodCuts.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCuts.html
https://root.cern/root/html532/TMVA__MethodCuts.html:1240,Performance,perform,performed,1240," » TMVA::MethodCuts. class TMVA::MethodCuts: public TMVA::MethodBase, public TMVA::IFitterTarget. Multivariate optimisation of signal efficiency for given background; efficiency, applying rectangular minimum and maximum requirements.; ; Also implemented is a ""decorrelate/diagonlized cuts approach"",; which improves over the uncorrelated cuts ansatz by; transforming linearly the input variables into a diagonal space,; using the square-root of the covariance matrix.; . Other optimisation criteria, such as maximising the signal significance-; squared, S^2/(S+B), with S and B being the signal and background yields,; correspond to a particular point in the optimised background rejection; versus signal efficiency curve. This working point requires the knowledge; of the expected yields, which is not the case in general. Note also that; for rare signals, Poissonian statistics should be used, which modifies; the significance criterion.; . The rectangular cut of a volume in the variable space is performed using; a binary tree to sort the training events. This provides a significant; reduction in computing time (up to several orders of magnitudes, depending; on the complexity of the problem at hand).; ; Technically, optimisation is achieved in TMVA by two methods:; ; Monte Carlo generation using uniform priors for the lower cut value,; and the cut width, thrown within the variable ranges.; A Genetic Algorithm (GA) searches for the optimal (""fittest"") cut sample.; The GA is configurable by many external settings through the option; string. For difficult cases (such as many variables), some tuning; may be necessary to achieve satisfying results; . Attempts to use Minuit fits (Simplex ot Migrad) instead have not shown; superior results, and often failed due to convergence at local minima.; . The tests we have performed so far showed that in generic applications,; the GA is superior to MC sampling, and hence GA is the default method.; It is worthwhile trying both anyway.; Decorrelat",MatchSource.WIKI,root/html532/TMVA__MethodCuts.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCuts.html
https://root.cern/root/html532/TMVA__MethodCuts.html:2066,Performance,perform,performed,2066," should be used, which modifies; the significance criterion.; . The rectangular cut of a volume in the variable space is performed using; a binary tree to sort the training events. This provides a significant; reduction in computing time (up to several orders of magnitudes, depending; on the complexity of the problem at hand).; ; Technically, optimisation is achieved in TMVA by two methods:; ; Monte Carlo generation using uniform priors for the lower cut value,; and the cut width, thrown within the variable ranges.; A Genetic Algorithm (GA) searches for the optimal (""fittest"") cut sample.; The GA is configurable by many external settings through the option; string. For difficult cases (such as many variables), some tuning; may be necessary to achieve satisfying results; . Attempts to use Minuit fits (Simplex ot Migrad) instead have not shown; superior results, and often failed due to convergence at local minima.; . The tests we have performed so far showed that in generic applications,; the GA is superior to MC sampling, and hence GA is the default method.; It is worthwhile trying both anyway.; Decorrelated (or ""diagonalized"") Cuts. See class description for Method Likelihood for a detailed explanation.; . Function Members (Methods); public:. virtual~MethodCuts(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidCheckSetup(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* ",MatchSource.WIKI,root/html532/TMVA__MethodCuts.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCuts.html
https://root.cern/root/html532/TMVA__MethodCuts.html:13828,Performance,tune,tuneParameters,13828,"oidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidSetTestSignalEfficiency(Double_t effS); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int",MatchSource.WIKI,root/html532/TMVA__MethodCuts.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCuts.html
https://root.cern/root/html532/TMVA__MethodCuts.html:19710,Performance,optimiz,optimized,19710,"m requirement; Double_t**fCutMinminimum requirement; vector<Interval*>fCutRangeallowed ranges for cut optimisation; Double_t*fCutRangeMaxmaximum of allowed cut range; Double_t*fCutRangeMinminimum of allowed cut range; TH1*fEffBvsSLocalintermediate eff. background versus eff signal histo; TMVA::MethodCuts::EEffMethodfEffMethodchosen efficiency calculation method; TStringfEffMethodSchosen efficiency calculation method (string); Double_tfEffRefreference efficiency; Double_tfEffSMaxused to test optimized signal efficiency; Double_tfEffSMinused to test optimized signal efficiency; TMVA::MethodCuts::EFitMethodTypefFitMethodchosen fit method; TStringfFitMethodSchosen fit method (string); vector<EFitParameters>*fFitParamsvector for series of fit methods; vector<Double_t>*fMeanBmeans of variables (background); vector<Double_t>*fMeanSmeans of variables (signal); Bool_tfNegEffWarningflag risen in case of negative efficiency warning; Int_tfNparnumber of parameters in fit (default: 2*Nvar); TRandom*fRandomrandom generator for MC optimisation method; vector<Int_t>*fRangeSignused to match cuts to fit parameters (and vice versa); vector<Double_t>*fRmsBRMSs of variables (background); vector<Double_t>*fRmsSRMSs of variables (signal); Double_tfTestSignalEffused to test optimized signal efficiency; Double_t*fTmpCutMaxtemporary maximum requirement; Double_t*fTmpCutMintemporary minimum requirement; vector<TH1*>*fVarHistBreference histograms (background); vector<TH1*>*fVarHistB_smoothsmoothed reference histograms (background); vector<TH1*>*fVarHistSreference histograms (signal); vector<TH1*>*fVarHistS_smoothsmoothed reference histograms (signal) ; vector<PDF*>*fVarPdfBreference PDFs (background); vector<PDF*>*fVarPdfSreference PDFs (signal). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodCuts(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = ""MC:150:10000:"", TDirectory* theTargetFile",MatchSource.WIKI,root/html532/TMVA__MethodCuts.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCuts.html
https://root.cern/root/html532/TMVA__MethodCuts.html:19768,Performance,optimiz,optimized,19768,"m requirement; Double_t**fCutMinminimum requirement; vector<Interval*>fCutRangeallowed ranges for cut optimisation; Double_t*fCutRangeMaxmaximum of allowed cut range; Double_t*fCutRangeMinminimum of allowed cut range; TH1*fEffBvsSLocalintermediate eff. background versus eff signal histo; TMVA::MethodCuts::EEffMethodfEffMethodchosen efficiency calculation method; TStringfEffMethodSchosen efficiency calculation method (string); Double_tfEffRefreference efficiency; Double_tfEffSMaxused to test optimized signal efficiency; Double_tfEffSMinused to test optimized signal efficiency; TMVA::MethodCuts::EFitMethodTypefFitMethodchosen fit method; TStringfFitMethodSchosen fit method (string); vector<EFitParameters>*fFitParamsvector for series of fit methods; vector<Double_t>*fMeanBmeans of variables (background); vector<Double_t>*fMeanSmeans of variables (signal); Bool_tfNegEffWarningflag risen in case of negative efficiency warning; Int_tfNparnumber of parameters in fit (default: 2*Nvar); TRandom*fRandomrandom generator for MC optimisation method; vector<Int_t>*fRangeSignused to match cuts to fit parameters (and vice versa); vector<Double_t>*fRmsBRMSs of variables (background); vector<Double_t>*fRmsSRMSs of variables (signal); Double_tfTestSignalEffused to test optimized signal efficiency; Double_t*fTmpCutMaxtemporary maximum requirement; Double_t*fTmpCutMintemporary minimum requirement; vector<TH1*>*fVarHistBreference histograms (background); vector<TH1*>*fVarHistB_smoothsmoothed reference histograms (background); vector<TH1*>*fVarHistSreference histograms (signal); vector<TH1*>*fVarHistS_smoothsmoothed reference histograms (signal) ; vector<PDF*>*fVarPdfBreference PDFs (background); vector<PDF*>*fVarPdfSreference PDFs (signal). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodCuts(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = ""MC:150:10000:"", TDirectory* theTargetFile",MatchSource.WIKI,root/html532/TMVA__MethodCuts.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCuts.html
https://root.cern/root/html532/TMVA__MethodCuts.html:20485,Performance,optimiz,optimized,20485,"m requirement; Double_t**fCutMinminimum requirement; vector<Interval*>fCutRangeallowed ranges for cut optimisation; Double_t*fCutRangeMaxmaximum of allowed cut range; Double_t*fCutRangeMinminimum of allowed cut range; TH1*fEffBvsSLocalintermediate eff. background versus eff signal histo; TMVA::MethodCuts::EEffMethodfEffMethodchosen efficiency calculation method; TStringfEffMethodSchosen efficiency calculation method (string); Double_tfEffRefreference efficiency; Double_tfEffSMaxused to test optimized signal efficiency; Double_tfEffSMinused to test optimized signal efficiency; TMVA::MethodCuts::EFitMethodTypefFitMethodchosen fit method; TStringfFitMethodSchosen fit method (string); vector<EFitParameters>*fFitParamsvector for series of fit methods; vector<Double_t>*fMeanBmeans of variables (background); vector<Double_t>*fMeanSmeans of variables (signal); Bool_tfNegEffWarningflag risen in case of negative efficiency warning; Int_tfNparnumber of parameters in fit (default: 2*Nvar); TRandom*fRandomrandom generator for MC optimisation method; vector<Int_t>*fRangeSignused to match cuts to fit parameters (and vice versa); vector<Double_t>*fRmsBRMSs of variables (background); vector<Double_t>*fRmsSRMSs of variables (signal); Double_tfTestSignalEffused to test optimized signal efficiency; Double_t*fTmpCutMaxtemporary maximum requirement; Double_t*fTmpCutMintemporary minimum requirement; vector<TH1*>*fVarHistBreference histograms (background); vector<TH1*>*fVarHistB_smoothsmoothed reference histograms (background); vector<TH1*>*fVarHistSreference histograms (signal); vector<TH1*>*fVarHistS_smoothsmoothed reference histograms (signal) ; vector<PDF*>*fVarPdfBreference PDFs (background); vector<PDF*>*fVarPdfSreference PDFs (signal). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodCuts(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = ""MC:150:10000:"", TDirectory* theTargetFile",MatchSource.WIKI,root/html532/TMVA__MethodCuts.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCuts.html
https://root.cern/root/html532/TMVA__MethodCuts.html:22286,Safety,sanity check,sanity check,22286,"TargetDir = NULL); construction from weight file. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); Cuts can only handle classification with 2 classes. void Init( void ); default initialisation called by all constructors. ~MethodCuts( void ); destructor. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options:; Method <string> Minimisation method; available values are: MC Monte Carlo <default>; GA Genetic Algorithm; SA Simulated annealing. EffMethod <string> Efficiency selection method; available values are: EffSel <default>; EffPDF. VarProp <string> Property of variable 1 for the MC method (taking precedence over the; globale setting. The same values as for the global option are available. Variables 1..10 can be; set this way. CutRangeMin/Max <float> user-defined ranges in which cuts are varied. void ProcessOptions(); process user options; sanity check, do not allow the input variables to be normalised, because this; only creates problems when interpreting the cuts. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); cut evaluation: returns 1.0 if event passed, 0.0 otherwise. void PrintCuts(Double_t effS) const; print cuts. Double_t GetCuts(Double_t effS, Double_t* cutMin, Double_t* cutMax) const; retrieve cut values for given signal efficiency; assume vector of correct size !!. Double_t GetCuts(Double_t effS, vector<Double_t>& cutMin, vector<Double_t>& cutMax) const; retrieve cut values for given signal efficiency. void Train( void ); training method: here the cuts are optimised for the training sample. void TestClassification(); nothing to test. Double_t EstimatorFunction(Int_t ievt1, Int_t ievt2); for full event scan. Double_t EstimatorFunction(vector<Double_t>& ); returns estimator for ""cut fitness"" used by GA. Double_t ComputeEstimator(vector<Double_t>& ); returns estimator for ""cut fitness"" used by GA; there are two requirements:; 1) the sign",MatchSource.WIKI,root/html532/TMVA__MethodCuts.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCuts.html
https://root.cern/root/html532/TMVA__MethodCuts.html:2052,Testability,test,tests,2052," should be used, which modifies; the significance criterion.; . The rectangular cut of a volume in the variable space is performed using; a binary tree to sort the training events. This provides a significant; reduction in computing time (up to several orders of magnitudes, depending; on the complexity of the problem at hand).; ; Technically, optimisation is achieved in TMVA by two methods:; ; Monte Carlo generation using uniform priors for the lower cut value,; and the cut width, thrown within the variable ranges.; A Genetic Algorithm (GA) searches for the optimal (""fittest"") cut sample.; The GA is configurable by many external settings through the option; string. For difficult cases (such as many variables), some tuning; may be necessary to achieve satisfying results; . Attempts to use Minuit fits (Simplex ot Migrad) instead have not shown; superior results, and often failed due to convergence at local minima.; . The tests we have performed so far showed that in generic applications,; the GA is superior to MC sampling, and hence GA is the default method.; It is worthwhile trying both anyway.; Decorrelated (or ""diagonalized"") Cuts. See class description for Method Likelihood for a detailed explanation.; . Function Members (Methods); public:. virtual~MethodCuts(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidCheckSetup(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* ",MatchSource.WIKI,root/html532/TMVA__MethodCuts.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCuts.html
https://root.cern/root/html532/TMVA__MethodCuts.html:13630,Testability,test,testTime,13630,"dTMVA::MethodBase::SetAnalysisType(TMVA::Types::EAnalysisType type); voidTMVA::MethodBase::SetBaseDir(TDirectory* methodDir); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidSetTestSignalEfficiency(Double_t effS); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const",MatchSource.WIKI,root/html532/TMVA__MethodCuts.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCuts.html
https://root.cern/root/html532/TMVA__MethodCuts.html:18095,Testability,test,testing,18095," effB); virtual voidInit(); voidMatchCutsToPars(vector<Double_t>&, Double_t*, Double_t*); voidMatchCutsToPars(vector<Double_t>&, Double_t**, Double_t**, Int_t ibin); voidMatchParsToCuts(const vector<Double_t>&, Double_t*, Double_t*); voidMatchParsToCuts(Double_t*, Double_t*, Double_t*). Data Members; public:. enum EFitMethodType { kUseMonteCarlo; kUseGeneticAlgorithm; kUseSimulatedAnnealing; kUseMinuit; kUseEventScan; kUseMonteCarloEvents; };; enum EEffMethod { kUseEventSelection; kUsePDFs; };; enum EFitParameters { kNotEnforced; kForceMin; kForceMax; kForceSmart; };; enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one; static const Double_tfgMaxAbsCutVal. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. TS",MatchSource.WIKI,root/html532/TMVA__MethodCuts.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCuts.html
https://root.cern/root/html532/TMVA__MethodCuts.html:19705,Testability,test,test,19705,"m requirement; Double_t**fCutMinminimum requirement; vector<Interval*>fCutRangeallowed ranges for cut optimisation; Double_t*fCutRangeMaxmaximum of allowed cut range; Double_t*fCutRangeMinminimum of allowed cut range; TH1*fEffBvsSLocalintermediate eff. background versus eff signal histo; TMVA::MethodCuts::EEffMethodfEffMethodchosen efficiency calculation method; TStringfEffMethodSchosen efficiency calculation method (string); Double_tfEffRefreference efficiency; Double_tfEffSMaxused to test optimized signal efficiency; Double_tfEffSMinused to test optimized signal efficiency; TMVA::MethodCuts::EFitMethodTypefFitMethodchosen fit method; TStringfFitMethodSchosen fit method (string); vector<EFitParameters>*fFitParamsvector for series of fit methods; vector<Double_t>*fMeanBmeans of variables (background); vector<Double_t>*fMeanSmeans of variables (signal); Bool_tfNegEffWarningflag risen in case of negative efficiency warning; Int_tfNparnumber of parameters in fit (default: 2*Nvar); TRandom*fRandomrandom generator for MC optimisation method; vector<Int_t>*fRangeSignused to match cuts to fit parameters (and vice versa); vector<Double_t>*fRmsBRMSs of variables (background); vector<Double_t>*fRmsSRMSs of variables (signal); Double_tfTestSignalEffused to test optimized signal efficiency; Double_t*fTmpCutMaxtemporary maximum requirement; Double_t*fTmpCutMintemporary minimum requirement; vector<TH1*>*fVarHistBreference histograms (background); vector<TH1*>*fVarHistB_smoothsmoothed reference histograms (background); vector<TH1*>*fVarHistSreference histograms (signal); vector<TH1*>*fVarHistS_smoothsmoothed reference histograms (signal) ; vector<PDF*>*fVarPdfBreference PDFs (background); vector<PDF*>*fVarPdfSreference PDFs (signal). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodCuts(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = ""MC:150:10000:"", TDirectory* theTargetFile",MatchSource.WIKI,root/html532/TMVA__MethodCuts.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCuts.html
https://root.cern/root/html532/TMVA__MethodCuts.html:19763,Testability,test,test,19763,"m requirement; Double_t**fCutMinminimum requirement; vector<Interval*>fCutRangeallowed ranges for cut optimisation; Double_t*fCutRangeMaxmaximum of allowed cut range; Double_t*fCutRangeMinminimum of allowed cut range; TH1*fEffBvsSLocalintermediate eff. background versus eff signal histo; TMVA::MethodCuts::EEffMethodfEffMethodchosen efficiency calculation method; TStringfEffMethodSchosen efficiency calculation method (string); Double_tfEffRefreference efficiency; Double_tfEffSMaxused to test optimized signal efficiency; Double_tfEffSMinused to test optimized signal efficiency; TMVA::MethodCuts::EFitMethodTypefFitMethodchosen fit method; TStringfFitMethodSchosen fit method (string); vector<EFitParameters>*fFitParamsvector for series of fit methods; vector<Double_t>*fMeanBmeans of variables (background); vector<Double_t>*fMeanSmeans of variables (signal); Bool_tfNegEffWarningflag risen in case of negative efficiency warning; Int_tfNparnumber of parameters in fit (default: 2*Nvar); TRandom*fRandomrandom generator for MC optimisation method; vector<Int_t>*fRangeSignused to match cuts to fit parameters (and vice versa); vector<Double_t>*fRmsBRMSs of variables (background); vector<Double_t>*fRmsSRMSs of variables (signal); Double_tfTestSignalEffused to test optimized signal efficiency; Double_t*fTmpCutMaxtemporary maximum requirement; Double_t*fTmpCutMintemporary minimum requirement; vector<TH1*>*fVarHistBreference histograms (background); vector<TH1*>*fVarHistB_smoothsmoothed reference histograms (background); vector<TH1*>*fVarHistSreference histograms (signal); vector<TH1*>*fVarHistS_smoothsmoothed reference histograms (signal) ; vector<PDF*>*fVarPdfBreference PDFs (background); vector<PDF*>*fVarPdfSreference PDFs (signal). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodCuts(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = ""MC:150:10000:"", TDirectory* theTargetFile",MatchSource.WIKI,root/html532/TMVA__MethodCuts.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCuts.html
https://root.cern/root/html532/TMVA__MethodCuts.html:20480,Testability,test,test,20480,"m requirement; Double_t**fCutMinminimum requirement; vector<Interval*>fCutRangeallowed ranges for cut optimisation; Double_t*fCutRangeMaxmaximum of allowed cut range; Double_t*fCutRangeMinminimum of allowed cut range; TH1*fEffBvsSLocalintermediate eff. background versus eff signal histo; TMVA::MethodCuts::EEffMethodfEffMethodchosen efficiency calculation method; TStringfEffMethodSchosen efficiency calculation method (string); Double_tfEffRefreference efficiency; Double_tfEffSMaxused to test optimized signal efficiency; Double_tfEffSMinused to test optimized signal efficiency; TMVA::MethodCuts::EFitMethodTypefFitMethodchosen fit method; TStringfFitMethodSchosen fit method (string); vector<EFitParameters>*fFitParamsvector for series of fit methods; vector<Double_t>*fMeanBmeans of variables (background); vector<Double_t>*fMeanSmeans of variables (signal); Bool_tfNegEffWarningflag risen in case of negative efficiency warning; Int_tfNparnumber of parameters in fit (default: 2*Nvar); TRandom*fRandomrandom generator for MC optimisation method; vector<Int_t>*fRangeSignused to match cuts to fit parameters (and vice versa); vector<Double_t>*fRmsBRMSs of variables (background); vector<Double_t>*fRmsSRMSs of variables (signal); Double_tfTestSignalEffused to test optimized signal efficiency; Double_t*fTmpCutMaxtemporary maximum requirement; Double_t*fTmpCutMintemporary minimum requirement; vector<TH1*>*fVarHistBreference histograms (background); vector<TH1*>*fVarHistB_smoothsmoothed reference histograms (background); vector<TH1*>*fVarHistSreference histograms (signal); vector<TH1*>*fVarHistS_smoothsmoothed reference histograms (signal) ; vector<PDF*>*fVarPdfBreference PDFs (background); vector<PDF*>*fVarPdfSreference PDFs (signal). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodCuts(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = ""MC:150:10000:"", TDirectory* theTargetFile",MatchSource.WIKI,root/html532/TMVA__MethodCuts.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCuts.html
https://root.cern/root/html532/TMVA__MethodCuts.html:23015,Testability,test,test,23015," of variable 1 for the MC method (taking precedence over the; globale setting. The same values as for the global option are available. Variables 1..10 can be; set this way. CutRangeMin/Max <float> user-defined ranges in which cuts are varied. void ProcessOptions(); process user options; sanity check, do not allow the input variables to be normalised, because this; only creates problems when interpreting the cuts. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); cut evaluation: returns 1.0 if event passed, 0.0 otherwise. void PrintCuts(Double_t effS) const; print cuts. Double_t GetCuts(Double_t effS, Double_t* cutMin, Double_t* cutMax) const; retrieve cut values for given signal efficiency; assume vector of correct size !!. Double_t GetCuts(Double_t effS, vector<Double_t>& cutMin, vector<Double_t>& cutMax) const; retrieve cut values for given signal efficiency. void Train( void ); training method: here the cuts are optimised for the training sample. void TestClassification(); nothing to test. Double_t EstimatorFunction(Int_t ievt1, Int_t ievt2); for full event scan. Double_t EstimatorFunction(vector<Double_t>& ); returns estimator for ""cut fitness"" used by GA. Double_t ComputeEstimator(vector<Double_t>& ); returns estimator for ""cut fitness"" used by GA; there are two requirements:; 1) the signal efficiency must be equal to the required one in the; efficiency scan; 2) the background efficiency must be as small as possible; the requirement 1) has priority over 2). void MatchParsToCuts( const std::vector<Double_t> & pars, Double_t* cutMin, Double_t* cutMax ); translates parameters into cuts. void MatchCutsToPars(vector<Double_t>& , Double_t** , Double_t** , Int_t ibin); translate the cuts into parameters (obsolete function). void MatchCutsToPars(vector<Double_t>& , Double_t* , Double_t* ); translates cuts into parameters. void GetEffsfromPDFs(Double_t* cutMin, Double_t* cutMax, Double_t& effS, Double_t& effB); compute signal and background efficiencies f",MatchSource.WIKI,root/html532/TMVA__MethodCuts.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodCuts.html
https://root.cern/root/html532/TMVA__MethodDT.html:5143,Availability,error,error,5143," const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidDeclareOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt, TMVA::Types",MatchSource.WIKI,root/html532/TMVA__MethodDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodDT.html
https://root.cern/root/html532/TMVA__MethodDT.html:5227,Availability,error,error,5227,"= """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidDeclareOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt, TMVA::Types::ETreeType type) const; const vector<TMVA::Event*>&TMVA::MethodBase::GetEventCollec",MatchSource.WIKI,root/html532/TMVA__MethodDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodDT.html
https://root.cern/root/html532/TMVA__MethodDT.html:19337,Availability,error,error,19337,"e::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. Bool_tfAutomaticuse user given prune strength or automatically determined one using a validation sample ; Double_tfDeltaPruneStrengthstep size in pruning, is adjusted according to experience of previous trees ; Double_tfErrorFractionntuple var: misclassification error fraction ; vector<TMVA::Event*,allocator<TMVA::Event*> >fEventSamplethe training events; UInt_tfMaxDepthmax depth; Int_tfNCutsgrid used in cut applied in node splitting; UInt_tfNNodesMaxmax # of nodes; Int_tfNodeMinEventsmin number of events in node ; Double_tfNodePurityLimitpurity limit for sig/bkg nodes; Bool_tfPruneBeforeBoostwhether to prune right after the training (before the boosting); TMVA::DecisionTree::EPruneMethodfPruneMethodmethod used for prunig ; TStringfPruneMethodSprune method option String; Double_tfPruneStrengtha parameter to set the ""amount"" of pruning..needs to be adjusted; Bool_tfRandomisedTreeschoose a random subset of possible cut variables at each node during training; TMVA::SeparationBase*fSepTypethe separation used in node splitting; TStringfSepTypeSthe separation (option string) used in node splitting; TMVA::DecisionTree*fTreethe decision tree; Int_tfUseNvarsthe number of variables used in the randomised tree splitting; Bool_tfUseYesNoLeafuse sig or bkg classification in leave nodes or sig/bkg; vector<Double_t>fVariableImportancethe relative importance of the different variables ; static const Int_tfgDebugLeve",MatchSource.WIKI,root/html532/TMVA__MethodDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodDT.html
https://root.cern/root/html532/TMVA__MethodDT.html:22007,Availability,error,error,22007,"nst TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = """", TDirectory* theTargetDir = 0); the standard constructor for just an ordinar ""decision trees"". MethodDT(TMVA::DataSetInfo& dsi, const TString& theWeightFile, TDirectory* theTargetDir = NULL); constructor from Reader. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); FDA can handle classification with 2 classes and regression with one regression-target. void DeclareOptions(); define the options (their key words) that can be set in the option string; UseRandomisedTrees choose at each node splitting a random set of variables; UseNvars use UseNvars variables in randomised trees; SeparationType the separation criterion applied in the node splitting; known: GiniIndex; MisClassificationError; CrossEntropy; SDivSqrtSPlusB; nEventsMin: the minimum number of events in a node (leaf criteria, stop splitting); nCuts: the number of steps in the optimisation of the cut for a node (if < 0, then; step size is determined by the events); UseYesNoLeaf decide if the classification is done simply by the node type, or the S/B; (from the training) in the leaf node; NodePurityLimit the minimum purity to classify a node as a signal node (used in pruning and boosting to determine; misclassification error rate); PruneMethod The Pruning method:; known: NoPruning // switch off pruning completely; ExpectedError; CostComplexity; PruneStrength a parameter to adjust the amount of pruning. Should be large enouth such that overtraining is avoided"");. void ProcessOptions(); the option string is decoded, for available options see ""DeclareOptions"". void Init( void ); common initialisation with defaults for the DT-Method. ~MethodDT( void ); destructor. void Train( void ). Bool_t MonitorBoost(TMVA::MethodBoost* booster). Double_t PruneTree(const Int_t methodIndex). Double_t TestTreeQuality(TMVA::DecisionTree* dt). void AddWeightsXMLTo(void* parent) const. void ReadWeightsFro",MatchSource.WIKI,root/html532/TMVA__MethodDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodDT.html
https://root.cern/root/html532/TMVA__MethodDT.html:22312,Availability,avail,available,22312," node splitting a random set of variables; UseNvars use UseNvars variables in randomised trees; SeparationType the separation criterion applied in the node splitting; known: GiniIndex; MisClassificationError; CrossEntropy; SDivSqrtSPlusB; nEventsMin: the minimum number of events in a node (leaf criteria, stop splitting); nCuts: the number of steps in the optimisation of the cut for a node (if < 0, then; step size is determined by the events); UseYesNoLeaf decide if the classification is done simply by the node type, or the S/B; (from the training) in the leaf node; NodePurityLimit the minimum purity to classify a node as a signal node (used in pruning and boosting to determine; misclassification error rate); PruneMethod The Pruning method:; known: NoPruning // switch off pruning completely; ExpectedError; CostComplexity; PruneStrength a parameter to adjust the amount of pruning. Should be large enouth such that overtraining is avoided"");. void ProcessOptions(); the option string is decoded, for available options see ""DeclareOptions"". void Init( void ); common initialisation with defaults for the DT-Method. ~MethodDT( void ); destructor. void Train( void ). Bool_t MonitorBoost(TMVA::MethodBoost* booster). Double_t PruneTree(const Int_t methodIndex). Double_t TestTreeQuality(TMVA::DecisionTree* dt). void AddWeightsXMLTo(void* parent) const. void ReadWeightsFromXML(void* wghtnode). void ReadWeightsFromStream(istream& istr). Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); returns MVA value. void GetHelpMessage() const. const TMVA::Ranking* CreateRanking(). Double_t GetPruneStrength(); { return fPruneStrength; }. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: MethodDT.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-12-02 14:28; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT",MatchSource.WIKI,root/html532/TMVA__MethodDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodDT.html
https://root.cern/root/html532/TMVA__MethodDT.html:3021,Integrability,depend,depending,3021,"ain; more signal respective background events from the training sample. Boosting:. the idea behind the boosting is, that signal events from the training; sample, that *end up in a background node (and vice versa) are given a; larger weight than events that are in the correct leave node. This; results in a re-weighed training event sample, with which then a new; decision tree can be developed. The boosting can be applied several; times (typically 100-500 times) and one ends up with a set of decision; trees (a forest). Bagging:. In this particular variant of the Boosted Decision Trees the boosting; is not done on the basis of previous training results, but by a simple; stochasitc re-sampling of the initial training event sample. Analysis:. applying an individual decision tree to a test event results in a; classification of the event as either signal or background. For the; boosted decision tree selection, an event is successively subjected to; the whole set of decision trees and depending on how often it is; classified as signal, a ""likelihood"" estimator is constructed for the; event being signal or background. The value of this estimator is the; one which is then used to select the events from an event sample, and; the cut value on this estimator defines the efficiency and purity of; the selection.; *. Function Members (Methods); public:. virtual~MethodDT(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidTMVA::MethodBase::CheckSetup(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """,MatchSource.WIKI,root/html532/TMVA__MethodDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodDT.html
https://root.cern/root/html532/TMVA__MethodDT.html:893,Modifiability,variab,variable,893,". TMVA::MethodDT. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodDT. class TMVA::MethodDT: public TMVA::MethodBase. Analysis of Boosted Decision Trees. Boosted decision trees have been successfully used in High Energy; Physics analysis for example by the MiniBooNE experiment; (Yang-Roe-Zhu, physics/0508045). In Boosted Decision Trees, the; selection is done on a majority vote on the result of several decision; trees, which are all derived from the same training sample by; supplying different event weights during the training. Decision trees:. successive decision nodes are used to categorize the; events out of the sample as either signal or background. Each node; uses only a single discriminating variable to decide if the event is; signal-like (""goes right"") or background-like (""goes left""). This; forms a tree like structure with ""baskets"" at the end (leave nodes),; and an event is classified as either signal or background according to; whether the basket where it ends up has been classified signal or; background during the training. Training of a decision tree is the; process to define the ""cut criteria"" for each node. The training; starts with the root node. Here one takes the full training event; sample and selects the variable and corresponding cut value that gives; the best separation between signal and background at this stage. Using; this cut criterion, the sample is then divided into two subsamples, a; signal-like (right) and a background-like (left) sample. Two new nodes; are then created for each of the two sub-samples and they are; constructed using the same mechanism as described for the root; node. The devision is stopped once a certain node has reached either a; minimum number of events, or a minimum or maximum signal purity. These; leave nodes are then called ""signal"" ",MatchSource.WIKI,root/html532/TMVA__MethodDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodDT.html
https://root.cern/root/html532/TMVA__MethodDT.html:1429,Modifiability,variab,variable,1429,"experiment; (Yang-Roe-Zhu, physics/0508045). In Boosted Decision Trees, the; selection is done on a majority vote on the result of several decision; trees, which are all derived from the same training sample by; supplying different event weights during the training. Decision trees:. successive decision nodes are used to categorize the; events out of the sample as either signal or background. Each node; uses only a single discriminating variable to decide if the event is; signal-like (""goes right"") or background-like (""goes left""). This; forms a tree like structure with ""baskets"" at the end (leave nodes),; and an event is classified as either signal or background according to; whether the basket where it ends up has been classified signal or; background during the training. Training of a decision tree is the; process to define the ""cut criteria"" for each node. The training; starts with the root node. Here one takes the full training event; sample and selects the variable and corresponding cut value that gives; the best separation between signal and background at this stage. Using; this cut criterion, the sample is then divided into two subsamples, a; signal-like (right) and a background-like (left) sample. Two new nodes; are then created for each of the two sub-samples and they are; constructed using the same mechanism as described for the root; node. The devision is stopped once a certain node has reached either a; minimum number of events, or a minimum or maximum signal purity. These; leave nodes are then called ""signal"" or ""background"" if they contain; more signal respective background events from the training sample. Boosting:. the idea behind the boosting is, that signal events from the training; sample, that *end up in a background node (and vice versa) are given a; larger weight than events that are in the correct leave node. This; results in a re-weighed training event sample, with which then a new; decision tree can be developed. The boosting can be applied s",MatchSource.WIKI,root/html532/TMVA__MethodDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodDT.html
https://root.cern/root/html532/TMVA__MethodDT.html:18443,Modifiability,variab,variables,18443,"ile(). private:. virtual voidInit(). Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. Bool_tfAutomaticuse user given prune strength or automatically determined one using a validation sample ; Double_tfDeltaPruneStrengthstep size in pruning, is adjusted according to experience of previous trees ; Double_tfErrorFractionntuple var: misclassification error fraction ; vector<TMVA::Event*,allocator<TMVA::Event*> >fEventSamplethe training events; UInt_tfMaxDepthmax depth; Int_tfNCutsgrid used in cut applied in node splitting; UInt_tfNNodesMaxmax # of nodes; Int_tfNodeMinEventsmin number of events in node ; Double_tfNodePurityLimitpurity li",MatchSource.WIKI,root/html532/TMVA__MethodDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodDT.html
https://root.cern/root/html532/TMVA__MethodDT.html:18632,Modifiability,variab,variable,18632,"ile(). private:. virtual voidInit(). Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. Bool_tfAutomaticuse user given prune strength or automatically determined one using a validation sample ; Double_tfDeltaPruneStrengthstep size in pruning, is adjusted according to experience of previous trees ; Double_tfErrorFractionntuple var: misclassification error fraction ; vector<TMVA::Event*,allocator<TMVA::Event*> >fEventSamplethe training events; UInt_tfMaxDepthmax depth; Int_tfNCutsgrid used in cut applied in node splitting; UInt_tfNNodesMaxmax # of nodes; Int_tfNodeMinEventsmin number of events in node ; Double_tfNodePurityLimitpurity li",MatchSource.WIKI,root/html532/TMVA__MethodDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodDT.html
https://root.cern/root/html532/TMVA__MethodDT.html:20005,Modifiability,variab,variables,20005,"ed according to experience of previous trees ; Double_tfErrorFractionntuple var: misclassification error fraction ; vector<TMVA::Event*,allocator<TMVA::Event*> >fEventSamplethe training events; UInt_tfMaxDepthmax depth; Int_tfNCutsgrid used in cut applied in node splitting; UInt_tfNNodesMaxmax # of nodes; Int_tfNodeMinEventsmin number of events in node ; Double_tfNodePurityLimitpurity limit for sig/bkg nodes; Bool_tfPruneBeforeBoostwhether to prune right after the training (before the boosting); TMVA::DecisionTree::EPruneMethodfPruneMethodmethod used for prunig ; TStringfPruneMethodSprune method option String; Double_tfPruneStrengtha parameter to set the ""amount"" of pruning..needs to be adjusted; Bool_tfRandomisedTreeschoose a random subset of possible cut variables at each node during training; TMVA::SeparationBase*fSepTypethe separation used in node splitting; TStringfSepTypeSthe separation (option string) used in node splitting; TMVA::DecisionTree*fTreethe decision tree; Int_tfUseNvarsthe number of variables used in the randomised tree splitting; Bool_tfUseYesNoLeafuse sig or bkg classification in leave nodes or sig/bkg; vector<Double_t>fVariableImportancethe relative importance of the different variables ; static const Int_tfgDebugLeveldebug level determining some printout/control plots etc. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodDT(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = """", TDirectory* theTargetDir = 0); the standard constructor for just an ordinar ""decision trees"". MethodDT(TMVA::DataSetInfo& dsi, const TString& theWeightFile, TDirectory* theTargetDir = NULL); constructor from Reader. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); FDA can handle classification with 2 classes and regression with one regression-target. void DeclareOptions(); define the options (their key words) that ca",MatchSource.WIKI,root/html532/TMVA__MethodDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodDT.html
https://root.cern/root/html532/TMVA__MethodDT.html:20255,Modifiability,variab,variables,20255,"ed according to experience of previous trees ; Double_tfErrorFractionntuple var: misclassification error fraction ; vector<TMVA::Event*,allocator<TMVA::Event*> >fEventSamplethe training events; UInt_tfMaxDepthmax depth; Int_tfNCutsgrid used in cut applied in node splitting; UInt_tfNNodesMaxmax # of nodes; Int_tfNodeMinEventsmin number of events in node ; Double_tfNodePurityLimitpurity limit for sig/bkg nodes; Bool_tfPruneBeforeBoostwhether to prune right after the training (before the boosting); TMVA::DecisionTree::EPruneMethodfPruneMethodmethod used for prunig ; TStringfPruneMethodSprune method option String; Double_tfPruneStrengtha parameter to set the ""amount"" of pruning..needs to be adjusted; Bool_tfRandomisedTreeschoose a random subset of possible cut variables at each node during training; TMVA::SeparationBase*fSepTypethe separation used in node splitting; TStringfSepTypeSthe separation (option string) used in node splitting; TMVA::DecisionTree*fTreethe decision tree; Int_tfUseNvarsthe number of variables used in the randomised tree splitting; Bool_tfUseYesNoLeafuse sig or bkg classification in leave nodes or sig/bkg; vector<Double_t>fVariableImportancethe relative importance of the different variables ; static const Int_tfgDebugLeveldebug level determining some printout/control plots etc. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodDT(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = """", TDirectory* theTargetDir = 0); the standard constructor for just an ordinar ""decision trees"". MethodDT(TMVA::DataSetInfo& dsi, const TString& theWeightFile, TDirectory* theTargetDir = NULL); constructor from Reader. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); FDA can handle classification with 2 classes and regression with one regression-target. void DeclareOptions(); define the options (their key words) that ca",MatchSource.WIKI,root/html532/TMVA__MethodDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodDT.html
https://root.cern/root/html532/TMVA__MethodDT.html:20456,Modifiability,variab,variables,20456,"ed according to experience of previous trees ; Double_tfErrorFractionntuple var: misclassification error fraction ; vector<TMVA::Event*,allocator<TMVA::Event*> >fEventSamplethe training events; UInt_tfMaxDepthmax depth; Int_tfNCutsgrid used in cut applied in node splitting; UInt_tfNNodesMaxmax # of nodes; Int_tfNodeMinEventsmin number of events in node ; Double_tfNodePurityLimitpurity limit for sig/bkg nodes; Bool_tfPruneBeforeBoostwhether to prune right after the training (before the boosting); TMVA::DecisionTree::EPruneMethodfPruneMethodmethod used for prunig ; TStringfPruneMethodSprune method option String; Double_tfPruneStrengtha parameter to set the ""amount"" of pruning..needs to be adjusted; Bool_tfRandomisedTreeschoose a random subset of possible cut variables at each node during training; TMVA::SeparationBase*fSepTypethe separation used in node splitting; TStringfSepTypeSthe separation (option string) used in node splitting; TMVA::DecisionTree*fTreethe decision tree; Int_tfUseNvarsthe number of variables used in the randomised tree splitting; Bool_tfUseYesNoLeafuse sig or bkg classification in leave nodes or sig/bkg; vector<Double_t>fVariableImportancethe relative importance of the different variables ; static const Int_tfgDebugLeveldebug level determining some printout/control plots etc. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodDT(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = """", TDirectory* theTargetDir = 0); the standard constructor for just an ordinar ""decision trees"". MethodDT(TMVA::DataSetInfo& dsi, const TString& theWeightFile, TDirectory* theTargetDir = NULL); constructor from Reader. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); FDA can handle classification with 2 classes and regression with one regression-target. void DeclareOptions(); define the options (their key words) that ca",MatchSource.WIKI,root/html532/TMVA__MethodDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodDT.html
https://root.cern/root/html532/TMVA__MethodDT.html:21334,Modifiability,variab,variables,21334,"nst TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = """", TDirectory* theTargetDir = 0); the standard constructor for just an ordinar ""decision trees"". MethodDT(TMVA::DataSetInfo& dsi, const TString& theWeightFile, TDirectory* theTargetDir = NULL); constructor from Reader. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); FDA can handle classification with 2 classes and regression with one regression-target. void DeclareOptions(); define the options (their key words) that can be set in the option string; UseRandomisedTrees choose at each node splitting a random set of variables; UseNvars use UseNvars variables in randomised trees; SeparationType the separation criterion applied in the node splitting; known: GiniIndex; MisClassificationError; CrossEntropy; SDivSqrtSPlusB; nEventsMin: the minimum number of events in a node (leaf criteria, stop splitting); nCuts: the number of steps in the optimisation of the cut for a node (if < 0, then; step size is determined by the events); UseYesNoLeaf decide if the classification is done simply by the node type, or the S/B; (from the training) in the leaf node; NodePurityLimit the minimum purity to classify a node as a signal node (used in pruning and boosting to determine; misclassification error rate); PruneMethod The Pruning method:; known: NoPruning // switch off pruning completely; ExpectedError; CostComplexity; PruneStrength a parameter to adjust the amount of pruning. Should be large enouth such that overtraining is avoided"");. void ProcessOptions(); the option string is decoded, for available options see ""DeclareOptions"". void Init( void ); common initialisation with defaults for the DT-Method. ~MethodDT( void ); destructor. void Train( void ). Bool_t MonitorBoost(TMVA::MethodBoost* booster). Double_t PruneTree(const Int_t methodIndex). Double_t TestTreeQuality(TMVA::DecisionTree* dt). void AddWeightsXMLTo(void* parent) const. void ReadWeightsFro",MatchSource.WIKI,root/html532/TMVA__MethodDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodDT.html
https://root.cern/root/html532/TMVA__MethodDT.html:21367,Modifiability,variab,variables,21367,"nst TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = """", TDirectory* theTargetDir = 0); the standard constructor for just an ordinar ""decision trees"". MethodDT(TMVA::DataSetInfo& dsi, const TString& theWeightFile, TDirectory* theTargetDir = NULL); constructor from Reader. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); FDA can handle classification with 2 classes and regression with one regression-target. void DeclareOptions(); define the options (their key words) that can be set in the option string; UseRandomisedTrees choose at each node splitting a random set of variables; UseNvars use UseNvars variables in randomised trees; SeparationType the separation criterion applied in the node splitting; known: GiniIndex; MisClassificationError; CrossEntropy; SDivSqrtSPlusB; nEventsMin: the minimum number of events in a node (leaf criteria, stop splitting); nCuts: the number of steps in the optimisation of the cut for a node (if < 0, then; step size is determined by the events); UseYesNoLeaf decide if the classification is done simply by the node type, or the S/B; (from the training) in the leaf node; NodePurityLimit the minimum purity to classify a node as a signal node (used in pruning and boosting to determine; misclassification error rate); PruneMethod The Pruning method:; known: NoPruning // switch off pruning completely; ExpectedError; CostComplexity; PruneStrength a parameter to adjust the amount of pruning. Should be large enouth such that overtraining is avoided"");. void ProcessOptions(); the option string is decoded, for available options see ""DeclareOptions"". void Init( void ); common initialisation with defaults for the DT-Method. ~MethodDT( void ); destructor. void Train( void ). Bool_t MonitorBoost(TMVA::MethodBoost* booster). Double_t PruneTree(const Int_t methodIndex). Double_t TestTreeQuality(TMVA::DecisionTree* dt). void AddWeightsXMLTo(void* parent) const. void ReadWeightsFro",MatchSource.WIKI,root/html532/TMVA__MethodDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodDT.html
https://root.cern/root/html532/TMVA__MethodDT.html:14527,Performance,tune,tuneParameters,14527,"voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); Double_tTestTreeQuality(TMVA::DecisionTree* dt); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virt",MatchSource.WIKI,root/html532/TMVA__MethodDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodDT.html
https://root.cern/root/html532/TMVA__MethodDT.html:22243,Safety,avoid,avoided,22243," words) that can be set in the option string; UseRandomisedTrees choose at each node splitting a random set of variables; UseNvars use UseNvars variables in randomised trees; SeparationType the separation criterion applied in the node splitting; known: GiniIndex; MisClassificationError; CrossEntropy; SDivSqrtSPlusB; nEventsMin: the minimum number of events in a node (leaf criteria, stop splitting); nCuts: the number of steps in the optimisation of the cut for a node (if < 0, then; step size is determined by the events); UseYesNoLeaf decide if the classification is done simply by the node type, or the S/B; (from the training) in the leaf node; NodePurityLimit the minimum purity to classify a node as a signal node (used in pruning and boosting to determine; misclassification error rate); PruneMethod The Pruning method:; known: NoPruning // switch off pruning completely; ExpectedError; CostComplexity; PruneStrength a parameter to adjust the amount of pruning. Should be large enouth such that overtraining is avoided"");. void ProcessOptions(); the option string is decoded, for available options see ""DeclareOptions"". void Init( void ); common initialisation with defaults for the DT-Method. ~MethodDT( void ); destructor. void Train( void ). Bool_t MonitorBoost(TMVA::MethodBoost* booster). Double_t PruneTree(const Int_t methodIndex). Double_t TestTreeQuality(TMVA::DecisionTree* dt). void AddWeightsXMLTo(void* parent) const. void ReadWeightsFromXML(void* wghtnode). void ReadWeightsFromStream(istream& istr). Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); returns MVA value. void GetHelpMessage() const. const TMVA::Ranking* CreateRanking(). Double_t GetPruneStrength(); { return fPruneStrength; }. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: MethodDT.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-12-02 14:28; This page has been automatically generated. For comments or sugges",MatchSource.WIKI,root/html532/TMVA__MethodDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodDT.html
https://root.cern/root/html532/TMVA__MethodDT.html:19160,Security,validat,validation,19160,"e::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. Bool_tfAutomaticuse user given prune strength or automatically determined one using a validation sample ; Double_tfDeltaPruneStrengthstep size in pruning, is adjusted according to experience of previous trees ; Double_tfErrorFractionntuple var: misclassification error fraction ; vector<TMVA::Event*,allocator<TMVA::Event*> >fEventSamplethe training events; UInt_tfMaxDepthmax depth; Int_tfNCutsgrid used in cut applied in node splitting; UInt_tfNNodesMaxmax # of nodes; Int_tfNodeMinEventsmin number of events in node ; Double_tfNodePurityLimitpurity limit for sig/bkg nodes; Bool_tfPruneBeforeBoostwhether to prune right after the training (before the boosting); TMVA::DecisionTree::EPruneMethodfPruneMethodmethod used for prunig ; TStringfPruneMethodSprune method option String; Double_tfPruneStrengtha parameter to set the ""amount"" of pruning..needs to be adjusted; Bool_tfRandomisedTreeschoose a random subset of possible cut variables at each node during training; TMVA::SeparationBase*fSepTypethe separation used in node splitting; TStringfSepTypeSthe separation (option string) used in node splitting; TMVA::DecisionTree*fTreethe decision tree; Int_tfUseNvarsthe number of variables used in the randomised tree splitting; Bool_tfUseYesNoLeafuse sig or bkg classification in leave nodes or sig/bkg; vector<Double_t>fVariableImportancethe relative importance of the different variables ; static const Int_tfgDebugLeve",MatchSource.WIKI,root/html532/TMVA__MethodDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodDT.html
https://root.cern/root/html532/TMVA__MethodDT.html:2819,Testability,test,test,2819,"is stopped once a certain node has reached either a; minimum number of events, or a minimum or maximum signal purity. These; leave nodes are then called ""signal"" or ""background"" if they contain; more signal respective background events from the training sample. Boosting:. the idea behind the boosting is, that signal events from the training; sample, that *end up in a background node (and vice versa) are given a; larger weight than events that are in the correct leave node. This; results in a re-weighed training event sample, with which then a new; decision tree can be developed. The boosting can be applied several; times (typically 100-500 times) and one ends up with a set of decision; trees (a forest). Bagging:. In this particular variant of the Boosted Decision Trees the boosting; is not done on the basis of previous training results, but by a simple; stochasitc re-sampling of the initial training event sample. Analysis:. applying an individual decision tree to a test event results in a; classification of the event as either signal or background. For the; boosted decision tree selection, an event is successively subjected to; the whole set of decision trees and depending on how often it is; classified as signal, a ""likelihood"" estimator is constructed for the; event being signal or background. The value of this estimator is the; one which is then used to select the events from an event sample, and; the cut value on this estimator defines the efficiency and purity of; the selection.; *. Function Members (Methods); public:. virtual~MethodDT(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurab",MatchSource.WIKI,root/html532/TMVA__MethodDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodDT.html
https://root.cern/root/html532/TMVA__MethodDT.html:14329,Testability,test,testTime,14329,"am& out, Option_t* option = """"); virtual voidTMVA::MethodBase::SetAnalysisType(TMVA::Types::EAnalysisType type); voidTMVA::MethodBase::SetBaseDir(TDirectory* methodDir); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); Double_tTestTreeQuality(TMVA::DecisionTree* dt); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual",MatchSource.WIKI,root/html532/TMVA__MethodDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodDT.html
https://root.cern/root/html532/TMVA__MethodDT.html:18133,Testability,test,testing,18133," *const err, Double_t *const errUpper); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::MethodBase::SetNormalised(Bool_t norm); voidTMVA::MethodBase::SetWeightFileDir(TString fileDir); voidTMVA::MethodBase::SetWeightFileName(TString); voidTMVA::MethodBase::Statistics(TMVA::Types::ETreeType treeType, const TString& theVarName, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&); Bool_tTMVA::MethodBase::TxtWeightsOnly() const; Bool_tTMVA::MethodBase::Verbose() const; voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. virtual voidInit(). Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. Bool_tfAutomaticuse u",MatchSource.WIKI,root/html532/TMVA__MethodDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodDT.html
https://root.cern/root/html532/TMVA__MethodDT.html:2697,Usability,simpl,simple,2697,"(left) sample. Two new nodes; are then created for each of the two sub-samples and they are; constructed using the same mechanism as described for the root; node. The devision is stopped once a certain node has reached either a; minimum number of events, or a minimum or maximum signal purity. These; leave nodes are then called ""signal"" or ""background"" if they contain; more signal respective background events from the training sample. Boosting:. the idea behind the boosting is, that signal events from the training; sample, that *end up in a background node (and vice versa) are given a; larger weight than events that are in the correct leave node. This; results in a re-weighed training event sample, with which then a new; decision tree can be developed. The boosting can be applied several; times (typically 100-500 times) and one ends up with a set of decision; trees (a forest). Bagging:. In this particular variant of the Boosted Decision Trees the boosting; is not done on the basis of previous training results, but by a simple; stochasitc re-sampling of the initial training event sample. Analysis:. applying an individual decision tree to a test event results in a; classification of the event as either signal or background. For the; boosted decision tree selection, an event is successively subjected to; the whole set of decision trees and depending on how often it is; classified as signal, a ""likelihood"" estimator is constructed for the; event being signal or background. The value of this estimator is the; one which is then used to select the events from an event sample, and; the cut value on this estimator defines the efficiency and purity of; the selection.; *. Function Members (Methods); public:. virtual~MethodDT(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* p",MatchSource.WIKI,root/html532/TMVA__MethodDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodDT.html
https://root.cern/root/html532/TMVA__MethodDT.html:21799,Usability,simpl,simply,21799,"nst TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = """", TDirectory* theTargetDir = 0); the standard constructor for just an ordinar ""decision trees"". MethodDT(TMVA::DataSetInfo& dsi, const TString& theWeightFile, TDirectory* theTargetDir = NULL); constructor from Reader. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); FDA can handle classification with 2 classes and regression with one regression-target. void DeclareOptions(); define the options (their key words) that can be set in the option string; UseRandomisedTrees choose at each node splitting a random set of variables; UseNvars use UseNvars variables in randomised trees; SeparationType the separation criterion applied in the node splitting; known: GiniIndex; MisClassificationError; CrossEntropy; SDivSqrtSPlusB; nEventsMin: the minimum number of events in a node (leaf criteria, stop splitting); nCuts: the number of steps in the optimisation of the cut for a node (if < 0, then; step size is determined by the events); UseYesNoLeaf decide if the classification is done simply by the node type, or the S/B; (from the training) in the leaf node; NodePurityLimit the minimum purity to classify a node as a signal node (used in pruning and boosting to determine; misclassification error rate); PruneMethod The Pruning method:; known: NoPruning // switch off pruning completely; ExpectedError; CostComplexity; PruneStrength a parameter to adjust the amount of pruning. Should be large enouth such that overtraining is avoided"");. void ProcessOptions(); the option string is decoded, for available options see ""DeclareOptions"". void Init( void ); common initialisation with defaults for the DT-Method. ~MethodDT( void ); destructor. void Train( void ). Bool_t MonitorBoost(TMVA::MethodBoost* booster). Double_t PruneTree(const Int_t methodIndex). Double_t TestTreeQuality(TMVA::DecisionTree* dt). void AddWeightsXMLTo(void* parent) const. void ReadWeightsFro",MatchSource.WIKI,root/html532/TMVA__MethodDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodDT.html
https://root.cern/root/html532/TMVA__MethodFDA.html:2585,Availability,error,error,2585,"leTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual Double_tEstimatorFunction(vector<Double_t>&); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt, TMVA::Types",MatchSource.WIKI,root/html532/TMVA__MethodFDA.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodFDA.html
https://root.cern/root/html532/TMVA__MethodFDA.html:2669,Availability,error,error,2669,"ct::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual Double_tEstimatorFunction(vector<Double_t>&); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt, TMVA::Types::ETreeType type) const; const vector<TMVA::Event*>&TMVA::MethodBase::GetEventCollec",MatchSource.WIKI,root/html532/TMVA__MethodFDA.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodFDA.html
https://root.cern/root/html532/TMVA__MethodFDA.html:18696,Availability,avail,availabel,18696,"itance; Inherited Members; Includes; Libraries. Function documentation; MethodFDA(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = """", TDirectory* theTargetDir = 0); standard constructor. MethodFDA(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL); constructor from weight file. void Init( void ); default initialisation. void DeclareOptions(); define the options (their key words) that can be set in the option string. format of function string:; ""x0*(0)+((1)/x1)**(2)...""; where ""[i]"" are the parameters, and ""xi"" the input variables. format of parameter string:; ""(-1.2,3.4);(-2.3,4.55);...""; where the numbers in ""(a,b)"" correspond to the a=min, b=max parameter ranges;; each parameter defined in the function string must have a corresponding range. void CreateFormula(); translate formula string into TFormula, and parameter string into par ranges. void ProcessOptions(); the option string is decoded, for availabel options see ""DeclareOptions"". ~MethodFDA( void ); destructor. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); FDA can handle classification with 2 classes and regression with one regression-target. void ClearAll( void ); delete and clear all class members. void Train( void ); FDA training. void PrintResults(const TString& , vector<Double_t>& , const Double_t ) const; display fit parameters; check maximum length of variable name. Double_t EstimatorFunction(vector<Double_t>& ); compute estimator for given parameter set (to be minimised); const Double_t sumOfWeights[] = { fSumOfWeightsSig, fSumOfWeightsBkg, fSumOfWeights };. Double_t InterpretFormula(const TMVA::Event* , vector<double,allocator<double> >::iterator begin, vector<double,allocator<double> >::iterator end); formula interpretation. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); returns MVA value for given event. const std::vector<Float_t>",MatchSource.WIKI,root/html532/TMVA__MethodFDA.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodFDA.html
https://root.cern/root/html532/TMVA__MethodFDA.html:440,Deployability,configurat,configuration,440,". TMVA::MethodFDA. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodFDA. class TMVA::MethodFDA: public TMVA::MethodBase, public TMVA::IFitterTarget. Function discriminant analysis (FDA). This simple classifier; fits any user-defined TFormula (via option configuration string) to; the training data by requiring a formula response of 1 (0) to signal; (background) events. The parameter fitting is done via the abstract; class FitterBase, featuring Monte Carlo sampling, Genetic; Algorithm, Simulated Annealing, MINUIT and combinations of these. Can compute regression value for one dimensional output. Function Members (Methods); public:. virtual~MethodFDA(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidCheckSetup(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWrit",MatchSource.WIKI,root/html532/TMVA__MethodFDA.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodFDA.html
https://root.cern/root/html532/TMVA__MethodFDA.html:20375,Integrability,message,message,20375,"arAll( void ); delete and clear all class members. void Train( void ); FDA training. void PrintResults(const TString& , vector<Double_t>& , const Double_t ) const; display fit parameters; check maximum length of variable name. Double_t EstimatorFunction(vector<Double_t>& ); compute estimator for given parameter set (to be minimised); const Double_t sumOfWeights[] = { fSumOfWeightsSig, fSumOfWeightsBkg, fSumOfWeights };. Double_t InterpretFormula(const TMVA::Event* , vector<double,allocator<double> >::iterator begin, vector<double,allocator<double> >::iterator end); formula interpretation. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); returns MVA value for given event. const std::vector<Float_t>& GetRegressionValues(). const std::vector<Float_t>& GetMulticlassValues(). void CalculateMulticlassValues(const TMVA::Event*& evt, vector<Double_t>& parameters, vector<Float_t>& values); calculate the values for multiclass. void ReadWeightsFromStream(istream& i); read back the training results from a file (stream). void AddWeightsXMLTo(void* parent) const; create XML description for LD classification and regression; (for arbitrary number of output classes/targets). void ReadWeightsFromXML(void* wghtnode); read coefficients from xml weight file. void MakeClassSpecific(ostream& , const TString& ) const; write FDA-specific classifier response. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". const Ranking* CreateRanking(); ranking of input variables. { return 0; }. void CheckSetup(); no check of options at this place. {}. » Author: Andreas Hoecker, Peter Speckmayer » Copyright (c) 2005-2010: *; » Last changed: root/tmva $Id: MethodFDA.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__MethodFDA.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodFDA.html
https://root.cern/root/html532/TMVA__MethodFDA.html:440,Modifiability,config,configuration,440,". TMVA::MethodFDA. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodFDA. class TMVA::MethodFDA: public TMVA::MethodBase, public TMVA::IFitterTarget. Function discriminant analysis (FDA). This simple classifier; fits any user-defined TFormula (via option configuration string) to; the training data by requiring a formula response of 1 (0) to signal; (background) events. The parameter fitting is done via the abstract; class FitterBase, featuring Monte Carlo sampling, Genetic; Algorithm, Simulated Annealing, MINUIT and combinations of these. Can compute regression value for one dimensional output. Function Members (Methods); public:. virtual~MethodFDA(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidCheckSetup(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWrit",MatchSource.WIKI,root/html532/TMVA__MethodFDA.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodFDA.html
https://root.cern/root/html532/TMVA__MethodFDA.html:16188,Modifiability,variab,variables,16188,"const; virtual voidProcessOptions(). Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. vector<Double_t>fBestParsthe pars that optimise (minimise) the estimator; TStringfConvergerfitmethod uses fConverger as intermediate step to converge into local minimas; TMVA::IFitterTarget*fConvergerFitterintermediate fitter; TStringfFitMethodestimator optimisation method; TMVA::FitterBase*fFitterthe fitter used in the training; TFormula*fFormulathe discrimination function; TStringfFormulaStringPstring with function; TStringfFormulaStringTstring with function; UInt_tfNParsnumber of parameters; Int_tfOutputDimensionsnumber of output values; vector<",MatchSource.WIKI,root/html532/TMVA__MethodFDA.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodFDA.html
https://root.cern/root/html532/TMVA__MethodFDA.html:16377,Modifiability,variab,variable,16377,"const; virtual voidProcessOptions(). Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. vector<Double_t>fBestParsthe pars that optimise (minimise) the estimator; TStringfConvergerfitmethod uses fConverger as intermediate step to converge into local minimas; TMVA::IFitterTarget*fConvergerFitterintermediate fitter; TStringfFitMethodestimator optimisation method; TMVA::FitterBase*fFitterthe fitter used in the training; TFormula*fFormulathe discrimination function; TStringfFormulaStringPstring with function; TStringfFormulaStringTstring with function; UInt_tfNParsnumber of parameters; Int_tfOutputDimensionsnumber of output values; vector<",MatchSource.WIKI,root/html532/TMVA__MethodFDA.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodFDA.html
https://root.cern/root/html532/TMVA__MethodFDA.html:18311,Modifiability,variab,variables,18311,"_tfNParsnumber of parameters; Int_tfOutputDimensionsnumber of output values; vector<Interval*>fParRangeranges of parameters; TStringfParRangeStringPstring with ranges of parameters; TStringfParRangeStringTstring with ranges of parameters; Double_tfSumOfWeightssum of weights; Double_tfSumOfWeightsBkgsum of weights (background); Double_tfSumOfWeightsSigsum of weights (signal). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodFDA(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = """", TDirectory* theTargetDir = 0); standard constructor. MethodFDA(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL); constructor from weight file. void Init( void ); default initialisation. void DeclareOptions(); define the options (their key words) that can be set in the option string. format of function string:; ""x0*(0)+((1)/x1)**(2)...""; where ""[i]"" are the parameters, and ""xi"" the input variables. format of parameter string:; ""(-1.2,3.4);(-2.3,4.55);...""; where the numbers in ""(a,b)"" correspond to the a=min, b=max parameter ranges;; each parameter defined in the function string must have a corresponding range. void CreateFormula(); translate formula string into TFormula, and parameter string into par ranges. void ProcessOptions(); the option string is decoded, for availabel options see ""DeclareOptions"". ~MethodFDA( void ); destructor. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); FDA can handle classification with 2 classes and regression with one regression-target. void ClearAll( void ); delete and clear all class members. void Train( void ); FDA training. void PrintResults(const TString& , vector<Double_t>& , const Double_t ) const; display fit parameters; check maximum length of variable name. Double_t EstimatorFunction(vector<Double_t>& ); compute estimator for given parameter set (to be ",MatchSource.WIKI,root/html532/TMVA__MethodFDA.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodFDA.html
https://root.cern/root/html532/TMVA__MethodFDA.html:19177,Modifiability,variab,variable,19177,"ptions(); define the options (their key words) that can be set in the option string. format of function string:; ""x0*(0)+((1)/x1)**(2)...""; where ""[i]"" are the parameters, and ""xi"" the input variables. format of parameter string:; ""(-1.2,3.4);(-2.3,4.55);...""; where the numbers in ""(a,b)"" correspond to the a=min, b=max parameter ranges;; each parameter defined in the function string must have a corresponding range. void CreateFormula(); translate formula string into TFormula, and parameter string into par ranges. void ProcessOptions(); the option string is decoded, for availabel options see ""DeclareOptions"". ~MethodFDA( void ); destructor. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); FDA can handle classification with 2 classes and regression with one regression-target. void ClearAll( void ); delete and clear all class members. void Train( void ); FDA training. void PrintResults(const TString& , vector<Double_t>& , const Double_t ) const; display fit parameters; check maximum length of variable name. Double_t EstimatorFunction(vector<Double_t>& ); compute estimator for given parameter set (to be minimised); const Double_t sumOfWeights[] = { fSumOfWeightsSig, fSumOfWeightsBkg, fSumOfWeights };. Double_t InterpretFormula(const TMVA::Event* , vector<double,allocator<double> >::iterator begin, vector<double,allocator<double> >::iterator end); formula interpretation. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); returns MVA value for given event. const std::vector<Float_t>& GetRegressionValues(). const std::vector<Float_t>& GetMulticlassValues(). void CalculateMulticlassValues(const TMVA::Event*& evt, vector<Double_t>& parameters, vector<Float_t>& values); calculate the values for multiclass. void ReadWeightsFromStream(istream& i); read back the training results from a file (stream). void AddWeightsXMLTo(void* parent) const; create XML description for LD classification and regression; (for arbitra",MatchSource.WIKI,root/html532/TMVA__MethodFDA.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodFDA.html
https://root.cern/root/html532/TMVA__MethodFDA.html:20536,Modifiability,variab,variables,20536,"arAll( void ); delete and clear all class members. void Train( void ); FDA training. void PrintResults(const TString& , vector<Double_t>& , const Double_t ) const; display fit parameters; check maximum length of variable name. Double_t EstimatorFunction(vector<Double_t>& ); compute estimator for given parameter set (to be minimised); const Double_t sumOfWeights[] = { fSumOfWeightsSig, fSumOfWeightsBkg, fSumOfWeights };. Double_t InterpretFormula(const TMVA::Event* , vector<double,allocator<double> >::iterator begin, vector<double,allocator<double> >::iterator end); formula interpretation. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); returns MVA value for given event. const std::vector<Float_t>& GetRegressionValues(). const std::vector<Float_t>& GetMulticlassValues(). void CalculateMulticlassValues(const TMVA::Event*& evt, vector<Double_t>& parameters, vector<Float_t>& values); calculate the values for multiclass. void ReadWeightsFromStream(istream& i); read back the training results from a file (stream). void AddWeightsXMLTo(void* parent) const; create XML description for LD classification and regression; (for arbitrary number of output classes/targets). void ReadWeightsFromXML(void* wghtnode); read coefficients from xml weight file. void MakeClassSpecific(ostream& , const TString& ) const; write FDA-specific classifier response. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". const Ranking* CreateRanking(); ranking of input variables. { return 0; }. void CheckSetup(); no check of options at this place. {}. » Author: Andreas Hoecker, Peter Speckmayer » Copyright (c) 2005-2010: *; » Last changed: root/tmva $Id: MethodFDA.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__MethodFDA.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodFDA.html
https://root.cern/root/html532/TMVA__MethodFDA.html:11899,Performance,tune,tuneParameters,11899,"voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int",MatchSource.WIKI,root/html532/TMVA__MethodFDA.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodFDA.html
https://root.cern/root/html532/TMVA__MethodFDA.html:11701,Testability,test,testTime,11701,"am& out, Option_t* option = """"); virtual voidTMVA::MethodBase::SetAnalysisType(TMVA::Types::EAnalysisType type); voidTMVA::MethodBase::SetBaseDir(TDirectory* methodDir); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObj",MatchSource.WIKI,root/html532/TMVA__MethodFDA.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodFDA.html
https://root.cern/root/html532/TMVA__MethodFDA.html:15878,Testability,test,testing,15878,"MethodBase::TxtWeightsOnly() const; Bool_tTMVA::MethodBase::Verbose() const; voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. voidCalculateMulticlassValues(const TMVA::Event*& evt, vector<Double_t>& parameters, vector<Float_t>& values); voidClearAll(); voidCreateFormula(); virtual voidDeclareOptions(); Double_tInterpretFormula(const TMVA::Event*, vector<double,allocator<double> >::iterator begin, vector<double,allocator<double> >::iterator end); voidPrintResults(const TString&, vector<Double_t>&, const Double_t) const; virtual voidProcessOptions(). Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. vector<Double_t>fBest",MatchSource.WIKI,root/html532/TMVA__MethodFDA.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodFDA.html
https://root.cern/root/html532/TMVA__MethodFDA.html:378,Usability,simpl,simple,378,". TMVA::MethodFDA. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodFDA. class TMVA::MethodFDA: public TMVA::MethodBase, public TMVA::IFitterTarget. Function discriminant analysis (FDA). This simple classifier; fits any user-defined TFormula (via option configuration string) to; the training data by requiring a formula response of 1 (0) to signal; (background) events. The parameter fitting is done via the abstract; class FitterBase, featuring Monte Carlo sampling, Genetic; Algorithm, Simulated Annealing, MINUIT and combinations of these. Can compute regression value for one dimensional output. Function Members (Methods); public:. virtual~MethodFDA(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidCheckSetup(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWrit",MatchSource.WIKI,root/html532/TMVA__MethodFDA.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodFDA.html
https://root.cern/root/html532/TMVA__MethodFDA.html:18991,Usability,clear,clear,18991,"theWeightFile, TDirectory* theTargetDir = NULL); constructor from weight file. void Init( void ); default initialisation. void DeclareOptions(); define the options (their key words) that can be set in the option string. format of function string:; ""x0*(0)+((1)/x1)**(2)...""; where ""[i]"" are the parameters, and ""xi"" the input variables. format of parameter string:; ""(-1.2,3.4);(-2.3,4.55);...""; where the numbers in ""(a,b)"" correspond to the a=min, b=max parameter ranges;; each parameter defined in the function string must have a corresponding range. void CreateFormula(); translate formula string into TFormula, and parameter string into par ranges. void ProcessOptions(); the option string is decoded, for availabel options see ""DeclareOptions"". ~MethodFDA( void ); destructor. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); FDA can handle classification with 2 classes and regression with one regression-target. void ClearAll( void ); delete and clear all class members. void Train( void ); FDA training. void PrintResults(const TString& , vector<Double_t>& , const Double_t ) const; display fit parameters; check maximum length of variable name. Double_t EstimatorFunction(vector<Double_t>& ); compute estimator for given parameter set (to be minimised); const Double_t sumOfWeights[] = { fSumOfWeightsSig, fSumOfWeightsBkg, fSumOfWeights };. Double_t InterpretFormula(const TMVA::Event* , vector<double,allocator<double> >::iterator begin, vector<double,allocator<double> >::iterator end); formula interpretation. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); returns MVA value for given event. const std::vector<Float_t>& GetRegressionValues(). const std::vector<Float_t>& GetMulticlassValues(). void CalculateMulticlassValues(const TMVA::Event*& evt, vector<Double_t>& parameters, vector<Float_t>& values); calculate the values for multiclass. void ReadWeightsFromStream(istream& i); read back the training results fro",MatchSource.WIKI,root/html532/TMVA__MethodFDA.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodFDA.html
https://root.cern/root/html532/TMVA__MethodFisher.html:4391,Availability,error,error,4391,"t::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt, TMVA::Types",MatchSource.WIKI,root/html532/TMVA__MethodFisher.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodFisher.html
https://root.cern/root/html532/TMVA__MethodFisher.html:4475,Availability,error,error,4475,"able(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt, TMVA::Types::ETreeType type) const; const vector<TMVA::Event*>&TMVA::MethodBase::GetEventCollec",MatchSource.WIKI,root/html532/TMVA__MethodFisher.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodFisher.html
https://root.cern/root/html532/TMVA__MethodFisher.html:2279,Energy Efficiency,power,power,2279,"le means, xS(B),i,; and total covariance matrix Tij. The covariance matrix; can be decomposed into the sum of a within- (Wij); and a between-class (Bij) class matrix. They describe; the dispersion of events relative to the means of their own class (within-class; matrix), and relative to the overall sample means (between-class matrix).; The Fisher coefficients, Fi, are then given by . where in TMVA is set NS=NB, so that the factor; in front of the sum simplifies to ½.; The Fisher discriminant then reads. The offset F0 centers the sample mean of xFi; at zero. Instead of using the within-class matrix, the Mahalanobis variant; determines the Fisher coefficients as follows:. with resulting xMa that are very similar to the; xFi. ; TMVA provides two outputs for the ranking of the input variables:. Fisher test: the Fisher analysis aims at simultaneously maximising; the between-class separation, while minimising the within-class dispersion.; A useful measure of the discrimination power of a variable is hence given; by the diagonal quantity: Bii/Wii.; ; Discrimination power: the value of the Fisher coefficient is a; measure of the discriminating power of a variable. The discrimination power; of set of input variables can therefore be measured by the scalar; . The corresponding numbers are printed on standard output.; ; . Function Members (Methods); public:. virtual~MethodFisher(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidTMVA::MethodBase::CheckSetup(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(",MatchSource.WIKI,root/html532/TMVA__MethodFisher.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodFisher.html
https://root.cern/root/html532/TMVA__MethodFisher.html:2368,Energy Efficiency,power,power,2368,"hin- (Wij); and a between-class (Bij) class matrix. They describe; the dispersion of events relative to the means of their own class (within-class; matrix), and relative to the overall sample means (between-class matrix).; The Fisher coefficients, Fi, are then given by . where in TMVA is set NS=NB, so that the factor; in front of the sum simplifies to ½.; The Fisher discriminant then reads. The offset F0 centers the sample mean of xFi; at zero. Instead of using the within-class matrix, the Mahalanobis variant; determines the Fisher coefficients as follows:. with resulting xMa that are very similar to the; xFi. ; TMVA provides two outputs for the ranking of the input variables:. Fisher test: the Fisher analysis aims at simultaneously maximising; the between-class separation, while minimising the within-class dispersion.; A useful measure of the discrimination power of a variable is hence given; by the diagonal quantity: Bii/Wii.; ; Discrimination power: the value of the Fisher coefficient is a; measure of the discriminating power of a variable. The discrimination power; of set of input variables can therefore be measured by the scalar; . The corresponding numbers are printed on standard output.; ; . Function Members (Methods); public:. virtual~MethodFisher(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidTMVA::MethodBase::CheckSetup(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(con",MatchSource.WIKI,root/html532/TMVA__MethodFisher.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodFisher.html
https://root.cern/root/html532/TMVA__MethodFisher.html:2447,Energy Efficiency,power,power,2447,"hin- (Wij); and a between-class (Bij) class matrix. They describe; the dispersion of events relative to the means of their own class (within-class; matrix), and relative to the overall sample means (between-class matrix).; The Fisher coefficients, Fi, are then given by . where in TMVA is set NS=NB, so that the factor; in front of the sum simplifies to ½.; The Fisher discriminant then reads. The offset F0 centers the sample mean of xFi; at zero. Instead of using the within-class matrix, the Mahalanobis variant; determines the Fisher coefficients as follows:. with resulting xMa that are very similar to the; xFi. ; TMVA provides two outputs for the ranking of the input variables:. Fisher test: the Fisher analysis aims at simultaneously maximising; the between-class separation, while minimising the within-class dispersion.; A useful measure of the discrimination power of a variable is hence given; by the diagonal quantity: Bii/Wii.; ; Discrimination power: the value of the Fisher coefficient is a; measure of the discriminating power of a variable. The discrimination power; of set of input variables can therefore be measured by the scalar; . The corresponding numbers are printed on standard output.; ; . Function Members (Methods); public:. virtual~MethodFisher(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidTMVA::MethodBase::CheckSetup(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(con",MatchSource.WIKI,root/html532/TMVA__MethodFisher.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodFisher.html
https://root.cern/root/html532/TMVA__MethodFisher.html:2487,Energy Efficiency,power,power,2487,"e means of their own class (within-class; matrix), and relative to the overall sample means (between-class matrix).; The Fisher coefficients, Fi, are then given by . where in TMVA is set NS=NB, so that the factor; in front of the sum simplifies to ½.; The Fisher discriminant then reads. The offset F0 centers the sample mean of xFi; at zero. Instead of using the within-class matrix, the Mahalanobis variant; determines the Fisher coefficients as follows:. with resulting xMa that are very similar to the; xFi. ; TMVA provides two outputs for the ranking of the input variables:. Fisher test: the Fisher analysis aims at simultaneously maximising; the between-class separation, while minimising the within-class dispersion.; A useful measure of the discrimination power of a variable is hence given; by the diagonal quantity: Bii/Wii.; ; Discrimination power: the value of the Fisher coefficient is a; measure of the discriminating power of a variable. The discrimination power; of set of input variables can therefore be measured by the scalar; . The corresponding numbers are printed on standard output.; ; . Function Members (Methods); public:. virtual~MethodFisher(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidTMVA::MethodBase::CheckSetup(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); ",MatchSource.WIKI,root/html532/TMVA__MethodFisher.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodFisher.html
https://root.cern/root/html532/TMVA__MethodFisher.html:18573,Energy Efficiency,power,power,18573,"TMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. TMatrixD*fBetwbetween-class matrix; TMatrixD*fCovfull covariance matrix; vector<Double_t>*fDiscrimPowdiscriminating power; Double_tfF0offset; vector<Double_t>*fFisherCoeffFisher coefficients; TMVA::MethodFisher::EFisherMethodfFisherMethodFisher or Mahalanobis ; TMatrixD*fMeanMatx; Double_tfSumOfWeightsBsum-of-weights for background training events; Double_tfSumOfWeightsSsum-of-weights for signal training events; TStringfTheMethodFisher or Mahalanobis; TMatrixD*fWithwithin-class matrix. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodFisher(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& dsi, const TString& theOption = ""Fisher"", TDirectory* theTargetDir = 0); standard constructor for the ""Fisher"". MethodFisher(TMVA::DataSetInfo& dsi, const TString& theWeightFile, TDirectory* theTargetDir = NULL); constructor from weight file. void Init( void ); default initialization called by all constructors. void DeclareOptions(). MethodFisher options:; format and syntax of option string: ""type""; where type is ""Fisher"" or ""Mahalanobis"". void ProcessOptions(); process user options. ~MethodFisher( void ); destructor. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type,",MatchSource.WIKI,root/html532/TMVA__MethodFisher.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodFisher.html
https://root.cern/root/html532/TMVA__MethodFisher.html:21105,Energy Efficiency,power,power,21105,"verall means. void GetCov_WithinClass( void ); the matrix of covariance 'within class' reflects the dispersion of the; events relative to the center of gravity of their own class. void GetCov_BetweenClass( void ); the matrix of covariance 'between class' reflects the dispersion of the; events of a class relative to the global center of gravity of all the class; hence the separation between classes. void GetCov_Full( void ); compute full covariance matrix from sum of within and between matrices. void GetFisherCoeff( void ); Fisher = Sum { [coeff]*[variables] }. let Xs be the array of the mean values of variables for signal evts; let Xb be the array of the mean values of variables for backgd evts; let InvWith be the inverse matrix of the 'within class' correlation matrix. then the array of Fisher coefficients is; [coeff] =sqrt(fNsig*fNbgd)/fNevt*transpose{Xs-Xb}*InvWith. void GetDiscrimPower( void ); computation of discrimination power indicator for each variable; small values of ""fWith"" indicates little compactness of sig & of backgd; big values of ""fBetw"" indicates large separation between sig & backgd. we want signal & backgd classes as compact and separated as possible; the discriminating power is then defined as the ration ""fBetw/fWith"". const TMVA::Ranking* CreateRanking(); computes ranking of input variables. void PrintCoefficients( void ); display Fisher coefficients and discriminating power for each variable; check maximum length of variable name. void ReadWeightsFromStream(istream& i); read Fisher coefficients from weight file. void AddWeightsXMLTo(void* parent) const; create XML description of Fisher classifier. void ReadWeightsFromXML(void* wghtnode); read Fisher coefficients from xml weight file. void MakeClassSpecific(ostream& , const TString& ) const; write Fisher-specific classifier response. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". EFisherMethod",MatchSource.WIKI,root/html532/TMVA__MethodFisher.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodFisher.html
https://root.cern/root/html532/TMVA__MethodFisher.html:21373,Energy Efficiency,power,power,21373,"v_BetweenClass( void ); the matrix of covariance 'between class' reflects the dispersion of the; events of a class relative to the global center of gravity of all the class; hence the separation between classes. void GetCov_Full( void ); compute full covariance matrix from sum of within and between matrices. void GetFisherCoeff( void ); Fisher = Sum { [coeff]*[variables] }. let Xs be the array of the mean values of variables for signal evts; let Xb be the array of the mean values of variables for backgd evts; let InvWith be the inverse matrix of the 'within class' correlation matrix. then the array of Fisher coefficients is; [coeff] =sqrt(fNsig*fNbgd)/fNevt*transpose{Xs-Xb}*InvWith. void GetDiscrimPower( void ); computation of discrimination power indicator for each variable; small values of ""fWith"" indicates little compactness of sig & of backgd; big values of ""fBetw"" indicates large separation between sig & backgd. we want signal & backgd classes as compact and separated as possible; the discriminating power is then defined as the ration ""fBetw/fWith"". const TMVA::Ranking* CreateRanking(); computes ranking of input variables. void PrintCoefficients( void ); display Fisher coefficients and discriminating power for each variable; check maximum length of variable name. void ReadWeightsFromStream(istream& i); read Fisher coefficients from weight file. void AddWeightsXMLTo(void* parent) const; create XML description of Fisher classifier. void ReadWeightsFromXML(void* wghtnode); read Fisher coefficients from xml weight file. void MakeClassSpecific(ostream& , const TString& ) const; write Fisher-specific classifier response. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". EFisherMethod GetFisherMethod( void ); { return fFisherMethod; }. » Author: Andreas Hoecker, Xavier Prudent, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: M",MatchSource.WIKI,root/html532/TMVA__MethodFisher.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodFisher.html
https://root.cern/root/html532/TMVA__MethodFisher.html:21578,Energy Efficiency,power,power,21578," GetCov_Full( void ); compute full covariance matrix from sum of within and between matrices. void GetFisherCoeff( void ); Fisher = Sum { [coeff]*[variables] }. let Xs be the array of the mean values of variables for signal evts; let Xb be the array of the mean values of variables for backgd evts; let InvWith be the inverse matrix of the 'within class' correlation matrix. then the array of Fisher coefficients is; [coeff] =sqrt(fNsig*fNbgd)/fNevt*transpose{Xs-Xb}*InvWith. void GetDiscrimPower( void ); computation of discrimination power indicator for each variable; small values of ""fWith"" indicates little compactness of sig & of backgd; big values of ""fBetw"" indicates large separation between sig & backgd. we want signal & backgd classes as compact and separated as possible; the discriminating power is then defined as the ration ""fBetw/fWith"". const TMVA::Ranking* CreateRanking(); computes ranking of input variables. void PrintCoefficients( void ); display Fisher coefficients and discriminating power for each variable; check maximum length of variable name. void ReadWeightsFromStream(istream& i); read Fisher coefficients from weight file. void AddWeightsXMLTo(void* parent) const; create XML description of Fisher classifier. void ReadWeightsFromXML(void* wghtnode); read Fisher coefficients from xml weight file. void MakeClassSpecific(ostream& , const TString& ) const; write Fisher-specific classifier response. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". EFisherMethod GetFisherMethod( void ); { return fFisherMethod; }. » Author: Andreas Hoecker, Xavier Prudent, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: MethodFisher.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send",MatchSource.WIKI,root/html532/TMVA__MethodFisher.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodFisher.html
https://root.cern/root/html532/TMVA__MethodFisher.html:22039,Integrability,message,message,22039,"ute full covariance matrix from sum of within and between matrices. void GetFisherCoeff( void ); Fisher = Sum { [coeff]*[variables] }. let Xs be the array of the mean values of variables for signal evts; let Xb be the array of the mean values of variables for backgd evts; let InvWith be the inverse matrix of the 'within class' correlation matrix. then the array of Fisher coefficients is; [coeff] =sqrt(fNsig*fNbgd)/fNevt*transpose{Xs-Xb}*InvWith. void GetDiscrimPower( void ); computation of discrimination power indicator for each variable; small values of ""fWith"" indicates little compactness of sig & of backgd; big values of ""fBetw"" indicates large separation between sig & backgd. we want signal & backgd classes as compact and separated as possible; the discriminating power is then defined as the ration ""fBetw/fWith"". const TMVA::Ranking* CreateRanking(); computes ranking of input variables. void PrintCoefficients( void ); display Fisher coefficients and discriminating power for each variable; check maximum length of variable name. void ReadWeightsFromStream(istream& i); read Fisher coefficients from weight file. void AddWeightsXMLTo(void* parent) const; create XML description of Fisher classifier. void ReadWeightsFromXML(void* wghtnode); read Fisher coefficients from xml weight file. void MakeClassSpecific(ostream& , const TString& ) const; write Fisher-specific classifier response. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". EFisherMethod GetFisherMethod( void ); { return fFisherMethod; }. » Author: Andreas Hoecker, Xavier Prudent, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: MethodFisher.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__MethodFisher.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodFisher.html
https://root.cern/root/html532/TMVA__MethodFisher.html:472,Modifiability,variab,variable,472,". TMVA::MethodFisher. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodFisher. class TMVA::MethodFisher: public TMVA::MethodBase. Fisher and Mahalanobis Discriminants (Linear Discriminant Analysis); ; In the method of Fisher discriminants event selection is performed; in a transformed variable space with zero linear correlations, by; distinguishing the mean values of the signal and background; distributions. The linear discriminant analysis determines an axis in the (correlated); hyperspace of the input variables; such that, when projecting the output classes (signal and background); upon this axis, they are pushed as far as possible away from each other,; while events of a same class are confined in a close vicinity.; The linearity property of this method is reflected in the metric with; which ""far apart"" and ""close vicinity"" are determined: the covariance; matrix of the discriminant variable space.; . The classification of the events in signal and background classes; relies on the following characteristics (only): overall sample means,; xi, for each input variable, i,; class-specific sample means, xS(B),i,; and total covariance matrix Tij. The covariance matrix; can be decomposed into the sum of a within- (Wij); and a between-class (Bij) class matrix. They describe; the dispersion of events relative to the means of their own class (within-class; matrix), and relative to the overall sample means (between-class matrix).; The Fisher coefficients, Fi, are then given by . where in TMVA is set NS=NB, so that the factor; in front of the sum simplifies to ½.; The Fisher discriminant then reads. The offset F0 centers the sample mean of xFi; at zero. Instead of using the within-class matrix, the Mahalanobis variant; determines the Fisher coefficients as follows:. with resulting xMa that are v",MatchSource.WIKI,root/html532/TMVA__MethodFisher.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodFisher.html
https://root.cern/root/html532/TMVA__MethodFisher.html:695,Modifiability,variab,variables,695,". TMVA::MethodFisher. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodFisher. class TMVA::MethodFisher: public TMVA::MethodBase. Fisher and Mahalanobis Discriminants (Linear Discriminant Analysis); ; In the method of Fisher discriminants event selection is performed; in a transformed variable space with zero linear correlations, by; distinguishing the mean values of the signal and background; distributions. The linear discriminant analysis determines an axis in the (correlated); hyperspace of the input variables; such that, when projecting the output classes (signal and background); upon this axis, they are pushed as far as possible away from each other,; while events of a same class are confined in a close vicinity.; The linearity property of this method is reflected in the metric with; which ""far apart"" and ""close vicinity"" are determined: the covariance; matrix of the discriminant variable space.; . The classification of the events in signal and background classes; relies on the following characteristics (only): overall sample means,; xi, for each input variable, i,; class-specific sample means, xS(B),i,; and total covariance matrix Tij. The covariance matrix; can be decomposed into the sum of a within- (Wij); and a between-class (Bij) class matrix. They describe; the dispersion of events relative to the means of their own class (within-class; matrix), and relative to the overall sample means (between-class matrix).; The Fisher coefficients, Fi, are then given by . where in TMVA is set NS=NB, so that the factor; in front of the sum simplifies to ½.; The Fisher discriminant then reads. The offset F0 centers the sample mean of xFi; at zero. Instead of using the within-class matrix, the Mahalanobis variant; determines the Fisher coefficients as follows:. with resulting xMa that are v",MatchSource.WIKI,root/html532/TMVA__MethodFisher.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodFisher.html
https://root.cern/root/html532/TMVA__MethodFisher.html:1084,Modifiability,variab,variable,1084,"::MethodFisher. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodFisher. class TMVA::MethodFisher: public TMVA::MethodBase. Fisher and Mahalanobis Discriminants (Linear Discriminant Analysis); ; In the method of Fisher discriminants event selection is performed; in a transformed variable space with zero linear correlations, by; distinguishing the mean values of the signal and background; distributions. The linear discriminant analysis determines an axis in the (correlated); hyperspace of the input variables; such that, when projecting the output classes (signal and background); upon this axis, they are pushed as far as possible away from each other,; while events of a same class are confined in a close vicinity.; The linearity property of this method is reflected in the metric with; which ""far apart"" and ""close vicinity"" are determined: the covariance; matrix of the discriminant variable space.; . The classification of the events in signal and background classes; relies on the following characteristics (only): overall sample means,; xi, for each input variable, i,; class-specific sample means, xS(B),i,; and total covariance matrix Tij. The covariance matrix; can be decomposed into the sum of a within- (Wij); and a between-class (Bij) class matrix. They describe; the dispersion of events relative to the means of their own class (within-class; matrix), and relative to the overall sample means (between-class matrix).; The Fisher coefficients, Fi, are then given by . where in TMVA is set NS=NB, so that the factor; in front of the sum simplifies to ½.; The Fisher discriminant then reads. The offset F0 centers the sample mean of xFi; at zero. Instead of using the within-class matrix, the Mahalanobis variant; determines the Fisher coefficients as follows:. with resulting xMa that are very s",MatchSource.WIKI,root/html532/TMVA__MethodFisher.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodFisher.html
https://root.cern/root/html532/TMVA__MethodFisher.html:1260,Modifiability,variab,variable,1260,"arts. ROOT; » TMVA; » TMVA::MethodFisher. class TMVA::MethodFisher: public TMVA::MethodBase. Fisher and Mahalanobis Discriminants (Linear Discriminant Analysis); ; In the method of Fisher discriminants event selection is performed; in a transformed variable space with zero linear correlations, by; distinguishing the mean values of the signal and background; distributions. The linear discriminant analysis determines an axis in the (correlated); hyperspace of the input variables; such that, when projecting the output classes (signal and background); upon this axis, they are pushed as far as possible away from each other,; while events of a same class are confined in a close vicinity.; The linearity property of this method is reflected in the metric with; which ""far apart"" and ""close vicinity"" are determined: the covariance; matrix of the discriminant variable space.; . The classification of the events in signal and background classes; relies on the following characteristics (only): overall sample means,; xi, for each input variable, i,; class-specific sample means, xS(B),i,; and total covariance matrix Tij. The covariance matrix; can be decomposed into the sum of a within- (Wij); and a between-class (Bij) class matrix. They describe; the dispersion of events relative to the means of their own class (within-class; matrix), and relative to the overall sample means (between-class matrix).; The Fisher coefficients, Fi, are then given by . where in TMVA is set NS=NB, so that the factor; in front of the sum simplifies to ½.; The Fisher discriminant then reads. The offset F0 centers the sample mean of xFi; at zero. Instead of using the within-class matrix, the Mahalanobis variant; determines the Fisher coefficients as follows:. with resulting xMa that are very similar to the; xFi. ; TMVA provides two outputs for the ranking of the input variables:. Fisher test: the Fisher analysis aims at simultaneously maximising; the between-class separation, while minimising the within-cla",MatchSource.WIKI,root/html532/TMVA__MethodFisher.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodFisher.html
https://root.cern/root/html532/TMVA__MethodFisher.html:2083,Modifiability,variab,variables,2083,"trix of the discriminant variable space.; . The classification of the events in signal and background classes; relies on the following characteristics (only): overall sample means,; xi, for each input variable, i,; class-specific sample means, xS(B),i,; and total covariance matrix Tij. The covariance matrix; can be decomposed into the sum of a within- (Wij); and a between-class (Bij) class matrix. They describe; the dispersion of events relative to the means of their own class (within-class; matrix), and relative to the overall sample means (between-class matrix).; The Fisher coefficients, Fi, are then given by . where in TMVA is set NS=NB, so that the factor; in front of the sum simplifies to ½.; The Fisher discriminant then reads. The offset F0 centers the sample mean of xFi; at zero. Instead of using the within-class matrix, the Mahalanobis variant; determines the Fisher coefficients as follows:. with resulting xMa that are very similar to the; xFi. ; TMVA provides two outputs for the ranking of the input variables:. Fisher test: the Fisher analysis aims at simultaneously maximising; the between-class separation, while minimising the within-class dispersion.; A useful measure of the discrimination power of a variable is hence given; by the diagonal quantity: Bii/Wii.; ; Discrimination power: the value of the Fisher coefficient is a; measure of the discriminating power of a variable. The discrimination power; of set of input variables can therefore be measured by the scalar; . The corresponding numbers are printed on standard output.; ; . Function Members (Methods); public:. virtual~MethodFisher(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virt",MatchSource.WIKI,root/html532/TMVA__MethodFisher.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodFisher.html
https://root.cern/root/html532/TMVA__MethodFisher.html:2290,Modifiability,variab,variable,2290,"le means, xS(B),i,; and total covariance matrix Tij. The covariance matrix; can be decomposed into the sum of a within- (Wij); and a between-class (Bij) class matrix. They describe; the dispersion of events relative to the means of their own class (within-class; matrix), and relative to the overall sample means (between-class matrix).; The Fisher coefficients, Fi, are then given by . where in TMVA is set NS=NB, so that the factor; in front of the sum simplifies to ½.; The Fisher discriminant then reads. The offset F0 centers the sample mean of xFi; at zero. Instead of using the within-class matrix, the Mahalanobis variant; determines the Fisher coefficients as follows:. with resulting xMa that are very similar to the; xFi. ; TMVA provides two outputs for the ranking of the input variables:. Fisher test: the Fisher analysis aims at simultaneously maximising; the between-class separation, while minimising the within-class dispersion.; A useful measure of the discrimination power of a variable is hence given; by the diagonal quantity: Bii/Wii.; ; Discrimination power: the value of the Fisher coefficient is a; measure of the discriminating power of a variable. The discrimination power; of set of input variables can therefore be measured by the scalar; . The corresponding numbers are printed on standard output.; ; . Function Members (Methods); public:. virtual~MethodFisher(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidTMVA::MethodBase::CheckSetup(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(",MatchSource.WIKI,root/html532/TMVA__MethodFisher.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodFisher.html
https://root.cern/root/html532/TMVA__MethodFisher.html:2458,Modifiability,variab,variable,2458,"hin- (Wij); and a between-class (Bij) class matrix. They describe; the dispersion of events relative to the means of their own class (within-class; matrix), and relative to the overall sample means (between-class matrix).; The Fisher coefficients, Fi, are then given by . where in TMVA is set NS=NB, so that the factor; in front of the sum simplifies to ½.; The Fisher discriminant then reads. The offset F0 centers the sample mean of xFi; at zero. Instead of using the within-class matrix, the Mahalanobis variant; determines the Fisher coefficients as follows:. with resulting xMa that are very similar to the; xFi. ; TMVA provides two outputs for the ranking of the input variables:. Fisher test: the Fisher analysis aims at simultaneously maximising; the between-class separation, while minimising the within-class dispersion.; A useful measure of the discrimination power of a variable is hence given; by the diagonal quantity: Bii/Wii.; ; Discrimination power: the value of the Fisher coefficient is a; measure of the discriminating power of a variable. The discrimination power; of set of input variables can therefore be measured by the scalar; . The corresponding numbers are printed on standard output.; ; . Function Members (Methods); public:. virtual~MethodFisher(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidTMVA::MethodBase::CheckSetup(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(con",MatchSource.WIKI,root/html532/TMVA__MethodFisher.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodFisher.html
https://root.cern/root/html532/TMVA__MethodFisher.html:2510,Modifiability,variab,variables,2510,"e means of their own class (within-class; matrix), and relative to the overall sample means (between-class matrix).; The Fisher coefficients, Fi, are then given by . where in TMVA is set NS=NB, so that the factor; in front of the sum simplifies to ½.; The Fisher discriminant then reads. The offset F0 centers the sample mean of xFi; at zero. Instead of using the within-class matrix, the Mahalanobis variant; determines the Fisher coefficients as follows:. with resulting xMa that are very similar to the; xFi. ; TMVA provides two outputs for the ranking of the input variables:. Fisher test: the Fisher analysis aims at simultaneously maximising; the between-class separation, while minimising the within-class dispersion.; A useful measure of the discrimination power of a variable is hence given; by the diagonal quantity: Bii/Wii.; ; Discrimination power: the value of the Fisher coefficient is a; measure of the discriminating power of a variable. The discrimination power; of set of input variables can therefore be measured by the scalar; . The corresponding numbers are printed on standard output.; ; . Function Members (Methods); public:. virtual~MethodFisher(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidTMVA::MethodBase::CheckSetup(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); ",MatchSource.WIKI,root/html532/TMVA__MethodFisher.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodFisher.html
https://root.cern/root/html532/TMVA__MethodFisher.html:17826,Modifiability,variab,variables,17826,"s; public:. enum EFisherMethod { kFisher; kMahalanobis; };; enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. TMatrixD*fBetwbetween-class matrix; TMatrixD*fCovfull covariance matrix; vector<Double_t>*fDiscrimPowdiscriminating power; Double_tfF0offset; vector<Double_t>*fFisherCoeffFisher coefficients; TMVA::MethodFisher::EFisherMethodfFisherMethodFisher or Mahalanobis ; TMatrixD*fMeanMatx; Double_tfSumOfWeightsBsum-of-weights for background training events; Double_tfSumOfWeightsSsum-of-weights for signal training events; TStringfTheMethodFisher or Mahalanobis; TMatrixD*fWithwithin-class matrix. Class Charts. Inheritance; Inherited Members; Includes; Librari",MatchSource.WIKI,root/html532/TMVA__MethodFisher.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodFisher.html
https://root.cern/root/html532/TMVA__MethodFisher.html:18015,Modifiability,variab,variable,18015,"s; public:. enum EFisherMethod { kFisher; kMahalanobis; };; enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. TMatrixD*fBetwbetween-class matrix; TMatrixD*fCovfull covariance matrix; vector<Double_t>*fDiscrimPowdiscriminating power; Double_tfF0offset; vector<Double_t>*fFisherCoeffFisher coefficients; TMVA::MethodFisher::EFisherMethodfFisherMethodFisher or Mahalanobis ; TMatrixD*fMeanMatx; Double_tfSumOfWeightsBsum-of-weights for background training events; Double_tfSumOfWeightsSsum-of-weights for signal training events; TStringfTheMethodFisher or Mahalanobis; TMatrixD*fWithwithin-class matrix. Class Charts. Inheritance; Inherited Members; Includes; Librari",MatchSource.WIKI,root/html532/TMVA__MethodFisher.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodFisher.html
https://root.cern/root/html532/TMVA__MethodFisher.html:20128,Modifiability,variab,variables,20128,"onst TString& theOption = ""Fisher"", TDirectory* theTargetDir = 0); standard constructor for the ""Fisher"". MethodFisher(TMVA::DataSetInfo& dsi, const TString& theWeightFile, TDirectory* theTargetDir = NULL); constructor from weight file. void Init( void ); default initialization called by all constructors. void DeclareOptions(). MethodFisher options:; format and syntax of option string: ""type""; where type is ""Fisher"" or ""Mahalanobis"". void ProcessOptions(); process user options. ~MethodFisher( void ); destructor. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); Fisher can only handle classification with 2 classes. void Train( void ); computation of Fisher coefficients by series of matrix operations. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); returns the Fisher value (no fixed range). void InitMatrices( void ); initializaton method; creates global matrices and vectors. void GetMean( void ); compute mean values of variables in each sample, and the overall means. void GetCov_WithinClass( void ); the matrix of covariance 'within class' reflects the dispersion of the; events relative to the center of gravity of their own class. void GetCov_BetweenClass( void ); the matrix of covariance 'between class' reflects the dispersion of the; events of a class relative to the global center of gravity of all the class; hence the separation between classes. void GetCov_Full( void ); compute full covariance matrix from sum of within and between matrices. void GetFisherCoeff( void ); Fisher = Sum { [coeff]*[variables] }. let Xs be the array of the mean values of variables for signal evts; let Xb be the array of the mean values of variables for backgd evts; let InvWith be the inverse matrix of the 'within class' correlation matrix. then the array of Fisher coefficients is; [coeff] =sqrt(fNsig*fNbgd)/fNevt*transpose{Xs-Xb}*InvWith. void GetDiscrimPower( void ); computation of discrimination power indicator for each",MatchSource.WIKI,root/html532/TMVA__MethodFisher.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodFisher.html
https://root.cern/root/html532/TMVA__MethodFisher.html:20716,Modifiability,variab,variables,20716,"e type, UInt_t numberClasses, UInt_t numberTargets); Fisher can only handle classification with 2 classes. void Train( void ); computation of Fisher coefficients by series of matrix operations. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); returns the Fisher value (no fixed range). void InitMatrices( void ); initializaton method; creates global matrices and vectors. void GetMean( void ); compute mean values of variables in each sample, and the overall means. void GetCov_WithinClass( void ); the matrix of covariance 'within class' reflects the dispersion of the; events relative to the center of gravity of their own class. void GetCov_BetweenClass( void ); the matrix of covariance 'between class' reflects the dispersion of the; events of a class relative to the global center of gravity of all the class; hence the separation between classes. void GetCov_Full( void ); compute full covariance matrix from sum of within and between matrices. void GetFisherCoeff( void ); Fisher = Sum { [coeff]*[variables] }. let Xs be the array of the mean values of variables for signal evts; let Xb be the array of the mean values of variables for backgd evts; let InvWith be the inverse matrix of the 'within class' correlation matrix. then the array of Fisher coefficients is; [coeff] =sqrt(fNsig*fNbgd)/fNevt*transpose{Xs-Xb}*InvWith. void GetDiscrimPower( void ); computation of discrimination power indicator for each variable; small values of ""fWith"" indicates little compactness of sig & of backgd; big values of ""fBetw"" indicates large separation between sig & backgd. we want signal & backgd classes as compact and separated as possible; the discriminating power is then defined as the ration ""fBetw/fWith"". const TMVA::Ranking* CreateRanking(); computes ranking of input variables. void PrintCoefficients( void ); display Fisher coefficients and discriminating power for each variable; check maximum length of variable name. void ReadWeightsFromStream(istream& i); read Fisher co",MatchSource.WIKI,root/html532/TMVA__MethodFisher.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodFisher.html
https://root.cern/root/html532/TMVA__MethodFisher.html:20772,Modifiability,variab,variables,20772," Fisher coefficients by series of matrix operations. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); returns the Fisher value (no fixed range). void InitMatrices( void ); initializaton method; creates global matrices and vectors. void GetMean( void ); compute mean values of variables in each sample, and the overall means. void GetCov_WithinClass( void ); the matrix of covariance 'within class' reflects the dispersion of the; events relative to the center of gravity of their own class. void GetCov_BetweenClass( void ); the matrix of covariance 'between class' reflects the dispersion of the; events of a class relative to the global center of gravity of all the class; hence the separation between classes. void GetCov_Full( void ); compute full covariance matrix from sum of within and between matrices. void GetFisherCoeff( void ); Fisher = Sum { [coeff]*[variables] }. let Xs be the array of the mean values of variables for signal evts; let Xb be the array of the mean values of variables for backgd evts; let InvWith be the inverse matrix of the 'within class' correlation matrix. then the array of Fisher coefficients is; [coeff] =sqrt(fNsig*fNbgd)/fNevt*transpose{Xs-Xb}*InvWith. void GetDiscrimPower( void ); computation of discrimination power indicator for each variable; small values of ""fWith"" indicates little compactness of sig & of backgd; big values of ""fBetw"" indicates large separation between sig & backgd. we want signal & backgd classes as compact and separated as possible; the discriminating power is then defined as the ration ""fBetw/fWith"". const TMVA::Ranking* CreateRanking(); computes ranking of input variables. void PrintCoefficients( void ); display Fisher coefficients and discriminating power for each variable; check maximum length of variable name. void ReadWeightsFromStream(istream& i); read Fisher coefficients from weight file. void AddWeightsXMLTo(void* parent) const; create XML description of Fisher classifier. void ReadWeightsFromXML(",MatchSource.WIKI,root/html532/TMVA__MethodFisher.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodFisher.html
https://root.cern/root/html532/TMVA__MethodFisher.html:20841,Modifiability,variab,variables,20841," Fisher coefficients by series of matrix operations. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); returns the Fisher value (no fixed range). void InitMatrices( void ); initializaton method; creates global matrices and vectors. void GetMean( void ); compute mean values of variables in each sample, and the overall means. void GetCov_WithinClass( void ); the matrix of covariance 'within class' reflects the dispersion of the; events relative to the center of gravity of their own class. void GetCov_BetweenClass( void ); the matrix of covariance 'between class' reflects the dispersion of the; events of a class relative to the global center of gravity of all the class; hence the separation between classes. void GetCov_Full( void ); compute full covariance matrix from sum of within and between matrices. void GetFisherCoeff( void ); Fisher = Sum { [coeff]*[variables] }. let Xs be the array of the mean values of variables for signal evts; let Xb be the array of the mean values of variables for backgd evts; let InvWith be the inverse matrix of the 'within class' correlation matrix. then the array of Fisher coefficients is; [coeff] =sqrt(fNsig*fNbgd)/fNevt*transpose{Xs-Xb}*InvWith. void GetDiscrimPower( void ); computation of discrimination power indicator for each variable; small values of ""fWith"" indicates little compactness of sig & of backgd; big values of ""fBetw"" indicates large separation between sig & backgd. we want signal & backgd classes as compact and separated as possible; the discriminating power is then defined as the ration ""fBetw/fWith"". const TMVA::Ranking* CreateRanking(); computes ranking of input variables. void PrintCoefficients( void ); display Fisher coefficients and discriminating power for each variable; check maximum length of variable name. void ReadWeightsFromStream(istream& i); read Fisher coefficients from weight file. void AddWeightsXMLTo(void* parent) const; create XML description of Fisher classifier. void ReadWeightsFromXML(",MatchSource.WIKI,root/html532/TMVA__MethodFisher.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodFisher.html
https://root.cern/root/html532/TMVA__MethodFisher.html:21130,Modifiability,variab,variable,21130,"verall means. void GetCov_WithinClass( void ); the matrix of covariance 'within class' reflects the dispersion of the; events relative to the center of gravity of their own class. void GetCov_BetweenClass( void ); the matrix of covariance 'between class' reflects the dispersion of the; events of a class relative to the global center of gravity of all the class; hence the separation between classes. void GetCov_Full( void ); compute full covariance matrix from sum of within and between matrices. void GetFisherCoeff( void ); Fisher = Sum { [coeff]*[variables] }. let Xs be the array of the mean values of variables for signal evts; let Xb be the array of the mean values of variables for backgd evts; let InvWith be the inverse matrix of the 'within class' correlation matrix. then the array of Fisher coefficients is; [coeff] =sqrt(fNsig*fNbgd)/fNevt*transpose{Xs-Xb}*InvWith. void GetDiscrimPower( void ); computation of discrimination power indicator for each variable; small values of ""fWith"" indicates little compactness of sig & of backgd; big values of ""fBetw"" indicates large separation between sig & backgd. we want signal & backgd classes as compact and separated as possible; the discriminating power is then defined as the ration ""fBetw/fWith"". const TMVA::Ranking* CreateRanking(); computes ranking of input variables. void PrintCoefficients( void ); display Fisher coefficients and discriminating power for each variable; check maximum length of variable name. void ReadWeightsFromStream(istream& i); read Fisher coefficients from weight file. void AddWeightsXMLTo(void* parent) const; create XML description of Fisher classifier. void ReadWeightsFromXML(void* wghtnode); read Fisher coefficients from xml weight file. void MakeClassSpecific(ostream& , const TString& ) const; write Fisher-specific classifier response. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". EFisherMethod",MatchSource.WIKI,root/html532/TMVA__MethodFisher.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodFisher.html
https://root.cern/root/html532/TMVA__MethodFisher.html:21488,Modifiability,variab,variables,21488,"a class relative to the global center of gravity of all the class; hence the separation between classes. void GetCov_Full( void ); compute full covariance matrix from sum of within and between matrices. void GetFisherCoeff( void ); Fisher = Sum { [coeff]*[variables] }. let Xs be the array of the mean values of variables for signal evts; let Xb be the array of the mean values of variables for backgd evts; let InvWith be the inverse matrix of the 'within class' correlation matrix. then the array of Fisher coefficients is; [coeff] =sqrt(fNsig*fNbgd)/fNevt*transpose{Xs-Xb}*InvWith. void GetDiscrimPower( void ); computation of discrimination power indicator for each variable; small values of ""fWith"" indicates little compactness of sig & of backgd; big values of ""fBetw"" indicates large separation between sig & backgd. we want signal & backgd classes as compact and separated as possible; the discriminating power is then defined as the ration ""fBetw/fWith"". const TMVA::Ranking* CreateRanking(); computes ranking of input variables. void PrintCoefficients( void ); display Fisher coefficients and discriminating power for each variable; check maximum length of variable name. void ReadWeightsFromStream(istream& i); read Fisher coefficients from weight file. void AddWeightsXMLTo(void* parent) const; create XML description of Fisher classifier. void ReadWeightsFromXML(void* wghtnode); read Fisher coefficients from xml weight file. void MakeClassSpecific(ostream& , const TString& ) const; write Fisher-specific classifier response. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". EFisherMethod GetFisherMethod( void ); { return fFisherMethod; }. » Author: Andreas Hoecker, Xavier Prudent, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: MethodFisher.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been au",MatchSource.WIKI,root/html532/TMVA__MethodFisher.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodFisher.html
https://root.cern/root/html532/TMVA__MethodFisher.html:21593,Modifiability,variab,variable,21593," GetCov_Full( void ); compute full covariance matrix from sum of within and between matrices. void GetFisherCoeff( void ); Fisher = Sum { [coeff]*[variables] }. let Xs be the array of the mean values of variables for signal evts; let Xb be the array of the mean values of variables for backgd evts; let InvWith be the inverse matrix of the 'within class' correlation matrix. then the array of Fisher coefficients is; [coeff] =sqrt(fNsig*fNbgd)/fNevt*transpose{Xs-Xb}*InvWith. void GetDiscrimPower( void ); computation of discrimination power indicator for each variable; small values of ""fWith"" indicates little compactness of sig & of backgd; big values of ""fBetw"" indicates large separation between sig & backgd. we want signal & backgd classes as compact and separated as possible; the discriminating power is then defined as the ration ""fBetw/fWith"". const TMVA::Ranking* CreateRanking(); computes ranking of input variables. void PrintCoefficients( void ); display Fisher coefficients and discriminating power for each variable; check maximum length of variable name. void ReadWeightsFromStream(istream& i); read Fisher coefficients from weight file. void AddWeightsXMLTo(void* parent) const; create XML description of Fisher classifier. void ReadWeightsFromXML(void* wghtnode); read Fisher coefficients from xml weight file. void MakeClassSpecific(ostream& , const TString& ) const; write Fisher-specific classifier response. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". EFisherMethod GetFisherMethod( void ); { return fFisherMethod; }. » Author: Andreas Hoecker, Xavier Prudent, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: MethodFisher.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send",MatchSource.WIKI,root/html532/TMVA__MethodFisher.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodFisher.html
https://root.cern/root/html532/TMVA__MethodFisher.html:21627,Modifiability,variab,variable,21627," GetCov_Full( void ); compute full covariance matrix from sum of within and between matrices. void GetFisherCoeff( void ); Fisher = Sum { [coeff]*[variables] }. let Xs be the array of the mean values of variables for signal evts; let Xb be the array of the mean values of variables for backgd evts; let InvWith be the inverse matrix of the 'within class' correlation matrix. then the array of Fisher coefficients is; [coeff] =sqrt(fNsig*fNbgd)/fNevt*transpose{Xs-Xb}*InvWith. void GetDiscrimPower( void ); computation of discrimination power indicator for each variable; small values of ""fWith"" indicates little compactness of sig & of backgd; big values of ""fBetw"" indicates large separation between sig & backgd. we want signal & backgd classes as compact and separated as possible; the discriminating power is then defined as the ration ""fBetw/fWith"". const TMVA::Ranking* CreateRanking(); computes ranking of input variables. void PrintCoefficients( void ); display Fisher coefficients and discriminating power for each variable; check maximum length of variable name. void ReadWeightsFromStream(istream& i); read Fisher coefficients from weight file. void AddWeightsXMLTo(void* parent) const; create XML description of Fisher classifier. void ReadWeightsFromXML(void* wghtnode); read Fisher coefficients from xml weight file. void MakeClassSpecific(ostream& , const TString& ) const; write Fisher-specific classifier response. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". EFisherMethod GetFisherMethod( void ); { return fFisherMethod; }. » Author: Andreas Hoecker, Xavier Prudent, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: MethodFisher.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send",MatchSource.WIKI,root/html532/TMVA__MethodFisher.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodFisher.html
https://root.cern/root/html532/TMVA__MethodFisher.html:444,Performance,perform,performed,444,". TMVA::MethodFisher. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodFisher. class TMVA::MethodFisher: public TMVA::MethodBase. Fisher and Mahalanobis Discriminants (Linear Discriminant Analysis); ; In the method of Fisher discriminants event selection is performed; in a transformed variable space with zero linear correlations, by; distinguishing the mean values of the signal and background; distributions. The linear discriminant analysis determines an axis in the (correlated); hyperspace of the input variables; such that, when projecting the output classes (signal and background); upon this axis, they are pushed as far as possible away from each other,; while events of a same class are confined in a close vicinity.; The linearity property of this method is reflected in the metric with; which ""far apart"" and ""close vicinity"" are determined: the covariance; matrix of the discriminant variable space.; . The classification of the events in signal and background classes; relies on the following characteristics (only): overall sample means,; xi, for each input variable, i,; class-specific sample means, xS(B),i,; and total covariance matrix Tij. The covariance matrix; can be decomposed into the sum of a within- (Wij); and a between-class (Bij) class matrix. They describe; the dispersion of events relative to the means of their own class (within-class; matrix), and relative to the overall sample means (between-class matrix).; The Fisher coefficients, Fi, are then given by . where in TMVA is set NS=NB, so that the factor; in front of the sum simplifies to ½.; The Fisher discriminant then reads. The offset F0 centers the sample mean of xFi; at zero. Instead of using the within-class matrix, the Mahalanobis variant; determines the Fisher coefficients as follows:. with resulting xMa that are v",MatchSource.WIKI,root/html532/TMVA__MethodFisher.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodFisher.html
https://root.cern/root/html532/TMVA__MethodFisher.html:13661,Performance,tune,tuneParameters,13661,"voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int",MatchSource.WIKI,root/html532/TMVA__MethodFisher.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodFisher.html
https://root.cern/root/html532/TMVA__MethodFisher.html:2102,Testability,test,test,2102,"es; relies on the following characteristics (only): overall sample means,; xi, for each input variable, i,; class-specific sample means, xS(B),i,; and total covariance matrix Tij. The covariance matrix; can be decomposed into the sum of a within- (Wij); and a between-class (Bij) class matrix. They describe; the dispersion of events relative to the means of their own class (within-class; matrix), and relative to the overall sample means (between-class matrix).; The Fisher coefficients, Fi, are then given by . where in TMVA is set NS=NB, so that the factor; in front of the sum simplifies to ½.; The Fisher discriminant then reads. The offset F0 centers the sample mean of xFi; at zero. Instead of using the within-class matrix, the Mahalanobis variant; determines the Fisher coefficients as follows:. with resulting xMa that are very similar to the; xFi. ; TMVA provides two outputs for the ranking of the input variables:. Fisher test: the Fisher analysis aims at simultaneously maximising; the between-class separation, while minimising the within-class dispersion.; A useful measure of the discrimination power of a variable is hence given; by the diagonal quantity: Bii/Wii.; ; Discrimination power: the value of the Fisher coefficient is a; measure of the discriminating power of a variable. The discrimination power; of set of input variables can therefore be measured by the scalar; . The corresponding numbers are printed on standard output.; ; . Function Members (Methods); public:. virtual~MethodFisher(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidT",MatchSource.WIKI,root/html532/TMVA__MethodFisher.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodFisher.html
https://root.cern/root/html532/TMVA__MethodFisher.html:13463,Testability,test,testTime,13463,"am& out, Option_t* option = """"); virtual voidTMVA::MethodBase::SetAnalysisType(TMVA::Types::EAnalysisType type); voidTMVA::MethodBase::SetBaseDir(TDirectory* methodDir); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObj",MatchSource.WIKI,root/html532/TMVA__MethodFisher.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodFisher.html
https://root.cern/root/html532/TMVA__MethodFisher.html:17516,Testability,test,testing,17516,"reeType treeType, const TString& theVarName, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&); Bool_tTMVA::MethodBase::TxtWeightsOnly() const; Bool_tTMVA::MethodBase::Verbose() const; voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. virtual voidDeclareOptions(); voidGetCov_BetweenClass(); voidGetCov_Full(); voidGetCov_WithinClass(); voidGetDiscrimPower(); voidGetFisherCoeff(); voidGetMean(); virtual voidInit(); voidInitMatrices(); voidPrintCoefficients(); virtual voidProcessOptions(). Data Members; public:. enum EFisherMethod { kFisher; kMahalanobis; };; enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. TMatrixD*fBetwbetween",MatchSource.WIKI,root/html532/TMVA__MethodFisher.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodFisher.html
https://root.cern/root/html532/TMVA__MethodFisher.html:1748,Usability,simpl,simplifies,1748," projecting the output classes (signal and background); upon this axis, they are pushed as far as possible away from each other,; while events of a same class are confined in a close vicinity.; The linearity property of this method is reflected in the metric with; which ""far apart"" and ""close vicinity"" are determined: the covariance; matrix of the discriminant variable space.; . The classification of the events in signal and background classes; relies on the following characteristics (only): overall sample means,; xi, for each input variable, i,; class-specific sample means, xS(B),i,; and total covariance matrix Tij. The covariance matrix; can be decomposed into the sum of a within- (Wij); and a between-class (Bij) class matrix. They describe; the dispersion of events relative to the means of their own class (within-class; matrix), and relative to the overall sample means (between-class matrix).; The Fisher coefficients, Fi, are then given by . where in TMVA is set NS=NB, so that the factor; in front of the sum simplifies to ½.; The Fisher discriminant then reads. The offset F0 centers the sample mean of xFi; at zero. Instead of using the within-class matrix, the Mahalanobis variant; determines the Fisher coefficients as follows:. with resulting xMa that are very similar to the; xFi. ; TMVA provides two outputs for the ranking of the input variables:. Fisher test: the Fisher analysis aims at simultaneously maximising; the between-class separation, while minimising the within-class dispersion.; A useful measure of the discrimination power of a variable is hence given; by the diagonal quantity: Bii/Wii.; ; Discrimination power: the value of the Fisher coefficient is a; measure of the discriminating power of a variable. The discrimination power; of set of input variables can therefore be measured by the scalar; . The corresponding numbers are printed on standard output.; ; . Function Members (Methods); public:. virtual~MethodFisher(); voidTObject::AbstractMethod(const c",MatchSource.WIKI,root/html532/TMVA__MethodFisher.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodFisher.html
https://root.cern/root/html532/TMVA__MethodHMatrix.html:2862,Availability,error,error,2862,"t::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt, TMVA::Types",MatchSource.WIKI,root/html532/TMVA__MethodHMatrix.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodHMatrix.html
https://root.cern/root/html532/TMVA__MethodHMatrix.html:2946,Availability,error,error,2946,"able(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt, TMVA::Types::ETreeType type) const; const vector<TMVA::Event*>&TMVA::MethodBase::GetEventCollec",MatchSource.WIKI,root/html532/TMVA__MethodHMatrix.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodHMatrix.html
https://root.cern/root/html532/TMVA__MethodHMatrix.html:18697,Integrability,message,message,18697,"andard constructor for the H-Matrix method. MethodHMatrix(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL); constructor from weight file. void Init( void ); default initialization called by all constructors. ~MethodHMatrix( void ); destructor. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); FDA can handle classification with 2 classes and regression with one regression-target. void DeclareOptions(); MethodHMatrix options: none (apart from those implemented in MethodBase). void ProcessOptions(); process user options. void Train( void ); computes H-matrices for signal and background samples. void ComputeCovariance(Bool_t , TMatrixD* ); compute covariance matrix. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); returns the H-matrix signal estimator. Double_t GetChi2(TMVA::Types::ESBType ); compute chi2-estimator for event according to type (signal/background). void AddWeightsXMLTo(void* parent) const; create XML description for HMatrix classification. void ReadWeightsFromXML(void* wghtnode); read weights from XML file. void ReadWeightsFromStream(istream& istr); read variable names and min/max; NOTE: the latter values are mandatory for the normalisation; in the reader application !!!. void MakeClassSpecific(ostream& , const TString& ) const; write Fisher-specific classifier response. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". const Ranking* CreateRanking(); ranking of input variables. { return 0; }. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: MethodHMatrix.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__MethodHMatrix.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodHMatrix.html
https://root.cern/root/html532/TMVA__MethodHMatrix.html:501,Modifiability,variab,variables,501,". TMVA::MethodHMatrix. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodHMatrix. class TMVA::MethodHMatrix: public TMVA::MethodBase. /*; H-Matrix method, which is implemented as a simple comparison of; chi-squared estimators for signal and background, taking into; account the linear correlations between the input variables; This MVA approach is used by the DØ collaboration (FNAL) for the; purpose of electron identification (see, eg.,; hep-ex/9507007).; As it is implemented in TMVA, it is usually equivalent or worse than; the Fisher-Mahalanobis discriminant, and it has only been added for; the purpose of completeness.; Two χ2 estimators are computed for an event, each one; for signal and background, using the estimates for the means and; covariance matrices obtained from the training sample:. TMVA then uses as normalised analyser for event (i) the ratio:; (χS(i)2 − χB2(i)); (χS2(i) + χB2(i)).; */. Function Members (Methods); public:. virtual~MethodHMatrix(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidTMVA::MethodBase::CheckSetup(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTOb",MatchSource.WIKI,root/html532/TMVA__MethodHMatrix.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodHMatrix.html
https://root.cern/root/html532/TMVA__MethodHMatrix.html:16163,Modifiability,variab,variables,16163,"nit(); virtual voidProcessOptions(). Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. TMatrixD*fInvHMatrixBinverse H-matrix (background); TMatrixD*fInvHMatrixSinverse H-matrix (signal); TVectorD*fVecMeanBvector of mean values (background); TVectorD*fVecMeanSvector of mean values (signal). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodHMatrix(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = """", TDirectory* theTargetDir = 0); standard constructor for the H-Matrix method. MethodHMatrix(TMVA::DataSetInfo& theData, const TString& ",MatchSource.WIKI,root/html532/TMVA__MethodHMatrix.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodHMatrix.html
https://root.cern/root/html532/TMVA__MethodHMatrix.html:16352,Modifiability,variab,variable,16352,"nit(); virtual voidProcessOptions(). Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. TMatrixD*fInvHMatrixBinverse H-matrix (background); TMatrixD*fInvHMatrixSinverse H-matrix (signal); TVectorD*fVecMeanBvector of mean values (background); TVectorD*fVecMeanSvector of mean values (signal). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodHMatrix(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = """", TDirectory* theTargetDir = 0); standard constructor for the H-Matrix method. MethodHMatrix(TMVA::DataSetInfo& theData, const TString& ",MatchSource.WIKI,root/html532/TMVA__MethodHMatrix.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodHMatrix.html
https://root.cern/root/html532/TMVA__MethodHMatrix.html:18438,Modifiability,variab,variable,18438,"andard constructor for the H-Matrix method. MethodHMatrix(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL); constructor from weight file. void Init( void ); default initialization called by all constructors. ~MethodHMatrix( void ); destructor. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); FDA can handle classification with 2 classes and regression with one regression-target. void DeclareOptions(); MethodHMatrix options: none (apart from those implemented in MethodBase). void ProcessOptions(); process user options. void Train( void ); computes H-matrices for signal and background samples. void ComputeCovariance(Bool_t , TMatrixD* ); compute covariance matrix. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); returns the H-matrix signal estimator. Double_t GetChi2(TMVA::Types::ESBType ); compute chi2-estimator for event according to type (signal/background). void AddWeightsXMLTo(void* parent) const; create XML description for HMatrix classification. void ReadWeightsFromXML(void* wghtnode); read weights from XML file. void ReadWeightsFromStream(istream& istr); read variable names and min/max; NOTE: the latter values are mandatory for the normalisation; in the reader application !!!. void MakeClassSpecific(ostream& , const TString& ) const; write Fisher-specific classifier response. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". const Ranking* CreateRanking(); ranking of input variables. { return 0; }. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: MethodHMatrix.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__MethodHMatrix.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodHMatrix.html
https://root.cern/root/html532/TMVA__MethodHMatrix.html:18858,Modifiability,variab,variables,18858,"andard constructor for the H-Matrix method. MethodHMatrix(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL); constructor from weight file. void Init( void ); default initialization called by all constructors. ~MethodHMatrix( void ); destructor. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); FDA can handle classification with 2 classes and regression with one regression-target. void DeclareOptions(); MethodHMatrix options: none (apart from those implemented in MethodBase). void ProcessOptions(); process user options. void Train( void ); computes H-matrices for signal and background samples. void ComputeCovariance(Bool_t , TMatrixD* ); compute covariance matrix. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); returns the H-matrix signal estimator. Double_t GetChi2(TMVA::Types::ESBType ); compute chi2-estimator for event according to type (signal/background). void AddWeightsXMLTo(void* parent) const; create XML description for HMatrix classification. void ReadWeightsFromXML(void* wghtnode); read weights from XML file. void ReadWeightsFromStream(istream& istr); read variable names and min/max; NOTE: the latter values are mandatory for the normalisation; in the reader application !!!. void MakeClassSpecific(ostream& , const TString& ) const; write Fisher-specific classifier response. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". const Ranking* CreateRanking(); ranking of input variables. { return 0; }. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: MethodHMatrix.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__MethodHMatrix.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodHMatrix.html
https://root.cern/root/html532/TMVA__MethodHMatrix.html:12142,Performance,tune,tuneParameters,12142,"voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int",MatchSource.WIKI,root/html532/TMVA__MethodHMatrix.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodHMatrix.html
https://root.cern/root/html532/TMVA__MethodHMatrix.html:11944,Testability,test,testTime,11944,"am& out, Option_t* option = """"); virtual voidTMVA::MethodBase::SetAnalysisType(TMVA::Types::EAnalysisType type); voidTMVA::MethodBase::SetBaseDir(TDirectory* methodDir); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObj",MatchSource.WIKI,root/html532/TMVA__MethodHMatrix.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodHMatrix.html
https://root.cern/root/html532/TMVA__MethodHMatrix.html:15853,Testability,test,testing,15853,"ethodBase::SetWeightFileDir(TString fileDir); voidTMVA::MethodBase::SetWeightFileName(TString); voidTMVA::MethodBase::Statistics(TMVA::Types::ETreeType treeType, const TString& theVarName, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&); Bool_tTMVA::MethodBase::TxtWeightsOnly() const; Bool_tTMVA::MethodBase::Verbose() const; voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. voidComputeCovariance(Bool_t, TMatrixD*); virtual voidDeclareOptions(); Double_tGetChi2(TMVA::Types::ESBType); virtual voidInit(); virtual voidProcessOptions(). Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. TMatrixD*fInvHMatrixB",MatchSource.WIKI,root/html532/TMVA__MethodHMatrix.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodHMatrix.html
https://root.cern/root/html532/TMVA__MethodHMatrix.html:366,Usability,simpl,simple,366,". TMVA::MethodHMatrix. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodHMatrix. class TMVA::MethodHMatrix: public TMVA::MethodBase. /*; H-Matrix method, which is implemented as a simple comparison of; chi-squared estimators for signal and background, taking into; account the linear correlations between the input variables; This MVA approach is used by the DØ collaboration (FNAL) for the; purpose of electron identification (see, eg.,; hep-ex/9507007).; As it is implemented in TMVA, it is usually equivalent or worse than; the Fisher-Mahalanobis discriminant, and it has only been added for; the purpose of completeness.; Two χ2 estimators are computed for an event, each one; for signal and background, using the estimates for the means and; covariance matrices obtained from the training sample:. TMVA then uses as normalised analyser for event (i) the ratio:; (χS(i)2 − χB2(i)); (χS2(i) + χB2(i)).; */. Function Members (Methods); public:. virtual~MethodHMatrix(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidTMVA::MethodBase::CheckSetup(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTOb",MatchSource.WIKI,root/html532/TMVA__MethodHMatrix.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodHMatrix.html
https://root.cern/root/html532/TMVA__MethodKNN.html:2051,Availability,error,error,2051,"t::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt, TMVA::Types",MatchSource.WIKI,root/html532/TMVA__MethodKNN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodKNN.html
https://root.cern/root/html532/TMVA__MethodKNN.html:2135,Availability,error,error,2135,"t* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt, TMVA::Types::ETreeType type) const; const vector<TMVA::Event*>&TMVA::MethodBase::GetEventCollec",MatchSource.WIKI,root/html532/TMVA__MethodKNN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodKNN.html
https://root.cern/root/html532/TMVA__MethodKNN.html:18906,Availability,avail,available,18906,"theData, const TString& theOption = ""KNN"", TDirectory* theTargetDir = NULL); standard constructor. MethodKNN(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL); constructor from weight file. ~MethodKNN(); destructor. void DeclareOptions(); MethodKNN options. void DeclareCompatibilityOptions(). void ProcessOptions(); process the options specified by the user. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); FDA can handle classification with 2 classes and regression with one regression-target. void Init(); Initialization. void MakeKNN(); create kNN. void Train(); kNN training. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); Compute classifier response. const std::vector< Float_t >& GetRegressionValues(). Return vector of averages for target values of k-nearest neighbors.; Use own copy of the regression vector, I do not like using a pointer to vector. const TMVA::Ranking* CreateRanking(); no ranking available. void AddWeightsXMLTo(void* parent) const; write weights to XML. void ReadWeightsFromXML(void* wghtnode). void ReadWeightsFromStream(istream& istr); read the weights. void WriteWeightsToStream(TFile& rf) const; save weights to ROOT file. void ReadWeightsFromStream(TFile& rf); read weights from ROOT file. void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". Double_t PolnKernel(Double_t value) const; polynomial kernel. Double_t GausKernel(const TMVA::kNN::Event& event_knn, const TMVA::kNN::Event& event, const vector<Double_t>& svec) const; Gaussian kernel. Double_t getKernelRadius(const list<pair<const TMVA::kNN::Node<TMVA::kNN::Event>*,float>,allocator<pair<const TMVA::kNN::Node<TMVA::kNN::Event>*,float> > >& rlist) const. Get polynomial kernel radius. const std::vector",MatchSource.WIKI,root/html532/TMVA__MethodKNN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodKNN.html
https://root.cern/root/html532/TMVA__MethodKNN.html:19354,Integrability,message,message,19354,", UInt_t numberClasses, UInt_t numberTargets); FDA can handle classification with 2 classes and regression with one regression-target. void Init(); Initialization. void MakeKNN(); create kNN. void Train(); kNN training. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); Compute classifier response. const std::vector< Float_t >& GetRegressionValues(). Return vector of averages for target values of k-nearest neighbors.; Use own copy of the regression vector, I do not like using a pointer to vector. const TMVA::Ranking* CreateRanking(); no ranking available. void AddWeightsXMLTo(void* parent) const; write weights to XML. void ReadWeightsFromXML(void* wghtnode). void ReadWeightsFromStream(istream& istr); read the weights. void WriteWeightsToStream(TFile& rf) const; save weights to ROOT file. void ReadWeightsFromStream(TFile& rf); read weights from ROOT file. void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". Double_t PolnKernel(Double_t value) const; polynomial kernel. Double_t GausKernel(const TMVA::kNN::Event& event_knn, const TMVA::kNN::Event& event, const vector<Double_t>& svec) const; Gaussian kernel. Double_t getKernelRadius(const list<pair<const TMVA::kNN::Node<TMVA::kNN::Event>*,float>,allocator<pair<const TMVA::kNN::Node<TMVA::kNN::Event>*,float> > >& rlist) const. Get polynomial kernel radius. const std::vector<Double_t> getRMS(const list<pair<const TMVA::kNN::Node<TMVA::kNN::Event>*,float>,allocator<pair<const TMVA::kNN::Node<TMVA::kNN::Event>*,float> > >& rlist, const TMVA::kNN::Event& event_knn) const. Get polynomial kernel radius. Double_t getLDAValue(const list<pair<const TMVA::kNN::Node<TMVA::kNN::Event>*,float>,allocator<pair<const TMVA::kNN::Node<TMVA::kNN::Event>*,float> > >& rlist, const TMVA::kNN::Event& event_knn). » Author: Rustem Ospanov » Cop",MatchSource.WIKI,root/html532/TMVA__MethodKNN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodKNN.html
https://root.cern/root/html532/TMVA__MethodKNN.html:16127,Modifiability,variab,variables,16127,"const; virtual voidProcessOptions(). Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. Int_tfBalanceDepthnumber of binary tree levels used for balancing tree; vector<TMVA::kNN::Event,allocator<TMVA::kNN::Event> >fEvent! (untouched) events used for learning; TStringfKernel=""Gaus"",""Poln"" - kernel type for smoothing; TMVA::LDAfLDA! Experimental feature for local knn analysis; TMVA::kNN::ModulekNN*fModule! module where all work is done; Float_tfScaleFracfraction of events used to compute variable width; Float_tfSigmaFactscale factor for Gaussian sigma in Gaus. kernel; Double_tfSumOfWeightsBsum-of-weights for background training events ; ",MatchSource.WIKI,root/html532/TMVA__MethodKNN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodKNN.html
https://root.cern/root/html532/TMVA__MethodKNN.html:16316,Modifiability,variab,variable,16316,"const; virtual voidProcessOptions(). Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. Int_tfBalanceDepthnumber of binary tree levels used for balancing tree; vector<TMVA::kNN::Event,allocator<TMVA::kNN::Event> >fEvent! (untouched) events used for learning; TStringfKernel=""Gaus"",""Poln"" - kernel type for smoothing; TMVA::LDAfLDA! Experimental feature for local knn analysis; TMVA::kNN::ModulekNN*fModule! module where all work is done; Float_tfScaleFracfraction of events used to compute variable width; Float_tfSigmaFactscale factor for Gaussian sigma in Gaus. kernel; Double_tfSumOfWeightsBsum-of-weights for background training events ; ",MatchSource.WIKI,root/html532/TMVA__MethodKNN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodKNN.html
https://root.cern/root/html532/TMVA__MethodKNN.html:17160,Modifiability,variab,variable,17160," UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. Int_tfBalanceDepthnumber of binary tree levels used for balancing tree; vector<TMVA::kNN::Event,allocator<TMVA::kNN::Event> >fEvent! (untouched) events used for learning; TStringfKernel=""Gaus"",""Poln"" - kernel type for smoothing; TMVA::LDAfLDA! Experimental feature for local knn analysis; TMVA::kNN::ModulekNN*fModule! module where all work is done; Float_tfScaleFracfraction of events used to compute variable width; Float_tfSigmaFactscale factor for Gaussian sigma in Gaus. kernel; Double_tfSumOfWeightsBsum-of-weights for background training events ; Double_tfSumOfWeightsSsum-of-weights for signal training events; Int_tfTreeOptDepthnumber of binary tree levels used for optimization; Bool_tfTrimset equal number of signal and background events; Bool_tfUseKerneluse polynomial kernel weight function; Bool_tfUseLDAuse local linear discriminat analysis to compute MVA; Bool_tfUseWeightuse weights to count kNN; Int_tfnkNNnumber of k-nearest neighbors . Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodKNN(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = ""KNN"", TDirectory* theTargetDir = NULL); standard constructor. MethodKNN(",MatchSource.WIKI,root/html532/TMVA__MethodKNN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodKNN.html
https://root.cern/root/html532/TMVA__MethodKNN.html:11349,Performance,tune,tuneParameters,11349,"voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int",MatchSource.WIKI,root/html532/TMVA__MethodKNN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodKNN.html
https://root.cern/root/html532/TMVA__MethodKNN.html:17433,Performance,optimiz,optimization,17433,"t histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. Int_tfBalanceDepthnumber of binary tree levels used for balancing tree; vector<TMVA::kNN::Event,allocator<TMVA::kNN::Event> >fEvent! (untouched) events used for learning; TStringfKernel=""Gaus"",""Poln"" - kernel type for smoothing; TMVA::LDAfLDA! Experimental feature for local knn analysis; TMVA::kNN::ModulekNN*fModule! module where all work is done; Float_tfScaleFracfraction of events used to compute variable width; Float_tfSigmaFactscale factor for Gaussian sigma in Gaus. kernel; Double_tfSumOfWeightsBsum-of-weights for background training events ; Double_tfSumOfWeightsSsum-of-weights for signal training events; Int_tfTreeOptDepthnumber of binary tree levels used for optimization; Bool_tfTrimset equal number of signal and background events; Bool_tfUseKerneluse polynomial kernel weight function; Bool_tfUseLDAuse local linear discriminat analysis to compute MVA; Bool_tfUseWeightuse weights to count kNN; Int_tfnkNNnumber of k-nearest neighbors . Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodKNN(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = ""KNN"", TDirectory* theTargetDir = NULL); standard constructor. MethodKNN(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL); constructor from weight file. ~MethodKNN(); destructor. void DeclareOptions(); MethodKNN options. void DeclareCompatibilityOptions(). void ProcessOptions(); process the options specified by the user. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); FDA can handle classification with 2 classes and regression with one regression-targe",MatchSource.WIKI,root/html532/TMVA__MethodKNN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodKNN.html
https://root.cern/root/html532/TMVA__MethodKNN.html:11151,Testability,test,testTime,11151,"am& out, Option_t* option = """"); virtual voidTMVA::MethodBase::SetAnalysisType(TMVA::Types::EAnalysisType type); voidTMVA::MethodBase::SetBaseDir(TDirectory* methodDir); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObj",MatchSource.WIKI,root/html532/TMVA__MethodKNN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodKNN.html
https://root.cern/root/html532/TMVA__MethodKNN.html:15817,Testability,test,testing,15817,"TMVA::kNN::Node<TMVA::kNN::Event>*,float> > >& rlist) const; doublegetLDAValue(const list<pair<const TMVA::kNN::Node<TMVA::kNN::Event>*,float>,allocator<pair<const TMVA::kNN::Node<TMVA::kNN::Event>*,float> > >& rlist, const TMVA::kNN::Event& event_knn); const vector<Double_t>getRMS(const list<pair<const TMVA::kNN::Node<TMVA::kNN::Event>*,float>,allocator<pair<const TMVA::kNN::Node<TMVA::kNN::Event>*,float> > >& rlist, const TMVA::kNN::Event& event_knn) const; virtual voidInit(); voidMakeKNN(); Double_tPolnKernel(Double_t value) const; virtual voidProcessOptions(). Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. Int_tfBalanceDepthnum",MatchSource.WIKI,root/html532/TMVA__MethodKNN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodKNN.html
https://root.cern/root/html532/TMVA__MethodKNN.html:16919,Usability,learn,learning,16919," UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. Int_tfBalanceDepthnumber of binary tree levels used for balancing tree; vector<TMVA::kNN::Event,allocator<TMVA::kNN::Event> >fEvent! (untouched) events used for learning; TStringfKernel=""Gaus"",""Poln"" - kernel type for smoothing; TMVA::LDAfLDA! Experimental feature for local knn analysis; TMVA::kNN::ModulekNN*fModule! module where all work is done; Float_tfScaleFracfraction of events used to compute variable width; Float_tfSigmaFactscale factor for Gaussian sigma in Gaus. kernel; Double_tfSumOfWeightsBsum-of-weights for background training events ; Double_tfSumOfWeightsSsum-of-weights for signal training events; Int_tfTreeOptDepthnumber of binary tree levels used for optimization; Bool_tfTrimset equal number of signal and background events; Bool_tfUseKerneluse polynomial kernel weight function; Bool_tfUseLDAuse local linear discriminat analysis to compute MVA; Bool_tfUseWeightuse weights to count kNN; Int_tfnkNNnumber of k-nearest neighbors . Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodKNN(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = ""KNN"", TDirectory* theTargetDir = NULL); standard constructor. MethodKNN(",MatchSource.WIKI,root/html532/TMVA__MethodKNN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodKNN.html
https://root.cern/root/html532/TMVA__MethodLD.html:2095,Availability,error,error,2095," const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidDeclareOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt, TMVA::Types",MatchSource.WIKI,root/html532/TMVA__MethodLD.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodLD.html
https://root.cern/root/html532/TMVA__MethodLD.html:2179,Availability,error,error,2179,"= """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidDeclareOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt, TMVA::Types::ETreeType type) const; const vector<TMVA::Event*>&TMVA::MethodBase::GetEventCollec",MatchSource.WIKI,root/html532/TMVA__MethodLD.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodLD.html
https://root.cern/root/html532/TMVA__MethodLD.html:18252,Integrability,message,message,18252,". Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); LD can handle classification with 2 classes and regression with one regression-target. void Train( void ); compute fSumMatx. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); Returns the MVA classification output. const std::vector< Float_t >& GetRegressionValues(); Calculates the regression output. void InitMatrices( void ); Initializaton method; creates global matrices and vectors. void GetSum( void ); Calculates the matrix transposed(X)*W*X with W being the diagonal weight matrix; and X the coordinates values. void GetSumVal( void ); Calculates the vector transposed(X)*W*Y with Y being the target vector. void GetLDCoeff( void ); Calculates the coeffiecients used for classification/regression. void ReadWeightsFromStream(istream& i); read LD coefficients from weight file. void AddWeightsXMLTo(void* parent) const; create XML description for LD classification and regression; (for arbitrary number of output classes/targets). void ReadWeightsFromXML(void* wghtnode); read coefficients from xml weight file. void MakeClassSpecific(ostream& , const TString& ) const; write LD-specific classifier response. const TMVA::Ranking* CreateRanking(); computes ranking of input variables. void DeclareOptions(); MethodLD options. void ProcessOptions(); this is the preparation for training. void PrintCoefficients( void ); Display the classification/regression coefficients for each variable. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". » Author: Krzysztof Danielowski, Kamil Kraszewski, Maciej Kruk, Jan Therhaag » Copyright (c) 2008-2011: *; » Last changed: Thu Nov 3 20:19:43 2011 » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__MethodLD.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodLD.html
https://root.cern/root/html532/TMVA__MethodLD.html:15329,Modifiability,variab,variables,15329,"Matrices(); voidPrintCoefficients(). Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. TMatrixD*fCoeffMatxMatrix of coefficients; vector<std::vector<Double_t>*>*fLDCoeffLD coefficients; Int_tfNRegOutsize of the output; TMatrixD*fSumMatxSum of coordinates product matrix ; TMatrixD*fSumValMatxSum of values multiplied by coordinates. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodLD(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& dsi, const TString& theOption = ""LD"", TDirectory* theTargetDir = 0); standard constructor for the LD. MethodLD(TMVA::DataSetInfo& dsi, co",MatchSource.WIKI,root/html532/TMVA__MethodLD.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodLD.html
https://root.cern/root/html532/TMVA__MethodLD.html:15518,Modifiability,variab,variable,15518,"Matrices(); voidPrintCoefficients(). Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. TMatrixD*fCoeffMatxMatrix of coefficients; vector<std::vector<Double_t>*>*fLDCoeffLD coefficients; Int_tfNRegOutsize of the output; TMatrixD*fSumMatxSum of coordinates product matrix ; TMatrixD*fSumValMatxSum of values multiplied by coordinates. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodLD(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& dsi, const TString& theOption = ""LD"", TDirectory* theTargetDir = 0); standard constructor for the LD. MethodLD(TMVA::DataSetInfo& dsi, co",MatchSource.WIKI,root/html532/TMVA__MethodLD.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodLD.html
https://root.cern/root/html532/TMVA__MethodLD.html:17999,Modifiability,variab,variables,17999,". Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); LD can handle classification with 2 classes and regression with one regression-target. void Train( void ); compute fSumMatx. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); Returns the MVA classification output. const std::vector< Float_t >& GetRegressionValues(); Calculates the regression output. void InitMatrices( void ); Initializaton method; creates global matrices and vectors. void GetSum( void ); Calculates the matrix transposed(X)*W*X with W being the diagonal weight matrix; and X the coordinates values. void GetSumVal( void ); Calculates the vector transposed(X)*W*Y with Y being the target vector. void GetLDCoeff( void ); Calculates the coeffiecients used for classification/regression. void ReadWeightsFromStream(istream& i); read LD coefficients from weight file. void AddWeightsXMLTo(void* parent) const; create XML description for LD classification and regression; (for arbitrary number of output classes/targets). void ReadWeightsFromXML(void* wghtnode); read coefficients from xml weight file. void MakeClassSpecific(ostream& , const TString& ) const; write LD-specific classifier response. const TMVA::Ranking* CreateRanking(); computes ranking of input variables. void DeclareOptions(); MethodLD options. void ProcessOptions(); this is the preparation for training. void PrintCoefficients( void ); Display the classification/regression coefficients for each variable. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". » Author: Krzysztof Danielowski, Kamil Kraszewski, Maciej Kruk, Jan Therhaag » Copyright (c) 2008-2011: *; » Last changed: Thu Nov 3 20:19:43 2011 » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__MethodLD.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodLD.html
https://root.cern/root/html532/TMVA__MethodLD.html:18204,Modifiability,variab,variable,18204,". Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); LD can handle classification with 2 classes and regression with one regression-target. void Train( void ); compute fSumMatx. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); Returns the MVA classification output. const std::vector< Float_t >& GetRegressionValues(); Calculates the regression output. void InitMatrices( void ); Initializaton method; creates global matrices and vectors. void GetSum( void ); Calculates the matrix transposed(X)*W*X with W being the diagonal weight matrix; and X the coordinates values. void GetSumVal( void ); Calculates the vector transposed(X)*W*Y with Y being the target vector. void GetLDCoeff( void ); Calculates the coeffiecients used for classification/regression. void ReadWeightsFromStream(istream& i); read LD coefficients from weight file. void AddWeightsXMLTo(void* parent) const; create XML description for LD classification and regression; (for arbitrary number of output classes/targets). void ReadWeightsFromXML(void* wghtnode); read coefficients from xml weight file. void MakeClassSpecific(ostream& , const TString& ) const; write LD-specific classifier response. const TMVA::Ranking* CreateRanking(); computes ranking of input variables. void DeclareOptions(); MethodLD options. void ProcessOptions(); this is the preparation for training. void PrintCoefficients( void ); Display the classification/regression coefficients for each variable. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". » Author: Krzysztof Danielowski, Kamil Kraszewski, Maciej Kruk, Jan Therhaag » Copyright (c) 2008-2011: *; » Last changed: Thu Nov 3 20:19:43 2011 » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__MethodLD.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodLD.html
https://root.cern/root/html532/TMVA__MethodLD.html:11355,Performance,tune,tuneParameters,11355,"voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int",MatchSource.WIKI,root/html532/TMVA__MethodLD.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodLD.html
https://root.cern/root/html532/TMVA__MethodLD.html:11157,Testability,test,testTime,11157,"am& out, Option_t* option = """"); virtual voidTMVA::MethodBase::SetAnalysisType(TMVA::Types::EAnalysisType type); voidTMVA::MethodBase::SetBaseDir(TDirectory* methodDir); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObj",MatchSource.WIKI,root/html532/TMVA__MethodLD.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodLD.html
https://root.cern/root/html532/TMVA__MethodLD.html:15019,Testability,test,testing,15019,"odBase::SetNormalised(Bool_t norm); voidTMVA::MethodBase::SetWeightFileDir(TString fileDir); voidTMVA::MethodBase::SetWeightFileName(TString); voidTMVA::MethodBase::Statistics(TMVA::Types::ETreeType treeType, const TString& theVarName, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&); Bool_tTMVA::MethodBase::TxtWeightsOnly() const; Bool_tTMVA::MethodBase::Verbose() const; voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. voidGetLDCoeff(); voidGetSum(); voidGetSumVal(); virtual voidInit(); voidInitMatrices(); voidPrintCoefficients(). Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. TMatrixD*fCoeffMatxMa",MatchSource.WIKI,root/html532/TMVA__MethodLD.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodLD.html
https://root.cern/root/html532/TMVA__MethodLikelihood.html:2570,Availability,recover,recovered,2570,"od; ratio is optimal, ie, no other method can beat it. However, in most; practical applications of MVAs correlations are present. . Linear correlations, measured from the training sample, can be taken; into account in a straightforward manner through the square-root; of the covariance matrix. The square-root of a matrix; C is the matrix C′ that multiplied with itself; yields C: C=C′C′. We compute the; square-root matrix (SQM) by means of diagonalising (D) the; covariance matrix: . and the linear transformation of the linearly correlated into the; uncorrelated variables space is then given by multiplying the measured; variable tuple by the inverse of the SQM. Note that these transformations; are performed for both signal and background separately, since the; correlation pattern is not the same in the two samples.; ; The above diagonalisation is complete for linearly correlated,; Gaussian distributed variables only. In real-world examples this; is not often the case, so that only little additional information; may be recovered by the diagonalisation procedure. In these cases,; non-linear methods must be applied.; . Function Members (Methods); public:. virtual~MethodLikelihood(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidTMVA::MethodBase::CheckSetup(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TSt",MatchSource.WIKI,root/html532/TMVA__MethodLikelihood.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodLikelihood.html
https://root.cern/root/html532/TMVA__MethodLikelihood.html:4378,Availability,error,error,4378,"t::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt, TMVA::Types",MatchSource.WIKI,root/html532/TMVA__MethodLikelihood.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodLikelihood.html
https://root.cern/root/html532/TMVA__MethodLikelihood.html:4462,Availability,error,error,4462,"t* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt, TMVA::Types::ETreeType type) const; const vector<TMVA::Event*>&TMVA::MethodBase::GetEventCollec",MatchSource.WIKI,root/html532/TMVA__MethodLikelihood.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodLikelihood.html
https://root.cern/root/html532/TMVA__MethodLikelihood.html:21923,Energy Efficiency,monitor,monitoring,21923,"ion is required, compute; corresponding square-root matrices; the reference histograms require the correct boundaries. Since in Likelihood classification; the transformations are applied using both classes, also the corresponding boundaries; need to take this into account. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); returns the likelihood estimator for signal; fill a new Likelihood branch into the testTree. Double_t TransformLikelihoodOutput(Double_t ps, Double_t pb) const; returns transformed or non-transformed output. void WriteOptionsToStream(ostream& o, const TString& prefix) const; write options to stream. void AddWeightsXMLTo(void* parent) const; write weights to XML. const TMVA::Ranking* CreateRanking(); computes ranking of input variables. void WriteWeightsToStream(TFile& rf) const; write reference PDFs to ROOT file. void ReadWeightsFromXML(void* wghtnode); read weights from XML. void ReadWeightsFromStream(istream& istr); read weight info from file; nothing to do for this method. void ReadWeightsFromStream(TFile& istr); read reference PDF from ROOT file. void WriteMonitoringHistosToFile( void ); write histograms and PDFs to file for monitoring purposes. void MakeClassSpecificHeader(ostream& , const TString& = """") const; write specific header of the classifier (mostly include files). void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss, Peter Speckmayer, Eckhard von Toerne, Jan Therhaag » Copyright (c) 2005-2011: *; » Last changed: root/tmva $Id: MethodLikelihood.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__MethodLikelihood.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodLikelihood.html
https://root.cern/root/html532/TMVA__MethodLikelihood.html:22208,Integrability,message,message,22208,"ion is required, compute; corresponding square-root matrices; the reference histograms require the correct boundaries. Since in Likelihood classification; the transformations are applied using both classes, also the corresponding boundaries; need to take this into account. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); returns the likelihood estimator for signal; fill a new Likelihood branch into the testTree. Double_t TransformLikelihoodOutput(Double_t ps, Double_t pb) const; returns transformed or non-transformed output. void WriteOptionsToStream(ostream& o, const TString& prefix) const; write options to stream. void AddWeightsXMLTo(void* parent) const; write weights to XML. const TMVA::Ranking* CreateRanking(); computes ranking of input variables. void WriteWeightsToStream(TFile& rf) const; write reference PDFs to ROOT file. void ReadWeightsFromXML(void* wghtnode); read weights from XML. void ReadWeightsFromStream(istream& istr); read weight info from file; nothing to do for this method. void ReadWeightsFromStream(TFile& istr); read reference PDF from ROOT file. void WriteMonitoringHistosToFile( void ); write histograms and PDFs to file for monitoring purposes. void MakeClassSpecificHeader(ostream& , const TString& = """") const; write specific header of the classifier (mostly include files). void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss, Peter Speckmayer, Eckhard von Toerne, Jan Therhaag » Copyright (c) 2005-2011: *; » Last changed: root/tmva $Id: MethodLikelihood.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__MethodLikelihood.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodLikelihood.html
https://root.cern/root/html532/TMVA__MethodLikelihood.html:529,Modifiability,variab,variables,529,". TMVA::MethodLikelihood. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodLikelihood. class TMVA::MethodLikelihood: public TMVA::MethodBase. Likelihood analysis (""non-parametric approach""); ; Also implemented is a ""diagonalized likelihood approach"",; which improves over the uncorrelated likelihood ansatz by; transforming linearly the input variables into a diagonal space,; using the square-root of the covariance matrix; ; The method of maximum likelihood is the most straightforward, and; certainly among the most elegant multivariate analyser approaches.; We define the likelihood ratio, RL, for event; i, by:. Here the signal and background likelihoods, LS,; LB, are products of the corresponding probability; densities, pS, pB, of the; Nvar discriminating variables used in the MVA: . and accordingly for LB.; In practise, TMVA uses polynomial splines to estimate the probability; density functions (PDF) obtained from the distributions of the; training variables. Note that in TMVA the output of the likelihood ratio is transformed; by. to avoid the occurrence of heavy peaks at RL=0,1.; Decorrelated (or ""diagonalized"") Likelihood. The biggest drawback of the Likelihood approach is that it assumes; that the discriminant variables are uncorrelated. If it were the case,; it can be proven that the discrimination obtained by the above likelihood; ratio is optimal, ie, no other method can beat it. However, in most; practical applications of MVAs correlations are present. . Linear correlations, measured from the training sample, can be taken; into account in a straightforward manner through the square-root; of the covariance matrix. The square-root of a matrix; C is the matrix C′ that multiplied with itself; yields C: C=C′C′. We compute the; square-root matrix (SQM) by means of diagonalising (D) th",MatchSource.WIKI,root/html532/TMVA__MethodLikelihood.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodLikelihood.html
https://root.cern/root/html532/TMVA__MethodLikelihood.html:950,Modifiability,variab,variables,950,". TMVA::MethodLikelihood. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodLikelihood. class TMVA::MethodLikelihood: public TMVA::MethodBase. Likelihood analysis (""non-parametric approach""); ; Also implemented is a ""diagonalized likelihood approach"",; which improves over the uncorrelated likelihood ansatz by; transforming linearly the input variables into a diagonal space,; using the square-root of the covariance matrix; ; The method of maximum likelihood is the most straightforward, and; certainly among the most elegant multivariate analyser approaches.; We define the likelihood ratio, RL, for event; i, by:. Here the signal and background likelihoods, LS,; LB, are products of the corresponding probability; densities, pS, pB, of the; Nvar discriminating variables used in the MVA: . and accordingly for LB.; In practise, TMVA uses polynomial splines to estimate the probability; density functions (PDF) obtained from the distributions of the; training variables. Note that in TMVA the output of the likelihood ratio is transformed; by. to avoid the occurrence of heavy peaks at RL=0,1.; Decorrelated (or ""diagonalized"") Likelihood. The biggest drawback of the Likelihood approach is that it assumes; that the discriminant variables are uncorrelated. If it were the case,; it can be proven that the discrimination obtained by the above likelihood; ratio is optimal, ie, no other method can beat it. However, in most; practical applications of MVAs correlations are present. . Linear correlations, measured from the training sample, can be taken; into account in a straightforward manner through the square-root; of the covariance matrix. The square-root of a matrix; C is the matrix C′ that multiplied with itself; yields C: C=C′C′. We compute the; square-root matrix (SQM) by means of diagonalising (D) th",MatchSource.WIKI,root/html532/TMVA__MethodLikelihood.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodLikelihood.html
https://root.cern/root/html532/TMVA__MethodLikelihood.html:1148,Modifiability,variab,variables,1148,"chy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodLikelihood. class TMVA::MethodLikelihood: public TMVA::MethodBase. Likelihood analysis (""non-parametric approach""); ; Also implemented is a ""diagonalized likelihood approach"",; which improves over the uncorrelated likelihood ansatz by; transforming linearly the input variables into a diagonal space,; using the square-root of the covariance matrix; ; The method of maximum likelihood is the most straightforward, and; certainly among the most elegant multivariate analyser approaches.; We define the likelihood ratio, RL, for event; i, by:. Here the signal and background likelihoods, LS,; LB, are products of the corresponding probability; densities, pS, pB, of the; Nvar discriminating variables used in the MVA: . and accordingly for LB.; In practise, TMVA uses polynomial splines to estimate the probability; density functions (PDF) obtained from the distributions of the; training variables. Note that in TMVA the output of the likelihood ratio is transformed; by. to avoid the occurrence of heavy peaks at RL=0,1.; Decorrelated (or ""diagonalized"") Likelihood. The biggest drawback of the Likelihood approach is that it assumes; that the discriminant variables are uncorrelated. If it were the case,; it can be proven that the discrimination obtained by the above likelihood; ratio is optimal, ie, no other method can beat it. However, in most; practical applications of MVAs correlations are present. . Linear correlations, measured from the training sample, can be taken; into account in a straightforward manner through the square-root; of the covariance matrix. The square-root of a matrix; C is the matrix C′ that multiplied with itself; yields C: C=C′C′. We compute the; square-root matrix (SQM) by means of diagonalising (D) the; covariance matrix: . and the linear transformation of the linearly correlate",MatchSource.WIKI,root/html532/TMVA__MethodLikelihood.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodLikelihood.html
https://root.cern/root/html532/TMVA__MethodLikelihood.html:1418,Modifiability,variab,variables,1418,"plemented is a ""diagonalized likelihood approach"",; which improves over the uncorrelated likelihood ansatz by; transforming linearly the input variables into a diagonal space,; using the square-root of the covariance matrix; ; The method of maximum likelihood is the most straightforward, and; certainly among the most elegant multivariate analyser approaches.; We define the likelihood ratio, RL, for event; i, by:. Here the signal and background likelihoods, LS,; LB, are products of the corresponding probability; densities, pS, pB, of the; Nvar discriminating variables used in the MVA: . and accordingly for LB.; In practise, TMVA uses polynomial splines to estimate the probability; density functions (PDF) obtained from the distributions of the; training variables. Note that in TMVA the output of the likelihood ratio is transformed; by. to avoid the occurrence of heavy peaks at RL=0,1.; Decorrelated (or ""diagonalized"") Likelihood. The biggest drawback of the Likelihood approach is that it assumes; that the discriminant variables are uncorrelated. If it were the case,; it can be proven that the discrimination obtained by the above likelihood; ratio is optimal, ie, no other method can beat it. However, in most; practical applications of MVAs correlations are present. . Linear correlations, measured from the training sample, can be taken; into account in a straightforward manner through the square-root; of the covariance matrix. The square-root of a matrix; C is the matrix C′ that multiplied with itself; yields C: C=C′C′. We compute the; square-root matrix (SQM) by means of diagonalising (D) the; covariance matrix: . and the linear transformation of the linearly correlated into the; uncorrelated variables space is then given by multiplying the measured; variable tuple by the inverse of the SQM. Note that these transformations; are performed for both signal and background separately, since the; correlation pattern is not the same in the two samples.; ; The above diagonalis",MatchSource.WIKI,root/html532/TMVA__MethodLikelihood.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodLikelihood.html
https://root.cern/root/html532/TMVA__MethodLikelihood.html:2105,Modifiability,variab,variables,2105,"he distributions of the; training variables. Note that in TMVA the output of the likelihood ratio is transformed; by. to avoid the occurrence of heavy peaks at RL=0,1.; Decorrelated (or ""diagonalized"") Likelihood. The biggest drawback of the Likelihood approach is that it assumes; that the discriminant variables are uncorrelated. If it were the case,; it can be proven that the discrimination obtained by the above likelihood; ratio is optimal, ie, no other method can beat it. However, in most; practical applications of MVAs correlations are present. . Linear correlations, measured from the training sample, can be taken; into account in a straightforward manner through the square-root; of the covariance matrix. The square-root of a matrix; C is the matrix C′ that multiplied with itself; yields C: C=C′C′. We compute the; square-root matrix (SQM) by means of diagonalising (D) the; covariance matrix: . and the linear transformation of the linearly correlated into the; uncorrelated variables space is then given by multiplying the measured; variable tuple by the inverse of the SQM. Note that these transformations; are performed for both signal and background separately, since the; correlation pattern is not the same in the two samples.; ; The above diagonalisation is complete for linearly correlated,; Gaussian distributed variables only. In real-world examples this; is not often the case, so that only little additional information; may be recovered by the diagonalisation procedure. In these cases,; non-linear methods must be applied.; . Function Members (Methods); public:. virtual~MethodLikelihood(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virtual voi",MatchSource.WIKI,root/html532/TMVA__MethodLikelihood.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodLikelihood.html
https://root.cern/root/html532/TMVA__MethodLikelihood.html:2164,Modifiability,variab,variable,2164,"he distributions of the; training variables. Note that in TMVA the output of the likelihood ratio is transformed; by. to avoid the occurrence of heavy peaks at RL=0,1.; Decorrelated (or ""diagonalized"") Likelihood. The biggest drawback of the Likelihood approach is that it assumes; that the discriminant variables are uncorrelated. If it were the case,; it can be proven that the discrimination obtained by the above likelihood; ratio is optimal, ie, no other method can beat it. However, in most; practical applications of MVAs correlations are present. . Linear correlations, measured from the training sample, can be taken; into account in a straightforward manner through the square-root; of the covariance matrix. The square-root of a matrix; C is the matrix C′ that multiplied with itself; yields C: C=C′C′. We compute the; square-root matrix (SQM) by means of diagonalising (D) the; covariance matrix: . and the linear transformation of the linearly correlated into the; uncorrelated variables space is then given by multiplying the measured; variable tuple by the inverse of the SQM. Note that these transformations; are performed for both signal and background separately, since the; correlation pattern is not the same in the two samples.; ; The above diagonalisation is complete for linearly correlated,; Gaussian distributed variables only. In real-world examples this; is not often the case, so that only little additional information; may be recovered by the diagonalisation procedure. In these cases,; non-linear methods must be applied.; . Function Members (Methods); public:. virtual~MethodLikelihood(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virtual voi",MatchSource.WIKI,root/html532/TMVA__MethodLikelihood.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodLikelihood.html
https://root.cern/root/html532/TMVA__MethodLikelihood.html:2451,Modifiability,variab,variables,2451,"ant variables are uncorrelated. If it were the case,; it can be proven that the discrimination obtained by the above likelihood; ratio is optimal, ie, no other method can beat it. However, in most; practical applications of MVAs correlations are present. . Linear correlations, measured from the training sample, can be taken; into account in a straightforward manner through the square-root; of the covariance matrix. The square-root of a matrix; C is the matrix C′ that multiplied with itself; yields C: C=C′C′. We compute the; square-root matrix (SQM) by means of diagonalising (D) the; covariance matrix: . and the linear transformation of the linearly correlated into the; uncorrelated variables space is then given by multiplying the measured; variable tuple by the inverse of the SQM. Note that these transformations; are performed for both signal and background separately, since the; correlation pattern is not the same in the two samples.; ; The above diagonalisation is complete for linearly correlated,; Gaussian distributed variables only. In real-world examples this; is not often the case, so that only little additional information; may be recovered by the diagonalisation procedure. In these cases,; non-linear methods must be applied.; . Function Members (Methods); public:. virtual~MethodLikelihood(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidTMVA::MethodBase::CheckSetup(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """"",MatchSource.WIKI,root/html532/TMVA__MethodLikelihood.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodLikelihood.html
https://root.cern/root/html532/TMVA__MethodLikelihood.html:17763,Modifiability,variab,variables,17763,"put(Double_t ps, Double_t pb) const. Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. Int_tfAverageEvtPerBinaverage events per bin; used to calculate fNbins; Int_t*fAverageEvtPerBinVarBaverage events per bin; used to calculate fNbins; Int_t*fAverageEvtPerBinVarSaverage events per bin; used to calculate fNbins; TStringfBorderMethodStringthe method to take care about ""border"" effects (string); TMVA::PDF*fDefaultPDFLikpdf that contains default definitions; Int_tfDropVariablefor ranking test; Double_tfEpsilonminimum number of likelihood (to avoid zero); vector<TH1*>*fHistBgdbackground PDFs (histograms); vector<TH1*>*fHistBgd_smoothbackg",MatchSource.WIKI,root/html532/TMVA__MethodLikelihood.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodLikelihood.html
https://root.cern/root/html532/TMVA__MethodLikelihood.html:17952,Modifiability,variab,variable,17952,"put(Double_t ps, Double_t pb) const. Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. Int_tfAverageEvtPerBinaverage events per bin; used to calculate fNbins; Int_t*fAverageEvtPerBinVarBaverage events per bin; used to calculate fNbins; Int_t*fAverageEvtPerBinVarSaverage events per bin; used to calculate fNbins; TStringfBorderMethodStringthe method to take care about ""border"" effects (string); TMVA::PDF*fDefaultPDFLikpdf that contains default definitions; Int_tfDropVariablefor ranking test; Double_tfEpsilonminimum number of likelihood (to avoid zero); vector<TH1*>*fHistBgdbackground PDFs (histograms); vector<TH1*>*fHistBgd_smoothbackg",MatchSource.WIKI,root/html532/TMVA__MethodLikelihood.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodLikelihood.html
https://root.cern/root/html532/TMVA__MethodLikelihood.html:19196,Modifiability,variab,variable,19196,"ion histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. Int_tfAverageEvtPerBinaverage events per bin; used to calculate fNbins; Int_t*fAverageEvtPerBinVarBaverage events per bin; used to calculate fNbins; Int_t*fAverageEvtPerBinVarSaverage events per bin; used to calculate fNbins; TStringfBorderMethodStringthe method to take care about ""border"" effects (string); TMVA::PDF*fDefaultPDFLikpdf that contains default definitions; Int_tfDropVariablefor ranking test; Double_tfEpsilonminimum number of likelihood (to avoid zero); vector<TH1*>*fHistBgdbackground PDFs (histograms); vector<TH1*>*fHistBgd_smoothbackground PDFs (smoothed histograms); vector<TH1*>*fHistSigsignal PDFs (histograms); vector<TH1*>*fHistSig_smoothsignal PDFs (smoothed histograms); TString*fInterpolateStringwhich interpolation method used for reference histograms (individual for each variable); Float_tfKDEfineFactorfine tuning factor for Adaptive KDE; TStringfKDEiterStringNumber of iterations (string); TStringfKDEtypeStringKernel type to use for KDE (string); Int_tfNsmoothnumber of smooth passes; Int_t*fNsmoothVarBnumber of smooth passes; Int_t*fNsmoothVarSnumber of smooth passes; vector<PDF*>*fPDFBgdlist of PDFs (background); vector<PDF*>*fPDFSiglist of PDFs (signal) ; Bool_tfTransformLikelihoodOutputlikelihood output is sigmoid-transformed. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodLikelihood(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = """", TDirectory* theTargetDir = 0); standard constructor. MethodLikelihood(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTa",MatchSource.WIKI,root/html532/TMVA__MethodLikelihood.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodLikelihood.html
https://root.cern/root/html532/TMVA__MethodLikelihood.html:21511,Modifiability,variab,variables,21511,"trongly peaked) likelihood output through sigmoid inversion. void DeclareCompatibilityOptions(). void ProcessOptions(). void Train( void ); create reference distributions (PDFs) from signal and background events:; fill histograms and smooth them; if decorrelation is required, compute; corresponding square-root matrices; the reference histograms require the correct boundaries. Since in Likelihood classification; the transformations are applied using both classes, also the corresponding boundaries; need to take this into account. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); returns the likelihood estimator for signal; fill a new Likelihood branch into the testTree. Double_t TransformLikelihoodOutput(Double_t ps, Double_t pb) const; returns transformed or non-transformed output. void WriteOptionsToStream(ostream& o, const TString& prefix) const; write options to stream. void AddWeightsXMLTo(void* parent) const; write weights to XML. const TMVA::Ranking* CreateRanking(); computes ranking of input variables. void WriteWeightsToStream(TFile& rf) const; write reference PDFs to ROOT file. void ReadWeightsFromXML(void* wghtnode); read weights from XML. void ReadWeightsFromStream(istream& istr); read weight info from file; nothing to do for this method. void ReadWeightsFromStream(TFile& istr); read reference PDF from ROOT file. void WriteMonitoringHistosToFile( void ); write histograms and PDFs to file for monitoring purposes. void MakeClassSpecificHeader(ostream& , const TString& = """") const; write specific header of the classifier (mostly include files). void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss, Peter Speckmayer, Eckhard von Toerne, Jan Therhaag » Copyright (c) 2005-2011: *; » Last changed: roo",MatchSource.WIKI,root/html532/TMVA__MethodLikelihood.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodLikelihood.html
https://root.cern/root/html532/TMVA__MethodLikelihood.html:2243,Performance,perform,performed,2243,"Decorrelated (or ""diagonalized"") Likelihood. The biggest drawback of the Likelihood approach is that it assumes; that the discriminant variables are uncorrelated. If it were the case,; it can be proven that the discrimination obtained by the above likelihood; ratio is optimal, ie, no other method can beat it. However, in most; practical applications of MVAs correlations are present. . Linear correlations, measured from the training sample, can be taken; into account in a straightforward manner through the square-root; of the covariance matrix. The square-root of a matrix; C is the matrix C′ that multiplied with itself; yields C: C=C′C′. We compute the; square-root matrix (SQM) by means of diagonalising (D) the; covariance matrix: . and the linear transformation of the linearly correlated into the; uncorrelated variables space is then given by multiplying the measured; variable tuple by the inverse of the SQM. Note that these transformations; are performed for both signal and background separately, since the; correlation pattern is not the same in the two samples.; ; The above diagonalisation is complete for linearly correlated,; Gaussian distributed variables only. In real-world examples this; is not often the case, so that only little additional information; may be recovered by the diagonalisation procedure. In these cases,; non-linear methods must be applied.; . Function Members (Methods); public:. virtual~MethodLikelihood(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidTMVA::MethodBase::CheckSetup(); static TClass*Class(); virtual const ch",MatchSource.WIKI,root/html532/TMVA__MethodLikelihood.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodLikelihood.html
https://root.cern/root/html532/TMVA__MethodLikelihood.html:13718,Performance,tune,tuneParameters,13718,"voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int",MatchSource.WIKI,root/html532/TMVA__MethodLikelihood.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodLikelihood.html
https://root.cern/root/html532/TMVA__MethodLikelihood.html:1235,Safety,avoid,avoid,1235,"ethodLikelihood. class TMVA::MethodLikelihood: public TMVA::MethodBase. Likelihood analysis (""non-parametric approach""); ; Also implemented is a ""diagonalized likelihood approach"",; which improves over the uncorrelated likelihood ansatz by; transforming linearly the input variables into a diagonal space,; using the square-root of the covariance matrix; ; The method of maximum likelihood is the most straightforward, and; certainly among the most elegant multivariate analyser approaches.; We define the likelihood ratio, RL, for event; i, by:. Here the signal and background likelihoods, LS,; LB, are products of the corresponding probability; densities, pS, pB, of the; Nvar discriminating variables used in the MVA: . and accordingly for LB.; In practise, TMVA uses polynomial splines to estimate the probability; density functions (PDF) obtained from the distributions of the; training variables. Note that in TMVA the output of the likelihood ratio is transformed; by. to avoid the occurrence of heavy peaks at RL=0,1.; Decorrelated (or ""diagonalized"") Likelihood. The biggest drawback of the Likelihood approach is that it assumes; that the discriminant variables are uncorrelated. If it were the case,; it can be proven that the discrimination obtained by the above likelihood; ratio is optimal, ie, no other method can beat it. However, in most; practical applications of MVAs correlations are present. . Linear correlations, measured from the training sample, can be taken; into account in a straightforward manner through the square-root; of the covariance matrix. The square-root of a matrix; C is the matrix C′ that multiplied with itself; yields C: C=C′C′. We compute the; square-root matrix (SQM) by means of diagonalising (D) the; covariance matrix: . and the linear transformation of the linearly correlated into the; uncorrelated variables space is then given by multiplying the measured; variable tuple by the inverse of the SQM. Note that these transformations; are performed for",MatchSource.WIKI,root/html532/TMVA__MethodLikelihood.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodLikelihood.html
https://root.cern/root/html532/TMVA__MethodLikelihood.html:2570,Safety,recover,recovered,2570,"od; ratio is optimal, ie, no other method can beat it. However, in most; practical applications of MVAs correlations are present. . Linear correlations, measured from the training sample, can be taken; into account in a straightforward manner through the square-root; of the covariance matrix. The square-root of a matrix; C is the matrix C′ that multiplied with itself; yields C: C=C′C′. We compute the; square-root matrix (SQM) by means of diagonalising (D) the; covariance matrix: . and the linear transformation of the linearly correlated into the; uncorrelated variables space is then given by multiplying the measured; variable tuple by the inverse of the SQM. Note that these transformations; are performed for both signal and background separately, since the; correlation pattern is not the same in the two samples.; ; The above diagonalisation is complete for linearly correlated,; Gaussian distributed variables only. In real-world examples this; is not often the case, so that only little additional information; may be recovered by the diagonalisation procedure. In these cases,; non-linear methods must be applied.; . Function Members (Methods); public:. virtual~MethodLikelihood(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidTMVA::MethodBase::CheckSetup(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TSt",MatchSource.WIKI,root/html532/TMVA__MethodLikelihood.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodLikelihood.html
https://root.cern/root/html532/TMVA__MethodLikelihood.html:18851,Safety,avoid,avoid,18851,"ion histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. Int_tfAverageEvtPerBinaverage events per bin; used to calculate fNbins; Int_t*fAverageEvtPerBinVarBaverage events per bin; used to calculate fNbins; Int_t*fAverageEvtPerBinVarSaverage events per bin; used to calculate fNbins; TStringfBorderMethodStringthe method to take care about ""border"" effects (string); TMVA::PDF*fDefaultPDFLikpdf that contains default definitions; Int_tfDropVariablefor ranking test; Double_tfEpsilonminimum number of likelihood (to avoid zero); vector<TH1*>*fHistBgdbackground PDFs (histograms); vector<TH1*>*fHistBgd_smoothbackground PDFs (smoothed histograms); vector<TH1*>*fHistSigsignal PDFs (histograms); vector<TH1*>*fHistSig_smoothsignal PDFs (smoothed histograms); TString*fInterpolateStringwhich interpolation method used for reference histograms (individual for each variable); Float_tfKDEfineFactorfine tuning factor for Adaptive KDE; TStringfKDEiterStringNumber of iterations (string); TStringfKDEtypeStringKernel type to use for KDE (string); Int_tfNsmoothnumber of smooth passes; Int_t*fNsmoothVarBnumber of smooth passes; Int_t*fNsmoothVarSnumber of smooth passes; vector<PDF*>*fPDFBgdlist of PDFs (background); vector<PDF*>*fPDFSiglist of PDFs (signal) ; Bool_tfTransformLikelihoodOutputlikelihood output is sigmoid-transformed. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodLikelihood(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = """", TDirectory* theTargetDir = 0); standard constructor. MethodLikelihood(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTa",MatchSource.WIKI,root/html532/TMVA__MethodLikelihood.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodLikelihood.html
https://root.cern/root/html532/TMVA__MethodLikelihood.html:13520,Testability,test,testTime,13520,"am& out, Option_t* option = """"); virtual voidTMVA::MethodBase::SetAnalysisType(TMVA::Types::EAnalysisType type); voidTMVA::MethodBase::SetBaseDir(TDirectory* methodDir); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObj",MatchSource.WIKI,root/html532/TMVA__MethodLikelihood.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodLikelihood.html
https://root.cern/root/html532/TMVA__MethodLikelihood.html:17453,Testability,test,testing,17453,"); voidTMVA::MethodBase::SetWeightFileDir(TString fileDir); voidTMVA::MethodBase::SetWeightFileName(TString); voidTMVA::MethodBase::Statistics(TMVA::Types::ETreeType treeType, const TString& theVarName, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&); Bool_tTMVA::MethodBase::TxtWeightsOnly() const; Bool_tTMVA::MethodBase::Verbose() const; voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. virtual voidDeclareOptions(); virtual voidInit(); virtual voidProcessOptions(); Double_tTransformLikelihoodOutput(Double_t ps, Double_t pb) const. Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. Int_tfAverageEvtPerBi",MatchSource.WIKI,root/html532/TMVA__MethodLikelihood.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodLikelihood.html
https://root.cern/root/html532/TMVA__MethodLikelihood.html:18796,Testability,test,test,18796,"ion histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. Int_tfAverageEvtPerBinaverage events per bin; used to calculate fNbins; Int_t*fAverageEvtPerBinVarBaverage events per bin; used to calculate fNbins; Int_t*fAverageEvtPerBinVarSaverage events per bin; used to calculate fNbins; TStringfBorderMethodStringthe method to take care about ""border"" effects (string); TMVA::PDF*fDefaultPDFLikpdf that contains default definitions; Int_tfDropVariablefor ranking test; Double_tfEpsilonminimum number of likelihood (to avoid zero); vector<TH1*>*fHistBgdbackground PDFs (histograms); vector<TH1*>*fHistBgd_smoothbackground PDFs (smoothed histograms); vector<TH1*>*fHistSigsignal PDFs (histograms); vector<TH1*>*fHistSig_smoothsignal PDFs (smoothed histograms); TString*fInterpolateStringwhich interpolation method used for reference histograms (individual for each variable); Float_tfKDEfineFactorfine tuning factor for Adaptive KDE; TStringfKDEiterStringNumber of iterations (string); TStringfKDEtypeStringKernel type to use for KDE (string); Int_tfNsmoothnumber of smooth passes; Int_t*fNsmoothVarBnumber of smooth passes; Int_t*fNsmoothVarSnumber of smooth passes; vector<PDF*>*fPDFBgdlist of PDFs (background); vector<PDF*>*fPDFSiglist of PDFs (signal) ; Bool_tfTransformLikelihoodOutputlikelihood output is sigmoid-transformed. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodLikelihood(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = """", TDirectory* theTargetDir = 0); standard constructor. MethodLikelihood(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTa",MatchSource.WIKI,root/html532/TMVA__MethodLikelihood.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodLikelihood.html
https://root.cern/root/html532/TMVA__MethodLikelihood.html:21165,Testability,test,testTree,21165,"Likelihood( void ); destructor. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); FDA can handle classification with 2 classes. void Init( void ); default initialisation called by all constructors. void DeclareOptions(); define the options (their key words) that can be set in the option string; TransformOutput <bool> transform (often strongly peaked) likelihood output through sigmoid inversion. void DeclareCompatibilityOptions(). void ProcessOptions(). void Train( void ); create reference distributions (PDFs) from signal and background events:; fill histograms and smooth them; if decorrelation is required, compute; corresponding square-root matrices; the reference histograms require the correct boundaries. Since in Likelihood classification; the transformations are applied using both classes, also the corresponding boundaries; need to take this into account. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); returns the likelihood estimator for signal; fill a new Likelihood branch into the testTree. Double_t TransformLikelihoodOutput(Double_t ps, Double_t pb) const; returns transformed or non-transformed output. void WriteOptionsToStream(ostream& o, const TString& prefix) const; write options to stream. void AddWeightsXMLTo(void* parent) const; write weights to XML. const TMVA::Ranking* CreateRanking(); computes ranking of input variables. void WriteWeightsToStream(TFile& rf) const; write reference PDFs to ROOT file. void ReadWeightsFromXML(void* wghtnode); read weights from XML. void ReadWeightsFromStream(istream& istr); read weight info from file; nothing to do for this method. void ReadWeightsFromStream(TFile& istr); read reference PDF from ROOT file. void WriteMonitoringHistosToFile( void ); write histograms and PDFs to file for monitoring purposes. void MakeClassSpecificHeader(ostream& , const TString& = """") const; write specific header of the classifier (mostly include files). void MakeClassSpeci",MatchSource.WIKI,root/html532/TMVA__MethodLikelihood.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodLikelihood.html
https://root.cern/root/html532/TMVA__MethodMLP.html:2391,Availability,error,error,2391," voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*TMVA::MethodANNBase::CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; Bool_tTMVA::MethodANNBase::Debug() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual Double_tEstimatorFunction(vector<Double_t>& parameters); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt, TMVA::Types",MatchSource.WIKI,root/html532/TMVA__MethodMLP.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodMLP.html
https://root.cern/root/html532/TMVA__MethodMLP.html:2475,Availability,error,error,2475,"NNBase::CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; Bool_tTMVA::MethodANNBase::Debug() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual Double_tEstimatorFunction(vector<Double_t>& parameters); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt, TMVA::Types::ETreeType type) const; const vector<TMVA::Event*>&TMVA::MethodBase::GetEventCollec",MatchSource.WIKI,root/html532/TMVA__MethodMLP.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodMLP.html
https://root.cern/root/html532/TMVA__MethodMLP.html:23167,Availability,avail,available,23167,"zjh; Float_tfWeightRangesuppress outliers for the estimator calculation; static const Bool_tfgPRINT_BATCHdebug flags; static const Int_tfgPRINT_ESTIMATOR_INCdebug flags; static const Bool_tfgPRINT_SEQdebug flags. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodMLP(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption, TDirectory* theTargetDir = 0); standard constructor. MethodMLP(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = 0); constructor from a weight file. ~MethodMLP(); destructor; nothing to be done. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); MLP can handle classification with 2 classes and regression with one regression-target. void Init(); default initializations. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options:; TrainingMethod <string> Training method; available values are: BP Back-Propagation <default>; GA Genetic Algorithm (takes a LONG time). LearningRate <float> NN learning rate parameter; DecayRate <float> Decay rate for learning parameter; TestRate <int> Test for overtraining performed at each #th epochs. BPMode <string> Back-propagation learning mode; available values are: sequential <default>; batch. BatchSize <int> Batch size: number of events/batch, only set if in Batch Mode,; -1 for BatchSize=number_of_events. void ProcessOptions(); process user options. void InitializeLearningRates(); initialize learning rates of synapses, used only by backpropagation. Double_t CalculateEstimator(TMVA::Types::ETreeType treeType = Types::kTraining, Int_t iEpoch = -1); calculate the estimator that training is attempting to minimize. void Train(Int_t nEpochs). void BFGSMinimize(Int_t nEpochs); train network with BFGS algorithm. void SetGammaDelta(TMatrixD& Gamma, TMatrixD& Delta, vector<Double_t>& Buffer). void ",MatchSource.WIKI,root/html532/TMVA__MethodMLP.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodMLP.html
https://root.cern/root/html532/TMVA__MethodMLP.html:23479,Availability,avail,available,23479," TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption, TDirectory* theTargetDir = 0); standard constructor. MethodMLP(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = 0); constructor from a weight file. ~MethodMLP(); destructor; nothing to be done. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); MLP can handle classification with 2 classes and regression with one regression-target. void Init(); default initializations. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options:; TrainingMethod <string> Training method; available values are: BP Back-Propagation <default>; GA Genetic Algorithm (takes a LONG time). LearningRate <float> NN learning rate parameter; DecayRate <float> Decay rate for learning parameter; TestRate <int> Test for overtraining performed at each #th epochs. BPMode <string> Back-propagation learning mode; available values are: sequential <default>; batch. BatchSize <int> Batch size: number of events/batch, only set if in Batch Mode,; -1 for BatchSize=number_of_events. void ProcessOptions(); process user options. void InitializeLearningRates(); initialize learning rates of synapses, used only by backpropagation. Double_t CalculateEstimator(TMVA::Types::ETreeType treeType = Types::kTraining, Int_t iEpoch = -1); calculate the estimator that training is attempting to minimize. void Train(Int_t nEpochs). void BFGSMinimize(Int_t nEpochs); train network with BFGS algorithm. void SetGammaDelta(TMatrixD& Gamma, TMatrixD& Delta, vector<Double_t>& Buffer). void ComputeDEDw(). void SimulateEvent(const TMVA::Event* ev). void SteepestDir(TMatrixD& Dir). Bool_t GetHessian(TMatrixD& Hessian, TMatrixD& Gamma, TMatrixD& Delta). void SetDir(TMatrixD& Hessian, TMatrixD& Dir). Double_t DerivDir(TMatrixD& Dir). Bool_t LineSearch(TMatrixD& Dir, vector<Double_t>& Buffer, Double_t* dError = 0). void SetDirWeight",MatchSource.WIKI,root/html532/TMVA__MethodMLP.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodMLP.html
https://root.cern/root/html532/TMVA__MethodMLP.html:26381,Availability,error,error,26381,"GetDesiredOutput(const TMVA::Event* ev); get the desired output of this event. void UpdateNetwork(Double_t desired, Double_t eventWeight = 1.0); update the network based on how closely; the output matched the desired output. void UpdateNetwork(vector<Float_t>& desired, Double_t eventWeight = 1.0); update the network based on how closely; the output matched the desired output. void CalculateNeuronDeltas(); have each neuron calculate its delta by backpropagation. void GeneticMinimize(); create genetics class similar to GeneticCut; give it vector of parameter ranges (parameters = weights); link fitness function of this class to ComputeEstimator; instantiate GA (see MethodCuts); run it; then this should exist for GA, Minuit and random sampling. Double_t EstimatorFunction(vector<Double_t>& parameters); interface to the estimate. Double_t ComputeEstimator(vector<Double_t>& parameters); this function is called by GeneticANN for GA optimization. void UpdateSynapses(); update synapse error fields and adjust the weights (if in sequential mode). void AdjustSynapseWeights(); just adjust the synapse weights (should be called in batch mode). void UpdatePriors(). void UpdateRegulators(). void GetApproxInvHessian(TMatrixD& InvHessian, bool regulate = true). Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0). void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". void Train(); { Train(NumCycles()); }. bool HasInverseHessian(); { return fCalculateErrors; }. » Author: Krzysztof Danielowski, Andreas Hoecker, Matt Jachowski, Kamil Kraszewski, Maciej Kruk, Peter Speckmayer, Joerg Stelzer, Eckhard von Toerne, Jan Therhaag, Jiahang Zhong » Copyright (c) 2005-2011: *; » Last changed: root/tmva $Id: MethodMLP.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-12-02 14:28; This page h",MatchSource.WIKI,root/html532/TMVA__MethodMLP.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodMLP.html
https://root.cern/root/html532/TMVA__MethodMLP.html:25536,Deployability,update,update,25536,"MSEErr(const TMVA::Event* ev, UInt_t index = 0). Double_t GetCEErr(const TMVA::Event* ev, UInt_t index = 0). void BackPropagationMinimize(Int_t nEpochs); minimize estimator / train network with backpropagation algorithm. void TrainOneEpoch(); train network over a single epoch/cyle of events. void Shuffle(Int_t* index, Int_t n); Input:; index: the array to shuffle; n: the size of the array; Output:; index: the shuffled indexes; This method is used for sequential training. void DecaySynapseWeights(Bool_t lateEpoch); decay synapse weights; in last 10 epochs, lower learning rate even more to find a good minimum. void TrainOneEventFast(Int_t ievt, Float_t*& branchVar, Int_t& type); fast per-event training. void TrainOneEvent(Int_t ievt); train network over a single event; this uses the new event model. Double_t GetDesiredOutput(const TMVA::Event* ev); get the desired output of this event. void UpdateNetwork(Double_t desired, Double_t eventWeight = 1.0); update the network based on how closely; the output matched the desired output. void UpdateNetwork(vector<Float_t>& desired, Double_t eventWeight = 1.0); update the network based on how closely; the output matched the desired output. void CalculateNeuronDeltas(); have each neuron calculate its delta by backpropagation. void GeneticMinimize(); create genetics class similar to GeneticCut; give it vector of parameter ranges (parameters = weights); link fitness function of this class to ComputeEstimator; instantiate GA (see MethodCuts); run it; then this should exist for GA, Minuit and random sampling. Double_t EstimatorFunction(vector<Double_t>& parameters); interface to the estimate. Double_t ComputeEstimator(vector<Double_t>& parameters); this function is called by GeneticANN for GA optimization. void UpdateSynapses(); update synapse error fields and adjust the weights (if in sequential mode). void AdjustSynapseWeights(); just adjust the synapse weights (should be called in batch mode). void UpdatePriors(). void UpdateRegul",MatchSource.WIKI,root/html532/TMVA__MethodMLP.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodMLP.html
https://root.cern/root/html532/TMVA__MethodMLP.html:25690,Deployability,update,update,25690,"minimize estimator / train network with backpropagation algorithm. void TrainOneEpoch(); train network over a single epoch/cyle of events. void Shuffle(Int_t* index, Int_t n); Input:; index: the array to shuffle; n: the size of the array; Output:; index: the shuffled indexes; This method is used for sequential training. void DecaySynapseWeights(Bool_t lateEpoch); decay synapse weights; in last 10 epochs, lower learning rate even more to find a good minimum. void TrainOneEventFast(Int_t ievt, Float_t*& branchVar, Int_t& type); fast per-event training. void TrainOneEvent(Int_t ievt); train network over a single event; this uses the new event model. Double_t GetDesiredOutput(const TMVA::Event* ev); get the desired output of this event. void UpdateNetwork(Double_t desired, Double_t eventWeight = 1.0); update the network based on how closely; the output matched the desired output. void UpdateNetwork(vector<Float_t>& desired, Double_t eventWeight = 1.0); update the network based on how closely; the output matched the desired output. void CalculateNeuronDeltas(); have each neuron calculate its delta by backpropagation. void GeneticMinimize(); create genetics class similar to GeneticCut; give it vector of parameter ranges (parameters = weights); link fitness function of this class to ComputeEstimator; instantiate GA (see MethodCuts); run it; then this should exist for GA, Minuit and random sampling. Double_t EstimatorFunction(vector<Double_t>& parameters); interface to the estimate. Double_t ComputeEstimator(vector<Double_t>& parameters); this function is called by GeneticANN for GA optimization. void UpdateSynapses(); update synapse error fields and adjust the weights (if in sequential mode). void AdjustSynapseWeights(); just adjust the synapse weights (should be called in batch mode). void UpdatePriors(). void UpdateRegulators(). void GetApproxInvHessian(TMatrixD& InvHessian, bool regulate = true). Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0). void MakeC",MatchSource.WIKI,root/html532/TMVA__MethodMLP.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodMLP.html
https://root.cern/root/html532/TMVA__MethodMLP.html:26366,Deployability,update,update,26366,"GetDesiredOutput(const TMVA::Event* ev); get the desired output of this event. void UpdateNetwork(Double_t desired, Double_t eventWeight = 1.0); update the network based on how closely; the output matched the desired output. void UpdateNetwork(vector<Float_t>& desired, Double_t eventWeight = 1.0); update the network based on how closely; the output matched the desired output. void CalculateNeuronDeltas(); have each neuron calculate its delta by backpropagation. void GeneticMinimize(); create genetics class similar to GeneticCut; give it vector of parameter ranges (parameters = weights); link fitness function of this class to ComputeEstimator; instantiate GA (see MethodCuts); run it; then this should exist for GA, Minuit and random sampling. Double_t EstimatorFunction(vector<Double_t>& parameters); interface to the estimate. Double_t ComputeEstimator(vector<Double_t>& parameters); this function is called by GeneticANN for GA optimization. void UpdateSynapses(); update synapse error fields and adjust the weights (if in sequential mode). void AdjustSynapseWeights(); just adjust the synapse weights (should be called in batch mode). void UpdatePriors(). void UpdateRegulators(). void GetApproxInvHessian(TMatrixD& InvHessian, bool regulate = true). Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0). void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". void Train(); { Train(NumCycles()); }. bool HasInverseHessian(); { return fCalculateErrors; }. » Author: Krzysztof Danielowski, Andreas Hoecker, Matt Jachowski, Kamil Kraszewski, Maciej Kruk, Peter Speckmayer, Joerg Stelzer, Eckhard von Toerne, Jan Therhaag, Jiahang Zhong » Copyright (c) 2005-2011: *; » Last changed: root/tmva $Id: MethodMLP.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-12-02 14:28; This page h",MatchSource.WIKI,root/html532/TMVA__MethodMLP.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodMLP.html
https://root.cern/root/html532/TMVA__MethodMLP.html:18483,Energy Efficiency,monitor,monitoring,18483,,MatchSource.WIKI,root/html532/TMVA__MethodMLP.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodMLP.html
https://root.cern/root/html532/TMVA__MethodMLP.html:18573,Energy Efficiency,monitor,monitoring,18573,,MatchSource.WIKI,root/html532/TMVA__MethodMLP.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodMLP.html
https://root.cern/root/html532/TMVA__MethodMLP.html:18659,Energy Efficiency,monitor,monitoring,18659,,MatchSource.WIKI,root/html532/TMVA__MethodMLP.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodMLP.html
https://root.cern/root/html532/TMVA__MethodMLP.html:21054,Energy Efficiency,monitor,monitoring,21054,"seRegulatorzjh; TRandom3*TMVA::MethodANNBase::frgenrandom number generator for various uses. private:. TMVA::MethodMLP::EBPTrainingModefBPModebackprop learning mode (sequential or batch); Int_tfBatchSizebatch size, only matters if in batch learning mode; TStringfBpModeSbackprop learning mode option string (sequential or batch); boolfCalculateErrorscompute inverse hessian matrix at the end of the training; Double_tfDecayRatedecay rate for above learning rate; vector<std::pair<Float_t,Float_t> >*fDeviationsFromTargetsdeviation from the targets, event weight; Bool_tfEpochMoncreate and fill epoch-wise monitoring histograms (makes outputfile big!); Double_tfGA_SC_factorGA settings: SC_factor; Int_tfGA_SC_rateGA settings: SC_rate; Int_tfGA_SC_stepsGA settings: SC_steps; Int_tfGA_nstepsGA settings: number of steps; Int_tfGA_preCalcGA settings: number of pre-calc steps; Double_tfLastAlphaline search variable; Double_tfLearnRatelearning rate for synapse weight adjustments; Double_tfPriorzjh; vector<Double_t>fPriorDevzjh; Int_tfResetStepreset time (how often we clear hessian matrix); Float_tfSamplingEpochfraction of epochs where sampling is used; Float_tfSamplingFractionfraction of events which is sampled for training; Bool_tfSamplingTestingThe testing sample is sampled; Bool_tfSamplingTrainingThe training sample is sampled; Float_tfSamplingWeightchanging factor for event weights when sampling is turned on; Double_tfTauline search variable; Int_tfTestRatetest for overtraining performed at each #th epochs; TStringfTrainMethodStraining method option param; TMVA::MethodMLP::ETrainingMethodfTrainingMethodmethod of training, BP or GA; Int_tfUpdateLimitzjh; boolfUseRegulatorzjh; Float_tfWeightRangesuppress outliers for the estimator calculation; static const Bool_tfgPRINT_BATCHdebug flags; static const Int_tfgPRINT_ESTIMATOR_INCdebug flags; static const Bool_tfgPRINT_SEQdebug flags. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodMLP(",MatchSource.WIKI,root/html532/TMVA__MethodMLP.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodMLP.html
https://root.cern/root/html532/TMVA__MethodMLP.html:15339,Integrability,message,message,15339,"_t ignoreIndex = -1); virtual voidGetHelpMessage() const; TMVA::TNeuron*TMVA::MethodANNBase::GetInputNeuron(Int_t index); const TString&TMVA::MethodBase::GetInternalVarName(Int_t ivar) const; Double_tTMVA::MethodANNBase::GetNetworkOutput(); const TString&TMVA::MethodBase::GetOriginalVarName(Int_t ivar) const; TMVA::TNeuron*TMVA::MethodANNBase::GetOutputNeuron(Int_t index = 0); const TString&TMVA::Configurable::GetReferenceFile() const; static TMVA::MethodBase*TMVA::MethodBase::GetThisBase(); Float_tTMVA::MethodBase::GetTWeight(const TMVA::Event* ev) const; const TString&TMVA::MethodBase::GetWeightFileDir() const; Bool_tTMVA::MethodBase::HasTrainingTree() const; Bool_tTMVA::MethodBase::Help() const; Bool_tTMVA::MethodBase::IgnoreEventsWithNegWeightsInTraining() const; Bool_tTMVA::MethodBase::IsConstructedFromWeightFile() const; Bool_tTMVA::MethodBase::IsNormalised() const; TMVA::MsgLogger&TMVA::Configurable::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; virtual voidMakeClassSpecific(ostream&, const TString&) const; virtual voidTMVA::MethodBase::MakeClassSpecificHeader(ostream&, const TString& = """") const; voidTObject::MakeZombie(); voidTMVA::MethodBase::NoErrorCalc(Double_t *const err, Double_t *const errUpper); Int_tTMVA::MethodANNBase::NumCycles(); vector<Int_t>*TMVA::MethodANNBase::ParseLayoutString(TString layerSpec); voidTMVA::MethodANNBase::PrintMessage(TString message, Bool_t force = kFALSE) const; voidTMVA::Configurable::ResetSetFlag(); voidTMVA::MethodBase::SetNormalised(Bool_t norm); voidTMVA::MethodBase::SetWeightFileDir(TString fileDir); voidTMVA::MethodBase::SetWeightFileName(TString); voidTMVA::MethodBase::Statistics(TMVA::Types::ETreeType treeType, const TString& theVarName, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&); Bool_tTMVA::MethodBase::TxtWeightsOnly() const; Bool_tTMVA::MethodBase::Verbose() const; voidTMVA::MethodANNBase::WaitForKeyboard(); voidTMVA::Configurable::WriteOptionsReferenceToFile().",MatchSource.WIKI,root/html532/TMVA__MethodMLP.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodMLP.html
https://root.cern/root/html532/TMVA__MethodMLP.html:19801,Integrability,depend,depending,19801,"thodANNBase::fEpochMonHistSepoch monitoring hitograms for signal; vector<TH1*>TMVA::MethodANNBase::fEpochMonHistWepoch monitoring hitograms for weights; TMVA::MethodANNBase::EEstimatorTMVA::MethodANNBase::fEstimator; TH1F*TMVA::MethodANNBase::fEstimatorHistTestmonitors convergence of independent test sample; TH1F*TMVA::MethodANNBase::fEstimatorHistTrainmonitors convergence of training sample; TStringTMVA::MethodANNBase::fEstimatorS; TMVA::TActivation*TMVA::MethodANNBase::fIdentityactivation for input and output layers; TMVA::TNeuronInput*TMVA::MethodANNBase::fInputCalculatorinput calculator for all neurons; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; TMatrixDTMVA::MethodANNBase::fInvHessianzjh; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TObjArray*TMVA::MethodANNBase::fNetworkTObjArray of TObjArrays representing network; TMVA::TActivation*TMVA::MethodANNBase::fOutputactivation function to be used for output layers, depending on estimator; Int_tTMVA::MethodANNBase::fRandomSeedrandom seed for initial synapse weights; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; vector<Int_t>TMVA::MethodANNBase::fRegulatorIdxindex to different priors from every synapses; vector<Double_t>TMVA::MethodANNBase::fRegulatorsthe priors as regulator; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class; TObjArray*TMVA::MethodANNBase::fSynapsesarray of pointers to synapses, no structural data; boolTMVA::MethodANNBase::fUseRegulatorzjh; TRandom3*TMVA::MethodANNBase::frgenrandom number generator for various uses.",MatchSource.WIKI,root/html532/TMVA__MethodMLP.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodMLP.html
https://root.cern/root/html532/TMVA__MethodMLP.html:26200,Integrability,interface,interface,26200,"imum. void TrainOneEventFast(Int_t ievt, Float_t*& branchVar, Int_t& type); fast per-event training. void TrainOneEvent(Int_t ievt); train network over a single event; this uses the new event model. Double_t GetDesiredOutput(const TMVA::Event* ev); get the desired output of this event. void UpdateNetwork(Double_t desired, Double_t eventWeight = 1.0); update the network based on how closely; the output matched the desired output. void UpdateNetwork(vector<Float_t>& desired, Double_t eventWeight = 1.0); update the network based on how closely; the output matched the desired output. void CalculateNeuronDeltas(); have each neuron calculate its delta by backpropagation. void GeneticMinimize(); create genetics class similar to GeneticCut; give it vector of parameter ranges (parameters = weights); link fitness function of this class to ComputeEstimator; instantiate GA (see MethodCuts); run it; then this should exist for GA, Minuit and random sampling. Double_t EstimatorFunction(vector<Double_t>& parameters); interface to the estimate. Double_t ComputeEstimator(vector<Double_t>& parameters); this function is called by GeneticANN for GA optimization. void UpdateSynapses(); update synapse error fields and adjust the weights (if in sequential mode). void AdjustSynapseWeights(); just adjust the synapse weights (should be called in batch mode). void UpdatePriors(). void UpdateRegulators(). void GetApproxInvHessian(TMatrixD& InvHessian, bool regulate = true). Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0). void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". void Train(); { Train(NumCycles()); }. bool HasInverseHessian(); { return fCalculateErrors; }. » Author: Krzysztof Danielowski, Andreas Hoecker, Matt Jachowski, Kamil Kraszewski, Maciej Kruk, Peter Speckmayer, Joerg Stelze",MatchSource.WIKI,root/html532/TMVA__MethodMLP.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodMLP.html
https://root.cern/root/html532/TMVA__MethodMLP.html:26850,Integrability,message,message,26850,"update the network based on how closely; the output matched the desired output. void UpdateNetwork(vector<Float_t>& desired, Double_t eventWeight = 1.0); update the network based on how closely; the output matched the desired output. void CalculateNeuronDeltas(); have each neuron calculate its delta by backpropagation. void GeneticMinimize(); create genetics class similar to GeneticCut; give it vector of parameter ranges (parameters = weights); link fitness function of this class to ComputeEstimator; instantiate GA (see MethodCuts); run it; then this should exist for GA, Minuit and random sampling. Double_t EstimatorFunction(vector<Double_t>& parameters); interface to the estimate. Double_t ComputeEstimator(vector<Double_t>& parameters); this function is called by GeneticANN for GA optimization. void UpdateSynapses(); update synapse error fields and adjust the weights (if in sequential mode). void AdjustSynapseWeights(); just adjust the synapse weights (should be called in batch mode). void UpdatePriors(). void UpdateRegulators(). void GetApproxInvHessian(TMatrixD& InvHessian, bool regulate = true). Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0). void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". void Train(); { Train(NumCycles()); }. bool HasInverseHessian(); { return fCalculateErrors; }. » Author: Krzysztof Danielowski, Andreas Hoecker, Matt Jachowski, Kamil Kraszewski, Maciej Kruk, Peter Speckmayer, Joerg Stelzer, Eckhard von Toerne, Jan Therhaag, Jiahang Zhong » Copyright (c) 2005-2011: *; » Last changed: root/tmva $Id: MethodMLP.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-12-02 14:28; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__MethodMLP.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodMLP.html
https://root.cern/root/html532/TMVA__MethodMLP.html:18233,Modifiability,layers,layers,18233,,MatchSource.WIKI,root/html532/TMVA__MethodMLP.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodMLP.html
https://root.cern/root/html532/TMVA__MethodMLP.html:19057,Modifiability,layers,layers,19057,,MatchSource.WIKI,root/html532/TMVA__MethodMLP.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodMLP.html
https://root.cern/root/html532/TMVA__MethodMLP.html:19215,Modifiability,variab,variables,19215,"d for hidden layers; TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TH1*>TMVA::MethodANNBase::fEpochMonHistBepoch monitoring hitograms for background; vector<TH1*>TMVA::MethodANNBase::fEpochMonHistSepoch monitoring hitograms for signal; vector<TH1*>TMVA::MethodANNBase::fEpochMonHistWepoch monitoring hitograms for weights; TMVA::MethodANNBase::EEstimatorTMVA::MethodANNBase::fEstimator; TH1F*TMVA::MethodANNBase::fEstimatorHistTestmonitors convergence of independent test sample; TH1F*TMVA::MethodANNBase::fEstimatorHistTrainmonitors convergence of training sample; TStringTMVA::MethodANNBase::fEstimatorS; TMVA::TActivation*TMVA::MethodANNBase::fIdentityactivation for input and output layers; TMVA::TNeuronInput*TMVA::MethodANNBase::fInputCalculatorinput calculator for all neurons; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; TMatrixDTMVA::MethodANNBase::fInvHessianzjh; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TObjArray*TMVA::MethodANNBase::fNetworkTObjArray of TObjArrays representing network; TMVA::TActivation*TMVA::MethodANNBase::fOutputactivation function to be used for output layers, depending on estimator; Int_tTMVA::MethodANNBase::fRandomSeedrandom seed for initial synapse weights; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; vector<Int_t>TMVA::MethodANNBase::fRegulatorIdxindex to different priors from every synapses; vector<Double_t>TMVA::Met",MatchSource.WIKI,root/html532/TMVA__MethodMLP.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodMLP.html
https://root.cern/root/html532/TMVA__MethodMLP.html:19449,Modifiability,variab,variable,19449,"dANNBase::fEpochMonHistBepoch monitoring hitograms for background; vector<TH1*>TMVA::MethodANNBase::fEpochMonHistSepoch monitoring hitograms for signal; vector<TH1*>TMVA::MethodANNBase::fEpochMonHistWepoch monitoring hitograms for weights; TMVA::MethodANNBase::EEstimatorTMVA::MethodANNBase::fEstimator; TH1F*TMVA::MethodANNBase::fEstimatorHistTestmonitors convergence of independent test sample; TH1F*TMVA::MethodANNBase::fEstimatorHistTrainmonitors convergence of training sample; TStringTMVA::MethodANNBase::fEstimatorS; TMVA::TActivation*TMVA::MethodANNBase::fIdentityactivation for input and output layers; TMVA::TNeuronInput*TMVA::MethodANNBase::fInputCalculatorinput calculator for all neurons; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; TMatrixDTMVA::MethodANNBase::fInvHessianzjh; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TObjArray*TMVA::MethodANNBase::fNetworkTObjArray of TObjArrays representing network; TMVA::TActivation*TMVA::MethodANNBase::fOutputactivation function to be used for output layers, depending on estimator; Int_tTMVA::MethodANNBase::fRandomSeedrandom seed for initial synapse weights; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; vector<Int_t>TMVA::MethodANNBase::fRegulatorIdxindex to different priors from every synapses; vector<Double_t>TMVA::MethodANNBase::fRegulatorsthe priors as regulator; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class; TObjArray*TMVA::MethodANNBase::fSynapsesarray of pointers to synapses, no structural data; boolTMVA::MethodANNBase::fUseReg",MatchSource.WIKI,root/html532/TMVA__MethodMLP.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodMLP.html
https://root.cern/root/html532/TMVA__MethodMLP.html:19793,Modifiability,layers,layers,19793,"thodANNBase::fEpochMonHistSepoch monitoring hitograms for signal; vector<TH1*>TMVA::MethodANNBase::fEpochMonHistWepoch monitoring hitograms for weights; TMVA::MethodANNBase::EEstimatorTMVA::MethodANNBase::fEstimator; TH1F*TMVA::MethodANNBase::fEstimatorHistTestmonitors convergence of independent test sample; TH1F*TMVA::MethodANNBase::fEstimatorHistTrainmonitors convergence of training sample; TStringTMVA::MethodANNBase::fEstimatorS; TMVA::TActivation*TMVA::MethodANNBase::fIdentityactivation for input and output layers; TMVA::TNeuronInput*TMVA::MethodANNBase::fInputCalculatorinput calculator for all neurons; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; TMatrixDTMVA::MethodANNBase::fInvHessianzjh; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TObjArray*TMVA::MethodANNBase::fNetworkTObjArray of TObjArrays representing network; TMVA::TActivation*TMVA::MethodANNBase::fOutputactivation function to be used for output layers, depending on estimator; Int_tTMVA::MethodANNBase::fRandomSeedrandom seed for initial synapse weights; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; vector<Int_t>TMVA::MethodANNBase::fRegulatorIdxindex to different priors from every synapses; vector<Double_t>TMVA::MethodANNBase::fRegulatorsthe priors as regulator; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class; TObjArray*TMVA::MethodANNBase::fSynapsesarray of pointers to synapses, no structural data; boolTMVA::MethodANNBase::fUseRegulatorzjh; TRandom3*TMVA::MethodANNBase::frgenrandom number generator for various uses.",MatchSource.WIKI,root/html532/TMVA__MethodMLP.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodMLP.html
https://root.cern/root/html532/TMVA__MethodMLP.html:21354,Modifiability,variab,variable,21354,"seRegulatorzjh; TRandom3*TMVA::MethodANNBase::frgenrandom number generator for various uses. private:. TMVA::MethodMLP::EBPTrainingModefBPModebackprop learning mode (sequential or batch); Int_tfBatchSizebatch size, only matters if in batch learning mode; TStringfBpModeSbackprop learning mode option string (sequential or batch); boolfCalculateErrorscompute inverse hessian matrix at the end of the training; Double_tfDecayRatedecay rate for above learning rate; vector<std::pair<Float_t,Float_t> >*fDeviationsFromTargetsdeviation from the targets, event weight; Bool_tfEpochMoncreate and fill epoch-wise monitoring histograms (makes outputfile big!); Double_tfGA_SC_factorGA settings: SC_factor; Int_tfGA_SC_rateGA settings: SC_rate; Int_tfGA_SC_stepsGA settings: SC_steps; Int_tfGA_nstepsGA settings: number of steps; Int_tfGA_preCalcGA settings: number of pre-calc steps; Double_tfLastAlphaline search variable; Double_tfLearnRatelearning rate for synapse weight adjustments; Double_tfPriorzjh; vector<Double_t>fPriorDevzjh; Int_tfResetStepreset time (how often we clear hessian matrix); Float_tfSamplingEpochfraction of epochs where sampling is used; Float_tfSamplingFractionfraction of events which is sampled for training; Bool_tfSamplingTestingThe testing sample is sampled; Bool_tfSamplingTrainingThe training sample is sampled; Float_tfSamplingWeightchanging factor for event weights when sampling is turned on; Double_tfTauline search variable; Int_tfTestRatetest for overtraining performed at each #th epochs; TStringfTrainMethodStraining method option param; TMVA::MethodMLP::ETrainingMethodfTrainingMethodmethod of training, BP or GA; Int_tfUpdateLimitzjh; boolfUseRegulatorzjh; Float_tfWeightRangesuppress outliers for the estimator calculation; static const Bool_tfgPRINT_BATCHdebug flags; static const Int_tfgPRINT_ESTIMATOR_INCdebug flags; static const Bool_tfgPRINT_SEQdebug flags. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodMLP(",MatchSource.WIKI,root/html532/TMVA__MethodMLP.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodMLP.html
https://root.cern/root/html532/TMVA__MethodMLP.html:21894,Modifiability,variab,variable,21894,"seRegulatorzjh; TRandom3*TMVA::MethodANNBase::frgenrandom number generator for various uses. private:. TMVA::MethodMLP::EBPTrainingModefBPModebackprop learning mode (sequential or batch); Int_tfBatchSizebatch size, only matters if in batch learning mode; TStringfBpModeSbackprop learning mode option string (sequential or batch); boolfCalculateErrorscompute inverse hessian matrix at the end of the training; Double_tfDecayRatedecay rate for above learning rate; vector<std::pair<Float_t,Float_t> >*fDeviationsFromTargetsdeviation from the targets, event weight; Bool_tfEpochMoncreate and fill epoch-wise monitoring histograms (makes outputfile big!); Double_tfGA_SC_factorGA settings: SC_factor; Int_tfGA_SC_rateGA settings: SC_rate; Int_tfGA_SC_stepsGA settings: SC_steps; Int_tfGA_nstepsGA settings: number of steps; Int_tfGA_preCalcGA settings: number of pre-calc steps; Double_tfLastAlphaline search variable; Double_tfLearnRatelearning rate for synapse weight adjustments; Double_tfPriorzjh; vector<Double_t>fPriorDevzjh; Int_tfResetStepreset time (how often we clear hessian matrix); Float_tfSamplingEpochfraction of epochs where sampling is used; Float_tfSamplingFractionfraction of events which is sampled for training; Bool_tfSamplingTestingThe testing sample is sampled; Bool_tfSamplingTrainingThe training sample is sampled; Float_tfSamplingWeightchanging factor for event weights when sampling is turned on; Double_tfTauline search variable; Int_tfTestRatetest for overtraining performed at each #th epochs; TStringfTrainMethodStraining method option param; TMVA::MethodMLP::ETrainingMethodfTrainingMethodmethod of training, BP or GA; Int_tfUpdateLimitzjh; boolfUseRegulatorzjh; Float_tfWeightRangesuppress outliers for the estimator calculation; static const Bool_tfgPRINT_BATCHdebug flags; static const Int_tfgPRINT_ESTIMATOR_INCdebug flags; static const Bool_tfgPRINT_SEQdebug flags. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodMLP(",MatchSource.WIKI,root/html532/TMVA__MethodMLP.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodMLP.html
https://root.cern/root/html532/TMVA__MethodMLP.html:12043,Performance,tune,tuneParameters,12043,"const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); voidTMVA::MethodANNBase::SetNeuronInputCalculator(TMVA::TNeuronInput* inputCalculator); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int",MatchSource.WIKI,root/html532/TMVA__MethodMLP.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodMLP.html
https://root.cern/root/html532/TMVA__MethodMLP.html:21940,Performance,perform,performed,21940,"seRegulatorzjh; TRandom3*TMVA::MethodANNBase::frgenrandom number generator for various uses. private:. TMVA::MethodMLP::EBPTrainingModefBPModebackprop learning mode (sequential or batch); Int_tfBatchSizebatch size, only matters if in batch learning mode; TStringfBpModeSbackprop learning mode option string (sequential or batch); boolfCalculateErrorscompute inverse hessian matrix at the end of the training; Double_tfDecayRatedecay rate for above learning rate; vector<std::pair<Float_t,Float_t> >*fDeviationsFromTargetsdeviation from the targets, event weight; Bool_tfEpochMoncreate and fill epoch-wise monitoring histograms (makes outputfile big!); Double_tfGA_SC_factorGA settings: SC_factor; Int_tfGA_SC_rateGA settings: SC_rate; Int_tfGA_SC_stepsGA settings: SC_steps; Int_tfGA_nstepsGA settings: number of steps; Int_tfGA_preCalcGA settings: number of pre-calc steps; Double_tfLastAlphaline search variable; Double_tfLearnRatelearning rate for synapse weight adjustments; Double_tfPriorzjh; vector<Double_t>fPriorDevzjh; Int_tfResetStepreset time (how often we clear hessian matrix); Float_tfSamplingEpochfraction of epochs where sampling is used; Float_tfSamplingFractionfraction of events which is sampled for training; Bool_tfSamplingTestingThe testing sample is sampled; Bool_tfSamplingTrainingThe training sample is sampled; Float_tfSamplingWeightchanging factor for event weights when sampling is turned on; Double_tfTauline search variable; Int_tfTestRatetest for overtraining performed at each #th epochs; TStringfTrainMethodStraining method option param; TMVA::MethodMLP::ETrainingMethodfTrainingMethodmethod of training, BP or GA; Int_tfUpdateLimitzjh; boolfUseRegulatorzjh; Float_tfWeightRangesuppress outliers for the estimator calculation; static const Bool_tfgPRINT_BATCHdebug flags; static const Int_tfgPRINT_ESTIMATOR_INCdebug flags; static const Bool_tfgPRINT_SEQdebug flags. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodMLP(",MatchSource.WIKI,root/html532/TMVA__MethodMLP.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodMLP.html
https://root.cern/root/html532/TMVA__MethodMLP.html:23401,Performance,perform,performed,23401,"gs. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodMLP(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption, TDirectory* theTargetDir = 0); standard constructor. MethodMLP(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = 0); constructor from a weight file. ~MethodMLP(); destructor; nothing to be done. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); MLP can handle classification with 2 classes and regression with one regression-target. void Init(); default initializations. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options:; TrainingMethod <string> Training method; available values are: BP Back-Propagation <default>; GA Genetic Algorithm (takes a LONG time). LearningRate <float> NN learning rate parameter; DecayRate <float> Decay rate for learning parameter; TestRate <int> Test for overtraining performed at each #th epochs. BPMode <string> Back-propagation learning mode; available values are: sequential <default>; batch. BatchSize <int> Batch size: number of events/batch, only set if in Batch Mode,; -1 for BatchSize=number_of_events. void ProcessOptions(); process user options. void InitializeLearningRates(); initialize learning rates of synapses, used only by backpropagation. Double_t CalculateEstimator(TMVA::Types::ETreeType treeType = Types::kTraining, Int_t iEpoch = -1); calculate the estimator that training is attempting to minimize. void Train(Int_t nEpochs). void BFGSMinimize(Int_t nEpochs); train network with BFGS algorithm. void SetGammaDelta(TMatrixD& Gamma, TMatrixD& Delta, vector<Double_t>& Buffer). void ComputeDEDw(). void SimulateEvent(const TMVA::Event* ev). void SteepestDir(TMatrixD& Dir). Bool_t GetHessian(TMatrixD& Hessian, TMatrixD& Gamma, TMatrixD& Delta). void SetDir(TMatrixD& Hessian, TMatrixD& Dir).",MatchSource.WIKI,root/html532/TMVA__MethodMLP.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodMLP.html
https://root.cern/root/html532/TMVA__MethodMLP.html:26329,Performance,optimiz,optimization,26329,"void TrainOneEvent(Int_t ievt); train network over a single event; this uses the new event model. Double_t GetDesiredOutput(const TMVA::Event* ev); get the desired output of this event. void UpdateNetwork(Double_t desired, Double_t eventWeight = 1.0); update the network based on how closely; the output matched the desired output. void UpdateNetwork(vector<Float_t>& desired, Double_t eventWeight = 1.0); update the network based on how closely; the output matched the desired output. void CalculateNeuronDeltas(); have each neuron calculate its delta by backpropagation. void GeneticMinimize(); create genetics class similar to GeneticCut; give it vector of parameter ranges (parameters = weights); link fitness function of this class to ComputeEstimator; instantiate GA (see MethodCuts); run it; then this should exist for GA, Minuit and random sampling. Double_t EstimatorFunction(vector<Double_t>& parameters); interface to the estimate. Double_t ComputeEstimator(vector<Double_t>& parameters); this function is called by GeneticANN for GA optimization. void UpdateSynapses(); update synapse error fields and adjust the weights (if in sequential mode). void AdjustSynapseWeights(); just adjust the synapse weights (should be called in batch mode). void UpdatePriors(). void UpdateRegulators(). void GetApproxInvHessian(TMatrixD& InvHessian, bool regulate = true). Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0). void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". void Train(); { Train(NumCycles()); }. bool HasInverseHessian(); { return fCalculateErrors; }. » Author: Krzysztof Danielowski, Andreas Hoecker, Matt Jachowski, Kamil Kraszewski, Maciej Kruk, Peter Speckmayer, Joerg Stelzer, Eckhard von Toerne, Jan Therhaag, Jiahang Zhong » Copyright (c) 2005-2011: *; » Last changed: roo",MatchSource.WIKI,root/html532/TMVA__MethodMLP.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodMLP.html
https://root.cern/root/html532/TMVA__MethodMLP.html:11845,Testability,test,testTime,11845,"es::EAnalysisType type); voidTMVA::MethodBase::SetBaseDir(TDirectory* methodDir); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); voidTMVA::MethodANNBase::SetNeuronInputCalculator(TMVA::TNeuronInput* inputCalculator); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObj",MatchSource.WIKI,root/html532/TMVA__MethodMLP.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodMLP.html
https://root.cern/root/html532/TMVA__MethodMLP.html:18080,Testability,test,testing,18080,"voidSimulateEvent(const TMVA::Event* ev); voidSteepestDir(TMatrixD& Dir); voidTrain(Int_t nEpochs); voidTrainOneEpoch(); voidTrainOneEvent(Int_t ievt); voidTrainOneEventFast(Int_t ievt, Float_t*& branchVar, Int_t& type); voidUpdateNetwork(Double_t desired, Double_t eventWeight = 1.0); voidUpdateNetwork(vector<Float_t>& desired, Double_t eventWeight = 1.0); voidUpdatePriors(); voidUpdateRegulators(); voidUpdateSynapses(). Data Members; public:. enum ETrainingMethod { kBP; kBFGS; kGA; };; enum EBPTrainingMode { kSequential; kBatch; };; enum TMVA::MethodANNBase::EEstimator { kMSE; kCE; };; enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::TActivation*TMVA::MethodANNBase::fActivationactivation function to be used for hidden layers; TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TH1*>TMVA::MethodANNBase::fEpochMonHistBepoch monitoring hitograms for background; vector<TH1*>TMVA::MethodANNBase::fEpochMonHistSepoch monitoring hitograms for signal; vector<TH1*>TMVA::MethodANNBase::fEpochMonHistWepoch monitoring hitograms for weights; TMVA::MethodANNBase::EEstimatorTMVA::MethodANNBase::fEstimator; TH1F*TMVA::MethodANNBase::fEstimatorHistTestmonitors convergence of independent test sample; TH1F*TMVA::MethodANNBase::fEstimatorHistTrainmonitors convergence of training sample; TStringTMVA::MethodANNBase::fEstimatorS; TMVA::TActivation*TMVA::MethodANNBase::fIdentityactivation for in",MatchSource.WIKI,root/html532/TMVA__MethodMLP.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodMLP.html
https://root.cern/root/html532/TMVA__MethodMLP.html:18837,Testability,test,test,18837,,MatchSource.WIKI,root/html532/TMVA__MethodMLP.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodMLP.html
https://root.cern/root/html532/TMVA__MethodMLP.html:21704,Testability,test,testing,21704,"seRegulatorzjh; TRandom3*TMVA::MethodANNBase::frgenrandom number generator for various uses. private:. TMVA::MethodMLP::EBPTrainingModefBPModebackprop learning mode (sequential or batch); Int_tfBatchSizebatch size, only matters if in batch learning mode; TStringfBpModeSbackprop learning mode option string (sequential or batch); boolfCalculateErrorscompute inverse hessian matrix at the end of the training; Double_tfDecayRatedecay rate for above learning rate; vector<std::pair<Float_t,Float_t> >*fDeviationsFromTargetsdeviation from the targets, event weight; Bool_tfEpochMoncreate and fill epoch-wise monitoring histograms (makes outputfile big!); Double_tfGA_SC_factorGA settings: SC_factor; Int_tfGA_SC_rateGA settings: SC_rate; Int_tfGA_SC_stepsGA settings: SC_steps; Int_tfGA_nstepsGA settings: number of steps; Int_tfGA_preCalcGA settings: number of pre-calc steps; Double_tfLastAlphaline search variable; Double_tfLearnRatelearning rate for synapse weight adjustments; Double_tfPriorzjh; vector<Double_t>fPriorDevzjh; Int_tfResetStepreset time (how often we clear hessian matrix); Float_tfSamplingEpochfraction of epochs where sampling is used; Float_tfSamplingFractionfraction of events which is sampled for training; Bool_tfSamplingTestingThe testing sample is sampled; Bool_tfSamplingTrainingThe training sample is sampled; Float_tfSamplingWeightchanging factor for event weights when sampling is turned on; Double_tfTauline search variable; Int_tfTestRatetest for overtraining performed at each #th epochs; TStringfTrainMethodStraining method option param; TMVA::MethodMLP::ETrainingMethodfTrainingMethodmethod of training, BP or GA; Int_tfUpdateLimitzjh; boolfUseRegulatorzjh; Float_tfWeightRangesuppress outliers for the estimator calculation; static const Bool_tfgPRINT_BATCHdebug flags; static const Int_tfgPRINT_ESTIMATOR_INCdebug flags; static const Bool_tfgPRINT_SEQdebug flags. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodMLP(",MatchSource.WIKI,root/html532/TMVA__MethodMLP.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodMLP.html
https://root.cern/root/html532/TMVA__MethodMLP.html:20600,Usability,learn,learning,20600,"seRegulatorzjh; TRandom3*TMVA::MethodANNBase::frgenrandom number generator for various uses. private:. TMVA::MethodMLP::EBPTrainingModefBPModebackprop learning mode (sequential or batch); Int_tfBatchSizebatch size, only matters if in batch learning mode; TStringfBpModeSbackprop learning mode option string (sequential or batch); boolfCalculateErrorscompute inverse hessian matrix at the end of the training; Double_tfDecayRatedecay rate for above learning rate; vector<std::pair<Float_t,Float_t> >*fDeviationsFromTargetsdeviation from the targets, event weight; Bool_tfEpochMoncreate and fill epoch-wise monitoring histograms (makes outputfile big!); Double_tfGA_SC_factorGA settings: SC_factor; Int_tfGA_SC_rateGA settings: SC_rate; Int_tfGA_SC_stepsGA settings: SC_steps; Int_tfGA_nstepsGA settings: number of steps; Int_tfGA_preCalcGA settings: number of pre-calc steps; Double_tfLastAlphaline search variable; Double_tfLearnRatelearning rate for synapse weight adjustments; Double_tfPriorzjh; vector<Double_t>fPriorDevzjh; Int_tfResetStepreset time (how often we clear hessian matrix); Float_tfSamplingEpochfraction of epochs where sampling is used; Float_tfSamplingFractionfraction of events which is sampled for training; Bool_tfSamplingTestingThe testing sample is sampled; Bool_tfSamplingTrainingThe training sample is sampled; Float_tfSamplingWeightchanging factor for event weights when sampling is turned on; Double_tfTauline search variable; Int_tfTestRatetest for overtraining performed at each #th epochs; TStringfTrainMethodStraining method option param; TMVA::MethodMLP::ETrainingMethodfTrainingMethodmethod of training, BP or GA; Int_tfUpdateLimitzjh; boolfUseRegulatorzjh; Float_tfWeightRangesuppress outliers for the estimator calculation; static const Bool_tfgPRINT_BATCHdebug flags; static const Int_tfgPRINT_ESTIMATOR_INCdebug flags; static const Bool_tfgPRINT_SEQdebug flags. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodMLP(",MatchSource.WIKI,root/html532/TMVA__MethodMLP.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodMLP.html
https://root.cern/root/html532/TMVA__MethodMLP.html:20689,Usability,learn,learning,20689,"seRegulatorzjh; TRandom3*TMVA::MethodANNBase::frgenrandom number generator for various uses. private:. TMVA::MethodMLP::EBPTrainingModefBPModebackprop learning mode (sequential or batch); Int_tfBatchSizebatch size, only matters if in batch learning mode; TStringfBpModeSbackprop learning mode option string (sequential or batch); boolfCalculateErrorscompute inverse hessian matrix at the end of the training; Double_tfDecayRatedecay rate for above learning rate; vector<std::pair<Float_t,Float_t> >*fDeviationsFromTargetsdeviation from the targets, event weight; Bool_tfEpochMoncreate and fill epoch-wise monitoring histograms (makes outputfile big!); Double_tfGA_SC_factorGA settings: SC_factor; Int_tfGA_SC_rateGA settings: SC_rate; Int_tfGA_SC_stepsGA settings: SC_steps; Int_tfGA_nstepsGA settings: number of steps; Int_tfGA_preCalcGA settings: number of pre-calc steps; Double_tfLastAlphaline search variable; Double_tfLearnRatelearning rate for synapse weight adjustments; Double_tfPriorzjh; vector<Double_t>fPriorDevzjh; Int_tfResetStepreset time (how often we clear hessian matrix); Float_tfSamplingEpochfraction of epochs where sampling is used; Float_tfSamplingFractionfraction of events which is sampled for training; Bool_tfSamplingTestingThe testing sample is sampled; Bool_tfSamplingTrainingThe training sample is sampled; Float_tfSamplingWeightchanging factor for event weights when sampling is turned on; Double_tfTauline search variable; Int_tfTestRatetest for overtraining performed at each #th epochs; TStringfTrainMethodStraining method option param; TMVA::MethodMLP::ETrainingMethodfTrainingMethodmethod of training, BP or GA; Int_tfUpdateLimitzjh; boolfUseRegulatorzjh; Float_tfWeightRangesuppress outliers for the estimator calculation; static const Bool_tfgPRINT_BATCHdebug flags; static const Int_tfgPRINT_ESTIMATOR_INCdebug flags; static const Bool_tfgPRINT_SEQdebug flags. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodMLP(",MatchSource.WIKI,root/html532/TMVA__MethodMLP.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodMLP.html
https://root.cern/root/html532/TMVA__MethodMLP.html:20728,Usability,learn,learning,20728,"seRegulatorzjh; TRandom3*TMVA::MethodANNBase::frgenrandom number generator for various uses. private:. TMVA::MethodMLP::EBPTrainingModefBPModebackprop learning mode (sequential or batch); Int_tfBatchSizebatch size, only matters if in batch learning mode; TStringfBpModeSbackprop learning mode option string (sequential or batch); boolfCalculateErrorscompute inverse hessian matrix at the end of the training; Double_tfDecayRatedecay rate for above learning rate; vector<std::pair<Float_t,Float_t> >*fDeviationsFromTargetsdeviation from the targets, event weight; Bool_tfEpochMoncreate and fill epoch-wise monitoring histograms (makes outputfile big!); Double_tfGA_SC_factorGA settings: SC_factor; Int_tfGA_SC_rateGA settings: SC_rate; Int_tfGA_SC_stepsGA settings: SC_steps; Int_tfGA_nstepsGA settings: number of steps; Int_tfGA_preCalcGA settings: number of pre-calc steps; Double_tfLastAlphaline search variable; Double_tfLearnRatelearning rate for synapse weight adjustments; Double_tfPriorzjh; vector<Double_t>fPriorDevzjh; Int_tfResetStepreset time (how often we clear hessian matrix); Float_tfSamplingEpochfraction of epochs where sampling is used; Float_tfSamplingFractionfraction of events which is sampled for training; Bool_tfSamplingTestingThe testing sample is sampled; Bool_tfSamplingTrainingThe training sample is sampled; Float_tfSamplingWeightchanging factor for event weights when sampling is turned on; Double_tfTauline search variable; Int_tfTestRatetest for overtraining performed at each #th epochs; TStringfTrainMethodStraining method option param; TMVA::MethodMLP::ETrainingMethodfTrainingMethodmethod of training, BP or GA; Int_tfUpdateLimitzjh; boolfUseRegulatorzjh; Float_tfWeightRangesuppress outliers for the estimator calculation; static const Bool_tfgPRINT_BATCHdebug flags; static const Int_tfgPRINT_ESTIMATOR_INCdebug flags; static const Bool_tfgPRINT_SEQdebug flags. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodMLP(",MatchSource.WIKI,root/html532/TMVA__MethodMLP.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodMLP.html
https://root.cern/root/html532/TMVA__MethodMLP.html:20897,Usability,learn,learning,20897,"seRegulatorzjh; TRandom3*TMVA::MethodANNBase::frgenrandom number generator for various uses. private:. TMVA::MethodMLP::EBPTrainingModefBPModebackprop learning mode (sequential or batch); Int_tfBatchSizebatch size, only matters if in batch learning mode; TStringfBpModeSbackprop learning mode option string (sequential or batch); boolfCalculateErrorscompute inverse hessian matrix at the end of the training; Double_tfDecayRatedecay rate for above learning rate; vector<std::pair<Float_t,Float_t> >*fDeviationsFromTargetsdeviation from the targets, event weight; Bool_tfEpochMoncreate and fill epoch-wise monitoring histograms (makes outputfile big!); Double_tfGA_SC_factorGA settings: SC_factor; Int_tfGA_SC_rateGA settings: SC_rate; Int_tfGA_SC_stepsGA settings: SC_steps; Int_tfGA_nstepsGA settings: number of steps; Int_tfGA_preCalcGA settings: number of pre-calc steps; Double_tfLastAlphaline search variable; Double_tfLearnRatelearning rate for synapse weight adjustments; Double_tfPriorzjh; vector<Double_t>fPriorDevzjh; Int_tfResetStepreset time (how often we clear hessian matrix); Float_tfSamplingEpochfraction of epochs where sampling is used; Float_tfSamplingFractionfraction of events which is sampled for training; Bool_tfSamplingTestingThe testing sample is sampled; Bool_tfSamplingTrainingThe training sample is sampled; Float_tfSamplingWeightchanging factor for event weights when sampling is turned on; Double_tfTauline search variable; Int_tfTestRatetest for overtraining performed at each #th epochs; TStringfTrainMethodStraining method option param; TMVA::MethodMLP::ETrainingMethodfTrainingMethodmethod of training, BP or GA; Int_tfUpdateLimitzjh; boolfUseRegulatorzjh; Float_tfWeightRangesuppress outliers for the estimator calculation; static const Bool_tfgPRINT_BATCHdebug flags; static const Int_tfgPRINT_ESTIMATOR_INCdebug flags; static const Bool_tfgPRINT_SEQdebug flags. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodMLP(",MatchSource.WIKI,root/html532/TMVA__MethodMLP.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodMLP.html
https://root.cern/root/html532/TMVA__MethodMLP.html:21517,Usability,clear,clear,21517,"seRegulatorzjh; TRandom3*TMVA::MethodANNBase::frgenrandom number generator for various uses. private:. TMVA::MethodMLP::EBPTrainingModefBPModebackprop learning mode (sequential or batch); Int_tfBatchSizebatch size, only matters if in batch learning mode; TStringfBpModeSbackprop learning mode option string (sequential or batch); boolfCalculateErrorscompute inverse hessian matrix at the end of the training; Double_tfDecayRatedecay rate for above learning rate; vector<std::pair<Float_t,Float_t> >*fDeviationsFromTargetsdeviation from the targets, event weight; Bool_tfEpochMoncreate and fill epoch-wise monitoring histograms (makes outputfile big!); Double_tfGA_SC_factorGA settings: SC_factor; Int_tfGA_SC_rateGA settings: SC_rate; Int_tfGA_SC_stepsGA settings: SC_steps; Int_tfGA_nstepsGA settings: number of steps; Int_tfGA_preCalcGA settings: number of pre-calc steps; Double_tfLastAlphaline search variable; Double_tfLearnRatelearning rate for synapse weight adjustments; Double_tfPriorzjh; vector<Double_t>fPriorDevzjh; Int_tfResetStepreset time (how often we clear hessian matrix); Float_tfSamplingEpochfraction of epochs where sampling is used; Float_tfSamplingFractionfraction of events which is sampled for training; Bool_tfSamplingTestingThe testing sample is sampled; Bool_tfSamplingTrainingThe training sample is sampled; Float_tfSamplingWeightchanging factor for event weights when sampling is turned on; Double_tfTauline search variable; Int_tfTestRatetest for overtraining performed at each #th epochs; TStringfTrainMethodStraining method option param; TMVA::MethodMLP::ETrainingMethodfTrainingMethodmethod of training, BP or GA; Int_tfUpdateLimitzjh; boolfUseRegulatorzjh; Float_tfWeightRangesuppress outliers for the estimator calculation; static const Bool_tfgPRINT_BATCHdebug flags; static const Int_tfgPRINT_ESTIMATOR_INCdebug flags; static const Bool_tfgPRINT_SEQdebug flags. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodMLP(",MatchSource.WIKI,root/html532/TMVA__MethodMLP.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodMLP.html
https://root.cern/root/html532/TMVA__MethodMLP.html:23286,Usability,learn,learning,23286,"gs. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodMLP(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption, TDirectory* theTargetDir = 0); standard constructor. MethodMLP(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = 0); constructor from a weight file. ~MethodMLP(); destructor; nothing to be done. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); MLP can handle classification with 2 classes and regression with one regression-target. void Init(); default initializations. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options:; TrainingMethod <string> Training method; available values are: BP Back-Propagation <default>; GA Genetic Algorithm (takes a LONG time). LearningRate <float> NN learning rate parameter; DecayRate <float> Decay rate for learning parameter; TestRate <int> Test for overtraining performed at each #th epochs. BPMode <string> Back-propagation learning mode; available values are: sequential <default>; batch. BatchSize <int> Batch size: number of events/batch, only set if in Batch Mode,; -1 for BatchSize=number_of_events. void ProcessOptions(); process user options. void InitializeLearningRates(); initialize learning rates of synapses, used only by backpropagation. Double_t CalculateEstimator(TMVA::Types::ETreeType treeType = Types::kTraining, Int_t iEpoch = -1); calculate the estimator that training is attempting to minimize. void Train(Int_t nEpochs). void BFGSMinimize(Int_t nEpochs); train network with BFGS algorithm. void SetGammaDelta(TMatrixD& Gamma, TMatrixD& Delta, vector<Double_t>& Buffer). void ComputeDEDw(). void SimulateEvent(const TMVA::Event* ev). void SteepestDir(TMatrixD& Dir). Bool_t GetHessian(TMatrixD& Hessian, TMatrixD& Gamma, TMatrixD& Delta). void SetDir(TMatrixD& Hessian, TMatrixD& Dir).",MatchSource.WIKI,root/html532/TMVA__MethodMLP.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodMLP.html
https://root.cern/root/html532/TMVA__MethodMLP.html:23344,Usability,learn,learning,23344,"gs. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodMLP(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption, TDirectory* theTargetDir = 0); standard constructor. MethodMLP(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = 0); constructor from a weight file. ~MethodMLP(); destructor; nothing to be done. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); MLP can handle classification with 2 classes and regression with one regression-target. void Init(); default initializations. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options:; TrainingMethod <string> Training method; available values are: BP Back-Propagation <default>; GA Genetic Algorithm (takes a LONG time). LearningRate <float> NN learning rate parameter; DecayRate <float> Decay rate for learning parameter; TestRate <int> Test for overtraining performed at each #th epochs. BPMode <string> Back-propagation learning mode; available values are: sequential <default>; batch. BatchSize <int> Batch size: number of events/batch, only set if in Batch Mode,; -1 for BatchSize=number_of_events. void ProcessOptions(); process user options. void InitializeLearningRates(); initialize learning rates of synapses, used only by backpropagation. Double_t CalculateEstimator(TMVA::Types::ETreeType treeType = Types::kTraining, Int_t iEpoch = -1); calculate the estimator that training is attempting to minimize. void Train(Int_t nEpochs). void BFGSMinimize(Int_t nEpochs); train network with BFGS algorithm. void SetGammaDelta(TMatrixD& Gamma, TMatrixD& Delta, vector<Double_t>& Buffer). void ComputeDEDw(). void SimulateEvent(const TMVA::Event* ev). void SteepestDir(TMatrixD& Dir). Bool_t GetHessian(TMatrixD& Hessian, TMatrixD& Gamma, TMatrixD& Delta). void SetDir(TMatrixD& Hessian, TMatrixD& Dir).",MatchSource.WIKI,root/html532/TMVA__MethodMLP.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodMLP.html
https://root.cern/root/html532/TMVA__MethodMLP.html:23464,Usability,learn,learning,23464," TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption, TDirectory* theTargetDir = 0); standard constructor. MethodMLP(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = 0); constructor from a weight file. ~MethodMLP(); destructor; nothing to be done. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); MLP can handle classification with 2 classes and regression with one regression-target. void Init(); default initializations. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options:; TrainingMethod <string> Training method; available values are: BP Back-Propagation <default>; GA Genetic Algorithm (takes a LONG time). LearningRate <float> NN learning rate parameter; DecayRate <float> Decay rate for learning parameter; TestRate <int> Test for overtraining performed at each #th epochs. BPMode <string> Back-propagation learning mode; available values are: sequential <default>; batch. BatchSize <int> Batch size: number of events/batch, only set if in Batch Mode,; -1 for BatchSize=number_of_events. void ProcessOptions(); process user options. void InitializeLearningRates(); initialize learning rates of synapses, used only by backpropagation. Double_t CalculateEstimator(TMVA::Types::ETreeType treeType = Types::kTraining, Int_t iEpoch = -1); calculate the estimator that training is attempting to minimize. void Train(Int_t nEpochs). void BFGSMinimize(Int_t nEpochs); train network with BFGS algorithm. void SetGammaDelta(TMatrixD& Gamma, TMatrixD& Delta, vector<Double_t>& Buffer). void ComputeDEDw(). void SimulateEvent(const TMVA::Event* ev). void SteepestDir(TMatrixD& Dir). Bool_t GetHessian(TMatrixD& Hessian, TMatrixD& Gamma, TMatrixD& Delta). void SetDir(TMatrixD& Hessian, TMatrixD& Dir). Double_t DerivDir(TMatrixD& Dir). Bool_t LineSearch(TMatrixD& Dir, vector<Double_t>& Buffer, Double_t* dError = 0). void SetDirWeight",MatchSource.WIKI,root/html532/TMVA__MethodMLP.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodMLP.html
https://root.cern/root/html532/TMVA__MethodMLP.html:23733,Usability,learn,learning,23733," ~MethodMLP(); destructor; nothing to be done. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); MLP can handle classification with 2 classes and regression with one regression-target. void Init(); default initializations. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options:; TrainingMethod <string> Training method; available values are: BP Back-Propagation <default>; GA Genetic Algorithm (takes a LONG time). LearningRate <float> NN learning rate parameter; DecayRate <float> Decay rate for learning parameter; TestRate <int> Test for overtraining performed at each #th epochs. BPMode <string> Back-propagation learning mode; available values are: sequential <default>; batch. BatchSize <int> Batch size: number of events/batch, only set if in Batch Mode,; -1 for BatchSize=number_of_events. void ProcessOptions(); process user options. void InitializeLearningRates(); initialize learning rates of synapses, used only by backpropagation. Double_t CalculateEstimator(TMVA::Types::ETreeType treeType = Types::kTraining, Int_t iEpoch = -1); calculate the estimator that training is attempting to minimize. void Train(Int_t nEpochs). void BFGSMinimize(Int_t nEpochs); train network with BFGS algorithm. void SetGammaDelta(TMatrixD& Gamma, TMatrixD& Delta, vector<Double_t>& Buffer). void ComputeDEDw(). void SimulateEvent(const TMVA::Event* ev). void SteepestDir(TMatrixD& Dir). Bool_t GetHessian(TMatrixD& Hessian, TMatrixD& Gamma, TMatrixD& Delta). void SetDir(TMatrixD& Hessian, TMatrixD& Dir). Double_t DerivDir(TMatrixD& Dir). Bool_t LineSearch(TMatrixD& Dir, vector<Double_t>& Buffer, Double_t* dError = 0). void SetDirWeights(vector<Double_t>& Origin, TMatrixD& Dir, Double_t alpha). Double_t GetError(). Double_t GetMSEErr(const TMVA::Event* ev, UInt_t index = 0). Double_t GetCEErr(const TMVA::Event* ev, UInt_t index = 0). void BackPropagationMinimize(Int_t nEpochs); minimize esti",MatchSource.WIKI,root/html532/TMVA__MethodMLP.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodMLP.html
https://root.cern/root/html532/TMVA__MethodMLP.html:25141,Usability,learn,learning,25141,"_t>& Buffer). void ComputeDEDw(). void SimulateEvent(const TMVA::Event* ev). void SteepestDir(TMatrixD& Dir). Bool_t GetHessian(TMatrixD& Hessian, TMatrixD& Gamma, TMatrixD& Delta). void SetDir(TMatrixD& Hessian, TMatrixD& Dir). Double_t DerivDir(TMatrixD& Dir). Bool_t LineSearch(TMatrixD& Dir, vector<Double_t>& Buffer, Double_t* dError = 0). void SetDirWeights(vector<Double_t>& Origin, TMatrixD& Dir, Double_t alpha). Double_t GetError(). Double_t GetMSEErr(const TMVA::Event* ev, UInt_t index = 0). Double_t GetCEErr(const TMVA::Event* ev, UInt_t index = 0). void BackPropagationMinimize(Int_t nEpochs); minimize estimator / train network with backpropagation algorithm. void TrainOneEpoch(); train network over a single epoch/cyle of events. void Shuffle(Int_t* index, Int_t n); Input:; index: the array to shuffle; n: the size of the array; Output:; index: the shuffled indexes; This method is used for sequential training. void DecaySynapseWeights(Bool_t lateEpoch); decay synapse weights; in last 10 epochs, lower learning rate even more to find a good minimum. void TrainOneEventFast(Int_t ievt, Float_t*& branchVar, Int_t& type); fast per-event training. void TrainOneEvent(Int_t ievt); train network over a single event; this uses the new event model. Double_t GetDesiredOutput(const TMVA::Event* ev); get the desired output of this event. void UpdateNetwork(Double_t desired, Double_t eventWeight = 1.0); update the network based on how closely; the output matched the desired output. void UpdateNetwork(vector<Float_t>& desired, Double_t eventWeight = 1.0); update the network based on how closely; the output matched the desired output. void CalculateNeuronDeltas(); have each neuron calculate its delta by backpropagation. void GeneticMinimize(); create genetics class similar to GeneticCut; give it vector of parameter ranges (parameters = weights); link fitness function of this class to ComputeEstimator; instantiate GA (see MethodCuts); run it; then this should exist for GA, Minu",MatchSource.WIKI,root/html532/TMVA__MethodMLP.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodMLP.html
https://root.cern/root/html532/TMVA__MethodPDEFoam.html:2842,Availability,error,error,2842,"t::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt, TMVA::Types",MatchSource.WIKI,root/html532/TMVA__MethodPDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDEFoam.html
https://root.cern/root/html532/TMVA__MethodPDEFoam.html:2926,Availability,error,error,2926,"t* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt, TMVA::Types::ETreeType type) const; const vector<TMVA::Event*>&TMVA::MethodBase::GetEventCollec",MatchSource.WIKI,root/html532/TMVA__MethodPDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDEFoam.html
https://root.cern/root/html532/TMVA__MethodPDEFoam.html:17911,Availability,error,error,17911,"d-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. Bool_tfCompresscompress foam output file; Bool_tfCutNminKeep for bw compatibility: Grabbing cell with maximal RMS to split next (TFoam default); TStringfDTLogicuse DT algorithm to split cells; TMVA::EDTSeparationfDTSeparationenum which specifies the separation to use for the DT logic; Float_tfDiscrErrCutcut on discrimant error; Int_tfEvPerBinMaximum events (equiv.) per bin in buid-up (1000); Bool_tfFillFoamWithOrigWeightsfill the foam with boost weights; vector<PDEFoam*>fFoamgrown PDEFoams; Float_tfFracFraction used for calc of Xmin, Xmax; TMVA::MethodPDEFoam::EKernelfKernelKernel for GetMvaValue(); TMVA::PDEFoamKernelBase*fKernelEstimatorKernel estimator; TStringfKernelStrKernel for GetMvaValue() (option string); UInt_tfMaxDepthmaximum depth of cell tree; Bool_tfMultiTargetRegressiondo regression on multible targets; UInt_tfNminminimal number of events in cell necessary to split cell""; Bool_tfPeekMaxBACKWARDS COMPATIBILITY: peek up cell with max. driver integral for split; Bool_tfSigBgSeparatedSeparate Sig and Bg, or not; TMVA::ETargetSelectionfTargetSelectionmethod of selecting the target (only mulit target regr.); TStringfTargetSelectionStrmethod of selecting th",MatchSource.WIKI,root/html532/TMVA__MethodPDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDEFoam.html
https://root.cern/root/html532/TMVA__MethodPDEFoam.html:21938,Availability,error,error,21938,"nMonoTargetRegression(); Training one (mono target regression) foam, whose cells contain; the average 0th target. The dimension of the foam = number of; non-targets (= number of variables). void TrainMultiTargetRegression(); Training one (multi target regression) foam, whose cells contain; the average event density. The dimension of the foam = number; of non-targets + number of targets. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); Return Mva-Value. In case of 'fSigBgSeparated==false' (one unifiend PDEFoam was; trained) the function returns the content of the cell, which; corresponds to the current TMVA::Event, i.e. D =; N_sig/(N_bg+N_sig). In case of 'fSigBgSeparated==true' (two separate PDEFoams were; trained) the function returns. D = Density_sig/(Density_sig+Density_bg). where 'Density_sig' is the content of the cell in the signal; PDEFoam (fFoam[0]) and 'Density_bg' is the content of the cell; in the background PDEFoam (fFoam[1]). In both cases the error on the discriminant is stored in 'err'. const std::vector<Float_t>& GetMulticlassValues(); Get the multiclass MVA response for the PDEFoam classifier. The; returned MVA values are normalized, i.e. their sum equals 1. const TMVA::Ranking* CreateRanking(); Compute ranking of input variables from the number of cuts made; in each PDEFoam dimension. The PDEFoam dimension (the variable); for which the most cuts were done is ranked highest. void GetNCuts(TMVA::PDEFoamCell* cell, vector<UInt_t>& nCuts); Fill in 'nCuts' the number of cuts made in every foam dimension,; starting at the root cell 'cell'. Parameters:. - cell - root cell to start the counting from. - nCuts - the number of cuts are saved in this vector. void SetXminXmax(TMVA::PDEFoam* ); Set Xmin, Xmax for every dimension in the given pdefoam object. TMVA::PDEFoam* InitFoam(TString , TMVA::EFoamType , UInt_t cls = 0); Create a new PDEFoam, set the PDEFoam options (nCells, nBin,; Xmin, Xmax, etc.) and initialize the PDEFoam by calling; pdef",MatchSource.WIKI,root/html532/TMVA__MethodPDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDEFoam.html
https://root.cern/root/html532/TMVA__MethodPDEFoam.html:1072,Deployability,integrat,integration,1072,"rarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodPDEFoam. class TMVA::MethodPDEFoam: public TMVA::MethodBase. MethodPDEFoam. The PDEFoam method is an extension of the PDERS method, which; divides the multi-dimensional phase space in a finite number of; hyper-rectangles (cells) of constant event density. This ""foam"" of; cells is filled with averaged probability-density information; sampled from a training event sample. For a given number of cells, the binning algorithm adjusts the size; and position of the cells inside the multidimensional phase space; based on a binary-split algorithm, minimizing the variance of the; event density in the cell.; The binned event density information of the final foam is stored in; binary trees, allowing for a fast and memory-efficient; classification of events. The implementation of PDEFoam is based on the Monte-Carlo; integration package TFoam included in the analysis package ROOT. Function Members (Methods); public:. virtual~MethodPDEFoam(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidTMVA::MethodBase::CheckSetup(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) cons",MatchSource.WIKI,root/html532/TMVA__MethodPDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDEFoam.html
https://root.cern/root/html532/TMVA__MethodPDEFoam.html:976,Energy Efficiency,efficient,efficient,976,". TMVA::MethodPDEFoam. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodPDEFoam. class TMVA::MethodPDEFoam: public TMVA::MethodBase. MethodPDEFoam. The PDEFoam method is an extension of the PDERS method, which; divides the multi-dimensional phase space in a finite number of; hyper-rectangles (cells) of constant event density. This ""foam"" of; cells is filled with averaged probability-density information; sampled from a training event sample. For a given number of cells, the binning algorithm adjusts the size; and position of the cells inside the multidimensional phase space; based on a binary-split algorithm, minimizing the variance of the; event density in the cell.; The binned event density information of the final foam is stored in; binary trees, allowing for a fast and memory-efficient; classification of events. The implementation of PDEFoam is based on the Monte-Carlo; integration package TFoam included in the analysis package ROOT. Function Members (Methods); public:. virtual~MethodPDEFoam(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidTMVA::MethodBase::CheckSetup(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const ",MatchSource.WIKI,root/html532/TMVA__MethodPDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDEFoam.html
https://root.cern/root/html532/TMVA__MethodPDEFoam.html:1072,Integrability,integrat,integration,1072,"rarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodPDEFoam. class TMVA::MethodPDEFoam: public TMVA::MethodBase. MethodPDEFoam. The PDEFoam method is an extension of the PDERS method, which; divides the multi-dimensional phase space in a finite number of; hyper-rectangles (cells) of constant event density. This ""foam"" of; cells is filled with averaged probability-density information; sampled from a training event sample. For a given number of cells, the binning algorithm adjusts the size; and position of the cells inside the multidimensional phase space; based on a binary-split algorithm, minimizing the variance of the; event density in the cell.; The binned event density information of the final foam is stored in; binary trees, allowing for a fast and memory-efficient; classification of events. The implementation of PDEFoam is based on the Monte-Carlo; integration package TFoam included in the analysis package ROOT. Function Members (Methods); public:. virtual~MethodPDEFoam(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidTMVA::MethodBase::CheckSetup(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) cons",MatchSource.WIKI,root/html532/TMVA__MethodPDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDEFoam.html
https://root.cern/root/html532/TMVA__MethodPDEFoam.html:20234,Integrability,depend,depending,20234,"; Inherited Members; Includes; Libraries. Function documentation; MethodPDEFoam(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& dsi, const TString& theOption = ""PDEFoam"", TDirectory* theTargetDir = 0); init PDEFoam objects. MethodPDEFoam(TMVA::DataSetInfo& dsi, const TString& theWeightFile, TDirectory* theTargetDir = NULL); constructor from weight file. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); PDEFoam can handle classification with multiple classes and regression; with one or more regression-targets. void Init( void ); default initialization called by all constructors. void DeclareOptions(). Declare MethodPDEFoam options. void DeclareCompatibilityOptions(). void ProcessOptions(); process user options. ~MethodPDEFoam( void ); destructor. void CalcXminXmax(); Determine foam range [fXmin, fXmax] for all dimensions, such; that a fraction of 'fFrac' events lie outside the foam. void Train( void ); Train PDE-Foam depending on the set options. void TrainSeparatedClassification(); Creation of 2 separated foams: one for signal events, one for; backgound events. At the end the foam cells of fFoam[0] will; contain the average number of signal events and fFoam[1] will; contain the average number of background events. void TrainUnifiedClassification(); Create only one unified foam (fFoam[0]) whose cells contain the; average discriminator (N_sig)/(N_sig + N_bg). void TrainMultiClassification(); Create one unified foam (see TrainUnifiedClassification()) for; each class, where the cells of foam i (fFoam[i]) contain the; average fraction of events of class i, i.e. D = number events of class i / total number of events. void TrainMonoTargetRegression(); Training one (mono target regression) foam, whose cells contain; the average 0th target. The dimension of the foam = number of; non-targets (= number of variables). void TrainMultiTargetRegression(); Training one (multi target regression) foam, whose cell",MatchSource.WIKI,root/html532/TMVA__MethodPDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDEFoam.html
https://root.cern/root/html532/TMVA__MethodPDEFoam.html:23386,Integrability,depend,depends,23386,"s were done is ranked highest. void GetNCuts(TMVA::PDEFoamCell* cell, vector<UInt_t>& nCuts); Fill in 'nCuts' the number of cuts made in every foam dimension,; starting at the root cell 'cell'. Parameters:. - cell - root cell to start the counting from. - nCuts - the number of cuts are saved in this vector. void SetXminXmax(TMVA::PDEFoam* ); Set Xmin, Xmax for every dimension in the given pdefoam object. TMVA::PDEFoam* InitFoam(TString , TMVA::EFoamType , UInt_t cls = 0); Create a new PDEFoam, set the PDEFoam options (nCells, nBin,; Xmin, Xmax, etc.) and initialize the PDEFoam by calling; pdefoam->Initialize(). Parameters:. - foamcaption - name of PDEFoam object. - ft - type of PDEFoam; Candidates are:; - kSeparate - creates TMVA::PDEFoamEvent; - kDiscr - creates TMVA::PDEFoamDiscriminant; - kMonoTarget - creates TMVA::PDEFoamTarget; - kMultiTarget - creates TMVA::MultiTarget; - kMultiClass - creates TMVA::PDEFoamDiscriminant. If 'fDTSeparation != kFoam' then a TMVA::PDEFoamDecisionTree; is created (the separation type depends on fDTSeparation). - cls - marked event class (optional, default value = 0). const std::vector<Float_t>& GetRegressionValues(); Return regression values for both multi- and mono-target regression. TMVA::PDEFoamKernelBase* CreatePDEFoamKernel(); create a pdefoam kernel estimator, depending on the current; value of fKernel. void DeleteFoams(); Deletes all trained foams. void Reset(); reset MethodPDEFoam:; - delete all PDEFoams; - delete the kernel estimator. void PrintCoefficients( void ); {}. void AddWeightsXMLTo(void* parent) const; create XML output of PDEFoam method variables. void WriteFoamsToFile() const; Write PDEFoams to file. void ReadWeightsFromStream(istream& i); read options and internal parameters. void ReadWeightsFromXML(void* wghtnode); read PDEFoam variables from xml weight file. TMVA::PDEFoam* ReadClonedFoamFromFile(TFile* , const TString& ); Reads a foam with name 'foamname' from file, and returns a clone; of the foam. The given",MatchSource.WIKI,root/html532/TMVA__MethodPDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDEFoam.html
https://root.cern/root/html532/TMVA__MethodPDEFoam.html:23674,Integrability,depend,depending,23674,"ector. void SetXminXmax(TMVA::PDEFoam* ); Set Xmin, Xmax for every dimension in the given pdefoam object. TMVA::PDEFoam* InitFoam(TString , TMVA::EFoamType , UInt_t cls = 0); Create a new PDEFoam, set the PDEFoam options (nCells, nBin,; Xmin, Xmax, etc.) and initialize the PDEFoam by calling; pdefoam->Initialize(). Parameters:. - foamcaption - name of PDEFoam object. - ft - type of PDEFoam; Candidates are:; - kSeparate - creates TMVA::PDEFoamEvent; - kDiscr - creates TMVA::PDEFoamDiscriminant; - kMonoTarget - creates TMVA::PDEFoamTarget; - kMultiTarget - creates TMVA::MultiTarget; - kMultiClass - creates TMVA::PDEFoamDiscriminant. If 'fDTSeparation != kFoam' then a TMVA::PDEFoamDecisionTree; is created (the separation type depends on fDTSeparation). - cls - marked event class (optional, default value = 0). const std::vector<Float_t>& GetRegressionValues(); Return regression values for both multi- and mono-target regression. TMVA::PDEFoamKernelBase* CreatePDEFoamKernel(); create a pdefoam kernel estimator, depending on the current; value of fKernel. void DeleteFoams(); Deletes all trained foams. void Reset(); reset MethodPDEFoam:; - delete all PDEFoams; - delete the kernel estimator. void PrintCoefficients( void ); {}. void AddWeightsXMLTo(void* parent) const; create XML output of PDEFoam method variables. void WriteFoamsToFile() const; Write PDEFoams to file. void ReadWeightsFromStream(istream& i); read options and internal parameters. void ReadWeightsFromXML(void* wghtnode); read PDEFoam variables from xml weight file. TMVA::PDEFoam* ReadClonedFoamFromFile(TFile* , const TString& ); Reads a foam with name 'foamname' from file, and returns a clone; of the foam. The given ROOT file must be open. (The ROOT file; will not be closed in this function.). Parameters:. - file - an open ROOT file. - foamname - name of foam to load from the file. Returns:. If a foam with name 'foamname' exists in the file, then it is; read from the file, cloned and returned. If a foam with nam",MatchSource.WIKI,root/html532/TMVA__MethodPDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDEFoam.html
https://root.cern/root/html532/TMVA__MethodPDEFoam.html:25177,Integrability,message,message,25177,"efficients( void ); {}. void AddWeightsXMLTo(void* parent) const; create XML output of PDEFoam method variables. void WriteFoamsToFile() const; Write PDEFoams to file. void ReadWeightsFromStream(istream& i); read options and internal parameters. void ReadWeightsFromXML(void* wghtnode); read PDEFoam variables from xml weight file. TMVA::PDEFoam* ReadClonedFoamFromFile(TFile* , const TString& ); Reads a foam with name 'foamname' from file, and returns a clone; of the foam. The given ROOT file must be open. (The ROOT file; will not be closed in this function.). Parameters:. - file - an open ROOT file. - foamname - name of foam to load from the file. Returns:. If a foam with name 'foamname' exists in the file, then it is; read from the file, cloned and returned. If a foam with name; 'foamname' does not exist in the file or the clone operation; does not succeed, then NULL is returned. void ReadFoamsFromFile(); read foams from file. TMVA::ETargetSelection UIntToTargetSelection(UInt_t its); convert UInt_t to ETargetSelection (used for reading weight files). void FillVariableNamesToFoam() const; store the variable names in all foams. void MakeClassSpecific(ostream& , const TString& ) const; write PDEFoam-specific classifier response; NOT IMPLEMENTED YET!. void GetHelpMessage() const; provide help message. EKernel GetKernel( void ); helper functions to convert enum types to UInt_t and back. { return fKernel; }. UInt_t KernelToUInt(TMVA::MethodPDEFoam::EKernel ker) const; { return UInt_t(ker); }. EKernel UIntToKernel(UInt_t iker). UInt_t TargetSelectionToUInt(TMVA::ETargetSelection ts) const; { return UInt_t(ts); }. » Author: Tancredi Carli, Dominik Dannheim, Alexander Voigt » Copyright (c) 2008, 2010: *; » Last changed: root/tmva $Id: MethodPDEFoam.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__MethodPDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDEFoam.html
https://root.cern/root/html532/TMVA__MethodPDEFoam.html:16957,Modifiability,variab,variables,16957,"a Members; public:. enum EKernel { kNone; kGaus; kLinN; };; enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. Bool_tfCompresscompress foam output file; Bool_tfCutNminKeep for bw compatibility: Grabbing cell with maximal RMS to split next (TFoam default); TStringfDTLogicuse DT algorithm to split cells; TMVA::EDTSeparationfDTSeparationenum which specifies the separation to use for the DT logic; Float_tfDiscrErrCutcut on discrimant error; Int_tfEvPerBinMaximum events (equiv.) per bin in buid-up (1000); Bool_tfFillFoamWithOrigWeightsfill the foam with boost weights; vector<PDEFoam*>fFoamgrown PDEFoams; Float_tfFracFraction used for calc of Xmin, Xmax; TMVA::Me",MatchSource.WIKI,root/html532/TMVA__MethodPDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDEFoam.html
https://root.cern/root/html532/TMVA__MethodPDEFoam.html:17146,Modifiability,variab,variable,17146,"a Members; public:. enum EKernel { kNone; kGaus; kLinN; };; enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. Bool_tfCompresscompress foam output file; Bool_tfCutNminKeep for bw compatibility: Grabbing cell with maximal RMS to split next (TFoam default); TStringfDTLogicuse DT algorithm to split cells; TMVA::EDTSeparationfDTSeparationenum which specifies the separation to use for the DT logic; Float_tfDiscrErrCutcut on discrimant error; Int_tfEvPerBinMaximum events (equiv.) per bin in buid-up (1000); Bool_tfFillFoamWithOrigWeightsfill the foam with boost weights; vector<PDEFoam*>fFoamgrown PDEFoams; Float_tfFracFraction used for calc of Xmin, Xmax; TMVA::Me",MatchSource.WIKI,root/html532/TMVA__MethodPDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDEFoam.html
https://root.cern/root/html532/TMVA__MethodPDEFoam.html:21129,Modifiability,variab,variables,21129,"[fXmin, fXmax] for all dimensions, such; that a fraction of 'fFrac' events lie outside the foam. void Train( void ); Train PDE-Foam depending on the set options. void TrainSeparatedClassification(); Creation of 2 separated foams: one for signal events, one for; backgound events. At the end the foam cells of fFoam[0] will; contain the average number of signal events and fFoam[1] will; contain the average number of background events. void TrainUnifiedClassification(); Create only one unified foam (fFoam[0]) whose cells contain the; average discriminator (N_sig)/(N_sig + N_bg). void TrainMultiClassification(); Create one unified foam (see TrainUnifiedClassification()) for; each class, where the cells of foam i (fFoam[i]) contain the; average fraction of events of class i, i.e. D = number events of class i / total number of events. void TrainMonoTargetRegression(); Training one (mono target regression) foam, whose cells contain; the average 0th target. The dimension of the foam = number of; non-targets (= number of variables). void TrainMultiTargetRegression(); Training one (multi target regression) foam, whose cells contain; the average event density. The dimension of the foam = number; of non-targets + number of targets. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); Return Mva-Value. In case of 'fSigBgSeparated==false' (one unifiend PDEFoam was; trained) the function returns the content of the cell, which; corresponds to the current TMVA::Event, i.e. D =; N_sig/(N_bg+N_sig). In case of 'fSigBgSeparated==true' (two separate PDEFoams were; trained) the function returns. D = Density_sig/(Density_sig+Density_bg). where 'Density_sig' is the content of the cell in the signal; PDEFoam (fFoam[0]) and 'Density_bg' is the content of the cell; in the background PDEFoam (fFoam[1]). In both cases the error on the discriminant is stored in 'err'. const std::vector<Float_t>& GetMulticlassValues(); Get the multiclass MVA response for the PDEFoam classifier. The; re",MatchSource.WIKI,root/html532/TMVA__MethodPDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDEFoam.html
https://root.cern/root/html532/TMVA__MethodPDEFoam.html:22224,Modifiability,variab,variables,22224,"e cells contain; the average event density. The dimension of the foam = number; of non-targets + number of targets. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); Return Mva-Value. In case of 'fSigBgSeparated==false' (one unifiend PDEFoam was; trained) the function returns the content of the cell, which; corresponds to the current TMVA::Event, i.e. D =; N_sig/(N_bg+N_sig). In case of 'fSigBgSeparated==true' (two separate PDEFoams were; trained) the function returns. D = Density_sig/(Density_sig+Density_bg). where 'Density_sig' is the content of the cell in the signal; PDEFoam (fFoam[0]) and 'Density_bg' is the content of the cell; in the background PDEFoam (fFoam[1]). In both cases the error on the discriminant is stored in 'err'. const std::vector<Float_t>& GetMulticlassValues(); Get the multiclass MVA response for the PDEFoam classifier. The; returned MVA values are normalized, i.e. their sum equals 1. const TMVA::Ranking* CreateRanking(); Compute ranking of input variables from the number of cuts made; in each PDEFoam dimension. The PDEFoam dimension (the variable); for which the most cuts were done is ranked highest. void GetNCuts(TMVA::PDEFoamCell* cell, vector<UInt_t>& nCuts); Fill in 'nCuts' the number of cuts made in every foam dimension,; starting at the root cell 'cell'. Parameters:. - cell - root cell to start the counting from. - nCuts - the number of cuts are saved in this vector. void SetXminXmax(TMVA::PDEFoam* ); Set Xmin, Xmax for every dimension in the given pdefoam object. TMVA::PDEFoam* InitFoam(TString , TMVA::EFoamType , UInt_t cls = 0); Create a new PDEFoam, set the PDEFoam options (nCells, nBin,; Xmin, Xmax, etc.) and initialize the PDEFoam by calling; pdefoam->Initialize(). Parameters:. - foamcaption - name of PDEFoam object. - ft - type of PDEFoam; Candidates are:; - kSeparate - creates TMVA::PDEFoamEvent; - kDiscr - creates TMVA::PDEFoamDiscriminant; - kMonoTarget - creates TMVA::PDEFoamTarget; - kMultiTarget - creates TMV",MatchSource.WIKI,root/html532/TMVA__MethodPDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDEFoam.html
https://root.cern/root/html532/TMVA__MethodPDEFoam.html:22318,Modifiability,variab,variable,22318,"gets. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); Return Mva-Value. In case of 'fSigBgSeparated==false' (one unifiend PDEFoam was; trained) the function returns the content of the cell, which; corresponds to the current TMVA::Event, i.e. D =; N_sig/(N_bg+N_sig). In case of 'fSigBgSeparated==true' (two separate PDEFoams were; trained) the function returns. D = Density_sig/(Density_sig+Density_bg). where 'Density_sig' is the content of the cell in the signal; PDEFoam (fFoam[0]) and 'Density_bg' is the content of the cell; in the background PDEFoam (fFoam[1]). In both cases the error on the discriminant is stored in 'err'. const std::vector<Float_t>& GetMulticlassValues(); Get the multiclass MVA response for the PDEFoam classifier. The; returned MVA values are normalized, i.e. their sum equals 1. const TMVA::Ranking* CreateRanking(); Compute ranking of input variables from the number of cuts made; in each PDEFoam dimension. The PDEFoam dimension (the variable); for which the most cuts were done is ranked highest. void GetNCuts(TMVA::PDEFoamCell* cell, vector<UInt_t>& nCuts); Fill in 'nCuts' the number of cuts made in every foam dimension,; starting at the root cell 'cell'. Parameters:. - cell - root cell to start the counting from. - nCuts - the number of cuts are saved in this vector. void SetXminXmax(TMVA::PDEFoam* ); Set Xmin, Xmax for every dimension in the given pdefoam object. TMVA::PDEFoam* InitFoam(TString , TMVA::EFoamType , UInt_t cls = 0); Create a new PDEFoam, set the PDEFoam options (nCells, nBin,; Xmin, Xmax, etc.) and initialize the PDEFoam by calling; pdefoam->Initialize(). Parameters:. - foamcaption - name of PDEFoam object. - ft - type of PDEFoam; Candidates are:; - kSeparate - creates TMVA::PDEFoamEvent; - kDiscr - creates TMVA::PDEFoamDiscriminant; - kMonoTarget - creates TMVA::PDEFoamTarget; - kMultiTarget - creates TMVA::MultiTarget; - kMultiClass - creates TMVA::PDEFoamDiscriminant. If 'fDTSeparation != kFoam' then a TMVA::PDE",MatchSource.WIKI,root/html532/TMVA__MethodPDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDEFoam.html
https://root.cern/root/html532/TMVA__MethodPDEFoam.html:23969,Modifiability,variab,variables,23969," by calling; pdefoam->Initialize(). Parameters:. - foamcaption - name of PDEFoam object. - ft - type of PDEFoam; Candidates are:; - kSeparate - creates TMVA::PDEFoamEvent; - kDiscr - creates TMVA::PDEFoamDiscriminant; - kMonoTarget - creates TMVA::PDEFoamTarget; - kMultiTarget - creates TMVA::MultiTarget; - kMultiClass - creates TMVA::PDEFoamDiscriminant. If 'fDTSeparation != kFoam' then a TMVA::PDEFoamDecisionTree; is created (the separation type depends on fDTSeparation). - cls - marked event class (optional, default value = 0). const std::vector<Float_t>& GetRegressionValues(); Return regression values for both multi- and mono-target regression. TMVA::PDEFoamKernelBase* CreatePDEFoamKernel(); create a pdefoam kernel estimator, depending on the current; value of fKernel. void DeleteFoams(); Deletes all trained foams. void Reset(); reset MethodPDEFoam:; - delete all PDEFoams; - delete the kernel estimator. void PrintCoefficients( void ); {}. void AddWeightsXMLTo(void* parent) const; create XML output of PDEFoam method variables. void WriteFoamsToFile() const; Write PDEFoams to file. void ReadWeightsFromStream(istream& i); read options and internal parameters. void ReadWeightsFromXML(void* wghtnode); read PDEFoam variables from xml weight file. TMVA::PDEFoam* ReadClonedFoamFromFile(TFile* , const TString& ); Reads a foam with name 'foamname' from file, and returns a clone; of the foam. The given ROOT file must be open. (The ROOT file; will not be closed in this function.). Parameters:. - file - an open ROOT file. - foamname - name of foam to load from the file. Returns:. If a foam with name 'foamname' exists in the file, then it is; read from the file, cloned and returned. If a foam with name; 'foamname' does not exist in the file or the clone operation; does not succeed, then NULL is returned. void ReadFoamsFromFile(); read foams from file. TMVA::ETargetSelection UIntToTargetSelection(UInt_t its); convert UInt_t to ETargetSelection (used for reading weight files). v",MatchSource.WIKI,root/html532/TMVA__MethodPDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDEFoam.html
https://root.cern/root/html532/TMVA__MethodPDEFoam.html:24167,Modifiability,variab,variables,24167,"MonoTarget - creates TMVA::PDEFoamTarget; - kMultiTarget - creates TMVA::MultiTarget; - kMultiClass - creates TMVA::PDEFoamDiscriminant. If 'fDTSeparation != kFoam' then a TMVA::PDEFoamDecisionTree; is created (the separation type depends on fDTSeparation). - cls - marked event class (optional, default value = 0). const std::vector<Float_t>& GetRegressionValues(); Return regression values for both multi- and mono-target regression. TMVA::PDEFoamKernelBase* CreatePDEFoamKernel(); create a pdefoam kernel estimator, depending on the current; value of fKernel. void DeleteFoams(); Deletes all trained foams. void Reset(); reset MethodPDEFoam:; - delete all PDEFoams; - delete the kernel estimator. void PrintCoefficients( void ); {}. void AddWeightsXMLTo(void* parent) const; create XML output of PDEFoam method variables. void WriteFoamsToFile() const; Write PDEFoams to file. void ReadWeightsFromStream(istream& i); read options and internal parameters. void ReadWeightsFromXML(void* wghtnode); read PDEFoam variables from xml weight file. TMVA::PDEFoam* ReadClonedFoamFromFile(TFile* , const TString& ); Reads a foam with name 'foamname' from file, and returns a clone; of the foam. The given ROOT file must be open. (The ROOT file; will not be closed in this function.). Parameters:. - file - an open ROOT file. - foamname - name of foam to load from the file. Returns:. If a foam with name 'foamname' exists in the file, then it is; read from the file, cloned and returned. If a foam with name; 'foamname' does not exist in the file or the clone operation; does not succeed, then NULL is returned. void ReadFoamsFromFile(); read foams from file. TMVA::ETargetSelection UIntToTargetSelection(UInt_t its); convert UInt_t to ETargetSelection (used for reading weight files). void FillVariableNamesToFoam() const; store the variable names in all foams. void MakeClassSpecific(ostream& , const TString& ) const; write PDEFoam-specific classifier response; NOT IMPLEMENTED YET!. void GetHelpMessage(",MatchSource.WIKI,root/html532/TMVA__MethodPDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDEFoam.html
https://root.cern/root/html532/TMVA__MethodPDEFoam.html:24982,Modifiability,variab,variable,24982,"efficients( void ); {}. void AddWeightsXMLTo(void* parent) const; create XML output of PDEFoam method variables. void WriteFoamsToFile() const; Write PDEFoams to file. void ReadWeightsFromStream(istream& i); read options and internal parameters. void ReadWeightsFromXML(void* wghtnode); read PDEFoam variables from xml weight file. TMVA::PDEFoam* ReadClonedFoamFromFile(TFile* , const TString& ); Reads a foam with name 'foamname' from file, and returns a clone; of the foam. The given ROOT file must be open. (The ROOT file; will not be closed in this function.). Parameters:. - file - an open ROOT file. - foamname - name of foam to load from the file. Returns:. If a foam with name 'foamname' exists in the file, then it is; read from the file, cloned and returned. If a foam with name; 'foamname' does not exist in the file or the clone operation; does not succeed, then NULL is returned. void ReadFoamsFromFile(); read foams from file. TMVA::ETargetSelection UIntToTargetSelection(UInt_t its); convert UInt_t to ETargetSelection (used for reading weight files). void FillVariableNamesToFoam() const; store the variable names in all foams. void MakeClassSpecific(ostream& , const TString& ) const; write PDEFoam-specific classifier response; NOT IMPLEMENTED YET!. void GetHelpMessage() const; provide help message. EKernel GetKernel( void ); helper functions to convert enum types to UInt_t and back. { return fKernel; }. UInt_t KernelToUInt(TMVA::MethodPDEFoam::EKernel ker) const; { return UInt_t(ker); }. EKernel UIntToKernel(UInt_t iker). UInt_t TargetSelectionToUInt(TMVA::ETargetSelection ts) const; { return UInt_t(ts); }. » Author: Tancredi Carli, Dominik Dannheim, Alexander Voigt » Copyright (c) 2008, 2010: *; » Last changed: root/tmva $Id: MethodPDEFoam.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__MethodPDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDEFoam.html
https://root.cern/root/html532/TMVA__MethodPDEFoam.html:12314,Performance,tune,tuneParameters,12314,"voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; UInt_tTargetSelectionToUInt(TMVA::ETargetSelection ts) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); voidTrainMonoTargetRegression(); voidTrainMultiClassification(); voidTrainMultiTargetRegression(); voidTrainSeparatedClassification(); voidTrainUnifiedClassification(); TMVA::MethodPDEFoam::EKern",MatchSource.WIKI,root/html532/TMVA__MethodPDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDEFoam.html
https://root.cern/root/html532/TMVA__MethodPDEFoam.html:24502,Performance,load,load,24502,">& GetRegressionValues(); Return regression values for both multi- and mono-target regression. TMVA::PDEFoamKernelBase* CreatePDEFoamKernel(); create a pdefoam kernel estimator, depending on the current; value of fKernel. void DeleteFoams(); Deletes all trained foams. void Reset(); reset MethodPDEFoam:; - delete all PDEFoams; - delete the kernel estimator. void PrintCoefficients( void ); {}. void AddWeightsXMLTo(void* parent) const; create XML output of PDEFoam method variables. void WriteFoamsToFile() const; Write PDEFoams to file. void ReadWeightsFromStream(istream& i); read options and internal parameters. void ReadWeightsFromXML(void* wghtnode); read PDEFoam variables from xml weight file. TMVA::PDEFoam* ReadClonedFoamFromFile(TFile* , const TString& ); Reads a foam with name 'foamname' from file, and returns a clone; of the foam. The given ROOT file must be open. (The ROOT file; will not be closed in this function.). Parameters:. - file - an open ROOT file. - foamname - name of foam to load from the file. Returns:. If a foam with name 'foamname' exists in the file, then it is; read from the file, cloned and returned. If a foam with name; 'foamname' does not exist in the file or the clone operation; does not succeed, then NULL is returned. void ReadFoamsFromFile(); read foams from file. TMVA::ETargetSelection UIntToTargetSelection(UInt_t its); convert UInt_t to ETargetSelection (used for reading weight files). void FillVariableNamesToFoam() const; store the variable names in all foams. void MakeClassSpecific(ostream& , const TString& ) const; write PDEFoam-specific classifier response; NOT IMPLEMENTED YET!. void GetHelpMessage() const; provide help message. EKernel GetKernel( void ); helper functions to convert enum types to UInt_t and back. { return fKernel; }. UInt_t KernelToUInt(TMVA::MethodPDEFoam::EKernel ker) const; { return UInt_t(ker); }. EKernel UIntToKernel(UInt_t iker). UInt_t TargetSelectionToUInt(TMVA::ETargetSelection ts) const; { return UInt_t(ts);",MatchSource.WIKI,root/html532/TMVA__MethodPDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDEFoam.html
https://root.cern/root/html532/TMVA__MethodPDEFoam.html:12116,Testability,test,testTime,12116,"am& out, Option_t* option = """"); virtual voidTMVA::MethodBase::SetAnalysisType(TMVA::Types::EAnalysisType type); voidTMVA::MethodBase::SetBaseDir(TDirectory* methodDir); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; UInt_tTargetSelectionToUInt(TMVA::ETargetSelection ts) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTMVA::MethodBase::TrainMeth",MatchSource.WIKI,root/html532/TMVA__MethodPDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDEFoam.html
https://root.cern/root/html532/TMVA__MethodPDEFoam.html:16647,Testability,test,testing,16647,"odBase::SetWeightFileName(TString); voidSetXminXmax(TMVA::PDEFoam*); voidTMVA::MethodBase::Statistics(TMVA::Types::ETreeType treeType, const TString& theVarName, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&); Bool_tTMVA::MethodBase::TxtWeightsOnly() const; Bool_tTMVA::MethodBase::Verbose() const; voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. virtual voidDeclareCompatibilityOptions(); virtual voidDeclareOptions(); virtual voidInit(); voidPrintCoefficients(); virtual voidProcessOptions(). Data Members; public:. enum EKernel { kNone; kGaus; kLinN; };; enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. Bool_tfCompresscompre",MatchSource.WIKI,root/html532/TMVA__MethodPDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDEFoam.html
https://root.cern/root/html532/TMVA__MethodPDEFoam.html:17867,Testability,log,logic,17867,"d-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. Bool_tfCompresscompress foam output file; Bool_tfCutNminKeep for bw compatibility: Grabbing cell with maximal RMS to split next (TFoam default); TStringfDTLogicuse DT algorithm to split cells; TMVA::EDTSeparationfDTSeparationenum which specifies the separation to use for the DT logic; Float_tfDiscrErrCutcut on discrimant error; Int_tfEvPerBinMaximum events (equiv.) per bin in buid-up (1000); Bool_tfFillFoamWithOrigWeightsfill the foam with boost weights; vector<PDEFoam*>fFoamgrown PDEFoams; Float_tfFracFraction used for calc of Xmin, Xmax; TMVA::MethodPDEFoam::EKernelfKernelKernel for GetMvaValue(); TMVA::PDEFoamKernelBase*fKernelEstimatorKernel estimator; TStringfKernelStrKernel for GetMvaValue() (option string); UInt_tfMaxDepthmaximum depth of cell tree; Bool_tfMultiTargetRegressiondo regression on multible targets; UInt_tfNminminimal number of events in cell necessary to split cell""; Bool_tfPeekMaxBACKWARDS COMPATIBILITY: peek up cell with max. driver integral for split; Bool_tfSigBgSeparatedSeparate Sig and Bg, or not; TMVA::ETargetSelectionfTargetSelectionmethod of selecting the target (only mulit target regr.); TStringfTargetSelectionStrmethod of selecting th",MatchSource.WIKI,root/html532/TMVA__MethodPDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDEFoam.html
https://root.cern/root/html532/TMVA__MethodPDERS.html:3522,Availability,error,error,3522,"har* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt, TMVA::Types",MatchSource.WIKI,root/html532/TMVA__MethodPDERS.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDERS.html
https://root.cern/root/html532/TMVA__MethodPDERS.html:3606,Availability,error,error,3606,"MVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt, TMVA::Types::ETreeType type) const; const vector<TMVA::Event*>&TMVA::MethodBase::GetEventCollec",MatchSource.WIKI,root/html532/TMVA__MethodPDERS.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDERS.html
https://root.cern/root/html532/TMVA__MethodPDERS.html:21285,Availability,avail,available,21285,"hisPDERSthis pointer (required by root finder); Int_tfkNNMaxmax number of events in kNN tree; Int_tfkNNMinmin number of events in kNN tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodPDERS(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption, TDirectory* theTargetDir = 0); standard constructor for the PDERS method. MethodPDERS(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL); construct MethodPDERS through from file. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); PDERS can handle classification with 2 classes and regression with one or more regression-targets. void Init( void ); default initialisation routine called by all constructors. ~MethodPDERS( void ); destructor. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options:; VolumeRangeMode <string> Method to determine volume range; available values are: MinMax; Unscaled; RMS; kNN; Adaptive <default>. KernelEstimator <string> Kernel estimation function; available values are: Box <default>; Sphere; Teepee; Gauss; Sinc3; Sinc5; Sinc7; Sinc9; Sinc11; Lanczos2; Lanczos3; Lanczos5; Lanczos8; Trim. DeltaFrac <float> Ratio of #EventsMin/#EventsMax for MinMax and RMS volume range; NEventsMin <int> Minimum number of events for adaptive volume range; NEventsMax <int> Maximum number of events for adaptive volume range; MaxVIterations <int> Maximum number of iterations for adaptive volume range; InitialScale <float> Initial scale for adaptive volume range; GaussSigma <float> Width with respect to the volume size of Gaussian kernel estimator. void ProcessOptions(); process the options specified by the user. void Train( void ); this is a dummy training: the preparation work to do is the construction; of the binary tree as a pointer chain. It is easier to directly save the; tra",MatchSource.WIKI,root/html532/TMVA__MethodPDERS.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDERS.html
https://root.cern/root/html532/TMVA__MethodPDERS.html:21408,Availability,avail,available,21408,"cumentation; MethodPDERS(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption, TDirectory* theTargetDir = 0); standard constructor for the PDERS method. MethodPDERS(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL); construct MethodPDERS through from file. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); PDERS can handle classification with 2 classes and regression with one or more regression-targets. void Init( void ); default initialisation routine called by all constructors. ~MethodPDERS( void ); destructor. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options:; VolumeRangeMode <string> Method to determine volume range; available values are: MinMax; Unscaled; RMS; kNN; Adaptive <default>. KernelEstimator <string> Kernel estimation function; available values are: Box <default>; Sphere; Teepee; Gauss; Sinc3; Sinc5; Sinc7; Sinc9; Sinc11; Lanczos2; Lanczos3; Lanczos5; Lanczos8; Trim. DeltaFrac <float> Ratio of #EventsMin/#EventsMax for MinMax and RMS volume range; NEventsMin <int> Minimum number of events for adaptive volume range; NEventsMax <int> Maximum number of events for adaptive volume range; MaxVIterations <int> Maximum number of iterations for adaptive volume range; InitialScale <float> Initial scale for adaptive volume range; GaussSigma <float> Width with respect to the volume size of Gaussian kernel estimator. void ProcessOptions(); process the options specified by the user. void Train( void ); this is a dummy training: the preparation work to do is the construction; of the binary tree as a pointer chain. It is easier to directly save the; trainingTree in the weight file, and to rebuild the binary tree in the; test phase from scratch. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); init the size of a volume element using a defined fraction o",MatchSource.WIKI,root/html532/TMVA__MethodPDERS.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDERS.html
https://root.cern/root/html532/TMVA__MethodPDERS.html:24415,Availability,error,error,24415,"ation factors so we can work with radius 1 hyperspheres. void RKernelEstimate(const TMVA::Event& , vector<const TMVA::BinarySearchTreeNode*,allocator<const TMVA::BinarySearchTreeNode*> >& , TMVA::Volume& , vector<Float_t>* pdfSum); normalization factors so we can work with radius 1 hyperspheres. Double_t ApplyKernelFunction(Double_t normalized_distance); from the normalized euclidean distance calculate the distance; for a certain kernel. Double_t KernelNormalization(Double_t pdf); Calculating the normalization factor only once (might need a reset at some point.; Can the method be restarted with different params?). Double_t GetNormalizedDistance(const TMVA::Event& base_event, const TMVA::BinarySearchTreeNode& sample_event, Double_t* dim_normalization); We use Euclidian metric here. Might not be best or most efficient. Double_t NormSinc(Double_t x); NormSinc. Double_t LanczosFilter(Int_t level, Double_t x); Lanczos Filter. Float_t GetError(Float_t countS, Float_t countB, Float_t sumW2S, Float_t sumW2B) const; statistical error estimate for RS estimator. void AddWeightsXMLTo(void* parent) const; write weights to xml file. void ReadWeightsFromXML(void* wghtnode). void ReadWeightsFromStream(istream& istr); read weight info from file. void WriteWeightsToStream(TFile& rf) const; write training sample (TTree) to file. void ReadWeightsFromStream(TFile& istr); read training sample from file. TMVA::MethodPDERS* ThisPDERS( void ); static pointer to this object. void UpdateThis( void ); update static this pointer. void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". BinarySearchTree* GetBinaryTree( void ); accessors. { return fBinaryTree; }. const Ranking* CreateRanking(); ranking of input variables. { return 0; }. » Author: Andreas Hoecker, Yair Mahalalel, Joerg Stelzer, Helge Voss, Kai Voss",MatchSource.WIKI,root/html532/TMVA__MethodPDERS.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDERS.html
https://root.cern/root/html532/TMVA__MethodPDERS.html:24879,Deployability,update,update,24879,"ble_t ApplyKernelFunction(Double_t normalized_distance); from the normalized euclidean distance calculate the distance; for a certain kernel. Double_t KernelNormalization(Double_t pdf); Calculating the normalization factor only once (might need a reset at some point.; Can the method be restarted with different params?). Double_t GetNormalizedDistance(const TMVA::Event& base_event, const TMVA::BinarySearchTreeNode& sample_event, Double_t* dim_normalization); We use Euclidian metric here. Might not be best or most efficient. Double_t NormSinc(Double_t x); NormSinc. Double_t LanczosFilter(Int_t level, Double_t x); Lanczos Filter. Float_t GetError(Float_t countS, Float_t countB, Float_t sumW2S, Float_t sumW2B) const; statistical error estimate for RS estimator. void AddWeightsXMLTo(void* parent) const; write weights to xml file. void ReadWeightsFromXML(void* wghtnode). void ReadWeightsFromStream(istream& istr); read weight info from file. void WriteWeightsToStream(TFile& rf) const; write training sample (TTree) to file. void ReadWeightsFromStream(TFile& istr); read training sample from file. TMVA::MethodPDERS* ThisPDERS( void ); static pointer to this object. void UpdateThis( void ); update static this pointer. void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". BinarySearchTree* GetBinaryTree( void ); accessors. { return fBinaryTree; }. const Ranking* CreateRanking(); ranking of input variables. { return 0; }. » Author: Andreas Hoecker, Yair Mahalalel, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: MethodPDERS.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__MethodPDERS.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDERS.html
https://root.cern/root/html532/TMVA__MethodPDERS.html:1135,Energy Efficiency,reduce,reduce,1135,"VC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodPDERS. class TMVA::MethodPDERS: public TMVA::MethodBase. /*; This is a generalization of the above Likelihood methods to Nvar; dimensions, where Nvar is the number of input variables; used in the MVA. If the multi-dimensional probability density functions; (PDFs) for signal and background were known, this method contains the entire; physical information, and is therefore optimal. Usually, kernel estimation; methods are used to approximate the PDFs using the events from the; training sample. ; A very simple probability density estimator (PDE) has been suggested; in hep-ex/0211019. The; PDE for a given test event is obtained from counting the (normalized); number of signal and background (training) events that occur in the; ""vicinity"" of the test event. The volume that describes ""vicinity"" is; user-defined. A search; method based on binary-trees is used to effectively reduce the; selection time for the range search. Three different volume definitions; are optional: . MinMax:; the volume is defined in each dimension with respect; to the full variable range found in the training sample. ; RMS:; the volume is defined in each dimensions with respect; to the RMS estimated from the training sample. ; Adaptive:; a volume element is defined in each dimensions with; respect to the RMS estimated from the training sample. The overall; scale of the volume element is then determined for each event so; that the total number of events confined in the volume be within; a user-defined range. The adaptive range search is used by default.; . Function Members (Methods); public:. virtual~MethodPDERS(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) cons",MatchSource.WIKI,root/html532/TMVA__MethodPDERS.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDERS.html
https://root.cern/root/html532/TMVA__MethodPDERS.html:1758,Energy Efficiency,adapt,adaptive,1758,"ity density estimator (PDE) has been suggested; in hep-ex/0211019. The; PDE for a given test event is obtained from counting the (normalized); number of signal and background (training) events that occur in the; ""vicinity"" of the test event. The volume that describes ""vicinity"" is; user-defined. A search; method based on binary-trees is used to effectively reduce the; selection time for the range search. Three different volume definitions; are optional: . MinMax:; the volume is defined in each dimension with respect; to the full variable range found in the training sample. ; RMS:; the volume is defined in each dimensions with respect; to the RMS estimated from the training sample. ; Adaptive:; a volume element is defined in each dimensions with; respect to the RMS estimated from the training sample. The overall; scale of the volume element is then determined for each event so; that the total number of events confined in the volume be within; a user-defined range. The adaptive range search is used by default.; . Function Members (Methods); public:. virtual~MethodPDERS(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidTMVA::MethodBase::CheckSetup(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; TMVA::DataSet*TMVA::MethodBase::Dat",MatchSource.WIKI,root/html532/TMVA__MethodPDERS.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDERS.html
https://root.cern/root/html532/TMVA__MethodPDERS.html:19313,Energy Efficiency,adapt,adaptive,19313,"histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. vector<Float_t>fAverageRMSaverage RMS of signal and background; TMVA::BinarySearchTree*fBinaryTreebinary tree; vector<Float_t>*fDeltasize of volume; Float_tfDeltaFracfraction of RMS; Double_tfGaussSigmasize of Gauss in adaptive volume ; Double_tfGaussSigmaNormsize of Gauss in adaptive volume (normalised to dimensions); Float_tfInitialScaleinitial scale for adaptive volume; Bool_tfInitializedVolumeEleis volume element initialized ?; TMVA::MethodPDERS::EKernelEstimatorfKernelEstimator; TStringfKernelStringoption kernel estimator; Float_tfMaxVIterationsmaximum number of iterations to adapt volume size; Double_tfMax_distancemaximum distance; Float_tfNEventsMaxmaximum number of events in adaptive volume; Float_tfNEventsMinminimum number of events in adaptive volume; Double_tfNRegOutnumber of output dimensions for regression; Bool_tfNormTreebinary-search tree is normalised; Bool_tfPrintedprint; Float_tfScaleBweight for background events; Float_tfScaleSweight for signal events; vector<Float_t>*fShiftvolume center; TMVA::MethodPDERS::EVolumeRangeModefVRangeMode; TStringfVolumeRangeoption volume range; static TMVA::MethodPDERS*fgThisPDERSthis pointer (required by root finder); Int_tfkNNMaxmax number of events in kNN tree; Int_tfkNNMinmin number of events in kNN tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodPDERS(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption, TDirectory* theTargetDir = 0); standard constructor for the PDERS method. MethodPDERS(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirect",MatchSource.WIKI,root/html532/TMVA__MethodPDERS.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDERS.html
https://root.cern/root/html532/TMVA__MethodPDERS.html:19371,Energy Efficiency,adapt,adaptive,19371,"histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. vector<Float_t>fAverageRMSaverage RMS of signal and background; TMVA::BinarySearchTree*fBinaryTreebinary tree; vector<Float_t>*fDeltasize of volume; Float_tfDeltaFracfraction of RMS; Double_tfGaussSigmasize of Gauss in adaptive volume ; Double_tfGaussSigmaNormsize of Gauss in adaptive volume (normalised to dimensions); Float_tfInitialScaleinitial scale for adaptive volume; Bool_tfInitializedVolumeEleis volume element initialized ?; TMVA::MethodPDERS::EKernelEstimatorfKernelEstimator; TStringfKernelStringoption kernel estimator; Float_tfMaxVIterationsmaximum number of iterations to adapt volume size; Double_tfMax_distancemaximum distance; Float_tfNEventsMaxmaximum number of events in adaptive volume; Float_tfNEventsMinminimum number of events in adaptive volume; Double_tfNRegOutnumber of output dimensions for regression; Bool_tfNormTreebinary-search tree is normalised; Bool_tfPrintedprint; Float_tfScaleBweight for background events; Float_tfScaleSweight for signal events; vector<Float_t>*fShiftvolume center; TMVA::MethodPDERS::EVolumeRangeModefVRangeMode; TStringfVolumeRangeoption volume range; static TMVA::MethodPDERS*fgThisPDERSthis pointer (required by root finder); Int_tfkNNMaxmax number of events in kNN tree; Int_tfkNNMinmin number of events in kNN tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodPDERS(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption, TDirectory* theTargetDir = 0); standard constructor for the PDERS method. MethodPDERS(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirect",MatchSource.WIKI,root/html532/TMVA__MethodPDERS.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDERS.html
https://root.cern/root/html532/TMVA__MethodPDERS.html:19453,Energy Efficiency,adapt,adaptive,19453,"histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. vector<Float_t>fAverageRMSaverage RMS of signal and background; TMVA::BinarySearchTree*fBinaryTreebinary tree; vector<Float_t>*fDeltasize of volume; Float_tfDeltaFracfraction of RMS; Double_tfGaussSigmasize of Gauss in adaptive volume ; Double_tfGaussSigmaNormsize of Gauss in adaptive volume (normalised to dimensions); Float_tfInitialScaleinitial scale for adaptive volume; Bool_tfInitializedVolumeEleis volume element initialized ?; TMVA::MethodPDERS::EKernelEstimatorfKernelEstimator; TStringfKernelStringoption kernel estimator; Float_tfMaxVIterationsmaximum number of iterations to adapt volume size; Double_tfMax_distancemaximum distance; Float_tfNEventsMaxmaximum number of events in adaptive volume; Float_tfNEventsMinminimum number of events in adaptive volume; Double_tfNRegOutnumber of output dimensions for regression; Bool_tfNormTreebinary-search tree is normalised; Bool_tfPrintedprint; Float_tfScaleBweight for background events; Float_tfScaleSweight for signal events; vector<Float_t>*fShiftvolume center; TMVA::MethodPDERS::EVolumeRangeModefVRangeMode; TStringfVolumeRangeoption volume range; static TMVA::MethodPDERS*fgThisPDERSthis pointer (required by root finder); Int_tfkNNMaxmax number of events in kNN tree; Int_tfkNNMinmin number of events in kNN tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodPDERS(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption, TDirectory* theTargetDir = 0); standard constructor for the PDERS method. MethodPDERS(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirect",MatchSource.WIKI,root/html532/TMVA__MethodPDERS.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDERS.html
https://root.cern/root/html532/TMVA__MethodPDERS.html:19682,Energy Efficiency,adapt,adapt,19682,"histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. vector<Float_t>fAverageRMSaverage RMS of signal and background; TMVA::BinarySearchTree*fBinaryTreebinary tree; vector<Float_t>*fDeltasize of volume; Float_tfDeltaFracfraction of RMS; Double_tfGaussSigmasize of Gauss in adaptive volume ; Double_tfGaussSigmaNormsize of Gauss in adaptive volume (normalised to dimensions); Float_tfInitialScaleinitial scale for adaptive volume; Bool_tfInitializedVolumeEleis volume element initialized ?; TMVA::MethodPDERS::EKernelEstimatorfKernelEstimator; TStringfKernelStringoption kernel estimator; Float_tfMaxVIterationsmaximum number of iterations to adapt volume size; Double_tfMax_distancemaximum distance; Float_tfNEventsMaxmaximum number of events in adaptive volume; Float_tfNEventsMinminimum number of events in adaptive volume; Double_tfNRegOutnumber of output dimensions for regression; Bool_tfNormTreebinary-search tree is normalised; Bool_tfPrintedprint; Float_tfScaleBweight for background events; Float_tfScaleSweight for signal events; vector<Float_t>*fShiftvolume center; TMVA::MethodPDERS::EVolumeRangeModefVRangeMode; TStringfVolumeRangeoption volume range; static TMVA::MethodPDERS*fgThisPDERSthis pointer (required by root finder); Int_tfkNNMaxmax number of events in kNN tree; Int_tfkNNMinmin number of events in kNN tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodPDERS(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption, TDirectory* theTargetDir = 0); standard constructor for the PDERS method. MethodPDERS(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirect",MatchSource.WIKI,root/html532/TMVA__MethodPDERS.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDERS.html
https://root.cern/root/html532/TMVA__MethodPDERS.html:19786,Energy Efficiency,adapt,adaptive,19786,"histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. vector<Float_t>fAverageRMSaverage RMS of signal and background; TMVA::BinarySearchTree*fBinaryTreebinary tree; vector<Float_t>*fDeltasize of volume; Float_tfDeltaFracfraction of RMS; Double_tfGaussSigmasize of Gauss in adaptive volume ; Double_tfGaussSigmaNormsize of Gauss in adaptive volume (normalised to dimensions); Float_tfInitialScaleinitial scale for adaptive volume; Bool_tfInitializedVolumeEleis volume element initialized ?; TMVA::MethodPDERS::EKernelEstimatorfKernelEstimator; TStringfKernelStringoption kernel estimator; Float_tfMaxVIterationsmaximum number of iterations to adapt volume size; Double_tfMax_distancemaximum distance; Float_tfNEventsMaxmaximum number of events in adaptive volume; Float_tfNEventsMinminimum number of events in adaptive volume; Double_tfNRegOutnumber of output dimensions for regression; Bool_tfNormTreebinary-search tree is normalised; Bool_tfPrintedprint; Float_tfScaleBweight for background events; Float_tfScaleSweight for signal events; vector<Float_t>*fShiftvolume center; TMVA::MethodPDERS::EVolumeRangeModefVRangeMode; TStringfVolumeRangeoption volume range; static TMVA::MethodPDERS*fgThisPDERSthis pointer (required by root finder); Int_tfkNNMaxmax number of events in kNN tree; Int_tfkNNMinmin number of events in kNN tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodPDERS(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption, TDirectory* theTargetDir = 0); standard constructor for the PDERS method. MethodPDERS(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirect",MatchSource.WIKI,root/html532/TMVA__MethodPDERS.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDERS.html
https://root.cern/root/html532/TMVA__MethodPDERS.html:19849,Energy Efficiency,adapt,adaptive,19849,"histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. vector<Float_t>fAverageRMSaverage RMS of signal and background; TMVA::BinarySearchTree*fBinaryTreebinary tree; vector<Float_t>*fDeltasize of volume; Float_tfDeltaFracfraction of RMS; Double_tfGaussSigmasize of Gauss in adaptive volume ; Double_tfGaussSigmaNormsize of Gauss in adaptive volume (normalised to dimensions); Float_tfInitialScaleinitial scale for adaptive volume; Bool_tfInitializedVolumeEleis volume element initialized ?; TMVA::MethodPDERS::EKernelEstimatorfKernelEstimator; TStringfKernelStringoption kernel estimator; Float_tfMaxVIterationsmaximum number of iterations to adapt volume size; Double_tfMax_distancemaximum distance; Float_tfNEventsMaxmaximum number of events in adaptive volume; Float_tfNEventsMinminimum number of events in adaptive volume; Double_tfNRegOutnumber of output dimensions for regression; Bool_tfNormTreebinary-search tree is normalised; Bool_tfPrintedprint; Float_tfScaleBweight for background events; Float_tfScaleSweight for signal events; vector<Float_t>*fShiftvolume center; TMVA::MethodPDERS::EVolumeRangeModefVRangeMode; TStringfVolumeRangeoption volume range; static TMVA::MethodPDERS*fgThisPDERSthis pointer (required by root finder); Int_tfkNNMaxmax number of events in kNN tree; Int_tfkNNMinmin number of events in kNN tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodPDERS(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption, TDirectory* theTargetDir = 0); standard constructor for the PDERS method. MethodPDERS(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirect",MatchSource.WIKI,root/html532/TMVA__MethodPDERS.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDERS.html
https://root.cern/root/html532/TMVA__MethodPDERS.html:21678,Energy Efficiency,adapt,adaptive,21678,"thodPDERS through from file. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); PDERS can handle classification with 2 classes and regression with one or more regression-targets. void Init( void ); default initialisation routine called by all constructors. ~MethodPDERS( void ); destructor. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options:; VolumeRangeMode <string> Method to determine volume range; available values are: MinMax; Unscaled; RMS; kNN; Adaptive <default>. KernelEstimator <string> Kernel estimation function; available values are: Box <default>; Sphere; Teepee; Gauss; Sinc3; Sinc5; Sinc7; Sinc9; Sinc11; Lanczos2; Lanczos3; Lanczos5; Lanczos8; Trim. DeltaFrac <float> Ratio of #EventsMin/#EventsMax for MinMax and RMS volume range; NEventsMin <int> Minimum number of events for adaptive volume range; NEventsMax <int> Maximum number of events for adaptive volume range; MaxVIterations <int> Maximum number of iterations for adaptive volume range; InitialScale <float> Initial scale for adaptive volume range; GaussSigma <float> Width with respect to the volume size of Gaussian kernel estimator. void ProcessOptions(); process the options specified by the user. void Train( void ); this is a dummy training: the preparation work to do is the construction; of the binary tree as a pointer chain. It is easier to directly save the; trainingTree in the weight file, and to rebuild the binary tree in the; test phase from scratch. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); init the size of a volume element using a defined fraction of the; volume containing the entire events. const std::vector< Float_t >& GetRegressionValues(). void CalcAverages(); compute also average RMS values required for adaptive Gaussian. void CreateBinarySearchTree(TMVA::Types::ETreeType type); create binary search trees for signal and background. void SetVolumeElement( voi",MatchSource.WIKI,root/html532/TMVA__MethodPDERS.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDERS.html
https://root.cern/root/html532/TMVA__MethodPDERS.html:21747,Energy Efficiency,adapt,adaptive,21747,"thodPDERS through from file. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); PDERS can handle classification with 2 classes and regression with one or more regression-targets. void Init( void ); default initialisation routine called by all constructors. ~MethodPDERS( void ); destructor. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options:; VolumeRangeMode <string> Method to determine volume range; available values are: MinMax; Unscaled; RMS; kNN; Adaptive <default>. KernelEstimator <string> Kernel estimation function; available values are: Box <default>; Sphere; Teepee; Gauss; Sinc3; Sinc5; Sinc7; Sinc9; Sinc11; Lanczos2; Lanczos3; Lanczos5; Lanczos8; Trim. DeltaFrac <float> Ratio of #EventsMin/#EventsMax for MinMax and RMS volume range; NEventsMin <int> Minimum number of events for adaptive volume range; NEventsMax <int> Maximum number of events for adaptive volume range; MaxVIterations <int> Maximum number of iterations for adaptive volume range; InitialScale <float> Initial scale for adaptive volume range; GaussSigma <float> Width with respect to the volume size of Gaussian kernel estimator. void ProcessOptions(); process the options specified by the user. void Train( void ); this is a dummy training: the preparation work to do is the construction; of the binary tree as a pointer chain. It is easier to directly save the; trainingTree in the weight file, and to rebuild the binary tree in the; test phase from scratch. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); init the size of a volume element using a defined fraction of the; volume containing the entire events. const std::vector< Float_t >& GetRegressionValues(). void CalcAverages(); compute also average RMS values required for adaptive Gaussian. void CreateBinarySearchTree(TMVA::Types::ETreeType type); create binary search trees for signal and background. void SetVolumeElement( voi",MatchSource.WIKI,root/html532/TMVA__MethodPDERS.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDERS.html
https://root.cern/root/html532/TMVA__MethodPDERS.html:21824,Energy Efficiency,adapt,adaptive,21824,"thodPDERS through from file. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); PDERS can handle classification with 2 classes and regression with one or more regression-targets. void Init( void ); default initialisation routine called by all constructors. ~MethodPDERS( void ); destructor. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options:; VolumeRangeMode <string> Method to determine volume range; available values are: MinMax; Unscaled; RMS; kNN; Adaptive <default>. KernelEstimator <string> Kernel estimation function; available values are: Box <default>; Sphere; Teepee; Gauss; Sinc3; Sinc5; Sinc7; Sinc9; Sinc11; Lanczos2; Lanczos3; Lanczos5; Lanczos8; Trim. DeltaFrac <float> Ratio of #EventsMin/#EventsMax for MinMax and RMS volume range; NEventsMin <int> Minimum number of events for adaptive volume range; NEventsMax <int> Maximum number of events for adaptive volume range; MaxVIterations <int> Maximum number of iterations for adaptive volume range; InitialScale <float> Initial scale for adaptive volume range; GaussSigma <float> Width with respect to the volume size of Gaussian kernel estimator. void ProcessOptions(); process the options specified by the user. void Train( void ); this is a dummy training: the preparation work to do is the construction; of the binary tree as a pointer chain. It is easier to directly save the; trainingTree in the weight file, and to rebuild the binary tree in the; test phase from scratch. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); init the size of a volume element using a defined fraction of the; volume containing the entire events. const std::vector< Float_t >& GetRegressionValues(). void CalcAverages(); compute also average RMS values required for adaptive Gaussian. void CreateBinarySearchTree(TMVA::Types::ETreeType type); create binary search trees for signal and background. void SetVolumeElement( voi",MatchSource.WIKI,root/html532/TMVA__MethodPDERS.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDERS.html
https://root.cern/root/html532/TMVA__MethodPDERS.html:21886,Energy Efficiency,adapt,adaptive,21886,"thodPDERS through from file. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); PDERS can handle classification with 2 classes and regression with one or more regression-targets. void Init( void ); default initialisation routine called by all constructors. ~MethodPDERS( void ); destructor. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options:; VolumeRangeMode <string> Method to determine volume range; available values are: MinMax; Unscaled; RMS; kNN; Adaptive <default>. KernelEstimator <string> Kernel estimation function; available values are: Box <default>; Sphere; Teepee; Gauss; Sinc3; Sinc5; Sinc7; Sinc9; Sinc11; Lanczos2; Lanczos3; Lanczos5; Lanczos8; Trim. DeltaFrac <float> Ratio of #EventsMin/#EventsMax for MinMax and RMS volume range; NEventsMin <int> Minimum number of events for adaptive volume range; NEventsMax <int> Maximum number of events for adaptive volume range; MaxVIterations <int> Maximum number of iterations for adaptive volume range; InitialScale <float> Initial scale for adaptive volume range; GaussSigma <float> Width with respect to the volume size of Gaussian kernel estimator. void ProcessOptions(); process the options specified by the user. void Train( void ); this is a dummy training: the preparation work to do is the construction; of the binary tree as a pointer chain. It is easier to directly save the; trainingTree in the weight file, and to rebuild the binary tree in the; test phase from scratch. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); init the size of a volume element using a defined fraction of the; volume containing the entire events. const std::vector< Float_t >& GetRegressionValues(). void CalcAverages(); compute also average RMS values required for adaptive Gaussian. void CreateBinarySearchTree(TMVA::Types::ETreeType type); create binary search trees for signal and background. void SetVolumeElement( voi",MatchSource.WIKI,root/html532/TMVA__MethodPDERS.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDERS.html
https://root.cern/root/html532/TMVA__MethodPDERS.html:22615,Energy Efficiency,adapt,adaptive,22615,"ventsMax for MinMax and RMS volume range; NEventsMin <int> Minimum number of events for adaptive volume range; NEventsMax <int> Maximum number of events for adaptive volume range; MaxVIterations <int> Maximum number of iterations for adaptive volume range; InitialScale <float> Initial scale for adaptive volume range; GaussSigma <float> Width with respect to the volume size of Gaussian kernel estimator. void ProcessOptions(); process the options specified by the user. void Train( void ); this is a dummy training: the preparation work to do is the construction; of the binary tree as a pointer chain. It is easier to directly save the; trainingTree in the weight file, and to rebuild the binary tree in the; test phase from scratch. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); init the size of a volume element using a defined fraction of the; volume containing the entire events. const std::vector< Float_t >& GetRegressionValues(). void CalcAverages(); compute also average RMS values required for adaptive Gaussian. void CreateBinarySearchTree(TMVA::Types::ETreeType type); create binary search trees for signal and background. void SetVolumeElement( void ); defines volume dimensions. Double_t IGetVolumeContentForRoot(Double_t ); Interface to RootFinder. Double_t GetVolumeContentForRoot(Double_t ); count number of events in rescaled volume. void GetSample(const TMVA::Event& e, vector<const TMVA::BinarySearchTreeNode*,allocator<const TMVA::BinarySearchTreeNode*> >& events, TMVA::Volume* volume). Double_t CRScalc(const TMVA::Event& ). void RRScalc(const TMVA::Event& , vector<Float_t>* count). Double_t CKernelEstimate(const TMVA::Event& , vector<const TMVA::BinarySearchTreeNode*,allocator<const TMVA::BinarySearchTreeNode*> >& , TMVA::Volume& ); normalization factors so we can work with radius 1 hyperspheres. void RKernelEstimate(const TMVA::Event& , vector<const TMVA::BinarySearchTreeNode*,allocator<const TMVA::BinarySearchTreeNode*> >& , TMVA::Volume& , vecto",MatchSource.WIKI,root/html532/TMVA__MethodPDERS.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDERS.html
https://root.cern/root/html532/TMVA__MethodPDERS.html:24198,Energy Efficiency,efficient,efficient,24198,"& , vector<Float_t>* count). Double_t CKernelEstimate(const TMVA::Event& , vector<const TMVA::BinarySearchTreeNode*,allocator<const TMVA::BinarySearchTreeNode*> >& , TMVA::Volume& ); normalization factors so we can work with radius 1 hyperspheres. void RKernelEstimate(const TMVA::Event& , vector<const TMVA::BinarySearchTreeNode*,allocator<const TMVA::BinarySearchTreeNode*> >& , TMVA::Volume& , vector<Float_t>* pdfSum); normalization factors so we can work with radius 1 hyperspheres. Double_t ApplyKernelFunction(Double_t normalized_distance); from the normalized euclidean distance calculate the distance; for a certain kernel. Double_t KernelNormalization(Double_t pdf); Calculating the normalization factor only once (might need a reset at some point.; Can the method be restarted with different params?). Double_t GetNormalizedDistance(const TMVA::Event& base_event, const TMVA::BinarySearchTreeNode& sample_event, Double_t* dim_normalization); We use Euclidian metric here. Might not be best or most efficient. Double_t NormSinc(Double_t x); NormSinc. Double_t LanczosFilter(Int_t level, Double_t x); Lanczos Filter. Float_t GetError(Float_t countS, Float_t countB, Float_t sumW2S, Float_t sumW2B) const; statistical error estimate for RS estimator. void AddWeightsXMLTo(void* parent) const; write weights to xml file. void ReadWeightsFromXML(void* wghtnode). void ReadWeightsFromStream(istream& istr); read weight info from file. void WriteWeightsToStream(TFile& rf) const; write training sample (TTree) to file. void ReadWeightsFromStream(TFile& istr); read training sample from file. TMVA::MethodPDERS* ThisPDERS( void ); static pointer to this object. void UpdateThis( void ); update static this pointer. void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". BinarySearchTree* GetBinaryTree( void )",MatchSource.WIKI,root/html532/TMVA__MethodPDERS.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDERS.html
https://root.cern/root/html532/TMVA__MethodPDERS.html:21043,Integrability,rout,routine,21043," Float_tfScaleSweight for signal events; vector<Float_t>*fShiftvolume center; TMVA::MethodPDERS::EVolumeRangeModefVRangeMode; TStringfVolumeRangeoption volume range; static TMVA::MethodPDERS*fgThisPDERSthis pointer (required by root finder); Int_tfkNNMaxmax number of events in kNN tree; Int_tfkNNMinmin number of events in kNN tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodPDERS(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption, TDirectory* theTargetDir = 0); standard constructor for the PDERS method. MethodPDERS(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL); construct MethodPDERS through from file. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); PDERS can handle classification with 2 classes and regression with one or more regression-targets. void Init( void ); default initialisation routine called by all constructors. ~MethodPDERS( void ); destructor. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options:; VolumeRangeMode <string> Method to determine volume range; available values are: MinMax; Unscaled; RMS; kNN; Adaptive <default>. KernelEstimator <string> Kernel estimation function; available values are: Box <default>; Sphere; Teepee; Gauss; Sinc3; Sinc5; Sinc7; Sinc9; Sinc11; Lanczos2; Lanczos3; Lanczos5; Lanczos8; Trim. DeltaFrac <float> Ratio of #EventsMin/#EventsMax for MinMax and RMS volume range; NEventsMin <int> Minimum number of events for adaptive volume range; NEventsMax <int> Maximum number of events for adaptive volume range; MaxVIterations <int> Maximum number of iterations for adaptive volume range; InitialScale <float> Initial scale for adaptive volume range; GaussSigma <float> Width with respect to the volume size of Gaussian kernel estimator. void ProcessOptions(); process the options ",MatchSource.WIKI,root/html532/TMVA__MethodPDERS.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDERS.html
https://root.cern/root/html532/TMVA__MethodPDERS.html:25039,Integrability,message,message,25039,"ble_t ApplyKernelFunction(Double_t normalized_distance); from the normalized euclidean distance calculate the distance; for a certain kernel. Double_t KernelNormalization(Double_t pdf); Calculating the normalization factor only once (might need a reset at some point.; Can the method be restarted with different params?). Double_t GetNormalizedDistance(const TMVA::Event& base_event, const TMVA::BinarySearchTreeNode& sample_event, Double_t* dim_normalization); We use Euclidian metric here. Might not be best or most efficient. Double_t NormSinc(Double_t x); NormSinc. Double_t LanczosFilter(Int_t level, Double_t x); Lanczos Filter. Float_t GetError(Float_t countS, Float_t countB, Float_t sumW2S, Float_t sumW2B) const; statistical error estimate for RS estimator. void AddWeightsXMLTo(void* parent) const; write weights to xml file. void ReadWeightsFromXML(void* wghtnode). void ReadWeightsFromStream(istream& istr); read weight info from file. void WriteWeightsToStream(TFile& rf) const; write training sample (TTree) to file. void ReadWeightsFromStream(TFile& istr); read training sample from file. TMVA::MethodPDERS* ThisPDERS( void ); static pointer to this object. void UpdateThis( void ); update static this pointer. void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". BinarySearchTree* GetBinaryTree( void ); accessors. { return fBinaryTree; }. const Ranking* CreateRanking(); ranking of input variables. { return 0; }. » Author: Andreas Hoecker, Yair Mahalalel, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: MethodPDERS.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__MethodPDERS.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDERS.html
https://root.cern/root/html532/TMVA__MethodPDERS.html:429,Modifiability,variab,variables,429,". TMVA::MethodPDERS. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodPDERS. class TMVA::MethodPDERS: public TMVA::MethodBase. /*; This is a generalization of the above Likelihood methods to Nvar; dimensions, where Nvar is the number of input variables; used in the MVA. If the multi-dimensional probability density functions; (PDFs) for signal and background were known, this method contains the entire; physical information, and is therefore optimal. Usually, kernel estimation; methods are used to approximate the PDFs using the events from the; training sample. ; A very simple probability density estimator (PDE) has been suggested; in hep-ex/0211019. The; PDE for a given test event is obtained from counting the (normalized); number of signal and background (training) events that occur in the; ""vicinity"" of the test event. The volume that describes ""vicinity"" is; user-defined. A search; method based on binary-trees is used to effectively reduce the; selection time for the range search. Three different volume definitions; are optional: . MinMax:; the volume is defined in each dimension with respect; to the full variable range found in the training sample. ; RMS:; the volume is defined in each dimensions with respect; to the RMS estimated from the training sample. ; Adaptive:; a volume element is defined in each dimensions with; respect to the RMS estimated from the training sample. The overall; scale of the volume element is then determined for each event so; that the total number of events confined in the volume be within; a user-defined range. The adaptive range search is used by default.; . Function Members (Methods); public:. virtual~MethodPDERS(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::",MatchSource.WIKI,root/html532/TMVA__MethodPDERS.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDERS.html
https://root.cern/root/html532/TMVA__MethodPDERS.html:1311,Modifiability,variab,variable,1311,"TMVA::MethodBase. /*; This is a generalization of the above Likelihood methods to Nvar; dimensions, where Nvar is the number of input variables; used in the MVA. If the multi-dimensional probability density functions; (PDFs) for signal and background were known, this method contains the entire; physical information, and is therefore optimal. Usually, kernel estimation; methods are used to approximate the PDFs using the events from the; training sample. ; A very simple probability density estimator (PDE) has been suggested; in hep-ex/0211019. The; PDE for a given test event is obtained from counting the (normalized); number of signal and background (training) events that occur in the; ""vicinity"" of the test event. The volume that describes ""vicinity"" is; user-defined. A search; method based on binary-trees is used to effectively reduce the; selection time for the range search. Three different volume definitions; are optional: . MinMax:; the volume is defined in each dimension with respect; to the full variable range found in the training sample. ; RMS:; the volume is defined in each dimensions with respect; to the RMS estimated from the training sample. ; Adaptive:; a volume element is defined in each dimensions with; respect to the RMS estimated from the training sample. The overall; scale of the volume element is then determined for each event so; that the total number of events confined in the volume be within; a user-defined range. The adaptive range search is used by default.; . Function Members (Methods); public:. virtual~MethodPDERS(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurabl",MatchSource.WIKI,root/html532/TMVA__MethodPDERS.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDERS.html
https://root.cern/root/html532/TMVA__MethodPDERS.html:1758,Modifiability,adapt,adaptive,1758,"ity density estimator (PDE) has been suggested; in hep-ex/0211019. The; PDE for a given test event is obtained from counting the (normalized); number of signal and background (training) events that occur in the; ""vicinity"" of the test event. The volume that describes ""vicinity"" is; user-defined. A search; method based on binary-trees is used to effectively reduce the; selection time for the range search. Three different volume definitions; are optional: . MinMax:; the volume is defined in each dimension with respect; to the full variable range found in the training sample. ; RMS:; the volume is defined in each dimensions with respect; to the RMS estimated from the training sample. ; Adaptive:; a volume element is defined in each dimensions with; respect to the RMS estimated from the training sample. The overall; scale of the volume element is then determined for each event so; that the total number of events confined in the volume be within; a user-defined range. The adaptive range search is used by default.; . Function Members (Methods); public:. virtual~MethodPDERS(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidTMVA::MethodBase::CheckSetup(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; TMVA::DataSet*TMVA::MethodBase::Dat",MatchSource.WIKI,root/html532/TMVA__MethodPDERS.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDERS.html
https://root.cern/root/html532/TMVA__MethodPDERS.html:18393,Modifiability,variab,variable,18393,"im; };; enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; Int_tfFcnCallnumber of external function calls (RootFinder); TMVA::Volume*fHelpVolumeauxiliary variable; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. vector<Float_t>fAverageRMSaverage RMS of signal and background; TMVA::BinarySearchTree*fBinaryTreebinary tree; vector<Float_t>*fDeltasize of volume; Float_tfDeltaFracfraction of RMS; Double_tfGaussSigmasize of Gauss in adaptive volume ; Double_tfGaussSigmaNormsize of Gauss in adaptive volume (normalised to dimensions); Float_tfInitialScaleinitial scale for adaptive volume; Bool_tfInitializedVolumeEleis volume element initialized ?; TMVA::MethodPDERS::EKernelEstimatorfKernelEstimator; TStringfKerne",MatchSource.WIKI,root/html532/TMVA__MethodPDERS.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDERS.html
https://root.cern/root/html532/TMVA__MethodPDERS.html:18463,Modifiability,variab,variables,18463,"im; };; enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; Int_tfFcnCallnumber of external function calls (RootFinder); TMVA::Volume*fHelpVolumeauxiliary variable; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. vector<Float_t>fAverageRMSaverage RMS of signal and background; TMVA::BinarySearchTree*fBinaryTreebinary tree; vector<Float_t>*fDeltasize of volume; Float_tfDeltaFracfraction of RMS; Double_tfGaussSigmasize of Gauss in adaptive volume ; Double_tfGaussSigmaNormsize of Gauss in adaptive volume (normalised to dimensions); Float_tfInitialScaleinitial scale for adaptive volume; Bool_tfInitializedVolumeEleis volume element initialized ?; TMVA::MethodPDERS::EKernelEstimatorfKernelEstimator; TStringfKerne",MatchSource.WIKI,root/html532/TMVA__MethodPDERS.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDERS.html
https://root.cern/root/html532/TMVA__MethodPDERS.html:18652,Modifiability,variab,variable,18652,"im; };; enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; Int_tfFcnCallnumber of external function calls (RootFinder); TMVA::Volume*fHelpVolumeauxiliary variable; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. vector<Float_t>fAverageRMSaverage RMS of signal and background; TMVA::BinarySearchTree*fBinaryTreebinary tree; vector<Float_t>*fDeltasize of volume; Float_tfDeltaFracfraction of RMS; Double_tfGaussSigmasize of Gauss in adaptive volume ; Double_tfGaussSigmaNormsize of Gauss in adaptive volume (normalised to dimensions); Float_tfInitialScaleinitial scale for adaptive volume; Bool_tfInitializedVolumeEleis volume element initialized ?; TMVA::MethodPDERS::EKernelEstimatorfKernelEstimator; TStringfKerne",MatchSource.WIKI,root/html532/TMVA__MethodPDERS.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDERS.html
https://root.cern/root/html532/TMVA__MethodPDERS.html:19313,Modifiability,adapt,adaptive,19313,"histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. vector<Float_t>fAverageRMSaverage RMS of signal and background; TMVA::BinarySearchTree*fBinaryTreebinary tree; vector<Float_t>*fDeltasize of volume; Float_tfDeltaFracfraction of RMS; Double_tfGaussSigmasize of Gauss in adaptive volume ; Double_tfGaussSigmaNormsize of Gauss in adaptive volume (normalised to dimensions); Float_tfInitialScaleinitial scale for adaptive volume; Bool_tfInitializedVolumeEleis volume element initialized ?; TMVA::MethodPDERS::EKernelEstimatorfKernelEstimator; TStringfKernelStringoption kernel estimator; Float_tfMaxVIterationsmaximum number of iterations to adapt volume size; Double_tfMax_distancemaximum distance; Float_tfNEventsMaxmaximum number of events in adaptive volume; Float_tfNEventsMinminimum number of events in adaptive volume; Double_tfNRegOutnumber of output dimensions for regression; Bool_tfNormTreebinary-search tree is normalised; Bool_tfPrintedprint; Float_tfScaleBweight for background events; Float_tfScaleSweight for signal events; vector<Float_t>*fShiftvolume center; TMVA::MethodPDERS::EVolumeRangeModefVRangeMode; TStringfVolumeRangeoption volume range; static TMVA::MethodPDERS*fgThisPDERSthis pointer (required by root finder); Int_tfkNNMaxmax number of events in kNN tree; Int_tfkNNMinmin number of events in kNN tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodPDERS(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption, TDirectory* theTargetDir = 0); standard constructor for the PDERS method. MethodPDERS(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirect",MatchSource.WIKI,root/html532/TMVA__MethodPDERS.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDERS.html
https://root.cern/root/html532/TMVA__MethodPDERS.html:19371,Modifiability,adapt,adaptive,19371,"histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. vector<Float_t>fAverageRMSaverage RMS of signal and background; TMVA::BinarySearchTree*fBinaryTreebinary tree; vector<Float_t>*fDeltasize of volume; Float_tfDeltaFracfraction of RMS; Double_tfGaussSigmasize of Gauss in adaptive volume ; Double_tfGaussSigmaNormsize of Gauss in adaptive volume (normalised to dimensions); Float_tfInitialScaleinitial scale for adaptive volume; Bool_tfInitializedVolumeEleis volume element initialized ?; TMVA::MethodPDERS::EKernelEstimatorfKernelEstimator; TStringfKernelStringoption kernel estimator; Float_tfMaxVIterationsmaximum number of iterations to adapt volume size; Double_tfMax_distancemaximum distance; Float_tfNEventsMaxmaximum number of events in adaptive volume; Float_tfNEventsMinminimum number of events in adaptive volume; Double_tfNRegOutnumber of output dimensions for regression; Bool_tfNormTreebinary-search tree is normalised; Bool_tfPrintedprint; Float_tfScaleBweight for background events; Float_tfScaleSweight for signal events; vector<Float_t>*fShiftvolume center; TMVA::MethodPDERS::EVolumeRangeModefVRangeMode; TStringfVolumeRangeoption volume range; static TMVA::MethodPDERS*fgThisPDERSthis pointer (required by root finder); Int_tfkNNMaxmax number of events in kNN tree; Int_tfkNNMinmin number of events in kNN tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodPDERS(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption, TDirectory* theTargetDir = 0); standard constructor for the PDERS method. MethodPDERS(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirect",MatchSource.WIKI,root/html532/TMVA__MethodPDERS.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDERS.html
https://root.cern/root/html532/TMVA__MethodPDERS.html:19453,Modifiability,adapt,adaptive,19453,"histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. vector<Float_t>fAverageRMSaverage RMS of signal and background; TMVA::BinarySearchTree*fBinaryTreebinary tree; vector<Float_t>*fDeltasize of volume; Float_tfDeltaFracfraction of RMS; Double_tfGaussSigmasize of Gauss in adaptive volume ; Double_tfGaussSigmaNormsize of Gauss in adaptive volume (normalised to dimensions); Float_tfInitialScaleinitial scale for adaptive volume; Bool_tfInitializedVolumeEleis volume element initialized ?; TMVA::MethodPDERS::EKernelEstimatorfKernelEstimator; TStringfKernelStringoption kernel estimator; Float_tfMaxVIterationsmaximum number of iterations to adapt volume size; Double_tfMax_distancemaximum distance; Float_tfNEventsMaxmaximum number of events in adaptive volume; Float_tfNEventsMinminimum number of events in adaptive volume; Double_tfNRegOutnumber of output dimensions for regression; Bool_tfNormTreebinary-search tree is normalised; Bool_tfPrintedprint; Float_tfScaleBweight for background events; Float_tfScaleSweight for signal events; vector<Float_t>*fShiftvolume center; TMVA::MethodPDERS::EVolumeRangeModefVRangeMode; TStringfVolumeRangeoption volume range; static TMVA::MethodPDERS*fgThisPDERSthis pointer (required by root finder); Int_tfkNNMaxmax number of events in kNN tree; Int_tfkNNMinmin number of events in kNN tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodPDERS(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption, TDirectory* theTargetDir = 0); standard constructor for the PDERS method. MethodPDERS(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirect",MatchSource.WIKI,root/html532/TMVA__MethodPDERS.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDERS.html
https://root.cern/root/html532/TMVA__MethodPDERS.html:19682,Modifiability,adapt,adapt,19682,"histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. vector<Float_t>fAverageRMSaverage RMS of signal and background; TMVA::BinarySearchTree*fBinaryTreebinary tree; vector<Float_t>*fDeltasize of volume; Float_tfDeltaFracfraction of RMS; Double_tfGaussSigmasize of Gauss in adaptive volume ; Double_tfGaussSigmaNormsize of Gauss in adaptive volume (normalised to dimensions); Float_tfInitialScaleinitial scale for adaptive volume; Bool_tfInitializedVolumeEleis volume element initialized ?; TMVA::MethodPDERS::EKernelEstimatorfKernelEstimator; TStringfKernelStringoption kernel estimator; Float_tfMaxVIterationsmaximum number of iterations to adapt volume size; Double_tfMax_distancemaximum distance; Float_tfNEventsMaxmaximum number of events in adaptive volume; Float_tfNEventsMinminimum number of events in adaptive volume; Double_tfNRegOutnumber of output dimensions for regression; Bool_tfNormTreebinary-search tree is normalised; Bool_tfPrintedprint; Float_tfScaleBweight for background events; Float_tfScaleSweight for signal events; vector<Float_t>*fShiftvolume center; TMVA::MethodPDERS::EVolumeRangeModefVRangeMode; TStringfVolumeRangeoption volume range; static TMVA::MethodPDERS*fgThisPDERSthis pointer (required by root finder); Int_tfkNNMaxmax number of events in kNN tree; Int_tfkNNMinmin number of events in kNN tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodPDERS(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption, TDirectory* theTargetDir = 0); standard constructor for the PDERS method. MethodPDERS(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirect",MatchSource.WIKI,root/html532/TMVA__MethodPDERS.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDERS.html
https://root.cern/root/html532/TMVA__MethodPDERS.html:19786,Modifiability,adapt,adaptive,19786,"histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. vector<Float_t>fAverageRMSaverage RMS of signal and background; TMVA::BinarySearchTree*fBinaryTreebinary tree; vector<Float_t>*fDeltasize of volume; Float_tfDeltaFracfraction of RMS; Double_tfGaussSigmasize of Gauss in adaptive volume ; Double_tfGaussSigmaNormsize of Gauss in adaptive volume (normalised to dimensions); Float_tfInitialScaleinitial scale for adaptive volume; Bool_tfInitializedVolumeEleis volume element initialized ?; TMVA::MethodPDERS::EKernelEstimatorfKernelEstimator; TStringfKernelStringoption kernel estimator; Float_tfMaxVIterationsmaximum number of iterations to adapt volume size; Double_tfMax_distancemaximum distance; Float_tfNEventsMaxmaximum number of events in adaptive volume; Float_tfNEventsMinminimum number of events in adaptive volume; Double_tfNRegOutnumber of output dimensions for regression; Bool_tfNormTreebinary-search tree is normalised; Bool_tfPrintedprint; Float_tfScaleBweight for background events; Float_tfScaleSweight for signal events; vector<Float_t>*fShiftvolume center; TMVA::MethodPDERS::EVolumeRangeModefVRangeMode; TStringfVolumeRangeoption volume range; static TMVA::MethodPDERS*fgThisPDERSthis pointer (required by root finder); Int_tfkNNMaxmax number of events in kNN tree; Int_tfkNNMinmin number of events in kNN tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodPDERS(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption, TDirectory* theTargetDir = 0); standard constructor for the PDERS method. MethodPDERS(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirect",MatchSource.WIKI,root/html532/TMVA__MethodPDERS.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDERS.html
https://root.cern/root/html532/TMVA__MethodPDERS.html:19849,Modifiability,adapt,adaptive,19849,"histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. vector<Float_t>fAverageRMSaverage RMS of signal and background; TMVA::BinarySearchTree*fBinaryTreebinary tree; vector<Float_t>*fDeltasize of volume; Float_tfDeltaFracfraction of RMS; Double_tfGaussSigmasize of Gauss in adaptive volume ; Double_tfGaussSigmaNormsize of Gauss in adaptive volume (normalised to dimensions); Float_tfInitialScaleinitial scale for adaptive volume; Bool_tfInitializedVolumeEleis volume element initialized ?; TMVA::MethodPDERS::EKernelEstimatorfKernelEstimator; TStringfKernelStringoption kernel estimator; Float_tfMaxVIterationsmaximum number of iterations to adapt volume size; Double_tfMax_distancemaximum distance; Float_tfNEventsMaxmaximum number of events in adaptive volume; Float_tfNEventsMinminimum number of events in adaptive volume; Double_tfNRegOutnumber of output dimensions for regression; Bool_tfNormTreebinary-search tree is normalised; Bool_tfPrintedprint; Float_tfScaleBweight for background events; Float_tfScaleSweight for signal events; vector<Float_t>*fShiftvolume center; TMVA::MethodPDERS::EVolumeRangeModefVRangeMode; TStringfVolumeRangeoption volume range; static TMVA::MethodPDERS*fgThisPDERSthis pointer (required by root finder); Int_tfkNNMaxmax number of events in kNN tree; Int_tfkNNMinmin number of events in kNN tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodPDERS(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption, TDirectory* theTargetDir = 0); standard constructor for the PDERS method. MethodPDERS(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirect",MatchSource.WIKI,root/html532/TMVA__MethodPDERS.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDERS.html
https://root.cern/root/html532/TMVA__MethodPDERS.html:21678,Modifiability,adapt,adaptive,21678,"thodPDERS through from file. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); PDERS can handle classification with 2 classes and regression with one or more regression-targets. void Init( void ); default initialisation routine called by all constructors. ~MethodPDERS( void ); destructor. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options:; VolumeRangeMode <string> Method to determine volume range; available values are: MinMax; Unscaled; RMS; kNN; Adaptive <default>. KernelEstimator <string> Kernel estimation function; available values are: Box <default>; Sphere; Teepee; Gauss; Sinc3; Sinc5; Sinc7; Sinc9; Sinc11; Lanczos2; Lanczos3; Lanczos5; Lanczos8; Trim. DeltaFrac <float> Ratio of #EventsMin/#EventsMax for MinMax and RMS volume range; NEventsMin <int> Minimum number of events for adaptive volume range; NEventsMax <int> Maximum number of events for adaptive volume range; MaxVIterations <int> Maximum number of iterations for adaptive volume range; InitialScale <float> Initial scale for adaptive volume range; GaussSigma <float> Width with respect to the volume size of Gaussian kernel estimator. void ProcessOptions(); process the options specified by the user. void Train( void ); this is a dummy training: the preparation work to do is the construction; of the binary tree as a pointer chain. It is easier to directly save the; trainingTree in the weight file, and to rebuild the binary tree in the; test phase from scratch. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); init the size of a volume element using a defined fraction of the; volume containing the entire events. const std::vector< Float_t >& GetRegressionValues(). void CalcAverages(); compute also average RMS values required for adaptive Gaussian. void CreateBinarySearchTree(TMVA::Types::ETreeType type); create binary search trees for signal and background. void SetVolumeElement( voi",MatchSource.WIKI,root/html532/TMVA__MethodPDERS.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDERS.html
https://root.cern/root/html532/TMVA__MethodPDERS.html:21747,Modifiability,adapt,adaptive,21747,"thodPDERS through from file. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); PDERS can handle classification with 2 classes and regression with one or more regression-targets. void Init( void ); default initialisation routine called by all constructors. ~MethodPDERS( void ); destructor. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options:; VolumeRangeMode <string> Method to determine volume range; available values are: MinMax; Unscaled; RMS; kNN; Adaptive <default>. KernelEstimator <string> Kernel estimation function; available values are: Box <default>; Sphere; Teepee; Gauss; Sinc3; Sinc5; Sinc7; Sinc9; Sinc11; Lanczos2; Lanczos3; Lanczos5; Lanczos8; Trim. DeltaFrac <float> Ratio of #EventsMin/#EventsMax for MinMax and RMS volume range; NEventsMin <int> Minimum number of events for adaptive volume range; NEventsMax <int> Maximum number of events for adaptive volume range; MaxVIterations <int> Maximum number of iterations for adaptive volume range; InitialScale <float> Initial scale for adaptive volume range; GaussSigma <float> Width with respect to the volume size of Gaussian kernel estimator. void ProcessOptions(); process the options specified by the user. void Train( void ); this is a dummy training: the preparation work to do is the construction; of the binary tree as a pointer chain. It is easier to directly save the; trainingTree in the weight file, and to rebuild the binary tree in the; test phase from scratch. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); init the size of a volume element using a defined fraction of the; volume containing the entire events. const std::vector< Float_t >& GetRegressionValues(). void CalcAverages(); compute also average RMS values required for adaptive Gaussian. void CreateBinarySearchTree(TMVA::Types::ETreeType type); create binary search trees for signal and background. void SetVolumeElement( voi",MatchSource.WIKI,root/html532/TMVA__MethodPDERS.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDERS.html
https://root.cern/root/html532/TMVA__MethodPDERS.html:21824,Modifiability,adapt,adaptive,21824,"thodPDERS through from file. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); PDERS can handle classification with 2 classes and regression with one or more regression-targets. void Init( void ); default initialisation routine called by all constructors. ~MethodPDERS( void ); destructor. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options:; VolumeRangeMode <string> Method to determine volume range; available values are: MinMax; Unscaled; RMS; kNN; Adaptive <default>. KernelEstimator <string> Kernel estimation function; available values are: Box <default>; Sphere; Teepee; Gauss; Sinc3; Sinc5; Sinc7; Sinc9; Sinc11; Lanczos2; Lanczos3; Lanczos5; Lanczos8; Trim. DeltaFrac <float> Ratio of #EventsMin/#EventsMax for MinMax and RMS volume range; NEventsMin <int> Minimum number of events for adaptive volume range; NEventsMax <int> Maximum number of events for adaptive volume range; MaxVIterations <int> Maximum number of iterations for adaptive volume range; InitialScale <float> Initial scale for adaptive volume range; GaussSigma <float> Width with respect to the volume size of Gaussian kernel estimator. void ProcessOptions(); process the options specified by the user. void Train( void ); this is a dummy training: the preparation work to do is the construction; of the binary tree as a pointer chain. It is easier to directly save the; trainingTree in the weight file, and to rebuild the binary tree in the; test phase from scratch. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); init the size of a volume element using a defined fraction of the; volume containing the entire events. const std::vector< Float_t >& GetRegressionValues(). void CalcAverages(); compute also average RMS values required for adaptive Gaussian. void CreateBinarySearchTree(TMVA::Types::ETreeType type); create binary search trees for signal and background. void SetVolumeElement( voi",MatchSource.WIKI,root/html532/TMVA__MethodPDERS.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDERS.html
https://root.cern/root/html532/TMVA__MethodPDERS.html:21886,Modifiability,adapt,adaptive,21886,"thodPDERS through from file. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); PDERS can handle classification with 2 classes and regression with one or more regression-targets. void Init( void ); default initialisation routine called by all constructors. ~MethodPDERS( void ); destructor. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options:; VolumeRangeMode <string> Method to determine volume range; available values are: MinMax; Unscaled; RMS; kNN; Adaptive <default>. KernelEstimator <string> Kernel estimation function; available values are: Box <default>; Sphere; Teepee; Gauss; Sinc3; Sinc5; Sinc7; Sinc9; Sinc11; Lanczos2; Lanczos3; Lanczos5; Lanczos8; Trim. DeltaFrac <float> Ratio of #EventsMin/#EventsMax for MinMax and RMS volume range; NEventsMin <int> Minimum number of events for adaptive volume range; NEventsMax <int> Maximum number of events for adaptive volume range; MaxVIterations <int> Maximum number of iterations for adaptive volume range; InitialScale <float> Initial scale for adaptive volume range; GaussSigma <float> Width with respect to the volume size of Gaussian kernel estimator. void ProcessOptions(); process the options specified by the user. void Train( void ); this is a dummy training: the preparation work to do is the construction; of the binary tree as a pointer chain. It is easier to directly save the; trainingTree in the weight file, and to rebuild the binary tree in the; test phase from scratch. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); init the size of a volume element using a defined fraction of the; volume containing the entire events. const std::vector< Float_t >& GetRegressionValues(). void CalcAverages(); compute also average RMS values required for adaptive Gaussian. void CreateBinarySearchTree(TMVA::Types::ETreeType type); create binary search trees for signal and background. void SetVolumeElement( voi",MatchSource.WIKI,root/html532/TMVA__MethodPDERS.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDERS.html
https://root.cern/root/html532/TMVA__MethodPDERS.html:22615,Modifiability,adapt,adaptive,22615,"ventsMax for MinMax and RMS volume range; NEventsMin <int> Minimum number of events for adaptive volume range; NEventsMax <int> Maximum number of events for adaptive volume range; MaxVIterations <int> Maximum number of iterations for adaptive volume range; InitialScale <float> Initial scale for adaptive volume range; GaussSigma <float> Width with respect to the volume size of Gaussian kernel estimator. void ProcessOptions(); process the options specified by the user. void Train( void ); this is a dummy training: the preparation work to do is the construction; of the binary tree as a pointer chain. It is easier to directly save the; trainingTree in the weight file, and to rebuild the binary tree in the; test phase from scratch. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); init the size of a volume element using a defined fraction of the; volume containing the entire events. const std::vector< Float_t >& GetRegressionValues(). void CalcAverages(); compute also average RMS values required for adaptive Gaussian. void CreateBinarySearchTree(TMVA::Types::ETreeType type); create binary search trees for signal and background. void SetVolumeElement( void ); defines volume dimensions. Double_t IGetVolumeContentForRoot(Double_t ); Interface to RootFinder. Double_t GetVolumeContentForRoot(Double_t ); count number of events in rescaled volume. void GetSample(const TMVA::Event& e, vector<const TMVA::BinarySearchTreeNode*,allocator<const TMVA::BinarySearchTreeNode*> >& events, TMVA::Volume* volume). Double_t CRScalc(const TMVA::Event& ). void RRScalc(const TMVA::Event& , vector<Float_t>* count). Double_t CKernelEstimate(const TMVA::Event& , vector<const TMVA::BinarySearchTreeNode*,allocator<const TMVA::BinarySearchTreeNode*> >& , TMVA::Volume& ); normalization factors so we can work with radius 1 hyperspheres. void RKernelEstimate(const TMVA::Event& , vector<const TMVA::BinarySearchTreeNode*,allocator<const TMVA::BinarySearchTreeNode*> >& , TMVA::Volume& , vecto",MatchSource.WIKI,root/html532/TMVA__MethodPDERS.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDERS.html
https://root.cern/root/html532/TMVA__MethodPDERS.html:25277,Modifiability,variab,variables,25277,"ble_t ApplyKernelFunction(Double_t normalized_distance); from the normalized euclidean distance calculate the distance; for a certain kernel. Double_t KernelNormalization(Double_t pdf); Calculating the normalization factor only once (might need a reset at some point.; Can the method be restarted with different params?). Double_t GetNormalizedDistance(const TMVA::Event& base_event, const TMVA::BinarySearchTreeNode& sample_event, Double_t* dim_normalization); We use Euclidian metric here. Might not be best or most efficient. Double_t NormSinc(Double_t x); NormSinc. Double_t LanczosFilter(Int_t level, Double_t x); Lanczos Filter. Float_t GetError(Float_t countS, Float_t countB, Float_t sumW2S, Float_t sumW2B) const; statistical error estimate for RS estimator. void AddWeightsXMLTo(void* parent) const; write weights to xml file. void ReadWeightsFromXML(void* wghtnode). void ReadWeightsFromStream(istream& istr); read weight info from file. void WriteWeightsToStream(TFile& rf) const; write training sample (TTree) to file. void ReadWeightsFromStream(TFile& istr); read training sample from file. TMVA::MethodPDERS* ThisPDERS( void ); static pointer to this object. void UpdateThis( void ); update static this pointer. void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". BinarySearchTree* GetBinaryTree( void ); accessors. { return fBinaryTree; }. const Ranking* CreateRanking(); ranking of input variables. { return 0; }. » Author: Andreas Hoecker, Yair Mahalalel, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: MethodPDERS.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__MethodPDERS.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDERS.html
https://root.cern/root/html532/TMVA__MethodPDERS.html:12913,Performance,tune,tuneParameters,12913,"voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); static TMVA::MethodPDERS*ThisPDERS(); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTO",MatchSource.WIKI,root/html532/TMVA__MethodPDERS.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDERS.html
https://root.cern/root/html532/TMVA__MethodPDERS.html:25192,Security,access,accessors,25192,"ble_t ApplyKernelFunction(Double_t normalized_distance); from the normalized euclidean distance calculate the distance; for a certain kernel. Double_t KernelNormalization(Double_t pdf); Calculating the normalization factor only once (might need a reset at some point.; Can the method be restarted with different params?). Double_t GetNormalizedDistance(const TMVA::Event& base_event, const TMVA::BinarySearchTreeNode& sample_event, Double_t* dim_normalization); We use Euclidian metric here. Might not be best or most efficient. Double_t NormSinc(Double_t x); NormSinc. Double_t LanczosFilter(Int_t level, Double_t x); Lanczos Filter. Float_t GetError(Float_t countS, Float_t countB, Float_t sumW2S, Float_t sumW2B) const; statistical error estimate for RS estimator. void AddWeightsXMLTo(void* parent) const; write weights to xml file. void ReadWeightsFromXML(void* wghtnode). void ReadWeightsFromStream(istream& istr); read weight info from file. void WriteWeightsToStream(TFile& rf) const; write training sample (TTree) to file. void ReadWeightsFromStream(TFile& istr); read training sample from file. TMVA::MethodPDERS* ThisPDERS( void ); static pointer to this object. void UpdateThis( void ); update static this pointer. void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". BinarySearchTree* GetBinaryTree( void ); accessors. { return fBinaryTree; }. const Ranking* CreateRanking(); ranking of input variables. { return 0; }. » Author: Andreas Hoecker, Yair Mahalalel, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: MethodPDERS.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__MethodPDERS.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDERS.html
https://root.cern/root/html532/TMVA__MethodPDERS.html:864,Testability,test,test,864,". TMVA::MethodPDERS. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodPDERS. class TMVA::MethodPDERS: public TMVA::MethodBase. /*; This is a generalization of the above Likelihood methods to Nvar; dimensions, where Nvar is the number of input variables; used in the MVA. If the multi-dimensional probability density functions; (PDFs) for signal and background were known, this method contains the entire; physical information, and is therefore optimal. Usually, kernel estimation; methods are used to approximate the PDFs using the events from the; training sample. ; A very simple probability density estimator (PDE) has been suggested; in hep-ex/0211019. The; PDE for a given test event is obtained from counting the (normalized); number of signal and background (training) events that occur in the; ""vicinity"" of the test event. The volume that describes ""vicinity"" is; user-defined. A search; method based on binary-trees is used to effectively reduce the; selection time for the range search. Three different volume definitions; are optional: . MinMax:; the volume is defined in each dimension with respect; to the full variable range found in the training sample. ; RMS:; the volume is defined in each dimensions with respect; to the RMS estimated from the training sample. ; Adaptive:; a volume element is defined in each dimensions with; respect to the RMS estimated from the training sample. The overall; scale of the volume element is then determined for each event so; that the total number of events confined in the volume be within; a user-defined range. The adaptive range search is used by default.; . Function Members (Methods); public:. virtual~MethodPDERS(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::",MatchSource.WIKI,root/html532/TMVA__MethodPDERS.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDERS.html
https://root.cern/root/html532/TMVA__MethodPDERS.html:1006,Testability,test,test,1006,". TMVA::MethodPDERS. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodPDERS. class TMVA::MethodPDERS: public TMVA::MethodBase. /*; This is a generalization of the above Likelihood methods to Nvar; dimensions, where Nvar is the number of input variables; used in the MVA. If the multi-dimensional probability density functions; (PDFs) for signal and background were known, this method contains the entire; physical information, and is therefore optimal. Usually, kernel estimation; methods are used to approximate the PDFs using the events from the; training sample. ; A very simple probability density estimator (PDE) has been suggested; in hep-ex/0211019. The; PDE for a given test event is obtained from counting the (normalized); number of signal and background (training) events that occur in the; ""vicinity"" of the test event. The volume that describes ""vicinity"" is; user-defined. A search; method based on binary-trees is used to effectively reduce the; selection time for the range search. Three different volume definitions; are optional: . MinMax:; the volume is defined in each dimension with respect; to the full variable range found in the training sample. ; RMS:; the volume is defined in each dimensions with respect; to the RMS estimated from the training sample. ; Adaptive:; a volume element is defined in each dimensions with; respect to the RMS estimated from the training sample. The overall; scale of the volume element is then determined for each event so; that the total number of events confined in the volume be within; a user-defined range. The adaptive range search is used by default.; . Function Members (Methods); public:. virtual~MethodPDERS(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::",MatchSource.WIKI,root/html532/TMVA__MethodPDERS.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDERS.html
https://root.cern/root/html532/TMVA__MethodPDERS.html:12715,Testability,test,testTime,12715,"am& out, Option_t* option = """"); virtual voidTMVA::MethodBase::SetAnalysisType(TMVA::Types::EAnalysisType type); voidTMVA::MethodBase::SetBaseDir(TDirectory* methodDir); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); static TMVA::MethodPDERS*ThisPDERS(); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObjec",MatchSource.WIKI,root/html532/TMVA__MethodPDERS.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDERS.html
https://root.cern/root/html532/TMVA__MethodPDERS.html:18048,Testability,test,testing,18048,"mW2S, Float_t sumW2B) const; voidGetSample(const TMVA::Event& e, vector<const TMVA::BinarySearchTreeNode*,allocator<const TMVA::BinarySearchTreeNode*> >& events, TMVA::Volume* volume); virtual voidInit(); virtual voidProcessOptions(); voidRRScalc(const TMVA::Event&, vector<Float_t>* count); voidSetVolumeElement(); voidUpdateThis(). Data Members; public:. enum EVolumeRangeMode { kUnsupported; kMinMax; kRMS; kAdaptive; kUnscaled; kkNN; };; enum EKernelEstimator { kBox; kSphere; kTeepee; kGauss; kSinc3; kSinc5; kSinc7; kSinc9; kSinc11; kLanczos2; kLanczos3; kLanczos5; kLanczos8; kTrim; };; enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; Int_tfFcnCallnumber of external function calls (RootFinder); TMVA::Volume*fHelpVolumeauxiliary variable; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the r",MatchSource.WIKI,root/html532/TMVA__MethodPDERS.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDERS.html
https://root.cern/root/html532/TMVA__MethodPDERS.html:22302,Testability,test,test,22302," determine volume range; available values are: MinMax; Unscaled; RMS; kNN; Adaptive <default>. KernelEstimator <string> Kernel estimation function; available values are: Box <default>; Sphere; Teepee; Gauss; Sinc3; Sinc5; Sinc7; Sinc9; Sinc11; Lanczos2; Lanczos3; Lanczos5; Lanczos8; Trim. DeltaFrac <float> Ratio of #EventsMin/#EventsMax for MinMax and RMS volume range; NEventsMin <int> Minimum number of events for adaptive volume range; NEventsMax <int> Maximum number of events for adaptive volume range; MaxVIterations <int> Maximum number of iterations for adaptive volume range; InitialScale <float> Initial scale for adaptive volume range; GaussSigma <float> Width with respect to the volume size of Gaussian kernel estimator. void ProcessOptions(); process the options specified by the user. void Train( void ); this is a dummy training: the preparation work to do is the construction; of the binary tree as a pointer chain. It is easier to directly save the; trainingTree in the weight file, and to rebuild the binary tree in the; test phase from scratch. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); init the size of a volume element using a defined fraction of the; volume containing the entire events. const std::vector< Float_t >& GetRegressionValues(). void CalcAverages(); compute also average RMS values required for adaptive Gaussian. void CreateBinarySearchTree(TMVA::Types::ETreeType type); create binary search trees for signal and background. void SetVolumeElement( void ); defines volume dimensions. Double_t IGetVolumeContentForRoot(Double_t ); Interface to RootFinder. Double_t GetVolumeContentForRoot(Double_t ); count number of events in rescaled volume. void GetSample(const TMVA::Event& e, vector<const TMVA::BinarySearchTreeNode*,allocator<const TMVA::BinarySearchTreeNode*> >& events, TMVA::Volume* volume). Double_t CRScalc(const TMVA::Event& ). void RRScalc(const TMVA::Event& , vector<Float_t>* count). Double_t CKernelEstimate(const TMVA::Event",MatchSource.WIKI,root/html532/TMVA__MethodPDERS.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDERS.html
https://root.cern/root/html532/TMVA__MethodPDERS.html:761,Usability,simpl,simple,761,". TMVA::MethodPDERS. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodPDERS. class TMVA::MethodPDERS: public TMVA::MethodBase. /*; This is a generalization of the above Likelihood methods to Nvar; dimensions, where Nvar is the number of input variables; used in the MVA. If the multi-dimensional probability density functions; (PDFs) for signal and background were known, this method contains the entire; physical information, and is therefore optimal. Usually, kernel estimation; methods are used to approximate the PDFs using the events from the; training sample. ; A very simple probability density estimator (PDE) has been suggested; in hep-ex/0211019. The; PDE for a given test event is obtained from counting the (normalized); number of signal and background (training) events that occur in the; ""vicinity"" of the test event. The volume that describes ""vicinity"" is; user-defined. A search; method based on binary-trees is used to effectively reduce the; selection time for the range search. Three different volume definitions; are optional: . MinMax:; the volume is defined in each dimension with respect; to the full variable range found in the training sample. ; RMS:; the volume is defined in each dimensions with respect; to the RMS estimated from the training sample. ; Adaptive:; a volume element is defined in each dimensions with; respect to the RMS estimated from the training sample. The overall; scale of the volume element is then determined for each event so; that the total number of events confined in the volume be within; a user-defined range. The adaptive range search is used by default.; . Function Members (Methods); public:. virtual~MethodPDERS(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::",MatchSource.WIKI,root/html532/TMVA__MethodPDERS.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodPDERS.html
https://root.cern/root/html532/TMVA__MethodRuleFit.html:2114,Availability,error,error,2114,"t::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt, TMVA::Types",MatchSource.WIKI,root/html532/TMVA__MethodRuleFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodRuleFit.html
https://root.cern/root/html532/TMVA__MethodRuleFit.html:2198,Availability,error,error,2198,"able(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt, TMVA::Types::ETreeType type) const; const vector<TMVA::Event*>&TMVA::MethodBase::GetEventCollec",MatchSource.WIKI,root/html532/TMVA__MethodRuleFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodRuleFit.html
https://root.cern/root/html532/TMVA__MethodRuleFit.html:20413,Availability,avail,available,20413,"fy initial s/b fraction in training data; Double_tfTreeEveFracfraction of events used for traing each tree; Bool_tfUseBoostuse boosted events for forest generation; Bool_tfUseRuleFitJFif true interface with J.Friedmans RuleFit module. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodRuleFit(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = """", TDirectory* theTargetDir = 0); standard constructor. MethodRuleFit(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL); constructor from weight file. ~MethodRuleFit( void ); destructor. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t ); RuleFit can handle classification with 2 classes. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options. general. RuleFitModule <string>; available values are: RFTMVA - use TMVA implementation; RFFriedman - use Friedmans original implementation. Path search (fitting). GDTau <float> gradient-directed path: fit threshhold, default; GDTauPrec <float> gradient-directed path: precision of estimated tau; GDStep <float> gradient-directed path: step size; GDNSteps <float> gradient-directed path: number of steps; GDErrScale <float> stop scan when error>scale*errmin. Tree generation. fEventsMin <float> minimum fraction of events in a splittable node; fEventsMax <float> maximum fraction of events in a splittable node; nTrees <float> number of trees in forest.; ForestType <string>; available values are: Random - create forest using random subsample and only random variables subset at each node; AdaBoost - create forest with boosted events. Model creation. RuleMinDist <float> min distance allowed between rules; MinImp <float> minimum rule importance accepted; Model <string> model to be used; available values are: ModRuleLinear <default>; ModRule; ModLinear. Friedmans module",MatchSource.WIKI,root/html532/TMVA__MethodRuleFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodRuleFit.html
https://root.cern/root/html532/TMVA__MethodRuleFit.html:20819,Availability,error,error,20819,"lass Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodRuleFit(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = """", TDirectory* theTargetDir = 0); standard constructor. MethodRuleFit(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL); constructor from weight file. ~MethodRuleFit( void ); destructor. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t ); RuleFit can handle classification with 2 classes. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options. general. RuleFitModule <string>; available values are: RFTMVA - use TMVA implementation; RFFriedman - use Friedmans original implementation. Path search (fitting). GDTau <float> gradient-directed path: fit threshhold, default; GDTauPrec <float> gradient-directed path: precision of estimated tau; GDStep <float> gradient-directed path: step size; GDNSteps <float> gradient-directed path: number of steps; GDErrScale <float> stop scan when error>scale*errmin. Tree generation. fEventsMin <float> minimum fraction of events in a splittable node; fEventsMax <float> maximum fraction of events in a splittable node; nTrees <float> number of trees in forest.; ForestType <string>; available values are: Random - create forest using random subsample and only random variables subset at each node; AdaBoost - create forest with boosted events. Model creation. RuleMinDist <float> min distance allowed between rules; MinImp <float> minimum rule importance accepted; Model <string> model to be used; available values are: ModRuleLinear <default>; ModRule; ModLinear. Friedmans module. RFWorkDir <string> directory where Friedmans module (rf_go.exe) is installed; RFNrules <int> maximum number of rules allowed; RFNendnodes <int> average number of end nodes in the forest of trees. void ProcessOptions(); process the opti",MatchSource.WIKI,root/html532/TMVA__MethodRuleFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodRuleFit.html
https://root.cern/root/html532/TMVA__MethodRuleFit.html:21056,Availability,avail,available,21056,"ctor. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t ); RuleFit can handle classification with 2 classes. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options. general. RuleFitModule <string>; available values are: RFTMVA - use TMVA implementation; RFFriedman - use Friedmans original implementation. Path search (fitting). GDTau <float> gradient-directed path: fit threshhold, default; GDTauPrec <float> gradient-directed path: precision of estimated tau; GDStep <float> gradient-directed path: step size; GDNSteps <float> gradient-directed path: number of steps; GDErrScale <float> stop scan when error>scale*errmin. Tree generation. fEventsMin <float> minimum fraction of events in a splittable node; fEventsMax <float> maximum fraction of events in a splittable node; nTrees <float> number of trees in forest.; ForestType <string>; available values are: Random - create forest using random subsample and only random variables subset at each node; AdaBoost - create forest with boosted events. Model creation. RuleMinDist <float> min distance allowed between rules; MinImp <float> minimum rule importance accepted; Model <string> model to be used; available values are: ModRuleLinear <default>; ModRule; ModLinear. Friedmans module. RFWorkDir <string> directory where Friedmans module (rf_go.exe) is installed; RFNrules <int> maximum number of rules allowed; RFNendnodes <int> average number of end nodes in the forest of trees. void ProcessOptions(); process the options specified by the user. void InitMonitorNtuple(); initialize the monitoring ntuple. void Init(); default initialization. void InitEventSample( void ); write all Events from the Tree into a vector of Events, that are; more easily manipulated.; This method should never be called without existing trainingTree, as it; the vector of events from the ROOT training tree. void Train( void ). void TrainTMVARuleFit( void ); training of ru",MatchSource.WIKI,root/html532/TMVA__MethodRuleFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodRuleFit.html
https://root.cern/root/html532/TMVA__MethodRuleFit.html:21371,Availability,avail,available,21371,"an be set in the option string; know options. general. RuleFitModule <string>; available values are: RFTMVA - use TMVA implementation; RFFriedman - use Friedmans original implementation. Path search (fitting). GDTau <float> gradient-directed path: fit threshhold, default; GDTauPrec <float> gradient-directed path: precision of estimated tau; GDStep <float> gradient-directed path: step size; GDNSteps <float> gradient-directed path: number of steps; GDErrScale <float> stop scan when error>scale*errmin. Tree generation. fEventsMin <float> minimum fraction of events in a splittable node; fEventsMax <float> maximum fraction of events in a splittable node; nTrees <float> number of trees in forest.; ForestType <string>; available values are: Random - create forest using random subsample and only random variables subset at each node; AdaBoost - create forest with boosted events. Model creation. RuleMinDist <float> min distance allowed between rules; MinImp <float> minimum rule importance accepted; Model <string> model to be used; available values are: ModRuleLinear <default>; ModRule; ModLinear. Friedmans module. RFWorkDir <string> directory where Friedmans module (rf_go.exe) is installed; RFNrules <int> maximum number of rules allowed; RFNendnodes <int> average number of end nodes in the forest of trees. void ProcessOptions(); process the options specified by the user. void InitMonitorNtuple(); initialize the monitoring ntuple. void Init(); default initialization. void InitEventSample( void ); write all Events from the Tree into a vector of Events, that are; more easily manipulated.; This method should never be called without existing trainingTree, as it; the vector of events from the ROOT training tree. void Train( void ). void TrainTMVARuleFit( void ); training of rules using TMVA implementation. void TrainJFRuleFit( void ); training of rules using Jerome Friedmans implementation. const TMVA::Ranking* CreateRanking(); computes ranking of input variables. void AddWeightsXML",MatchSource.WIKI,root/html532/TMVA__MethodRuleFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodRuleFit.html
https://root.cern/root/html532/TMVA__MethodRuleFit.html:21523,Deployability,install,installed,21523,"it threshhold, default; GDTauPrec <float> gradient-directed path: precision of estimated tau; GDStep <float> gradient-directed path: step size; GDNSteps <float> gradient-directed path: number of steps; GDErrScale <float> stop scan when error>scale*errmin. Tree generation. fEventsMin <float> minimum fraction of events in a splittable node; fEventsMax <float> maximum fraction of events in a splittable node; nTrees <float> number of trees in forest.; ForestType <string>; available values are: Random - create forest using random subsample and only random variables subset at each node; AdaBoost - create forest with boosted events. Model creation. RuleMinDist <float> min distance allowed between rules; MinImp <float> minimum rule importance accepted; Model <string> model to be used; available values are: ModRuleLinear <default>; ModRule; ModLinear. Friedmans module. RFWorkDir <string> directory where Friedmans module (rf_go.exe) is installed; RFNrules <int> maximum number of rules allowed; RFNendnodes <int> average number of end nodes in the forest of trees. void ProcessOptions(); process the options specified by the user. void InitMonitorNtuple(); initialize the monitoring ntuple. void Init(); default initialization. void InitEventSample( void ); write all Events from the Tree into a vector of Events, that are; more easily manipulated.; This method should never be called without existing trainingTree, as it; the vector of events from the ROOT training tree. void Train( void ). void TrainTMVARuleFit( void ); training of rules using TMVA implementation. void TrainJFRuleFit( void ); training of rules using Jerome Friedmans implementation. const TMVA::Ranking* CreateRanking(); computes ranking of input variables. void AddWeightsXMLTo(void* parent) const; add the rules to XML node. void ReadWeightsFromStream(istream& istr); read rules from an istream. void ReadWeightsFromXML(void* wghtnode); read rules from XML node. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper ",MatchSource.WIKI,root/html532/TMVA__MethodRuleFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodRuleFit.html
https://root.cern/root/html532/TMVA__MethodRuleFit.html:18037,Energy Efficiency,monitor,monitor,18037,,MatchSource.WIKI,root/html532/TMVA__MethodRuleFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodRuleFit.html
https://root.cern/root/html532/TMVA__MethodRuleFit.html:21759,Energy Efficiency,monitor,monitoring,21759,"dient-directed path: number of steps; GDErrScale <float> stop scan when error>scale*errmin. Tree generation. fEventsMin <float> minimum fraction of events in a splittable node; fEventsMax <float> maximum fraction of events in a splittable node; nTrees <float> number of trees in forest.; ForestType <string>; available values are: Random - create forest using random subsample and only random variables subset at each node; AdaBoost - create forest with boosted events. Model creation. RuleMinDist <float> min distance allowed between rules; MinImp <float> minimum rule importance accepted; Model <string> model to be used; available values are: ModRuleLinear <default>; ModRule; ModLinear. Friedmans module. RFWorkDir <string> directory where Friedmans module (rf_go.exe) is installed; RFNrules <int> maximum number of rules allowed; RFNendnodes <int> average number of end nodes in the forest of trees. void ProcessOptions(); process the options specified by the user. void InitMonitorNtuple(); initialize the monitoring ntuple. void Init(); default initialization. void InitEventSample( void ); write all Events from the Tree into a vector of Events, that are; more easily manipulated.; This method should never be called without existing trainingTree, as it; the vector of events from the ROOT training tree. void Train( void ). void TrainTMVARuleFit( void ); training of rules using TMVA implementation. void TrainJFRuleFit( void ); training of rules using Jerome Friedmans implementation. const TMVA::Ranking* CreateRanking(); computes ranking of input variables. void AddWeightsXMLTo(void* parent) const; add the rules to XML node. void ReadWeightsFromStream(istream& istr); read rules from an istream. void ReadWeightsFromXML(void* wghtnode); read rules from XML node. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); returns MVA value for given event. void WriteMonitoringHistosToFile( void ); write special monitoring histograms to file (here ntuple). void MakeClassSpecific",MatchSource.WIKI,root/html532/TMVA__MethodRuleFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodRuleFit.html
https://root.cern/root/html532/TMVA__MethodRuleFit.html:22680,Energy Efficiency,monitor,monitoring,22680,"; process the options specified by the user. void InitMonitorNtuple(); initialize the monitoring ntuple. void Init(); default initialization. void InitEventSample( void ); write all Events from the Tree into a vector of Events, that are; more easily manipulated.; This method should never be called without existing trainingTree, as it; the vector of events from the ROOT training tree. void Train( void ). void TrainTMVARuleFit( void ); training of rules using TMVA implementation. void TrainJFRuleFit( void ); training of rules using Jerome Friedmans implementation. const TMVA::Ranking* CreateRanking(); computes ranking of input variables. void AddWeightsXMLTo(void* parent) const; add the rules to XML node. void ReadWeightsFromStream(istream& istr); read rules from an istream. void ReadWeightsFromXML(void* wghtnode); read rules from XML node. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); returns MVA value for given event. void WriteMonitoringHistosToFile( void ); write special monitoring histograms to file (here ntuple). void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. void MakeClassRuleCuts(ostream& ) const; print out the rule cuts. void MakeClassLinear(ostream& ) const; print out the linear terms. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". Bool_t UseBoost() const; { return fUseBoost; }. RuleFit* GetRuleFitPtr(); accessors. { return &fRuleFit; }. const RuleFit* GetRuleFitConstPtr() const; { return &fRuleFit; }. TDirectory* GetMethodBaseDir() const; { return BaseDir(); }. const std::vector<TMVA::Event*>& GetTrainingEvents() const; { return fEventSample; }. const std::vector<TMVA::DecisionTree*>& GetForest() const; { return fForest; }. Int_t GetNTrees() const; { return fNTrees; }. Double_t GetTreeEveFrac() const; { return fTreeEveFrac; }. const SeparationBase* GetSeparationBaseConst() const; { return fSe",MatchSource.WIKI,root/html532/TMVA__MethodRuleFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodRuleFit.html
https://root.cern/root/html532/TMVA__MethodRuleFit.html:19646,Integrability,interface,interface,19646,"ble_tfGDValidEveFracGD path: fraction of subsamples used for the fitting; Double_tfLinQuantilequantile cut to remove outliers - see RuleEnsemble; Double_tfMaxFracNEveditto max; Double_tfMinFracNEvemin fraction of number events; Double_tfMinimprule/linear: minimum importance; TStringfModelTypeSrule ensemble: which model (rule,linear or both); TTree*fMonitorNtuplepointer to monitor rule ntuple; Int_tfNCutsgrid used in cut applied in node splitting; Double_tfNTCoefficientntuple: rule coefficient; Double_tfNTImportancentuple: rule importance; Int_tfNTNcutsntuple: rule number of cuts; Int_tfNTNvarsntuple: rule number of vars; Double_tfNTPbbntuple: rule P(tag b, true b); Double_tfNTPbsntuple: rule P(tag b, true s); Double_tfNTPsbntuple: rule P(tag s, true b); Double_tfNTPssntuple: rule P(tag s, true s); Double_tfNTPtagntuple: rule P(tag); Double_tfNTSSBntuple: rule S/(S+B); Double_tfNTSupportntuple: rule support; Int_tfNTTypentuple: rule type (+1->signal, -1->bkg); Int_tfNTreesnumber of trees in forest; TMVA::DecisionTree::EPruneMethodfPruneMethodforest generation: method used for pruning - see DecisionTree ; TStringfPruneMethodSforest generation: prune method - see DecisionTree; Double_tfPruneStrengthforest generation: prune strength - see DecisionTree; Int_tfRFNendnodesmax number of rules (only Friedmans module); Int_tfRFNrulesmax number of rules (only Friedmans module); TStringfRFWorkDirworking directory from Friedmans module; TMVA::RuleFitfRuleFitRuleFit instance; TStringfRuleFitModuleSwhich rulefit module to use; Double_tfRuleMinDistrule min distance - see RuleEnsemble; TMVA::SeparationBase*fSepTypethe separation used in node splitting; TStringfSepTypeSforest generation: separation type - see DecisionTree; Double_tfSignalFractionscalefactor for bkg events to modify initial s/b fraction in training data; Double_tfTreeEveFracfraction of events used for traing each tree; Bool_tfUseBoostuse boosted events for forest generation; Bool_tfUseRuleFitJFif true interface with J.",MatchSource.WIKI,root/html532/TMVA__MethodRuleFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodRuleFit.html
https://root.cern/root/html532/TMVA__MethodRuleFit.html:22990,Integrability,message,message,22990,"ut existing trainingTree, as it; the vector of events from the ROOT training tree. void Train( void ). void TrainTMVARuleFit( void ); training of rules using TMVA implementation. void TrainJFRuleFit( void ); training of rules using Jerome Friedmans implementation. const TMVA::Ranking* CreateRanking(); computes ranking of input variables. void AddWeightsXMLTo(void* parent) const; add the rules to XML node. void ReadWeightsFromStream(istream& istr); read rules from an istream. void ReadWeightsFromXML(void* wghtnode); read rules from XML node. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); returns MVA value for given event. void WriteMonitoringHistosToFile( void ); write special monitoring histograms to file (here ntuple). void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. void MakeClassRuleCuts(ostream& ) const; print out the rule cuts. void MakeClassLinear(ostream& ) const; print out the linear terms. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". Bool_t UseBoost() const; { return fUseBoost; }. RuleFit* GetRuleFitPtr(); accessors. { return &fRuleFit; }. const RuleFit* GetRuleFitConstPtr() const; { return &fRuleFit; }. TDirectory* GetMethodBaseDir() const; { return BaseDir(); }. const std::vector<TMVA::Event*>& GetTrainingEvents() const; { return fEventSample; }. const std::vector<TMVA::DecisionTree*>& GetForest() const; { return fForest; }. Int_t GetNTrees() const; { return fNTrees; }. Double_t GetTreeEveFrac() const; { return fTreeEveFrac; }. const SeparationBase* GetSeparationBaseConst() const; { return fSepType; }. SeparationBase* GetSeparationBase() const; { return fSepType; }. TMVA::DecisionTree::EPruneMethod GetPruneMethod() const; { return fPruneMethod; }. Double_t GetPruneStrength() const; { return fPruneStrength; }. Double_t GetMinFracNEve() const; { return fMinFracNEve; }. Double_t GetMaxFracNEve",MatchSource.WIKI,root/html532/TMVA__MethodRuleFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodRuleFit.html
https://root.cern/root/html532/TMVA__MethodRuleFit.html:16342,Modifiability,variab,variables,16342,"ons(); virtual voidProcessOptions(). Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. vector<TMVA::Event*>fEventSamplethe complete training sample; vector<TMVA::DecisionTree*,allocator<TMVA::DecisionTree*> >fForestthe forest; TStringfForestTypeSforest generation: how the trees are generated; Double_tfGDErrScaleGD path: stop ; Int_tfGDNPathStepsGD path: number of steps; Double_tfGDPathEveFracGD path: fraction of subsamples used for the fitting; Double_tfGDPathStepGD path: step size in path; Double_tfGDTauGD path: def threshhold fraction [0..1]; Double_tfGDTauMaxGD path: max threshhold fraction [0..1]; Double_tfGDTauMinGD path: min th",MatchSource.WIKI,root/html532/TMVA__MethodRuleFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodRuleFit.html
https://root.cern/root/html532/TMVA__MethodRuleFit.html:16531,Modifiability,variab,variable,16531,"ons(); virtual voidProcessOptions(). Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. vector<TMVA::Event*>fEventSamplethe complete training sample; vector<TMVA::DecisionTree*,allocator<TMVA::DecisionTree*> >fForestthe forest; TStringfForestTypeSforest generation: how the trees are generated; Double_tfGDErrScaleGD path: stop ; Int_tfGDNPathStepsGD path: number of steps; Double_tfGDPathEveFracGD path: fraction of subsamples used for the fitting; Double_tfGDPathStepGD path: step size in path; Double_tfGDTauGD path: def threshhold fraction [0..1]; Double_tfGDTauMaxGD path: max threshhold fraction [0..1]; Double_tfGDTauMinGD path: min th",MatchSource.WIKI,root/html532/TMVA__MethodRuleFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodRuleFit.html
https://root.cern/root/html532/TMVA__MethodRuleFit.html:21140,Modifiability,variab,variables,21140,"ctor. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t ); RuleFit can handle classification with 2 classes. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options. general. RuleFitModule <string>; available values are: RFTMVA - use TMVA implementation; RFFriedman - use Friedmans original implementation. Path search (fitting). GDTau <float> gradient-directed path: fit threshhold, default; GDTauPrec <float> gradient-directed path: precision of estimated tau; GDStep <float> gradient-directed path: step size; GDNSteps <float> gradient-directed path: number of steps; GDErrScale <float> stop scan when error>scale*errmin. Tree generation. fEventsMin <float> minimum fraction of events in a splittable node; fEventsMax <float> maximum fraction of events in a splittable node; nTrees <float> number of trees in forest.; ForestType <string>; available values are: Random - create forest using random subsample and only random variables subset at each node; AdaBoost - create forest with boosted events. Model creation. RuleMinDist <float> min distance allowed between rules; MinImp <float> minimum rule importance accepted; Model <string> model to be used; available values are: ModRuleLinear <default>; ModRule; ModLinear. Friedmans module. RFWorkDir <string> directory where Friedmans module (rf_go.exe) is installed; RFNrules <int> maximum number of rules allowed; RFNendnodes <int> average number of end nodes in the forest of trees. void ProcessOptions(); process the options specified by the user. void InitMonitorNtuple(); initialize the monitoring ntuple. void Init(); default initialization. void InitEventSample( void ); write all Events from the Tree into a vector of Events, that are; more easily manipulated.; This method should never be called without existing trainingTree, as it; the vector of events from the ROOT training tree. void Train( void ). void TrainTMVARuleFit( void ); training of ru",MatchSource.WIKI,root/html532/TMVA__MethodRuleFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodRuleFit.html
https://root.cern/root/html532/TMVA__MethodRuleFit.html:22306,Modifiability,variab,variables,22306,"een rules; MinImp <float> minimum rule importance accepted; Model <string> model to be used; available values are: ModRuleLinear <default>; ModRule; ModLinear. Friedmans module. RFWorkDir <string> directory where Friedmans module (rf_go.exe) is installed; RFNrules <int> maximum number of rules allowed; RFNendnodes <int> average number of end nodes in the forest of trees. void ProcessOptions(); process the options specified by the user. void InitMonitorNtuple(); initialize the monitoring ntuple. void Init(); default initialization. void InitEventSample( void ); write all Events from the Tree into a vector of Events, that are; more easily manipulated.; This method should never be called without existing trainingTree, as it; the vector of events from the ROOT training tree. void Train( void ). void TrainTMVARuleFit( void ); training of rules using TMVA implementation. void TrainJFRuleFit( void ); training of rules using Jerome Friedmans implementation. const TMVA::Ranking* CreateRanking(); computes ranking of input variables. void AddWeightsXMLTo(void* parent) const; add the rules to XML node. void ReadWeightsFromStream(istream& istr); read rules from an istream. void ReadWeightsFromXML(void* wghtnode); read rules from XML node. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); returns MVA value for given event. void WriteMonitoringHistosToFile( void ); write special monitoring histograms to file (here ntuple). void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. void MakeClassRuleCuts(ostream& ) const; print out the rule cuts. void MakeClassLinear(ostream& ) const; print out the linear terms. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". Bool_t UseBoost() const; { return fUseBoost; }. RuleFit* GetRuleFitPtr(); accessors. { return &fRuleFit; }. const RuleFit* GetRuleFitConstPtr() const; { return &fRuleFit; }. TDi",MatchSource.WIKI,root/html532/TMVA__MethodRuleFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodRuleFit.html
https://root.cern/root/html532/TMVA__MethodRuleFit.html:12226,Performance,tune,tuneParameters,12226,"voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); Bool_tUseBoost() const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(c",MatchSource.WIKI,root/html532/TMVA__MethodRuleFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodRuleFit.html
https://root.cern/root/html532/TMVA__MethodRuleFit.html:23176,Security,access,accessors,23176,"FRuleFit( void ); training of rules using Jerome Friedmans implementation. const TMVA::Ranking* CreateRanking(); computes ranking of input variables. void AddWeightsXMLTo(void* parent) const; add the rules to XML node. void ReadWeightsFromStream(istream& istr); read rules from an istream. void ReadWeightsFromXML(void* wghtnode); read rules from XML node. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); returns MVA value for given event. void WriteMonitoringHistosToFile( void ); write special monitoring histograms to file (here ntuple). void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. void MakeClassRuleCuts(ostream& ) const; print out the rule cuts. void MakeClassLinear(ostream& ) const; print out the linear terms. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". Bool_t UseBoost() const; { return fUseBoost; }. RuleFit* GetRuleFitPtr(); accessors. { return &fRuleFit; }. const RuleFit* GetRuleFitConstPtr() const; { return &fRuleFit; }. TDirectory* GetMethodBaseDir() const; { return BaseDir(); }. const std::vector<TMVA::Event*>& GetTrainingEvents() const; { return fEventSample; }. const std::vector<TMVA::DecisionTree*>& GetForest() const; { return fForest; }. Int_t GetNTrees() const; { return fNTrees; }. Double_t GetTreeEveFrac() const; { return fTreeEveFrac; }. const SeparationBase* GetSeparationBaseConst() const; { return fSepType; }. SeparationBase* GetSeparationBase() const; { return fSepType; }. TMVA::DecisionTree::EPruneMethod GetPruneMethod() const; { return fPruneMethod; }. Double_t GetPruneStrength() const; { return fPruneStrength; }. Double_t GetMinFracNEve() const; { return fMinFracNEve; }. Double_t GetMaxFracNEve() const; { return fMaxFracNEve; }. Int_t GetNCuts() const. { return fNCuts; }. Int_t GetGDNPathSteps() const; { return fGDNPathSteps; }. Double_t GetGDPathStep() const; { return fGDPathStep;",MatchSource.WIKI,root/html532/TMVA__MethodRuleFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodRuleFit.html
https://root.cern/root/html532/TMVA__MethodRuleFit.html:12028,Testability,test,testTime,12028,"am& out, Option_t* option = """"); virtual voidTMVA::MethodBase::SetAnalysisType(TMVA::Types::EAnalysisType type); voidTMVA::MethodBase::SetBaseDir(TDirectory* methodDir); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); Bool_tUseBoost() const; virtual voidTObject::UseCurrentS",MatchSource.WIKI,root/html532/TMVA__MethodRuleFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodRuleFit.html
https://root.cern/root/html532/TMVA__MethodRuleFit.html:16032,Testability,test,testing,16032,"VA::MethodBase::SetNormalised(Bool_t norm); voidTMVA::MethodBase::SetWeightFileDir(TString fileDir); voidTMVA::MethodBase::SetWeightFileName(TString); voidTMVA::MethodBase::Statistics(TMVA::Types::ETreeType treeType, const TString& theVarName, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&); voidTrainJFRuleFit(); voidTrainTMVARuleFit(); Bool_tTMVA::MethodBase::TxtWeightsOnly() const; Bool_tTMVA::MethodBase::Verbose() const; voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. virtual voidDeclareOptions(); virtual voidProcessOptions(). Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. vector<TMVA::Event*>f",MatchSource.WIKI,root/html532/TMVA__MethodRuleFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodRuleFit.html
https://root.cern/root/html532/TMVA__MethodSVM.html:2072,Availability,error,error,2072,"t::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt, TMVA::Types",MatchSource.WIKI,root/html532/TMVA__MethodSVM.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodSVM.html
https://root.cern/root/html532/TMVA__MethodSVM.html:2156,Availability,error,error,2156,"t* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt, TMVA::Types::ETreeType type) const; const vector<TMVA::Event*>&TMVA::MethodBase::GetEventCollec",MatchSource.WIKI,root/html532/TMVA__MethodSVM.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodSVM.html
https://root.cern/root/html532/TMVA__MethodSVM.html:17483,Availability,avail,available,17483,"_tfOrderfor Polynomial Kernel ( polynomial order ); TMVA::SVKernelFunction*fSVKernelFunctionkernel function; vector<TMVA::SVEvent*>*fSupportVectorscontains support vectors; TStringfTheKernelkernel name; Float_tfThetafor Sigmoidal Kernel; Float_tfTolerancetolerance parameter; TMVA::SVWorkingSet*fWgSetsvm working set . Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodSVM(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = """", TDirectory* theTargetDir = 0); standard constructor. MethodSVM(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL); constructor from weight file. ~MethodSVM(); destructor. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); SVM can handle classification with 2 classes and regression with one regression-target. void Init(); default initialisation. void DeclareOptions(); declare options available for this method. void DeclareCompatibilityOptions(). void ProcessOptions(); option post processing (if necessary). void Train(); Train SVM. void AddWeightsXMLTo(void* parent) const; write configuration to xml file. void ReadWeightsFromXML(void* wghtnode). void WriteWeightsToStream(TFile& fout) const; TODO write IT; write training sample (TTree) to file. void ReadWeightsFromStream(istream& istr). void ReadWeightsFromStream(TFile& fFin); TODO write IT. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); returns MVA value for given event. const std::vector<Float_t>& GetRegressionValues(). void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". const Ranking* CreateRanking(); ranking of input variables. { return 0; }. » Author: Marcin Wolter, Andrzej Zemla » Copyright (c) 200",MatchSource.WIKI,root/html532/TMVA__MethodSVM.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodSVM.html
https://root.cern/root/html532/TMVA__MethodSVM.html:17681,Deployability,configurat,configuration,17681,"nel name; Float_tfThetafor Sigmoidal Kernel; Float_tfTolerancetolerance parameter; TMVA::SVWorkingSet*fWgSetsvm working set . Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodSVM(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = """", TDirectory* theTargetDir = 0); standard constructor. MethodSVM(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL); constructor from weight file. ~MethodSVM(); destructor. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); SVM can handle classification with 2 classes and regression with one regression-target. void Init(); default initialisation. void DeclareOptions(); declare options available for this method. void DeclareCompatibilityOptions(). void ProcessOptions(); option post processing (if necessary). void Train(); Train SVM. void AddWeightsXMLTo(void* parent) const; write configuration to xml file. void ReadWeightsFromXML(void* wghtnode). void WriteWeightsToStream(TFile& fout) const; TODO write IT; write training sample (TTree) to file. void ReadWeightsFromStream(istream& istr). void ReadWeightsFromStream(TFile& fFin); TODO write IT. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); returns MVA value for given event. const std::vector<Float_t>& GetRegressionValues(). void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". const Ranking* CreateRanking(); ranking of input variables. { return 0; }. » Author: Marcin Wolter, Andrzej Zemla » Copyright (c) 2005: *; » Last changed: root/tmva $Id: MethodSVM.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-12-02 14:28; This page has been automatically generated. For comments or suggestions ",MatchSource.WIKI,root/html532/TMVA__MethodSVM.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodSVM.html
https://root.cern/root/html532/TMVA__MethodSVM.html:18231,Integrability,message,message,18231,"MVA::SVWorkingSet*fWgSetsvm working set . Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodSVM(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = """", TDirectory* theTargetDir = 0); standard constructor. MethodSVM(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL); constructor from weight file. ~MethodSVM(); destructor. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); SVM can handle classification with 2 classes and regression with one regression-target. void Init(); default initialisation. void DeclareOptions(); declare options available for this method. void DeclareCompatibilityOptions(). void ProcessOptions(); option post processing (if necessary). void Train(); Train SVM. void AddWeightsXMLTo(void* parent) const; write configuration to xml file. void ReadWeightsFromXML(void* wghtnode). void WriteWeightsToStream(TFile& fout) const; TODO write IT; write training sample (TTree) to file. void ReadWeightsFromStream(istream& istr). void ReadWeightsFromStream(TFile& fFin); TODO write IT. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); returns MVA value for given event. const std::vector<Float_t>& GetRegressionValues(). void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". const Ranking* CreateRanking(); ranking of input variables. { return 0; }. » Author: Marcin Wolter, Andrzej Zemla » Copyright (c) 2005: *; » Last changed: root/tmva $Id: MethodSVM.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-12-02 14:28; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__MethodSVM.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodSVM.html
https://root.cern/root/html532/TMVA__MethodSVM.html:15394,Modifiability,variab,variables,15394,"ons(); virtual voidProcessOptions(). Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. Float_tfBparmfree plane coefficient ; Float_tfCostcost value; Float_tfDoubleSigmaSquaredfor RBF Kernel; Float_tfGammaRBF Kernel parameter; vector<TMVA::SVEvent*>*fInputDatavector of training data in SVM format; Float_tfKappafor Sigmoidal Kernel; UInt_tfMaxItermax number of iteration; TVectorD*fMaxVarsfor normalization //is it still needed?? ; TVectorD*fMinVarsfor normalization //is it still needed?? ; UShort_tfNSubSetsnr of subsets, default 1; Int_tfOrderfor Polynomial Kernel ( polynomial order ); TMVA::SVKernelFunction*fSVKernelFunctionkernel func",MatchSource.WIKI,root/html532/TMVA__MethodSVM.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodSVM.html
https://root.cern/root/html532/TMVA__MethodSVM.html:15583,Modifiability,variab,variable,15583,"ons(); virtual voidProcessOptions(). Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. Float_tfBparmfree plane coefficient ; Float_tfCostcost value; Float_tfDoubleSigmaSquaredfor RBF Kernel; Float_tfGammaRBF Kernel parameter; vector<TMVA::SVEvent*>*fInputDatavector of training data in SVM format; Float_tfKappafor Sigmoidal Kernel; UInt_tfMaxItermax number of iteration; TVectorD*fMaxVarsfor normalization //is it still needed?? ; TVectorD*fMinVarsfor normalization //is it still needed?? ; UShort_tfNSubSetsnr of subsets, default 1; Int_tfOrderfor Polynomial Kernel ( polynomial order ); TMVA::SVKernelFunction*fSVKernelFunctionkernel func",MatchSource.WIKI,root/html532/TMVA__MethodSVM.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodSVM.html
https://root.cern/root/html532/TMVA__MethodSVM.html:17681,Modifiability,config,configuration,17681,"nel name; Float_tfThetafor Sigmoidal Kernel; Float_tfTolerancetolerance parameter; TMVA::SVWorkingSet*fWgSetsvm working set . Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodSVM(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = """", TDirectory* theTargetDir = 0); standard constructor. MethodSVM(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL); constructor from weight file. ~MethodSVM(); destructor. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); SVM can handle classification with 2 classes and regression with one regression-target. void Init(); default initialisation. void DeclareOptions(); declare options available for this method. void DeclareCompatibilityOptions(). void ProcessOptions(); option post processing (if necessary). void Train(); Train SVM. void AddWeightsXMLTo(void* parent) const; write configuration to xml file. void ReadWeightsFromXML(void* wghtnode). void WriteWeightsToStream(TFile& fout) const; TODO write IT; write training sample (TTree) to file. void ReadWeightsFromStream(istream& istr). void ReadWeightsFromStream(TFile& fFin); TODO write IT. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); returns MVA value for given event. const std::vector<Float_t>& GetRegressionValues(). void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". const Ranking* CreateRanking(); ranking of input variables. { return 0; }. » Author: Marcin Wolter, Andrzej Zemla » Copyright (c) 2005: *; » Last changed: root/tmva $Id: MethodSVM.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-12-02 14:28; This page has been automatically generated. For comments or suggestions ",MatchSource.WIKI,root/html532/TMVA__MethodSVM.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodSVM.html
https://root.cern/root/html532/TMVA__MethodSVM.html:18392,Modifiability,variab,variables,18392,"MVA::SVWorkingSet*fWgSetsvm working set . Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodSVM(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = """", TDirectory* theTargetDir = 0); standard constructor. MethodSVM(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL); constructor from weight file. ~MethodSVM(); destructor. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); SVM can handle classification with 2 classes and regression with one regression-target. void Init(); default initialisation. void DeclareOptions(); declare options available for this method. void DeclareCompatibilityOptions(). void ProcessOptions(); option post processing (if necessary). void Train(); Train SVM. void AddWeightsXMLTo(void* parent) const; write configuration to xml file. void ReadWeightsFromXML(void* wghtnode). void WriteWeightsToStream(TFile& fout) const; TODO write IT; write training sample (TTree) to file. void ReadWeightsFromStream(istream& istr). void ReadWeightsFromStream(TFile& fFin); TODO write IT. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); returns MVA value for given event. const std::vector<Float_t>& GetRegressionValues(). void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". const Ranking* CreateRanking(); ranking of input variables. { return 0; }. » Author: Marcin Wolter, Andrzej Zemla » Copyright (c) 2005: *; » Last changed: root/tmva $Id: MethodSVM.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-12-02 14:28; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__MethodSVM.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodSVM.html
https://root.cern/root/html532/TMVA__MethodSVM.html:11386,Performance,tune,tuneParameters,11386,"voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int",MatchSource.WIKI,root/html532/TMVA__MethodSVM.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodSVM.html
https://root.cern/root/html532/TMVA__MethodSVM.html:11188,Testability,test,testTime,11188,"am& out, Option_t* option = """"); virtual voidTMVA::MethodBase::SetAnalysisType(TMVA::Types::EAnalysisType type); voidTMVA::MethodBase::SetBaseDir(TDirectory* methodDir); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObj",MatchSource.WIKI,root/html532/TMVA__MethodSVM.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodSVM.html
https://root.cern/root/html532/TMVA__MethodSVM.html:15084,Testability,test,testing,15084,"dTMVA::MethodBase::SetNormalised(Bool_t norm); voidTMVA::MethodBase::SetWeightFileDir(TString fileDir); voidTMVA::MethodBase::SetWeightFileName(TString); voidTMVA::MethodBase::Statistics(TMVA::Types::ETreeType treeType, const TString& theVarName, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&); Bool_tTMVA::MethodBase::TxtWeightsOnly() const; Bool_tTMVA::MethodBase::Verbose() const; voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. virtual voidDeclareCompatibilityOptions(); virtual voidDeclareOptions(); virtual voidProcessOptions(). Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. Float_tfBparmfree pla",MatchSource.WIKI,root/html532/TMVA__MethodSVM.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodSVM.html
https://root.cern/root/html532/TMVA__MethodTMlpANN.html:2414,Availability,error,error,2414,"t::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt, TMVA::Types",MatchSource.WIKI,root/html532/TMVA__MethodTMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodTMlpANN.html
https://root.cern/root/html532/TMVA__MethodTMlpANN.html:2498,Availability,error,error,2498,"able(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt, TMVA::Types::ETreeType type) const; const vector<TMVA::Event*>&TMVA::MethodBase::GetEventCollec",MatchSource.WIKI,root/html532/TMVA__MethodTMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodTMlpANN.html
https://root.cern/root/html532/TMVA__MethodTMlpANN.html:18428,Availability,avail,available,18428,"oid ); destructor. void CreateMLPOptions(TString ); translates options from option string into TMlpANN language. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options:; NCycles <integer> Number of training cycles (too many cycles could overtrain the network); HiddenLayers <string> Layout of the hidden layers (nodes per layer); * specifiactions for each hidden layer are separated by commata; * for each layer the number of nodes can be either absolut (simply a number); or relative to the number of input nodes to the neural net (N); * there is always a single node in the output layer; example: a net with 6 input nodes and ""Hiddenlayers=N-1,N-2"" has 6,5,4,1 nodes in the; layers 1,2,3,4, repectively. void ProcessOptions(); builds the neural network as specified by the user. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); calculate the value of the neural net for the current event. void Train( void ); performs TMlpANN training; available learning methods:. TMultiLayerPerceptron::kStochastic; TMultiLayerPerceptron::kBatch; TMultiLayerPerceptron::kSteepestDescent; TMultiLayerPerceptron::kRibierePolak; TMultiLayerPerceptron::kFletcherReeves; TMultiLayerPerceptron::kBFGS. TMultiLayerPerceptron wants test and training tree at once; so merge the training and testing trees from the MVA factory first:. void AddWeightsXMLTo(void* parent) const; write weights to xml file. void ReadWeightsFromXML(void* wghtnode); rebuild temporary textfile from xml weightfile and load this; file into MLP. void ReadWeightsFromStream(istream& istr); read weights from stream; since the MLP can not read from the stream, we; 1st: write the weights to temporary file. void MakeClass(const TString& classFileName = TString("""")) const; create reader class for classifier -> overwrites base class function; create specific class for TMultiLayerPerceptron. void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier r",MatchSource.WIKI,root/html532/TMVA__MethodTMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodTMlpANN.html
https://root.cern/root/html532/TMVA__MethodTMlpANN.html:358,Integrability,interface,interface,358,". TMVA::MethodTMlpANN. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodTMlpANN. class TMVA::MethodTMlpANN: public TMVA::MethodBase. This is the TMVA TMultiLayerPerceptron interface class. It provides the; training and testing the ROOT internal MLP class in the TMVA framework.; Available learning methods:. Stochastic ; Batch ; SteepestDescent ; RibierePolak ; FletcherReeves ; BFGS . . See the TMultiLayerPerceptron class description; for details on this ANN. Function Members (Methods); public:. virtual~MethodTMlpANN(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidTMVA::MethodBase::CheckSetup(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticla",MatchSource.WIKI,root/html532/TMVA__MethodTMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodTMlpANN.html
https://root.cern/root/html532/TMVA__MethodTMlpANN.html:19530,Integrability,message,message,19530,"1,2,3,4, repectively. void ProcessOptions(); builds the neural network as specified by the user. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); calculate the value of the neural net for the current event. void Train( void ); performs TMlpANN training; available learning methods:. TMultiLayerPerceptron::kStochastic; TMultiLayerPerceptron::kBatch; TMultiLayerPerceptron::kSteepestDescent; TMultiLayerPerceptron::kRibierePolak; TMultiLayerPerceptron::kFletcherReeves; TMultiLayerPerceptron::kBFGS. TMultiLayerPerceptron wants test and training tree at once; so merge the training and testing trees from the MVA factory first:. void AddWeightsXMLTo(void* parent) const; write weights to xml file. void ReadWeightsFromXML(void* wghtnode); rebuild temporary textfile from xml weightfile and load this; file into MLP. void ReadWeightsFromStream(istream& istr); read weights from stream; since the MLP can not read from the stream, we; 1st: write the weights to temporary file. void MakeClass(const TString& classFileName = TString("""")) const; create reader class for classifier -> overwrites base class function; create specific class for TMultiLayerPerceptron. void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response; nothing to do here - all taken care of by TMultiLayerPerceptron. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". void SetHiddenLayer(TString hiddenlayer = """"); { fHiddenLayer=hiddenlayer; }. const Ranking* CreateRanking(); ranking of input variables. { return 0; }. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: MethodTMlpANN.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__MethodTMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodTMlpANN.html
https://root.cern/root/html532/TMVA__MethodTMlpANN.html:15705,Modifiability,variab,variables,15705,"nit(); virtual voidProcessOptions(). Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. TStringfHiddenLayerstring containig the hidden layer structure; TStringfLayerSpecLayer specification option; TStringfLearningMethodthe learning method (given via option string); TTree*fLocalTrainingTreelocal copy of training tree; TMultiLayerPerceptron*fMLPthe TMLP; TStringfMLPBuildOptionsoption string to build the mlp; Int_tfNcyclesnumber of training cylcles; Double_tfValidationFractionfraction of events in training tree used for cross validation. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodTMlp",MatchSource.WIKI,root/html532/TMVA__MethodTMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodTMlpANN.html
https://root.cern/root/html532/TMVA__MethodTMlpANN.html:15894,Modifiability,variab,variable,15894,"nit(); virtual voidProcessOptions(). Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. TStringfHiddenLayerstring containig the hidden layer structure; TStringfLayerSpecLayer specification option; TStringfLearningMethodthe learning method (given via option string); TTree*fLocalTrainingTreelocal copy of training tree; TMultiLayerPerceptron*fMLPthe TMLP; TStringfMLPBuildOptionsoption string to build the mlp; Int_tfNcyclesnumber of training cylcles; Double_tfValidationFractionfraction of events in training tree used for cross validation. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodTMlp",MatchSource.WIKI,root/html532/TMVA__MethodTMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodTMlpANN.html
https://root.cern/root/html532/TMVA__MethodTMlpANN.html:17778,Modifiability,layers,layers,17778,". Function documentation; MethodTMlpANN(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = ""3000:N-1:N-2"", TDirectory* theTargetDir = 0); standard constructor. MethodTMlpANN(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL); constructor from weight file. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); TMlpANN can handle classification with 2 classes. void Init( void ); default initialisations. ~MethodTMlpANN( void ); destructor. void CreateMLPOptions(TString ); translates options from option string into TMlpANN language. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options:; NCycles <integer> Number of training cycles (too many cycles could overtrain the network); HiddenLayers <string> Layout of the hidden layers (nodes per layer); * specifiactions for each hidden layer are separated by commata; * for each layer the number of nodes can be either absolut (simply a number); or relative to the number of input nodes to the neural net (N); * there is always a single node in the output layer; example: a net with 6 input nodes and ""Hiddenlayers=N-1,N-2"" has 6,5,4,1 nodes in the; layers 1,2,3,4, repectively. void ProcessOptions(); builds the neural network as specified by the user. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); calculate the value of the neural net for the current event. void Train( void ); performs TMlpANN training; available learning methods:. TMultiLayerPerceptron::kStochastic; TMultiLayerPerceptron::kBatch; TMultiLayerPerceptron::kSteepestDescent; TMultiLayerPerceptron::kRibierePolak; TMultiLayerPerceptron::kFletcherReeves; TMultiLayerPerceptron::kBFGS. TMultiLayerPerceptron wants test and training tree at once; so merge the training and testing trees from the MVA factory first:. void AddWeightsXMLTo(void* parent) const; write weigh",MatchSource.WIKI,root/html532/TMVA__MethodTMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodTMlpANN.html
https://root.cern/root/html532/TMVA__MethodTMlpANN.html:18151,Modifiability,layers,layers,18151,". Function documentation; MethodTMlpANN(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = ""3000:N-1:N-2"", TDirectory* theTargetDir = 0); standard constructor. MethodTMlpANN(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL); constructor from weight file. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); TMlpANN can handle classification with 2 classes. void Init( void ); default initialisations. ~MethodTMlpANN( void ); destructor. void CreateMLPOptions(TString ); translates options from option string into TMlpANN language. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options:; NCycles <integer> Number of training cycles (too many cycles could overtrain the network); HiddenLayers <string> Layout of the hidden layers (nodes per layer); * specifiactions for each hidden layer are separated by commata; * for each layer the number of nodes can be either absolut (simply a number); or relative to the number of input nodes to the neural net (N); * there is always a single node in the output layer; example: a net with 6 input nodes and ""Hiddenlayers=N-1,N-2"" has 6,5,4,1 nodes in the; layers 1,2,3,4, repectively. void ProcessOptions(); builds the neural network as specified by the user. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); calculate the value of the neural net for the current event. void Train( void ); performs TMlpANN training; available learning methods:. TMultiLayerPerceptron::kStochastic; TMultiLayerPerceptron::kBatch; TMultiLayerPerceptron::kSteepestDescent; TMultiLayerPerceptron::kRibierePolak; TMultiLayerPerceptron::kFletcherReeves; TMultiLayerPerceptron::kBFGS. TMultiLayerPerceptron wants test and training tree at once; so merge the training and testing trees from the MVA factory first:. void AddWeightsXMLTo(void* parent) const; write weigh",MatchSource.WIKI,root/html532/TMVA__MethodTMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodTMlpANN.html
https://root.cern/root/html532/TMVA__MethodTMlpANN.html:19769,Modifiability,variab,variables,19769,"1,2,3,4, repectively. void ProcessOptions(); builds the neural network as specified by the user. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); calculate the value of the neural net for the current event. void Train( void ); performs TMlpANN training; available learning methods:. TMultiLayerPerceptron::kStochastic; TMultiLayerPerceptron::kBatch; TMultiLayerPerceptron::kSteepestDescent; TMultiLayerPerceptron::kRibierePolak; TMultiLayerPerceptron::kFletcherReeves; TMultiLayerPerceptron::kBFGS. TMultiLayerPerceptron wants test and training tree at once; so merge the training and testing trees from the MVA factory first:. void AddWeightsXMLTo(void* parent) const; write weights to xml file. void ReadWeightsFromXML(void* wghtnode); rebuild temporary textfile from xml weightfile and load this; file into MLP. void ReadWeightsFromStream(istream& istr); read weights from stream; since the MLP can not read from the stream, we; 1st: write the weights to temporary file. void MakeClass(const TString& classFileName = TString("""")) const; create reader class for classifier -> overwrites base class function; create specific class for TMultiLayerPerceptron. void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response; nothing to do here - all taken care of by TMultiLayerPerceptron. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". void SetHiddenLayer(TString hiddenlayer = """"); { fHiddenLayer=hiddenlayer; }. const Ranking* CreateRanking(); ranking of input variables. { return 0; }. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: MethodTMlpANN.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__MethodTMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodTMlpANN.html
https://root.cern/root/html532/TMVA__MethodTMlpANN.html:11734,Performance,tune,tuneParameters,11734,"dTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidSetHiddenLayer(TString hiddenlayer = """"); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int",MatchSource.WIKI,root/html532/TMVA__MethodTMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodTMlpANN.html
https://root.cern/root/html532/TMVA__MethodTMlpANN.html:18401,Performance,perform,performs,18401,"oid ); destructor. void CreateMLPOptions(TString ); translates options from option string into TMlpANN language. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options:; NCycles <integer> Number of training cycles (too many cycles could overtrain the network); HiddenLayers <string> Layout of the hidden layers (nodes per layer); * specifiactions for each hidden layer are separated by commata; * for each layer the number of nodes can be either absolut (simply a number); or relative to the number of input nodes to the neural net (N); * there is always a single node in the output layer; example: a net with 6 input nodes and ""Hiddenlayers=N-1,N-2"" has 6,5,4,1 nodes in the; layers 1,2,3,4, repectively. void ProcessOptions(); builds the neural network as specified by the user. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); calculate the value of the neural net for the current event. void Train( void ); performs TMlpANN training; available learning methods:. TMultiLayerPerceptron::kStochastic; TMultiLayerPerceptron::kBatch; TMultiLayerPerceptron::kSteepestDescent; TMultiLayerPerceptron::kRibierePolak; TMultiLayerPerceptron::kFletcherReeves; TMultiLayerPerceptron::kBFGS. TMultiLayerPerceptron wants test and training tree at once; so merge the training and testing trees from the MVA factory first:. void AddWeightsXMLTo(void* parent) const; write weights to xml file. void ReadWeightsFromXML(void* wghtnode); rebuild temporary textfile from xml weightfile and load this; file into MLP. void ReadWeightsFromStream(istream& istr); read weights from stream; since the MLP can not read from the stream, we; 1st: write the weights to temporary file. void MakeClass(const TString& classFileName = TString("""")) const; create reader class for classifier -> overwrites base class function; create specific class for TMultiLayerPerceptron. void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier r",MatchSource.WIKI,root/html532/TMVA__MethodTMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodTMlpANN.html
https://root.cern/root/html532/TMVA__MethodTMlpANN.html:18963,Performance,load,load,18963,"simply a number); or relative to the number of input nodes to the neural net (N); * there is always a single node in the output layer; example: a net with 6 input nodes and ""Hiddenlayers=N-1,N-2"" has 6,5,4,1 nodes in the; layers 1,2,3,4, repectively. void ProcessOptions(); builds the neural network as specified by the user. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); calculate the value of the neural net for the current event. void Train( void ); performs TMlpANN training; available learning methods:. TMultiLayerPerceptron::kStochastic; TMultiLayerPerceptron::kBatch; TMultiLayerPerceptron::kSteepestDescent; TMultiLayerPerceptron::kRibierePolak; TMultiLayerPerceptron::kFletcherReeves; TMultiLayerPerceptron::kBFGS. TMultiLayerPerceptron wants test and training tree at once; so merge the training and testing trees from the MVA factory first:. void AddWeightsXMLTo(void* parent) const; write weights to xml file. void ReadWeightsFromXML(void* wghtnode); rebuild temporary textfile from xml weightfile and load this; file into MLP. void ReadWeightsFromStream(istream& istr); read weights from stream; since the MLP can not read from the stream, we; 1st: write the weights to temporary file. void MakeClass(const TString& classFileName = TString("""")) const; create reader class for classifier -> overwrites base class function; create specific class for TMultiLayerPerceptron. void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response; nothing to do here - all taken care of by TMultiLayerPerceptron. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". void SetHiddenLayer(TString hiddenlayer = """"); { fHiddenLayer=hiddenlayer; }. const Ranking* CreateRanking(); ranking of input variables. { return 0; }. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: MethodTMlpANN.h",MatchSource.WIKI,root/html532/TMVA__MethodTMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodTMlpANN.html
https://root.cern/root/html532/TMVA__MethodTMlpANN.html:16777,Security,validat,validation,16777,"ssification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. TStringfHiddenLayerstring containig the hidden layer structure; TStringfLayerSpecLayer specification option; TStringfLearningMethodthe learning method (given via option string); TTree*fLocalTrainingTreelocal copy of training tree; TMultiLayerPerceptron*fMLPthe TMLP; TStringfMLPBuildOptionsoption string to build the mlp; Int_tfNcyclesnumber of training cylcles; Double_tfValidationFractionfraction of events in training tree used for cross validation. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodTMlpANN(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = ""3000:N-1:N-2"", TDirectory* theTargetDir = 0); standard constructor. MethodTMlpANN(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL); constructor from weight file. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); TMlpANN can handle classification with 2 classes. void Init( void ); default initialisations. ~MethodTMlpANN( void ); destructor. void CreateMLPOptions(TString ); translates options from option string into TMlpANN language. void DeclareOptions(); define t",MatchSource.WIKI,root/html532/TMVA__MethodTMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodTMlpANN.html
https://root.cern/root/html532/TMVA__MethodTMlpANN.html:405,Testability,test,testing,405,". TMVA::MethodTMlpANN. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodTMlpANN. class TMVA::MethodTMlpANN: public TMVA::MethodBase. This is the TMVA TMultiLayerPerceptron interface class. It provides the; training and testing the ROOT internal MLP class in the TMVA framework.; Available learning methods:. Stochastic ; Batch ; SteepestDescent ; RibierePolak ; FletcherReeves ; BFGS . . See the TMultiLayerPerceptron class description; for details on this ANN. Function Members (Methods); public:. virtual~MethodTMlpANN(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidTMVA::MethodBase::CheckSetup(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticla",MatchSource.WIKI,root/html532/TMVA__MethodTMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodTMlpANN.html
https://root.cern/root/html532/TMVA__MethodTMlpANN.html:11536,Testability,test,testTime,11536,"MVA::MethodBase::SetAnalysisType(TMVA::Types::EAnalysisType type); voidTMVA::MethodBase::SetBaseDir(TDirectory* methodDir); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidSetHiddenLayer(TString hiddenlayer = """"); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObj",MatchSource.WIKI,root/html532/TMVA__MethodTMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodTMlpANN.html
https://root.cern/root/html532/TMVA__MethodTMlpANN.html:15395,Testability,test,testing,15395,"ethodBase::SetNormalised(Bool_t norm); voidTMVA::MethodBase::SetWeightFileDir(TString fileDir); voidTMVA::MethodBase::SetWeightFileName(TString); voidTMVA::MethodBase::Statistics(TMVA::Types::ETreeType treeType, const TString& theVarName, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&); Bool_tTMVA::MethodBase::TxtWeightsOnly() const; Bool_tTMVA::MethodBase::Verbose() const; voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. voidCreateMLPOptions(TString); virtual voidDeclareOptions(); virtual voidInit(); virtual voidProcessOptions(). Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. TStringfHiddenLayerst",MatchSource.WIKI,root/html532/TMVA__MethodTMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodTMlpANN.html
https://root.cern/root/html532/TMVA__MethodTMlpANN.html:18701,Testability,test,test,18701,"iddenLayers <string> Layout of the hidden layers (nodes per layer); * specifiactions for each hidden layer are separated by commata; * for each layer the number of nodes can be either absolut (simply a number); or relative to the number of input nodes to the neural net (N); * there is always a single node in the output layer; example: a net with 6 input nodes and ""Hiddenlayers=N-1,N-2"" has 6,5,4,1 nodes in the; layers 1,2,3,4, repectively. void ProcessOptions(); builds the neural network as specified by the user. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); calculate the value of the neural net for the current event. void Train( void ); performs TMlpANN training; available learning methods:. TMultiLayerPerceptron::kStochastic; TMultiLayerPerceptron::kBatch; TMultiLayerPerceptron::kSteepestDescent; TMultiLayerPerceptron::kRibierePolak; TMultiLayerPerceptron::kFletcherReeves; TMultiLayerPerceptron::kBFGS. TMultiLayerPerceptron wants test and training tree at once; so merge the training and testing trees from the MVA factory first:. void AddWeightsXMLTo(void* parent) const; write weights to xml file. void ReadWeightsFromXML(void* wghtnode); rebuild temporary textfile from xml weightfile and load this; file into MLP. void ReadWeightsFromStream(istream& istr); read weights from stream; since the MLP can not read from the stream, we; 1st: write the weights to temporary file. void MakeClass(const TString& classFileName = TString("""")) const; create reader class for classifier -> overwrites base class function; create specific class for TMultiLayerPerceptron. void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response; nothing to do here - all taken care of by TMultiLayerPerceptron. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". void SetHiddenLayer(TString hiddenlayer = """"); { fHiddenLayer=hiddenlayer; }. const Ranking* Cr",MatchSource.WIKI,root/html532/TMVA__MethodTMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodTMlpANN.html
https://root.cern/root/html532/TMVA__MethodTMlpANN.html:18759,Testability,test,testing,18759,"iddenLayers <string> Layout of the hidden layers (nodes per layer); * specifiactions for each hidden layer are separated by commata; * for each layer the number of nodes can be either absolut (simply a number); or relative to the number of input nodes to the neural net (N); * there is always a single node in the output layer; example: a net with 6 input nodes and ""Hiddenlayers=N-1,N-2"" has 6,5,4,1 nodes in the; layers 1,2,3,4, repectively. void ProcessOptions(); builds the neural network as specified by the user. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); calculate the value of the neural net for the current event. void Train( void ); performs TMlpANN training; available learning methods:. TMultiLayerPerceptron::kStochastic; TMultiLayerPerceptron::kBatch; TMultiLayerPerceptron::kSteepestDescent; TMultiLayerPerceptron::kRibierePolak; TMultiLayerPerceptron::kFletcherReeves; TMultiLayerPerceptron::kBFGS. TMultiLayerPerceptron wants test and training tree at once; so merge the training and testing trees from the MVA factory first:. void AddWeightsXMLTo(void* parent) const; write weights to xml file. void ReadWeightsFromXML(void* wghtnode); rebuild temporary textfile from xml weightfile and load this; file into MLP. void ReadWeightsFromStream(istream& istr); read weights from stream; since the MLP can not read from the stream, we; 1st: write the weights to temporary file. void MakeClass(const TString& classFileName = TString("""")) const; create reader class for classifier -> overwrites base class function; create specific class for TMultiLayerPerceptron. void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response; nothing to do here - all taken care of by TMultiLayerPerceptron. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". void SetHiddenLayer(TString hiddenlayer = """"); { fHiddenLayer=hiddenlayer; }. const Ranking* Cr",MatchSource.WIKI,root/html532/TMVA__MethodTMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodTMlpANN.html
https://root.cern/root/html532/TMVA__MethodTMlpANN.html:475,Usability,learn,learning,475,". TMVA::MethodTMlpANN. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodTMlpANN. class TMVA::MethodTMlpANN: public TMVA::MethodBase. This is the TMVA TMultiLayerPerceptron interface class. It provides the; training and testing the ROOT internal MLP class in the TMVA framework.; Available learning methods:. Stochastic ; Batch ; SteepestDescent ; RibierePolak ; FletcherReeves ; BFGS . . See the TMultiLayerPerceptron class description; for details on this ANN. Function Members (Methods); public:. virtual~MethodTMlpANN(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidTMVA::MethodBase::CheckSetup(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticla",MatchSource.WIKI,root/html532/TMVA__MethodTMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodTMlpANN.html
https://root.cern/root/html532/TMVA__MethodTMlpANN.html:16471,Usability,learn,learning,16471,"ssification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. TStringfHiddenLayerstring containig the hidden layer structure; TStringfLayerSpecLayer specification option; TStringfLearningMethodthe learning method (given via option string); TTree*fLocalTrainingTreelocal copy of training tree; TMultiLayerPerceptron*fMLPthe TMLP; TStringfMLPBuildOptionsoption string to build the mlp; Int_tfNcyclesnumber of training cylcles; Double_tfValidationFractionfraction of events in training tree used for cross validation. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodTMlpANN(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = ""3000:N-1:N-2"", TDirectory* theTargetDir = 0); standard constructor. MethodTMlpANN(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL); constructor from weight file. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); TMlpANN can handle classification with 2 classes. void Init( void ); default initialisations. ~MethodTMlpANN( void ); destructor. void CreateMLPOptions(TString ); translates options from option string into TMlpANN language. void DeclareOptions(); define t",MatchSource.WIKI,root/html532/TMVA__MethodTMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodTMlpANN.html
https://root.cern/root/html532/TMVA__MethodTMlpANN.html:17929,Usability,simpl,simply,17929,". Function documentation; MethodTMlpANN(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = ""3000:N-1:N-2"", TDirectory* theTargetDir = 0); standard constructor. MethodTMlpANN(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL); constructor from weight file. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); TMlpANN can handle classification with 2 classes. void Init( void ); default initialisations. ~MethodTMlpANN( void ); destructor. void CreateMLPOptions(TString ); translates options from option string into TMlpANN language. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options:; NCycles <integer> Number of training cycles (too many cycles could overtrain the network); HiddenLayers <string> Layout of the hidden layers (nodes per layer); * specifiactions for each hidden layer are separated by commata; * for each layer the number of nodes can be either absolut (simply a number); or relative to the number of input nodes to the neural net (N); * there is always a single node in the output layer; example: a net with 6 input nodes and ""Hiddenlayers=N-1,N-2"" has 6,5,4,1 nodes in the; layers 1,2,3,4, repectively. void ProcessOptions(); builds the neural network as specified by the user. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); calculate the value of the neural net for the current event. void Train( void ); performs TMlpANN training; available learning methods:. TMultiLayerPerceptron::kStochastic; TMultiLayerPerceptron::kBatch; TMultiLayerPerceptron::kSteepestDescent; TMultiLayerPerceptron::kRibierePolak; TMultiLayerPerceptron::kFletcherReeves; TMultiLayerPerceptron::kBFGS. TMultiLayerPerceptron wants test and training tree at once; so merge the training and testing trees from the MVA factory first:. void AddWeightsXMLTo(void* parent) const; write weigh",MatchSource.WIKI,root/html532/TMVA__MethodTMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodTMlpANN.html
https://root.cern/root/html532/TMVA__MethodTMlpANN.html:18438,Usability,learn,learning,18438,"oid ); destructor. void CreateMLPOptions(TString ); translates options from option string into TMlpANN language. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options:; NCycles <integer> Number of training cycles (too many cycles could overtrain the network); HiddenLayers <string> Layout of the hidden layers (nodes per layer); * specifiactions for each hidden layer are separated by commata; * for each layer the number of nodes can be either absolut (simply a number); or relative to the number of input nodes to the neural net (N); * there is always a single node in the output layer; example: a net with 6 input nodes and ""Hiddenlayers=N-1,N-2"" has 6,5,4,1 nodes in the; layers 1,2,3,4, repectively. void ProcessOptions(); builds the neural network as specified by the user. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); calculate the value of the neural net for the current event. void Train( void ); performs TMlpANN training; available learning methods:. TMultiLayerPerceptron::kStochastic; TMultiLayerPerceptron::kBatch; TMultiLayerPerceptron::kSteepestDescent; TMultiLayerPerceptron::kRibierePolak; TMultiLayerPerceptron::kFletcherReeves; TMultiLayerPerceptron::kBFGS. TMultiLayerPerceptron wants test and training tree at once; so merge the training and testing trees from the MVA factory first:. void AddWeightsXMLTo(void* parent) const; write weights to xml file. void ReadWeightsFromXML(void* wghtnode); rebuild temporary textfile from xml weightfile and load this; file into MLP. void ReadWeightsFromStream(istream& istr); read weights from stream; since the MLP can not read from the stream, we; 1st: write the weights to temporary file. void MakeClass(const TString& classFileName = TString("""")) const; create reader class for classifier -> overwrites base class function; create specific class for TMultiLayerPerceptron. void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier r",MatchSource.WIKI,root/html532/TMVA__MethodTMlpANN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodTMlpANN.html
https://root.cern/root/html532/TMVA__MinuitFitter.html:499,Availability,avail,available,499,". TMVA::MinuitFitter. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MinuitFitter. class TMVA::MinuitFitter: public TMVA::FitterBase, public TMVA::IFitterTarget. Fitter using MINUIT. Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~MinuitFitter(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tEstimatorFunction(vector<Double_t>& pars); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const ch",MatchSource.WIKI,root/html532/TMVA__MinuitFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MinuitFitter.html
https://root.cern/root/html532/TMVA__MinuitFitter.html:1719,Availability,error,error,1719," """"); virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tEstimatorFunction(vector<Double_t>& pars); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TMVA::IFitterTarget&TMVA::FitterBase::GetFitterTarget() const; virtual const char*TObject::GetIconName() const; virtual const char*TMVA::FitterBase::GetName() const; Int_tTMVA::FitterBase::GetNpars() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&TMVA::Configurable::GetOptions() const; virtual const char*TObject::GetT",MatchSource.WIKI,root/html532/TMVA__MinuitFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MinuitFitter.html
https://root.cern/root/html532/TMVA__MinuitFitter.html:1803,Availability,error,error,1803,"edOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tEstimatorFunction(vector<Double_t>& pars); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TMVA::IFitterTarget&TMVA::FitterBase::GetFitterTarget() const; virtual const char*TObject::GetIconName() const; virtual const char*TMVA::FitterBase::GetName() const; Int_tTMVA::FitterBase::GetNpars() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&TMVA::Configurable::GetOptions() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::Han",MatchSource.WIKI,root/html532/TMVA__MinuitFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MinuitFitter.html
https://root.cern/root/html532/TMVA__MinuitFitter.html:7237,Availability,error,error,7237,::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. virtual voidDeclareOptions(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringTMVA::FitterBase::fClassNameremove TMVA:: from TObject name; TMVA::IFitterTarget&TMVA::FitterBase::fFitterTargetpointer to target of fitting procedure; TMVA::MsgLogger*TMVA::FitterBase::fLoggermessage logger; TMVA::MinuitWrapper*fMinWrapholds a wrapper around TMinuit; Int_tTMVA::FitterBase::fNparsnumber of parameters; const vector<TMVA::Interval*>TMVA::FitterBase::fRangesallowed intervals. private:. Bool_tfBatchbatch mode; Int_tfErrorLevelminuit error level; Int_tfFitStrategyminuit strategy level; Int_tfMaxCalls(approximate) maximum number of function calls; Int_tfPrintLevelminuit printout level; Bool_tfPrintWarningsminuit warnings level; Double_tfTolerancetolerance to the function value at the minimum; Bool_tfUseImproveflag for 'IMPROVE' use; Bool_tfUseMinosflag for 'MINOS' use. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; ~MinuitFitter(); destructor. void DeclareOptions(); declare SA options. void Init(); minuit-specific settings. Double_t Run(vector<Double_t>& pars); performs the fit. Double_t EstimatorFunction(vector<Double_t>& pars); performs the fit by calliung Run(pars). » Author: Andreas Hoecker » Copyright (c) 2005: *; » Last changed: root/tmva $Id: MinuitFitter.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ,MatchSource.WIKI,root/html532/TMVA__MinuitFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MinuitFitter.html
https://root.cern/root/html532/TMVA__MinuitFitter.html:7032,Integrability,wrap,wrapper,7032,"x) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&TMVA::FitterBase::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. virtual voidDeclareOptions(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringTMVA::FitterBase::fClassNameremove TMVA:: from TObject name; TMVA::IFitterTarget&TMVA::FitterBase::fFitterTargetpointer to target of fitting procedure; TMVA::MsgLogger*TMVA::FitterBase::fLoggermessage logger; TMVA::MinuitWrapper*fMinWrapholds a wrapper around TMinuit; Int_tTMVA::FitterBase::fNparsnumber of parameters; const vector<TMVA::Interval*>TMVA::FitterBase::fRangesallowed intervals. private:. Bool_tfBatchbatch mode; Int_tfErrorLevelminuit error level; Int_tfFitStrategyminuit strategy level; Int_tfMaxCalls(approximate) maximum number of function calls; Int_tfPrintLevelminuit printout level; Bool_tfPrintWarningsminuit warnings level; Double_tfTolerancetolerance to the function value at the minimum; Bool_tfUseImproveflag for 'IMPROVE' use; Bool_tfUseMinosflag for 'MINOS' use. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; ~MinuitFitter(); destructor. void DeclareOptions(); declare SA options. void Init(); minuit-specific settings. Double_t Run(vector<Double_t>& pars); performs the fit. Double_t EstimatorFunction(vector<Double_t>& pars); performs the fit by calliung Run(pars). » Author: Andreas Hoecker » Copyright (c) 2005: *; ",MatchSource.WIKI,root/html532/TMVA__MinuitFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MinuitFitter.html
https://root.cern/root/html532/TMVA__MinuitFitter.html:7818,Performance,perform,performs,7818,::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. virtual voidDeclareOptions(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringTMVA::FitterBase::fClassNameremove TMVA:: from TObject name; TMVA::IFitterTarget&TMVA::FitterBase::fFitterTargetpointer to target of fitting procedure; TMVA::MsgLogger*TMVA::FitterBase::fLoggermessage logger; TMVA::MinuitWrapper*fMinWrapholds a wrapper around TMinuit; Int_tTMVA::FitterBase::fNparsnumber of parameters; const vector<TMVA::Interval*>TMVA::FitterBase::fRangesallowed intervals. private:. Bool_tfBatchbatch mode; Int_tfErrorLevelminuit error level; Int_tfFitStrategyminuit strategy level; Int_tfMaxCalls(approximate) maximum number of function calls; Int_tfPrintLevelminuit printout level; Bool_tfPrintWarningsminuit warnings level; Double_tfTolerancetolerance to the function value at the minimum; Bool_tfUseImproveflag for 'IMPROVE' use; Bool_tfUseMinosflag for 'MINOS' use. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; ~MinuitFitter(); destructor. void DeclareOptions(); declare SA options. void Init(); minuit-specific settings. Double_t Run(vector<Double_t>& pars); performs the fit. Double_t EstimatorFunction(vector<Double_t>& pars); performs the fit by calliung Run(pars). » Author: Andreas Hoecker » Copyright (c) 2005: *; » Last changed: root/tmva $Id: MinuitFitter.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ,MatchSource.WIKI,root/html532/TMVA__MinuitFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MinuitFitter.html
https://root.cern/root/html532/TMVA__MinuitFitter.html:7888,Performance,perform,performs,7888,::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. virtual voidDeclareOptions(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringTMVA::FitterBase::fClassNameremove TMVA:: from TObject name; TMVA::IFitterTarget&TMVA::FitterBase::fFitterTargetpointer to target of fitting procedure; TMVA::MsgLogger*TMVA::FitterBase::fLoggermessage logger; TMVA::MinuitWrapper*fMinWrapholds a wrapper around TMinuit; Int_tTMVA::FitterBase::fNparsnumber of parameters; const vector<TMVA::Interval*>TMVA::FitterBase::fRangesallowed intervals. private:. Bool_tfBatchbatch mode; Int_tfErrorLevelminuit error level; Int_tfFitStrategyminuit strategy level; Int_tfMaxCalls(approximate) maximum number of function calls; Int_tfPrintLevelminuit printout level; Bool_tfPrintWarningsminuit warnings level; Double_tfTolerancetolerance to the function value at the minimum; Bool_tfUseImproveflag for 'IMPROVE' use; Bool_tfUseMinosflag for 'MINOS' use. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; ~MinuitFitter(); destructor. void DeclareOptions(); declare SA options. void Init(); minuit-specific settings. Double_t Run(vector<Double_t>& pars); performs the fit. Double_t EstimatorFunction(vector<Double_t>& pars); performs the fit by calliung Run(pars). » Author: Andreas Hoecker » Copyright (c) 2005: *; » Last changed: root/tmva $Id: MinuitFitter.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ,MatchSource.WIKI,root/html532/TMVA__MinuitFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MinuitFitter.html
https://root.cern/root/html532/TMVA__MinuitFitter.html:6988,Testability,log,logger,6988,"x) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&TMVA::FitterBase::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. virtual voidDeclareOptions(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringTMVA::FitterBase::fClassNameremove TMVA:: from TObject name; TMVA::IFitterTarget&TMVA::FitterBase::fFitterTargetpointer to target of fitting procedure; TMVA::MsgLogger*TMVA::FitterBase::fLoggermessage logger; TMVA::MinuitWrapper*fMinWrapholds a wrapper around TMinuit; Int_tTMVA::FitterBase::fNparsnumber of parameters; const vector<TMVA::Interval*>TMVA::FitterBase::fRangesallowed intervals. private:. Bool_tfBatchbatch mode; Int_tfErrorLevelminuit error level; Int_tfFitStrategyminuit strategy level; Int_tfMaxCalls(approximate) maximum number of function calls; Int_tfPrintLevelminuit printout level; Bool_tfPrintWarningsminuit warnings level; Double_tfTolerancetolerance to the function value at the minimum; Bool_tfUseImproveflag for 'IMPROVE' use; Bool_tfUseMinosflag for 'MINOS' use. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; ~MinuitFitter(); destructor. void DeclareOptions(); declare SA options. void Init(); minuit-specific settings. Double_t Run(vector<Double_t>& pars); performs the fit. Double_t EstimatorFunction(vector<Double_t>& pars); performs the fit by calliung Run(pars). » Author: Andreas Hoecker » Copyright (c) 2005: *; ",MatchSource.WIKI,root/html532/TMVA__MinuitFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MinuitFitter.html
https://root.cern/root/html532/TMVA__MinuitWrapper.html:1712,Availability,error,error,1712,"ject*Clone(const char*) const; virtual Int_tTMinuit::Command(const char* command); virtual Int_tTNamed::Compare(const TObject* obj) const; virtual TObject*TMinuit::Contour(Int_t npoints = 10, Int_t pa1 = 0, Int_t pa2 = 1); virtual voidTNamed::Copy(TObject& named) const; virtual Int_tTMinuit::DefineParameter(Int_t parNo, const char* name, Double_t initVal, Double_t initErr, Double_t lowerLimit, Double_t upperLimit); virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual voidTMinuit::DeleteArrays(); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual Int_tEval(Int_t, Double_t*, Double_t&, Double_t*, Int_t); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); Int_tExecuteCommand(const char* command, Double_t* args, Int_t nargs); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual voidTNamed::FillBuffer(char*& buffer); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Int_tTMinuit::FixParameter(Int_t parNo); virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); Int_tGetErrors(Int_t ipar, Double_t& eplus, Double_t& eminus, Double_t& eparab, Double_t& globcc); virtual const char*TObject::GetIconName() const; Int_tTMinuit::GetMaxIterations() const; TMethodCall*TMinuit::GetMethodCall() const; virtual const char*TNamed::GetName() const; virtual Int_tTMinuit::GetNumFixedPars() const; virtual Int_tTMinuit::GetNumFreePars() const; virtual Int_tTMinui",MatchSource.WIKI,root/html532/TMVA__MinuitWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MinuitWrapper.html
https://root.cern/root/html532/TMVA__MinuitWrapper.html:1796,Availability,error,error,1796,"irtual Int_tTNamed::Compare(const TObject* obj) const; virtual TObject*TMinuit::Contour(Int_t npoints = 10, Int_t pa1 = 0, Int_t pa2 = 1); virtual voidTNamed::Copy(TObject& named) const; virtual Int_tTMinuit::DefineParameter(Int_t parNo, const char* name, Double_t initVal, Double_t initErr, Double_t lowerLimit, Double_t upperLimit); virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual voidTMinuit::DeleteArrays(); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual Int_tEval(Int_t, Double_t*, Double_t&, Double_t*, Int_t); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); Int_tExecuteCommand(const char* command, Double_t* args, Int_t nargs); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual voidTNamed::FillBuffer(char*& buffer); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Int_tTMinuit::FixParameter(Int_t parNo); virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); Int_tGetErrors(Int_t ipar, Double_t& eplus, Double_t& eminus, Double_t& eparab, Double_t& globcc); virtual const char*TObject::GetIconName() const; Int_tTMinuit::GetMaxIterations() const; TMethodCall*TMinuit::GetMethodCall() const; virtual const char*TNamed::GetName() const; virtual Int_tTMinuit::GetNumFixedPars() const; virtual Int_tTMinuit::GetNumFreePars() const; virtual Int_tTMinuit::GetNumPars() const; TObject*TMinuit::GetObjectFit() const; virtual char*TObject::",MatchSource.WIKI,root/html532/TMVA__MinuitWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MinuitWrapper.html
https://root.cern/root/html532/TMVA__MinuitWrapper.html:5986,Availability,toler,toler,5986," Int_t mits, Double_t* work, Double_t precis, Int_t& ifault); virtual voidTMinuit::mnemat(Double_t* emat, Int_t ndim); virtual voidTMinuit::mnerrs(Int_t number, Double_t& eplus, Double_t& eminus, Double_t& eparab, Double_t& gcc); virtual voidTMinuit::mneval(Double_t anext, Double_t& fnext, Int_t& ierev); virtual voidTMinuit::mnexcm(const char* comand, Double_t* plist, Int_t llist, Int_t& ierflg); virtual voidTMinuit::mnexin(Double_t* pint); virtual voidTMinuit::mnfixp(Int_t iint, Int_t& ierr); virtual voidTMinuit::mnfree(Int_t k); virtual voidTMinuit::mngrad(); virtual voidTMinuit::mnhelp(TString comd); virtual voidTMinuit::mnhelp(const char* command = """"); virtual voidTMinuit::mnhes1(); virtual voidTMinuit::mnhess(); virtual voidTMinuit::mnimpr(); virtual voidTMinuit::mninex(Double_t* pint); virtual voidTMinuit::mninit(Int_t i1, Int_t i2, Int_t i3); virtual voidTMinuit::mnlims(); virtual voidTMinuit::mnline(Double_t* start, Double_t fstart, Double_t* step, Double_t slope, Double_t toler); virtual voidTMinuit::mnmatu(Int_t kode); virtual voidTMinuit::mnmigr(); virtual voidTMinuit::mnmnos(); virtual voidTMinuit::mnmnot(Int_t ilax, Int_t ilax2, Double_t& val2pl, Double_t& val2mi); virtual voidTMinuit::mnparm(Int_t k, TString cnamj, Double_t uk, Double_t wk, Double_t a, Double_t b, Int_t& ierflg); virtual voidTMinuit::mnpars(TString& crdbuf, Int_t& icondn); virtual voidTMinuit::mnpfit(Double_t* parx2p, Double_t* pary2p, Int_t npar2p, Double_t* coef2p, Double_t& sdev2p); virtual voidTMinuit::mnpint(Double_t& pexti, Int_t i, Double_t& pinti); virtual voidTMinuit::mnplot(Double_t* xpt, Double_t* ypt, char* chpt, Int_t nxypt, Int_t npagwd, Int_t npagln); virtual voidTMinuit::mnpout(Int_t iuext, TString& chnam, Double_t& val, Double_t& err, Double_t& xlolim, Double_t& xuplim, Int_t& iuint) const; virtual voidTMinuit::mnprin(Int_t inkode, Double_t fval); virtual voidTMinuit::mnpsdf(); virtual voidTMinuit::mnrazz(Double_t ynew, Double_t* pnew, Double_t* y, Int_t& jh, Int_t& j",MatchSource.WIKI,root/html532/TMVA__MinuitWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MinuitWrapper.html
https://root.cern/root/html532/TMVA__MinuitWrapper.html:12141,Availability,error,errors,12141,"t*TMinuit::fCONTgcc[fMaxpar] array used in mncont; Double_t*TMinuit::fCONTw[fMaxpar] array used in mncont; TStringTMinuit::fCfrom; char*TMinuit::fChpt!Character to be plotted at the X,Y contour positions; TStringTMinuit::fCovmes[4]; TString*TMinuit::fCpnam[fMaxpar2] Array of parameters names; TStringTMinuit::fCstatu; TStringTMinuit::fCtitl; TStringTMinuit::fCundef; TStringTMinuit::fCvrsn; TStringTMinuit::fCword; Double_tTMinuit::fDcovarRelative change in covariance matrix; Double_t*TMinuit::fDgrd[fMaxpar] Uncertainties; Double_t*TMinuit::fDirin[fMaxpar] (Internal) step sizes for current step; Double_t*TMinuit::fDirins[fMaxpar] (Internal) step sizes for current step for fixed params; Double_tTMinuit::fEDMEstimated vertical distance to the minimum; Int_tTMinuit::fEmptyInitialization flag (1 = Minuit initialized); Double_tTMinuit::fEpsi; Double_tTMinuit::fEpsma2sqrt(fEpsmac); Double_tTMinuit::fEpsmacmachine precision for floating points:; Double_t*TMinuit::fErn[fMaxpar] Negative Minos errors if calculated; Double_t*TMinuit::fErp[fMaxpar] Positive Minos errors if calculated; voidTMinuit::fFCN!; Double_t*TMinuit::fFIXPyy[fMaxpar] array used in mnfixp; Double_tTMinuit::fFval3; Double_t*TMinuit::fG2[fMaxpar] ; Double_t*TMinuit::fG2s[fMaxpar] ; Double_t*TMinuit::fGRADgf[fMaxpar] array used in mngrad; Double_t*TMinuit::fGin[fMaxpar2] ; Double_t*TMinuit::fGlobcc[fMaxpar] Global Correlation Coefficients; Bool_tTMinuit::fGraphicsModetrue if graphics mode on (default); Double_t*TMinuit::fGrd[fMaxpar] First derivatives; Double_t*TMinuit::fGrds[fMaxpar] ; Double_t*TMinuit::fGstep[fMaxpar] Step sizes; Double_t*TMinuit::fGsteps[fMaxpar] ; Double_t*TMinuit::fHESSyy[fMaxpar] array used in mnhess; Double_t*TMinuit::fIMPRdsav[fMaxpar] array used in mnimpr; Double_t*TMinuit::fIMPRy[fMaxpar] array used in mnimpr; Int_tTMinuit::fISW[7]Array of switches; Int_tTMinuit::fIcirc[2]; Int_tTMinuit::fIcomndNumber of commands; Int_tTMinuit::fIdbg[11]Array of internal debug switches; Int_t*TMinuit::f",MatchSource.WIKI,root/html532/TMVA__MinuitWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MinuitWrapper.html
https://root.cern/root/html532/TMVA__MinuitWrapper.html:12210,Availability,error,errors,12210,"fCONTw[fMaxpar] array used in mncont; TStringTMinuit::fCfrom; char*TMinuit::fChpt!Character to be plotted at the X,Y contour positions; TStringTMinuit::fCovmes[4]; TString*TMinuit::fCpnam[fMaxpar2] Array of parameters names; TStringTMinuit::fCstatu; TStringTMinuit::fCtitl; TStringTMinuit::fCundef; TStringTMinuit::fCvrsn; TStringTMinuit::fCword; Double_tTMinuit::fDcovarRelative change in covariance matrix; Double_t*TMinuit::fDgrd[fMaxpar] Uncertainties; Double_t*TMinuit::fDirin[fMaxpar] (Internal) step sizes for current step; Double_t*TMinuit::fDirins[fMaxpar] (Internal) step sizes for current step for fixed params; Double_tTMinuit::fEDMEstimated vertical distance to the minimum; Int_tTMinuit::fEmptyInitialization flag (1 = Minuit initialized); Double_tTMinuit::fEpsi; Double_tTMinuit::fEpsma2sqrt(fEpsmac); Double_tTMinuit::fEpsmacmachine precision for floating points:; Double_t*TMinuit::fErn[fMaxpar] Negative Minos errors if calculated; Double_t*TMinuit::fErp[fMaxpar] Positive Minos errors if calculated; voidTMinuit::fFCN!; Double_t*TMinuit::fFIXPyy[fMaxpar] array used in mnfixp; Double_tTMinuit::fFval3; Double_t*TMinuit::fG2[fMaxpar] ; Double_t*TMinuit::fG2s[fMaxpar] ; Double_t*TMinuit::fGRADgf[fMaxpar] array used in mngrad; Double_t*TMinuit::fGin[fMaxpar2] ; Double_t*TMinuit::fGlobcc[fMaxpar] Global Correlation Coefficients; Bool_tTMinuit::fGraphicsModetrue if graphics mode on (default); Double_t*TMinuit::fGrd[fMaxpar] First derivatives; Double_t*TMinuit::fGrds[fMaxpar] ; Double_t*TMinuit::fGstep[fMaxpar] Step sizes; Double_t*TMinuit::fGsteps[fMaxpar] ; Double_t*TMinuit::fHESSyy[fMaxpar] array used in mnhess; Double_t*TMinuit::fIMPRdsav[fMaxpar] array used in mnimpr; Double_t*TMinuit::fIMPRy[fMaxpar] array used in mnimpr; Int_tTMinuit::fISW[7]Array of switches; Int_tTMinuit::fIcirc[2]; Int_tTMinuit::fIcomndNumber of commands; Int_tTMinuit::fIdbg[11]Array of internal debug switches; Int_t*TMinuit::fIpfix[fMaxpar] List of fixed parameters; Int_tTMinuit::fIstkrd[10]; I",MatchSource.WIKI,root/html532/TMVA__MinuitWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MinuitWrapper.html
https://root.cern/root/html532/TMVA__MinuitWrapper.html:16626,Availability,error,errors,16626,,MatchSource.WIKI,root/html532/TMVA__MinuitWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MinuitWrapper.html
https://root.cern/root/html532/TMVA__MinuitWrapper.html:16901,Availability,error,error,16901,"TMinuit::fOrigin[100]; Double_t*TMinuit::fP[fMaxpar1] ; Double_t*TMinuit::fPARSplist[fMaxpar] array used in mnpars; Double_t*TMinuit::fPSDFs[fMaxpar] array used in mnpsdf; Double_t*TMinuit::fPbar[fMaxpar] ; TObject*TMinuit::fPlotPointer to TGraph object created by mncont; Double_t*TMinuit::fPrho[fMaxpar] Minimum point of parabola; Double_t*TMinuit::fPstar[fMaxpar2] ; Double_t*TMinuit::fPstst[fMaxpar] ; Double_t*TMinuit::fSEEKxbest[fMaxpar] array used in mnseek; Double_t*TMinuit::fSEEKxmid[fMaxpar] array used in mnseek; Double_t*TMinuit::fSIMPy[fMaxpar] array used in mnsimp; Int_tTMinuit::fStatusStatus flag for the last called Minuit function; Double_t*TMinuit::fU[fMaxpar2] External (visible to user in FCN) value of parameters; Double_tTMinuit::fUndefiUndefined number = -54321; Double_tTMinuit::fUpFCN+-UP defines errors (for chisquare fits UP=1); Double_tTMinuit::fUpdflt; Double_t*TMinuit::fVERTpp[fMaxpar] array used in mnvert; Double_t*TMinuit::fVERTq[fMaxpar] array used in mnvert; Double_t*TMinuit::fVERTs[fMaxpar] array used in mnvert; Double_t*TMinuit::fVhmat[fMaxpar5] (Internal) error matrix stored as Half MATrix, since it is symmetric; Double_tTMinuit::fVlimhi; Double_tTMinuit::fVlimlo; Double_t*TMinuit::fVthmat[fMaxpar5] VHMAT is sometimes saved in VTHMAT, especially in MNMNOT; TStringTMinuit::fWarmes[100]; Double_t*TMinuit::fWerr[fMaxpar] External parameters error (standard deviation, defined by UP); Double_t*TMinuit::fWord7[fMaxpar] ; Double_t*TMinuit::fX[fMaxpar] Internal parameters values; Double_tTMinuit::fXdircr; Double_tTMinuit::fXmidcr; Double_t*TMinuit::fXpt[fMaxcpt] X array of points for contours; Double_t*TMinuit::fXs[fMaxpar] Internal parameters values saved for fixed params; Double_t*TMinuit::fXt[fMaxpar] Internal parameters values X saved as Xt; Double_t*TMinuit::fXts[fMaxpar] Internal parameters values X saved as Xt for fixed params; Double_tTMinuit::fYdircr; Double_tTMinuit::fYmidcr; Double_t*TMinuit::fYpt[fMaxcpt] Y array of points for contours.",MatchSource.WIKI,root/html532/TMVA__MinuitWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MinuitWrapper.html
https://root.cern/root/html532/TMVA__MinuitWrapper.html:17189,Availability,error,error,17189,"TMinuit::fOrigin[100]; Double_t*TMinuit::fP[fMaxpar1] ; Double_t*TMinuit::fPARSplist[fMaxpar] array used in mnpars; Double_t*TMinuit::fPSDFs[fMaxpar] array used in mnpsdf; Double_t*TMinuit::fPbar[fMaxpar] ; TObject*TMinuit::fPlotPointer to TGraph object created by mncont; Double_t*TMinuit::fPrho[fMaxpar] Minimum point of parabola; Double_t*TMinuit::fPstar[fMaxpar2] ; Double_t*TMinuit::fPstst[fMaxpar] ; Double_t*TMinuit::fSEEKxbest[fMaxpar] array used in mnseek; Double_t*TMinuit::fSEEKxmid[fMaxpar] array used in mnseek; Double_t*TMinuit::fSIMPy[fMaxpar] array used in mnsimp; Int_tTMinuit::fStatusStatus flag for the last called Minuit function; Double_t*TMinuit::fU[fMaxpar2] External (visible to user in FCN) value of parameters; Double_tTMinuit::fUndefiUndefined number = -54321; Double_tTMinuit::fUpFCN+-UP defines errors (for chisquare fits UP=1); Double_tTMinuit::fUpdflt; Double_t*TMinuit::fVERTpp[fMaxpar] array used in mnvert; Double_t*TMinuit::fVERTq[fMaxpar] array used in mnvert; Double_t*TMinuit::fVERTs[fMaxpar] array used in mnvert; Double_t*TMinuit::fVhmat[fMaxpar5] (Internal) error matrix stored as Half MATrix, since it is symmetric; Double_tTMinuit::fVlimhi; Double_tTMinuit::fVlimlo; Double_t*TMinuit::fVthmat[fMaxpar5] VHMAT is sometimes saved in VTHMAT, especially in MNMNOT; TStringTMinuit::fWarmes[100]; Double_t*TMinuit::fWerr[fMaxpar] External parameters error (standard deviation, defined by UP); Double_t*TMinuit::fWord7[fMaxpar] ; Double_t*TMinuit::fX[fMaxpar] Internal parameters values; Double_tTMinuit::fXdircr; Double_tTMinuit::fXmidcr; Double_t*TMinuit::fXpt[fMaxcpt] X array of points for contours; Double_t*TMinuit::fXs[fMaxpar] Internal parameters values saved for fixed params; Double_t*TMinuit::fXt[fMaxpar] Internal parameters values X saved as Xt; Double_t*TMinuit::fXts[fMaxpar] Internal parameters values X saved as Xt for fixed params; Double_tTMinuit::fYdircr; Double_tTMinuit::fYmidcr; Double_t*TMinuit::fYpt[fMaxcpt] Y array of points for contours.",MatchSource.WIKI,root/html532/TMVA__MinuitWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MinuitWrapper.html
https://root.cern/root/html532/TMVA__MinuitWrapper.html:18916,Availability,error,errors,18916,"er Target; Int_tfNumParnumber of parameters; vector<Double_t>fParametersvector holding the current parameters . Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MinuitWrapper(TMVA::IFitterTarget& target, Int_t maxpar); constructor. Int_t Eval(Int_t , Double_t* , Double_t& , Double_t* , Int_t ); std::vector<Double_t> parameters( npar );. Int_t ExecuteCommand(const char* command, Double_t* args, Int_t nargs); Execute a fitter command;; command : command string; args : list of nargs command arguments. void Clear(Option_t* = 0); reset the fitter environment. Int_t GetStats(Double_t& amin, Double_t& edm, Double_t& errdef, Int_t& nvpar, Int_t& nparx); return global fit parameters; amin : chisquare; edm : estimated distance to minimum; errdef; nvpar : number of variable parameters; nparx : total number of parameters. Int_t GetErrors(Int_t ipar, Double_t& eplus, Double_t& eminus, Double_t& eparab, Double_t& globcc); return current errors for a parameter; ipar : parameter number; eplus : upper error; eminus : lower error; eparab : parabolic error; globcc : global correlation coefficient. Int_t SetParameter(Int_t ipar, const char* parname, Double_t value, Double_t verr, Double_t vlow, Double_t vhigh); set initial values for a parameter; ipar : parameter number; parname : parameter name; value : initial parameter value; verr : initial error for this parameter; vlow : lower value for the parameter; vhigh : upper value for the parameter. TObject * Clone(const char* ) const; produces a clone of this MinuitWrapper. virtual ~MinuitWrapper(); {}. void SetFitterTarget(TMVA::IFitterTarget& target); { fFitterTarget = target; }. » Author: Peter Speckmayer » Copyright (c) 2005: *; » Last changed: root/tmva $Id: MinuitWrapper.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT supp",MatchSource.WIKI,root/html532/TMVA__MinuitWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MinuitWrapper.html
https://root.cern/root/html532/TMVA__MinuitWrapper.html:18979,Availability,error,error,18979,"er Target; Int_tfNumParnumber of parameters; vector<Double_t>fParametersvector holding the current parameters . Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MinuitWrapper(TMVA::IFitterTarget& target, Int_t maxpar); constructor. Int_t Eval(Int_t , Double_t* , Double_t& , Double_t* , Int_t ); std::vector<Double_t> parameters( npar );. Int_t ExecuteCommand(const char* command, Double_t* args, Int_t nargs); Execute a fitter command;; command : command string; args : list of nargs command arguments. void Clear(Option_t* = 0); reset the fitter environment. Int_t GetStats(Double_t& amin, Double_t& edm, Double_t& errdef, Int_t& nvpar, Int_t& nparx); return global fit parameters; amin : chisquare; edm : estimated distance to minimum; errdef; nvpar : number of variable parameters; nparx : total number of parameters. Int_t GetErrors(Int_t ipar, Double_t& eplus, Double_t& eminus, Double_t& eparab, Double_t& globcc); return current errors for a parameter; ipar : parameter number; eplus : upper error; eminus : lower error; eparab : parabolic error; globcc : global correlation coefficient. Int_t SetParameter(Int_t ipar, const char* parname, Double_t value, Double_t verr, Double_t vlow, Double_t vhigh); set initial values for a parameter; ipar : parameter number; parname : parameter name; value : initial parameter value; verr : initial error for this parameter; vlow : lower value for the parameter; vhigh : upper value for the parameter. TObject * Clone(const char* ) const; produces a clone of this MinuitWrapper. virtual ~MinuitWrapper(); {}. void SetFitterTarget(TMVA::IFitterTarget& target); { fFitterTarget = target; }. » Author: Peter Speckmayer » Copyright (c) 2005: *; » Last changed: root/tmva $Id: MinuitWrapper.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT supp",MatchSource.WIKI,root/html532/TMVA__MinuitWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MinuitWrapper.html
https://root.cern/root/html532/TMVA__MinuitWrapper.html:19001,Availability,error,error,19001,"er Target; Int_tfNumParnumber of parameters; vector<Double_t>fParametersvector holding the current parameters . Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MinuitWrapper(TMVA::IFitterTarget& target, Int_t maxpar); constructor. Int_t Eval(Int_t , Double_t* , Double_t& , Double_t* , Int_t ); std::vector<Double_t> parameters( npar );. Int_t ExecuteCommand(const char* command, Double_t* args, Int_t nargs); Execute a fitter command;; command : command string; args : list of nargs command arguments. void Clear(Option_t* = 0); reset the fitter environment. Int_t GetStats(Double_t& amin, Double_t& edm, Double_t& errdef, Int_t& nvpar, Int_t& nparx); return global fit parameters; amin : chisquare; edm : estimated distance to minimum; errdef; nvpar : number of variable parameters; nparx : total number of parameters. Int_t GetErrors(Int_t ipar, Double_t& eplus, Double_t& eminus, Double_t& eparab, Double_t& globcc); return current errors for a parameter; ipar : parameter number; eplus : upper error; eminus : lower error; eparab : parabolic error; globcc : global correlation coefficient. Int_t SetParameter(Int_t ipar, const char* parname, Double_t value, Double_t verr, Double_t vlow, Double_t vhigh); set initial values for a parameter; ipar : parameter number; parname : parameter name; value : initial parameter value; verr : initial error for this parameter; vlow : lower value for the parameter; vhigh : upper value for the parameter. TObject * Clone(const char* ) const; produces a clone of this MinuitWrapper. virtual ~MinuitWrapper(); {}. void SetFitterTarget(TMVA::IFitterTarget& target); { fFitterTarget = target; }. » Author: Peter Speckmayer » Copyright (c) 2005: *; » Last changed: root/tmva $Id: MinuitWrapper.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT supp",MatchSource.WIKI,root/html532/TMVA__MinuitWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MinuitWrapper.html
https://root.cern/root/html532/TMVA__MinuitWrapper.html:19027,Availability,error,error,19027,"er Target; Int_tfNumParnumber of parameters; vector<Double_t>fParametersvector holding the current parameters . Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MinuitWrapper(TMVA::IFitterTarget& target, Int_t maxpar); constructor. Int_t Eval(Int_t , Double_t* , Double_t& , Double_t* , Int_t ); std::vector<Double_t> parameters( npar );. Int_t ExecuteCommand(const char* command, Double_t* args, Int_t nargs); Execute a fitter command;; command : command string; args : list of nargs command arguments. void Clear(Option_t* = 0); reset the fitter environment. Int_t GetStats(Double_t& amin, Double_t& edm, Double_t& errdef, Int_t& nvpar, Int_t& nparx); return global fit parameters; amin : chisquare; edm : estimated distance to minimum; errdef; nvpar : number of variable parameters; nparx : total number of parameters. Int_t GetErrors(Int_t ipar, Double_t& eplus, Double_t& eminus, Double_t& eparab, Double_t& globcc); return current errors for a parameter; ipar : parameter number; eplus : upper error; eminus : lower error; eparab : parabolic error; globcc : global correlation coefficient. Int_t SetParameter(Int_t ipar, const char* parname, Double_t value, Double_t verr, Double_t vlow, Double_t vhigh); set initial values for a parameter; ipar : parameter number; parname : parameter name; value : initial parameter value; verr : initial error for this parameter; vlow : lower value for the parameter; vhigh : upper value for the parameter. TObject * Clone(const char* ) const; produces a clone of this MinuitWrapper. virtual ~MinuitWrapper(); {}. void SetFitterTarget(TMVA::IFitterTarget& target); { fFitterTarget = target; }. » Author: Peter Speckmayer » Copyright (c) 2005: *; » Last changed: root/tmva $Id: MinuitWrapper.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT supp",MatchSource.WIKI,root/html532/TMVA__MinuitWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MinuitWrapper.html
https://root.cern/root/html532/TMVA__MinuitWrapper.html:19325,Availability,error,error,19325,"rget; Int_tfNumParnumber of parameters; vector<Double_t>fParametersvector holding the current parameters . Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MinuitWrapper(TMVA::IFitterTarget& target, Int_t maxpar); constructor. Int_t Eval(Int_t , Double_t* , Double_t& , Double_t* , Int_t ); std::vector<Double_t> parameters( npar );. Int_t ExecuteCommand(const char* command, Double_t* args, Int_t nargs); Execute a fitter command;; command : command string; args : list of nargs command arguments. void Clear(Option_t* = 0); reset the fitter environment. Int_t GetStats(Double_t& amin, Double_t& edm, Double_t& errdef, Int_t& nvpar, Int_t& nparx); return global fit parameters; amin : chisquare; edm : estimated distance to minimum; errdef; nvpar : number of variable parameters; nparx : total number of parameters. Int_t GetErrors(Int_t ipar, Double_t& eplus, Double_t& eminus, Double_t& eparab, Double_t& globcc); return current errors for a parameter; ipar : parameter number; eplus : upper error; eminus : lower error; eparab : parabolic error; globcc : global correlation coefficient. Int_t SetParameter(Int_t ipar, const char* parname, Double_t value, Double_t verr, Double_t vlow, Double_t vhigh); set initial values for a parameter; ipar : parameter number; parname : parameter name; value : initial parameter value; verr : initial error for this parameter; vlow : lower value for the parameter; vhigh : upper value for the parameter. TObject * Clone(const char* ) const; produces a clone of this MinuitWrapper. virtual ~MinuitWrapper(); {}. void SetFitterTarget(TMVA::IFitterTarget& target); { fFitterTarget = target; }. » Author: Peter Speckmayer » Copyright (c) 2005: *; » Last changed: root/tmva $Id: MinuitWrapper.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__MinuitWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MinuitWrapper.html
https://root.cern/root/html532/TMVA__MinuitWrapper.html:15068,Modifiability,variab,variable,15068,"if a heading should be put out for the next parameter definition; Bool_tTMinuit::fLreportrue if exceptional conditions are put out (default=false); Bool_tTMinuit::fLwarntrue if warning messges are to be put out (default=true); Double_t*TMinuit::fMATUvline[fMaxpar] array used in mnmatu; Double_t*TMinuit::fMIGRflnu[fMaxpar] array used in mnmigr; Double_t*TMinuit::fMIGRgs[fMaxpar] array used in mnmigr; Double_t*TMinuit::fMIGRstep[fMaxpar] array used in mnmigr; Double_t*TMinuit::fMIGRvg[fMaxpar] array used in mnmigr; Double_t*TMinuit::fMIGRxxs[fMaxpar] array used in mnmigr; Double_t*TMinuit::fMNOTgcc[fMaxpar] array used in mnmnot; Double_t*TMinuit::fMNOTw[fMaxpar] array used in mnmnot; Double_t*TMinuit::fMNOTxdev[fMaxpar] array used in mnmnot; Int_tTMinuit::fMaxIterationsMaximum number of iterations; Int_tTMinuit::fMaxcpt; Int_tTMinuit::fMaxextMaximum number of external parameters; Int_tTMinuit::fMaxintMaximum number of internal parameters; Int_tTMinuit::fMaxparMaximum number of parameters; Int_tTMinuit::fMaxpar1fMaxpar*(fMaxpar+1); Int_tTMinuit::fMaxpar2fMaxpar*fMaxpar; Int_tTMinuit::fMaxpar5fMaxpar*(fMaxpar+1)/2; TMethodCall*TMinuit::fMethodCallPointer to MethodCall in case of interpreted function; Int_tTMinuit::fNblockNumber of Minuit data blocks; Int_tTMinuit::fNewpag; Int_t*TMinuit::fNexofi[fMaxpar] External parameters number for currently variable parameters; Int_tTMinuit::fNfcnNumber of calls to FCN; Int_tTMinuit::fNfcnfr; Int_tTMinuit::fNfcnlc; Int_tTMinuit::fNfcnmxMaximum number of calls to FCN; Int_tTMinuit::fNfcwar[20]; Int_t*TMinuit::fNiofex[fMaxpar2] Internal parameters number, or zero if not currently variable; Int_tTMinuit::fNpaglnNumber of lines per page; Int_tTMinuit::fNpagwdPage width; Int_tTMinuit::fNparNumber of free parameters (total number of pars = fNpar + fNfix); Int_tTMinuit::fNpfixNumber of fixed parameters; Int_tTMinuit::fNstkrd; Int_tTMinuit::fNstkwr; Int_tTMinuit::fNu; Int_t*TMinuit::fNvarl[fMaxpar2] parameters flag (-1=undefined, 0=constant.",MatchSource.WIKI,root/html532/TMVA__MinuitWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MinuitWrapper.html
https://root.cern/root/html532/TMVA__MinuitWrapper.html:15344,Modifiability,variab,variable,15344,"if a heading should be put out for the next parameter definition; Bool_tTMinuit::fLreportrue if exceptional conditions are put out (default=false); Bool_tTMinuit::fLwarntrue if warning messges are to be put out (default=true); Double_t*TMinuit::fMATUvline[fMaxpar] array used in mnmatu; Double_t*TMinuit::fMIGRflnu[fMaxpar] array used in mnmigr; Double_t*TMinuit::fMIGRgs[fMaxpar] array used in mnmigr; Double_t*TMinuit::fMIGRstep[fMaxpar] array used in mnmigr; Double_t*TMinuit::fMIGRvg[fMaxpar] array used in mnmigr; Double_t*TMinuit::fMIGRxxs[fMaxpar] array used in mnmigr; Double_t*TMinuit::fMNOTgcc[fMaxpar] array used in mnmnot; Double_t*TMinuit::fMNOTw[fMaxpar] array used in mnmnot; Double_t*TMinuit::fMNOTxdev[fMaxpar] array used in mnmnot; Int_tTMinuit::fMaxIterationsMaximum number of iterations; Int_tTMinuit::fMaxcpt; Int_tTMinuit::fMaxextMaximum number of external parameters; Int_tTMinuit::fMaxintMaximum number of internal parameters; Int_tTMinuit::fMaxparMaximum number of parameters; Int_tTMinuit::fMaxpar1fMaxpar*(fMaxpar+1); Int_tTMinuit::fMaxpar2fMaxpar*fMaxpar; Int_tTMinuit::fMaxpar5fMaxpar*(fMaxpar+1)/2; TMethodCall*TMinuit::fMethodCallPointer to MethodCall in case of interpreted function; Int_tTMinuit::fNblockNumber of Minuit data blocks; Int_tTMinuit::fNewpag; Int_t*TMinuit::fNexofi[fMaxpar] External parameters number for currently variable parameters; Int_tTMinuit::fNfcnNumber of calls to FCN; Int_tTMinuit::fNfcnfr; Int_tTMinuit::fNfcnlc; Int_tTMinuit::fNfcnmxMaximum number of calls to FCN; Int_tTMinuit::fNfcwar[20]; Int_t*TMinuit::fNiofex[fMaxpar2] Internal parameters number, or zero if not currently variable; Int_tTMinuit::fNpaglnNumber of lines per page; Int_tTMinuit::fNpagwdPage width; Int_tTMinuit::fNparNumber of free parameters (total number of pars = fNpar + fNfix); Int_tTMinuit::fNpfixNumber of fixed parameters; Int_tTMinuit::fNstkrd; Int_tTMinuit::fNstkwr; Int_tTMinuit::fNu; Int_t*TMinuit::fNvarl[fMaxpar2] parameters flag (-1=undefined, 0=constant.",MatchSource.WIKI,root/html532/TMVA__MinuitWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MinuitWrapper.html
https://root.cern/root/html532/TMVA__MinuitWrapper.html:18744,Modifiability,variab,variable,18744," for fixed params; Double_tTMinuit::fYdircr; Double_tTMinuit::fYmidcr; Double_t*TMinuit::fYpt[fMaxcpt] Y array of points for contours. protected:. TStringTNamed::fNameobject identifier; TStringTNamed::fTitleobject title. private:. TMVA::IFitterTarget&fFitterTargetfitter Target; Int_tfNumParnumber of parameters; vector<Double_t>fParametersvector holding the current parameters . Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MinuitWrapper(TMVA::IFitterTarget& target, Int_t maxpar); constructor. Int_t Eval(Int_t , Double_t* , Double_t& , Double_t* , Int_t ); std::vector<Double_t> parameters( npar );. Int_t ExecuteCommand(const char* command, Double_t* args, Int_t nargs); Execute a fitter command;; command : command string; args : list of nargs command arguments. void Clear(Option_t* = 0); reset the fitter environment. Int_t GetStats(Double_t& amin, Double_t& edm, Double_t& errdef, Int_t& nvpar, Int_t& nparx); return global fit parameters; amin : chisquare; edm : estimated distance to minimum; errdef; nvpar : number of variable parameters; nparx : total number of parameters. Int_t GetErrors(Int_t ipar, Double_t& eplus, Double_t& eminus, Double_t& eparab, Double_t& globcc); return current errors for a parameter; ipar : parameter number; eplus : upper error; eminus : lower error; eparab : parabolic error; globcc : global correlation coefficient. Int_t SetParameter(Int_t ipar, const char* parname, Double_t value, Double_t verr, Double_t vlow, Double_t vhigh); set initial values for a parameter; ipar : parameter number; parname : parameter name; value : initial parameter value; verr : initial error for this parameter; vlow : lower value for the parameter; vhigh : upper value for the parameter. TObject * Clone(const char* ) const; produces a clone of this MinuitWrapper. virtual ~MinuitWrapper(); {}. void SetFitterTarget(TMVA::IFitterTarget& target); { fFitterTarget = target; }. » Author: Peter Speckmayer » Copyright (c) 2005: *; » L",MatchSource.WIKI,root/html532/TMVA__MinuitWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MinuitWrapper.html
https://root.cern/root/html532/TMVA__MisClassificationError.html:1476,Availability,error,error,1476,"le; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MisClassificationError. class TMVA::MisClassificationError: public TMVA::SeparationBase. Implementation of the MisClassificationError as separation criterion. Function Members (Methods); public:. virtual~MisClassificationError(); static TClass*Class(); const TString&TMVA::SeparationBase::GetName(); Double_tTMVA::SeparationBase::GetSeparationGain(const Double_t& nSelS, const Double_t& nSelB, const Double_t& nTotS, const Double_t& nTotB); virtual Double_tGetSeparationIndex(const Double_t& s, const Double_t& b); virtual TClass*IsA() const; TMVA::MisClassificationErrorMisClassificationError(); TMVA::MisClassificationErrorMisClassificationError(const TMVA::MisClassificationError& g); TMVA::MisClassificationError&operator=(const TMVA::MisClassificationError&); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). Data Members; protected:. TStringTMVA::SeparationBase::fNamename of the concrete Separation Index impementation; Double_tTMVA::SeparationBase::fPrecisionCut. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Double_t GetSeparationIndex(const Double_t& s, const Double_t& b); Misclassifiacton error criterion: 1-max(p, 1-p) (p: purity= s/(s+b)). MisClassificationError(); consturctor for the Misclassification error. { fName = ""MisCl""; }. MisClassificationError(const TMVA::MisClassificationError& g); copy constructor. {}. virtual ~MisClassificationError(); destructor. {}. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: MisClassificationError.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__MisClassificationError.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MisClassificationError.html
https://root.cern/root/html532/TMVA__MisClassificationError.html:1593,Availability,error,error,1593,"le; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MisClassificationError. class TMVA::MisClassificationError: public TMVA::SeparationBase. Implementation of the MisClassificationError as separation criterion. Function Members (Methods); public:. virtual~MisClassificationError(); static TClass*Class(); const TString&TMVA::SeparationBase::GetName(); Double_tTMVA::SeparationBase::GetSeparationGain(const Double_t& nSelS, const Double_t& nSelB, const Double_t& nTotS, const Double_t& nTotB); virtual Double_tGetSeparationIndex(const Double_t& s, const Double_t& b); virtual TClass*IsA() const; TMVA::MisClassificationErrorMisClassificationError(); TMVA::MisClassificationErrorMisClassificationError(const TMVA::MisClassificationError& g); TMVA::MisClassificationError&operator=(const TMVA::MisClassificationError&); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). Data Members; protected:. TStringTMVA::SeparationBase::fNamename of the concrete Separation Index impementation; Double_tTMVA::SeparationBase::fPrecisionCut. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Double_t GetSeparationIndex(const Double_t& s, const Double_t& b); Misclassifiacton error criterion: 1-max(p, 1-p) (p: purity= s/(s+b)). MisClassificationError(); consturctor for the Misclassification error. { fName = ""MisCl""; }. MisClassificationError(const TMVA::MisClassificationError& g); copy constructor. {}. virtual ~MisClassificationError(); destructor. {}. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: MisClassificationError.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__MisClassificationError.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MisClassificationError.html
https://root.cern/root/html532/TMVA__MsgLogger.html:1885,Availability,error,error,1885,"; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; basic_ios<char,char_traits<char> >&basic_ios<char,char_traits<char> >::copyfmt(const basic_ios<char,char_traits<char> >& rhs); virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; static voidEnableOutput(); static TMVA::MsgLogger&Endmsg(TMVA::MsgLogger& logger); boolbasic_ios<char,char_traits<char> >::eof() const; virtual voidTObject::Error(const char* method, const char* msgfmt) const; ios_base::iostatebasic_ios<char,char_traits<char> >::exceptions() const; voidbasic_ios<char,char_traits<char> >::exceptions(ios_base::iostate excpt); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); boolbasic_ios<char,char_traits<char> >::fail() const; virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; basic_ios<char,char_traits<char> >::char_typebasic_ios<char,char_traits<char> >::fill() const; basic_ios<char,char_traits<char> >::char_typebasic_ios<char,char_traits<char> >::fill(basic_ios<char,char_traits<char> >::char_type ch); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; ios_base::fmtflagsios_base::flags() const; ios_base::fmtflagsios_base::flags(ios_base::fmtflags fmtfl); basic_ostream<char,char_traits<char> >::__ostream_type&basic_ostream<char,char_traits<char> >::flush(); ostream&basic_ostream<char,char_traits<char> >::form(char* format); virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorO",MatchSource.WIKI,root/html532/TMVA__MsgLogger.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MsgLogger.html
https://root.cern/root/html532/TMVA__MsgLogger.html:1969,Availability,error,error,1969,"(TObject& object) const; basic_ios<char,char_traits<char> >&basic_ios<char,char_traits<char> >::copyfmt(const basic_ios<char,char_traits<char> >& rhs); virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; static voidEnableOutput(); static TMVA::MsgLogger&Endmsg(TMVA::MsgLogger& logger); boolbasic_ios<char,char_traits<char> >::eof() const; virtual voidTObject::Error(const char* method, const char* msgfmt) const; ios_base::iostatebasic_ios<char,char_traits<char> >::exceptions() const; voidbasic_ios<char,char_traits<char> >::exceptions(ios_base::iostate excpt); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); boolbasic_ios<char,char_traits<char> >::fail() const; virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; basic_ios<char,char_traits<char> >::char_typebasic_ios<char,char_traits<char> >::fill() const; basic_ios<char,char_traits<char> >::char_typebasic_ios<char,char_traits<char> >::fill(basic_ios<char,char_traits<char> >::char_type ch); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; ios_base::fmtflagsios_base::flags() const; ios_base::fmtflagsios_base::flags(ios_base::fmtflags fmtfl); basic_ostream<char,char_traits<char> >::__ostream_type&basic_ostream<char,char_traits<char> >::flush(); ostream&basic_ostream<char,char_traits<char> >::form(char* format); virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); stringGetFormattedSource() const; virtual const char*TObject::GetIconName() c",MatchSource.WIKI,root/html532/TMVA__MsgLogger.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MsgLogger.html
https://root.cern/root/html532/TMVA__MsgLogger.html:6992,Availability,mask,mask,6992,"ject::Read(const char* name); virtual voidTObject::RecursiveRemove(TObject* obj); voidios_base::register_callback(ios_base::event_callback fn, int index); voidTObject::ResetBit(UInt_t f); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); basic_ostream<char,char_traits<char> >::__ostream_type&basic_ostream<char,char_traits<char> >::seekp(basic_ostream<char,char_traits<char> >::pos_type pos); basic_ostream<char,char_traits<char> >::__ostream_type&basic_ostream<char,char_traits<char> >::seekp(basic_ostream<char,char_traits<char> >::off_type, ios_base::seekdir); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); ios_base::fmtflagsios_base::setf(ios_base::fmtflags fmtfl); ios_base::fmtflagsios_base::setf(ios_base::fmtflags fmtfl, ios_base::fmtflags mask); voidSetMinType(TMVA::EMsgType minType); static voidTObject::SetObjectStat(Bool_t stat); voidSetSource(const string& source); voidbasic_ios<char,char_traits<char> >::setstate(ios_base::iostate state); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); basic_ostringstream<char,char_traits<char>,allocator<char> >::__string_typebasic_ostringstream<char,char_traits<char>,allocator<char> >::str() const; voidbasic_ostringstream<char,char_traits<char>,allocator<char> >::str(const basic_ostringstream<char,char_traits<char>,allocator<char> >::__string_type& str); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); boolios_base::sync_with_stdio(bool sync = true); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; basic_ostream<char,char_traits<char> >::pos_typebasic_ostream<char,char_traits<char> >::tellp(); Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; basic_ostream<char,ch",MatchSource.WIKI,root/html532/TMVA__MsgLogger.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MsgLogger.html
https://root.cern/root/html532/TMVA__MsgLogger.html:8231,Availability,mask,mask,8231,"se::setf(ios_base::fmtflags fmtfl); ios_base::fmtflagsios_base::setf(ios_base::fmtflags fmtfl, ios_base::fmtflags mask); voidSetMinType(TMVA::EMsgType minType); static voidTObject::SetObjectStat(Bool_t stat); voidSetSource(const string& source); voidbasic_ios<char,char_traits<char> >::setstate(ios_base::iostate state); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); basic_ostringstream<char,char_traits<char>,allocator<char> >::__string_typebasic_ostringstream<char,char_traits<char>,allocator<char> >::str() const; voidbasic_ostringstream<char,char_traits<char>,allocator<char> >::str(const basic_ostringstream<char,char_traits<char>,allocator<char> >::__string_type& str); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); boolios_base::sync_with_stdio(bool sync = true); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; basic_ostream<char,char_traits<char> >::pos_typebasic_ostream<char,char_traits<char> >::tellp(); Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; basic_ostream<char,char_traits<char> >*basic_ios<char,char_traits<char> >::tie() const; basic_ostream<char,char_traits<char> >*basic_ios<char,char_traits<char> >::tie(basic_ostream<char,char_traits<char> >* tie_arg); voidios_base::unsetf(ios_base::fmtflags mask); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; charbasic_ios<char,char_traits<char> >::widen(char) const; streamsizeios_base::width() const; streamsizeios_base::width(streamsize wide); basic_ostream<char,char_traits<char> >::__ostream_type&basic_ostream<char,char_traits<char> >::write(const basic_ostream<char,char_traits<char> >::char_type* s, streamsize n); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; static intios_base::xalloc().",MatchSource.WIKI,root/html532/TMVA__MsgLogger.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MsgLogger.html
https://root.cern/root/html532/TMVA__MsgLogger.html:11422,Integrability,message,message,11422,"x of the source name; static const stringfgSuffixsuffix following source name; static map<EMsgType,std::string>*fgTypeMapmatches output types with strings. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; void InhibitOutput(); { fgInhibitOutput = kTRUE; }. void EnableOutput(). { fgInhibitOutput = kFALSE; }. MsgLogger(const TObject* source, TMVA::EMsgType minType = kINFO); constructor. MsgLogger(const string& source, TMVA::EMsgType minType = kINFO); constructor. MsgLogger( EMsgType minType ); constructor. MsgLogger( const MsgLogger& parent ); copy constructor. ~MsgLogger(); destructor. TMVA::MsgLogger& operator=(const TMVA::MsgLogger& parent); assingment operator. std::string GetFormattedSource() const; make sure the source name is no longer than fgMaxSourceSize:. std::string GetPrintedSource() const; the full logger prefix. void Send(); activates the logger writer. void WriteMsg(TMVA::EMsgType type, const string& line) const; putting the output string, the message type, and the color; switcher together into a single string. TMVA::MsgLogger& Endmsg(TMVA::MsgLogger& logger); end line. void InitMaps(); Create the message type and color maps. void SetSource(const string& source); Accessors. { fStrSource = source; }. EMsgType GetMinType() const; { return fMinType; }. void SetMinType(TMVA::EMsgType minType); { fMinType = minType; }. std::string GetSource() const; { return fStrSource; }. UInt_t GetMaxSourceSize(); { return (UInt_t)fgMaxSourceSize; }. MsgLogger& operator<<( MsgLogger& ( *_f )( MsgLogger& ) ); Accept stream modifiers. MsgLogger& operator<<( std::ostream& ( *_f )( std::ostream& ) ). » Author: Attila Krasznahorkay, Andreas Hoecker, Joerg Stelzer, Eckhard von Toerne » Copyright (c) 2005-2011: *; » Last changed: root/tmva $Id: MsgLogger.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in g",MatchSource.WIKI,root/html532/TMVA__MsgLogger.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MsgLogger.html
https://root.cern/root/html532/TMVA__MsgLogger.html:11579,Integrability,message,message,11579,"Suffixsuffix following source name; static map<EMsgType,std::string>*fgTypeMapmatches output types with strings. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; void InhibitOutput(); { fgInhibitOutput = kTRUE; }. void EnableOutput(). { fgInhibitOutput = kFALSE; }. MsgLogger(const TObject* source, TMVA::EMsgType minType = kINFO); constructor. MsgLogger(const string& source, TMVA::EMsgType minType = kINFO); constructor. MsgLogger( EMsgType minType ); constructor. MsgLogger( const MsgLogger& parent ); copy constructor. ~MsgLogger(); destructor. TMVA::MsgLogger& operator=(const TMVA::MsgLogger& parent); assingment operator. std::string GetFormattedSource() const; make sure the source name is no longer than fgMaxSourceSize:. std::string GetPrintedSource() const; the full logger prefix. void Send(); activates the logger writer. void WriteMsg(TMVA::EMsgType type, const string& line) const; putting the output string, the message type, and the color; switcher together into a single string. TMVA::MsgLogger& Endmsg(TMVA::MsgLogger& logger); end line. void InitMaps(); Create the message type and color maps. void SetSource(const string& source); Accessors. { fStrSource = source; }. EMsgType GetMinType() const; { return fMinType; }. void SetMinType(TMVA::EMsgType minType); { fMinType = minType; }. std::string GetSource() const; { return fStrSource; }. UInt_t GetMaxSourceSize(); { return (UInt_t)fgMaxSourceSize; }. MsgLogger& operator<<( MsgLogger& ( *_f )( MsgLogger& ) ); Accept stream modifiers. MsgLogger& operator<<( std::ostream& ( *_f )( std::ostream& ) ). » Author: Attila Krasznahorkay, Andreas Hoecker, Joerg Stelzer, Eckhard von Toerne » Copyright (c) 2005-2011: *; » Last changed: root/tmva $Id: MsgLogger.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__MsgLogger.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MsgLogger.html
https://root.cern/root/html532/TMVA__MsgLogger.html:1523,Testability,log,logger,1523,"n = """"); boolbasic_ios<char,char_traits<char> >::bad() const; virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); voidbasic_ios<char,char_traits<char> >::clear(ios_base::iostate state = goodbit); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; basic_ios<char,char_traits<char> >&basic_ios<char,char_traits<char> >::copyfmt(const basic_ios<char,char_traits<char> >& rhs); virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; static voidEnableOutput(); static TMVA::MsgLogger&Endmsg(TMVA::MsgLogger& logger); boolbasic_ios<char,char_traits<char> >::eof() const; virtual voidTObject::Error(const char* method, const char* msgfmt) const; ios_base::iostatebasic_ios<char,char_traits<char> >::exceptions() const; voidbasic_ios<char,char_traits<char> >::exceptions(ios_base::iostate excpt); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); boolbasic_ios<char,char_traits<char> >::fail() const; virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; basic_ios<char,char_traits<char> >::char_typebasic_ios<char,char_traits<char> >::fill() const; basic_ios<char,char_traits<char> >::char_typebasic_ios<char,char_traits<char> >::fill(basic_ios<char,char_traits<char> >::char_type ch); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) c",MatchSource.WIKI,root/html532/TMVA__MsgLogger.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MsgLogger.html
https://root.cern/root/html532/TMVA__MsgLogger.html:11272,Testability,log,logger,11272,"izemaximum length of source name; static Bool_tfgOutputSupresseddisable the output globaly (used by generic booster); static const stringfgPrefixthe prefix of the source name; static const stringfgSuffixsuffix following source name; static map<EMsgType,std::string>*fgTypeMapmatches output types with strings. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; void InhibitOutput(); { fgInhibitOutput = kTRUE; }. void EnableOutput(). { fgInhibitOutput = kFALSE; }. MsgLogger(const TObject* source, TMVA::EMsgType minType = kINFO); constructor. MsgLogger(const string& source, TMVA::EMsgType minType = kINFO); constructor. MsgLogger( EMsgType minType ); constructor. MsgLogger( const MsgLogger& parent ); copy constructor. ~MsgLogger(); destructor. TMVA::MsgLogger& operator=(const TMVA::MsgLogger& parent); assingment operator. std::string GetFormattedSource() const; make sure the source name is no longer than fgMaxSourceSize:. std::string GetPrintedSource() const; the full logger prefix. void Send(); activates the logger writer. void WriteMsg(TMVA::EMsgType type, const string& line) const; putting the output string, the message type, and the color; switcher together into a single string. TMVA::MsgLogger& Endmsg(TMVA::MsgLogger& logger); end line. void InitMaps(); Create the message type and color maps. void SetSource(const string& source); Accessors. { fStrSource = source; }. EMsgType GetMinType() const; { return fMinType; }. void SetMinType(TMVA::EMsgType minType); { fMinType = minType; }. std::string GetSource() const; { return fStrSource; }. UInt_t GetMaxSourceSize(); { return (UInt_t)fgMaxSourceSize; }. MsgLogger& operator<<( MsgLogger& ( *_f )( MsgLogger& ) ); Accept stream modifiers. MsgLogger& operator<<( std::ostream& ( *_f )( std::ostream& ) ). » Author: Attila Krasznahorkay, Andreas Hoecker, Joerg Stelzer, Eckhard von Toerne » Copyright (c) 2005-2011: *; » Last changed: root/tmva $Id: MsgLogger.h 40005 2011-06-27 15:29:10Z stel",MatchSource.WIKI,root/html532/TMVA__MsgLogger.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MsgLogger.html
https://root.cern/root/html532/TMVA__MsgLogger.html:11314,Testability,log,logger,11314,"putSupresseddisable the output globaly (used by generic booster); static const stringfgPrefixthe prefix of the source name; static const stringfgSuffixsuffix following source name; static map<EMsgType,std::string>*fgTypeMapmatches output types with strings. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; void InhibitOutput(); { fgInhibitOutput = kTRUE; }. void EnableOutput(). { fgInhibitOutput = kFALSE; }. MsgLogger(const TObject* source, TMVA::EMsgType minType = kINFO); constructor. MsgLogger(const string& source, TMVA::EMsgType minType = kINFO); constructor. MsgLogger( EMsgType minType ); constructor. MsgLogger( const MsgLogger& parent ); copy constructor. ~MsgLogger(); destructor. TMVA::MsgLogger& operator=(const TMVA::MsgLogger& parent); assingment operator. std::string GetFormattedSource() const; make sure the source name is no longer than fgMaxSourceSize:. std::string GetPrintedSource() const; the full logger prefix. void Send(); activates the logger writer. void WriteMsg(TMVA::EMsgType type, const string& line) const; putting the output string, the message type, and the color; switcher together into a single string. TMVA::MsgLogger& Endmsg(TMVA::MsgLogger& logger); end line. void InitMaps(); Create the message type and color maps. void SetSource(const string& source); Accessors. { fStrSource = source; }. EMsgType GetMinType() const; { return fMinType; }. void SetMinType(TMVA::EMsgType minType); { fMinType = minType; }. std::string GetSource() const; { return fStrSource; }. UInt_t GetMaxSourceSize(); { return (UInt_t)fgMaxSourceSize; }. MsgLogger& operator<<( MsgLogger& ( *_f )( MsgLogger& ) ); Accept stream modifiers. MsgLogger& operator<<( std::ostream& ( *_f )( std::ostream& ) ). » Author: Attila Krasznahorkay, Andreas Hoecker, Joerg Stelzer, Eckhard von Toerne » Copyright (c) 2005-2011: *; » Last changed: root/tmva $Id: MsgLogger.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page ",MatchSource.WIKI,root/html532/TMVA__MsgLogger.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MsgLogger.html
https://root.cern/root/html532/TMVA__MsgLogger.html:11532,Testability,log,logger,11532,"Suffixsuffix following source name; static map<EMsgType,std::string>*fgTypeMapmatches output types with strings. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; void InhibitOutput(); { fgInhibitOutput = kTRUE; }. void EnableOutput(). { fgInhibitOutput = kFALSE; }. MsgLogger(const TObject* source, TMVA::EMsgType minType = kINFO); constructor. MsgLogger(const string& source, TMVA::EMsgType minType = kINFO); constructor. MsgLogger( EMsgType minType ); constructor. MsgLogger( const MsgLogger& parent ); copy constructor. ~MsgLogger(); destructor. TMVA::MsgLogger& operator=(const TMVA::MsgLogger& parent); assingment operator. std::string GetFormattedSource() const; make sure the source name is no longer than fgMaxSourceSize:. std::string GetPrintedSource() const; the full logger prefix. void Send(); activates the logger writer. void WriteMsg(TMVA::EMsgType type, const string& line) const; putting the output string, the message type, and the color; switcher together into a single string. TMVA::MsgLogger& Endmsg(TMVA::MsgLogger& logger); end line. void InitMaps(); Create the message type and color maps. void SetSource(const string& source); Accessors. { fStrSource = source; }. EMsgType GetMinType() const; { return fMinType; }. void SetMinType(TMVA::EMsgType minType); { fMinType = minType; }. std::string GetSource() const; { return fStrSource; }. UInt_t GetMaxSourceSize(); { return (UInt_t)fgMaxSourceSize; }. MsgLogger& operator<<( MsgLogger& ( *_f )( MsgLogger& ) ); Accept stream modifiers. MsgLogger& operator<<( std::ostream& ( *_f )( std::ostream& ) ). » Author: Attila Krasznahorkay, Andreas Hoecker, Joerg Stelzer, Eckhard von Toerne » Copyright (c) 2005-2011: *; » Last changed: root/tmva $Id: MsgLogger.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__MsgLogger.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MsgLogger.html
https://root.cern/root/html532/TMVA__MsgLogger.html:784,Usability,clear,clear,784," virtual~MsgLogger(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); boolbasic_ios<char,char_traits<char> >::bad() const; virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); voidbasic_ios<char,char_traits<char> >::clear(ios_base::iostate state = goodbit); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; basic_ios<char,char_traits<char> >&basic_ios<char,char_traits<char> >::copyfmt(const basic_ios<char,char_traits<char> >& rhs); virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; static voidEnableOutput(); static TMVA::MsgLogger&Endmsg(TMVA::MsgLogger& logger); boolbasic_ios<char,char_traits<char> >::eof() const; virtual voidTObject::Error(const char* method, const char* msgfmt) const; ios_base::iostatebasic_ios<char,char_traits<char> >::exceptions() const; voidbasic_ios<char,char_traits<char> >::exceptions(ios_base::iostate excpt); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject:",MatchSource.WIKI,root/html532/TMVA__MsgLogger.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MsgLogger.html
https://root.cern/root/html532/TMVA__Node.html:723,Availability,avail,available,723,". TMVA::Node. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Node. class TMVA::Node. Node for the BinarySearch or Decision Trees. For the binary search tree, it basically consists of the EVENT, and; pointers to the parent and daughters. In case of the Decision Tree, it specifies parent and daughters, as; well as ""which variable is used"" in the selection of this node,; including the respective cut value. Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~Node(); virtual voidAddAttributesToNode(void* node) const; virtual voidAddContentToNode(stringstream& s) const; void*AddXMLTo(void* parent) const; static TClass*Class(); Int_tCountMeAndAllDaughters() const; virtual TMVA::Node*CreateNode() const; intGetCount(); UInt_tGetDepth() const; virtual TMVA::Node*GetLeft() const; virtual TMVA::Node*GetParent() const; virtual TMVA::BinaryTree*GetParentTree() const; charGetPos() const; virtual TMVA::Node*GetRight() const; virtual Bool_tGoesLeft(const TMVA::Event&) const; virtual Bool_tGoesRight(const TMVA::Event&) const; virtual TClass*IsA() const; TMVA::Node&operator=(const TMVA::Node&); virtual voidPrint(ostream& os) const; virtual voidPrintRec(ostream& os) const; virtual voidReadAttributes(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); virtual voidReadContent(stringstream& s); virtual Bool_tReadDataRecord(istream&, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); voidReadXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); voidSetDepth(UInt_t d); virtual voidSetLeft(TMVA::Node* l); virtual voidSetParent(TMVA::Node* p); virtual voidSetParentTree(TMVA::BinaryTree* t); voidSetPos(char s); virtual voidSetRight(TMVA::Node* r); virtual voidShowMembers(TMemberInsp",MatchSource.WIKI,root/html532/TMVA__Node.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Node.html
https://root.cern/root/html532/TMVA__Node.html:503,Modifiability,variab,variable,503,". TMVA::Node. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Node. class TMVA::Node. Node for the BinarySearch or Decision Trees. For the binary search tree, it basically consists of the EVENT, and; pointers to the parent and daughters. In case of the Decision Tree, it specifies parent and daughters, as; well as ""which variable is used"" in the selection of this node,; including the respective cut value. Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~Node(); virtual voidAddAttributesToNode(void* node) const; virtual voidAddContentToNode(stringstream& s) const; void*AddXMLTo(void* parent) const; static TClass*Class(); Int_tCountMeAndAllDaughters() const; virtual TMVA::Node*CreateNode() const; intGetCount(); UInt_tGetDepth() const; virtual TMVA::Node*GetLeft() const; virtual TMVA::Node*GetParent() const; virtual TMVA::BinaryTree*GetParentTree() const; charGetPos() const; virtual TMVA::Node*GetRight() const; virtual Bool_tGoesLeft(const TMVA::Event&) const; virtual Bool_tGoesRight(const TMVA::Event&) const; virtual TClass*IsA() const; TMVA::Node&operator=(const TMVA::Node&); virtual voidPrint(ostream& os) const; virtual voidPrintRec(ostream& os) const; virtual voidReadAttributes(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); virtual voidReadContent(stringstream& s); virtual Bool_tReadDataRecord(istream&, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); voidReadXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); voidSetDepth(UInt_t d); virtual voidSetLeft(TMVA::Node* l); virtual voidSetParent(TMVA::Node* p); virtual voidSetParentTree(TMVA::BinaryTree* t); voidSetPos(char s); virtual voidSetRight(TMVA::Node* r); virtual voidShowMembers(TMemberInsp",MatchSource.WIKI,root/html532/TMVA__Node.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Node.html
https://root.cern/root/html532/TMVA__Node.html:3108,Testability,test,test,3108,"fDepthdepth of the node within the tree (seen from root node); TMVA::Node*fLeftpointers to the two ""daughter"" nodes; TMVA::Node*fParentthe previous (parent) node; TMVA::BinaryTree*fParentTreepointer to the parent tree to which the Node belongs ; charfPosposition, i.e. it is a left (l) or right (r) daughter ; TMVA::Node*fRightpointers to the two ""daughter"" nodes. private:. static Int_tfgCountcounter of all nodes present.. for debug.. to spot memory leaks... Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; ~Node(); node destructor. int GetCount(); retuns the global number of instantiated nodes. Int_t CountMeAndAllDaughters() const; recursively go through the part of the tree below this node and count all daughters. void* AddXMLTo(void* parent) const; add attributes to XML. void ReadXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); read attributes from XML. Node* CreateNode() const. Bool_t GoesRight(const TMVA::Event& ) const; test event if i{ decends the tree at this node to the right. Bool_t GoesLeft(const TMVA::Event& ) const; test event if it decends the tree at this node to the left. Node* GetLeft() const; test event if it is equal to the event that ""makes the node"" (just for the ""search tree""; return pointer to the left/right daughter or parent node. { return fLeft; }. Node* GetRight() const; { return fRight; }. Node* GetParent() const; { return fParent; }. void SetLeft(TMVA::Node* l); set pointer to the left/right daughter or parent node. { fLeft = l;}. void SetRight(TMVA::Node* r); { fRight = r;}. void SetParent(TMVA::Node* p); { fParent = p;}. void Print(ostream& os) const; printout of the node. void PrintRec(ostream& os) const; recursive printout of the node and it daughters. void AddAttributesToNode(void* node) const. void AddContentToNode(stringstream& s) const. void SetDepth(UInt_t d); Set depth, layer of the where the node is within the tree, seen from the top (root). {fDepth=d;}. UInt_t GetDepth() co",MatchSource.WIKI,root/html532/TMVA__Node.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Node.html
https://root.cern/root/html532/TMVA__Node.html:3213,Testability,test,test,3213,"ter"" nodes; TMVA::Node*fParentthe previous (parent) node; TMVA::BinaryTree*fParentTreepointer to the parent tree to which the Node belongs ; charfPosposition, i.e. it is a left (l) or right (r) daughter ; TMVA::Node*fRightpointers to the two ""daughter"" nodes. private:. static Int_tfgCountcounter of all nodes present.. for debug.. to spot memory leaks... Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; ~Node(); node destructor. int GetCount(); retuns the global number of instantiated nodes. Int_t CountMeAndAllDaughters() const; recursively go through the part of the tree below this node and count all daughters. void* AddXMLTo(void* parent) const; add attributes to XML. void ReadXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); read attributes from XML. Node* CreateNode() const. Bool_t GoesRight(const TMVA::Event& ) const; test event if i{ decends the tree at this node to the right. Bool_t GoesLeft(const TMVA::Event& ) const; test event if it decends the tree at this node to the left. Node* GetLeft() const; test event if it is equal to the event that ""makes the node"" (just for the ""search tree""; return pointer to the left/right daughter or parent node. { return fLeft; }. Node* GetRight() const; { return fRight; }. Node* GetParent() const; { return fParent; }. void SetLeft(TMVA::Node* l); set pointer to the left/right daughter or parent node. { fLeft = l;}. void SetRight(TMVA::Node* r); { fRight = r;}. void SetParent(TMVA::Node* p); { fParent = p;}. void Print(ostream& os) const; printout of the node. void PrintRec(ostream& os) const; recursive printout of the node and it daughters. void AddAttributesToNode(void* node) const. void AddContentToNode(stringstream& s) const. void SetDepth(UInt_t d); Set depth, layer of the where the node is within the tree, seen from the top (root). {fDepth=d;}. UInt_t GetDepth() const; Return depth, layer of the where the node is within the tree, seen from the top (root). {return fDep",MatchSource.WIKI,root/html532/TMVA__Node.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Node.html
https://root.cern/root/html532/TMVA__Node.html:3296,Testability,test,test,3296,"s ; charfPosposition, i.e. it is a left (l) or right (r) daughter ; TMVA::Node*fRightpointers to the two ""daughter"" nodes. private:. static Int_tfgCountcounter of all nodes present.. for debug.. to spot memory leaks... Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; ~Node(); node destructor. int GetCount(); retuns the global number of instantiated nodes. Int_t CountMeAndAllDaughters() const; recursively go through the part of the tree below this node and count all daughters. void* AddXMLTo(void* parent) const; add attributes to XML. void ReadXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); read attributes from XML. Node* CreateNode() const. Bool_t GoesRight(const TMVA::Event& ) const; test event if i{ decends the tree at this node to the right. Bool_t GoesLeft(const TMVA::Event& ) const; test event if it decends the tree at this node to the left. Node* GetLeft() const; test event if it is equal to the event that ""makes the node"" (just for the ""search tree""; return pointer to the left/right daughter or parent node. { return fLeft; }. Node* GetRight() const; { return fRight; }. Node* GetParent() const; { return fParent; }. void SetLeft(TMVA::Node* l); set pointer to the left/right daughter or parent node. { fLeft = l;}. void SetRight(TMVA::Node* r); { fRight = r;}. void SetParent(TMVA::Node* p); { fParent = p;}. void Print(ostream& os) const; printout of the node. void PrintRec(ostream& os) const; recursive printout of the node and it daughters. void AddAttributesToNode(void* node) const. void AddContentToNode(stringstream& s) const. void SetDepth(UInt_t d); Set depth, layer of the where the node is within the tree, seen from the top (root). {fDepth=d;}. UInt_t GetDepth() const; Return depth, layer of the where the node is within the tree, seen from the top (root). {return fDepth;}. void SetPos(char s); set node position, i.e, the node is a left (l) or right (r) daugther. {fPos=s;}. char GetPos() const; Return th",MatchSource.WIKI,root/html532/TMVA__Node.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Node.html
https://root.cern/root/html532/TMVA__OptimizeConfigParameters.html:3952,Availability,reliab,reliably,3952,"d::vector< int > GetScanIndices(int val, vector<int> base); helper function to scan through the all the combinations in the; parameter space. void optimizeScan(); do the actual optimization using a simple scan method,; i.e. calcualte the FOM for; different tuning paraemters and remember which one is; gave the best FOM. void optimizeFit(); ranges (intervals) in which the fit varies the parameters. Double_t EstimatorFunction(vector<Double_t>& ); return the estimator (from current FOM) for the fitting interface. Double_t GetFOM(); Return the Figure of Merit (FOM) used in the parameter; optimization process. void GetMVADists(); fill the private histograms with the mva distributinos for sig/bkg. Double_t GetSeparation(); return the searation between the signal and background; MVA ouput distribution. Double_t GetROCIntegral(); calculate the area (integral) under the ROC curve as a; overall quality measure of the classification. makeing pdfs out of the MVA-ouput distributions doesn't work; reliably for cases where the MVA-ouput isn't a smooth distribution.; this happens ""frequently"" in BDTs for example when the number of; trees is small resulting in only some discrete possible MVA ouput values.; (I still leave the code here, but use this with care!!! The default; however is to use the distributions!!!. Double_t GetSigEffAtBkgEff(Double_t bkgEff = 0.1); calculate the signal efficiency for a given background efficiency. Double_t GetBkgEffAtSigEff(Double_t sigEff = 0.5); calculate the background efficiency for a given signal efficiency. Double_t GetBkgRejAtSigEff(Double_t sigEff = 0.5); calculate the background rejection for a given signal efficiency. OptimizeConfigParameters(TMVA::MethodBase *const method, map<TString,TMVA::Interval> tuneParameters, TString fomType = ""Separation"", TString optimizationType = ""GA""); default constructor. MethodBase* GetMethod(); {return fMethod;}. » Last changed: Thu Nov 3 20:19:51 2011 » Last generated: 2011-11-03 20:19; This page has been aut",MatchSource.WIKI,root/html532/TMVA__OptimizeConfigParameters.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__OptimizeConfigParameters.html
https://root.cern/root/html532/TMVA__OptimizeConfigParameters.html:3458,Integrability,interface,interface,3458,"tring,Double_t>fTunedParametersparameters included in the tuning. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; OptimizeConfigParameters(TMVA::MethodBase *const method, map<TString,TMVA::Interval> tuneParameters, TString fomType = ""Separation"", TString optimizationType = ""GA""); Constructor which sets either ""Classification or Regression"". ~OptimizeConfigParameters(); the destructor (delete the OptimizeConfigParameters, store the graph and .. delete it). std::map<TString,Double_t> optimize(). std::vector< int > GetScanIndices(int val, vector<int> base); helper function to scan through the all the combinations in the; parameter space. void optimizeScan(); do the actual optimization using a simple scan method,; i.e. calcualte the FOM for; different tuning paraemters and remember which one is; gave the best FOM. void optimizeFit(); ranges (intervals) in which the fit varies the parameters. Double_t EstimatorFunction(vector<Double_t>& ); return the estimator (from current FOM) for the fitting interface. Double_t GetFOM(); Return the Figure of Merit (FOM) used in the parameter; optimization process. void GetMVADists(); fill the private histograms with the mva distributinos for sig/bkg. Double_t GetSeparation(); return the searation between the signal and background; MVA ouput distribution. Double_t GetROCIntegral(); calculate the area (integral) under the ROC curve as a; overall quality measure of the classification. makeing pdfs out of the MVA-ouput distributions doesn't work; reliably for cases where the MVA-ouput isn't a smooth distribution.; this happens ""frequently"" in BDTs for example when the number of; trees is small resulting in only some discrete possible MVA ouput values.; (I still leave the code here, but use this with care!!! The default; however is to use the distributions!!!. Double_t GetSigEffAtBkgEff(Double_t bkgEff = 0.1); calculate the signal efficiency for a given background efficiency. Double_t GetBkgEffAtSi",MatchSource.WIKI,root/html532/TMVA__OptimizeConfigParameters.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__OptimizeConfigParameters.html
https://root.cern/root/html532/TMVA__OptimizeConfigParameters.html:580,Performance,optimiz,optimize,580,". TMVA::OptimizeConfigParameters. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::OptimizeConfigParameters. class TMVA::OptimizeConfigParameters: public TMVA::IFitterTarget. Function Members (Methods); public:. virtual~OptimizeConfigParameters(); static TClass*Class(); virtual TClass*IsA() const; TMVA::IFitterTarget&TMVA::IFitterTarget::operator=(const TMVA::IFitterTarget&); map<TString,Double_t>optimize(); TMVA::OptimizeConfigParametersOptimizeConfigParameters(const TMVA::OptimizeConfigParameters&); TMVA::OptimizeConfigParametersOptimizeConfigParameters(TMVA::MethodBase *const method, map<TString,TMVA::Interval> tuneParameters, TString fomType = ""Separation"", TString optimizationType = ""GA""); virtual voidTMVA::IFitterTarget::ProgressNotifier(TString, TString); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). private:. virtual Double_tEstimatorFunction(vector<Double_t>&); Double_tGetBkgEffAtSigEff(Double_t sigEff = 0.5); Double_tGetBkgRejAtSigEff(Double_t sigEff = 0.5); Double_tGetFOM(); TMVA::MethodBase*GetMethod(); voidGetMVADists(); Double_tGetROCIntegral(); vector<int>GetScanIndices(int val, vector<int> base); Double_tGetSeparation(); Double_tGetSigEffAtBkgEff(Double_t bkgEff = 0.1); TMVA::MsgLogger&Log() const; voidoptimizeFit(); voidoptimizeScan(). Data Members; private:. map<std::vector<Double_t>,Double_t>fAlreadyTrainedParCombinationsave parameters for which the FOM is already known (GA seems to evaluate the same parameters several times); TStringfFOMTypethe FOM type (Separation, ROC integra.. whaeter you implemented..; vector<Float_t>fFOMvsItergraph showing the develompment of the Figure Of Merit values during the fit; TMVA::MsgLogger*fLoggermessage logger; TMVA::MethodBase *constfMethodThe MVA method to be evalua",MatchSource.WIKI,root/html532/TMVA__OptimizeConfigParameters.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__OptimizeConfigParameters.html
https://root.cern/root/html532/TMVA__OptimizeConfigParameters.html:802,Performance,tune,tuneParameters,802,". TMVA::OptimizeConfigParameters. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::OptimizeConfigParameters. class TMVA::OptimizeConfigParameters: public TMVA::IFitterTarget. Function Members (Methods); public:. virtual~OptimizeConfigParameters(); static TClass*Class(); virtual TClass*IsA() const; TMVA::IFitterTarget&TMVA::IFitterTarget::operator=(const TMVA::IFitterTarget&); map<TString,Double_t>optimize(); TMVA::OptimizeConfigParametersOptimizeConfigParameters(const TMVA::OptimizeConfigParameters&); TMVA::OptimizeConfigParametersOptimizeConfigParameters(TMVA::MethodBase *const method, map<TString,TMVA::Interval> tuneParameters, TString fomType = ""Separation"", TString optimizationType = ""GA""); virtual voidTMVA::IFitterTarget::ProgressNotifier(TString, TString); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). private:. virtual Double_tEstimatorFunction(vector<Double_t>&); Double_tGetBkgEffAtSigEff(Double_t sigEff = 0.5); Double_tGetBkgRejAtSigEff(Double_t sigEff = 0.5); Double_tGetFOM(); TMVA::MethodBase*GetMethod(); voidGetMVADists(); Double_tGetROCIntegral(); vector<int>GetScanIndices(int val, vector<int> base); Double_tGetSeparation(); Double_tGetSigEffAtBkgEff(Double_t bkgEff = 0.1); TMVA::MsgLogger&Log() const; voidoptimizeFit(); voidoptimizeScan(). Data Members; private:. map<std::vector<Double_t>,Double_t>fAlreadyTrainedParCombinationsave parameters for which the FOM is already known (GA seems to evaluate the same parameters several times); TStringfFOMTypethe FOM type (Separation, ROC integra.. whaeter you implemented..; vector<Float_t>fFOMvsItergraph showing the develompment of the Figure Of Merit values during the fit; TMVA::MsgLogger*fLoggermessage logger; TMVA::MethodBase *constfMethodThe MVA method to be evalua",MatchSource.WIKI,root/html532/TMVA__OptimizeConfigParameters.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__OptimizeConfigParameters.html
https://root.cern/root/html532/TMVA__OptimizeConfigParameters.html:858,Performance,optimiz,optimizationType,858,". TMVA::OptimizeConfigParameters. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::OptimizeConfigParameters. class TMVA::OptimizeConfigParameters: public TMVA::IFitterTarget. Function Members (Methods); public:. virtual~OptimizeConfigParameters(); static TClass*Class(); virtual TClass*IsA() const; TMVA::IFitterTarget&TMVA::IFitterTarget::operator=(const TMVA::IFitterTarget&); map<TString,Double_t>optimize(); TMVA::OptimizeConfigParametersOptimizeConfigParameters(const TMVA::OptimizeConfigParameters&); TMVA::OptimizeConfigParametersOptimizeConfigParameters(TMVA::MethodBase *const method, map<TString,TMVA::Interval> tuneParameters, TString fomType = ""Separation"", TString optimizationType = ""GA""); virtual voidTMVA::IFitterTarget::ProgressNotifier(TString, TString); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). private:. virtual Double_tEstimatorFunction(vector<Double_t>&); Double_tGetBkgEffAtSigEff(Double_t sigEff = 0.5); Double_tGetBkgRejAtSigEff(Double_t sigEff = 0.5); Double_tGetFOM(); TMVA::MethodBase*GetMethod(); voidGetMVADists(); Double_tGetROCIntegral(); vector<int>GetScanIndices(int val, vector<int> base); Double_tGetSeparation(); Double_tGetSigEffAtBkgEff(Double_t bkgEff = 0.1); TMVA::MsgLogger&Log() const; voidoptimizeFit(); voidoptimizeScan(). Data Members; private:. map<std::vector<Double_t>,Double_t>fAlreadyTrainedParCombinationsave parameters for which the FOM is already known (GA seems to evaluate the same parameters several times); TStringfFOMTypethe FOM type (Separation, ROC integra.. whaeter you implemented..; vector<Float_t>fFOMvsItergraph showing the develompment of the Figure Of Merit values during the fit; TMVA::MsgLogger*fLoggermessage logger; TMVA::MethodBase *constfMethodThe MVA method to be evalua",MatchSource.WIKI,root/html532/TMVA__OptimizeConfigParameters.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__OptimizeConfigParameters.html
https://root.cern/root/html532/TMVA__OptimizeConfigParameters.html:2652,Performance,tune,tuneParameters,2652,"eems to evaluate the same parameters several times); TStringfFOMTypethe FOM type (Separation, ROC integra.. whaeter you implemented..; vector<Float_t>fFOMvsItergraph showing the develompment of the Figure Of Merit values during the fit; TMVA::MsgLogger*fLoggermessage logger; TMVA::MethodBase *constfMethodThe MVA method to be evaluated; TH1D*fMvaBkgMVA distrituion for bakgr. events, used for spline fit; TH1D*fMvaBkgFineBinMVA distrituion for bakgr. events; TH1D*fMvaSigMVA distrituion for signal events, used for spline fit; TH1D*fMvaSigFineBinMVA distrituion for signal events; TStringfOptimizationFitTypewhich type of optimisation procedure to be used ; map<TString,TMVA::Interval>fTuneParametersparameters included in the tuning; map<TString,Double_t>fTunedParametersparameters included in the tuning. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; OptimizeConfigParameters(TMVA::MethodBase *const method, map<TString,TMVA::Interval> tuneParameters, TString fomType = ""Separation"", TString optimizationType = ""GA""); Constructor which sets either ""Classification or Regression"". ~OptimizeConfigParameters(); the destructor (delete the OptimizeConfigParameters, store the graph and .. delete it). std::map<TString,Double_t> optimize(). std::vector< int > GetScanIndices(int val, vector<int> base); helper function to scan through the all the combinations in the; parameter space. void optimizeScan(); do the actual optimization using a simple scan method,; i.e. calcualte the FOM for; different tuning paraemters and remember which one is; gave the best FOM. void optimizeFit(); ranges (intervals) in which the fit varies the parameters. Double_t EstimatorFunction(vector<Double_t>& ); return the estimator (from current FOM) for the fitting interface. Double_t GetFOM(); Return the Figure of Merit (FOM) used in the parameter; optimization process. void GetMVADists(); fill the private histograms with the mva distributinos for sig/bkg. Double_t GetSep",MatchSource.WIKI,root/html532/TMVA__OptimizeConfigParameters.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__OptimizeConfigParameters.html
https://root.cern/root/html532/TMVA__OptimizeConfigParameters.html:2708,Performance,optimiz,optimizationType,2708,"eems to evaluate the same parameters several times); TStringfFOMTypethe FOM type (Separation, ROC integra.. whaeter you implemented..; vector<Float_t>fFOMvsItergraph showing the develompment of the Figure Of Merit values during the fit; TMVA::MsgLogger*fLoggermessage logger; TMVA::MethodBase *constfMethodThe MVA method to be evaluated; TH1D*fMvaBkgMVA distrituion for bakgr. events, used for spline fit; TH1D*fMvaBkgFineBinMVA distrituion for bakgr. events; TH1D*fMvaSigMVA distrituion for signal events, used for spline fit; TH1D*fMvaSigFineBinMVA distrituion for signal events; TStringfOptimizationFitTypewhich type of optimisation procedure to be used ; map<TString,TMVA::Interval>fTuneParametersparameters included in the tuning; map<TString,Double_t>fTunedParametersparameters included in the tuning. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; OptimizeConfigParameters(TMVA::MethodBase *const method, map<TString,TMVA::Interval> tuneParameters, TString fomType = ""Separation"", TString optimizationType = ""GA""); Constructor which sets either ""Classification or Regression"". ~OptimizeConfigParameters(); the destructor (delete the OptimizeConfigParameters, store the graph and .. delete it). std::map<TString,Double_t> optimize(). std::vector< int > GetScanIndices(int val, vector<int> base); helper function to scan through the all the combinations in the; parameter space. void optimizeScan(); do the actual optimization using a simple scan method,; i.e. calcualte the FOM for; different tuning paraemters and remember which one is; gave the best FOM. void optimizeFit(); ranges (intervals) in which the fit varies the parameters. Double_t EstimatorFunction(vector<Double_t>& ); return the estimator (from current FOM) for the fitting interface. Double_t GetFOM(); Return the Figure of Merit (FOM) used in the parameter; optimization process. void GetMVADists(); fill the private histograms with the mva distributinos for sig/bkg. Double_t GetSep",MatchSource.WIKI,root/html532/TMVA__OptimizeConfigParameters.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__OptimizeConfigParameters.html
https://root.cern/root/html532/TMVA__OptimizeConfigParameters.html:2940,Performance,optimiz,optimize,2940,"sage logger; TMVA::MethodBase *constfMethodThe MVA method to be evaluated; TH1D*fMvaBkgMVA distrituion for bakgr. events, used for spline fit; TH1D*fMvaBkgFineBinMVA distrituion for bakgr. events; TH1D*fMvaSigMVA distrituion for signal events, used for spline fit; TH1D*fMvaSigFineBinMVA distrituion for signal events; TStringfOptimizationFitTypewhich type of optimisation procedure to be used ; map<TString,TMVA::Interval>fTuneParametersparameters included in the tuning; map<TString,Double_t>fTunedParametersparameters included in the tuning. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; OptimizeConfigParameters(TMVA::MethodBase *const method, map<TString,TMVA::Interval> tuneParameters, TString fomType = ""Separation"", TString optimizationType = ""GA""); Constructor which sets either ""Classification or Regression"". ~OptimizeConfigParameters(); the destructor (delete the OptimizeConfigParameters, store the graph and .. delete it). std::map<TString,Double_t> optimize(). std::vector< int > GetScanIndices(int val, vector<int> base); helper function to scan through the all the combinations in the; parameter space. void optimizeScan(); do the actual optimization using a simple scan method,; i.e. calcualte the FOM for; different tuning paraemters and remember which one is; gave the best FOM. void optimizeFit(); ranges (intervals) in which the fit varies the parameters. Double_t EstimatorFunction(vector<Double_t>& ); return the estimator (from current FOM) for the fitting interface. Double_t GetFOM(); Return the Figure of Merit (FOM) used in the parameter; optimization process. void GetMVADists(); fill the private histograms with the mva distributinos for sig/bkg. Double_t GetSeparation(); return the searation between the signal and background; MVA ouput distribution. Double_t GetROCIntegral(); calculate the area (integral) under the ROC curve as a; overall quality measure of the classification. makeing pdfs out of the MVA-ouput distribu",MatchSource.WIKI,root/html532/TMVA__OptimizeConfigParameters.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__OptimizeConfigParameters.html
https://root.cern/root/html532/TMVA__OptimizeConfigParameters.html:3101,Performance,optimiz,optimizeScan,3101,"vaSigMVA distrituion for signal events, used for spline fit; TH1D*fMvaSigFineBinMVA distrituion for signal events; TStringfOptimizationFitTypewhich type of optimisation procedure to be used ; map<TString,TMVA::Interval>fTuneParametersparameters included in the tuning; map<TString,Double_t>fTunedParametersparameters included in the tuning. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; OptimizeConfigParameters(TMVA::MethodBase *const method, map<TString,TMVA::Interval> tuneParameters, TString fomType = ""Separation"", TString optimizationType = ""GA""); Constructor which sets either ""Classification or Regression"". ~OptimizeConfigParameters(); the destructor (delete the OptimizeConfigParameters, store the graph and .. delete it). std::map<TString,Double_t> optimize(). std::vector< int > GetScanIndices(int val, vector<int> base); helper function to scan through the all the combinations in the; parameter space. void optimizeScan(); do the actual optimization using a simple scan method,; i.e. calcualte the FOM for; different tuning paraemters and remember which one is; gave the best FOM. void optimizeFit(); ranges (intervals) in which the fit varies the parameters. Double_t EstimatorFunction(vector<Double_t>& ); return the estimator (from current FOM) for the fitting interface. Double_t GetFOM(); Return the Figure of Merit (FOM) used in the parameter; optimization process. void GetMVADists(); fill the private histograms with the mva distributinos for sig/bkg. Double_t GetSeparation(); return the searation between the signal and background; MVA ouput distribution. Double_t GetROCIntegral(); calculate the area (integral) under the ROC curve as a; overall quality measure of the classification. makeing pdfs out of the MVA-ouput distributions doesn't work; reliably for cases where the MVA-ouput isn't a smooth distribution.; this happens ""frequently"" in BDTs for example when the number of; trees is small resulting in only some discrete p",MatchSource.WIKI,root/html532/TMVA__OptimizeConfigParameters.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__OptimizeConfigParameters.html
https://root.cern/root/html532/TMVA__OptimizeConfigParameters.html:3131,Performance,optimiz,optimization,3131,"vaSigMVA distrituion for signal events, used for spline fit; TH1D*fMvaSigFineBinMVA distrituion for signal events; TStringfOptimizationFitTypewhich type of optimisation procedure to be used ; map<TString,TMVA::Interval>fTuneParametersparameters included in the tuning; map<TString,Double_t>fTunedParametersparameters included in the tuning. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; OptimizeConfigParameters(TMVA::MethodBase *const method, map<TString,TMVA::Interval> tuneParameters, TString fomType = ""Separation"", TString optimizationType = ""GA""); Constructor which sets either ""Classification or Regression"". ~OptimizeConfigParameters(); the destructor (delete the OptimizeConfigParameters, store the graph and .. delete it). std::map<TString,Double_t> optimize(). std::vector< int > GetScanIndices(int val, vector<int> base); helper function to scan through the all the combinations in the; parameter space. void optimizeScan(); do the actual optimization using a simple scan method,; i.e. calcualte the FOM for; different tuning paraemters and remember which one is; gave the best FOM. void optimizeFit(); ranges (intervals) in which the fit varies the parameters. Double_t EstimatorFunction(vector<Double_t>& ); return the estimator (from current FOM) for the fitting interface. Double_t GetFOM(); Return the Figure of Merit (FOM) used in the parameter; optimization process. void GetMVADists(); fill the private histograms with the mva distributinos for sig/bkg. Double_t GetSeparation(); return the searation between the signal and background; MVA ouput distribution. Double_t GetROCIntegral(); calculate the area (integral) under the ROC curve as a; overall quality measure of the classification. makeing pdfs out of the MVA-ouput distributions doesn't work; reliably for cases where the MVA-ouput isn't a smooth distribution.; this happens ""frequently"" in BDTs for example when the number of; trees is small resulting in only some discrete p",MatchSource.WIKI,root/html532/TMVA__OptimizeConfigParameters.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__OptimizeConfigParameters.html
https://root.cern/root/html532/TMVA__OptimizeConfigParameters.html:3280,Performance,optimiz,optimizeFit,3280," to be used ; map<TString,TMVA::Interval>fTuneParametersparameters included in the tuning; map<TString,Double_t>fTunedParametersparameters included in the tuning. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; OptimizeConfigParameters(TMVA::MethodBase *const method, map<TString,TMVA::Interval> tuneParameters, TString fomType = ""Separation"", TString optimizationType = ""GA""); Constructor which sets either ""Classification or Regression"". ~OptimizeConfigParameters(); the destructor (delete the OptimizeConfigParameters, store the graph and .. delete it). std::map<TString,Double_t> optimize(). std::vector< int > GetScanIndices(int val, vector<int> base); helper function to scan through the all the combinations in the; parameter space. void optimizeScan(); do the actual optimization using a simple scan method,; i.e. calcualte the FOM for; different tuning paraemters and remember which one is; gave the best FOM. void optimizeFit(); ranges (intervals) in which the fit varies the parameters. Double_t EstimatorFunction(vector<Double_t>& ); return the estimator (from current FOM) for the fitting interface. Double_t GetFOM(); Return the Figure of Merit (FOM) used in the parameter; optimization process. void GetMVADists(); fill the private histograms with the mva distributinos for sig/bkg. Double_t GetSeparation(); return the searation between the signal and background; MVA ouput distribution. Double_t GetROCIntegral(); calculate the area (integral) under the ROC curve as a; overall quality measure of the classification. makeing pdfs out of the MVA-ouput distributions doesn't work; reliably for cases where the MVA-ouput isn't a smooth distribution.; this happens ""frequently"" in BDTs for example when the number of; trees is small resulting in only some discrete possible MVA ouput values.; (I still leave the code here, but use this with care!!! The default; however is to use the distributions!!!. Double_t GetSigEffAtBkgEff(Double_t bkgEff ",MatchSource.WIKI,root/html532/TMVA__OptimizeConfigParameters.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__OptimizeConfigParameters.html
https://root.cern/root/html532/TMVA__OptimizeConfigParameters.html:3544,Performance,optimiz,optimization,3544,"bers; Includes; Libraries. Function documentation; OptimizeConfigParameters(TMVA::MethodBase *const method, map<TString,TMVA::Interval> tuneParameters, TString fomType = ""Separation"", TString optimizationType = ""GA""); Constructor which sets either ""Classification or Regression"". ~OptimizeConfigParameters(); the destructor (delete the OptimizeConfigParameters, store the graph and .. delete it). std::map<TString,Double_t> optimize(). std::vector< int > GetScanIndices(int val, vector<int> base); helper function to scan through the all the combinations in the; parameter space. void optimizeScan(); do the actual optimization using a simple scan method,; i.e. calcualte the FOM for; different tuning paraemters and remember which one is; gave the best FOM. void optimizeFit(); ranges (intervals) in which the fit varies the parameters. Double_t EstimatorFunction(vector<Double_t>& ); return the estimator (from current FOM) for the fitting interface. Double_t GetFOM(); Return the Figure of Merit (FOM) used in the parameter; optimization process. void GetMVADists(); fill the private histograms with the mva distributinos for sig/bkg. Double_t GetSeparation(); return the searation between the signal and background; MVA ouput distribution. Double_t GetROCIntegral(); calculate the area (integral) under the ROC curve as a; overall quality measure of the classification. makeing pdfs out of the MVA-ouput distributions doesn't work; reliably for cases where the MVA-ouput isn't a smooth distribution.; this happens ""frequently"" in BDTs for example when the number of; trees is small resulting in only some discrete possible MVA ouput values.; (I still leave the code here, but use this with care!!! The default; however is to use the distributions!!!. Double_t GetSigEffAtBkgEff(Double_t bkgEff = 0.1); calculate the signal efficiency for a given background efficiency. Double_t GetBkgEffAtSigEff(Double_t sigEff = 0.5); calculate the background efficiency for a given signal efficiency. Double_t G",MatchSource.WIKI,root/html532/TMVA__OptimizeConfigParameters.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__OptimizeConfigParameters.html
https://root.cern/root/html532/TMVA__OptimizeConfigParameters.html:4709,Performance,tune,tuneParameters,4709,"r space. void optimizeScan(); do the actual optimization using a simple scan method,; i.e. calcualte the FOM for; different tuning paraemters and remember which one is; gave the best FOM. void optimizeFit(); ranges (intervals) in which the fit varies the parameters. Double_t EstimatorFunction(vector<Double_t>& ); return the estimator (from current FOM) for the fitting interface. Double_t GetFOM(); Return the Figure of Merit (FOM) used in the parameter; optimization process. void GetMVADists(); fill the private histograms with the mva distributinos for sig/bkg. Double_t GetSeparation(); return the searation between the signal and background; MVA ouput distribution. Double_t GetROCIntegral(); calculate the area (integral) under the ROC curve as a; overall quality measure of the classification. makeing pdfs out of the MVA-ouput distributions doesn't work; reliably for cases where the MVA-ouput isn't a smooth distribution.; this happens ""frequently"" in BDTs for example when the number of; trees is small resulting in only some discrete possible MVA ouput values.; (I still leave the code here, but use this with care!!! The default; however is to use the distributions!!!. Double_t GetSigEffAtBkgEff(Double_t bkgEff = 0.1); calculate the signal efficiency for a given background efficiency. Double_t GetBkgEffAtSigEff(Double_t sigEff = 0.5); calculate the background efficiency for a given signal efficiency. Double_t GetBkgRejAtSigEff(Double_t sigEff = 0.5); calculate the background rejection for a given signal efficiency. OptimizeConfigParameters(TMVA::MethodBase *const method, map<TString,TMVA::Interval> tuneParameters, TString fomType = ""Separation"", TString optimizationType = ""GA""); default constructor. MethodBase* GetMethod(); {return fMethod;}. » Last changed: Thu Nov 3 20:19:51 2011 » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__OptimizeConfigParameters.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__OptimizeConfigParameters.html
https://root.cern/root/html532/TMVA__OptimizeConfigParameters.html:4765,Performance,optimiz,optimizationType,4765,"r space. void optimizeScan(); do the actual optimization using a simple scan method,; i.e. calcualte the FOM for; different tuning paraemters and remember which one is; gave the best FOM. void optimizeFit(); ranges (intervals) in which the fit varies the parameters. Double_t EstimatorFunction(vector<Double_t>& ); return the estimator (from current FOM) for the fitting interface. Double_t GetFOM(); Return the Figure of Merit (FOM) used in the parameter; optimization process. void GetMVADists(); fill the private histograms with the mva distributinos for sig/bkg. Double_t GetSeparation(); return the searation between the signal and background; MVA ouput distribution. Double_t GetROCIntegral(); calculate the area (integral) under the ROC curve as a; overall quality measure of the classification. makeing pdfs out of the MVA-ouput distributions doesn't work; reliably for cases where the MVA-ouput isn't a smooth distribution.; this happens ""frequently"" in BDTs for example when the number of; trees is small resulting in only some discrete possible MVA ouput values.; (I still leave the code here, but use this with care!!! The default; however is to use the distributions!!!. Double_t GetSigEffAtBkgEff(Double_t bkgEff = 0.1); calculate the signal efficiency for a given background efficiency. Double_t GetBkgEffAtSigEff(Double_t sigEff = 0.5); calculate the background efficiency for a given signal efficiency. Double_t GetBkgRejAtSigEff(Double_t sigEff = 0.5); calculate the background rejection for a given signal efficiency. OptimizeConfigParameters(TMVA::MethodBase *const method, map<TString,TMVA::Interval> tuneParameters, TString fomType = ""Separation"", TString optimizationType = ""GA""); default constructor. MethodBase* GetMethod(); {return fMethod;}. » Last changed: Thu Nov 3 20:19:51 2011 » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__OptimizeConfigParameters.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__OptimizeConfigParameters.html
https://root.cern/root/html532/TMVA__OptimizeConfigParameters.html:1936,Testability,log,logger,1936,"essNotifier(TString, TString); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). private:. virtual Double_tEstimatorFunction(vector<Double_t>&); Double_tGetBkgEffAtSigEff(Double_t sigEff = 0.5); Double_tGetBkgRejAtSigEff(Double_t sigEff = 0.5); Double_tGetFOM(); TMVA::MethodBase*GetMethod(); voidGetMVADists(); Double_tGetROCIntegral(); vector<int>GetScanIndices(int val, vector<int> base); Double_tGetSeparation(); Double_tGetSigEffAtBkgEff(Double_t bkgEff = 0.1); TMVA::MsgLogger&Log() const; voidoptimizeFit(); voidoptimizeScan(). Data Members; private:. map<std::vector<Double_t>,Double_t>fAlreadyTrainedParCombinationsave parameters for which the FOM is already known (GA seems to evaluate the same parameters several times); TStringfFOMTypethe FOM type (Separation, ROC integra.. whaeter you implemented..; vector<Float_t>fFOMvsItergraph showing the develompment of the Figure Of Merit values during the fit; TMVA::MsgLogger*fLoggermessage logger; TMVA::MethodBase *constfMethodThe MVA method to be evaluated; TH1D*fMvaBkgMVA distrituion for bakgr. events, used for spline fit; TH1D*fMvaBkgFineBinMVA distrituion for bakgr. events; TH1D*fMvaSigMVA distrituion for signal events, used for spline fit; TH1D*fMvaSigFineBinMVA distrituion for signal events; TStringfOptimizationFitTypewhich type of optimisation procedure to be used ; map<TString,TMVA::Interval>fTuneParametersparameters included in the tuning; map<TString,Double_t>fTunedParametersparameters included in the tuning. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; OptimizeConfigParameters(TMVA::MethodBase *const method, map<TString,TMVA::Interval> tuneParameters, TString fomType = ""Separation"", TString optimizationType = ""GA""); Constructor which sets either ""Classification or Regression"". ~OptimizeConfigParameters(); the destructor (delete the OptimizeConfigParameters, store the graph and .. delete it). std::map<T",MatchSource.WIKI,root/html532/TMVA__OptimizeConfigParameters.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__OptimizeConfigParameters.html
https://root.cern/root/html532/TMVA__OptimizeConfigParameters.html:3152,Usability,simpl,simple,3152,"vaSigMVA distrituion for signal events, used for spline fit; TH1D*fMvaSigFineBinMVA distrituion for signal events; TStringfOptimizationFitTypewhich type of optimisation procedure to be used ; map<TString,TMVA::Interval>fTuneParametersparameters included in the tuning; map<TString,Double_t>fTunedParametersparameters included in the tuning. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; OptimizeConfigParameters(TMVA::MethodBase *const method, map<TString,TMVA::Interval> tuneParameters, TString fomType = ""Separation"", TString optimizationType = ""GA""); Constructor which sets either ""Classification or Regression"". ~OptimizeConfigParameters(); the destructor (delete the OptimizeConfigParameters, store the graph and .. delete it). std::map<TString,Double_t> optimize(). std::vector< int > GetScanIndices(int val, vector<int> base); helper function to scan through the all the combinations in the; parameter space. void optimizeScan(); do the actual optimization using a simple scan method,; i.e. calcualte the FOM for; different tuning paraemters and remember which one is; gave the best FOM. void optimizeFit(); ranges (intervals) in which the fit varies the parameters. Double_t EstimatorFunction(vector<Double_t>& ); return the estimator (from current FOM) for the fitting interface. Double_t GetFOM(); Return the Figure of Merit (FOM) used in the parameter; optimization process. void GetMVADists(); fill the private histograms with the mva distributinos for sig/bkg. Double_t GetSeparation(); return the searation between the signal and background; MVA ouput distribution. Double_t GetROCIntegral(); calculate the area (integral) under the ROC curve as a; overall quality measure of the classification. makeing pdfs out of the MVA-ouput distributions doesn't work; reliably for cases where the MVA-ouput isn't a smooth distribution.; this happens ""frequently"" in BDTs for example when the number of; trees is small resulting in only some discrete p",MatchSource.WIKI,root/html532/TMVA__OptimizeConfigParameters.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__OptimizeConfigParameters.html
https://root.cern/root/html532/TMVA__PDEFoam.html:2813,Availability,error,error,2813,"AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidCheckAll(Int_t); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; voidCreate(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidDeleteBinarySearchTree(); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); TH1D*Draw1Dim(TMVA::ECellValue cell_value, Int_t nbin, TMVA::PDEFoamKernelBase* kernel = NULL); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; voidFillBinarySearchTree(const TMVA::Event* ev); virtual voidFillFoamCells(const TMVA::Event* ev, Float_t wt); virtual voidFinalize(); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual vector<Float_t>GetCellValue(const map<Int_t,Float_t>& xvec, TMVA::ECellValue cv); virtual Float_tGetCellValue(const TMVA::PDEFoamCell* cell, TMVA::ECellValue cv); virtual Float_tGetCellValue(const vector<Float_t>& xvec, TMVA::ECellValue cv, TMVA::PDEFoamKernelBase*); virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TStringGetFoamName() const; virtual const char*TObject::GetIconName() const; UInt_tGetMaxDepth() const; UInt_tGetNActiveCells() const; virtual c",MatchSource.WIKI,root/html532/TMVA__PDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoam.html
https://root.cern/root/html532/TMVA__PDEFoam.html:2897,Availability,error,error,2897,"kAll(Int_t); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; voidCreate(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidDeleteBinarySearchTree(); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); TH1D*Draw1Dim(TMVA::ECellValue cell_value, Int_t nbin, TMVA::PDEFoamKernelBase* kernel = NULL); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; voidFillBinarySearchTree(const TMVA::Event* ev); virtual voidFillFoamCells(const TMVA::Event* ev, Float_t wt); virtual voidFinalize(); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual vector<Float_t>GetCellValue(const map<Int_t,Float_t>& xvec, TMVA::ECellValue cv); virtual Float_tGetCellValue(const TMVA::PDEFoamCell* cell, TMVA::ECellValue cv); virtual Float_tGetCellValue(const vector<Float_t>& xvec, TMVA::ECellValue cv, TMVA::PDEFoamKernelBase*); virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TStringGetFoamName() const; virtual const char*TObject::GetIconName() const; UInt_tGetMaxDepth() const; UInt_tGetNActiveCells() const; virtual const char*TObject::GetName() const; UInt_tGetNCells() const; UInt_tGetNInActiveCells",MatchSource.WIKI,root/html532/TMVA__PDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoam.html
https://root.cern/root/html532/TMVA__PDEFoam.html:15120,Availability,failure,failures,15120,"x is added to list of vertices.; List of active cells is updated, iCell removed, two daughters added; and their properties set with help of MC sampling (PDEFoam_Explore); Returns Code RC=-1 of buffer limit is reached, fLastCe=fnBuf. Double_t Eval(Double_t* xRand, Double_t& event_density); Internal subprogram.; Evaluates (training) distribution. void Grow(); Internal subrogram used by Create.; It grow new cells by the binary division process.; This function is overridden by the PDEFoam class to stop the foam buildup process; if one of the cut conditions stop the cell split. void SetInhiDiv(Int_t , Int_t ); This can be called before Create, after setting kDim; It defines which variables are excluded in the process of the cell division.; For example 'FoamX->SetInhiDiv(1, 1);' inhibits division of y-variable. void CheckAll(Int_t ); User utility, miscellaneous and debug.; Checks all pointers in the tree of cells. This is useful autodiagnostic.; level=0, no printout, failures causes STOP; level=1, printout, failures lead to WARNINGS only. void PrintCell(Long_t iCell = 0); Prints geometry of and elements of 'iCell', as well as relations; to parent and daughter cells. void PrintCells(void); Prints geometry of ALL cells of the FOAM. void FillFoamCells(const TMVA::Event* ev, Float_t wt); This function fills a weight 'wt' into the PDEFoam cell, which; corresponds to the given event 'ev'. Per default cell element 0; is filled with the weight 'wt', and cell element 1 is filled; with the squared weight. This function can be overridden by a; subclass in order to change the values stored in the foam cells. void ResetCellElements(); Remove the cell elements from all cells. Bool_t CellValueIsUndefined(TMVA::PDEFoamCell* ); Returns true, if the value of the given cell is undefined.; Default value: kFALSE. This function can be overridden by; sub-classes. Float_t GetCellValue(const vector<Float_t>& xvec, TMVA::ECellValue cv, TMVA::PDEFoamKernelBase* ); This function finds the cell, whic",MatchSource.WIKI,root/html532/TMVA__PDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoam.html
https://root.cern/root/html532/TMVA__PDEFoam.html:15161,Availability,failure,failures,15161,"x is added to list of vertices.; List of active cells is updated, iCell removed, two daughters added; and their properties set with help of MC sampling (PDEFoam_Explore); Returns Code RC=-1 of buffer limit is reached, fLastCe=fnBuf. Double_t Eval(Double_t* xRand, Double_t& event_density); Internal subprogram.; Evaluates (training) distribution. void Grow(); Internal subrogram used by Create.; It grow new cells by the binary division process.; This function is overridden by the PDEFoam class to stop the foam buildup process; if one of the cut conditions stop the cell split. void SetInhiDiv(Int_t , Int_t ); This can be called before Create, after setting kDim; It defines which variables are excluded in the process of the cell division.; For example 'FoamX->SetInhiDiv(1, 1);' inhibits division of y-variable. void CheckAll(Int_t ); User utility, miscellaneous and debug.; Checks all pointers in the tree of cells. This is useful autodiagnostic.; level=0, no printout, failures causes STOP; level=1, printout, failures lead to WARNINGS only. void PrintCell(Long_t iCell = 0); Prints geometry of and elements of 'iCell', as well as relations; to parent and daughter cells. void PrintCells(void); Prints geometry of ALL cells of the FOAM. void FillFoamCells(const TMVA::Event* ev, Float_t wt); This function fills a weight 'wt' into the PDEFoam cell, which; corresponds to the given event 'ev'. Per default cell element 0; is filled with the weight 'wt', and cell element 1 is filled; with the squared weight. This function can be overridden by a; subclass in order to change the values stored in the foam cells. void ResetCellElements(); Remove the cell elements from all cells. Bool_t CellValueIsUndefined(TMVA::PDEFoamCell* ); Returns true, if the value of the given cell is undefined.; Default value: kFALSE. This function can be overridden by; sub-classes. Float_t GetCellValue(const vector<Float_t>& xvec, TMVA::ECellValue cv, TMVA::PDEFoamKernelBase* ); This function finds the cell, whic",MatchSource.WIKI,root/html532/TMVA__PDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoam.html
https://root.cern/root/html532/TMVA__PDEFoam.html:916,Deployability,integrat,integration,916,". TMVA::PDEFoam. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::PDEFoam. class TMVA::PDEFoam: public TObject. Implementation of PDEFoam. The PDEFoam method is an extension of the PDERS method, which uses; self-adapting binning to divide the multi-dimensional phase space; in a finite number of hyper-rectangles (boxes). For a given number of boxes, the binning algorithm adjusts the size; and position of the boxes inside the multidimensional phase space,; minimizing the variance of the signal and background densities inside; the boxes. The binned density information is stored in binary trees,; allowing for a very fast and memory-efficient classification of; events. The implementation of the PDEFoam is based on the monte-carlo; integration package TFoam included in the analysis package ROOT. The class TMVA::PDEFoam defines the default interface for the; PDEFoam variants:. - PDEFoamEvent; - PDEFoamDiscriminant; - PDEFoamTarget; - PDEFoamMultiTarget; - PDEFoamDecisionTree. Per default PDEFoam stores in the cells the number of events (event; weights) and therefore acts as an event density estimator.; However, the above listed derived classes override this behaviour; to implement certain PDEFoam variations. In order to use PDEFoam the user has to set the density estimator; of the type TMVA::PDEFoamDensityBase, which is used to during the foam; build-up. The default PDEFoam should be used with; PDEFoamEventDensity. Function Members (Methods); public:. virtual~PDEFoam(); voidTObject::AbstractMethod(const char* method) const; voidAddVariableName(const char* s); voidAddVariableName(TObjString* s); virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidCheckAll(Int_t); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObjec",MatchSource.WIKI,root/html532/TMVA__PDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoam.html
https://root.cern/root/html532/TMVA__PDEFoam.html:9554,Deployability,integrat,integration,9554,"FoamCell*,allocator<TMVA::PDEFoamCell*> >&) const; Double_tGetCellElement(const TMVA::PDEFoamCell* cell, UInt_t i) const; TMVA::PDEFoamDensityBase*GetDistr() const; voidGrow(); voidInitCells(); voidMakeAlpha(); voidTObject::MakeZombie(); voidOutputGrow(Bool_t finished = false); TMVA::PDEFoamPDEFoam(const TMVA::PDEFoam&); Long_tPeekMax(); voidSetCellElement(TMVA::PDEFoamCell* cell, UInt_t i, Double_t value); voidVaredu(Double_t*, Int_t&, Double_t&, Double_t&). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. Double_t*fAlpha[fDim] Internal parameters of the hyperrectangle; TMVA::PDEFoamCell**fCells[fNCells] Array of ALL cells; TMVA::EDTSeparationfDTSeparationBACKWARDS COMPATIBILITY: split cells according to decision tree logic; Int_tfDimDimension of the integration/simulation space; TMVA::PDEFoamDensityBase*fDistr! distribution of training events; Int_tfEvPerBinMaximum number of effective (wt=1) events per bin; Bool_tfFillFoamWithOrigWeightsBACKWARDS COMPATIBILITY: fill the foam with boost or orig. weights; TMVA::EFoamTypefFoamTypeBACKWARDS COMPATIBILITY: type of foam; TObjArray*fHistEdgHistograms of wt, one for each cell edge; Int_t*fInhiDiv! [fDim] Flags for inhibiting cell division; Int_tfLastCeIndex of the last cell; TMVA::MsgLogger*fLogger! message logger; Int_t*fMaskDiv! [fDim] Dynamic Mask for cell division; UInt_tfMaxDepthmaximum depth of cell tree; Int_tfNBinNo. of bins in the edge histogram for cell MC exploration; Int_tfNCellsMaximum number of cells; UInt_tfNElementsBACKWARDS COMPATIBILITY: number of variables in every cell; Int_tfNSamplNo. of MC events, when dividing (exploring) cell; TStringfNameName of a given instance of the FOAM class; UInt_tfNminminimal number of events in cell to split cell; Int_tfNoActNumber of acti",MatchSource.WIKI,root/html532/TMVA__PDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoam.html
https://root.cern/root/html532/TMVA__PDEFoam.html:12854,Deployability,update,updated,12854," using SetPseRan and SetRho prior to invoking this initializator!. After the foam is grown, space for 2 variables is reserved in; every cell. They are used for filling the foam cells. void InitCells(); Internal subprogram used by Create.; It initializes ""root part"" of the FOAM of the tree of cells. Int_t CellFill(Int_t , TMVA::PDEFoamCell* ); Internal subprogram used by Create.; It initializes content of the newly allocated active cell. void Explore(TMVA::PDEFoamCell* Cell); Internal subprogram used by Create.; It explores newly defined cell with help of special short MC sampling.; As a result, estimates of kTRUE and drive volume is defined/determined; Average and dispersion of the weight distribution will is found along; each edge and the best edge (minimum dispersion, best maximum weight); is memorized for future use.; The optimal division point for eventual future cell division is; determined/recorded. Recorded are also minimum and maximum weight etc.; The volume estimate in all (inactive) parent cells is updated.; Note that links to parents and initial volume = 1/2 parent has to be; already defined prior to calling this routine. If fNmin > 0 then the total number of (training) events found in; the cell during the exploration is stored in the cell. This; information is used withing PeekMax() to avoid splitting cells; which contain less than fNmin events. void Varedu(Double_t* , Int_t& , Double_t& , Double_t& ); Internal subrogram used by Create.; In determines the best edge candidate and the position of the cell division plane; in case of the variance reduction for future cell division,; using results of the MC exploration run stored in fHistEdg. void MakeAlpha(); Internal subrogram used by Create.; Provides random vector Alpha 0< Alpha(i) < 1. Long_t PeekMax(); Internal subprogram used by Create. It finds cell with maximal; driver integral for the purpose of the division. This function; is overridden by the PDEFoam Class to apply cuts on the number; of events in",MatchSource.WIKI,root/html532/TMVA__PDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoam.html
https://root.cern/root/html532/TMVA__PDEFoam.html:14201,Deployability,update,updated,14201,"l subrogram used by Create.; In determines the best edge candidate and the position of the cell division plane; in case of the variance reduction for future cell division,; using results of the MC exploration run stored in fHistEdg. void MakeAlpha(); Internal subrogram used by Create.; Provides random vector Alpha 0< Alpha(i) < 1. Long_t PeekMax(); Internal subprogram used by Create. It finds cell with maximal; driver integral for the purpose of the division. This function; is overridden by the PDEFoam Class to apply cuts on the number; of events in the cell (fNmin) and the cell tree depth; (GetMaxDepth() > 0) during cell buildup. Int_t Divide(TMVA::PDEFoamCell* ); Internal subrogram used by Create.; It divides cell iCell into two daughter cells.; The iCell is retained and tagged as inactive, daughter cells are appended; at the end of the buffer.; New vertex is added to list of vertices.; List of active cells is updated, iCell removed, two daughters added; and their properties set with help of MC sampling (PDEFoam_Explore); Returns Code RC=-1 of buffer limit is reached, fLastCe=fnBuf. Double_t Eval(Double_t* xRand, Double_t& event_density); Internal subprogram.; Evaluates (training) distribution. void Grow(); Internal subrogram used by Create.; It grow new cells by the binary division process.; This function is overridden by the PDEFoam class to stop the foam buildup process; if one of the cut conditions stop the cell split. void SetInhiDiv(Int_t , Int_t ); This can be called before Create, after setting kDim; It defines which variables are excluded in the process of the cell division.; For example 'FoamX->SetInhiDiv(1, 1);' inhibits division of y-variable. void CheckAll(Int_t ); User utility, miscellaneous and debug.; Checks all pointers in the tree of cells. This is useful autodiagnostic.; level=0, no printout, failures causes STOP; level=1, printout, failures lead to WARNINGS only. void PrintCell(Long_t iCell = 0); Prints geometry of and elements of 'iCell', as we",MatchSource.WIKI,root/html532/TMVA__PDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoam.html
https://root.cern/root/html532/TMVA__PDEFoam.html:392,Energy Efficiency,adapt,adapting,392,". TMVA::PDEFoam. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::PDEFoam. class TMVA::PDEFoam: public TObject. Implementation of PDEFoam. The PDEFoam method is an extension of the PDERS method, which uses; self-adapting binning to divide the multi-dimensional phase space; in a finite number of hyper-rectangles (boxes). For a given number of boxes, the binning algorithm adjusts the size; and position of the boxes inside the multidimensional phase space,; minimizing the variance of the signal and background densities inside; the boxes. The binned density information is stored in binary trees,; allowing for a very fast and memory-efficient classification of; events. The implementation of the PDEFoam is based on the monte-carlo; integration package TFoam included in the analysis package ROOT. The class TMVA::PDEFoam defines the default interface for the; PDEFoam variants:. - PDEFoamEvent; - PDEFoamDiscriminant; - PDEFoamTarget; - PDEFoamMultiTarget; - PDEFoamDecisionTree. Per default PDEFoam stores in the cells the number of events (event; weights) and therefore acts as an event density estimator.; However, the above listed derived classes override this behaviour; to implement certain PDEFoam variations. In order to use PDEFoam the user has to set the density estimator; of the type TMVA::PDEFoamDensityBase, which is used to during the foam; build-up. The default PDEFoam should be used with; PDEFoamEventDensity. Function Members (Methods); public:. virtual~PDEFoam(); voidTObject::AbstractMethod(const char* method) const; voidAddVariableName(const char* s); voidAddVariableName(TObjString* s); virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidCheckAll(Int_t); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObjec",MatchSource.WIKI,root/html532/TMVA__PDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoam.html
https://root.cern/root/html532/TMVA__PDEFoam.html:816,Energy Efficiency,efficient,efficient,816,". TMVA::PDEFoam. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::PDEFoam. class TMVA::PDEFoam: public TObject. Implementation of PDEFoam. The PDEFoam method is an extension of the PDERS method, which uses; self-adapting binning to divide the multi-dimensional phase space; in a finite number of hyper-rectangles (boxes). For a given number of boxes, the binning algorithm adjusts the size; and position of the boxes inside the multidimensional phase space,; minimizing the variance of the signal and background densities inside; the boxes. The binned density information is stored in binary trees,; allowing for a very fast and memory-efficient classification of; events. The implementation of the PDEFoam is based on the monte-carlo; integration package TFoam included in the analysis package ROOT. The class TMVA::PDEFoam defines the default interface for the; PDEFoam variants:. - PDEFoamEvent; - PDEFoamDiscriminant; - PDEFoamTarget; - PDEFoamMultiTarget; - PDEFoamDecisionTree. Per default PDEFoam stores in the cells the number of events (event; weights) and therefore acts as an event density estimator.; However, the above listed derived classes override this behaviour; to implement certain PDEFoam variations. In order to use PDEFoam the user has to set the density estimator; of the type TMVA::PDEFoamDensityBase, which is used to during the foam; build-up. The default PDEFoam should be used with; PDEFoamEventDensity. Function Members (Methods); public:. virtual~PDEFoam(); voidTObject::AbstractMethod(const char* method) const; voidAddVariableName(const char* s); voidAddVariableName(TObjString* s); virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidCheckAll(Int_t); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObjec",MatchSource.WIKI,root/html532/TMVA__PDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoam.html
https://root.cern/root/html532/TMVA__PDEFoam.html:12248,Energy Efficiency,allocate,allocated,12248," for streamer, user should not use it. PDEFoam(const TString& ); User constructor, to be employed by the user. ~PDEFoam(); Default destructor. PDEFoam(const TMVA::PDEFoam& ); Copy Constructor NOT IMPLEMENTED (NEVER USED). void SetDim(Int_t kDim); Sets dimension of cubical space. void SetXmin(Int_t idim, Double_t wmin); set lower foam bound in dimension idim. void SetXmax(Int_t idim, Double_t wmax); set upper foam bound in dimension idim. void Create(); Basic initialization of FOAM invoked by the user.; IMPORTANT: Random number generator and the distribution object has to be; provided using SetPseRan and SetRho prior to invoking this initializator!. After the foam is grown, space for 2 variables is reserved in; every cell. They are used for filling the foam cells. void InitCells(); Internal subprogram used by Create.; It initializes ""root part"" of the FOAM of the tree of cells. Int_t CellFill(Int_t , TMVA::PDEFoamCell* ); Internal subprogram used by Create.; It initializes content of the newly allocated active cell. void Explore(TMVA::PDEFoamCell* Cell); Internal subprogram used by Create.; It explores newly defined cell with help of special short MC sampling.; As a result, estimates of kTRUE and drive volume is defined/determined; Average and dispersion of the weight distribution will is found along; each edge and the best edge (minimum dispersion, best maximum weight); is memorized for future use.; The optimal division point for eventual future cell division is; determined/recorded. Recorded are also minimum and maximum weight etc.; The volume estimate in all (inactive) parent cells is updated.; Note that links to parents and initial volume = 1/2 parent has to be; already defined prior to calling this routine. If fNmin > 0 then the total number of (training) events found in; the cell during the exploration is stored in the cell. This; information is used withing PeekMax() to avoid splitting cells; which contain less than fNmin events. void Varedu(Double_t* , Int_t&",MatchSource.WIKI,root/html532/TMVA__PDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoam.html
https://root.cern/root/html532/TMVA__PDEFoam.html:916,Integrability,integrat,integration,916,". TMVA::PDEFoam. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::PDEFoam. class TMVA::PDEFoam: public TObject. Implementation of PDEFoam. The PDEFoam method is an extension of the PDERS method, which uses; self-adapting binning to divide the multi-dimensional phase space; in a finite number of hyper-rectangles (boxes). For a given number of boxes, the binning algorithm adjusts the size; and position of the boxes inside the multidimensional phase space,; minimizing the variance of the signal and background densities inside; the boxes. The binned density information is stored in binary trees,; allowing for a very fast and memory-efficient classification of; events. The implementation of the PDEFoam is based on the monte-carlo; integration package TFoam included in the analysis package ROOT. The class TMVA::PDEFoam defines the default interface for the; PDEFoam variants:. - PDEFoamEvent; - PDEFoamDiscriminant; - PDEFoamTarget; - PDEFoamMultiTarget; - PDEFoamDecisionTree. Per default PDEFoam stores in the cells the number of events (event; weights) and therefore acts as an event density estimator.; However, the above listed derived classes override this behaviour; to implement certain PDEFoam variations. In order to use PDEFoam the user has to set the density estimator; of the type TMVA::PDEFoamDensityBase, which is used to during the foam; build-up. The default PDEFoam should be used with; PDEFoamEventDensity. Function Members (Methods); public:. virtual~PDEFoam(); voidTObject::AbstractMethod(const char* method) const; voidAddVariableName(const char* s); voidAddVariableName(TObjString* s); virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidCheckAll(Int_t); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObjec",MatchSource.WIKI,root/html532/TMVA__PDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoam.html
https://root.cern/root/html532/TMVA__PDEFoam.html:1025,Integrability,interface,interface,1025,"k Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::PDEFoam. class TMVA::PDEFoam: public TObject. Implementation of PDEFoam. The PDEFoam method is an extension of the PDERS method, which uses; self-adapting binning to divide the multi-dimensional phase space; in a finite number of hyper-rectangles (boxes). For a given number of boxes, the binning algorithm adjusts the size; and position of the boxes inside the multidimensional phase space,; minimizing the variance of the signal and background densities inside; the boxes. The binned density information is stored in binary trees,; allowing for a very fast and memory-efficient classification of; events. The implementation of the PDEFoam is based on the monte-carlo; integration package TFoam included in the analysis package ROOT. The class TMVA::PDEFoam defines the default interface for the; PDEFoam variants:. - PDEFoamEvent; - PDEFoamDiscriminant; - PDEFoamTarget; - PDEFoamMultiTarget; - PDEFoamDecisionTree. Per default PDEFoam stores in the cells the number of events (event; weights) and therefore acts as an event density estimator.; However, the above listed derived classes override this behaviour; to implement certain PDEFoam variations. In order to use PDEFoam the user has to set the density estimator; of the type TMVA::PDEFoamDensityBase, which is used to during the foam; build-up. The default PDEFoam should be used with; PDEFoamEventDensity. Function Members (Methods); public:. virtual~PDEFoam(); voidTObject::AbstractMethod(const char* method) const; voidAddVariableName(const char* s); voidAddVariableName(TObjString* s); virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidCheckAll(Int_t); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* =",MatchSource.WIKI,root/html532/TMVA__PDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoam.html
https://root.cern/root/html532/TMVA__PDEFoam.html:9554,Integrability,integrat,integration,9554,"FoamCell*,allocator<TMVA::PDEFoamCell*> >&) const; Double_tGetCellElement(const TMVA::PDEFoamCell* cell, UInt_t i) const; TMVA::PDEFoamDensityBase*GetDistr() const; voidGrow(); voidInitCells(); voidMakeAlpha(); voidTObject::MakeZombie(); voidOutputGrow(Bool_t finished = false); TMVA::PDEFoamPDEFoam(const TMVA::PDEFoam&); Long_tPeekMax(); voidSetCellElement(TMVA::PDEFoamCell* cell, UInt_t i, Double_t value); voidVaredu(Double_t*, Int_t&, Double_t&, Double_t&). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. Double_t*fAlpha[fDim] Internal parameters of the hyperrectangle; TMVA::PDEFoamCell**fCells[fNCells] Array of ALL cells; TMVA::EDTSeparationfDTSeparationBACKWARDS COMPATIBILITY: split cells according to decision tree logic; Int_tfDimDimension of the integration/simulation space; TMVA::PDEFoamDensityBase*fDistr! distribution of training events; Int_tfEvPerBinMaximum number of effective (wt=1) events per bin; Bool_tfFillFoamWithOrigWeightsBACKWARDS COMPATIBILITY: fill the foam with boost or orig. weights; TMVA::EFoamTypefFoamTypeBACKWARDS COMPATIBILITY: type of foam; TObjArray*fHistEdgHistograms of wt, one for each cell edge; Int_t*fInhiDiv! [fDim] Flags for inhibiting cell division; Int_tfLastCeIndex of the last cell; TMVA::MsgLogger*fLogger! message logger; Int_t*fMaskDiv! [fDim] Dynamic Mask for cell division; UInt_tfMaxDepthmaximum depth of cell tree; Int_tfNBinNo. of bins in the edge histogram for cell MC exploration; Int_tfNCellsMaximum number of cells; UInt_tfNElementsBACKWARDS COMPATIBILITY: number of variables in every cell; Int_tfNSamplNo. of MC events, when dividing (exploring) cell; TStringfNameName of a given instance of the FOAM class; UInt_tfNminminimal number of events in cell to split cell; Int_tfNoActNumber of acti",MatchSource.WIKI,root/html532/TMVA__PDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoam.html
https://root.cern/root/html532/TMVA__PDEFoam.html:10056,Integrability,message,message,10056," Double_t&, Double_t&). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. Double_t*fAlpha[fDim] Internal parameters of the hyperrectangle; TMVA::PDEFoamCell**fCells[fNCells] Array of ALL cells; TMVA::EDTSeparationfDTSeparationBACKWARDS COMPATIBILITY: split cells according to decision tree logic; Int_tfDimDimension of the integration/simulation space; TMVA::PDEFoamDensityBase*fDistr! distribution of training events; Int_tfEvPerBinMaximum number of effective (wt=1) events per bin; Bool_tfFillFoamWithOrigWeightsBACKWARDS COMPATIBILITY: fill the foam with boost or orig. weights; TMVA::EFoamTypefFoamTypeBACKWARDS COMPATIBILITY: type of foam; TObjArray*fHistEdgHistograms of wt, one for each cell edge; Int_t*fInhiDiv! [fDim] Flags for inhibiting cell division; Int_tfLastCeIndex of the last cell; TMVA::MsgLogger*fLogger! message logger; Int_t*fMaskDiv! [fDim] Dynamic Mask for cell division; UInt_tfMaxDepthmaximum depth of cell tree; Int_tfNBinNo. of bins in the edge histogram for cell MC exploration; Int_tfNCellsMaximum number of cells; UInt_tfNElementsBACKWARDS COMPATIBILITY: number of variables in every cell; Int_tfNSamplNo. of MC events, when dividing (exploring) cell; TStringfNameName of a given instance of the FOAM class; UInt_tfNminminimal number of events in cell to split cell; Int_tfNoActNumber of active cells; Bool_tfPeekMaxBACKWARDS COMPATIBILITY: peek up cell with max. driver integral for split; TRandom3*fPseRanPointer to user-defined generator of pseudorandom numbers; Double_t*fRvec[fDim] random number vector from r.n. generator fDim+1 maximum elements; TMVA::Timer*fTimer! timer for graphical output; TObjArray*fVariableNamescollection of all variable names; Float_tfVolFracBACKWARDS COMPATIBILITY: volume fraction (with respect to",MatchSource.WIKI,root/html532/TMVA__PDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoam.html
https://root.cern/root/html532/TMVA__PDEFoam.html:12972,Integrability,rout,routine,12972," space for 2 variables is reserved in; every cell. They are used for filling the foam cells. void InitCells(); Internal subprogram used by Create.; It initializes ""root part"" of the FOAM of the tree of cells. Int_t CellFill(Int_t , TMVA::PDEFoamCell* ); Internal subprogram used by Create.; It initializes content of the newly allocated active cell. void Explore(TMVA::PDEFoamCell* Cell); Internal subprogram used by Create.; It explores newly defined cell with help of special short MC sampling.; As a result, estimates of kTRUE and drive volume is defined/determined; Average and dispersion of the weight distribution will is found along; each edge and the best edge (minimum dispersion, best maximum weight); is memorized for future use.; The optimal division point for eventual future cell division is; determined/recorded. Recorded are also minimum and maximum weight etc.; The volume estimate in all (inactive) parent cells is updated.; Note that links to parents and initial volume = 1/2 parent has to be; already defined prior to calling this routine. If fNmin > 0 then the total number of (training) events found in; the cell during the exploration is stored in the cell. This; information is used withing PeekMax() to avoid splitting cells; which contain less than fNmin events. void Varedu(Double_t* , Int_t& , Double_t& , Double_t& ); Internal subrogram used by Create.; In determines the best edge candidate and the position of the cell division plane; in case of the variance reduction for future cell division,; using results of the MC exploration run stored in fHistEdg. void MakeAlpha(); Internal subrogram used by Create.; Provides random vector Alpha 0< Alpha(i) < 1. Long_t PeekMax(); Internal subprogram used by Create. It finds cell with maximal; driver integral for the purpose of the division. This function; is overridden by the PDEFoam Class to apply cuts on the number; of events in the cell (fNmin) and the cell tree depth; (GetMaxDepth() > 0) during cell buildup. Int_t D",MatchSource.WIKI,root/html532/TMVA__PDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoam.html
https://root.cern/root/html532/TMVA__PDEFoam.html:392,Modifiability,adapt,adapting,392,". TMVA::PDEFoam. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::PDEFoam. class TMVA::PDEFoam: public TObject. Implementation of PDEFoam. The PDEFoam method is an extension of the PDERS method, which uses; self-adapting binning to divide the multi-dimensional phase space; in a finite number of hyper-rectangles (boxes). For a given number of boxes, the binning algorithm adjusts the size; and position of the boxes inside the multidimensional phase space,; minimizing the variance of the signal and background densities inside; the boxes. The binned density information is stored in binary trees,; allowing for a very fast and memory-efficient classification of; events. The implementation of the PDEFoam is based on the monte-carlo; integration package TFoam included in the analysis package ROOT. The class TMVA::PDEFoam defines the default interface for the; PDEFoam variants:. - PDEFoamEvent; - PDEFoamDiscriminant; - PDEFoamTarget; - PDEFoamMultiTarget; - PDEFoamDecisionTree. Per default PDEFoam stores in the cells the number of events (event; weights) and therefore acts as an event density estimator.; However, the above listed derived classes override this behaviour; to implement certain PDEFoam variations. In order to use PDEFoam the user has to set the density estimator; of the type TMVA::PDEFoamDensityBase, which is used to during the foam; build-up. The default PDEFoam should be used with; PDEFoamEventDensity. Function Members (Methods); public:. virtual~PDEFoam(); voidTObject::AbstractMethod(const char* method) const; voidAddVariableName(const char* s); voidAddVariableName(TObjString* s); virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidCheckAll(Int_t); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObjec",MatchSource.WIKI,root/html532/TMVA__PDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoam.html
https://root.cern/root/html532/TMVA__PDEFoam.html:10327,Modifiability,variab,variables,10327,"kWriteDelete; };. protected:. Double_t*fAlpha[fDim] Internal parameters of the hyperrectangle; TMVA::PDEFoamCell**fCells[fNCells] Array of ALL cells; TMVA::EDTSeparationfDTSeparationBACKWARDS COMPATIBILITY: split cells according to decision tree logic; Int_tfDimDimension of the integration/simulation space; TMVA::PDEFoamDensityBase*fDistr! distribution of training events; Int_tfEvPerBinMaximum number of effective (wt=1) events per bin; Bool_tfFillFoamWithOrigWeightsBACKWARDS COMPATIBILITY: fill the foam with boost or orig. weights; TMVA::EFoamTypefFoamTypeBACKWARDS COMPATIBILITY: type of foam; TObjArray*fHistEdgHistograms of wt, one for each cell edge; Int_t*fInhiDiv! [fDim] Flags for inhibiting cell division; Int_tfLastCeIndex of the last cell; TMVA::MsgLogger*fLogger! message logger; Int_t*fMaskDiv! [fDim] Dynamic Mask for cell division; UInt_tfMaxDepthmaximum depth of cell tree; Int_tfNBinNo. of bins in the edge histogram for cell MC exploration; Int_tfNCellsMaximum number of cells; UInt_tfNElementsBACKWARDS COMPATIBILITY: number of variables in every cell; Int_tfNSamplNo. of MC events, when dividing (exploring) cell; TStringfNameName of a given instance of the FOAM class; UInt_tfNminminimal number of events in cell to split cell; Int_tfNoActNumber of active cells; Bool_tfPeekMaxBACKWARDS COMPATIBILITY: peek up cell with max. driver integral for split; TRandom3*fPseRanPointer to user-defined generator of pseudorandom numbers; Double_t*fRvec[fDim] random number vector from r.n. generator fDim+1 maximum elements; TMVA::Timer*fTimer! timer for graphical output; TObjArray*fVariableNamescollection of all variable names; Float_tfVolFracBACKWARDS COMPATIBILITY: volume fraction (with respect to total phase space; Double_t*fXmax[fDim] maximum for variable transform; Double_t*fXmin[fDim] minimum for variable transform. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDEFoam(); Default constructor for streamer, user should not use ",MatchSource.WIKI,root/html532/TMVA__PDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoam.html
https://root.cern/root/html532/TMVA__PDEFoam.html:10905,Modifiability,variab,variable,10905,"iv! [fDim] Flags for inhibiting cell division; Int_tfLastCeIndex of the last cell; TMVA::MsgLogger*fLogger! message logger; Int_t*fMaskDiv! [fDim] Dynamic Mask for cell division; UInt_tfMaxDepthmaximum depth of cell tree; Int_tfNBinNo. of bins in the edge histogram for cell MC exploration; Int_tfNCellsMaximum number of cells; UInt_tfNElementsBACKWARDS COMPATIBILITY: number of variables in every cell; Int_tfNSamplNo. of MC events, when dividing (exploring) cell; TStringfNameName of a given instance of the FOAM class; UInt_tfNminminimal number of events in cell to split cell; Int_tfNoActNumber of active cells; Bool_tfPeekMaxBACKWARDS COMPATIBILITY: peek up cell with max. driver integral for split; TRandom3*fPseRanPointer to user-defined generator of pseudorandom numbers; Double_t*fRvec[fDim] random number vector from r.n. generator fDim+1 maximum elements; TMVA::Timer*fTimer! timer for graphical output; TObjArray*fVariableNamescollection of all variable names; Float_tfVolFracBACKWARDS COMPATIBILITY: volume fraction (with respect to total phase space; Double_t*fXmax[fDim] maximum for variable transform; Double_t*fXmin[fDim] minimum for variable transform. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDEFoam(); Default constructor for streamer, user should not use it. PDEFoam(const TString& ); User constructor, to be employed by the user. ~PDEFoam(); Default destructor. PDEFoam(const TMVA::PDEFoam& ); Copy Constructor NOT IMPLEMENTED (NEVER USED). void SetDim(Int_t kDim); Sets dimension of cubical space. void SetXmin(Int_t idim, Double_t wmin); set lower foam bound in dimension idim. void SetXmax(Int_t idim, Double_t wmax); set upper foam bound in dimension idim. void Create(); Basic initialization of FOAM invoked by the user.; IMPORTANT: Random number generator and the distribution object has to be; provided using SetPseRan and SetRho prior to invoking this initializator!. After the foam is grown, space for 2 variables is re",MatchSource.WIKI,root/html532/TMVA__PDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoam.html
https://root.cern/root/html532/TMVA__PDEFoam.html:11046,Modifiability,variab,variable,11046,"iv! [fDim] Flags for inhibiting cell division; Int_tfLastCeIndex of the last cell; TMVA::MsgLogger*fLogger! message logger; Int_t*fMaskDiv! [fDim] Dynamic Mask for cell division; UInt_tfMaxDepthmaximum depth of cell tree; Int_tfNBinNo. of bins in the edge histogram for cell MC exploration; Int_tfNCellsMaximum number of cells; UInt_tfNElementsBACKWARDS COMPATIBILITY: number of variables in every cell; Int_tfNSamplNo. of MC events, when dividing (exploring) cell; TStringfNameName of a given instance of the FOAM class; UInt_tfNminminimal number of events in cell to split cell; Int_tfNoActNumber of active cells; Bool_tfPeekMaxBACKWARDS COMPATIBILITY: peek up cell with max. driver integral for split; TRandom3*fPseRanPointer to user-defined generator of pseudorandom numbers; Double_t*fRvec[fDim] random number vector from r.n. generator fDim+1 maximum elements; TMVA::Timer*fTimer! timer for graphical output; TObjArray*fVariableNamescollection of all variable names; Float_tfVolFracBACKWARDS COMPATIBILITY: volume fraction (with respect to total phase space; Double_t*fXmax[fDim] maximum for variable transform; Double_t*fXmin[fDim] minimum for variable transform. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDEFoam(); Default constructor for streamer, user should not use it. PDEFoam(const TString& ); User constructor, to be employed by the user. ~PDEFoam(); Default destructor. PDEFoam(const TMVA::PDEFoam& ); Copy Constructor NOT IMPLEMENTED (NEVER USED). void SetDim(Int_t kDim); Sets dimension of cubical space. void SetXmin(Int_t idim, Double_t wmin); set lower foam bound in dimension idim. void SetXmax(Int_t idim, Double_t wmax); set upper foam bound in dimension idim. void Create(); Basic initialization of FOAM invoked by the user.; IMPORTANT: Random number generator and the distribution object has to be; provided using SetPseRan and SetRho prior to invoking this initializator!. After the foam is grown, space for 2 variables is re",MatchSource.WIKI,root/html532/TMVA__PDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoam.html
https://root.cern/root/html532/TMVA__PDEFoam.html:11099,Modifiability,variab,variable,11099,"iv! [fDim] Flags for inhibiting cell division; Int_tfLastCeIndex of the last cell; TMVA::MsgLogger*fLogger! message logger; Int_t*fMaskDiv! [fDim] Dynamic Mask for cell division; UInt_tfMaxDepthmaximum depth of cell tree; Int_tfNBinNo. of bins in the edge histogram for cell MC exploration; Int_tfNCellsMaximum number of cells; UInt_tfNElementsBACKWARDS COMPATIBILITY: number of variables in every cell; Int_tfNSamplNo. of MC events, when dividing (exploring) cell; TStringfNameName of a given instance of the FOAM class; UInt_tfNminminimal number of events in cell to split cell; Int_tfNoActNumber of active cells; Bool_tfPeekMaxBACKWARDS COMPATIBILITY: peek up cell with max. driver integral for split; TRandom3*fPseRanPointer to user-defined generator of pseudorandom numbers; Double_t*fRvec[fDim] random number vector from r.n. generator fDim+1 maximum elements; TMVA::Timer*fTimer! timer for graphical output; TObjArray*fVariableNamescollection of all variable names; Float_tfVolFracBACKWARDS COMPATIBILITY: volume fraction (with respect to total phase space; Double_t*fXmax[fDim] maximum for variable transform; Double_t*fXmin[fDim] minimum for variable transform. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDEFoam(); Default constructor for streamer, user should not use it. PDEFoam(const TString& ); User constructor, to be employed by the user. ~PDEFoam(); Default destructor. PDEFoam(const TMVA::PDEFoam& ); Copy Constructor NOT IMPLEMENTED (NEVER USED). void SetDim(Int_t kDim); Sets dimension of cubical space. void SetXmin(Int_t idim, Double_t wmin); set lower foam bound in dimension idim. void SetXmax(Int_t idim, Double_t wmax); set upper foam bound in dimension idim. void Create(); Basic initialization of FOAM invoked by the user.; IMPORTANT: Random number generator and the distribution object has to be; provided using SetPseRan and SetRho prior to invoking this initializator!. After the foam is grown, space for 2 variables is re",MatchSource.WIKI,root/html532/TMVA__PDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoam.html
https://root.cern/root/html532/TMVA__PDEFoam.html:11934,Modifiability,variab,variables,11934,"racBACKWARDS COMPATIBILITY: volume fraction (with respect to total phase space; Double_t*fXmax[fDim] maximum for variable transform; Double_t*fXmin[fDim] minimum for variable transform. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDEFoam(); Default constructor for streamer, user should not use it. PDEFoam(const TString& ); User constructor, to be employed by the user. ~PDEFoam(); Default destructor. PDEFoam(const TMVA::PDEFoam& ); Copy Constructor NOT IMPLEMENTED (NEVER USED). void SetDim(Int_t kDim); Sets dimension of cubical space. void SetXmin(Int_t idim, Double_t wmin); set lower foam bound in dimension idim. void SetXmax(Int_t idim, Double_t wmax); set upper foam bound in dimension idim. void Create(); Basic initialization of FOAM invoked by the user.; IMPORTANT: Random number generator and the distribution object has to be; provided using SetPseRan and SetRho prior to invoking this initializator!. After the foam is grown, space for 2 variables is reserved in; every cell. They are used for filling the foam cells. void InitCells(); Internal subprogram used by Create.; It initializes ""root part"" of the FOAM of the tree of cells. Int_t CellFill(Int_t , TMVA::PDEFoamCell* ); Internal subprogram used by Create.; It initializes content of the newly allocated active cell. void Explore(TMVA::PDEFoamCell* Cell); Internal subprogram used by Create.; It explores newly defined cell with help of special short MC sampling.; As a result, estimates of kTRUE and drive volume is defined/determined; Average and dispersion of the weight distribution will is found along; each edge and the best edge (minimum dispersion, best maximum weight); is memorized for future use.; The optimal division point for eventual future cell division is; determined/recorded. Recorded are also minimum and maximum weight etc.; The volume estimate in all (inactive) parent cells is updated.; Note that links to parents and initial volume = 1/2 parent has to be; ",MatchSource.WIKI,root/html532/TMVA__PDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoam.html
https://root.cern/root/html532/TMVA__PDEFoam.html:14828,Modifiability,variab,variables,14828," the number; of events in the cell (fNmin) and the cell tree depth; (GetMaxDepth() > 0) during cell buildup. Int_t Divide(TMVA::PDEFoamCell* ); Internal subrogram used by Create.; It divides cell iCell into two daughter cells.; The iCell is retained and tagged as inactive, daughter cells are appended; at the end of the buffer.; New vertex is added to list of vertices.; List of active cells is updated, iCell removed, two daughters added; and their properties set with help of MC sampling (PDEFoam_Explore); Returns Code RC=-1 of buffer limit is reached, fLastCe=fnBuf. Double_t Eval(Double_t* xRand, Double_t& event_density); Internal subprogram.; Evaluates (training) distribution. void Grow(); Internal subrogram used by Create.; It grow new cells by the binary division process.; This function is overridden by the PDEFoam class to stop the foam buildup process; if one of the cut conditions stop the cell split. void SetInhiDiv(Int_t , Int_t ); This can be called before Create, after setting kDim; It defines which variables are excluded in the process of the cell division.; For example 'FoamX->SetInhiDiv(1, 1);' inhibits division of y-variable. void CheckAll(Int_t ); User utility, miscellaneous and debug.; Checks all pointers in the tree of cells. This is useful autodiagnostic.; level=0, no printout, failures causes STOP; level=1, printout, failures lead to WARNINGS only. void PrintCell(Long_t iCell = 0); Prints geometry of and elements of 'iCell', as well as relations; to parent and daughter cells. void PrintCells(void); Prints geometry of ALL cells of the FOAM. void FillFoamCells(const TMVA::Event* ev, Float_t wt); This function fills a weight 'wt' into the PDEFoam cell, which; corresponds to the given event 'ev'. Per default cell element 0; is filled with the weight 'wt', and cell element 1 is filled; with the squared weight. This function can be overridden by a; subclass in order to change the values stored in the foam cells. void ResetCellElements(); Remove the cell e",MatchSource.WIKI,root/html532/TMVA__PDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoam.html
https://root.cern/root/html532/TMVA__PDEFoam.html:14951,Modifiability,variab,variable,14951,"ide(TMVA::PDEFoamCell* ); Internal subrogram used by Create.; It divides cell iCell into two daughter cells.; The iCell is retained and tagged as inactive, daughter cells are appended; at the end of the buffer.; New vertex is added to list of vertices.; List of active cells is updated, iCell removed, two daughters added; and their properties set with help of MC sampling (PDEFoam_Explore); Returns Code RC=-1 of buffer limit is reached, fLastCe=fnBuf. Double_t Eval(Double_t* xRand, Double_t& event_density); Internal subprogram.; Evaluates (training) distribution. void Grow(); Internal subrogram used by Create.; It grow new cells by the binary division process.; This function is overridden by the PDEFoam class to stop the foam buildup process; if one of the cut conditions stop the cell split. void SetInhiDiv(Int_t , Int_t ); This can be called before Create, after setting kDim; It defines which variables are excluded in the process of the cell division.; For example 'FoamX->SetInhiDiv(1, 1);' inhibits division of y-variable. void CheckAll(Int_t ); User utility, miscellaneous and debug.; Checks all pointers in the tree of cells. This is useful autodiagnostic.; level=0, no printout, failures causes STOP; level=1, printout, failures lead to WARNINGS only. void PrintCell(Long_t iCell = 0); Prints geometry of and elements of 'iCell', as well as relations; to parent and daughter cells. void PrintCells(void); Prints geometry of ALL cells of the FOAM. void FillFoamCells(const TMVA::Event* ev, Float_t wt); This function fills a weight 'wt' into the PDEFoam cell, which; corresponds to the given event 'ev'. Per default cell element 0; is filled with the weight 'wt', and cell element 1 is filled; with the squared weight. This function can be overridden by a; subclass in order to change the values stored in the foam cells. void ResetCellElements(); Remove the cell elements from all cells. Bool_t CellValueIsUndefined(TMVA::PDEFoamCell* ); Returns true, if the value of the given cell ",MatchSource.WIKI,root/html532/TMVA__PDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoam.html
https://root.cern/root/html532/TMVA__PDEFoam.html:16358,Modifiability,variab,variables,16358,"ells. void PrintCells(void); Prints geometry of ALL cells of the FOAM. void FillFoamCells(const TMVA::Event* ev, Float_t wt); This function fills a weight 'wt' into the PDEFoam cell, which; corresponds to the given event 'ev'. Per default cell element 0; is filled with the weight 'wt', and cell element 1 is filled; with the squared weight. This function can be overridden by a; subclass in order to change the values stored in the foam cells. void ResetCellElements(); Remove the cell elements from all cells. Bool_t CellValueIsUndefined(TMVA::PDEFoamCell* ); Returns true, if the value of the given cell is undefined.; Default value: kFALSE. This function can be overridden by; sub-classes. Float_t GetCellValue(const vector<Float_t>& xvec, TMVA::ECellValue cv, TMVA::PDEFoamKernelBase* ); This function finds the cell, which corresponds to the given; untransformed event vector 'xvec' and return its value, which is; given by the parameter 'cv'. If kernel != NULL, then; PDEFoamKernelBase::Estimate() is called on the transformed event; variables. Parameters:. - xvec - event vector (untransformed, [fXmin,fXmax]). - cv - the cell value to return. - kernel - PDEFoam kernel estimator. If NULL is given, than the; pure cell value is returned. Return:. The cell value, corresponding to 'xvec', estimated by the given; kernel. std::vector<Float_t> GetCellValue( const std::map<Int_t,Float_t>& xvec, ECellValue cv ); This function finds all cells, which corresponds to the given; (incomplete) untransformed event vector 'xvec' and returns the; cell values, according to the parameter 'cv'. Parameters:. - xvec - map for the untransformed vector. The key (Int_t) is; the dimension, and the value (Float_t) is the event; coordinate. Note that not all coordinates have to be; specified. - cv - cell values to return. Return:. cell values from all cells that were found. TMVA::PDEFoamCell* FindCell(const vector<Float_t>& ) const; Find cell that contains 'xvec' (in foam coordinates [0,1]). Loop to find ",MatchSource.WIKI,root/html532/TMVA__PDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoam.html
https://root.cern/root/html532/TMVA__PDEFoam.html:18673,Modifiability,variab,variables,18673,"ls(const map<Int_t,Float_t>& , TMVA::PDEFoamCell* , vector<TMVA::PDEFoamCell*,allocator<TMVA::PDEFoamCell*> >& ) const; This is a helper function for std::vector<PDEFoamCell*>; FindCells(...) and a generalisation of PDEFoamCell* FindCell().; It saves in 'cells' all cells, which contain the coordinates; specifies in 'txvec'. Note, that not all coordinates have to be; specified in 'txvec'. Parameters:. - txvec - event vector in foam coordinates [0,1]. The key is; the dimension and the value is the event coordinate. Note,; that not all coordinates have to be specified. - cell - cell to start searching with (usually root cell; fCells[0]). - cells - list of cells that were found. std::vector<TMVA::PDEFoamCell*> FindCells(const std::vector<Float_t> &txvec); Find all cells, that contain txvec. This function can be used,; when the dimension of the foam is greater than the dimension of; txvec. E.g. this is the case for multi-target regression. Parameters:. - txvec - event vector of variables, transformed into foam; coordinates [0,1]. The size of txvec can be smaller than the; dimension of the foam. Return value:. - vector of cells, that fit txvec. std::vector<TMVA::PDEFoamCell*> FindCells(const std::map<Int_t, Float_t> &txvec); Find all cells, that contain the coordinates specified in txvec.; The key in 'txvec' is the dimension, and the corresponding value; is the coordinate. Note, that not all coordinates have to be; specified in txvec. Parameters:. - txvec - map of coordinates (transformed into foam coordinates; [0,1]). Return value:. - vector of cells, that fit txvec. TH1D* Draw1Dim(TMVA::ECellValue cell_value, Int_t nbin, TMVA::PDEFoamKernelBase* kernel = NULL); Draws 1-dimensional foam (= histogram). Parameters:. - cell_value - the cell value to draw. - nbin - number of bins of result histogram. - kernel - a PDEFoam kernel. TH2D* Project2(Int_t idim1, Int_t idim2, TMVA::ECellValue cell_value = kValue, TMVA::PDEFoamKernelBase* kernel = NULL, UInt_t maxbins = 50); Project ",MatchSource.WIKI,root/html532/TMVA__PDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoam.html
https://root.cern/root/html532/TMVA__PDEFoam.html:19691,Modifiability,variab,variable,19691,"ameters:. - txvec - event vector of variables, transformed into foam; coordinates [0,1]. The size of txvec can be smaller than the; dimension of the foam. Return value:. - vector of cells, that fit txvec. std::vector<TMVA::PDEFoamCell*> FindCells(const std::map<Int_t, Float_t> &txvec); Find all cells, that contain the coordinates specified in txvec.; The key in 'txvec' is the dimension, and the corresponding value; is the coordinate. Note, that not all coordinates have to be; specified in txvec. Parameters:. - txvec - map of coordinates (transformed into foam coordinates; [0,1]). Return value:. - vector of cells, that fit txvec. TH1D* Draw1Dim(TMVA::ECellValue cell_value, Int_t nbin, TMVA::PDEFoamKernelBase* kernel = NULL); Draws 1-dimensional foam (= histogram). Parameters:. - cell_value - the cell value to draw. - nbin - number of bins of result histogram. - kernel - a PDEFoam kernel. TH2D* Project2(Int_t idim1, Int_t idim2, TMVA::ECellValue cell_value = kValue, TMVA::PDEFoamKernelBase* kernel = NULL, UInt_t maxbins = 50); Project foam variable idim1 and variable idim2 to histogram. Parameters:. - idim1, idim2 - dimensions to project to. - cell_value - the cell value to draw. - kernel - a PDEFoam kernel (optional). If NULL is given, the; kernel is ignored and the pure cell values are; plotted. - nbin - number of bins in x and y direction of result histogram; (optional, default is 50). Returns:; a 2-dimensional histogram. Float_t GetCellValue(const PDEFoamCell* cell, ECellValue cv); Returns the cell value of 'cell' corresponding to the given; option 'cv'. This function should be overridden by the subclass; in order to specify which cell elements to return for a given; cell value 'cv'. By default kValue returns cell element 0, and; kValueError returns cell element 1. Double_t GetCellElement(const TMVA::PDEFoamCell* cell, UInt_t i) const; Returns cell element i of cell 'cell'. If the cell has no; elements or the index 'i' is out of range, than 0 is returned. void Set",MatchSource.WIKI,root/html532/TMVA__PDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoam.html
https://root.cern/root/html532/TMVA__PDEFoam.html:19710,Modifiability,variab,variable,19710,"ameters:. - txvec - event vector of variables, transformed into foam; coordinates [0,1]. The size of txvec can be smaller than the; dimension of the foam. Return value:. - vector of cells, that fit txvec. std::vector<TMVA::PDEFoamCell*> FindCells(const std::map<Int_t, Float_t> &txvec); Find all cells, that contain the coordinates specified in txvec.; The key in 'txvec' is the dimension, and the corresponding value; is the coordinate. Note, that not all coordinates have to be; specified in txvec. Parameters:. - txvec - map of coordinates (transformed into foam coordinates; [0,1]). Return value:. - vector of cells, that fit txvec. TH1D* Draw1Dim(TMVA::ECellValue cell_value, Int_t nbin, TMVA::PDEFoamKernelBase* kernel = NULL); Draws 1-dimensional foam (= histogram). Parameters:. - cell_value - the cell value to draw. - nbin - number of bins of result histogram. - kernel - a PDEFoam kernel. TH2D* Project2(Int_t idim1, Int_t idim2, TMVA::ECellValue cell_value = kValue, TMVA::PDEFoamKernelBase* kernel = NULL, UInt_t maxbins = 50); Project foam variable idim1 and variable idim2 to histogram. Parameters:. - idim1, idim2 - dimensions to project to. - cell_value - the cell value to draw. - kernel - a PDEFoam kernel (optional). If NULL is given, the; kernel is ignored and the pure cell values are; plotted. - nbin - number of bins in x and y direction of result histogram; (optional, default is 50). Returns:; a 2-dimensional histogram. Float_t GetCellValue(const PDEFoamCell* cell, ECellValue cv); Returns the cell value of 'cell' corresponding to the given; option 'cv'. This function should be overridden by the subclass; in order to specify which cell elements to return for a given; cell value 'cv'. By default kValue returns cell element 0, and; kValueError returns cell element 1. Double_t GetCellElement(const TMVA::PDEFoamCell* cell, UInt_t i) const; Returns cell element i of cell 'cell'. If the cell has no; elements or the index 'i' is out of range, than 0 is returned. void Set",MatchSource.WIKI,root/html532/TMVA__PDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoam.html
https://root.cern/root/html532/TMVA__PDEFoam.html:24053,Modifiability,variab,variable,24053,"loat_t>& invec) const. Float_t VarTransformInvers(Int_t idim, Float_t x) const. std::vector<Float_t> VarTransformInvers(const vector<Float_t>& invec) const. PDEFoamDensityBase* GetDistr() const; get internal density. { assert(fDistr); return fDistr; }. void Initialize(); ---------- Foam creation functions. {}. void Finalize(); function to call after foam is grown. {}. void SetnCells(Long_t nCells); {fNCells =nCells;}. void SetnSampl(Long_t nSampl); {fNSampl =nSampl;}. void SetnBin(Int_t nBin); {fNBin = nBin;}. void SetEvPerBin(Int_t EvPerBin); {fEvPerBin =EvPerBin;}. void SetDensity(TMVA::PDEFoamDensityBase* dens); { fDistr = dens; }. Int_t GetTotDim() const; coverity[ -tainted_data_return ]. {return fDim; }. TString GetFoamName() const; {return fName; }. UInt_t GetNActiveCells() const; {return fNoAct;}. UInt_t GetNInActiveCells() const; {return GetNCells()-GetNActiveCells();}. UInt_t GetNCells() const; {return fNCells;}. PDEFoamCell* GetRootCell() const; {return fCells[0];}. void SetNmin(UInt_t val); Getters and Setters for user cut options. { fNmin=val; }. UInt_t GetNmin(); { return fNmin; }. void SetMaxDepth(UInt_t maxdepth); { fMaxDepth = maxdepth; }. UInt_t GetMaxDepth() const; { return fMaxDepth; }. Double_t GetXmin(Int_t idim) const; {return fXmin[idim];}. Double_t GetXmax(Int_t idim) const; {return fXmax[idim];}. void AddVariableName(const char* s); Getters and Setters for variable names. { AddVariableName(new TObjString(s)); }. void AddVariableName(TObjString* s); { fVariableNames->Add(s); }. TObjString* GetVariableName(Int_t idx); {return dynamic_cast<TObjString*>(fVariableNames->At(idx));}. » Author: S. Jadach, Tancredi Carli, Dominik Dannheim, Alexander Voigt » Copyright (c) 2008, 2010: *; » Last changed: root/tmva $Id: PDEFoam.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-12-02 14:28; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__PDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoam.html
https://root.cern/root/html532/TMVA__PDEFoam.html:21865,Performance,load,load,21865,"e foam output.; Draw TMVA-process bar instead. void RootPlot2dim(const TString& filename, TString opt, Bool_t CreateCanvas = kTRUE, Bool_t colors = kTRUE); Debugging tool which plots the cells of a 2-dimensional PDEFoam; as rectangles in C++ format readable for ROOT. Parameters:; - filename - filename of ouput root macro. - opt - cell_value, rms, rms_ov_mean; If cell_value is set, the following values will be filled into; the result histogram:; - number of events - in case of classification with 2 separate; foams or multi-target regression; - discriminator - in case of classification with one; unified foam; - target - in case of mono-target regression; If none of {cell_value, rms, rms_ov_mean} is given, the cells; will not be filled.; If 'opt' contains the string 'cellnumber', the index of; each cell is draw in addition. - CreateCanvas - whether to create a new canvas or not. - colors - whether to fill cells with colors or shades of grey. Example:. The following commands load a mono-target regression foam from; file 'foam.root' and create a ROOT macro 'output.C', which; draws all PDEFoam cells with little boxes. The latter are; filled with colors according to the target value stored in the; cell. Also the cell number is drawn. TFile file(""foam.root"");; TMVA::PDEFoam *foam = (TMVA::PDEFoam*) gDirectory->Get(""MonoTargetRegressionFoam"");; foam->RootPlot2dim(""output.C"",""cell_value,cellnumber"");; gROOT->Macro(""output.C"");. void FillBinarySearchTree(const TMVA::Event* ev); Insert event to internal foam's density estimator; PDEFoamDensityBase. void DeleteBinarySearchTree(); Delete the foam's density estimator, which contains the binary; search tree. Float_t VarTransform(Int_t idim, Float_t x) const. std::vector<Float_t> VarTransform(const vector<Float_t>& invec) const. Float_t VarTransformInvers(Int_t idim, Float_t x) const. std::vector<Float_t> VarTransformInvers(const vector<Float_t>& invec) const. PDEFoamDensityBase* GetDistr() const; get internal density. { assert(fDis",MatchSource.WIKI,root/html532/TMVA__PDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoam.html
https://root.cern/root/html532/TMVA__PDEFoam.html:13149,Safety,avoid,avoid,13149,"VA::PDEFoamCell* ); Internal subprogram used by Create.; It initializes content of the newly allocated active cell. void Explore(TMVA::PDEFoamCell* Cell); Internal subprogram used by Create.; It explores newly defined cell with help of special short MC sampling.; As a result, estimates of kTRUE and drive volume is defined/determined; Average and dispersion of the weight distribution will is found along; each edge and the best edge (minimum dispersion, best maximum weight); is memorized for future use.; The optimal division point for eventual future cell division is; determined/recorded. Recorded are also minimum and maximum weight etc.; The volume estimate in all (inactive) parent cells is updated.; Note that links to parents and initial volume = 1/2 parent has to be; already defined prior to calling this routine. If fNmin > 0 then the total number of (training) events found in; the cell during the exploration is stored in the cell. This; information is used withing PeekMax() to avoid splitting cells; which contain less than fNmin events. void Varedu(Double_t* , Int_t& , Double_t& , Double_t& ); Internal subrogram used by Create.; In determines the best edge candidate and the position of the cell division plane; in case of the variance reduction for future cell division,; using results of the MC exploration run stored in fHistEdg. void MakeAlpha(); Internal subrogram used by Create.; Provides random vector Alpha 0< Alpha(i) < 1. Long_t PeekMax(); Internal subprogram used by Create. It finds cell with maximal; driver integral for the purpose of the division. This function; is overridden by the PDEFoam Class to apply cuts on the number; of events in the cell (fNmin) and the cell tree depth; (GetMaxDepth() > 0) during cell buildup. Int_t Divide(TMVA::PDEFoamCell* ); Internal subrogram used by Create.; It divides cell iCell into two daughter cells.; The iCell is retained and tagged as inactive, daughter cells are appended; at the end of the buffer.; New vertex is added ",MatchSource.WIKI,root/html532/TMVA__PDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoam.html
https://root.cern/root/html532/TMVA__PDEFoam.html:20868,Safety,avoid,avoid,20868," - a PDEFoam kernel (optional). If NULL is given, the; kernel is ignored and the pure cell values are; plotted. - nbin - number of bins in x and y direction of result histogram; (optional, default is 50). Returns:; a 2-dimensional histogram. Float_t GetCellValue(const PDEFoamCell* cell, ECellValue cv); Returns the cell value of 'cell' corresponding to the given; option 'cv'. This function should be overridden by the subclass; in order to specify which cell elements to return for a given; cell value 'cv'. By default kValue returns cell element 0, and; kValueError returns cell element 1. Double_t GetCellElement(const TMVA::PDEFoamCell* cell, UInt_t i) const; Returns cell element i of cell 'cell'. If the cell has no; elements or the index 'i' is out of range, than 0 is returned. void SetCellElement(TMVA::PDEFoamCell* cell, UInt_t i, Double_t value); Set cell element i of cell to value. If the cell element i does; not exist, it is created. void OutputGrow(Bool_t finished = false); Overridden function of PDEFoam to avoid native foam output.; Draw TMVA-process bar instead. void RootPlot2dim(const TString& filename, TString opt, Bool_t CreateCanvas = kTRUE, Bool_t colors = kTRUE); Debugging tool which plots the cells of a 2-dimensional PDEFoam; as rectangles in C++ format readable for ROOT. Parameters:; - filename - filename of ouput root macro. - opt - cell_value, rms, rms_ov_mean; If cell_value is set, the following values will be filled into; the result histogram:; - number of events - in case of classification with 2 separate; foams or multi-target regression; - discriminator - in case of classification with one; unified foam; - target - in case of mono-target regression; If none of {cell_value, rms, rms_ov_mean} is given, the cells; will not be filled.; If 'opt' contains the string 'cellnumber', the index of; each cell is draw in addition. - CreateCanvas - whether to create a new canvas or not. - colors - whether to fill cells with colors or shades of grey. Example:. ",MatchSource.WIKI,root/html532/TMVA__PDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoam.html
https://root.cern/root/html532/TMVA__PDEFoam.html:9521,Testability,log,logic,9521,"FoamCell*,allocator<TMVA::PDEFoamCell*> >&) const; Double_tGetCellElement(const TMVA::PDEFoamCell* cell, UInt_t i) const; TMVA::PDEFoamDensityBase*GetDistr() const; voidGrow(); voidInitCells(); voidMakeAlpha(); voidTObject::MakeZombie(); voidOutputGrow(Bool_t finished = false); TMVA::PDEFoamPDEFoam(const TMVA::PDEFoam&); Long_tPeekMax(); voidSetCellElement(TMVA::PDEFoamCell* cell, UInt_t i, Double_t value); voidVaredu(Double_t*, Int_t&, Double_t&, Double_t&). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. Double_t*fAlpha[fDim] Internal parameters of the hyperrectangle; TMVA::PDEFoamCell**fCells[fNCells] Array of ALL cells; TMVA::EDTSeparationfDTSeparationBACKWARDS COMPATIBILITY: split cells according to decision tree logic; Int_tfDimDimension of the integration/simulation space; TMVA::PDEFoamDensityBase*fDistr! distribution of training events; Int_tfEvPerBinMaximum number of effective (wt=1) events per bin; Bool_tfFillFoamWithOrigWeightsBACKWARDS COMPATIBILITY: fill the foam with boost or orig. weights; TMVA::EFoamTypefFoamTypeBACKWARDS COMPATIBILITY: type of foam; TObjArray*fHistEdgHistograms of wt, one for each cell edge; Int_t*fInhiDiv! [fDim] Flags for inhibiting cell division; Int_tfLastCeIndex of the last cell; TMVA::MsgLogger*fLogger! message logger; Int_t*fMaskDiv! [fDim] Dynamic Mask for cell division; UInt_tfMaxDepthmaximum depth of cell tree; Int_tfNBinNo. of bins in the edge histogram for cell MC exploration; Int_tfNCellsMaximum number of cells; UInt_tfNElementsBACKWARDS COMPATIBILITY: number of variables in every cell; Int_tfNSamplNo. of MC events, when dividing (exploring) cell; TStringfNameName of a given instance of the FOAM class; UInt_tfNminminimal number of events in cell to split cell; Int_tfNoActNumber of acti",MatchSource.WIKI,root/html532/TMVA__PDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoam.html
https://root.cern/root/html532/TMVA__PDEFoam.html:10064,Testability,log,logger,10064," Double_t&, Double_t&). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. Double_t*fAlpha[fDim] Internal parameters of the hyperrectangle; TMVA::PDEFoamCell**fCells[fNCells] Array of ALL cells; TMVA::EDTSeparationfDTSeparationBACKWARDS COMPATIBILITY: split cells according to decision tree logic; Int_tfDimDimension of the integration/simulation space; TMVA::PDEFoamDensityBase*fDistr! distribution of training events; Int_tfEvPerBinMaximum number of effective (wt=1) events per bin; Bool_tfFillFoamWithOrigWeightsBACKWARDS COMPATIBILITY: fill the foam with boost or orig. weights; TMVA::EFoamTypefFoamTypeBACKWARDS COMPATIBILITY: type of foam; TObjArray*fHistEdgHistograms of wt, one for each cell edge; Int_t*fInhiDiv! [fDim] Flags for inhibiting cell division; Int_tfLastCeIndex of the last cell; TMVA::MsgLogger*fLogger! message logger; Int_t*fMaskDiv! [fDim] Dynamic Mask for cell division; UInt_tfMaxDepthmaximum depth of cell tree; Int_tfNBinNo. of bins in the edge histogram for cell MC exploration; Int_tfNCellsMaximum number of cells; UInt_tfNElementsBACKWARDS COMPATIBILITY: number of variables in every cell; Int_tfNSamplNo. of MC events, when dividing (exploring) cell; TStringfNameName of a given instance of the FOAM class; UInt_tfNminminimal number of events in cell to split cell; Int_tfNoActNumber of active cells; Bool_tfPeekMaxBACKWARDS COMPATIBILITY: peek up cell with max. driver integral for split; TRandom3*fPseRanPointer to user-defined generator of pseudorandom numbers; Double_t*fRvec[fDim] random number vector from r.n. generator fDim+1 maximum elements; TMVA::Timer*fTimer! timer for graphical output; TObjArray*fVariableNamescollection of all variable names; Float_tfVolFracBACKWARDS COMPATIBILITY: volume fraction (with respect to",MatchSource.WIKI,root/html532/TMVA__PDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoam.html
https://root.cern/root/html532/TMVA__PDEFoam.html:22868,Testability,assert,assert,22868," regression foam from; file 'foam.root' and create a ROOT macro 'output.C', which; draws all PDEFoam cells with little boxes. The latter are; filled with colors according to the target value stored in the; cell. Also the cell number is drawn. TFile file(""foam.root"");; TMVA::PDEFoam *foam = (TMVA::PDEFoam*) gDirectory->Get(""MonoTargetRegressionFoam"");; foam->RootPlot2dim(""output.C"",""cell_value,cellnumber"");; gROOT->Macro(""output.C"");. void FillBinarySearchTree(const TMVA::Event* ev); Insert event to internal foam's density estimator; PDEFoamDensityBase. void DeleteBinarySearchTree(); Delete the foam's density estimator, which contains the binary; search tree. Float_t VarTransform(Int_t idim, Float_t x) const. std::vector<Float_t> VarTransform(const vector<Float_t>& invec) const. Float_t VarTransformInvers(Int_t idim, Float_t x) const. std::vector<Float_t> VarTransformInvers(const vector<Float_t>& invec) const. PDEFoamDensityBase* GetDistr() const; get internal density. { assert(fDistr); return fDistr; }. void Initialize(); ---------- Foam creation functions. {}. void Finalize(); function to call after foam is grown. {}. void SetnCells(Long_t nCells); {fNCells =nCells;}. void SetnSampl(Long_t nSampl); {fNSampl =nSampl;}. void SetnBin(Int_t nBin); {fNBin = nBin;}. void SetEvPerBin(Int_t EvPerBin); {fEvPerBin =EvPerBin;}. void SetDensity(TMVA::PDEFoamDensityBase* dens); { fDistr = dens; }. Int_t GetTotDim() const; coverity[ -tainted_data_return ]. {return fDim; }. TString GetFoamName() const; {return fName; }. UInt_t GetNActiveCells() const; {return fNoAct;}. UInt_t GetNInActiveCells() const; {return GetNCells()-GetNActiveCells();}. UInt_t GetNCells() const; {return fNCells;}. PDEFoamCell* GetRootCell() const; {return fCells[0];}. void SetNmin(UInt_t val); Getters and Setters for user cut options. { fNmin=val; }. UInt_t GetNmin(); { return fNmin; }. void SetMaxDepth(UInt_t maxdepth); { fMaxDepth = maxdepth; }. UInt_t GetMaxDepth() const; { return fMaxDepth; }. Double_t ",MatchSource.WIKI,root/html532/TMVA__PDEFoam.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoam.html
https://root.cern/root/html532/TMVA__PDEFoamCell.html:1294,Availability,error,error,1294," virtual~PDEFoamCell(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidCalcVolume(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; voidFill(Int_t, TMVA::PDEFoamCell*, TMVA::PDEFoamCell*, TMVA::PDEFoamCell*); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; Int_tGetBest() const; TMVA::PDEFoamCell*GetDau0() const; TMVA::PDEFoamCell*GetDau1() const; UInt_tGetDepth(); virtual Option_t*TObject::GetDrawOption() const; Double_tGetDriv() const; static Long_tTObject::GetDtorOnly(); TObject*GetElement() const; voidGetHcub(TMVA::P",MatchSource.WIKI,root/html532/TMVA__PDEFoamCell.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamCell.html
https://root.cern/root/html532/TMVA__PDEFoamCell.html:1378,Availability,error,error,1378,"ractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidCalcVolume(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; voidFill(Int_t, TMVA::PDEFoamCell*, TMVA::PDEFoamCell*, TMVA::PDEFoamCell*); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; Int_tGetBest() const; TMVA::PDEFoamCell*GetDau0() const; TMVA::PDEFoamCell*GetDau1() const; UInt_tGetDepth(); virtual Option_t*TObject::GetDrawOption() const; Double_tGetDriv() const; static Long_tTObject::GetDtorOnly(); TObject*GetElement() const; voidGetHcub(TMVA::PDEFoamVect&, TMVA::PDEFoamVect&) const; voidGetHSize(TMVA::PDEFoamVect&) const; virtual const char*TObject::GetIconName() const; Double_tGetIntg() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; TMVA::PDEFoamCell*GetPare() const;",MatchSource.WIKI,root/html532/TMVA__PDEFoamCell.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamCell.html
https://root.cern/root/html532/TMVA__PDEFoamCell.html:6937,Energy Efficiency,allocate,allocated,6937,"bject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. Int_tfBestBest Edge for division; TReffDaught0Pointer to daughter 1; TReffDaught1Pointer to daughter 2; Short_tfDimDimension of the vector space; Double_tfDriveDriver integral, only for cell build-up; TObject*fElementmay set by the user to save some data in this cell; Double_tfIntegralIntegral over cell (estimate from exploration); TReffParentPointer to parent cell; Int_tfSerialSerial number; Int_tfStatusStatus (active, inactive); Double_tfVolumeCartesian Volume of cell; Double_tfXdivFactor for division. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDEFoamCell(); Default constructor for streamer. PDEFoamCell(Int_t ); User constructor allocating single empty Cell. PDEFoamCell(const TMVA::PDEFoamCell& ); Copy constructor. ~PDEFoamCell(); Destructor. void Fill(Int_t , TMVA::PDEFoamCell* , TMVA::PDEFoamCell* , TMVA::PDEFoamCell* ); Fills in certain data into newly allocated cell. void GetHcub(TMVA::PDEFoamVect& , TMVA::PDEFoamVect& ) const; Provides size and position of the cell; These parameter are calculated by analyzing information in all parents; cells up to the root cell. It takes time but saves memory. void GetHSize(TMVA::PDEFoamVect& ) const; Provides size of the cell; Size parameters are calculated by analyzing information in all parents; cells up to the root cell. It takes time but saves memory. void CalcVolume(void); Calculates volume of the cell using size params which are calculated. UInt_t GetDepth(); Get depth of cell in binary tree, where the root cell has depth; 1. UInt_t GetTreeDepth(UInt_t depth = 0); Get depth of cell tree, starting at this cell. void Print(Option_t* option) const; Printout of the cell geometry parameters for the debug purpose. Double_t GetXdiv() const; Geometry. { return fXdiv;}. Int_t GetBest() const; { return fBest;}. void SetBest(Int_t Best); { fBest =Best;",MatchSource.WIKI,root/html532/TMVA__PDEFoamCell.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamCell.html
https://root.cern/root/html532/TMVA__PDEFoamCell.html:8855,Modifiability,variab,variable,8855,"ion in all parents; cells up to the root cell. It takes time but saves memory. void CalcVolume(void); Calculates volume of the cell using size params which are calculated. UInt_t GetDepth(); Get depth of cell in binary tree, where the root cell has depth; 1. UInt_t GetTreeDepth(UInt_t depth = 0); Get depth of cell tree, starting at this cell. void Print(Option_t* option) const; Printout of the cell geometry parameters for the debug purpose. Double_t GetXdiv() const; Geometry. { return fXdiv;}. Int_t GetBest() const; { return fBest;}. void SetBest(Int_t Best); { fBest =Best;}. void SetXdiv(Double_t Xdiv); { fXdiv =Xdiv;}. Double_t GetVolume() const; { return fVolume;}. Double_t GetIntg() const; { return fIntegral;}. Double_t GetDriv() const; { return fDrive;}. void SetIntg(Double_t Intg); { fIntegral=Intg;}. void SetDriv(Double_t Driv); linked tree organization. { fDrive =Driv;}. Int_t GetStat() const; { return fStatus;}. void SetStat(Int_t Stat); { fStatus=Stat;}. PDEFoamCell* GetPare() const; { return (PDEFoamCell*) fParent.GetObject(); }. PDEFoamCell* GetDau0() const; { return (PDEFoamCell*) fDaught0.GetObject(); }. PDEFoamCell* GetDau1() const; { return (PDEFoamCell*) fDaught1.GetObject(); }. void SetDau0(TMVA::PDEFoamCell* Daug); { fDaught0 = Daug;}. void SetDau1(TMVA::PDEFoamCell* Daug); { fDaught1 = Daug;}. void SetPare(TMVA::PDEFoamCell* Pare); { fParent = Pare;}. void SetSerial(Int_t Serial); { fSerial=Serial;}. Int_t GetSerial() const; { return fSerial;}. void SetElement(TObject* fobj); getter and setter for user variable. { fElement = fobj; }. TObject* GetElement() const. { return fElement; }. » Author: S. Jadach, Tancredi Carli, Dominik Dannheim, Alexander Voigt » Copyright (c) 2008: *; » Last changed: root/tmva $Id: PDEFoamCell.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__PDEFoamCell.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamCell.html
https://root.cern/root/html532/TMVA__PDEFoamDecisionTree.html:540,Availability,error,error,540,". TMVA::PDEFoamDecisionTree. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::PDEFoamDecisionTree. class TMVA::PDEFoamDecisionTree: public TMVA::PDEFoamDiscriminant. PDEFoamDecisionTree. This PDEFoam variant acts like a decision tree and stores in every; cell the discriminant. D = #events with given class / total number of events. as well as the statistical error on the discriminant. It therefore; acts as a discriminant estimator. The decision tree-like behaviour; is achieved by overriding PDEFoamDiscriminant::Explore() to use a; decision tree-like cell splitting algorithm (given a separation; type). This PDEFoam variant should be booked together with the; PDEFoamDecisionTreeDensity density estimator, which returns the; events in a cell without sampling. Function Members (Methods); public:. virtual~PDEFoamDecisionTree(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::PDEFoam::AddVariableName(const char* s); voidTMVA::PDEFoam::AddVariableName(TObjString* s); virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidTMVA::PDEFoam::CheckAll(Int_t); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; voidTMVA::PDEFoam::Create(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::PDEFoam::DeleteBinarySearchTree(); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); TH1D*TMVA::PDEFoam::Draw1Dim(TMVA::ECellValue cell_value, Int_t nbin, TMVA::PDEFoamKernelBase* kernel = NULL); virtual voidTObject::DrawClass() constMENU ; virtual TObje",MatchSource.WIKI,root/html532/TMVA__PDEFoamDecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamDecisionTree.html
https://root.cern/root/html532/TMVA__PDEFoamDecisionTree.html:2248,Availability,error,error,2248,"e(TBrowser* b); voidTMVA::PDEFoam::CheckAll(Int_t); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; voidTMVA::PDEFoam::Create(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::PDEFoam::DeleteBinarySearchTree(); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); TH1D*TMVA::PDEFoam::Draw1Dim(TMVA::ECellValue cell_value, Int_t nbin, TMVA::PDEFoamKernelBase* kernel = NULL); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; voidTMVA::PDEFoam::FillBinarySearchTree(const TMVA::Event* ev); virtual voidTMVA::PDEFoamDiscriminant::FillFoamCells(const TMVA::Event* ev, Float_t wt); virtual voidTMVA::PDEFoamDiscriminant::Finalize(); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual vector<Float_t>TMVA::PDEFoam::GetCellValue(const map<Int_t,Float_t>& xvec, TMVA::ECellValue cv); virtual Float_tTMVA::PDEFoam::GetCellValue(const TMVA::PDEFoamCell* cell, TMVA::ECellValue cv); virtual Float_tTMVA::PDEFoam::GetCellValue(const vector<Float_t>& xvec, TMVA::ECellValue cv, TMVA::PDEFoamKernelBase*); virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TStringTMVA::PDEFoam::GetFoamN",MatchSource.WIKI,root/html532/TMVA__PDEFoamDecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamDecisionTree.html
https://root.cern/root/html532/TMVA__PDEFoamDecisionTree.html:2332,Availability,error,error,2332,"onst char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; voidTMVA::PDEFoam::Create(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::PDEFoam::DeleteBinarySearchTree(); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); TH1D*TMVA::PDEFoam::Draw1Dim(TMVA::ECellValue cell_value, Int_t nbin, TMVA::PDEFoamKernelBase* kernel = NULL); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; voidTMVA::PDEFoam::FillBinarySearchTree(const TMVA::Event* ev); virtual voidTMVA::PDEFoamDiscriminant::FillFoamCells(const TMVA::Event* ev, Float_t wt); virtual voidTMVA::PDEFoamDiscriminant::Finalize(); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual vector<Float_t>TMVA::PDEFoam::GetCellValue(const map<Int_t,Float_t>& xvec, TMVA::ECellValue cv); virtual Float_tTMVA::PDEFoam::GetCellValue(const TMVA::PDEFoamCell* cell, TMVA::ECellValue cv); virtual Float_tTMVA::PDEFoam::GetCellValue(const vector<Float_t>& xvec, TMVA::ECellValue cv, TMVA::PDEFoamKernelBase*); virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TStringTMVA::PDEFoam::GetFoamName() const; virtual const char*TObject::GetIconName() const; UInt_tTMVA::PDEFoam::G",MatchSource.WIKI,root/html532/TMVA__PDEFoamDecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamDecisionTree.html
https://root.cern/root/html532/TMVA__PDEFoamDecisionTree.html:10500,Deployability,integrat,integration,10500,":PDEFoam&); TMVA::PDEFoamDecisionTreePDEFoamDecisionTree(const TMVA::PDEFoamDecisionTree&); TMVA::PDEFoamDiscriminantTMVA::PDEFoamDiscriminant::PDEFoamDiscriminant(const TMVA::PDEFoamDiscriminant&); Long_tTMVA::PDEFoam::PeekMax(); voidTMVA::PDEFoam::SetCellElement(TMVA::PDEFoamCell* cell, UInt_t i, Double_t value); voidTMVA::PDEFoam::Varedu(Double_t*, Int_t&, Double_t&, Double_t&). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. Double_t*TMVA::PDEFoam::fAlpha[fDim] Internal parameters of the hyperrectangle; TMVA::PDEFoamCell**TMVA::PDEFoam::fCells[fNCells] Array of ALL cells; UInt_tTMVA::PDEFoamDiscriminant::fClasssignal class; TMVA::EDTSeparationTMVA::PDEFoam::fDTSeparationBACKWARDS COMPATIBILITY: split cells according to decision tree logic; Int_tTMVA::PDEFoam::fDimDimension of the integration/simulation space; TMVA::PDEFoamDensityBase*TMVA::PDEFoam::fDistr! distribution of training events; Int_tTMVA::PDEFoam::fEvPerBinMaximum number of effective (wt=1) events per bin; Bool_tTMVA::PDEFoam::fFillFoamWithOrigWeightsBACKWARDS COMPATIBILITY: fill the foam with boost or orig. weights; TMVA::EFoamTypeTMVA::PDEFoam::fFoamTypeBACKWARDS COMPATIBILITY: type of foam; TObjArray*TMVA::PDEFoam::fHistEdgHistograms of wt, one for each cell edge; Int_t*TMVA::PDEFoam::fInhiDiv! [fDim] Flags for inhibiting cell division; Int_tTMVA::PDEFoam::fLastCeIndex of the last cell; TMVA::MsgLogger*TMVA::PDEFoam::fLogger! message logger; Int_t*TMVA::PDEFoam::fMaskDiv! [fDim] Dynamic Mask for cell division; UInt_tTMVA::PDEFoam::fMaxDepthmaximum depth of cell tree; Int_tTMVA::PDEFoam::fNBinNo. of bins in the edge histogram for cell MC exploration; Int_tTMVA::PDEFoam::fNCellsMaximum number of cells; UInt_tTMVA::PDEFoam::fNElementsBACKWARDS COMPATIBILITY: number o",MatchSource.WIKI,root/html532/TMVA__PDEFoamDecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamDecisionTree.html
https://root.cern/root/html532/TMVA__PDEFoamDecisionTree.html:10500,Integrability,integrat,integration,10500,":PDEFoam&); TMVA::PDEFoamDecisionTreePDEFoamDecisionTree(const TMVA::PDEFoamDecisionTree&); TMVA::PDEFoamDiscriminantTMVA::PDEFoamDiscriminant::PDEFoamDiscriminant(const TMVA::PDEFoamDiscriminant&); Long_tTMVA::PDEFoam::PeekMax(); voidTMVA::PDEFoam::SetCellElement(TMVA::PDEFoamCell* cell, UInt_t i, Double_t value); voidTMVA::PDEFoam::Varedu(Double_t*, Int_t&, Double_t&, Double_t&). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. Double_t*TMVA::PDEFoam::fAlpha[fDim] Internal parameters of the hyperrectangle; TMVA::PDEFoamCell**TMVA::PDEFoam::fCells[fNCells] Array of ALL cells; UInt_tTMVA::PDEFoamDiscriminant::fClasssignal class; TMVA::EDTSeparationTMVA::PDEFoam::fDTSeparationBACKWARDS COMPATIBILITY: split cells according to decision tree logic; Int_tTMVA::PDEFoam::fDimDimension of the integration/simulation space; TMVA::PDEFoamDensityBase*TMVA::PDEFoam::fDistr! distribution of training events; Int_tTMVA::PDEFoam::fEvPerBinMaximum number of effective (wt=1) events per bin; Bool_tTMVA::PDEFoam::fFillFoamWithOrigWeightsBACKWARDS COMPATIBILITY: fill the foam with boost or orig. weights; TMVA::EFoamTypeTMVA::PDEFoam::fFoamTypeBACKWARDS COMPATIBILITY: type of foam; TObjArray*TMVA::PDEFoam::fHistEdgHistograms of wt, one for each cell edge; Int_t*TMVA::PDEFoam::fInhiDiv! [fDim] Flags for inhibiting cell division; Int_tTMVA::PDEFoam::fLastCeIndex of the last cell; TMVA::MsgLogger*TMVA::PDEFoam::fLogger! message logger; Int_t*TMVA::PDEFoam::fMaskDiv! [fDim] Dynamic Mask for cell division; UInt_tTMVA::PDEFoam::fMaxDepthmaximum depth of cell tree; Int_tTMVA::PDEFoam::fNBinNo. of bins in the edge histogram for cell MC exploration; Int_tTMVA::PDEFoam::fNCellsMaximum number of cells; UInt_tTMVA::PDEFoam::fNElementsBACKWARDS COMPATIBILITY: number o",MatchSource.WIKI,root/html532/TMVA__PDEFoamDecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamDecisionTree.html
https://root.cern/root/html532/TMVA__PDEFoamDecisionTree.html:11122,Integrability,message,message,11122,"OnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. Double_t*TMVA::PDEFoam::fAlpha[fDim] Internal parameters of the hyperrectangle; TMVA::PDEFoamCell**TMVA::PDEFoam::fCells[fNCells] Array of ALL cells; UInt_tTMVA::PDEFoamDiscriminant::fClasssignal class; TMVA::EDTSeparationTMVA::PDEFoam::fDTSeparationBACKWARDS COMPATIBILITY: split cells according to decision tree logic; Int_tTMVA::PDEFoam::fDimDimension of the integration/simulation space; TMVA::PDEFoamDensityBase*TMVA::PDEFoam::fDistr! distribution of training events; Int_tTMVA::PDEFoam::fEvPerBinMaximum number of effective (wt=1) events per bin; Bool_tTMVA::PDEFoam::fFillFoamWithOrigWeightsBACKWARDS COMPATIBILITY: fill the foam with boost or orig. weights; TMVA::EFoamTypeTMVA::PDEFoam::fFoamTypeBACKWARDS COMPATIBILITY: type of foam; TObjArray*TMVA::PDEFoam::fHistEdgHistograms of wt, one for each cell edge; Int_t*TMVA::PDEFoam::fInhiDiv! [fDim] Flags for inhibiting cell division; Int_tTMVA::PDEFoam::fLastCeIndex of the last cell; TMVA::MsgLogger*TMVA::PDEFoam::fLogger! message logger; Int_t*TMVA::PDEFoam::fMaskDiv! [fDim] Dynamic Mask for cell division; UInt_tTMVA::PDEFoam::fMaxDepthmaximum depth of cell tree; Int_tTMVA::PDEFoam::fNBinNo. of bins in the edge histogram for cell MC exploration; Int_tTMVA::PDEFoam::fNCellsMaximum number of cells; UInt_tTMVA::PDEFoam::fNElementsBACKWARDS COMPATIBILITY: number of variables in every cell; Int_tTMVA::PDEFoam::fNSamplNo. of MC events, when dividing (exploring) cell; TStringTMVA::PDEFoam::fNameName of a given instance of the FOAM class; UInt_tTMVA::PDEFoam::fNminminimal number of events in cell to split cell; Int_tTMVA::PDEFoam::fNoActNumber of active cells; Bool_tTMVA::PDEFoam::fPeekMaxBACKWARDS COMPATIBILITY: peek up cell with max. driver integral for split; TRandom3*TMVA::PDEFoam::fPseRanPointer to user-defined generator of pseudorandom numbers; Double_t*TMVA::PDEFoam::fRvec[fDim] random number vector from r.n. generator fDim+1 m",MatchSource.WIKI,root/html532/TMVA__PDEFoamDecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamDecisionTree.html
https://root.cern/root/html532/TMVA__PDEFoamDecisionTree.html:13515,Integrability,rout,routine,13515,"tor from r.n. generator fDim+1 maximum elements; TMVA::Timer*TMVA::PDEFoam::fTimer! timer for graphical output; TObjArray*TMVA::PDEFoam::fVariableNamescollection of all variable names; Float_tTMVA::PDEFoam::fVolFracBACKWARDS COMPATIBILITY: volume fraction (with respect to total phase space; Double_t*TMVA::PDEFoam::fXmax[fDim] maximum for variable transform; Double_t*TMVA::PDEFoam::fXmin[fDim] minimum for variable transform. private:. TMVA::SeparationBase*fSepTypeseparation type. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDEFoamDecisionTree(); Default constructor for streamer, user should not use it. PDEFoamDecisionTree(const TString& , TMVA::SeparationBase* sepType, UInt_t cls); Parameters:. - Name - name of the foam. - sepType - separation type used for the cell splitting (will be; deleted in the destructor). - cls - class to consider as signal when calcualting the purity. PDEFoamDecisionTree(const TMVA::PDEFoamDecisionTree& ); Copy Constructor NOT IMPLEMENTED (NEVER USED). ~PDEFoamDecisionTree(); Destructor; deletes fSepType. void Explore(TMVA::PDEFoamCell* Cell); Internal subprogram used by Create. It explores newly defined; cell with according to the decision tree logic. The separation; set via the 'sepType' option in the constructor. The optimal division point for eventual future cell division is; determined/recorded. Note that links to parents and initial; volume = 1/2 parent has to be already defined prior to calling; this routine. Note, that according to the decision tree logic, a cell is only; split, if the number of (unweighted) events in each dautghter; cell is greater than fNmin. » Author: Alexander Voigt » Copyright (c) 2010: *; » Last changed: root/tmva $Id: PDEFoamDecisionTree.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__PDEFoamDecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamDecisionTree.html
https://root.cern/root/html532/TMVA__PDEFoamDecisionTree.html:11468,Modifiability,variab,variables,11468,"ITY: split cells according to decision tree logic; Int_tTMVA::PDEFoam::fDimDimension of the integration/simulation space; TMVA::PDEFoamDensityBase*TMVA::PDEFoam::fDistr! distribution of training events; Int_tTMVA::PDEFoam::fEvPerBinMaximum number of effective (wt=1) events per bin; Bool_tTMVA::PDEFoam::fFillFoamWithOrigWeightsBACKWARDS COMPATIBILITY: fill the foam with boost or orig. weights; TMVA::EFoamTypeTMVA::PDEFoam::fFoamTypeBACKWARDS COMPATIBILITY: type of foam; TObjArray*TMVA::PDEFoam::fHistEdgHistograms of wt, one for each cell edge; Int_t*TMVA::PDEFoam::fInhiDiv! [fDim] Flags for inhibiting cell division; Int_tTMVA::PDEFoam::fLastCeIndex of the last cell; TMVA::MsgLogger*TMVA::PDEFoam::fLogger! message logger; Int_t*TMVA::PDEFoam::fMaskDiv! [fDim] Dynamic Mask for cell division; UInt_tTMVA::PDEFoam::fMaxDepthmaximum depth of cell tree; Int_tTMVA::PDEFoam::fNBinNo. of bins in the edge histogram for cell MC exploration; Int_tTMVA::PDEFoam::fNCellsMaximum number of cells; UInt_tTMVA::PDEFoam::fNElementsBACKWARDS COMPATIBILITY: number of variables in every cell; Int_tTMVA::PDEFoam::fNSamplNo. of MC events, when dividing (exploring) cell; TStringTMVA::PDEFoam::fNameName of a given instance of the FOAM class; UInt_tTMVA::PDEFoam::fNminminimal number of events in cell to split cell; Int_tTMVA::PDEFoam::fNoActNumber of active cells; Bool_tTMVA::PDEFoam::fPeekMaxBACKWARDS COMPATIBILITY: peek up cell with max. driver integral for split; TRandom3*TMVA::PDEFoam::fPseRanPointer to user-defined generator of pseudorandom numbers; Double_t*TMVA::PDEFoam::fRvec[fDim] random number vector from r.n. generator fDim+1 maximum elements; TMVA::Timer*TMVA::PDEFoam::fTimer! timer for graphical output; TObjArray*TMVA::PDEFoam::fVariableNamescollection of all variable names; Float_tTMVA::PDEFoam::fVolFracBACKWARDS COMPATIBILITY: volume fraction (with respect to total phase space; Double_t*TMVA::PDEFoam::fXmax[fDim] maximum for variable transform; Double_t*TMVA::PDEFoam::fXmin[fDim] m",MatchSource.WIKI,root/html532/TMVA__PDEFoamDecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamDecisionTree.html
https://root.cern/root/html532/TMVA__PDEFoamDecisionTree.html:12181,Modifiability,variab,variable,12181,"xDepthmaximum depth of cell tree; Int_tTMVA::PDEFoam::fNBinNo. of bins in the edge histogram for cell MC exploration; Int_tTMVA::PDEFoam::fNCellsMaximum number of cells; UInt_tTMVA::PDEFoam::fNElementsBACKWARDS COMPATIBILITY: number of variables in every cell; Int_tTMVA::PDEFoam::fNSamplNo. of MC events, when dividing (exploring) cell; TStringTMVA::PDEFoam::fNameName of a given instance of the FOAM class; UInt_tTMVA::PDEFoam::fNminminimal number of events in cell to split cell; Int_tTMVA::PDEFoam::fNoActNumber of active cells; Bool_tTMVA::PDEFoam::fPeekMaxBACKWARDS COMPATIBILITY: peek up cell with max. driver integral for split; TRandom3*TMVA::PDEFoam::fPseRanPointer to user-defined generator of pseudorandom numbers; Double_t*TMVA::PDEFoam::fRvec[fDim] random number vector from r.n. generator fDim+1 maximum elements; TMVA::Timer*TMVA::PDEFoam::fTimer! timer for graphical output; TObjArray*TMVA::PDEFoam::fVariableNamescollection of all variable names; Float_tTMVA::PDEFoam::fVolFracBACKWARDS COMPATIBILITY: volume fraction (with respect to total phase space; Double_t*TMVA::PDEFoam::fXmax[fDim] maximum for variable transform; Double_t*TMVA::PDEFoam::fXmin[fDim] minimum for variable transform. private:. TMVA::SeparationBase*fSepTypeseparation type. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDEFoamDecisionTree(); Default constructor for streamer, user should not use it. PDEFoamDecisionTree(const TString& , TMVA::SeparationBase* sepType, UInt_t cls); Parameters:. - Name - name of the foam. - sepType - separation type used for the cell splitting (will be; deleted in the destructor). - cls - class to consider as signal when calcualting the purity. PDEFoamDecisionTree(const TMVA::PDEFoamDecisionTree& ); Copy Constructor NOT IMPLEMENTED (NEVER USED). ~PDEFoamDecisionTree(); Destructor; deletes fSepType. void Explore(TMVA::PDEFoamCell* Cell); Internal subprogram used by Create. It explores newly defined; cell with according to th",MatchSource.WIKI,root/html532/TMVA__PDEFoamDecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamDecisionTree.html
https://root.cern/root/html532/TMVA__PDEFoamDecisionTree.html:12352,Modifiability,variab,variable,12352,"xDepthmaximum depth of cell tree; Int_tTMVA::PDEFoam::fNBinNo. of bins in the edge histogram for cell MC exploration; Int_tTMVA::PDEFoam::fNCellsMaximum number of cells; UInt_tTMVA::PDEFoam::fNElementsBACKWARDS COMPATIBILITY: number of variables in every cell; Int_tTMVA::PDEFoam::fNSamplNo. of MC events, when dividing (exploring) cell; TStringTMVA::PDEFoam::fNameName of a given instance of the FOAM class; UInt_tTMVA::PDEFoam::fNminminimal number of events in cell to split cell; Int_tTMVA::PDEFoam::fNoActNumber of active cells; Bool_tTMVA::PDEFoam::fPeekMaxBACKWARDS COMPATIBILITY: peek up cell with max. driver integral for split; TRandom3*TMVA::PDEFoam::fPseRanPointer to user-defined generator of pseudorandom numbers; Double_t*TMVA::PDEFoam::fRvec[fDim] random number vector from r.n. generator fDim+1 maximum elements; TMVA::Timer*TMVA::PDEFoam::fTimer! timer for graphical output; TObjArray*TMVA::PDEFoam::fVariableNamescollection of all variable names; Float_tTMVA::PDEFoam::fVolFracBACKWARDS COMPATIBILITY: volume fraction (with respect to total phase space; Double_t*TMVA::PDEFoam::fXmax[fDim] maximum for variable transform; Double_t*TMVA::PDEFoam::fXmin[fDim] minimum for variable transform. private:. TMVA::SeparationBase*fSepTypeseparation type. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDEFoamDecisionTree(); Default constructor for streamer, user should not use it. PDEFoamDecisionTree(const TString& , TMVA::SeparationBase* sepType, UInt_t cls); Parameters:. - Name - name of the foam. - sepType - separation type used for the cell splitting (will be; deleted in the destructor). - cls - class to consider as signal when calcualting the purity. PDEFoamDecisionTree(const TMVA::PDEFoamDecisionTree& ); Copy Constructor NOT IMPLEMENTED (NEVER USED). ~PDEFoamDecisionTree(); Destructor; deletes fSepType. void Explore(TMVA::PDEFoamCell* Cell); Internal subprogram used by Create. It explores newly defined; cell with according to th",MatchSource.WIKI,root/html532/TMVA__PDEFoamDecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamDecisionTree.html
https://root.cern/root/html532/TMVA__PDEFoamDecisionTree.html:12420,Modifiability,variab,variable,12420,"xDepthmaximum depth of cell tree; Int_tTMVA::PDEFoam::fNBinNo. of bins in the edge histogram for cell MC exploration; Int_tTMVA::PDEFoam::fNCellsMaximum number of cells; UInt_tTMVA::PDEFoam::fNElementsBACKWARDS COMPATIBILITY: number of variables in every cell; Int_tTMVA::PDEFoam::fNSamplNo. of MC events, when dividing (exploring) cell; TStringTMVA::PDEFoam::fNameName of a given instance of the FOAM class; UInt_tTMVA::PDEFoam::fNminminimal number of events in cell to split cell; Int_tTMVA::PDEFoam::fNoActNumber of active cells; Bool_tTMVA::PDEFoam::fPeekMaxBACKWARDS COMPATIBILITY: peek up cell with max. driver integral for split; TRandom3*TMVA::PDEFoam::fPseRanPointer to user-defined generator of pseudorandom numbers; Double_t*TMVA::PDEFoam::fRvec[fDim] random number vector from r.n. generator fDim+1 maximum elements; TMVA::Timer*TMVA::PDEFoam::fTimer! timer for graphical output; TObjArray*TMVA::PDEFoam::fVariableNamescollection of all variable names; Float_tTMVA::PDEFoam::fVolFracBACKWARDS COMPATIBILITY: volume fraction (with respect to total phase space; Double_t*TMVA::PDEFoam::fXmax[fDim] maximum for variable transform; Double_t*TMVA::PDEFoam::fXmin[fDim] minimum for variable transform. private:. TMVA::SeparationBase*fSepTypeseparation type. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDEFoamDecisionTree(); Default constructor for streamer, user should not use it. PDEFoamDecisionTree(const TString& , TMVA::SeparationBase* sepType, UInt_t cls); Parameters:. - Name - name of the foam. - sepType - separation type used for the cell splitting (will be; deleted in the destructor). - cls - class to consider as signal when calcualting the purity. PDEFoamDecisionTree(const TMVA::PDEFoamDecisionTree& ); Copy Constructor NOT IMPLEMENTED (NEVER USED). ~PDEFoamDecisionTree(); Destructor; deletes fSepType. void Explore(TMVA::PDEFoamCell* Cell); Internal subprogram used by Create. It explores newly defined; cell with according to th",MatchSource.WIKI,root/html532/TMVA__PDEFoamDecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamDecisionTree.html
https://root.cern/root/html532/TMVA__PDEFoamDecisionTree.html:10452,Testability,log,logic,10452,":PDEFoam&); TMVA::PDEFoamDecisionTreePDEFoamDecisionTree(const TMVA::PDEFoamDecisionTree&); TMVA::PDEFoamDiscriminantTMVA::PDEFoamDiscriminant::PDEFoamDiscriminant(const TMVA::PDEFoamDiscriminant&); Long_tTMVA::PDEFoam::PeekMax(); voidTMVA::PDEFoam::SetCellElement(TMVA::PDEFoamCell* cell, UInt_t i, Double_t value); voidTMVA::PDEFoam::Varedu(Double_t*, Int_t&, Double_t&, Double_t&). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. Double_t*TMVA::PDEFoam::fAlpha[fDim] Internal parameters of the hyperrectangle; TMVA::PDEFoamCell**TMVA::PDEFoam::fCells[fNCells] Array of ALL cells; UInt_tTMVA::PDEFoamDiscriminant::fClasssignal class; TMVA::EDTSeparationTMVA::PDEFoam::fDTSeparationBACKWARDS COMPATIBILITY: split cells according to decision tree logic; Int_tTMVA::PDEFoam::fDimDimension of the integration/simulation space; TMVA::PDEFoamDensityBase*TMVA::PDEFoam::fDistr! distribution of training events; Int_tTMVA::PDEFoam::fEvPerBinMaximum number of effective (wt=1) events per bin; Bool_tTMVA::PDEFoam::fFillFoamWithOrigWeightsBACKWARDS COMPATIBILITY: fill the foam with boost or orig. weights; TMVA::EFoamTypeTMVA::PDEFoam::fFoamTypeBACKWARDS COMPATIBILITY: type of foam; TObjArray*TMVA::PDEFoam::fHistEdgHistograms of wt, one for each cell edge; Int_t*TMVA::PDEFoam::fInhiDiv! [fDim] Flags for inhibiting cell division; Int_tTMVA::PDEFoam::fLastCeIndex of the last cell; TMVA::MsgLogger*TMVA::PDEFoam::fLogger! message logger; Int_t*TMVA::PDEFoam::fMaskDiv! [fDim] Dynamic Mask for cell division; UInt_tTMVA::PDEFoam::fMaxDepthmaximum depth of cell tree; Int_tTMVA::PDEFoam::fNBinNo. of bins in the edge histogram for cell MC exploration; Int_tTMVA::PDEFoam::fNCellsMaximum number of cells; UInt_tTMVA::PDEFoam::fNElementsBACKWARDS COMPATIBILITY: number o",MatchSource.WIKI,root/html532/TMVA__PDEFoamDecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamDecisionTree.html
https://root.cern/root/html532/TMVA__PDEFoamDecisionTree.html:11130,Testability,log,logger,11130,"OnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. Double_t*TMVA::PDEFoam::fAlpha[fDim] Internal parameters of the hyperrectangle; TMVA::PDEFoamCell**TMVA::PDEFoam::fCells[fNCells] Array of ALL cells; UInt_tTMVA::PDEFoamDiscriminant::fClasssignal class; TMVA::EDTSeparationTMVA::PDEFoam::fDTSeparationBACKWARDS COMPATIBILITY: split cells according to decision tree logic; Int_tTMVA::PDEFoam::fDimDimension of the integration/simulation space; TMVA::PDEFoamDensityBase*TMVA::PDEFoam::fDistr! distribution of training events; Int_tTMVA::PDEFoam::fEvPerBinMaximum number of effective (wt=1) events per bin; Bool_tTMVA::PDEFoam::fFillFoamWithOrigWeightsBACKWARDS COMPATIBILITY: fill the foam with boost or orig. weights; TMVA::EFoamTypeTMVA::PDEFoam::fFoamTypeBACKWARDS COMPATIBILITY: type of foam; TObjArray*TMVA::PDEFoam::fHistEdgHistograms of wt, one for each cell edge; Int_t*TMVA::PDEFoam::fInhiDiv! [fDim] Flags for inhibiting cell division; Int_tTMVA::PDEFoam::fLastCeIndex of the last cell; TMVA::MsgLogger*TMVA::PDEFoam::fLogger! message logger; Int_t*TMVA::PDEFoam::fMaskDiv! [fDim] Dynamic Mask for cell division; UInt_tTMVA::PDEFoam::fMaxDepthmaximum depth of cell tree; Int_tTMVA::PDEFoam::fNBinNo. of bins in the edge histogram for cell MC exploration; Int_tTMVA::PDEFoam::fNCellsMaximum number of cells; UInt_tTMVA::PDEFoam::fNElementsBACKWARDS COMPATIBILITY: number of variables in every cell; Int_tTMVA::PDEFoam::fNSamplNo. of MC events, when dividing (exploring) cell; TStringTMVA::PDEFoam::fNameName of a given instance of the FOAM class; UInt_tTMVA::PDEFoam::fNminminimal number of events in cell to split cell; Int_tTMVA::PDEFoam::fNoActNumber of active cells; Bool_tTMVA::PDEFoam::fPeekMaxBACKWARDS COMPATIBILITY: peek up cell with max. driver integral for split; TRandom3*TMVA::PDEFoam::fPseRanPointer to user-defined generator of pseudorandom numbers; Double_t*TMVA::PDEFoam::fRvec[fDim] random number vector from r.n. generator fDim+1 m",MatchSource.WIKI,root/html532/TMVA__PDEFoamDecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamDecisionTree.html
https://root.cern/root/html532/TMVA__PDEFoamDecisionTree.html:13248,Testability,log,logic,13248,"tor from r.n. generator fDim+1 maximum elements; TMVA::Timer*TMVA::PDEFoam::fTimer! timer for graphical output; TObjArray*TMVA::PDEFoam::fVariableNamescollection of all variable names; Float_tTMVA::PDEFoam::fVolFracBACKWARDS COMPATIBILITY: volume fraction (with respect to total phase space; Double_t*TMVA::PDEFoam::fXmax[fDim] maximum for variable transform; Double_t*TMVA::PDEFoam::fXmin[fDim] minimum for variable transform. private:. TMVA::SeparationBase*fSepTypeseparation type. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDEFoamDecisionTree(); Default constructor for streamer, user should not use it. PDEFoamDecisionTree(const TString& , TMVA::SeparationBase* sepType, UInt_t cls); Parameters:. - Name - name of the foam. - sepType - separation type used for the cell splitting (will be; deleted in the destructor). - cls - class to consider as signal when calcualting the purity. PDEFoamDecisionTree(const TMVA::PDEFoamDecisionTree& ); Copy Constructor NOT IMPLEMENTED (NEVER USED). ~PDEFoamDecisionTree(); Destructor; deletes fSepType. void Explore(TMVA::PDEFoamCell* Cell); Internal subprogram used by Create. It explores newly defined; cell with according to the decision tree logic. The separation; set via the 'sepType' option in the constructor. The optimal division point for eventual future cell division is; determined/recorded. Note that links to parents and initial; volume = 1/2 parent has to be already defined prior to calling; this routine. Note, that according to the decision tree logic, a cell is only; split, if the number of (unweighted) events in each dautghter; cell is greater than fNmin. » Author: Alexander Voigt » Copyright (c) 2010: *; » Last changed: root/tmva $Id: PDEFoamDecisionTree.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__PDEFoamDecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamDecisionTree.html
https://root.cern/root/html532/TMVA__PDEFoamDecisionTree.html:13566,Testability,log,logic,13566,"tor from r.n. generator fDim+1 maximum elements; TMVA::Timer*TMVA::PDEFoam::fTimer! timer for graphical output; TObjArray*TMVA::PDEFoam::fVariableNamescollection of all variable names; Float_tTMVA::PDEFoam::fVolFracBACKWARDS COMPATIBILITY: volume fraction (with respect to total phase space; Double_t*TMVA::PDEFoam::fXmax[fDim] maximum for variable transform; Double_t*TMVA::PDEFoam::fXmin[fDim] minimum for variable transform. private:. TMVA::SeparationBase*fSepTypeseparation type. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDEFoamDecisionTree(); Default constructor for streamer, user should not use it. PDEFoamDecisionTree(const TString& , TMVA::SeparationBase* sepType, UInt_t cls); Parameters:. - Name - name of the foam. - sepType - separation type used for the cell splitting (will be; deleted in the destructor). - cls - class to consider as signal when calcualting the purity. PDEFoamDecisionTree(const TMVA::PDEFoamDecisionTree& ); Copy Constructor NOT IMPLEMENTED (NEVER USED). ~PDEFoamDecisionTree(); Destructor; deletes fSepType. void Explore(TMVA::PDEFoamCell* Cell); Internal subprogram used by Create. It explores newly defined; cell with according to the decision tree logic. The separation; set via the 'sepType' option in the constructor. The optimal division point for eventual future cell division is; determined/recorded. Note that links to parents and initial; volume = 1/2 parent has to be already defined prior to calling; this routine. Note, that according to the decision tree logic, a cell is only; split, if the number of (unweighted) events in each dautghter; cell is greater than fNmin. » Author: Alexander Voigt » Copyright (c) 2010: *; » Last changed: root/tmva $Id: PDEFoamDecisionTree.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__PDEFoamDecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamDecisionTree.html
https://root.cern/root/html532/TMVA__PDEFoamDecisionTreeDensity.html:1638,Availability,error,error,1638,"Density(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Double_tDensity(vector<Double_t>& Xarg, Double_t& event_density); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; voidTMVA::PDEFoamDensityBase::FillBinarySearchTree(const TMVA::Event* ev); virtual voidFillHistograms(TMVA::Volume&, vector<TH1D*>&, vector<TH1D*>&, vector<TH1D*>&, vector<TH1D*>&); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const vector<Double_t>&TMVA::PDEFoamDensityBase::GetBox() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject",MatchSource.WIKI,root/html532/TMVA__PDEFoamDecisionTreeDensity.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamDecisionTreeDensity.html
https://root.cern/root/html532/TMVA__PDEFoamDecisionTreeDensity.html:1722,Availability,error,error,1722,"t::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Double_tDensity(vector<Double_t>& Xarg, Double_t& event_density); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; voidTMVA::PDEFoamDensityBase::FillBinarySearchTree(const TMVA::Event* ev); virtual voidFillHistograms(TMVA::Volume&, vector<TH1D*>&, vector<TH1D*>&, vector<TH1D*>&, vector<TH1D*>&); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const vector<Double_t>&TMVA::PDEFoamDensityBase::GetBox() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual UL",MatchSource.WIKI,root/html532/TMVA__PDEFoamDecisionTreeDensity.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamDecisionTreeDensity.html
https://root.cern/root/html532/TMVA__PDEFoamDecisionTreeDensity.html:6283,Integrability,message,message,6283,"ol_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; Double_tTMVA::PDEFoamDensityBase::GetBoxVolume(); TMVA::MsgLogger&TMVA::PDEFoamDensityBase::Log() const; voidTObject::MakeZombie(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TMVA::BinarySearchTree*TMVA::PDEFoamDensityBase::fBstBinary tree to find events within a volume; UInt_tfClasssignal class; TMVA::MsgLogger*TMVA::PDEFoamDensityBase::fLogger! message logger. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDEFoamDecisionTreeDensity(); {}. PDEFoamDecisionTreeDensity(vector<Double_t> box, UInt_t cls); User construcor:. Parameters:. - box - size of the range-searching box (n-dimensional; std::vector). - cls - event class used for the range-searching. PDEFoamDecisionTreeDensity(const TMVA::PDEFoamDecisionTreeDensity& ); Copy constructor. Double_t Density(vector<Double_t>& Xarg, Double_t& event_density); This function is not used in the decision tree like PDEFoam,; instead FillHist() is used. void FillHistograms(TMVA::Volume& , vector<TH1D*>& , vector<TH1D*>& , vector<TH1D*>& , vector<TH1D*>& ); Fill the given histograms with signal and background events,; which are found in the volume. Parameters:. - volume - volume box to search in. - hsig, hbkg, hsig_unw, hbkg_unw - histograms with weighted and; unweighte",MatchSource.WIKI,root/html532/TMVA__PDEFoamDecisionTreeDensity.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamDecisionTreeDensity.html
https://root.cern/root/html532/TMVA__PDEFoamDecisionTreeDensity.html:6291,Testability,log,logger,6291,"ol_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; Double_tTMVA::PDEFoamDensityBase::GetBoxVolume(); TMVA::MsgLogger&TMVA::PDEFoamDensityBase::Log() const; voidTObject::MakeZombie(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TMVA::BinarySearchTree*TMVA::PDEFoamDensityBase::fBstBinary tree to find events within a volume; UInt_tfClasssignal class; TMVA::MsgLogger*TMVA::PDEFoamDensityBase::fLogger! message logger. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDEFoamDecisionTreeDensity(); {}. PDEFoamDecisionTreeDensity(vector<Double_t> box, UInt_t cls); User construcor:. Parameters:. - box - size of the range-searching box (n-dimensional; std::vector). - cls - event class used for the range-searching. PDEFoamDecisionTreeDensity(const TMVA::PDEFoamDecisionTreeDensity& ); Copy constructor. Double_t Density(vector<Double_t>& Xarg, Double_t& event_density); This function is not used in the decision tree like PDEFoam,; instead FillHist() is used. void FillHistograms(TMVA::Volume& , vector<TH1D*>& , vector<TH1D*>& , vector<TH1D*>& , vector<TH1D*>& ); Fill the given histograms with signal and background events,; which are found in the volume. Parameters:. - volume - volume box to search in. - hsig, hbkg, hsig_unw, hbkg_unw - histograms with weighted and; unweighte",MatchSource.WIKI,root/html532/TMVA__PDEFoamDecisionTreeDensity.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamDecisionTreeDensity.html
https://root.cern/root/html532/TMVA__PDEFoamDensityBase.html:1252,Availability,avail,available,1252,"MVA; » TMVA::PDEFoamDensityBase. class TMVA::PDEFoamDensityBase: public TObject. PDEFoamDensityBase. This is an abstract class, which provides an interface for a; PDEFoam density estimator. Derived classes have to implement the; Density(...) function, which returns the density of a certain; quantity at a given phase-space point during the foam build-up. Variants of PDEFoamDensityBase are:. - PDEFoamEventDensity; - PDEFoamDiscriminantDensity; - PDEFoamTargetDensity; - PDEFoamDecisionTreeDensity. Usage:. The user has to instantiate a child class of PDEFoamDensityBase and; set the pointer to the owner, which is a PDEFoam object:. PDEFoamDensityBase *dens = new MyDensity();; pdefoam->SetDensity(dens);. Afterwards the binary search tree should be filled with TMVA; events, by either using. pdefoam->FillBinarySearchTree(event);. or. dens->FillBinarySearchTree(event);. Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~PDEFoamDensityBase(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Double_tDensity(vector<Double_t>& Xarg, Double_t& event_density); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject",MatchSource.WIKI,root/html532/TMVA__PDEFoamDensityBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamDensityBase.html
https://root.cern/root/html532/TMVA__PDEFoamDensityBase.html:2302,Availability,error,error,2302,"ityBase(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Double_tDensity(vector<Double_t>& Xarg, Double_t& event_density); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; voidFillBinarySearchTree(const TMVA::Event* ev); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const vector<Double_t>&GetBox() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, c",MatchSource.WIKI,root/html532/TMVA__PDEFoamDensityBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamDensityBase.html
https://root.cern/root/html532/TMVA__PDEFoamDensityBase.html:2386,Availability,error,error,2386,"t::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Double_tDensity(vector<Double_t>& Xarg, Double_t& event_density); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; voidFillBinarySearchTree(const TMVA::Event* ev); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const vector<Double_t>&GetBox() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname)",MatchSource.WIKI,root/html532/TMVA__PDEFoamDensityBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamDensityBase.html
https://root.cern/root/html532/TMVA__PDEFoamDensityBase.html:390,Integrability,interface,interface,390,". TMVA::PDEFoamDensityBase. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::PDEFoamDensityBase. class TMVA::PDEFoamDensityBase: public TObject. PDEFoamDensityBase. This is an abstract class, which provides an interface for a; PDEFoam density estimator. Derived classes have to implement the; Density(...) function, which returns the density of a certain; quantity at a given phase-space point during the foam build-up. Variants of PDEFoamDensityBase are:. - PDEFoamEventDensity; - PDEFoamDiscriminantDensity; - PDEFoamTargetDensity; - PDEFoamDecisionTreeDensity. Usage:. The user has to instantiate a child class of PDEFoamDensityBase and; set the pointer to the owner, which is a PDEFoam object:. PDEFoamDensityBase *dens = new MyDensity();; pdefoam->SetDensity(dens);. Afterwards the binary search tree should be filled with TMVA; events, by either using. pdefoam->FillBinarySearchTree(event);. or. dens->FillBinarySearchTree(event);. Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~PDEFoamDensityBase(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Double_tDensity(vector<Double_t>& Xarg, Double_t& event_density); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virt",MatchSource.WIKI,root/html532/TMVA__PDEFoamDensityBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamDensityBase.html
https://root.cern/root/html532/TMVA__PDEFoamDensityBase.html:6359,Integrability,message,message,6359,"Buffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; Double_tGetBoxVolume(); TMVA::MsgLogger&Log() const; voidTObject::MakeZombie(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TMVA::BinarySearchTree*fBstBinary tree to find events within a volume; TMVA::MsgLogger*fLogger! message logger. private:. vector<Double_t>fBoxrange-searching box; Bool_tfBoxHasChangedrange searching box has changed; Double_tfBoxVolumevolume of range searching box. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; ~PDEFoamDensityBase(). void FillBinarySearchTree(const TMVA::Event* ev); This method inserts the given event 'ev' it into the binary; search tree. Double_t GetBoxVolume(); Returns the volume of range searching box fBox. If the range searching box 'fBox' has changed (fBoxHasChanged is; kTRUE), recalculate the box volume and set fBoxHasChanged to; kFALSE. void SetBox(vector<Double_t> box); set the range-searching box. { fBox = box; fBoxHasChanged = kTRUE; }. const std::vector<Double_t>& GetBox() const; get the range-searching box. { return fBox; }. Double_t Density(vector<Double_t>& Xarg, Double_t& event_density); main function used by PDEFoam; returns density at a given point by range search",MatchSource.WIKI,root/html532/TMVA__PDEFoamDensityBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamDensityBase.html
https://root.cern/root/html532/TMVA__PDEFoamDensityBase.html:6367,Testability,log,logger,6367,"Buffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; Double_tGetBoxVolume(); TMVA::MsgLogger&Log() const; voidTObject::MakeZombie(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TMVA::BinarySearchTree*fBstBinary tree to find events within a volume; TMVA::MsgLogger*fLogger! message logger. private:. vector<Double_t>fBoxrange-searching box; Bool_tfBoxHasChangedrange searching box has changed; Double_tfBoxVolumevolume of range searching box. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; ~PDEFoamDensityBase(). void FillBinarySearchTree(const TMVA::Event* ev); This method inserts the given event 'ev' it into the binary; search tree. Double_t GetBoxVolume(); Returns the volume of range searching box fBox. If the range searching box 'fBox' has changed (fBoxHasChanged is; kTRUE), recalculate the box volume and set fBoxHasChanged to; kFALSE. void SetBox(vector<Double_t> box); set the range-searching box. { fBox = box; fBoxHasChanged = kTRUE; }. const std::vector<Double_t>& GetBox() const; get the range-searching box. { return fBox; }. Double_t Density(vector<Double_t>& Xarg, Double_t& event_density); main function used by PDEFoam; returns density at a given point by range search",MatchSource.WIKI,root/html532/TMVA__PDEFoamDensityBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamDensityBase.html
https://root.cern/root/html532/TMVA__PDEFoamDiscriminant.html:497,Availability,error,error,497,". TMVA::PDEFoamDiscriminant. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::PDEFoamDiscriminant. class TMVA::PDEFoamDiscriminant: public TMVA::PDEFoam. PDEFoamDiscriminant. This PDEFoam variant stores in every cell the discriminant. D = #events with given class / total number of events. as well as the statistical error on the discriminant. It therefore; acts as a discriminant estimator. It should be booked together; with the PDEFoamDiscriminantDensity density estimator, which; returns the discriminant density at a given phase space point; during the foam build-up. Function Members (Methods); public:. virtual~PDEFoamDiscriminant(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::PDEFoam::AddVariableName(const char* s); voidTMVA::PDEFoam::AddVariableName(TObjString* s); virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidTMVA::PDEFoam::CheckAll(Int_t); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; voidTMVA::PDEFoam::Create(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::PDEFoam::DeleteBinarySearchTree(); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); TH1D*TMVA::PDEFoam::Draw1Dim(TMVA::ECellValue cell_value, Int_t nbin, TMVA::PDEFoamKernelBase* kernel = NULL); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::",MatchSource.WIKI,root/html532/TMVA__PDEFoamDiscriminant.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamDiscriminant.html
https://root.cern/root/html532/TMVA__PDEFoamDiscriminant.html:2056,Availability,error,error,2056,"e(TBrowser* b); voidTMVA::PDEFoam::CheckAll(Int_t); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; voidTMVA::PDEFoam::Create(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::PDEFoam::DeleteBinarySearchTree(); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); TH1D*TMVA::PDEFoam::Draw1Dim(TMVA::ECellValue cell_value, Int_t nbin, TMVA::PDEFoamKernelBase* kernel = NULL); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; voidTMVA::PDEFoam::FillBinarySearchTree(const TMVA::Event* ev); virtual voidFillFoamCells(const TMVA::Event* ev, Float_t wt); virtual voidFinalize(); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual vector<Float_t>TMVA::PDEFoam::GetCellValue(const map<Int_t,Float_t>& xvec, TMVA::ECellValue cv); virtual Float_tTMVA::PDEFoam::GetCellValue(const TMVA::PDEFoamCell* cell, TMVA::ECellValue cv); virtual Float_tTMVA::PDEFoam::GetCellValue(const vector<Float_t>& xvec, TMVA::ECellValue cv, TMVA::PDEFoamKernelBase*); virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TStringTMVA::PDEFoam::GetFoamName() const; virtual const char*TObject::GetIconName()",MatchSource.WIKI,root/html532/TMVA__PDEFoamDiscriminant.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamDiscriminant.html
https://root.cern/root/html532/TMVA__PDEFoamDiscriminant.html:2140,Availability,error,error,2140,"onst char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; voidTMVA::PDEFoam::Create(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::PDEFoam::DeleteBinarySearchTree(); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); TH1D*TMVA::PDEFoam::Draw1Dim(TMVA::ECellValue cell_value, Int_t nbin, TMVA::PDEFoamKernelBase* kernel = NULL); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; voidTMVA::PDEFoam::FillBinarySearchTree(const TMVA::Event* ev); virtual voidFillFoamCells(const TMVA::Event* ev, Float_t wt); virtual voidFinalize(); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual vector<Float_t>TMVA::PDEFoam::GetCellValue(const map<Int_t,Float_t>& xvec, TMVA::ECellValue cv); virtual Float_tTMVA::PDEFoam::GetCellValue(const TMVA::PDEFoamCell* cell, TMVA::ECellValue cv); virtual Float_tTMVA::PDEFoam::GetCellValue(const vector<Float_t>& xvec, TMVA::ECellValue cv, TMVA::PDEFoamKernelBase*); virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TStringTMVA::PDEFoam::GetFoamName() const; virtual const char*TObject::GetIconName() const; UInt_tTMVA::PDEFoam::GetMaxDepth() const; UInt_tTMVA::PDEFoam::GetNActiveCel",MatchSource.WIKI,root/html532/TMVA__PDEFoamDiscriminant.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamDiscriminant.html
https://root.cern/root/html532/TMVA__PDEFoamDiscriminant.html:12455,Availability,error,error,12455,"ments; TMVA::Timer*TMVA::PDEFoam::fTimer! timer for graphical output; TObjArray*TMVA::PDEFoam::fVariableNamescollection of all variable names; Float_tTMVA::PDEFoam::fVolFracBACKWARDS COMPATIBILITY: volume fraction (with respect to total phase space; Double_t*TMVA::PDEFoam::fXmax[fDim] maximum for variable transform; Double_t*TMVA::PDEFoam::fXmin[fDim] minimum for variable transform. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDEFoamDiscriminant(); Default constructor for streamer, user should not use it. PDEFoamDiscriminant(const TString& , UInt_t ); {}. PDEFoamDiscriminant(const TMVA::PDEFoamDiscriminant& ); Copy Constructor NOT IMPLEMENTED (NEVER USED). void FillFoamCells(const TMVA::Event* ev, Float_t wt); This function fills an event into the discriminant PDEFoam. The; event weight 'wt' is filled into cell element 0 if the event is; of class fClass, and filled into cell element 1 otherwise. void Finalize(); Calc discriminator and its error for every cell and save it to; the cell. TH2D* Project2(Int_t , Int_t , TMVA::ECellValue , TMVA::PDEFoamKernelBase* , UInt_t ); Project foam variable idim1 and variable idim2 to histogram.; The projection algorithm is modified such that the z axis range; of the returned histogram is [0, 1], as necessary for the; interpretation as a discriminator. This is done by weighting; the cell values (in case of cell_value = kValue) by the cell; volume in all dimensions, excluding 'idim1' and 'idim2'. Parameters:. - idim1, idim2 - dimensions to project to. - cell_value - the cell value to draw. - kernel - a PDEFoam kernel (optional). If NULL is given, the; kernel is ignored and the pure cell values are; plotted. - nbin - number of bins in x and y direction of result histogram; (optional, default is 50). Returns:; a 2-dimensional histogram. virtual ~PDEFoamDiscriminant(); {}. » Author: Tancredi Carli, Dominik Dannheim, Alexander Voigt » Copyright (c) 2008, 2010: *; » Last changed: root/tmva $I",MatchSource.WIKI,root/html532/TMVA__PDEFoamDiscriminant.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamDiscriminant.html
https://root.cern/root/html532/TMVA__PDEFoamDiscriminant.html:9901,Deployability,integrat,integration,9901,"t::MakeZombie(); voidTMVA::PDEFoam::OutputGrow(Bool_t finished = false); TMVA::PDEFoamTMVA::PDEFoam::PDEFoam(const TMVA::PDEFoam&); TMVA::PDEFoamDiscriminantPDEFoamDiscriminant(const TMVA::PDEFoamDiscriminant&); Long_tTMVA::PDEFoam::PeekMax(); voidTMVA::PDEFoam::SetCellElement(TMVA::PDEFoamCell* cell, UInt_t i, Double_t value); voidTMVA::PDEFoam::Varedu(Double_t*, Int_t&, Double_t&, Double_t&). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. Double_t*TMVA::PDEFoam::fAlpha[fDim] Internal parameters of the hyperrectangle; TMVA::PDEFoamCell**TMVA::PDEFoam::fCells[fNCells] Array of ALL cells; UInt_tfClasssignal class; TMVA::EDTSeparationTMVA::PDEFoam::fDTSeparationBACKWARDS COMPATIBILITY: split cells according to decision tree logic; Int_tTMVA::PDEFoam::fDimDimension of the integration/simulation space; TMVA::PDEFoamDensityBase*TMVA::PDEFoam::fDistr! distribution of training events; Int_tTMVA::PDEFoam::fEvPerBinMaximum number of effective (wt=1) events per bin; Bool_tTMVA::PDEFoam::fFillFoamWithOrigWeightsBACKWARDS COMPATIBILITY: fill the foam with boost or orig. weights; TMVA::EFoamTypeTMVA::PDEFoam::fFoamTypeBACKWARDS COMPATIBILITY: type of foam; TObjArray*TMVA::PDEFoam::fHistEdgHistograms of wt, one for each cell edge; Int_t*TMVA::PDEFoam::fInhiDiv! [fDim] Flags for inhibiting cell division; Int_tTMVA::PDEFoam::fLastCeIndex of the last cell; TMVA::MsgLogger*TMVA::PDEFoam::fLogger! message logger; Int_t*TMVA::PDEFoam::fMaskDiv! [fDim] Dynamic Mask for cell division; UInt_tTMVA::PDEFoam::fMaxDepthmaximum depth of cell tree; Int_tTMVA::PDEFoam::fNBinNo. of bins in the edge histogram for cell MC exploration; Int_tTMVA::PDEFoam::fNCellsMaximum number of cells; UInt_tTMVA::PDEFoam::fNElementsBACKWARDS COMPATIBILITY: number of variables i",MatchSource.WIKI,root/html532/TMVA__PDEFoamDiscriminant.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamDiscriminant.html
https://root.cern/root/html532/TMVA__PDEFoamDiscriminant.html:9901,Integrability,integrat,integration,9901,"t::MakeZombie(); voidTMVA::PDEFoam::OutputGrow(Bool_t finished = false); TMVA::PDEFoamTMVA::PDEFoam::PDEFoam(const TMVA::PDEFoam&); TMVA::PDEFoamDiscriminantPDEFoamDiscriminant(const TMVA::PDEFoamDiscriminant&); Long_tTMVA::PDEFoam::PeekMax(); voidTMVA::PDEFoam::SetCellElement(TMVA::PDEFoamCell* cell, UInt_t i, Double_t value); voidTMVA::PDEFoam::Varedu(Double_t*, Int_t&, Double_t&, Double_t&). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. Double_t*TMVA::PDEFoam::fAlpha[fDim] Internal parameters of the hyperrectangle; TMVA::PDEFoamCell**TMVA::PDEFoam::fCells[fNCells] Array of ALL cells; UInt_tfClasssignal class; TMVA::EDTSeparationTMVA::PDEFoam::fDTSeparationBACKWARDS COMPATIBILITY: split cells according to decision tree logic; Int_tTMVA::PDEFoam::fDimDimension of the integration/simulation space; TMVA::PDEFoamDensityBase*TMVA::PDEFoam::fDistr! distribution of training events; Int_tTMVA::PDEFoam::fEvPerBinMaximum number of effective (wt=1) events per bin; Bool_tTMVA::PDEFoam::fFillFoamWithOrigWeightsBACKWARDS COMPATIBILITY: fill the foam with boost or orig. weights; TMVA::EFoamTypeTMVA::PDEFoam::fFoamTypeBACKWARDS COMPATIBILITY: type of foam; TObjArray*TMVA::PDEFoam::fHistEdgHistograms of wt, one for each cell edge; Int_t*TMVA::PDEFoam::fInhiDiv! [fDim] Flags for inhibiting cell division; Int_tTMVA::PDEFoam::fLastCeIndex of the last cell; TMVA::MsgLogger*TMVA::PDEFoam::fLogger! message logger; Int_t*TMVA::PDEFoam::fMaskDiv! [fDim] Dynamic Mask for cell division; UInt_tTMVA::PDEFoam::fMaxDepthmaximum depth of cell tree; Int_tTMVA::PDEFoam::fNBinNo. of bins in the edge histogram for cell MC exploration; Int_tTMVA::PDEFoam::fNCellsMaximum number of cells; UInt_tTMVA::PDEFoam::fNElementsBACKWARDS COMPATIBILITY: number of variables i",MatchSource.WIKI,root/html532/TMVA__PDEFoamDiscriminant.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamDiscriminant.html
https://root.cern/root/html532/TMVA__PDEFoamDiscriminant.html:10523,Integrability,message,message,10523,"um TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. Double_t*TMVA::PDEFoam::fAlpha[fDim] Internal parameters of the hyperrectangle; TMVA::PDEFoamCell**TMVA::PDEFoam::fCells[fNCells] Array of ALL cells; UInt_tfClasssignal class; TMVA::EDTSeparationTMVA::PDEFoam::fDTSeparationBACKWARDS COMPATIBILITY: split cells according to decision tree logic; Int_tTMVA::PDEFoam::fDimDimension of the integration/simulation space; TMVA::PDEFoamDensityBase*TMVA::PDEFoam::fDistr! distribution of training events; Int_tTMVA::PDEFoam::fEvPerBinMaximum number of effective (wt=1) events per bin; Bool_tTMVA::PDEFoam::fFillFoamWithOrigWeightsBACKWARDS COMPATIBILITY: fill the foam with boost or orig. weights; TMVA::EFoamTypeTMVA::PDEFoam::fFoamTypeBACKWARDS COMPATIBILITY: type of foam; TObjArray*TMVA::PDEFoam::fHistEdgHistograms of wt, one for each cell edge; Int_t*TMVA::PDEFoam::fInhiDiv! [fDim] Flags for inhibiting cell division; Int_tTMVA::PDEFoam::fLastCeIndex of the last cell; TMVA::MsgLogger*TMVA::PDEFoam::fLogger! message logger; Int_t*TMVA::PDEFoam::fMaskDiv! [fDim] Dynamic Mask for cell division; UInt_tTMVA::PDEFoam::fMaxDepthmaximum depth of cell tree; Int_tTMVA::PDEFoam::fNBinNo. of bins in the edge histogram for cell MC exploration; Int_tTMVA::PDEFoam::fNCellsMaximum number of cells; UInt_tTMVA::PDEFoam::fNElementsBACKWARDS COMPATIBILITY: number of variables in every cell; Int_tTMVA::PDEFoam::fNSamplNo. of MC events, when dividing (exploring) cell; TStringTMVA::PDEFoam::fNameName of a given instance of the FOAM class; UInt_tTMVA::PDEFoam::fNminminimal number of events in cell to split cell; Int_tTMVA::PDEFoam::fNoActNumber of active cells; Bool_tTMVA::PDEFoam::fPeekMaxBACKWARDS COMPATIBILITY: peek up cell with max. driver integral for split; TRandom3*TMVA::PDEFoam::fPseRanPointer to user-defined generator of pseudorandom numbers; Double_t*TMVA::PDEFoam::fRvec[fDim] random number vector from r.n. generator fDim+1 m",MatchSource.WIKI,root/html532/TMVA__PDEFoamDiscriminant.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamDiscriminant.html
https://root.cern/root/html532/TMVA__PDEFoamDiscriminant.html:10869,Modifiability,variab,variables,10869,"ITY: split cells according to decision tree logic; Int_tTMVA::PDEFoam::fDimDimension of the integration/simulation space; TMVA::PDEFoamDensityBase*TMVA::PDEFoam::fDistr! distribution of training events; Int_tTMVA::PDEFoam::fEvPerBinMaximum number of effective (wt=1) events per bin; Bool_tTMVA::PDEFoam::fFillFoamWithOrigWeightsBACKWARDS COMPATIBILITY: fill the foam with boost or orig. weights; TMVA::EFoamTypeTMVA::PDEFoam::fFoamTypeBACKWARDS COMPATIBILITY: type of foam; TObjArray*TMVA::PDEFoam::fHistEdgHistograms of wt, one for each cell edge; Int_t*TMVA::PDEFoam::fInhiDiv! [fDim] Flags for inhibiting cell division; Int_tTMVA::PDEFoam::fLastCeIndex of the last cell; TMVA::MsgLogger*TMVA::PDEFoam::fLogger! message logger; Int_t*TMVA::PDEFoam::fMaskDiv! [fDim] Dynamic Mask for cell division; UInt_tTMVA::PDEFoam::fMaxDepthmaximum depth of cell tree; Int_tTMVA::PDEFoam::fNBinNo. of bins in the edge histogram for cell MC exploration; Int_tTMVA::PDEFoam::fNCellsMaximum number of cells; UInt_tTMVA::PDEFoam::fNElementsBACKWARDS COMPATIBILITY: number of variables in every cell; Int_tTMVA::PDEFoam::fNSamplNo. of MC events, when dividing (exploring) cell; TStringTMVA::PDEFoam::fNameName of a given instance of the FOAM class; UInt_tTMVA::PDEFoam::fNminminimal number of events in cell to split cell; Int_tTMVA::PDEFoam::fNoActNumber of active cells; Bool_tTMVA::PDEFoam::fPeekMaxBACKWARDS COMPATIBILITY: peek up cell with max. driver integral for split; TRandom3*TMVA::PDEFoam::fPseRanPointer to user-defined generator of pseudorandom numbers; Double_t*TMVA::PDEFoam::fRvec[fDim] random number vector from r.n. generator fDim+1 maximum elements; TMVA::Timer*TMVA::PDEFoam::fTimer! timer for graphical output; TObjArray*TMVA::PDEFoam::fVariableNamescollection of all variable names; Float_tTMVA::PDEFoam::fVolFracBACKWARDS COMPATIBILITY: volume fraction (with respect to total phase space; Double_t*TMVA::PDEFoam::fXmax[fDim] maximum for variable transform; Double_t*TMVA::PDEFoam::fXmin[fDim] m",MatchSource.WIKI,root/html532/TMVA__PDEFoamDiscriminant.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamDiscriminant.html
https://root.cern/root/html532/TMVA__PDEFoamDiscriminant.html:11582,Modifiability,variab,variable,11582,"xDepthmaximum depth of cell tree; Int_tTMVA::PDEFoam::fNBinNo. of bins in the edge histogram for cell MC exploration; Int_tTMVA::PDEFoam::fNCellsMaximum number of cells; UInt_tTMVA::PDEFoam::fNElementsBACKWARDS COMPATIBILITY: number of variables in every cell; Int_tTMVA::PDEFoam::fNSamplNo. of MC events, when dividing (exploring) cell; TStringTMVA::PDEFoam::fNameName of a given instance of the FOAM class; UInt_tTMVA::PDEFoam::fNminminimal number of events in cell to split cell; Int_tTMVA::PDEFoam::fNoActNumber of active cells; Bool_tTMVA::PDEFoam::fPeekMaxBACKWARDS COMPATIBILITY: peek up cell with max. driver integral for split; TRandom3*TMVA::PDEFoam::fPseRanPointer to user-defined generator of pseudorandom numbers; Double_t*TMVA::PDEFoam::fRvec[fDim] random number vector from r.n. generator fDim+1 maximum elements; TMVA::Timer*TMVA::PDEFoam::fTimer! timer for graphical output; TObjArray*TMVA::PDEFoam::fVariableNamescollection of all variable names; Float_tTMVA::PDEFoam::fVolFracBACKWARDS COMPATIBILITY: volume fraction (with respect to total phase space; Double_t*TMVA::PDEFoam::fXmax[fDim] maximum for variable transform; Double_t*TMVA::PDEFoam::fXmin[fDim] minimum for variable transform. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDEFoamDiscriminant(); Default constructor for streamer, user should not use it. PDEFoamDiscriminant(const TString& , UInt_t ); {}. PDEFoamDiscriminant(const TMVA::PDEFoamDiscriminant& ); Copy Constructor NOT IMPLEMENTED (NEVER USED). void FillFoamCells(const TMVA::Event* ev, Float_t wt); This function fills an event into the discriminant PDEFoam. The; event weight 'wt' is filled into cell element 0 if the event is; of class fClass, and filled into cell element 1 otherwise. void Finalize(); Calc discriminator and its error for every cell and save it to; the cell. TH2D* Project2(Int_t , Int_t , TMVA::ECellValue , TMVA::PDEFoamKernelBase* , UInt_t ); Project foam variable idim1 and variable idi",MatchSource.WIKI,root/html532/TMVA__PDEFoamDiscriminant.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamDiscriminant.html
https://root.cern/root/html532/TMVA__PDEFoamDiscriminant.html:11753,Modifiability,variab,variable,11753,"xDepthmaximum depth of cell tree; Int_tTMVA::PDEFoam::fNBinNo. of bins in the edge histogram for cell MC exploration; Int_tTMVA::PDEFoam::fNCellsMaximum number of cells; UInt_tTMVA::PDEFoam::fNElementsBACKWARDS COMPATIBILITY: number of variables in every cell; Int_tTMVA::PDEFoam::fNSamplNo. of MC events, when dividing (exploring) cell; TStringTMVA::PDEFoam::fNameName of a given instance of the FOAM class; UInt_tTMVA::PDEFoam::fNminminimal number of events in cell to split cell; Int_tTMVA::PDEFoam::fNoActNumber of active cells; Bool_tTMVA::PDEFoam::fPeekMaxBACKWARDS COMPATIBILITY: peek up cell with max. driver integral for split; TRandom3*TMVA::PDEFoam::fPseRanPointer to user-defined generator of pseudorandom numbers; Double_t*TMVA::PDEFoam::fRvec[fDim] random number vector from r.n. generator fDim+1 maximum elements; TMVA::Timer*TMVA::PDEFoam::fTimer! timer for graphical output; TObjArray*TMVA::PDEFoam::fVariableNamescollection of all variable names; Float_tTMVA::PDEFoam::fVolFracBACKWARDS COMPATIBILITY: volume fraction (with respect to total phase space; Double_t*TMVA::PDEFoam::fXmax[fDim] maximum for variable transform; Double_t*TMVA::PDEFoam::fXmin[fDim] minimum for variable transform. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDEFoamDiscriminant(); Default constructor for streamer, user should not use it. PDEFoamDiscriminant(const TString& , UInt_t ); {}. PDEFoamDiscriminant(const TMVA::PDEFoamDiscriminant& ); Copy Constructor NOT IMPLEMENTED (NEVER USED). void FillFoamCells(const TMVA::Event* ev, Float_t wt); This function fills an event into the discriminant PDEFoam. The; event weight 'wt' is filled into cell element 0 if the event is; of class fClass, and filled into cell element 1 otherwise. void Finalize(); Calc discriminator and its error for every cell and save it to; the cell. TH2D* Project2(Int_t , Int_t , TMVA::ECellValue , TMVA::PDEFoamKernelBase* , UInt_t ); Project foam variable idim1 and variable idi",MatchSource.WIKI,root/html532/TMVA__PDEFoamDiscriminant.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamDiscriminant.html
https://root.cern/root/html532/TMVA__PDEFoamDiscriminant.html:11821,Modifiability,variab,variable,11821,"xDepthmaximum depth of cell tree; Int_tTMVA::PDEFoam::fNBinNo. of bins in the edge histogram for cell MC exploration; Int_tTMVA::PDEFoam::fNCellsMaximum number of cells; UInt_tTMVA::PDEFoam::fNElementsBACKWARDS COMPATIBILITY: number of variables in every cell; Int_tTMVA::PDEFoam::fNSamplNo. of MC events, when dividing (exploring) cell; TStringTMVA::PDEFoam::fNameName of a given instance of the FOAM class; UInt_tTMVA::PDEFoam::fNminminimal number of events in cell to split cell; Int_tTMVA::PDEFoam::fNoActNumber of active cells; Bool_tTMVA::PDEFoam::fPeekMaxBACKWARDS COMPATIBILITY: peek up cell with max. driver integral for split; TRandom3*TMVA::PDEFoam::fPseRanPointer to user-defined generator of pseudorandom numbers; Double_t*TMVA::PDEFoam::fRvec[fDim] random number vector from r.n. generator fDim+1 maximum elements; TMVA::Timer*TMVA::PDEFoam::fTimer! timer for graphical output; TObjArray*TMVA::PDEFoam::fVariableNamescollection of all variable names; Float_tTMVA::PDEFoam::fVolFracBACKWARDS COMPATIBILITY: volume fraction (with respect to total phase space; Double_t*TMVA::PDEFoam::fXmax[fDim] maximum for variable transform; Double_t*TMVA::PDEFoam::fXmin[fDim] minimum for variable transform. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDEFoamDiscriminant(); Default constructor for streamer, user should not use it. PDEFoamDiscriminant(const TString& , UInt_t ); {}. PDEFoamDiscriminant(const TMVA::PDEFoamDiscriminant& ); Copy Constructor NOT IMPLEMENTED (NEVER USED). void FillFoamCells(const TMVA::Event* ev, Float_t wt); This function fills an event into the discriminant PDEFoam. The; event weight 'wt' is filled into cell element 0 if the event is; of class fClass, and filled into cell element 1 otherwise. void Finalize(); Calc discriminator and its error for every cell and save it to; the cell. TH2D* Project2(Int_t , Int_t , TMVA::ECellValue , TMVA::PDEFoamKernelBase* , UInt_t ); Project foam variable idim1 and variable idi",MatchSource.WIKI,root/html532/TMVA__PDEFoamDiscriminant.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamDiscriminant.html
https://root.cern/root/html532/TMVA__PDEFoamDiscriminant.html:12602,Modifiability,variab,variable,12602,"of all variable names; Float_tTMVA::PDEFoam::fVolFracBACKWARDS COMPATIBILITY: volume fraction (with respect to total phase space; Double_t*TMVA::PDEFoam::fXmax[fDim] maximum for variable transform; Double_t*TMVA::PDEFoam::fXmin[fDim] minimum for variable transform. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDEFoamDiscriminant(); Default constructor for streamer, user should not use it. PDEFoamDiscriminant(const TString& , UInt_t ); {}. PDEFoamDiscriminant(const TMVA::PDEFoamDiscriminant& ); Copy Constructor NOT IMPLEMENTED (NEVER USED). void FillFoamCells(const TMVA::Event* ev, Float_t wt); This function fills an event into the discriminant PDEFoam. The; event weight 'wt' is filled into cell element 0 if the event is; of class fClass, and filled into cell element 1 otherwise. void Finalize(); Calc discriminator and its error for every cell and save it to; the cell. TH2D* Project2(Int_t , Int_t , TMVA::ECellValue , TMVA::PDEFoamKernelBase* , UInt_t ); Project foam variable idim1 and variable idim2 to histogram.; The projection algorithm is modified such that the z axis range; of the returned histogram is [0, 1], as necessary for the; interpretation as a discriminator. This is done by weighting; the cell values (in case of cell_value = kValue) by the cell; volume in all dimensions, excluding 'idim1' and 'idim2'. Parameters:. - idim1, idim2 - dimensions to project to. - cell_value - the cell value to draw. - kernel - a PDEFoam kernel (optional). If NULL is given, the; kernel is ignored and the pure cell values are; plotted. - nbin - number of bins in x and y direction of result histogram; (optional, default is 50). Returns:; a 2-dimensional histogram. virtual ~PDEFoamDiscriminant(); {}. » Author: Tancredi Carli, Dominik Dannheim, Alexander Voigt » Copyright (c) 2008, 2010: *; » Last changed: root/tmva $Id: PDEFoamDiscriminant.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been au",MatchSource.WIKI,root/html532/TMVA__PDEFoamDiscriminant.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamDiscriminant.html
https://root.cern/root/html532/TMVA__PDEFoamDiscriminant.html:12621,Modifiability,variab,variable,12621,"of all variable names; Float_tTMVA::PDEFoam::fVolFracBACKWARDS COMPATIBILITY: volume fraction (with respect to total phase space; Double_t*TMVA::PDEFoam::fXmax[fDim] maximum for variable transform; Double_t*TMVA::PDEFoam::fXmin[fDim] minimum for variable transform. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDEFoamDiscriminant(); Default constructor for streamer, user should not use it. PDEFoamDiscriminant(const TString& , UInt_t ); {}. PDEFoamDiscriminant(const TMVA::PDEFoamDiscriminant& ); Copy Constructor NOT IMPLEMENTED (NEVER USED). void FillFoamCells(const TMVA::Event* ev, Float_t wt); This function fills an event into the discriminant PDEFoam. The; event weight 'wt' is filled into cell element 0 if the event is; of class fClass, and filled into cell element 1 otherwise. void Finalize(); Calc discriminator and its error for every cell and save it to; the cell. TH2D* Project2(Int_t , Int_t , TMVA::ECellValue , TMVA::PDEFoamKernelBase* , UInt_t ); Project foam variable idim1 and variable idim2 to histogram.; The projection algorithm is modified such that the z axis range; of the returned histogram is [0, 1], as necessary for the; interpretation as a discriminator. This is done by weighting; the cell values (in case of cell_value = kValue) by the cell; volume in all dimensions, excluding 'idim1' and 'idim2'. Parameters:. - idim1, idim2 - dimensions to project to. - cell_value - the cell value to draw. - kernel - a PDEFoam kernel (optional). If NULL is given, the; kernel is ignored and the pure cell values are; plotted. - nbin - number of bins in x and y direction of result histogram; (optional, default is 50). Returns:; a 2-dimensional histogram. virtual ~PDEFoamDiscriminant(); {}. » Author: Tancredi Carli, Dominik Dannheim, Alexander Voigt » Copyright (c) 2008, 2010: *; » Last changed: root/tmva $Id: PDEFoamDiscriminant.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been au",MatchSource.WIKI,root/html532/TMVA__PDEFoamDiscriminant.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamDiscriminant.html
https://root.cern/root/html532/TMVA__PDEFoamDiscriminant.html:9853,Testability,log,logic,9853,"t::MakeZombie(); voidTMVA::PDEFoam::OutputGrow(Bool_t finished = false); TMVA::PDEFoamTMVA::PDEFoam::PDEFoam(const TMVA::PDEFoam&); TMVA::PDEFoamDiscriminantPDEFoamDiscriminant(const TMVA::PDEFoamDiscriminant&); Long_tTMVA::PDEFoam::PeekMax(); voidTMVA::PDEFoam::SetCellElement(TMVA::PDEFoamCell* cell, UInt_t i, Double_t value); voidTMVA::PDEFoam::Varedu(Double_t*, Int_t&, Double_t&, Double_t&). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. Double_t*TMVA::PDEFoam::fAlpha[fDim] Internal parameters of the hyperrectangle; TMVA::PDEFoamCell**TMVA::PDEFoam::fCells[fNCells] Array of ALL cells; UInt_tfClasssignal class; TMVA::EDTSeparationTMVA::PDEFoam::fDTSeparationBACKWARDS COMPATIBILITY: split cells according to decision tree logic; Int_tTMVA::PDEFoam::fDimDimension of the integration/simulation space; TMVA::PDEFoamDensityBase*TMVA::PDEFoam::fDistr! distribution of training events; Int_tTMVA::PDEFoam::fEvPerBinMaximum number of effective (wt=1) events per bin; Bool_tTMVA::PDEFoam::fFillFoamWithOrigWeightsBACKWARDS COMPATIBILITY: fill the foam with boost or orig. weights; TMVA::EFoamTypeTMVA::PDEFoam::fFoamTypeBACKWARDS COMPATIBILITY: type of foam; TObjArray*TMVA::PDEFoam::fHistEdgHistograms of wt, one for each cell edge; Int_t*TMVA::PDEFoam::fInhiDiv! [fDim] Flags for inhibiting cell division; Int_tTMVA::PDEFoam::fLastCeIndex of the last cell; TMVA::MsgLogger*TMVA::PDEFoam::fLogger! message logger; Int_t*TMVA::PDEFoam::fMaskDiv! [fDim] Dynamic Mask for cell division; UInt_tTMVA::PDEFoam::fMaxDepthmaximum depth of cell tree; Int_tTMVA::PDEFoam::fNBinNo. of bins in the edge histogram for cell MC exploration; Int_tTMVA::PDEFoam::fNCellsMaximum number of cells; UInt_tTMVA::PDEFoam::fNElementsBACKWARDS COMPATIBILITY: number of variables i",MatchSource.WIKI,root/html532/TMVA__PDEFoamDiscriminant.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamDiscriminant.html
https://root.cern/root/html532/TMVA__PDEFoamDiscriminant.html:10531,Testability,log,logger,10531,"um TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. Double_t*TMVA::PDEFoam::fAlpha[fDim] Internal parameters of the hyperrectangle; TMVA::PDEFoamCell**TMVA::PDEFoam::fCells[fNCells] Array of ALL cells; UInt_tfClasssignal class; TMVA::EDTSeparationTMVA::PDEFoam::fDTSeparationBACKWARDS COMPATIBILITY: split cells according to decision tree logic; Int_tTMVA::PDEFoam::fDimDimension of the integration/simulation space; TMVA::PDEFoamDensityBase*TMVA::PDEFoam::fDistr! distribution of training events; Int_tTMVA::PDEFoam::fEvPerBinMaximum number of effective (wt=1) events per bin; Bool_tTMVA::PDEFoam::fFillFoamWithOrigWeightsBACKWARDS COMPATIBILITY: fill the foam with boost or orig. weights; TMVA::EFoamTypeTMVA::PDEFoam::fFoamTypeBACKWARDS COMPATIBILITY: type of foam; TObjArray*TMVA::PDEFoam::fHistEdgHistograms of wt, one for each cell edge; Int_t*TMVA::PDEFoam::fInhiDiv! [fDim] Flags for inhibiting cell division; Int_tTMVA::PDEFoam::fLastCeIndex of the last cell; TMVA::MsgLogger*TMVA::PDEFoam::fLogger! message logger; Int_t*TMVA::PDEFoam::fMaskDiv! [fDim] Dynamic Mask for cell division; UInt_tTMVA::PDEFoam::fMaxDepthmaximum depth of cell tree; Int_tTMVA::PDEFoam::fNBinNo. of bins in the edge histogram for cell MC exploration; Int_tTMVA::PDEFoam::fNCellsMaximum number of cells; UInt_tTMVA::PDEFoam::fNElementsBACKWARDS COMPATIBILITY: number of variables in every cell; Int_tTMVA::PDEFoam::fNSamplNo. of MC events, when dividing (exploring) cell; TStringTMVA::PDEFoam::fNameName of a given instance of the FOAM class; UInt_tTMVA::PDEFoam::fNminminimal number of events in cell to split cell; Int_tTMVA::PDEFoam::fNoActNumber of active cells; Bool_tTMVA::PDEFoam::fPeekMaxBACKWARDS COMPATIBILITY: peek up cell with max. driver integral for split; TRandom3*TMVA::PDEFoam::fPseRanPointer to user-defined generator of pseudorandom numbers; Double_t*TMVA::PDEFoam::fRvec[fDim] random number vector from r.n. generator fDim+1 m",MatchSource.WIKI,root/html532/TMVA__PDEFoamDiscriminant.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamDiscriminant.html
https://root.cern/root/html532/TMVA__PDEFoamDiscriminantDensity.html:1692,Availability,error,error,1692,"Density(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Double_tDensity(vector<Double_t>& Xarg, Double_t& event_density); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; voidTMVA::PDEFoamDensityBase::FillBinarySearchTree(const TMVA::Event* ev); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const vector<Double_t>&TMVA::PDEFoamDensityBase::GetBox() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() co",MatchSource.WIKI,root/html532/TMVA__PDEFoamDiscriminantDensity.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamDiscriminantDensity.html
https://root.cern/root/html532/TMVA__PDEFoamDiscriminantDensity.html:1776,Availability,error,error,1776,"t::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Double_tDensity(vector<Double_t>& Xarg, Double_t& event_density); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; voidTMVA::PDEFoamDensityBase::FillBinarySearchTree(const TMVA::Event* ev); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const vector<Double_t>&TMVA::PDEFoamDensityBase::GetBox() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtua",MatchSource.WIKI,root/html532/TMVA__PDEFoamDiscriminantDensity.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamDiscriminantDensity.html
https://root.cern/root/html532/TMVA__PDEFoamDiscriminantDensity.html:6230,Integrability,message,message,6230,"ol_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; Double_tTMVA::PDEFoamDensityBase::GetBoxVolume(); TMVA::MsgLogger&TMVA::PDEFoamDensityBase::Log() const; voidTObject::MakeZombie(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TMVA::BinarySearchTree*TMVA::PDEFoamDensityBase::fBstBinary tree to find events within a volume; UInt_tfClasssignal class; TMVA::MsgLogger*TMVA::PDEFoamDensityBase::fLogger! message logger. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDEFoamDiscriminantDensity(); {}. PDEFoamDiscriminantDensity(vector<Double_t> box, UInt_t cls); User construcor:. Parameters:. - box - size of the range-searching box (n-dimensional; std::vector). - cls - event class used for the range-searching. PDEFoamDiscriminantDensity(const TMVA::PDEFoamDiscriminantDensity& ); Copy constructor. Double_t Density(vector<Double_t>& Xarg, Double_t& event_density); This function is needed during the foam buildup. It returns the; average number density of events of type fClass within the; range-searching volume (specified by fBox). Parameters:. - Xarg - event vector (in [fXmin,fXmax]) to place the box at. - event_density - here the event density is stored. Returns:. Number of events (event weights) of type fClass, which were; found in the range-searching volume at point",MatchSource.WIKI,root/html532/TMVA__PDEFoamDiscriminantDensity.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamDiscriminantDensity.html
https://root.cern/root/html532/TMVA__PDEFoamDiscriminantDensity.html:6238,Testability,log,logger,6238,"ol_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; Double_tTMVA::PDEFoamDensityBase::GetBoxVolume(); TMVA::MsgLogger&TMVA::PDEFoamDensityBase::Log() const; voidTObject::MakeZombie(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TMVA::BinarySearchTree*TMVA::PDEFoamDensityBase::fBstBinary tree to find events within a volume; UInt_tfClasssignal class; TMVA::MsgLogger*TMVA::PDEFoamDensityBase::fLogger! message logger. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDEFoamDiscriminantDensity(); {}. PDEFoamDiscriminantDensity(vector<Double_t> box, UInt_t cls); User construcor:. Parameters:. - box - size of the range-searching box (n-dimensional; std::vector). - cls - event class used for the range-searching. PDEFoamDiscriminantDensity(const TMVA::PDEFoamDiscriminantDensity& ); Copy constructor. Double_t Density(vector<Double_t>& Xarg, Double_t& event_density); This function is needed during the foam buildup. It returns the; average number density of events of type fClass within the; range-searching volume (specified by fBox). Parameters:. - Xarg - event vector (in [fXmin,fXmax]) to place the box at. - event_density - here the event density is stored. Returns:. Number of events (event weights) of type fClass, which were; found in the range-searching volume at point",MatchSource.WIKI,root/html532/TMVA__PDEFoamDiscriminantDensity.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamDiscriminantDensity.html
https://root.cern/root/html532/TMVA__PDEFoamEvent.html:1954,Availability,error,error,1954,"e(TBrowser* b); voidTMVA::PDEFoam::CheckAll(Int_t); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; voidTMVA::PDEFoam::Create(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::PDEFoam::DeleteBinarySearchTree(); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); TH1D*TMVA::PDEFoam::Draw1Dim(TMVA::ECellValue cell_value, Int_t nbin, TMVA::PDEFoamKernelBase* kernel = NULL); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; voidTMVA::PDEFoam::FillBinarySearchTree(const TMVA::Event* ev); virtual voidFillFoamCells(const TMVA::Event* ev, Float_t wt); virtual voidTMVA::PDEFoam::Finalize(); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual vector<Float_t>TMVA::PDEFoam::GetCellValue(const map<Int_t,Float_t>& xvec, TMVA::ECellValue cv); virtual Float_tTMVA::PDEFoam::GetCellValue(const TMVA::PDEFoamCell* cell, TMVA::ECellValue cv); virtual Float_tTMVA::PDEFoam::GetCellValue(const vector<Float_t>& xvec, TMVA::ECellValue cv, TMVA::PDEFoamKernelBase*); virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TStringTMVA::PDEFoam::GetFoamName() const; virtual const char*TObject",MatchSource.WIKI,root/html532/TMVA__PDEFoamEvent.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamEvent.html
https://root.cern/root/html532/TMVA__PDEFoamEvent.html:2038,Availability,error,error,2038,"onst char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; voidTMVA::PDEFoam::Create(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::PDEFoam::DeleteBinarySearchTree(); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); TH1D*TMVA::PDEFoam::Draw1Dim(TMVA::ECellValue cell_value, Int_t nbin, TMVA::PDEFoamKernelBase* kernel = NULL); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; voidTMVA::PDEFoam::FillBinarySearchTree(const TMVA::Event* ev); virtual voidFillFoamCells(const TMVA::Event* ev, Float_t wt); virtual voidTMVA::PDEFoam::Finalize(); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual vector<Float_t>TMVA::PDEFoam::GetCellValue(const map<Int_t,Float_t>& xvec, TMVA::ECellValue cv); virtual Float_tTMVA::PDEFoam::GetCellValue(const TMVA::PDEFoamCell* cell, TMVA::ECellValue cv); virtual Float_tTMVA::PDEFoam::GetCellValue(const vector<Float_t>& xvec, TMVA::ECellValue cv, TMVA::PDEFoamKernelBase*); virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TStringTMVA::PDEFoam::GetFoamName() const; virtual const char*TObject::GetIconName() const; UInt_tTMVA::PDEFoam::GetMaxDepth() const; UInt_tTMVA::PDEFoam",MatchSource.WIKI,root/html532/TMVA__PDEFoamEvent.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamEvent.html
https://root.cern/root/html532/TMVA__PDEFoamEvent.html:9791,Deployability,integrat,integration,9791,"::PDEFoam::MakeAlpha(); voidTObject::MakeZombie(); voidTMVA::PDEFoam::OutputGrow(Bool_t finished = false); TMVA::PDEFoamTMVA::PDEFoam::PDEFoam(const TMVA::PDEFoam&); TMVA::PDEFoamEventPDEFoamEvent(const TMVA::PDEFoamEvent&); Long_tTMVA::PDEFoam::PeekMax(); voidTMVA::PDEFoam::SetCellElement(TMVA::PDEFoamCell* cell, UInt_t i, Double_t value); voidTMVA::PDEFoam::Varedu(Double_t*, Int_t&, Double_t&, Double_t&). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. Double_t*TMVA::PDEFoam::fAlpha[fDim] Internal parameters of the hyperrectangle; TMVA::PDEFoamCell**TMVA::PDEFoam::fCells[fNCells] Array of ALL cells; TMVA::EDTSeparationTMVA::PDEFoam::fDTSeparationBACKWARDS COMPATIBILITY: split cells according to decision tree logic; Int_tTMVA::PDEFoam::fDimDimension of the integration/simulation space; TMVA::PDEFoamDensityBase*TMVA::PDEFoam::fDistr! distribution of training events; Int_tTMVA::PDEFoam::fEvPerBinMaximum number of effective (wt=1) events per bin; Bool_tTMVA::PDEFoam::fFillFoamWithOrigWeightsBACKWARDS COMPATIBILITY: fill the foam with boost or orig. weights; TMVA::EFoamTypeTMVA::PDEFoam::fFoamTypeBACKWARDS COMPATIBILITY: type of foam; TObjArray*TMVA::PDEFoam::fHistEdgHistograms of wt, one for each cell edge; Int_t*TMVA::PDEFoam::fInhiDiv! [fDim] Flags for inhibiting cell division; Int_tTMVA::PDEFoam::fLastCeIndex of the last cell; TMVA::MsgLogger*TMVA::PDEFoam::fLogger! message logger; Int_t*TMVA::PDEFoam::fMaskDiv! [fDim] Dynamic Mask for cell division; UInt_tTMVA::PDEFoam::fMaxDepthmaximum depth of cell tree; Int_tTMVA::PDEFoam::fNBinNo. of bins in the edge histogram for cell MC exploration; Int_tTMVA::PDEFoam::fNCellsMaximum number of cells; UInt_tTMVA::PDEFoam::fNElementsBACKWARDS COMPATIBILITY: number of variables in every cell;",MatchSource.WIKI,root/html532/TMVA__PDEFoamEvent.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamEvent.html
https://root.cern/root/html532/TMVA__PDEFoamEvent.html:9791,Integrability,integrat,integration,9791,"::PDEFoam::MakeAlpha(); voidTObject::MakeZombie(); voidTMVA::PDEFoam::OutputGrow(Bool_t finished = false); TMVA::PDEFoamTMVA::PDEFoam::PDEFoam(const TMVA::PDEFoam&); TMVA::PDEFoamEventPDEFoamEvent(const TMVA::PDEFoamEvent&); Long_tTMVA::PDEFoam::PeekMax(); voidTMVA::PDEFoam::SetCellElement(TMVA::PDEFoamCell* cell, UInt_t i, Double_t value); voidTMVA::PDEFoam::Varedu(Double_t*, Int_t&, Double_t&, Double_t&). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. Double_t*TMVA::PDEFoam::fAlpha[fDim] Internal parameters of the hyperrectangle; TMVA::PDEFoamCell**TMVA::PDEFoam::fCells[fNCells] Array of ALL cells; TMVA::EDTSeparationTMVA::PDEFoam::fDTSeparationBACKWARDS COMPATIBILITY: split cells according to decision tree logic; Int_tTMVA::PDEFoam::fDimDimension of the integration/simulation space; TMVA::PDEFoamDensityBase*TMVA::PDEFoam::fDistr! distribution of training events; Int_tTMVA::PDEFoam::fEvPerBinMaximum number of effective (wt=1) events per bin; Bool_tTMVA::PDEFoam::fFillFoamWithOrigWeightsBACKWARDS COMPATIBILITY: fill the foam with boost or orig. weights; TMVA::EFoamTypeTMVA::PDEFoam::fFoamTypeBACKWARDS COMPATIBILITY: type of foam; TObjArray*TMVA::PDEFoam::fHistEdgHistograms of wt, one for each cell edge; Int_t*TMVA::PDEFoam::fInhiDiv! [fDim] Flags for inhibiting cell division; Int_tTMVA::PDEFoam::fLastCeIndex of the last cell; TMVA::MsgLogger*TMVA::PDEFoam::fLogger! message logger; Int_t*TMVA::PDEFoam::fMaskDiv! [fDim] Dynamic Mask for cell division; UInt_tTMVA::PDEFoam::fMaxDepthmaximum depth of cell tree; Int_tTMVA::PDEFoam::fNBinNo. of bins in the edge histogram for cell MC exploration; Int_tTMVA::PDEFoam::fNCellsMaximum number of cells; UInt_tTMVA::PDEFoam::fNElementsBACKWARDS COMPATIBILITY: number of variables in every cell;",MatchSource.WIKI,root/html532/TMVA__PDEFoamEvent.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamEvent.html
https://root.cern/root/html532/TMVA__PDEFoamEvent.html:10413,Integrability,message,message,10413,"nu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. Double_t*TMVA::PDEFoam::fAlpha[fDim] Internal parameters of the hyperrectangle; TMVA::PDEFoamCell**TMVA::PDEFoam::fCells[fNCells] Array of ALL cells; TMVA::EDTSeparationTMVA::PDEFoam::fDTSeparationBACKWARDS COMPATIBILITY: split cells according to decision tree logic; Int_tTMVA::PDEFoam::fDimDimension of the integration/simulation space; TMVA::PDEFoamDensityBase*TMVA::PDEFoam::fDistr! distribution of training events; Int_tTMVA::PDEFoam::fEvPerBinMaximum number of effective (wt=1) events per bin; Bool_tTMVA::PDEFoam::fFillFoamWithOrigWeightsBACKWARDS COMPATIBILITY: fill the foam with boost or orig. weights; TMVA::EFoamTypeTMVA::PDEFoam::fFoamTypeBACKWARDS COMPATIBILITY: type of foam; TObjArray*TMVA::PDEFoam::fHistEdgHistograms of wt, one for each cell edge; Int_t*TMVA::PDEFoam::fInhiDiv! [fDim] Flags for inhibiting cell division; Int_tTMVA::PDEFoam::fLastCeIndex of the last cell; TMVA::MsgLogger*TMVA::PDEFoam::fLogger! message logger; Int_t*TMVA::PDEFoam::fMaskDiv! [fDim] Dynamic Mask for cell division; UInt_tTMVA::PDEFoam::fMaxDepthmaximum depth of cell tree; Int_tTMVA::PDEFoam::fNBinNo. of bins in the edge histogram for cell MC exploration; Int_tTMVA::PDEFoam::fNCellsMaximum number of cells; UInt_tTMVA::PDEFoam::fNElementsBACKWARDS COMPATIBILITY: number of variables in every cell; Int_tTMVA::PDEFoam::fNSamplNo. of MC events, when dividing (exploring) cell; TStringTMVA::PDEFoam::fNameName of a given instance of the FOAM class; UInt_tTMVA::PDEFoam::fNminminimal number of events in cell to split cell; Int_tTMVA::PDEFoam::fNoActNumber of active cells; Bool_tTMVA::PDEFoam::fPeekMaxBACKWARDS COMPATIBILITY: peek up cell with max. driver integral for split; TRandom3*TMVA::PDEFoam::fPseRanPointer to user-defined generator of pseudorandom numbers; Double_t*TMVA::PDEFoam::fRvec[fDim] random number vector from r.n. generator fDim+1 m",MatchSource.WIKI,root/html532/TMVA__PDEFoamEvent.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamEvent.html
https://root.cern/root/html532/TMVA__PDEFoamEvent.html:10759,Modifiability,variab,variables,10759,"ITY: split cells according to decision tree logic; Int_tTMVA::PDEFoam::fDimDimension of the integration/simulation space; TMVA::PDEFoamDensityBase*TMVA::PDEFoam::fDistr! distribution of training events; Int_tTMVA::PDEFoam::fEvPerBinMaximum number of effective (wt=1) events per bin; Bool_tTMVA::PDEFoam::fFillFoamWithOrigWeightsBACKWARDS COMPATIBILITY: fill the foam with boost or orig. weights; TMVA::EFoamTypeTMVA::PDEFoam::fFoamTypeBACKWARDS COMPATIBILITY: type of foam; TObjArray*TMVA::PDEFoam::fHistEdgHistograms of wt, one for each cell edge; Int_t*TMVA::PDEFoam::fInhiDiv! [fDim] Flags for inhibiting cell division; Int_tTMVA::PDEFoam::fLastCeIndex of the last cell; TMVA::MsgLogger*TMVA::PDEFoam::fLogger! message logger; Int_t*TMVA::PDEFoam::fMaskDiv! [fDim] Dynamic Mask for cell division; UInt_tTMVA::PDEFoam::fMaxDepthmaximum depth of cell tree; Int_tTMVA::PDEFoam::fNBinNo. of bins in the edge histogram for cell MC exploration; Int_tTMVA::PDEFoam::fNCellsMaximum number of cells; UInt_tTMVA::PDEFoam::fNElementsBACKWARDS COMPATIBILITY: number of variables in every cell; Int_tTMVA::PDEFoam::fNSamplNo. of MC events, when dividing (exploring) cell; TStringTMVA::PDEFoam::fNameName of a given instance of the FOAM class; UInt_tTMVA::PDEFoam::fNminminimal number of events in cell to split cell; Int_tTMVA::PDEFoam::fNoActNumber of active cells; Bool_tTMVA::PDEFoam::fPeekMaxBACKWARDS COMPATIBILITY: peek up cell with max. driver integral for split; TRandom3*TMVA::PDEFoam::fPseRanPointer to user-defined generator of pseudorandom numbers; Double_t*TMVA::PDEFoam::fRvec[fDim] random number vector from r.n. generator fDim+1 maximum elements; TMVA::Timer*TMVA::PDEFoam::fTimer! timer for graphical output; TObjArray*TMVA::PDEFoam::fVariableNamescollection of all variable names; Float_tTMVA::PDEFoam::fVolFracBACKWARDS COMPATIBILITY: volume fraction (with respect to total phase space; Double_t*TMVA::PDEFoam::fXmax[fDim] maximum for variable transform; Double_t*TMVA::PDEFoam::fXmin[fDim] m",MatchSource.WIKI,root/html532/TMVA__PDEFoamEvent.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamEvent.html
https://root.cern/root/html532/TMVA__PDEFoamEvent.html:11472,Modifiability,variab,variable,11472,"xDepthmaximum depth of cell tree; Int_tTMVA::PDEFoam::fNBinNo. of bins in the edge histogram for cell MC exploration; Int_tTMVA::PDEFoam::fNCellsMaximum number of cells; UInt_tTMVA::PDEFoam::fNElementsBACKWARDS COMPATIBILITY: number of variables in every cell; Int_tTMVA::PDEFoam::fNSamplNo. of MC events, when dividing (exploring) cell; TStringTMVA::PDEFoam::fNameName of a given instance of the FOAM class; UInt_tTMVA::PDEFoam::fNminminimal number of events in cell to split cell; Int_tTMVA::PDEFoam::fNoActNumber of active cells; Bool_tTMVA::PDEFoam::fPeekMaxBACKWARDS COMPATIBILITY: peek up cell with max. driver integral for split; TRandom3*TMVA::PDEFoam::fPseRanPointer to user-defined generator of pseudorandom numbers; Double_t*TMVA::PDEFoam::fRvec[fDim] random number vector from r.n. generator fDim+1 maximum elements; TMVA::Timer*TMVA::PDEFoam::fTimer! timer for graphical output; TObjArray*TMVA::PDEFoam::fVariableNamescollection of all variable names; Float_tTMVA::PDEFoam::fVolFracBACKWARDS COMPATIBILITY: volume fraction (with respect to total phase space; Double_t*TMVA::PDEFoam::fXmax[fDim] maximum for variable transform; Double_t*TMVA::PDEFoam::fXmin[fDim] minimum for variable transform. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDEFoamEvent(); Default constructor for streamer, user should not use it. PDEFoamEvent(const TString& ); {}. PDEFoamEvent(const TMVA::PDEFoamEvent& ); Copy Constructor NOT IMPLEMENTED (NEVER USED). void FillFoamCells(const TMVA::Event* ev, Float_t wt); This function fills an event weight 'wt' into the PDEFoam. Cell; element 0 is filled with the weight 'wt', and element 1 is; filled with the squared weight. virtual ~PDEFoamEvent(); {}. » Author: Tancredi Carli, Dominik Dannheim, Alexander Voigt » Copyright (c) 2008, 2010: *; » Last changed: root/tmva $Id: PDEFoamEvent.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comm",MatchSource.WIKI,root/html532/TMVA__PDEFoamEvent.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamEvent.html
https://root.cern/root/html532/TMVA__PDEFoamEvent.html:11643,Modifiability,variab,variable,11643,"xDepthmaximum depth of cell tree; Int_tTMVA::PDEFoam::fNBinNo. of bins in the edge histogram for cell MC exploration; Int_tTMVA::PDEFoam::fNCellsMaximum number of cells; UInt_tTMVA::PDEFoam::fNElementsBACKWARDS COMPATIBILITY: number of variables in every cell; Int_tTMVA::PDEFoam::fNSamplNo. of MC events, when dividing (exploring) cell; TStringTMVA::PDEFoam::fNameName of a given instance of the FOAM class; UInt_tTMVA::PDEFoam::fNminminimal number of events in cell to split cell; Int_tTMVA::PDEFoam::fNoActNumber of active cells; Bool_tTMVA::PDEFoam::fPeekMaxBACKWARDS COMPATIBILITY: peek up cell with max. driver integral for split; TRandom3*TMVA::PDEFoam::fPseRanPointer to user-defined generator of pseudorandom numbers; Double_t*TMVA::PDEFoam::fRvec[fDim] random number vector from r.n. generator fDim+1 maximum elements; TMVA::Timer*TMVA::PDEFoam::fTimer! timer for graphical output; TObjArray*TMVA::PDEFoam::fVariableNamescollection of all variable names; Float_tTMVA::PDEFoam::fVolFracBACKWARDS COMPATIBILITY: volume fraction (with respect to total phase space; Double_t*TMVA::PDEFoam::fXmax[fDim] maximum for variable transform; Double_t*TMVA::PDEFoam::fXmin[fDim] minimum for variable transform. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDEFoamEvent(); Default constructor for streamer, user should not use it. PDEFoamEvent(const TString& ); {}. PDEFoamEvent(const TMVA::PDEFoamEvent& ); Copy Constructor NOT IMPLEMENTED (NEVER USED). void FillFoamCells(const TMVA::Event* ev, Float_t wt); This function fills an event weight 'wt' into the PDEFoam. Cell; element 0 is filled with the weight 'wt', and element 1 is; filled with the squared weight. virtual ~PDEFoamEvent(); {}. » Author: Tancredi Carli, Dominik Dannheim, Alexander Voigt » Copyright (c) 2008, 2010: *; » Last changed: root/tmva $Id: PDEFoamEvent.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comm",MatchSource.WIKI,root/html532/TMVA__PDEFoamEvent.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamEvent.html
https://root.cern/root/html532/TMVA__PDEFoamEvent.html:11711,Modifiability,variab,variable,11711,"xDepthmaximum depth of cell tree; Int_tTMVA::PDEFoam::fNBinNo. of bins in the edge histogram for cell MC exploration; Int_tTMVA::PDEFoam::fNCellsMaximum number of cells; UInt_tTMVA::PDEFoam::fNElementsBACKWARDS COMPATIBILITY: number of variables in every cell; Int_tTMVA::PDEFoam::fNSamplNo. of MC events, when dividing (exploring) cell; TStringTMVA::PDEFoam::fNameName of a given instance of the FOAM class; UInt_tTMVA::PDEFoam::fNminminimal number of events in cell to split cell; Int_tTMVA::PDEFoam::fNoActNumber of active cells; Bool_tTMVA::PDEFoam::fPeekMaxBACKWARDS COMPATIBILITY: peek up cell with max. driver integral for split; TRandom3*TMVA::PDEFoam::fPseRanPointer to user-defined generator of pseudorandom numbers; Double_t*TMVA::PDEFoam::fRvec[fDim] random number vector from r.n. generator fDim+1 maximum elements; TMVA::Timer*TMVA::PDEFoam::fTimer! timer for graphical output; TObjArray*TMVA::PDEFoam::fVariableNamescollection of all variable names; Float_tTMVA::PDEFoam::fVolFracBACKWARDS COMPATIBILITY: volume fraction (with respect to total phase space; Double_t*TMVA::PDEFoam::fXmax[fDim] maximum for variable transform; Double_t*TMVA::PDEFoam::fXmin[fDim] minimum for variable transform. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDEFoamEvent(); Default constructor for streamer, user should not use it. PDEFoamEvent(const TString& ); {}. PDEFoamEvent(const TMVA::PDEFoamEvent& ); Copy Constructor NOT IMPLEMENTED (NEVER USED). void FillFoamCells(const TMVA::Event* ev, Float_t wt); This function fills an event weight 'wt' into the PDEFoam. Cell; element 0 is filled with the weight 'wt', and element 1 is; filled with the squared weight. virtual ~PDEFoamEvent(); {}. » Author: Tancredi Carli, Dominik Dannheim, Alexander Voigt » Copyright (c) 2008, 2010: *; » Last changed: root/tmva $Id: PDEFoamEvent.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comm",MatchSource.WIKI,root/html532/TMVA__PDEFoamEvent.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamEvent.html
https://root.cern/root/html532/TMVA__PDEFoamEvent.html:9743,Testability,log,logic,9743,"::PDEFoam::MakeAlpha(); voidTObject::MakeZombie(); voidTMVA::PDEFoam::OutputGrow(Bool_t finished = false); TMVA::PDEFoamTMVA::PDEFoam::PDEFoam(const TMVA::PDEFoam&); TMVA::PDEFoamEventPDEFoamEvent(const TMVA::PDEFoamEvent&); Long_tTMVA::PDEFoam::PeekMax(); voidTMVA::PDEFoam::SetCellElement(TMVA::PDEFoamCell* cell, UInt_t i, Double_t value); voidTMVA::PDEFoam::Varedu(Double_t*, Int_t&, Double_t&, Double_t&). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. Double_t*TMVA::PDEFoam::fAlpha[fDim] Internal parameters of the hyperrectangle; TMVA::PDEFoamCell**TMVA::PDEFoam::fCells[fNCells] Array of ALL cells; TMVA::EDTSeparationTMVA::PDEFoam::fDTSeparationBACKWARDS COMPATIBILITY: split cells according to decision tree logic; Int_tTMVA::PDEFoam::fDimDimension of the integration/simulation space; TMVA::PDEFoamDensityBase*TMVA::PDEFoam::fDistr! distribution of training events; Int_tTMVA::PDEFoam::fEvPerBinMaximum number of effective (wt=1) events per bin; Bool_tTMVA::PDEFoam::fFillFoamWithOrigWeightsBACKWARDS COMPATIBILITY: fill the foam with boost or orig. weights; TMVA::EFoamTypeTMVA::PDEFoam::fFoamTypeBACKWARDS COMPATIBILITY: type of foam; TObjArray*TMVA::PDEFoam::fHistEdgHistograms of wt, one for each cell edge; Int_t*TMVA::PDEFoam::fInhiDiv! [fDim] Flags for inhibiting cell division; Int_tTMVA::PDEFoam::fLastCeIndex of the last cell; TMVA::MsgLogger*TMVA::PDEFoam::fLogger! message logger; Int_t*TMVA::PDEFoam::fMaskDiv! [fDim] Dynamic Mask for cell division; UInt_tTMVA::PDEFoam::fMaxDepthmaximum depth of cell tree; Int_tTMVA::PDEFoam::fNBinNo. of bins in the edge histogram for cell MC exploration; Int_tTMVA::PDEFoam::fNCellsMaximum number of cells; UInt_tTMVA::PDEFoam::fNElementsBACKWARDS COMPATIBILITY: number of variables in every cell;",MatchSource.WIKI,root/html532/TMVA__PDEFoamEvent.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamEvent.html
https://root.cern/root/html532/TMVA__PDEFoamEvent.html:10421,Testability,log,logger,10421,"nu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. Double_t*TMVA::PDEFoam::fAlpha[fDim] Internal parameters of the hyperrectangle; TMVA::PDEFoamCell**TMVA::PDEFoam::fCells[fNCells] Array of ALL cells; TMVA::EDTSeparationTMVA::PDEFoam::fDTSeparationBACKWARDS COMPATIBILITY: split cells according to decision tree logic; Int_tTMVA::PDEFoam::fDimDimension of the integration/simulation space; TMVA::PDEFoamDensityBase*TMVA::PDEFoam::fDistr! distribution of training events; Int_tTMVA::PDEFoam::fEvPerBinMaximum number of effective (wt=1) events per bin; Bool_tTMVA::PDEFoam::fFillFoamWithOrigWeightsBACKWARDS COMPATIBILITY: fill the foam with boost or orig. weights; TMVA::EFoamTypeTMVA::PDEFoam::fFoamTypeBACKWARDS COMPATIBILITY: type of foam; TObjArray*TMVA::PDEFoam::fHistEdgHistograms of wt, one for each cell edge; Int_t*TMVA::PDEFoam::fInhiDiv! [fDim] Flags for inhibiting cell division; Int_tTMVA::PDEFoam::fLastCeIndex of the last cell; TMVA::MsgLogger*TMVA::PDEFoam::fLogger! message logger; Int_t*TMVA::PDEFoam::fMaskDiv! [fDim] Dynamic Mask for cell division; UInt_tTMVA::PDEFoam::fMaxDepthmaximum depth of cell tree; Int_tTMVA::PDEFoam::fNBinNo. of bins in the edge histogram for cell MC exploration; Int_tTMVA::PDEFoam::fNCellsMaximum number of cells; UInt_tTMVA::PDEFoam::fNElementsBACKWARDS COMPATIBILITY: number of variables in every cell; Int_tTMVA::PDEFoam::fNSamplNo. of MC events, when dividing (exploring) cell; TStringTMVA::PDEFoam::fNameName of a given instance of the FOAM class; UInt_tTMVA::PDEFoam::fNminminimal number of events in cell to split cell; Int_tTMVA::PDEFoam::fNoActNumber of active cells; Bool_tTMVA::PDEFoam::fPeekMaxBACKWARDS COMPATIBILITY: peek up cell with max. driver integral for split; TRandom3*TMVA::PDEFoam::fPseRanPointer to user-defined generator of pseudorandom numbers; Double_t*TMVA::PDEFoam::fRvec[fDim] random number vector from r.n. generator fDim+1 m",MatchSource.WIKI,root/html532/TMVA__PDEFoamEvent.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamEvent.html
https://root.cern/root/html532/TMVA__PDEFoamEventDensity.html:1570,Availability,error,error,1570,"Density(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Double_tDensity(vector<Double_t>& Xarg, Double_t& event_density); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; voidTMVA::PDEFoamDensityBase::FillBinarySearchTree(const TMVA::Event* ev); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const vector<Double_t>&TMVA::PDEFoamDensityBase::GetBox() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() co",MatchSource.WIKI,root/html532/TMVA__PDEFoamEventDensity.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamEventDensity.html
https://root.cern/root/html532/TMVA__PDEFoamEventDensity.html:1654,Availability,error,error,1654,"t::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Double_tDensity(vector<Double_t>& Xarg, Double_t& event_density); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; voidTMVA::PDEFoamDensityBase::FillBinarySearchTree(const TMVA::Event* ev); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const vector<Double_t>&TMVA::PDEFoamDensityBase::GetBox() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtua",MatchSource.WIKI,root/html532/TMVA__PDEFoamEventDensity.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamEventDensity.html
https://root.cern/root/html532/TMVA__PDEFoamEventDensity.html:6007,Integrability,message,message,6007,"mt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; Double_tTMVA::PDEFoamDensityBase::GetBoxVolume(); TMVA::MsgLogger&TMVA::PDEFoamDensityBase::Log() const; voidTObject::MakeZombie(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TMVA::BinarySearchTree*TMVA::PDEFoamDensityBase::fBstBinary tree to find events within a volume; TMVA::MsgLogger*TMVA::PDEFoamDensityBase::fLogger! message logger. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDEFoamEventDensity(); {}. PDEFoamEventDensity(vector<Double_t> box); User construcor. Parameters:. - box - size of sampling box. PDEFoamEventDensity(const TMVA::PDEFoamEventDensity& ); Copy constructor. Double_t Density(vector<Double_t>& Xarg, Double_t& event_density); This function is needed during the foam buildup. It returns the; event density within the range-searching volume (specified by; fBox). Parameters:. - Xarg - event vector (in [fXmin,fXmax]) to place the box at. - event_density - here the event density is stored. Returns:. Number of events (event weights), which were found in the; range-searching volume at point 'Xarg', divided by the box; volume. virtual ~PDEFoamEventDensity(); {}. » Author: Tancredi Carli, Dominik Dannheim, Alexander Voigt » Copyright (c) 2008, 2010: *; » Last changed: root/tmva $Id",MatchSource.WIKI,root/html532/TMVA__PDEFoamEventDensity.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamEventDensity.html
https://root.cern/root/html532/TMVA__PDEFoamEventDensity.html:6015,Testability,log,logger,6015,"mt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; Double_tTMVA::PDEFoamDensityBase::GetBoxVolume(); TMVA::MsgLogger&TMVA::PDEFoamDensityBase::Log() const; voidTObject::MakeZombie(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TMVA::BinarySearchTree*TMVA::PDEFoamDensityBase::fBstBinary tree to find events within a volume; TMVA::MsgLogger*TMVA::PDEFoamDensityBase::fLogger! message logger. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDEFoamEventDensity(); {}. PDEFoamEventDensity(vector<Double_t> box); User construcor. Parameters:. - box - size of sampling box. PDEFoamEventDensity(const TMVA::PDEFoamEventDensity& ); Copy constructor. Double_t Density(vector<Double_t>& Xarg, Double_t& event_density); This function is needed during the foam buildup. It returns the; event density within the range-searching volume (specified by; fBox). Parameters:. - Xarg - event vector (in [fXmin,fXmax]) to place the box at. - event_density - here the event density is stored. Returns:. Number of events (event weights), which were found in the; range-searching volume at point 'Xarg', divided by the box; volume. virtual ~PDEFoamEventDensity(); {}. » Author: Tancredi Carli, Dominik Dannheim, Alexander Voigt » Copyright (c) 2008, 2010: *; » Last changed: root/tmva $Id",MatchSource.WIKI,root/html532/TMVA__PDEFoamEventDensity.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamEventDensity.html
https://root.cern/root/html532/TMVA__PDEFoamKernelBase.html:772,Availability,avail,available,772,". TMVA::PDEFoamKernelBase. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::PDEFoamKernelBase. class TMVA::PDEFoamKernelBase: public TObject. PDEFoamKernelBase. This class is the abstract kernel interface for PDEFoam. The; kernel can be used for manipulating (smearing) the cell values of a; PDEFoam, by passing it as an argument to; PDEFoam::GetCellValue(...). Derived classes must implement the Estimate() function to provide a; specific kernel behaviour. Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~PDEFoamKernelBase(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual Float_tEstimate(TMVA::PDEFoam*, vector<Float_t>&, TMVA::ECellValue); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidT",MatchSource.WIKI,root/html532/TMVA__PDEFoamKernelBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamKernelBase.html
https://root.cern/root/html532/TMVA__PDEFoamKernelBase.html:1824,Availability,error,error,1824,"Base(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual Float_tEstimate(TMVA::PDEFoam*, vector<Float_t>&, TMVA::ECellValue); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) con",MatchSource.WIKI,root/html532/TMVA__PDEFoamKernelBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamKernelBase.html
https://root.cern/root/html532/TMVA__PDEFoamKernelBase.html:1908,Availability,error,error,1908,"AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual Float_tEstimate(TMVA::PDEFoam*, vector<Float_t>&, TMVA::ECellValue); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTObject",MatchSource.WIKI,root/html532/TMVA__PDEFoamKernelBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamKernelBase.html
https://root.cern/root/html532/TMVA__PDEFoamKernelBase.html:375,Integrability,interface,interface,375,". TMVA::PDEFoamKernelBase. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::PDEFoamKernelBase. class TMVA::PDEFoamKernelBase: public TObject. PDEFoamKernelBase. This class is the abstract kernel interface for PDEFoam. The; kernel can be used for manipulating (smearing) the cell values of a; PDEFoam, by passing it as an argument to; PDEFoam::GetCellValue(...). Derived classes must implement the Estimate() function to provide a; specific kernel behaviour. Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~PDEFoamKernelBase(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual Float_tEstimate(TMVA::PDEFoam*, vector<Float_t>&, TMVA::ECellValue); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidT",MatchSource.WIKI,root/html532/TMVA__PDEFoamKernelBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamKernelBase.html
https://root.cern/root/html532/TMVA__PDEFoamKernelBase.html:5662,Integrability,message,message,5662,"ilename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); static voidTObject::SetObjectStat(Bool_t stat); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTObject::MakeZombie(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TMVA::MsgLogger*fLogger! message logger. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; ~PDEFoamKernelBase(); Destructor. Float_t Estimate(TMVA::PDEFoam* , vector<Float_t>& , TMVA::ECellValue ); kernel estimator. » Author: Dominik Dannheim, Alexander Voigt » Copyright (c) 2010: *; » Last changed: root/tmva $Id: PDEFoamKernelBase.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__PDEFoamKernelBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamKernelBase.html
https://root.cern/root/html532/TMVA__PDEFoamKernelBase.html:5670,Testability,log,logger,5670,"ilename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); static voidTObject::SetObjectStat(Bool_t stat); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTObject::MakeZombie(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TMVA::MsgLogger*fLogger! message logger. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; ~PDEFoamKernelBase(); Destructor. Float_t Estimate(TMVA::PDEFoam* , vector<Float_t>& , TMVA::ECellValue ); kernel estimator. » Author: Dominik Dannheim, Alexander Voigt » Copyright (c) 2010: *; » Last changed: root/tmva $Id: PDEFoamKernelBase.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__PDEFoamKernelBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamKernelBase.html
https://root.cern/root/html532/TMVA__PDEFoamKernelGauss.html:1531,Availability,error,error,1531,"auss(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual Float_tEstimate(TMVA::PDEFoam*, vector<Float_t>&, TMVA::ECellValue); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) con",MatchSource.WIKI,root/html532/TMVA__PDEFoamKernelGauss.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamKernelGauss.html
https://root.cern/root/html532/TMVA__PDEFoamKernelGauss.html:1615,Availability,error,error,1615,"AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual Float_tEstimate(TMVA::PDEFoam*, vector<Float_t>&, TMVA::ECellValue); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTObject",MatchSource.WIKI,root/html532/TMVA__PDEFoamKernelGauss.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamKernelGauss.html
https://root.cern/root/html532/TMVA__PDEFoamKernelGauss.html:5715,Integrability,message,message,5715,"ect::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; Float_tGetAverageNeighborsValue(TMVA::PDEFoam*, vector<Float_t>&, TMVA::ECellValue); voidTObject::MakeZombie(); Float_tWeightGaus(TMVA::PDEFoam*, TMVA::PDEFoamCell*, vector<Float_t>&). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TMVA::MsgLogger*TMVA::PDEFoamKernelBase::fLogger! message logger; Float_tfSigmawidth of gauss curve. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDEFoamKernelGauss(Float_t sigma); Default constructor for streamer. PDEFoamKernelGauss(const TMVA::PDEFoamKernelGauss& ); Copy constructor. Float_t Estimate(TMVA::PDEFoam* , vector<Float_t>& , TMVA::ECellValue ); Gaussian kernel estimator. It returns the cell value 'cv',; corresponding to the event vector 'txvec' (in foam coordinates); weighted by the cell values of all other cells, where the weight; is a gaussian function. Parameters:. - foam - the pdefoam to search in. - txvec - event vector in foam coordinates [0,1]. - cv - cell value to estimate. Float_t GetAverageNeighborsValue(TMVA::PDEFoam* , vector<Float_t>& , TMVA::ECellValue ); This function returns the average value 'cv' of only nearest; neighbor cells. It is used in cases when a cell value is; undefined and the cell value shall be estimated by the; (well-defined) cell values of the n",MatchSource.WIKI,root/html532/TMVA__PDEFoamKernelGauss.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamKernelGauss.html
https://root.cern/root/html532/TMVA__PDEFoamKernelGauss.html:7107,Modifiability,variab,variables,7107,"ed Members; Includes; Libraries. Function documentation; PDEFoamKernelGauss(Float_t sigma); Default constructor for streamer. PDEFoamKernelGauss(const TMVA::PDEFoamKernelGauss& ); Copy constructor. Float_t Estimate(TMVA::PDEFoam* , vector<Float_t>& , TMVA::ECellValue ); Gaussian kernel estimator. It returns the cell value 'cv',; corresponding to the event vector 'txvec' (in foam coordinates); weighted by the cell values of all other cells, where the weight; is a gaussian function. Parameters:. - foam - the pdefoam to search in. - txvec - event vector in foam coordinates [0,1]. - cv - cell value to estimate. Float_t GetAverageNeighborsValue(TMVA::PDEFoam* , vector<Float_t>& , TMVA::ECellValue ); This function returns the average value 'cv' of only nearest; neighbor cells. It is used in cases when a cell value is; undefined and the cell value shall be estimated by the; (well-defined) cell values of the neighbor cells. Parameters:; - foam - the foam to search in; - txvec - event vector, transformed into foam coordinates [0, 1]; - cv - cell value, see definition of ECellValue. Float_t WeightGaus(TMVA::PDEFoam* , TMVA::PDEFoamCell* , vector<Float_t>& ); Returns the gauss weight between the 'cell' and a given coordinate 'txvec'. Parameters:; - cell - the cell. - txvec - the transformed event variables (in [0,1]) (coordinates <0 are; set to 0, >1 are set to 1). Returns:; exp(-(d/sigma)^2/2), where; - d - is the euclidean distance between 'txvec' and the point of the 'cell'; which is most close to 'txvec' (in order to avoid artefacts because of the; form of the cells).; - sigma = 1/VolFrac. virtual ~PDEFoamKernelGauss(); {}. » Author: Dominik Dannheim, Alexander Voigt » Copyright (c) 2008, 2010: *; » Last changed: root/tmva $Id: PDEFoamKernelGauss.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__PDEFoamKernelGauss.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamKernelGauss.html
https://root.cern/root/html532/TMVA__PDEFoamKernelGauss.html:7336,Safety,avoid,avoid,7336,"ed Members; Includes; Libraries. Function documentation; PDEFoamKernelGauss(Float_t sigma); Default constructor for streamer. PDEFoamKernelGauss(const TMVA::PDEFoamKernelGauss& ); Copy constructor. Float_t Estimate(TMVA::PDEFoam* , vector<Float_t>& , TMVA::ECellValue ); Gaussian kernel estimator. It returns the cell value 'cv',; corresponding to the event vector 'txvec' (in foam coordinates); weighted by the cell values of all other cells, where the weight; is a gaussian function. Parameters:. - foam - the pdefoam to search in. - txvec - event vector in foam coordinates [0,1]. - cv - cell value to estimate. Float_t GetAverageNeighborsValue(TMVA::PDEFoam* , vector<Float_t>& , TMVA::ECellValue ); This function returns the average value 'cv' of only nearest; neighbor cells. It is used in cases when a cell value is; undefined and the cell value shall be estimated by the; (well-defined) cell values of the neighbor cells. Parameters:; - foam - the foam to search in; - txvec - event vector, transformed into foam coordinates [0, 1]; - cv - cell value, see definition of ECellValue. Float_t WeightGaus(TMVA::PDEFoam* , TMVA::PDEFoamCell* , vector<Float_t>& ); Returns the gauss weight between the 'cell' and a given coordinate 'txvec'. Parameters:; - cell - the cell. - txvec - the transformed event variables (in [0,1]) (coordinates <0 are; set to 0, >1 are set to 1). Returns:; exp(-(d/sigma)^2/2), where; - d - is the euclidean distance between 'txvec' and the point of the 'cell'; which is most close to 'txvec' (in order to avoid artefacts because of the; form of the cells).; - sigma = 1/VolFrac. virtual ~PDEFoamKernelGauss(); {}. » Author: Dominik Dannheim, Alexander Voigt » Copyright (c) 2008, 2010: *; » Last changed: root/tmva $Id: PDEFoamKernelGauss.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__PDEFoamKernelGauss.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamKernelGauss.html
https://root.cern/root/html532/TMVA__PDEFoamKernelGauss.html:5723,Testability,log,logger,5723,"ect::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; Float_tGetAverageNeighborsValue(TMVA::PDEFoam*, vector<Float_t>&, TMVA::ECellValue); voidTObject::MakeZombie(); Float_tWeightGaus(TMVA::PDEFoam*, TMVA::PDEFoamCell*, vector<Float_t>&). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TMVA::MsgLogger*TMVA::PDEFoamKernelBase::fLogger! message logger; Float_tfSigmawidth of gauss curve. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDEFoamKernelGauss(Float_t sigma); Default constructor for streamer. PDEFoamKernelGauss(const TMVA::PDEFoamKernelGauss& ); Copy constructor. Float_t Estimate(TMVA::PDEFoam* , vector<Float_t>& , TMVA::ECellValue ); Gaussian kernel estimator. It returns the cell value 'cv',; corresponding to the event vector 'txvec' (in foam coordinates); weighted by the cell values of all other cells, where the weight; is a gaussian function. Parameters:. - foam - the pdefoam to search in. - txvec - event vector in foam coordinates [0,1]. - cv - cell value to estimate. Float_t GetAverageNeighborsValue(TMVA::PDEFoam* , vector<Float_t>& , TMVA::ECellValue ); This function returns the average value 'cv' of only nearest; neighbor cells. It is used in cases when a cell value is; undefined and the cell value shall be estimated by the; (well-defined) cell values of the n",MatchSource.WIKI,root/html532/TMVA__PDEFoamKernelGauss.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamKernelGauss.html
https://root.cern/root/html532/TMVA__PDEFoamKernelLinN.html:1535,Availability,error,error,1535,"LinN(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual Float_tEstimate(TMVA::PDEFoam*, vector<Float_t>&, TMVA::ECellValue); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) con",MatchSource.WIKI,root/html532/TMVA__PDEFoamKernelLinN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamKernelLinN.html
https://root.cern/root/html532/TMVA__PDEFoamKernelLinN.html:1619,Availability,error,error,1619,"AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual Float_tEstimate(TMVA::PDEFoam*, vector<Float_t>&, TMVA::ECellValue); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTObject",MatchSource.WIKI,root/html532/TMVA__PDEFoamKernelLinN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamKernelLinN.html
https://root.cern/root/html532/TMVA__PDEFoamKernelLinN.html:5713,Integrability,message,message,5713,"Object::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; Float_tGetAverageNeighborsValue(TMVA::PDEFoam*, vector<Float_t>&, TMVA::ECellValue); voidTObject::MakeZombie(); Float_tWeightLinNeighbors(TMVA::PDEFoam*, vector<Float_t>&, TMVA::ECellValue, Bool_t). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TMVA::MsgLogger*TMVA::PDEFoamKernelBase::fLogger! message logger. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDEFoamKernelLinN(); Default constructor for streamer. PDEFoamKernelLinN(const TMVA::PDEFoamKernelLinN& ); Copy constructor. Float_t Estimate(TMVA::PDEFoam* , vector<Float_t>& , TMVA::ECellValue ); Linear neighbors kernel estimator. It returns the cell value; 'cv', corresponding to the event vector 'txvec' (in foam; coordinates) linear weighted by the cell values of the neighbor; cells. Parameters:. - foam - the pdefoam to search in. - txvec - event vector in foam coordinates [0,1]. - cv - cell value to estimate. Float_t WeightLinNeighbors(TMVA::PDEFoam* , vector<Float_t>& , TMVA::ECellValue , Bool_t ); Returns the cell value, corresponding to 'txvec' (foam; coordinates [0,1]), weighted by the neighbor cells via a linear; function. Parameters:; - foam - the foam to search in. - txvec - event vector, transformed into foam coordinates [0,1]. - cv - cell value to be",MatchSource.WIKI,root/html532/TMVA__PDEFoamKernelLinN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamKernelLinN.html
https://root.cern/root/html532/TMVA__PDEFoamKernelLinN.html:5721,Testability,log,logger,5721,"Object::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; Float_tGetAverageNeighborsValue(TMVA::PDEFoam*, vector<Float_t>&, TMVA::ECellValue); voidTObject::MakeZombie(); Float_tWeightLinNeighbors(TMVA::PDEFoam*, vector<Float_t>&, TMVA::ECellValue, Bool_t). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TMVA::MsgLogger*TMVA::PDEFoamKernelBase::fLogger! message logger. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDEFoamKernelLinN(); Default constructor for streamer. PDEFoamKernelLinN(const TMVA::PDEFoamKernelLinN& ); Copy constructor. Float_t Estimate(TMVA::PDEFoam* , vector<Float_t>& , TMVA::ECellValue ); Linear neighbors kernel estimator. It returns the cell value; 'cv', corresponding to the event vector 'txvec' (in foam; coordinates) linear weighted by the cell values of the neighbor; cells. Parameters:. - foam - the pdefoam to search in. - txvec - event vector in foam coordinates [0,1]. - cv - cell value to estimate. Float_t WeightLinNeighbors(TMVA::PDEFoam* , vector<Float_t>& , TMVA::ECellValue , Bool_t ); Returns the cell value, corresponding to 'txvec' (foam; coordinates [0,1]), weighted by the neighbor cells via a linear; function. Parameters:; - foam - the foam to search in. - txvec - event vector, transformed into foam coordinates [0,1]. - cv - cell value to be",MatchSource.WIKI,root/html532/TMVA__PDEFoamKernelLinN.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamKernelLinN.html
https://root.cern/root/html532/TMVA__PDEFoamKernelTrivial.html:1550,Availability,error,error,1550,"vial(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual Float_tEstimate(TMVA::PDEFoam*, vector<Float_t>&, TMVA::ECellValue); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) con",MatchSource.WIKI,root/html532/TMVA__PDEFoamKernelTrivial.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamKernelTrivial.html
https://root.cern/root/html532/TMVA__PDEFoamKernelTrivial.html:1634,Availability,error,error,1634,"AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual Float_tEstimate(TMVA::PDEFoam*, vector<Float_t>&, TMVA::ECellValue); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTObject",MatchSource.WIKI,root/html532/TMVA__PDEFoamKernelTrivial.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamKernelTrivial.html
https://root.cern/root/html532/TMVA__PDEFoamKernelTrivial.html:5577,Integrability,message,message,5577,"irtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTObject::MakeZombie(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TMVA::MsgLogger*TMVA::PDEFoamKernelBase::fLogger! message logger. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDEFoamKernelTrivial(); Default constructor for streamer. PDEFoamKernelTrivial(const TMVA::PDEFoamKernelTrivial& ); Copy constructor. Float_t Estimate(TMVA::PDEFoam* , vector<Float_t>& , TMVA::ECellValue ); Simple kernel estimator. It returns the cell value 'cv',; corresponding to the event vector 'txvec' (in foam coordinates). Parameters:. - foam - the pdefoam to search in. - txvec - event vector in foam coordinates [0,1]. - cv - cell value to estimate. virtual ~PDEFoamKernelTrivial(); {}. » Author: Dominik Dannheim, Alexander Voigt » Copyright (c) 2010: *; » Last changed: root/tmva $Id: PDEFoamKernelTrivial.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__PDEFoamKernelTrivial.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamKernelTrivial.html
https://root.cern/root/html532/TMVA__PDEFoamKernelTrivial.html:5585,Testability,log,logger,5585,"irtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTObject::MakeZombie(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TMVA::MsgLogger*TMVA::PDEFoamKernelBase::fLogger! message logger. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDEFoamKernelTrivial(); Default constructor for streamer. PDEFoamKernelTrivial(const TMVA::PDEFoamKernelTrivial& ); Copy constructor. Float_t Estimate(TMVA::PDEFoam* , vector<Float_t>& , TMVA::ECellValue ); Simple kernel estimator. It returns the cell value 'cv',; corresponding to the event vector 'txvec' (in foam coordinates). Parameters:. - foam - the pdefoam to search in. - txvec - event vector in foam coordinates [0,1]. - cv - cell value to estimate. virtual ~PDEFoamKernelTrivial(); {}. » Author: Dominik Dannheim, Alexander Voigt » Copyright (c) 2010: *; » Last changed: root/tmva $Id: PDEFoamKernelTrivial.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__PDEFoamKernelTrivial.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamKernelTrivial.html
https://root.cern/root/html532/TMVA__PDEFoamMultiTarget.html:2488,Availability,error,error,2488,"e(TBrowser* b); voidTMVA::PDEFoam::CheckAll(Int_t); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; voidTMVA::PDEFoam::Create(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::PDEFoam::DeleteBinarySearchTree(); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); TH1D*TMVA::PDEFoam::Draw1Dim(TMVA::ECellValue cell_value, Int_t nbin, TMVA::PDEFoamKernelBase* kernel = NULL); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; voidTMVA::PDEFoam::FillBinarySearchTree(const TMVA::Event* ev); virtual voidTMVA::PDEFoamEvent::FillFoamCells(const TMVA::Event* ev, Float_t wt); virtual voidTMVA::PDEFoam::Finalize(); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual vector<Float_t>GetCellValue(const map<Int_t,Float_t>&, TMVA::ECellValue); virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TStringTMVA::PDEFoam::GetFoamName() const; virtual const char*TObject::GetIconName() const; UInt_tTMVA::PDEFoam::GetMaxDepth() const; UInt_tTMVA::PDEFoam::GetNActiveCells() const; virtual const char*TObject::GetName() const; UInt_tTMVA::PDEFoam::GetNCells() const; UInt_tTMVA::PDEFoam::Ge",MatchSource.WIKI,root/html532/TMVA__PDEFoamMultiTarget.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamMultiTarget.html
https://root.cern/root/html532/TMVA__PDEFoamMultiTarget.html:2572,Availability,error,error,2572,"onst char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; voidTMVA::PDEFoam::Create(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::PDEFoam::DeleteBinarySearchTree(); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); TH1D*TMVA::PDEFoam::Draw1Dim(TMVA::ECellValue cell_value, Int_t nbin, TMVA::PDEFoamKernelBase* kernel = NULL); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; voidTMVA::PDEFoam::FillBinarySearchTree(const TMVA::Event* ev); virtual voidTMVA::PDEFoamEvent::FillFoamCells(const TMVA::Event* ev, Float_t wt); virtual voidTMVA::PDEFoam::Finalize(); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual vector<Float_t>GetCellValue(const map<Int_t,Float_t>&, TMVA::ECellValue); virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TStringTMVA::PDEFoam::GetFoamName() const; virtual const char*TObject::GetIconName() const; UInt_tTMVA::PDEFoam::GetMaxDepth() const; UInt_tTMVA::PDEFoam::GetNActiveCells() const; virtual const char*TObject::GetName() const; UInt_tTMVA::PDEFoam::GetNCells() const; UInt_tTMVA::PDEFoam::GetNInActiveCells() const; UInt_tTMVA::PDEFoam::GetNmin(); virtual char*TObject::GetOb",MatchSource.WIKI,root/html532/TMVA__PDEFoamMultiTarget.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamMultiTarget.html
https://root.cern/root/html532/TMVA__PDEFoamMultiTarget.html:10385,Deployability,integrat,integration,10385,"= false); TMVA::PDEFoamTMVA::PDEFoam::PDEFoam(const TMVA::PDEFoam&); TMVA::PDEFoamEventTMVA::PDEFoamEvent::PDEFoamEvent(const TMVA::PDEFoamEvent&); TMVA::PDEFoamMultiTargetPDEFoamMultiTarget(const TMVA::PDEFoamMultiTarget&); Long_tTMVA::PDEFoam::PeekMax(); voidTMVA::PDEFoam::SetCellElement(TMVA::PDEFoamCell* cell, UInt_t i, Double_t value); voidTMVA::PDEFoam::Varedu(Double_t*, Int_t&, Double_t&, Double_t&). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. Double_t*TMVA::PDEFoam::fAlpha[fDim] Internal parameters of the hyperrectangle; TMVA::PDEFoamCell**TMVA::PDEFoam::fCells[fNCells] Array of ALL cells; TMVA::EDTSeparationTMVA::PDEFoam::fDTSeparationBACKWARDS COMPATIBILITY: split cells according to decision tree logic; Int_tTMVA::PDEFoam::fDimDimension of the integration/simulation space; TMVA::PDEFoamDensityBase*TMVA::PDEFoam::fDistr! distribution of training events; Int_tTMVA::PDEFoam::fEvPerBinMaximum number of effective (wt=1) events per bin; Bool_tTMVA::PDEFoam::fFillFoamWithOrigWeightsBACKWARDS COMPATIBILITY: fill the foam with boost or orig. weights; TMVA::EFoamTypeTMVA::PDEFoam::fFoamTypeBACKWARDS COMPATIBILITY: type of foam; TObjArray*TMVA::PDEFoam::fHistEdgHistograms of wt, one for each cell edge; Int_t*TMVA::PDEFoam::fInhiDiv! [fDim] Flags for inhibiting cell division; Int_tTMVA::PDEFoam::fLastCeIndex of the last cell; TMVA::MsgLogger*TMVA::PDEFoam::fLogger! message logger; Int_t*TMVA::PDEFoam::fMaskDiv! [fDim] Dynamic Mask for cell division; UInt_tTMVA::PDEFoam::fMaxDepthmaximum depth of cell tree; Int_tTMVA::PDEFoam::fNBinNo. of bins in the edge histogram for cell MC exploration; Int_tTMVA::PDEFoam::fNCellsMaximum number of cells; UInt_tTMVA::PDEFoam::fNElementsBACKWARDS COMPATIBILITY: number of variables in every cell;",MatchSource.WIKI,root/html532/TMVA__PDEFoamMultiTarget.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamMultiTarget.html
https://root.cern/root/html532/TMVA__PDEFoamMultiTarget.html:903,Integrability,depend,depending,903,". TMVA::PDEFoamMultiTarget. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::PDEFoamMultiTarget. class TMVA::PDEFoamMultiTarget: public TMVA::PDEFoamEvent. PDEFoamMultiTarget. This PDEFoam variant is used to estimate multiple targets by; creating an event density foam (PDEFoamEvent), which has dimension:. dimension = number of variables + number targets. This PDEFoam variant stores in every cell the sum of event weights; and the sum of the squared event weights. During evaluation for a; given event, which has only variables and no targets (number of; event variables is smaller than the foam dimension), the targets; are estimated by finding all cells, which correspond to this event; and calculate the Mean (or Mpv, depending on the ETargetSelection); cell center weighted by the event density in the cell. This PDEFoam variant should be booked together with the; PDEFoamEventDensity density estimator, which returns the event; weight density at a given phase space point during the foam; build-up. Function Members (Methods); public:. virtual~PDEFoamMultiTarget(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::PDEFoam::AddVariableName(const char* s); voidTMVA::PDEFoam::AddVariableName(TObjString* s); virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidTMVA::PDEFoam::CheckAll(Int_t); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; voidTMVA::PDEFoam::Create(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::PDEFoam::DeleteBinarySearchTree(); virtual Int_tTObject::DistancetoPrimitive(",MatchSource.WIKI,root/html532/TMVA__PDEFoamMultiTarget.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamMultiTarget.html
https://root.cern/root/html532/TMVA__PDEFoamMultiTarget.html:10385,Integrability,integrat,integration,10385,"= false); TMVA::PDEFoamTMVA::PDEFoam::PDEFoam(const TMVA::PDEFoam&); TMVA::PDEFoamEventTMVA::PDEFoamEvent::PDEFoamEvent(const TMVA::PDEFoamEvent&); TMVA::PDEFoamMultiTargetPDEFoamMultiTarget(const TMVA::PDEFoamMultiTarget&); Long_tTMVA::PDEFoam::PeekMax(); voidTMVA::PDEFoam::SetCellElement(TMVA::PDEFoamCell* cell, UInt_t i, Double_t value); voidTMVA::PDEFoam::Varedu(Double_t*, Int_t&, Double_t&, Double_t&). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. Double_t*TMVA::PDEFoam::fAlpha[fDim] Internal parameters of the hyperrectangle; TMVA::PDEFoamCell**TMVA::PDEFoam::fCells[fNCells] Array of ALL cells; TMVA::EDTSeparationTMVA::PDEFoam::fDTSeparationBACKWARDS COMPATIBILITY: split cells according to decision tree logic; Int_tTMVA::PDEFoam::fDimDimension of the integration/simulation space; TMVA::PDEFoamDensityBase*TMVA::PDEFoam::fDistr! distribution of training events; Int_tTMVA::PDEFoam::fEvPerBinMaximum number of effective (wt=1) events per bin; Bool_tTMVA::PDEFoam::fFillFoamWithOrigWeightsBACKWARDS COMPATIBILITY: fill the foam with boost or orig. weights; TMVA::EFoamTypeTMVA::PDEFoam::fFoamTypeBACKWARDS COMPATIBILITY: type of foam; TObjArray*TMVA::PDEFoam::fHistEdgHistograms of wt, one for each cell edge; Int_t*TMVA::PDEFoam::fInhiDiv! [fDim] Flags for inhibiting cell division; Int_tTMVA::PDEFoam::fLastCeIndex of the last cell; TMVA::MsgLogger*TMVA::PDEFoam::fLogger! message logger; Int_t*TMVA::PDEFoam::fMaskDiv! [fDim] Dynamic Mask for cell division; UInt_tTMVA::PDEFoam::fMaxDepthmaximum depth of cell tree; Int_tTMVA::PDEFoam::fNBinNo. of bins in the edge histogram for cell MC exploration; Int_tTMVA::PDEFoam::fNCellsMaximum number of cells; UInt_tTMVA::PDEFoam::fNElementsBACKWARDS COMPATIBILITY: number of variables in every cell;",MatchSource.WIKI,root/html532/TMVA__PDEFoamMultiTarget.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamMultiTarget.html
https://root.cern/root/html532/TMVA__PDEFoamMultiTarget.html:11007,Integrability,message,message,11007,"nu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. Double_t*TMVA::PDEFoam::fAlpha[fDim] Internal parameters of the hyperrectangle; TMVA::PDEFoamCell**TMVA::PDEFoam::fCells[fNCells] Array of ALL cells; TMVA::EDTSeparationTMVA::PDEFoam::fDTSeparationBACKWARDS COMPATIBILITY: split cells according to decision tree logic; Int_tTMVA::PDEFoam::fDimDimension of the integration/simulation space; TMVA::PDEFoamDensityBase*TMVA::PDEFoam::fDistr! distribution of training events; Int_tTMVA::PDEFoam::fEvPerBinMaximum number of effective (wt=1) events per bin; Bool_tTMVA::PDEFoam::fFillFoamWithOrigWeightsBACKWARDS COMPATIBILITY: fill the foam with boost or orig. weights; TMVA::EFoamTypeTMVA::PDEFoam::fFoamTypeBACKWARDS COMPATIBILITY: type of foam; TObjArray*TMVA::PDEFoam::fHistEdgHistograms of wt, one for each cell edge; Int_t*TMVA::PDEFoam::fInhiDiv! [fDim] Flags for inhibiting cell division; Int_tTMVA::PDEFoam::fLastCeIndex of the last cell; TMVA::MsgLogger*TMVA::PDEFoam::fLogger! message logger; Int_t*TMVA::PDEFoam::fMaskDiv! [fDim] Dynamic Mask for cell division; UInt_tTMVA::PDEFoam::fMaxDepthmaximum depth of cell tree; Int_tTMVA::PDEFoam::fNBinNo. of bins in the edge histogram for cell MC exploration; Int_tTMVA::PDEFoam::fNCellsMaximum number of cells; UInt_tTMVA::PDEFoam::fNElementsBACKWARDS COMPATIBILITY: number of variables in every cell; Int_tTMVA::PDEFoam::fNSamplNo. of MC events, when dividing (exploring) cell; TStringTMVA::PDEFoam::fNameName of a given instance of the FOAM class; UInt_tTMVA::PDEFoam::fNminminimal number of events in cell to split cell; Int_tTMVA::PDEFoam::fNoActNumber of active cells; Bool_tTMVA::PDEFoam::fPeekMaxBACKWARDS COMPATIBILITY: peek up cell with max. driver integral for split; TRandom3*TMVA::PDEFoam::fPseRanPointer to user-defined generator of pseudorandom numbers; Double_t*TMVA::PDEFoam::fRvec[fDim] random number vector from r.n. generator fDim+1 m",MatchSource.WIKI,root/html532/TMVA__PDEFoamMultiTarget.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamMultiTarget.html
https://root.cern/root/html532/TMVA__PDEFoamMultiTarget.html:509,Modifiability,variab,variables,509,". TMVA::PDEFoamMultiTarget. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::PDEFoamMultiTarget. class TMVA::PDEFoamMultiTarget: public TMVA::PDEFoamEvent. PDEFoamMultiTarget. This PDEFoam variant is used to estimate multiple targets by; creating an event density foam (PDEFoamEvent), which has dimension:. dimension = number of variables + number targets. This PDEFoam variant stores in every cell the sum of event weights; and the sum of the squared event weights. During evaluation for a; given event, which has only variables and no targets (number of; event variables is smaller than the foam dimension), the targets; are estimated by finding all cells, which correspond to this event; and calculate the Mean (or Mpv, depending on the ETargetSelection); cell center weighted by the event density in the cell. This PDEFoam variant should be booked together with the; PDEFoamEventDensity density estimator, which returns the event; weight density at a given phase space point during the foam; build-up. Function Members (Methods); public:. virtual~PDEFoamMultiTarget(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::PDEFoam::AddVariableName(const char* s); voidTMVA::PDEFoam::AddVariableName(TObjString* s); virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidTMVA::PDEFoam::CheckAll(Int_t); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; voidTMVA::PDEFoam::Create(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::PDEFoam::DeleteBinarySearchTree(); virtual Int_tTObject::DistancetoPrimitive(",MatchSource.WIKI,root/html532/TMVA__PDEFoamMultiTarget.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamMultiTarget.html
https://root.cern/root/html532/TMVA__PDEFoamMultiTarget.html:700,Modifiability,variab,variables,700,". TMVA::PDEFoamMultiTarget. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::PDEFoamMultiTarget. class TMVA::PDEFoamMultiTarget: public TMVA::PDEFoamEvent. PDEFoamMultiTarget. This PDEFoam variant is used to estimate multiple targets by; creating an event density foam (PDEFoamEvent), which has dimension:. dimension = number of variables + number targets. This PDEFoam variant stores in every cell the sum of event weights; and the sum of the squared event weights. During evaluation for a; given event, which has only variables and no targets (number of; event variables is smaller than the foam dimension), the targets; are estimated by finding all cells, which correspond to this event; and calculate the Mean (or Mpv, depending on the ETargetSelection); cell center weighted by the event density in the cell. This PDEFoam variant should be booked together with the; PDEFoamEventDensity density estimator, which returns the event; weight density at a given phase space point during the foam; build-up. Function Members (Methods); public:. virtual~PDEFoamMultiTarget(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::PDEFoam::AddVariableName(const char* s); voidTMVA::PDEFoam::AddVariableName(TObjString* s); virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidTMVA::PDEFoam::CheckAll(Int_t); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; voidTMVA::PDEFoam::Create(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::PDEFoam::DeleteBinarySearchTree(); virtual Int_tTObject::DistancetoPrimitive(",MatchSource.WIKI,root/html532/TMVA__PDEFoamMultiTarget.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamMultiTarget.html
https://root.cern/root/html532/TMVA__PDEFoamMultiTarget.html:743,Modifiability,variab,variables,743,". TMVA::PDEFoamMultiTarget. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::PDEFoamMultiTarget. class TMVA::PDEFoamMultiTarget: public TMVA::PDEFoamEvent. PDEFoamMultiTarget. This PDEFoam variant is used to estimate multiple targets by; creating an event density foam (PDEFoamEvent), which has dimension:. dimension = number of variables + number targets. This PDEFoam variant stores in every cell the sum of event weights; and the sum of the squared event weights. During evaluation for a; given event, which has only variables and no targets (number of; event variables is smaller than the foam dimension), the targets; are estimated by finding all cells, which correspond to this event; and calculate the Mean (or Mpv, depending on the ETargetSelection); cell center weighted by the event density in the cell. This PDEFoam variant should be booked together with the; PDEFoamEventDensity density estimator, which returns the event; weight density at a given phase space point during the foam; build-up. Function Members (Methods); public:. virtual~PDEFoamMultiTarget(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::PDEFoam::AddVariableName(const char* s); voidTMVA::PDEFoam::AddVariableName(TObjString* s); virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidTMVA::PDEFoam::CheckAll(Int_t); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; voidTMVA::PDEFoam::Create(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::PDEFoam::DeleteBinarySearchTree(); virtual Int_tTObject::DistancetoPrimitive(",MatchSource.WIKI,root/html532/TMVA__PDEFoamMultiTarget.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamMultiTarget.html
https://root.cern/root/html532/TMVA__PDEFoamMultiTarget.html:11353,Modifiability,variab,variables,11353,"ITY: split cells according to decision tree logic; Int_tTMVA::PDEFoam::fDimDimension of the integration/simulation space; TMVA::PDEFoamDensityBase*TMVA::PDEFoam::fDistr! distribution of training events; Int_tTMVA::PDEFoam::fEvPerBinMaximum number of effective (wt=1) events per bin; Bool_tTMVA::PDEFoam::fFillFoamWithOrigWeightsBACKWARDS COMPATIBILITY: fill the foam with boost or orig. weights; TMVA::EFoamTypeTMVA::PDEFoam::fFoamTypeBACKWARDS COMPATIBILITY: type of foam; TObjArray*TMVA::PDEFoam::fHistEdgHistograms of wt, one for each cell edge; Int_t*TMVA::PDEFoam::fInhiDiv! [fDim] Flags for inhibiting cell division; Int_tTMVA::PDEFoam::fLastCeIndex of the last cell; TMVA::MsgLogger*TMVA::PDEFoam::fLogger! message logger; Int_t*TMVA::PDEFoam::fMaskDiv! [fDim] Dynamic Mask for cell division; UInt_tTMVA::PDEFoam::fMaxDepthmaximum depth of cell tree; Int_tTMVA::PDEFoam::fNBinNo. of bins in the edge histogram for cell MC exploration; Int_tTMVA::PDEFoam::fNCellsMaximum number of cells; UInt_tTMVA::PDEFoam::fNElementsBACKWARDS COMPATIBILITY: number of variables in every cell; Int_tTMVA::PDEFoam::fNSamplNo. of MC events, when dividing (exploring) cell; TStringTMVA::PDEFoam::fNameName of a given instance of the FOAM class; UInt_tTMVA::PDEFoam::fNminminimal number of events in cell to split cell; Int_tTMVA::PDEFoam::fNoActNumber of active cells; Bool_tTMVA::PDEFoam::fPeekMaxBACKWARDS COMPATIBILITY: peek up cell with max. driver integral for split; TRandom3*TMVA::PDEFoam::fPseRanPointer to user-defined generator of pseudorandom numbers; Double_t*TMVA::PDEFoam::fRvec[fDim] random number vector from r.n. generator fDim+1 maximum elements; TMVA::ETargetSelectionfTargetSelectionthe target selection method; TMVA::Timer*TMVA::PDEFoam::fTimer! timer for graphical output; TObjArray*TMVA::PDEFoam::fVariableNamescollection of all variable names; Float_tTMVA::PDEFoam::fVolFracBACKWARDS COMPATIBILITY: volume fraction (with respect to total phase space; Double_t*TMVA::PDEFoam::fXmax[fDim] ma",MatchSource.WIKI,root/html532/TMVA__PDEFoamMultiTarget.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamMultiTarget.html
https://root.cern/root/html532/TMVA__PDEFoamMultiTarget.html:12133,Modifiability,variab,variable,12133," Int_tTMVA::PDEFoam::fNBinNo. of bins in the edge histogram for cell MC exploration; Int_tTMVA::PDEFoam::fNCellsMaximum number of cells; UInt_tTMVA::PDEFoam::fNElementsBACKWARDS COMPATIBILITY: number of variables in every cell; Int_tTMVA::PDEFoam::fNSamplNo. of MC events, when dividing (exploring) cell; TStringTMVA::PDEFoam::fNameName of a given instance of the FOAM class; UInt_tTMVA::PDEFoam::fNminminimal number of events in cell to split cell; Int_tTMVA::PDEFoam::fNoActNumber of active cells; Bool_tTMVA::PDEFoam::fPeekMaxBACKWARDS COMPATIBILITY: peek up cell with max. driver integral for split; TRandom3*TMVA::PDEFoam::fPseRanPointer to user-defined generator of pseudorandom numbers; Double_t*TMVA::PDEFoam::fRvec[fDim] random number vector from r.n. generator fDim+1 maximum elements; TMVA::ETargetSelectionfTargetSelectionthe target selection method; TMVA::Timer*TMVA::PDEFoam::fTimer! timer for graphical output; TObjArray*TMVA::PDEFoam::fVariableNamescollection of all variable names; Float_tTMVA::PDEFoam::fVolFracBACKWARDS COMPATIBILITY: volume fraction (with respect to total phase space; Double_t*TMVA::PDEFoam::fXmax[fDim] maximum for variable transform; Double_t*TMVA::PDEFoam::fXmin[fDim] minimum for variable transform. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDEFoamMultiTarget(); Default constructor for streamer, user should not use it. PDEFoamMultiTarget(const TString& , TMVA::ETargetSelection ); User constructor. Parameters:. - Name - name of PDEFoam object. - ts - target selection method used in; GetCellValue(const std::map<Int_t, Float_t>& xvec, ECellValue); Cadidates are: TMVA::kMean, TMVA::kMpv. - TMVA::kMean - The function GetCellValue() finds all cells; which contain a given event vector 'xvec' and returns the; mean target (for every target variable in the foam). - TMVA::kMpv - The function GetCellValue() finds all cells; which contain a given event vector 'xvec' and returns the; most probable target (for ",MatchSource.WIKI,root/html532/TMVA__PDEFoamMultiTarget.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamMultiTarget.html
https://root.cern/root/html532/TMVA__PDEFoamMultiTarget.html:12304,Modifiability,variab,variable,12304," Int_tTMVA::PDEFoam::fNBinNo. of bins in the edge histogram for cell MC exploration; Int_tTMVA::PDEFoam::fNCellsMaximum number of cells; UInt_tTMVA::PDEFoam::fNElementsBACKWARDS COMPATIBILITY: number of variables in every cell; Int_tTMVA::PDEFoam::fNSamplNo. of MC events, when dividing (exploring) cell; TStringTMVA::PDEFoam::fNameName of a given instance of the FOAM class; UInt_tTMVA::PDEFoam::fNminminimal number of events in cell to split cell; Int_tTMVA::PDEFoam::fNoActNumber of active cells; Bool_tTMVA::PDEFoam::fPeekMaxBACKWARDS COMPATIBILITY: peek up cell with max. driver integral for split; TRandom3*TMVA::PDEFoam::fPseRanPointer to user-defined generator of pseudorandom numbers; Double_t*TMVA::PDEFoam::fRvec[fDim] random number vector from r.n. generator fDim+1 maximum elements; TMVA::ETargetSelectionfTargetSelectionthe target selection method; TMVA::Timer*TMVA::PDEFoam::fTimer! timer for graphical output; TObjArray*TMVA::PDEFoam::fVariableNamescollection of all variable names; Float_tTMVA::PDEFoam::fVolFracBACKWARDS COMPATIBILITY: volume fraction (with respect to total phase space; Double_t*TMVA::PDEFoam::fXmax[fDim] maximum for variable transform; Double_t*TMVA::PDEFoam::fXmin[fDim] minimum for variable transform. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDEFoamMultiTarget(); Default constructor for streamer, user should not use it. PDEFoamMultiTarget(const TString& , TMVA::ETargetSelection ); User constructor. Parameters:. - Name - name of PDEFoam object. - ts - target selection method used in; GetCellValue(const std::map<Int_t, Float_t>& xvec, ECellValue); Cadidates are: TMVA::kMean, TMVA::kMpv. - TMVA::kMean - The function GetCellValue() finds all cells; which contain a given event vector 'xvec' and returns the; mean target (for every target variable in the foam). - TMVA::kMpv - The function GetCellValue() finds all cells; which contain a given event vector 'xvec' and returns the; most probable target (for ",MatchSource.WIKI,root/html532/TMVA__PDEFoamMultiTarget.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamMultiTarget.html
https://root.cern/root/html532/TMVA__PDEFoamMultiTarget.html:12372,Modifiability,variab,variable,12372," Int_tTMVA::PDEFoam::fNBinNo. of bins in the edge histogram for cell MC exploration; Int_tTMVA::PDEFoam::fNCellsMaximum number of cells; UInt_tTMVA::PDEFoam::fNElementsBACKWARDS COMPATIBILITY: number of variables in every cell; Int_tTMVA::PDEFoam::fNSamplNo. of MC events, when dividing (exploring) cell; TStringTMVA::PDEFoam::fNameName of a given instance of the FOAM class; UInt_tTMVA::PDEFoam::fNminminimal number of events in cell to split cell; Int_tTMVA::PDEFoam::fNoActNumber of active cells; Bool_tTMVA::PDEFoam::fPeekMaxBACKWARDS COMPATIBILITY: peek up cell with max. driver integral for split; TRandom3*TMVA::PDEFoam::fPseRanPointer to user-defined generator of pseudorandom numbers; Double_t*TMVA::PDEFoam::fRvec[fDim] random number vector from r.n. generator fDim+1 maximum elements; TMVA::ETargetSelectionfTargetSelectionthe target selection method; TMVA::Timer*TMVA::PDEFoam::fTimer! timer for graphical output; TObjArray*TMVA::PDEFoam::fVariableNamescollection of all variable names; Float_tTMVA::PDEFoam::fVolFracBACKWARDS COMPATIBILITY: volume fraction (with respect to total phase space; Double_t*TMVA::PDEFoam::fXmax[fDim] maximum for variable transform; Double_t*TMVA::PDEFoam::fXmin[fDim] minimum for variable transform. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDEFoamMultiTarget(); Default constructor for streamer, user should not use it. PDEFoamMultiTarget(const TString& , TMVA::ETargetSelection ); User constructor. Parameters:. - Name - name of PDEFoam object. - ts - target selection method used in; GetCellValue(const std::map<Int_t, Float_t>& xvec, ECellValue); Cadidates are: TMVA::kMean, TMVA::kMpv. - TMVA::kMean - The function GetCellValue() finds all cells; which contain a given event vector 'xvec' and returns the; mean target (for every target variable in the foam). - TMVA::kMpv - The function GetCellValue() finds all cells; which contain a given event vector 'xvec' and returns the; most probable target (for ",MatchSource.WIKI,root/html532/TMVA__PDEFoamMultiTarget.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamMultiTarget.html
https://root.cern/root/html532/TMVA__PDEFoamMultiTarget.html:12983,Modifiability,variab,variable,12983,"or fDim+1 maximum elements; TMVA::ETargetSelectionfTargetSelectionthe target selection method; TMVA::Timer*TMVA::PDEFoam::fTimer! timer for graphical output; TObjArray*TMVA::PDEFoam::fVariableNamescollection of all variable names; Float_tTMVA::PDEFoam::fVolFracBACKWARDS COMPATIBILITY: volume fraction (with respect to total phase space; Double_t*TMVA::PDEFoam::fXmax[fDim] maximum for variable transform; Double_t*TMVA::PDEFoam::fXmin[fDim] minimum for variable transform. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDEFoamMultiTarget(); Default constructor for streamer, user should not use it. PDEFoamMultiTarget(const TString& , TMVA::ETargetSelection ); User constructor. Parameters:. - Name - name of PDEFoam object. - ts - target selection method used in; GetCellValue(const std::map<Int_t, Float_t>& xvec, ECellValue); Cadidates are: TMVA::kMean, TMVA::kMpv. - TMVA::kMean - The function GetCellValue() finds all cells; which contain a given event vector 'xvec' and returns the; mean target (for every target variable in the foam). - TMVA::kMpv - The function GetCellValue() finds all cells; which contain a given event vector 'xvec' and returns the; most probable target (for every target variable in the; foam), that is the target value which corresponds to the; cell with the largest event density. PDEFoamMultiTarget(const TMVA::PDEFoamMultiTarget& ); Copy Constructor NOT IMPLEMENTED (NEVER USED). std::vector<Float_t> GetCellValue(const map<Int_t,Float_t>& , TMVA::ECellValue ); This function is overridden from PDFEFoam. It returns all; regression targets (in order), given an untransformed event; vector 'xvec'. The key of 'xvec' is the dimension and the value; (Float_t) is the coordinate. Note: number of foam dimensions = number of variables + number; of targets. Parameters:; - xvec - map of event variables (no targets!); - cv - cell value to return (ignored!). Return:; Targets, ordered by missing dimensions in 'xvec'.; The size o",MatchSource.WIKI,root/html532/TMVA__PDEFoamMultiTarget.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamMultiTarget.html
https://root.cern/root/html532/TMVA__PDEFoamMultiTarget.html:13164,Modifiability,variab,variable,13164,"e names; Float_tTMVA::PDEFoam::fVolFracBACKWARDS COMPATIBILITY: volume fraction (with respect to total phase space; Double_t*TMVA::PDEFoam::fXmax[fDim] maximum for variable transform; Double_t*TMVA::PDEFoam::fXmin[fDim] minimum for variable transform. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDEFoamMultiTarget(); Default constructor for streamer, user should not use it. PDEFoamMultiTarget(const TString& , TMVA::ETargetSelection ); User constructor. Parameters:. - Name - name of PDEFoam object. - ts - target selection method used in; GetCellValue(const std::map<Int_t, Float_t>& xvec, ECellValue); Cadidates are: TMVA::kMean, TMVA::kMpv. - TMVA::kMean - The function GetCellValue() finds all cells; which contain a given event vector 'xvec' and returns the; mean target (for every target variable in the foam). - TMVA::kMpv - The function GetCellValue() finds all cells; which contain a given event vector 'xvec' and returns the; most probable target (for every target variable in the; foam), that is the target value which corresponds to the; cell with the largest event density. PDEFoamMultiTarget(const TMVA::PDEFoamMultiTarget& ); Copy Constructor NOT IMPLEMENTED (NEVER USED). std::vector<Float_t> GetCellValue(const map<Int_t,Float_t>& , TMVA::ECellValue ); This function is overridden from PDFEFoam. It returns all; regression targets (in order), given an untransformed event; vector 'xvec'. The key of 'xvec' is the dimension and the value; (Float_t) is the coordinate. Note: number of foam dimensions = number of variables + number; of targets. Parameters:; - xvec - map of event variables (no targets!); - cv - cell value to return (ignored!). Return:; Targets, ordered by missing dimensions in 'xvec'.; The size of the returned vector = foam dimension - size of xvec. virtual ~PDEFoamMultiTarget(); {}. » Author: Tancredi Carli, Dominik Dannheim, Alexander Voigt » Copyright (c) 2008, 2010: *; » Last changed: root/tmva $Id: PDEFoamMu",MatchSource.WIKI,root/html532/TMVA__PDEFoamMultiTarget.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamMultiTarget.html
https://root.cern/root/html532/TMVA__PDEFoamMultiTarget.html:13717,Modifiability,variab,variables,13717," transform. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDEFoamMultiTarget(); Default constructor for streamer, user should not use it. PDEFoamMultiTarget(const TString& , TMVA::ETargetSelection ); User constructor. Parameters:. - Name - name of PDEFoam object. - ts - target selection method used in; GetCellValue(const std::map<Int_t, Float_t>& xvec, ECellValue); Cadidates are: TMVA::kMean, TMVA::kMpv. - TMVA::kMean - The function GetCellValue() finds all cells; which contain a given event vector 'xvec' and returns the; mean target (for every target variable in the foam). - TMVA::kMpv - The function GetCellValue() finds all cells; which contain a given event vector 'xvec' and returns the; most probable target (for every target variable in the; foam), that is the target value which corresponds to the; cell with the largest event density. PDEFoamMultiTarget(const TMVA::PDEFoamMultiTarget& ); Copy Constructor NOT IMPLEMENTED (NEVER USED). std::vector<Float_t> GetCellValue(const map<Int_t,Float_t>& , TMVA::ECellValue ); This function is overridden from PDFEFoam. It returns all; regression targets (in order), given an untransformed event; vector 'xvec'. The key of 'xvec' is the dimension and the value; (Float_t) is the coordinate. Note: number of foam dimensions = number of variables + number; of targets. Parameters:; - xvec - map of event variables (no targets!); - cv - cell value to return (ignored!). Return:; Targets, ordered by missing dimensions in 'xvec'.; The size of the returned vector = foam dimension - size of xvec. virtual ~PDEFoamMultiTarget(); {}. » Author: Tancredi Carli, Dominik Dannheim, Alexander Voigt » Copyright (c) 2008, 2010: *; » Last changed: root/tmva $Id: PDEFoamMultiTarget.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__PDEFoamMultiTarget.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamMultiTarget.html
https://root.cern/root/html532/TMVA__PDEFoamMultiTarget.html:13784,Modifiability,variab,variables,13784," transform. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDEFoamMultiTarget(); Default constructor for streamer, user should not use it. PDEFoamMultiTarget(const TString& , TMVA::ETargetSelection ); User constructor. Parameters:. - Name - name of PDEFoam object. - ts - target selection method used in; GetCellValue(const std::map<Int_t, Float_t>& xvec, ECellValue); Cadidates are: TMVA::kMean, TMVA::kMpv. - TMVA::kMean - The function GetCellValue() finds all cells; which contain a given event vector 'xvec' and returns the; mean target (for every target variable in the foam). - TMVA::kMpv - The function GetCellValue() finds all cells; which contain a given event vector 'xvec' and returns the; most probable target (for every target variable in the; foam), that is the target value which corresponds to the; cell with the largest event density. PDEFoamMultiTarget(const TMVA::PDEFoamMultiTarget& ); Copy Constructor NOT IMPLEMENTED (NEVER USED). std::vector<Float_t> GetCellValue(const map<Int_t,Float_t>& , TMVA::ECellValue ); This function is overridden from PDFEFoam. It returns all; regression targets (in order), given an untransformed event; vector 'xvec'. The key of 'xvec' is the dimension and the value; (Float_t) is the coordinate. Note: number of foam dimensions = number of variables + number; of targets. Parameters:; - xvec - map of event variables (no targets!); - cv - cell value to return (ignored!). Return:; Targets, ordered by missing dimensions in 'xvec'.; The size of the returned vector = foam dimension - size of xvec. virtual ~PDEFoamMultiTarget(); {}. » Author: Tancredi Carli, Dominik Dannheim, Alexander Voigt » Copyright (c) 2008, 2010: *; » Last changed: root/tmva $Id: PDEFoamMultiTarget.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__PDEFoamMultiTarget.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamMultiTarget.html
https://root.cern/root/html532/TMVA__PDEFoamMultiTarget.html:10337,Testability,log,logic,10337,"= false); TMVA::PDEFoamTMVA::PDEFoam::PDEFoam(const TMVA::PDEFoam&); TMVA::PDEFoamEventTMVA::PDEFoamEvent::PDEFoamEvent(const TMVA::PDEFoamEvent&); TMVA::PDEFoamMultiTargetPDEFoamMultiTarget(const TMVA::PDEFoamMultiTarget&); Long_tTMVA::PDEFoam::PeekMax(); voidTMVA::PDEFoam::SetCellElement(TMVA::PDEFoamCell* cell, UInt_t i, Double_t value); voidTMVA::PDEFoam::Varedu(Double_t*, Int_t&, Double_t&, Double_t&). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. Double_t*TMVA::PDEFoam::fAlpha[fDim] Internal parameters of the hyperrectangle; TMVA::PDEFoamCell**TMVA::PDEFoam::fCells[fNCells] Array of ALL cells; TMVA::EDTSeparationTMVA::PDEFoam::fDTSeparationBACKWARDS COMPATIBILITY: split cells according to decision tree logic; Int_tTMVA::PDEFoam::fDimDimension of the integration/simulation space; TMVA::PDEFoamDensityBase*TMVA::PDEFoam::fDistr! distribution of training events; Int_tTMVA::PDEFoam::fEvPerBinMaximum number of effective (wt=1) events per bin; Bool_tTMVA::PDEFoam::fFillFoamWithOrigWeightsBACKWARDS COMPATIBILITY: fill the foam with boost or orig. weights; TMVA::EFoamTypeTMVA::PDEFoam::fFoamTypeBACKWARDS COMPATIBILITY: type of foam; TObjArray*TMVA::PDEFoam::fHistEdgHistograms of wt, one for each cell edge; Int_t*TMVA::PDEFoam::fInhiDiv! [fDim] Flags for inhibiting cell division; Int_tTMVA::PDEFoam::fLastCeIndex of the last cell; TMVA::MsgLogger*TMVA::PDEFoam::fLogger! message logger; Int_t*TMVA::PDEFoam::fMaskDiv! [fDim] Dynamic Mask for cell division; UInt_tTMVA::PDEFoam::fMaxDepthmaximum depth of cell tree; Int_tTMVA::PDEFoam::fNBinNo. of bins in the edge histogram for cell MC exploration; Int_tTMVA::PDEFoam::fNCellsMaximum number of cells; UInt_tTMVA::PDEFoam::fNElementsBACKWARDS COMPATIBILITY: number of variables in every cell;",MatchSource.WIKI,root/html532/TMVA__PDEFoamMultiTarget.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamMultiTarget.html
https://root.cern/root/html532/TMVA__PDEFoamMultiTarget.html:11015,Testability,log,logger,11015,"nu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. Double_t*TMVA::PDEFoam::fAlpha[fDim] Internal parameters of the hyperrectangle; TMVA::PDEFoamCell**TMVA::PDEFoam::fCells[fNCells] Array of ALL cells; TMVA::EDTSeparationTMVA::PDEFoam::fDTSeparationBACKWARDS COMPATIBILITY: split cells according to decision tree logic; Int_tTMVA::PDEFoam::fDimDimension of the integration/simulation space; TMVA::PDEFoamDensityBase*TMVA::PDEFoam::fDistr! distribution of training events; Int_tTMVA::PDEFoam::fEvPerBinMaximum number of effective (wt=1) events per bin; Bool_tTMVA::PDEFoam::fFillFoamWithOrigWeightsBACKWARDS COMPATIBILITY: fill the foam with boost or orig. weights; TMVA::EFoamTypeTMVA::PDEFoam::fFoamTypeBACKWARDS COMPATIBILITY: type of foam; TObjArray*TMVA::PDEFoam::fHistEdgHistograms of wt, one for each cell edge; Int_t*TMVA::PDEFoam::fInhiDiv! [fDim] Flags for inhibiting cell division; Int_tTMVA::PDEFoam::fLastCeIndex of the last cell; TMVA::MsgLogger*TMVA::PDEFoam::fLogger! message logger; Int_t*TMVA::PDEFoam::fMaskDiv! [fDim] Dynamic Mask for cell division; UInt_tTMVA::PDEFoam::fMaxDepthmaximum depth of cell tree; Int_tTMVA::PDEFoam::fNBinNo. of bins in the edge histogram for cell MC exploration; Int_tTMVA::PDEFoam::fNCellsMaximum number of cells; UInt_tTMVA::PDEFoam::fNElementsBACKWARDS COMPATIBILITY: number of variables in every cell; Int_tTMVA::PDEFoam::fNSamplNo. of MC events, when dividing (exploring) cell; TStringTMVA::PDEFoam::fNameName of a given instance of the FOAM class; UInt_tTMVA::PDEFoam::fNminminimal number of events in cell to split cell; Int_tTMVA::PDEFoam::fNoActNumber of active cells; Bool_tTMVA::PDEFoam::fPeekMaxBACKWARDS COMPATIBILITY: peek up cell with max. driver integral for split; TRandom3*TMVA::PDEFoam::fPseRanPointer to user-defined generator of pseudorandom numbers; Double_t*TMVA::PDEFoam::fRvec[fDim] random number vector from r.n. generator fDim+1 m",MatchSource.WIKI,root/html532/TMVA__PDEFoamMultiTarget.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamMultiTarget.html
https://root.cern/root/html532/TMVA__PDEFoamTarget.html:450,Availability,error,error,450,". TMVA::PDEFoamTarget. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::PDEFoamTarget. class TMVA::PDEFoamTarget: public TMVA::PDEFoam. PDEFoamTarget. This PDEFoam variant stores in every cell the average target; fTarget (see the Constructor) as well as the statistical error on; the target fTarget. It therefore acts as a target estimator. It; should be booked together with the PDEFoamTargetDensity density; estimator, which returns the target fTarget density at a given; phase space point during the foam build-up. Function Members (Methods); public:. virtual~PDEFoamTarget(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::PDEFoam::AddVariableName(const char* s); voidTMVA::PDEFoam::AddVariableName(TObjString* s); virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidTMVA::PDEFoam::CheckAll(Int_t); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; voidTMVA::PDEFoam::Create(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::PDEFoam::DeleteBinarySearchTree(); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); TH1D*TMVA::PDEFoam::Draw1Dim(TMVA::ECellValue cell_value, Int_t nbin, TMVA::PDEFoamKernelBase* kernel = NULL); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error ",MatchSource.WIKI,root/html532/TMVA__PDEFoamTarget.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamTarget.html
https://root.cern/root/html532/TMVA__PDEFoamTarget.html:1995,Availability,error,error,1995,"e(TBrowser* b); voidTMVA::PDEFoam::CheckAll(Int_t); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; voidTMVA::PDEFoam::Create(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::PDEFoam::DeleteBinarySearchTree(); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); TH1D*TMVA::PDEFoam::Draw1Dim(TMVA::ECellValue cell_value, Int_t nbin, TMVA::PDEFoamKernelBase* kernel = NULL); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; voidTMVA::PDEFoam::FillBinarySearchTree(const TMVA::Event* ev); virtual voidFillFoamCells(const TMVA::Event* ev, Float_t wt); virtual voidFinalize(); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Float_tGetCellValue(const vector<Float_t>& xvec, TMVA::ECellValue cv, TMVA::PDEFoamKernelBase*); virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TStringTMVA::PDEFoam::GetFoamName() const; virtual const char*TObject::GetIconName() const; UInt_tTMVA::PDEFoam::GetMaxDepth() const; UInt_tTMVA::PDEFoam::GetNActiveCells() const; virtual const char*TObject::GetName() const; UInt_tTMVA::PDEFoam::GetNCells() const; UInt_tTMVA::PDEFoam::GetNInActiveCe",MatchSource.WIKI,root/html532/TMVA__PDEFoamTarget.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamTarget.html
https://root.cern/root/html532/TMVA__PDEFoamTarget.html:2079,Availability,error,error,2079,"onst char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; voidTMVA::PDEFoam::Create(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::PDEFoam::DeleteBinarySearchTree(); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); TH1D*TMVA::PDEFoam::Draw1Dim(TMVA::ECellValue cell_value, Int_t nbin, TMVA::PDEFoamKernelBase* kernel = NULL); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; voidTMVA::PDEFoam::FillBinarySearchTree(const TMVA::Event* ev); virtual voidFillFoamCells(const TMVA::Event* ev, Float_t wt); virtual voidFinalize(); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Float_tGetCellValue(const vector<Float_t>& xvec, TMVA::ECellValue cv, TMVA::PDEFoamKernelBase*); virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TStringTMVA::PDEFoam::GetFoamName() const; virtual const char*TObject::GetIconName() const; UInt_tTMVA::PDEFoam::GetMaxDepth() const; UInt_tTMVA::PDEFoam::GetNActiveCells() const; virtual const char*TObject::GetName() const; UInt_tTMVA::PDEFoam::GetNCells() const; UInt_tTMVA::PDEFoam::GetNInActiveCells() const; UInt_tTMVA::PDEFoam::GetNmin(); virtual char*TObject::GetObjectInfo(Int",MatchSource.WIKI,root/html532/TMVA__PDEFoamTarget.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamTarget.html
https://root.cern/root/html532/TMVA__PDEFoamTarget.html:12487,Availability,error,error,12487,"CKWARDS COMPATIBILITY: volume fraction (with respect to total phase space; Double_t*TMVA::PDEFoam::fXmax[fDim] maximum for variable transform; Double_t*TMVA::PDEFoam::fXmin[fDim] minimum for variable transform. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDEFoamTarget(); Default constructor for streamer, user should not use it. PDEFoamTarget(const TString& , UInt_t ); User constructor. Parameters:. - Name - name of PDEFoam object. - target - target number to range-search for. PDEFoamTarget(const TMVA::PDEFoamTarget& ); Copy Constructor NOT IMPLEMENTED (NEVER USED). void FillFoamCells(const TMVA::Event* ev, Float_t wt); This function fills an event into the discriminant PDEFoam. The; weight 'wt' is filled into cell element 0 if the event is of; class 'fTarget', and filled into cell element 1 otherwise. void Finalize(); Calculate average cell target in every cell and save them to the; cell. Cell element 0 will contain the average target and cell; element 1 will contain the error on the target. Bool_t CellValueIsUndefined(TMVA::PDEFoamCell* cell); Returns true, if the target error equals -1, as set in; Finalize() in case of no events in the cell. Float_t GetCellValue(const vector<Float_t>& xvec, TMVA::ECellValue cv, TMVA::PDEFoamKernelBase* ); This function finds the cell, which corresponds to the given; untransformed event vector 'xvec' and return its value, which is; given by the parameter 'cv'. If cv == kValue, it is checked wether the cell value is; undefined. If this is the case, then the mean of the neighbor's; target values is returned, using GetAverageNeighborsValue(). Float_t GetAverageNeighborsValue(vector<Float_t>& , TMVA::ECellValue ); This function returns the average value 'cv' of only nearest; neighbor cells. It is used in cases, where empty cells shall; not be evaluated. Parameters:; - txvec - event vector, transformed into foam coordinates [0, 1]; - cv - cell value, see definition of ECellValue. virtual ~PD",MatchSource.WIKI,root/html532/TMVA__PDEFoamTarget.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamTarget.html
https://root.cern/root/html532/TMVA__PDEFoamTarget.html:12590,Availability,error,error,12590,"e transform; Double_t*TMVA::PDEFoam::fXmin[fDim] minimum for variable transform. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDEFoamTarget(); Default constructor for streamer, user should not use it. PDEFoamTarget(const TString& , UInt_t ); User constructor. Parameters:. - Name - name of PDEFoam object. - target - target number to range-search for. PDEFoamTarget(const TMVA::PDEFoamTarget& ); Copy Constructor NOT IMPLEMENTED (NEVER USED). void FillFoamCells(const TMVA::Event* ev, Float_t wt); This function fills an event into the discriminant PDEFoam. The; weight 'wt' is filled into cell element 0 if the event is of; class 'fTarget', and filled into cell element 1 otherwise. void Finalize(); Calculate average cell target in every cell and save them to the; cell. Cell element 0 will contain the average target and cell; element 1 will contain the error on the target. Bool_t CellValueIsUndefined(TMVA::PDEFoamCell* cell); Returns true, if the target error equals -1, as set in; Finalize() in case of no events in the cell. Float_t GetCellValue(const vector<Float_t>& xvec, TMVA::ECellValue cv, TMVA::PDEFoamKernelBase* ); This function finds the cell, which corresponds to the given; untransformed event vector 'xvec' and return its value, which is; given by the parameter 'cv'. If cv == kValue, it is checked wether the cell value is; undefined. If this is the case, then the mean of the neighbor's; target values is returned, using GetAverageNeighborsValue(). Float_t GetAverageNeighborsValue(vector<Float_t>& , TMVA::ECellValue ); This function returns the average value 'cv' of only nearest; neighbor cells. It is used in cases, where empty cells shall; not be evaluated. Parameters:; - txvec - event vector, transformed into foam coordinates [0, 1]; - cv - cell value, see definition of ECellValue. virtual ~PDEFoamTarget(); {}. » Author: Tancredi Carli, Dominik Dannheim, Alexander Voigt » Copyright (c) 2008, 2010: *; » Last changed: root",MatchSource.WIKI,root/html532/TMVA__PDEFoamTarget.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamTarget.html
https://root.cern/root/html532/TMVA__PDEFoamTarget.html:9677,Deployability,integrat,integration,9677,"DEFoam::MakeAlpha(); voidTObject::MakeZombie(); voidTMVA::PDEFoam::OutputGrow(Bool_t finished = false); TMVA::PDEFoamTMVA::PDEFoam::PDEFoam(const TMVA::PDEFoam&); TMVA::PDEFoamTargetPDEFoamTarget(const TMVA::PDEFoamTarget&); Long_tTMVA::PDEFoam::PeekMax(); voidTMVA::PDEFoam::SetCellElement(TMVA::PDEFoamCell* cell, UInt_t i, Double_t value); voidTMVA::PDEFoam::Varedu(Double_t*, Int_t&, Double_t&, Double_t&). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. Double_t*TMVA::PDEFoam::fAlpha[fDim] Internal parameters of the hyperrectangle; TMVA::PDEFoamCell**TMVA::PDEFoam::fCells[fNCells] Array of ALL cells; TMVA::EDTSeparationTMVA::PDEFoam::fDTSeparationBACKWARDS COMPATIBILITY: split cells according to decision tree logic; Int_tTMVA::PDEFoam::fDimDimension of the integration/simulation space; TMVA::PDEFoamDensityBase*TMVA::PDEFoam::fDistr! distribution of training events; Int_tTMVA::PDEFoam::fEvPerBinMaximum number of effective (wt=1) events per bin; Bool_tTMVA::PDEFoam::fFillFoamWithOrigWeightsBACKWARDS COMPATIBILITY: fill the foam with boost or orig. weights; TMVA::EFoamTypeTMVA::PDEFoam::fFoamTypeBACKWARDS COMPATIBILITY: type of foam; TObjArray*TMVA::PDEFoam::fHistEdgHistograms of wt, one for each cell edge; Int_t*TMVA::PDEFoam::fInhiDiv! [fDim] Flags for inhibiting cell division; Int_tTMVA::PDEFoam::fLastCeIndex of the last cell; TMVA::MsgLogger*TMVA::PDEFoam::fLogger! message logger; Int_t*TMVA::PDEFoam::fMaskDiv! [fDim] Dynamic Mask for cell division; UInt_tTMVA::PDEFoam::fMaxDepthmaximum depth of cell tree; Int_tTMVA::PDEFoam::fNBinNo. of bins in the edge histogram for cell MC exploration; Int_tTMVA::PDEFoam::fNCellsMaximum number of cells; UInt_tTMVA::PDEFoam::fNElementsBACKWARDS COMPATIBILITY: number of variables in every cell;",MatchSource.WIKI,root/html532/TMVA__PDEFoamTarget.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamTarget.html
https://root.cern/root/html532/TMVA__PDEFoamTarget.html:9677,Integrability,integrat,integration,9677,"DEFoam::MakeAlpha(); voidTObject::MakeZombie(); voidTMVA::PDEFoam::OutputGrow(Bool_t finished = false); TMVA::PDEFoamTMVA::PDEFoam::PDEFoam(const TMVA::PDEFoam&); TMVA::PDEFoamTargetPDEFoamTarget(const TMVA::PDEFoamTarget&); Long_tTMVA::PDEFoam::PeekMax(); voidTMVA::PDEFoam::SetCellElement(TMVA::PDEFoamCell* cell, UInt_t i, Double_t value); voidTMVA::PDEFoam::Varedu(Double_t*, Int_t&, Double_t&, Double_t&). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. Double_t*TMVA::PDEFoam::fAlpha[fDim] Internal parameters of the hyperrectangle; TMVA::PDEFoamCell**TMVA::PDEFoam::fCells[fNCells] Array of ALL cells; TMVA::EDTSeparationTMVA::PDEFoam::fDTSeparationBACKWARDS COMPATIBILITY: split cells according to decision tree logic; Int_tTMVA::PDEFoam::fDimDimension of the integration/simulation space; TMVA::PDEFoamDensityBase*TMVA::PDEFoam::fDistr! distribution of training events; Int_tTMVA::PDEFoam::fEvPerBinMaximum number of effective (wt=1) events per bin; Bool_tTMVA::PDEFoam::fFillFoamWithOrigWeightsBACKWARDS COMPATIBILITY: fill the foam with boost or orig. weights; TMVA::EFoamTypeTMVA::PDEFoam::fFoamTypeBACKWARDS COMPATIBILITY: type of foam; TObjArray*TMVA::PDEFoam::fHistEdgHistograms of wt, one for each cell edge; Int_t*TMVA::PDEFoam::fInhiDiv! [fDim] Flags for inhibiting cell division; Int_tTMVA::PDEFoam::fLastCeIndex of the last cell; TMVA::MsgLogger*TMVA::PDEFoam::fLogger! message logger; Int_t*TMVA::PDEFoam::fMaskDiv! [fDim] Dynamic Mask for cell division; UInt_tTMVA::PDEFoam::fMaxDepthmaximum depth of cell tree; Int_tTMVA::PDEFoam::fNBinNo. of bins in the edge histogram for cell MC exploration; Int_tTMVA::PDEFoam::fNCellsMaximum number of cells; UInt_tTMVA::PDEFoam::fNElementsBACKWARDS COMPATIBILITY: number of variables in every cell;",MatchSource.WIKI,root/html532/TMVA__PDEFoamTarget.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamTarget.html
https://root.cern/root/html532/TMVA__PDEFoamTarget.html:10299,Integrability,message,message,10299,"nu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. Double_t*TMVA::PDEFoam::fAlpha[fDim] Internal parameters of the hyperrectangle; TMVA::PDEFoamCell**TMVA::PDEFoam::fCells[fNCells] Array of ALL cells; TMVA::EDTSeparationTMVA::PDEFoam::fDTSeparationBACKWARDS COMPATIBILITY: split cells according to decision tree logic; Int_tTMVA::PDEFoam::fDimDimension of the integration/simulation space; TMVA::PDEFoamDensityBase*TMVA::PDEFoam::fDistr! distribution of training events; Int_tTMVA::PDEFoam::fEvPerBinMaximum number of effective (wt=1) events per bin; Bool_tTMVA::PDEFoam::fFillFoamWithOrigWeightsBACKWARDS COMPATIBILITY: fill the foam with boost or orig. weights; TMVA::EFoamTypeTMVA::PDEFoam::fFoamTypeBACKWARDS COMPATIBILITY: type of foam; TObjArray*TMVA::PDEFoam::fHistEdgHistograms of wt, one for each cell edge; Int_t*TMVA::PDEFoam::fInhiDiv! [fDim] Flags for inhibiting cell division; Int_tTMVA::PDEFoam::fLastCeIndex of the last cell; TMVA::MsgLogger*TMVA::PDEFoam::fLogger! message logger; Int_t*TMVA::PDEFoam::fMaskDiv! [fDim] Dynamic Mask for cell division; UInt_tTMVA::PDEFoam::fMaxDepthmaximum depth of cell tree; Int_tTMVA::PDEFoam::fNBinNo. of bins in the edge histogram for cell MC exploration; Int_tTMVA::PDEFoam::fNCellsMaximum number of cells; UInt_tTMVA::PDEFoam::fNElementsBACKWARDS COMPATIBILITY: number of variables in every cell; Int_tTMVA::PDEFoam::fNSamplNo. of MC events, when dividing (exploring) cell; TStringTMVA::PDEFoam::fNameName of a given instance of the FOAM class; UInt_tTMVA::PDEFoam::fNminminimal number of events in cell to split cell; Int_tTMVA::PDEFoam::fNoActNumber of active cells; Bool_tTMVA::PDEFoam::fPeekMaxBACKWARDS COMPATIBILITY: peek up cell with max. driver integral for split; TRandom3*TMVA::PDEFoam::fPseRanPointer to user-defined generator of pseudorandom numbers; Double_t*TMVA::PDEFoam::fRvec[fDim] random number vector from r.n. generator fDim+1 m",MatchSource.WIKI,root/html532/TMVA__PDEFoamTarget.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamTarget.html
https://root.cern/root/html532/TMVA__PDEFoamTarget.html:10645,Modifiability,variab,variables,10645,"ITY: split cells according to decision tree logic; Int_tTMVA::PDEFoam::fDimDimension of the integration/simulation space; TMVA::PDEFoamDensityBase*TMVA::PDEFoam::fDistr! distribution of training events; Int_tTMVA::PDEFoam::fEvPerBinMaximum number of effective (wt=1) events per bin; Bool_tTMVA::PDEFoam::fFillFoamWithOrigWeightsBACKWARDS COMPATIBILITY: fill the foam with boost or orig. weights; TMVA::EFoamTypeTMVA::PDEFoam::fFoamTypeBACKWARDS COMPATIBILITY: type of foam; TObjArray*TMVA::PDEFoam::fHistEdgHistograms of wt, one for each cell edge; Int_t*TMVA::PDEFoam::fInhiDiv! [fDim] Flags for inhibiting cell division; Int_tTMVA::PDEFoam::fLastCeIndex of the last cell; TMVA::MsgLogger*TMVA::PDEFoam::fLogger! message logger; Int_t*TMVA::PDEFoam::fMaskDiv! [fDim] Dynamic Mask for cell division; UInt_tTMVA::PDEFoam::fMaxDepthmaximum depth of cell tree; Int_tTMVA::PDEFoam::fNBinNo. of bins in the edge histogram for cell MC exploration; Int_tTMVA::PDEFoam::fNCellsMaximum number of cells; UInt_tTMVA::PDEFoam::fNElementsBACKWARDS COMPATIBILITY: number of variables in every cell; Int_tTMVA::PDEFoam::fNSamplNo. of MC events, when dividing (exploring) cell; TStringTMVA::PDEFoam::fNameName of a given instance of the FOAM class; UInt_tTMVA::PDEFoam::fNminminimal number of events in cell to split cell; Int_tTMVA::PDEFoam::fNoActNumber of active cells; Bool_tTMVA::PDEFoam::fPeekMaxBACKWARDS COMPATIBILITY: peek up cell with max. driver integral for split; TRandom3*TMVA::PDEFoam::fPseRanPointer to user-defined generator of pseudorandom numbers; Double_t*TMVA::PDEFoam::fRvec[fDim] random number vector from r.n. generator fDim+1 maximum elements; UInt_tfTargetthe target to fill the cells with; TMVA::Timer*TMVA::PDEFoam::fTimer! timer for graphical output; TObjArray*TMVA::PDEFoam::fVariableNamescollection of all variable names; Float_tTMVA::PDEFoam::fVolFracBACKWARDS COMPATIBILITY: volume fraction (with respect to total phase space; Double_t*TMVA::PDEFoam::fXmax[fDim] maximum for variable ",MatchSource.WIKI,root/html532/TMVA__PDEFoamTarget.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamTarget.html
https://root.cern/root/html532/TMVA__PDEFoamTarget.html:11406,Modifiability,variab,variable,11406,"ell tree; Int_tTMVA::PDEFoam::fNBinNo. of bins in the edge histogram for cell MC exploration; Int_tTMVA::PDEFoam::fNCellsMaximum number of cells; UInt_tTMVA::PDEFoam::fNElementsBACKWARDS COMPATIBILITY: number of variables in every cell; Int_tTMVA::PDEFoam::fNSamplNo. of MC events, when dividing (exploring) cell; TStringTMVA::PDEFoam::fNameName of a given instance of the FOAM class; UInt_tTMVA::PDEFoam::fNminminimal number of events in cell to split cell; Int_tTMVA::PDEFoam::fNoActNumber of active cells; Bool_tTMVA::PDEFoam::fPeekMaxBACKWARDS COMPATIBILITY: peek up cell with max. driver integral for split; TRandom3*TMVA::PDEFoam::fPseRanPointer to user-defined generator of pseudorandom numbers; Double_t*TMVA::PDEFoam::fRvec[fDim] random number vector from r.n. generator fDim+1 maximum elements; UInt_tfTargetthe target to fill the cells with; TMVA::Timer*TMVA::PDEFoam::fTimer! timer for graphical output; TObjArray*TMVA::PDEFoam::fVariableNamescollection of all variable names; Float_tTMVA::PDEFoam::fVolFracBACKWARDS COMPATIBILITY: volume fraction (with respect to total phase space; Double_t*TMVA::PDEFoam::fXmax[fDim] maximum for variable transform; Double_t*TMVA::PDEFoam::fXmin[fDim] minimum for variable transform. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDEFoamTarget(); Default constructor for streamer, user should not use it. PDEFoamTarget(const TString& , UInt_t ); User constructor. Parameters:. - Name - name of PDEFoam object. - target - target number to range-search for. PDEFoamTarget(const TMVA::PDEFoamTarget& ); Copy Constructor NOT IMPLEMENTED (NEVER USED). void FillFoamCells(const TMVA::Event* ev, Float_t wt); This function fills an event into the discriminant PDEFoam. The; weight 'wt' is filled into cell element 0 if the event is of; class 'fTarget', and filled into cell element 1 otherwise. void Finalize(); Calculate average cell target in every cell and save them to the; cell. Cell element 0 will contain th",MatchSource.WIKI,root/html532/TMVA__PDEFoamTarget.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamTarget.html
https://root.cern/root/html532/TMVA__PDEFoamTarget.html:11577,Modifiability,variab,variable,11577,"ell tree; Int_tTMVA::PDEFoam::fNBinNo. of bins in the edge histogram for cell MC exploration; Int_tTMVA::PDEFoam::fNCellsMaximum number of cells; UInt_tTMVA::PDEFoam::fNElementsBACKWARDS COMPATIBILITY: number of variables in every cell; Int_tTMVA::PDEFoam::fNSamplNo. of MC events, when dividing (exploring) cell; TStringTMVA::PDEFoam::fNameName of a given instance of the FOAM class; UInt_tTMVA::PDEFoam::fNminminimal number of events in cell to split cell; Int_tTMVA::PDEFoam::fNoActNumber of active cells; Bool_tTMVA::PDEFoam::fPeekMaxBACKWARDS COMPATIBILITY: peek up cell with max. driver integral for split; TRandom3*TMVA::PDEFoam::fPseRanPointer to user-defined generator of pseudorandom numbers; Double_t*TMVA::PDEFoam::fRvec[fDim] random number vector from r.n. generator fDim+1 maximum elements; UInt_tfTargetthe target to fill the cells with; TMVA::Timer*TMVA::PDEFoam::fTimer! timer for graphical output; TObjArray*TMVA::PDEFoam::fVariableNamescollection of all variable names; Float_tTMVA::PDEFoam::fVolFracBACKWARDS COMPATIBILITY: volume fraction (with respect to total phase space; Double_t*TMVA::PDEFoam::fXmax[fDim] maximum for variable transform; Double_t*TMVA::PDEFoam::fXmin[fDim] minimum for variable transform. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDEFoamTarget(); Default constructor for streamer, user should not use it. PDEFoamTarget(const TString& , UInt_t ); User constructor. Parameters:. - Name - name of PDEFoam object. - target - target number to range-search for. PDEFoamTarget(const TMVA::PDEFoamTarget& ); Copy Constructor NOT IMPLEMENTED (NEVER USED). void FillFoamCells(const TMVA::Event* ev, Float_t wt); This function fills an event into the discriminant PDEFoam. The; weight 'wt' is filled into cell element 0 if the event is of; class 'fTarget', and filled into cell element 1 otherwise. void Finalize(); Calculate average cell target in every cell and save them to the; cell. Cell element 0 will contain th",MatchSource.WIKI,root/html532/TMVA__PDEFoamTarget.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamTarget.html
https://root.cern/root/html532/TMVA__PDEFoamTarget.html:11645,Modifiability,variab,variable,11645,"ell tree; Int_tTMVA::PDEFoam::fNBinNo. of bins in the edge histogram for cell MC exploration; Int_tTMVA::PDEFoam::fNCellsMaximum number of cells; UInt_tTMVA::PDEFoam::fNElementsBACKWARDS COMPATIBILITY: number of variables in every cell; Int_tTMVA::PDEFoam::fNSamplNo. of MC events, when dividing (exploring) cell; TStringTMVA::PDEFoam::fNameName of a given instance of the FOAM class; UInt_tTMVA::PDEFoam::fNminminimal number of events in cell to split cell; Int_tTMVA::PDEFoam::fNoActNumber of active cells; Bool_tTMVA::PDEFoam::fPeekMaxBACKWARDS COMPATIBILITY: peek up cell with max. driver integral for split; TRandom3*TMVA::PDEFoam::fPseRanPointer to user-defined generator of pseudorandom numbers; Double_t*TMVA::PDEFoam::fRvec[fDim] random number vector from r.n. generator fDim+1 maximum elements; UInt_tfTargetthe target to fill the cells with; TMVA::Timer*TMVA::PDEFoam::fTimer! timer for graphical output; TObjArray*TMVA::PDEFoam::fVariableNamescollection of all variable names; Float_tTMVA::PDEFoam::fVolFracBACKWARDS COMPATIBILITY: volume fraction (with respect to total phase space; Double_t*TMVA::PDEFoam::fXmax[fDim] maximum for variable transform; Double_t*TMVA::PDEFoam::fXmin[fDim] minimum for variable transform. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDEFoamTarget(); Default constructor for streamer, user should not use it. PDEFoamTarget(const TString& , UInt_t ); User constructor. Parameters:. - Name - name of PDEFoam object. - target - target number to range-search for. PDEFoamTarget(const TMVA::PDEFoamTarget& ); Copy Constructor NOT IMPLEMENTED (NEVER USED). void FillFoamCells(const TMVA::Event* ev, Float_t wt); This function fills an event into the discriminant PDEFoam. The; weight 'wt' is filled into cell element 0 if the event is of; class 'fTarget', and filled into cell element 1 otherwise. void Finalize(); Calculate average cell target in every cell and save them to the; cell. Cell element 0 will contain th",MatchSource.WIKI,root/html532/TMVA__PDEFoamTarget.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamTarget.html
https://root.cern/root/html532/TMVA__PDEFoamTarget.html:9629,Testability,log,logic,9629,"DEFoam::MakeAlpha(); voidTObject::MakeZombie(); voidTMVA::PDEFoam::OutputGrow(Bool_t finished = false); TMVA::PDEFoamTMVA::PDEFoam::PDEFoam(const TMVA::PDEFoam&); TMVA::PDEFoamTargetPDEFoamTarget(const TMVA::PDEFoamTarget&); Long_tTMVA::PDEFoam::PeekMax(); voidTMVA::PDEFoam::SetCellElement(TMVA::PDEFoamCell* cell, UInt_t i, Double_t value); voidTMVA::PDEFoam::Varedu(Double_t*, Int_t&, Double_t&, Double_t&). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. Double_t*TMVA::PDEFoam::fAlpha[fDim] Internal parameters of the hyperrectangle; TMVA::PDEFoamCell**TMVA::PDEFoam::fCells[fNCells] Array of ALL cells; TMVA::EDTSeparationTMVA::PDEFoam::fDTSeparationBACKWARDS COMPATIBILITY: split cells according to decision tree logic; Int_tTMVA::PDEFoam::fDimDimension of the integration/simulation space; TMVA::PDEFoamDensityBase*TMVA::PDEFoam::fDistr! distribution of training events; Int_tTMVA::PDEFoam::fEvPerBinMaximum number of effective (wt=1) events per bin; Bool_tTMVA::PDEFoam::fFillFoamWithOrigWeightsBACKWARDS COMPATIBILITY: fill the foam with boost or orig. weights; TMVA::EFoamTypeTMVA::PDEFoam::fFoamTypeBACKWARDS COMPATIBILITY: type of foam; TObjArray*TMVA::PDEFoam::fHistEdgHistograms of wt, one for each cell edge; Int_t*TMVA::PDEFoam::fInhiDiv! [fDim] Flags for inhibiting cell division; Int_tTMVA::PDEFoam::fLastCeIndex of the last cell; TMVA::MsgLogger*TMVA::PDEFoam::fLogger! message logger; Int_t*TMVA::PDEFoam::fMaskDiv! [fDim] Dynamic Mask for cell division; UInt_tTMVA::PDEFoam::fMaxDepthmaximum depth of cell tree; Int_tTMVA::PDEFoam::fNBinNo. of bins in the edge histogram for cell MC exploration; Int_tTMVA::PDEFoam::fNCellsMaximum number of cells; UInt_tTMVA::PDEFoam::fNElementsBACKWARDS COMPATIBILITY: number of variables in every cell;",MatchSource.WIKI,root/html532/TMVA__PDEFoamTarget.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamTarget.html
https://root.cern/root/html532/TMVA__PDEFoamTarget.html:10307,Testability,log,logger,10307,"nu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. Double_t*TMVA::PDEFoam::fAlpha[fDim] Internal parameters of the hyperrectangle; TMVA::PDEFoamCell**TMVA::PDEFoam::fCells[fNCells] Array of ALL cells; TMVA::EDTSeparationTMVA::PDEFoam::fDTSeparationBACKWARDS COMPATIBILITY: split cells according to decision tree logic; Int_tTMVA::PDEFoam::fDimDimension of the integration/simulation space; TMVA::PDEFoamDensityBase*TMVA::PDEFoam::fDistr! distribution of training events; Int_tTMVA::PDEFoam::fEvPerBinMaximum number of effective (wt=1) events per bin; Bool_tTMVA::PDEFoam::fFillFoamWithOrigWeightsBACKWARDS COMPATIBILITY: fill the foam with boost or orig. weights; TMVA::EFoamTypeTMVA::PDEFoam::fFoamTypeBACKWARDS COMPATIBILITY: type of foam; TObjArray*TMVA::PDEFoam::fHistEdgHistograms of wt, one for each cell edge; Int_t*TMVA::PDEFoam::fInhiDiv! [fDim] Flags for inhibiting cell division; Int_tTMVA::PDEFoam::fLastCeIndex of the last cell; TMVA::MsgLogger*TMVA::PDEFoam::fLogger! message logger; Int_t*TMVA::PDEFoam::fMaskDiv! [fDim] Dynamic Mask for cell division; UInt_tTMVA::PDEFoam::fMaxDepthmaximum depth of cell tree; Int_tTMVA::PDEFoam::fNBinNo. of bins in the edge histogram for cell MC exploration; Int_tTMVA::PDEFoam::fNCellsMaximum number of cells; UInt_tTMVA::PDEFoam::fNElementsBACKWARDS COMPATIBILITY: number of variables in every cell; Int_tTMVA::PDEFoam::fNSamplNo. of MC events, when dividing (exploring) cell; TStringTMVA::PDEFoam::fNameName of a given instance of the FOAM class; UInt_tTMVA::PDEFoam::fNminminimal number of events in cell to split cell; Int_tTMVA::PDEFoam::fNoActNumber of active cells; Bool_tTMVA::PDEFoam::fPeekMaxBACKWARDS COMPATIBILITY: peek up cell with max. driver integral for split; TRandom3*TMVA::PDEFoam::fPseRanPointer to user-defined generator of pseudorandom numbers; Double_t*TMVA::PDEFoam::fRvec[fDim] random number vector from r.n. generator fDim+1 m",MatchSource.WIKI,root/html532/TMVA__PDEFoamTarget.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamTarget.html
https://root.cern/root/html532/TMVA__PDEFoamTargetDensity.html:1592,Availability,error,error,1592,"Density(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Double_tDensity(vector<Double_t>& Xarg, Double_t& event_density); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; voidTMVA::PDEFoamDensityBase::FillBinarySearchTree(const TMVA::Event* ev); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const vector<Double_t>&TMVA::PDEFoamDensityBase::GetBox() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() co",MatchSource.WIKI,root/html532/TMVA__PDEFoamTargetDensity.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamTargetDensity.html
https://root.cern/root/html532/TMVA__PDEFoamTargetDensity.html:1676,Availability,error,error,1676,"t::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Double_tDensity(vector<Double_t>& Xarg, Double_t& event_density); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; voidTMVA::PDEFoamDensityBase::FillBinarySearchTree(const TMVA::Event* ev); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const vector<Double_t>&TMVA::PDEFoamDensityBase::GetBox() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtua",MatchSource.WIKI,root/html532/TMVA__PDEFoamTargetDensity.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamTargetDensity.html
https://root.cern/root/html532/TMVA__PDEFoamTargetDensity.html:6053,Integrability,message,message,6053,"estBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; Double_tTMVA::PDEFoamDensityBase::GetBoxVolume(); TMVA::MsgLogger&TMVA::PDEFoamDensityBase::Log() const; voidTObject::MakeZombie(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TMVA::BinarySearchTree*TMVA::PDEFoamDensityBase::fBstBinary tree to find events within a volume; TMVA::MsgLogger*TMVA::PDEFoamDensityBase::fLogger! message logger; UInt_tfTargetthe target to calculate the density for. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDEFoamTargetDensity(); {}. PDEFoamTargetDensity(vector<Double_t> box, UInt_t target); User construcor. Parameters:. - box - size of the range-searching box (n-dimensional; std::vector). - target - the target number to calculate the density for. PDEFoamTargetDensity(const TMVA::PDEFoamTargetDensity& ); Copy constructor. Double_t Density(vector<Double_t>& Xarg, Double_t& event_density); This function is needed during the foam buildup. It returns the; average target value within the range-searching box at point; Xarg, divided by volume (specified by fBox). Parameters:. - Xarg - event vector (in [fXmin,fXmax]) to place the box at. - event_density - here the event density is stored. Returns:. Average target value in the range-searching volume at point; 'Xarg', divided by the box volume. virtu",MatchSource.WIKI,root/html532/TMVA__PDEFoamTargetDensity.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamTargetDensity.html
https://root.cern/root/html532/TMVA__PDEFoamTargetDensity.html:6061,Testability,log,logger,6061,"estBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; Double_tTMVA::PDEFoamDensityBase::GetBoxVolume(); TMVA::MsgLogger&TMVA::PDEFoamDensityBase::Log() const; voidTObject::MakeZombie(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TMVA::BinarySearchTree*TMVA::PDEFoamDensityBase::fBstBinary tree to find events within a volume; TMVA::MsgLogger*TMVA::PDEFoamDensityBase::fLogger! message logger; UInt_tfTargetthe target to calculate the density for. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDEFoamTargetDensity(); {}. PDEFoamTargetDensity(vector<Double_t> box, UInt_t target); User construcor. Parameters:. - box - size of the range-searching box (n-dimensional; std::vector). - target - the target number to calculate the density for. PDEFoamTargetDensity(const TMVA::PDEFoamTargetDensity& ); Copy constructor. Double_t Density(vector<Double_t>& Xarg, Double_t& event_density); This function is needed during the foam buildup. It returns the; average target value within the range-searching box at point; Xarg, divided by volume (specified by fBox). Parameters:. - Xarg - event vector (in [fXmin,fXmax]) to place the box at. - event_density - here the event density is stored. Returns:. Average target value in the range-searching volume at point; 'Xarg', divided by the box volume. virtu",MatchSource.WIKI,root/html532/TMVA__PDEFoamTargetDensity.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamTargetDensity.html
https://root.cern/root/html532/TMVA__PDEFoamVect.html:1276,Availability,error,error,1276," virtual~PDEFoamVect(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; Double_tGetCoord(Int_t i) const; Int_tGetDim() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::G",MatchSource.WIKI,root/html532/TMVA__PDEFoamVect.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamVect.html
https://root.cern/root/html532/TMVA__PDEFoamVect.html:1360,Availability,error,error,1360," voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; Double_tGetCoord(Int_t i) const; Int_tGetDim() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::Inh",MatchSource.WIKI,root/html532/TMVA__PDEFoamVect.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamVect.html
https://root.cern/root/html532/TMVA__PDEFoamVect.html:6025,Security,access,access,6025,"e = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTObject::MakeZombie(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. Double_t*fCoords[fDim] Coordinates; Int_tfDimDimension. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDEFoamVect(); Default constructor for streamer. PDEFoamVect(Int_t ); User constructor creating n-dimensional vector; and allocating dynamically array of components. PDEFoamVect(const TMVA::PDEFoamVect& ); Copy constructor. ~PDEFoamVect(); Destructor. Double_t & operator[](Int_t ); [] is for access to elements as in ordinary matrix like a[j]=b[j]; (Perhaps against some strict rules but rather practical.); Range protection is built in, consequently for substitution; one should use rather use a=b than explicit loop!. TMVA::PDEFoamVect& operator*=(const Double_t& ); unary multiplication operator *=. TMVA::PDEFoamVect& operator+=(const TMVA::PDEFoamVect& ); unary addition operator +=; adding vector c*=x,. TMVA::PDEFoamVect& operator-=(const TMVA::PDEFoamVect& ); unary subtraction operator -=. TMVA::PDEFoamVect operator+(const TMVA::PDEFoamVect& ); addition operator +; sum of 2 vectors: c=a+b, a=a+b,; NEVER USE IT, VERY SLOW!!!. TMVA::PDEFoamVect operator-(const TMVA::PDEFoamVect& ); subtraction operator -; difference of 2 vectors; c=a-b, a=a-b,; NEVER USE IT, VERY SLOW!!!. void Print(Option_t* option) const; Printout of all vector components. Int_t GetDim() const; { return fDim; }. Double_t GetCoord(Int_t i) const; { return fCoords[i]; }. » Author: S. Jadach, Tancredi Carli, Dominik Dannheim, Alexander Voigt » C",MatchSource.WIKI,root/html532/TMVA__PDEFoamVect.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDEFoamVect.html
https://root.cern/root/html532/TMVA__PDF.html:1538,Availability,error,error,1538," virtual voidTObject::Browse(TBrowser* b); voidBuildPDF(const TH1* theHist); voidTMVA::Configurable::CheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; voidDeclareOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); Int_tGetHistNBins(Int_t evtNum = 0); virtual const char*TObject::GetIconName() const; Double_tGetIntegral(Double_t xmin, Double_t xmax); TMVA::PDF::EInterpolateMethodGetInterpolMethod(); virtual const char*GetName() const; Int_tGetNBins() const; TH1*GetNSmoothHist() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&TMVA:",MatchSource.WIKI,root/html532/TMVA__PDF.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDF.html
https://root.cern/root/html532/TMVA__PDF.html:1622,Availability,error,error,1622,"A::Configurable::CheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; voidDeclareOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); Int_tGetHistNBins(Int_t evtNum = 0); virtual const char*TObject::GetIconName() const; Double_tGetIntegral(Double_t xmin, Double_t xmax); TMVA::PDF::EInterpolateMethodGetInterpolMethod(); virtual const char*GetName() const; Int_tGetNBins() const; TH1*GetNSmoothHist() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&TMVA::Configurable::GetOptions() const; TH1*GetOriginalHist() const; TH1*GetPDFHist() con",MatchSource.WIKI,root/html532/TMVA__PDF.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDF.html
https://root.cern/root/html532/TMVA__PDF.html:9627,Deployability,integrat,integration,9627,"k; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. TStringfBorderMethodString; Bool_tfCheckHistcheck of source histogram; Float_tfFineFactorfine tuning factor for Adaptive KDE; TGraph*fGraph! needed to create PDF from histogram; TH1*fHistcopy of input histogram; Int_tfHistAvgEvtPerBinavg event per source hist bin; Int_tfHistDefinedNBinssource hist bin num set by user; TH1*fHistOriginalthe input histogram; TF1*fIGetValintegration interface; TMVA::PDF::EInterpolateMethodfInterpolMethodinterpolation method; TStringfInterpolateString; TMVA::KDEKernel::EKernelBorderfKDEborderThe method to take care about ""border"" effects (string); TMVA::KDEKernel::EKernelIterfKDEiterNumber of iterations (adaptive or not); TStringfKDEiterString; TMVA::KDEKernel::EKernelTypefKDEtypeKernel type to use for KDE; TStringfKDEtypeStringstrings used to read definitions; TMVA::MsgLogger*fLogger! message logger; Int_tfMaxNsmoothMax number of smoothing iterations; Int_tfMinNsmoothMin number of smoothing iterations; TH1*fNSmoothHistnumber of smooth for each bin; Bool_tfNormalizenormalize histogram (false for cumulative distribution used in GaussTranform); Int_tfNsmoothMin number of smoothing iterations; TH1*fPDFHistthe high-binned histogram corresponding to the PDF; TStringfPDFNamefor output; UInt_tfReadingVersionthe TMVA version of the weight file; TSpline*fSpline! the used spline type; TStringfSuffix! the suffix for options; Bool_tfUseHistogramspline0 uses histogram as reference; static const Double_tfgEpsilonminimum PDF return; static const Bool_tfgManualIntegrationmanual integration (sum over bins) or DGAUSS; static const Int_tfgNbin_PdfHistnumber of bins in high-binned reference histogram; static TMVA::PDF*fgThisPDFthis PDF pointer . Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDF(const TString& name, Bool_t norm = kTRUE); default constructor ",MatchSource.WIKI,root/html532/TMVA__PDF.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDF.html
https://root.cern/root/html532/TMVA__PDF.html:8752,Energy Efficiency,adapt,adaptive,8752,"k; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. TStringfBorderMethodString; Bool_tfCheckHistcheck of source histogram; Float_tfFineFactorfine tuning factor for Adaptive KDE; TGraph*fGraph! needed to create PDF from histogram; TH1*fHistcopy of input histogram; Int_tfHistAvgEvtPerBinavg event per source hist bin; Int_tfHistDefinedNBinssource hist bin num set by user; TH1*fHistOriginalthe input histogram; TF1*fIGetValintegration interface; TMVA::PDF::EInterpolateMethodfInterpolMethodinterpolation method; TStringfInterpolateString; TMVA::KDEKernel::EKernelBorderfKDEborderThe method to take care about ""border"" effects (string); TMVA::KDEKernel::EKernelIterfKDEiterNumber of iterations (adaptive or not); TStringfKDEiterString; TMVA::KDEKernel::EKernelTypefKDEtypeKernel type to use for KDE; TStringfKDEtypeStringstrings used to read definitions; TMVA::MsgLogger*fLogger! message logger; Int_tfMaxNsmoothMax number of smoothing iterations; Int_tfMinNsmoothMin number of smoothing iterations; TH1*fNSmoothHistnumber of smooth for each bin; Bool_tfNormalizenormalize histogram (false for cumulative distribution used in GaussTranform); Int_tfNsmoothMin number of smoothing iterations; TH1*fPDFHistthe high-binned histogram corresponding to the PDF; TStringfPDFNamefor output; UInt_tfReadingVersionthe TMVA version of the weight file; TSpline*fSpline! the used spline type; TStringfSuffix! the suffix for options; Bool_tfUseHistogramspline0 uses histogram as reference; static const Double_tfgEpsilonminimum PDF return; static const Bool_tfgManualIntegrationmanual integration (sum over bins) or DGAUSS; static const Int_tfgNbin_PdfHistnumber of bins in high-binned reference histogram; static TMVA::PDF*fgThisPDFthis PDF pointer . Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDF(const TString& name, Bool_t norm = kTRUE); default constructor ",MatchSource.WIKI,root/html532/TMVA__PDF.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDF.html
https://root.cern/root/html532/TMVA__PDF.html:12642,Energy Efficiency,adapt,adaptive,12642,"e PDF(x). Double_t GetValInverse(Double_t y, Bool_t isMonotonouslyIncreasingFunction = kFALSE) const; returns value PDF^{-1}(y). void FindBinInverse(const TH1* histogram, Int_t& lowerBin, Int_t& higherBin, Double_t& lowerBinValue, Double_t& higherBinValue, Double_t y, Bool_t isMonotonouslyIncreasingFunction = kFALSE) const; find bin from value on ordinate. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options:; PDFInterpol[ivar] <string> Spline0, Spline1, Spline2 <default>, Spline3, Spline5, KDE used to interpolate reference histograms; if no variable index is given, it is valid for ALL the variables. NSmooth <int> how often the input histos are smoothed; MinNSmooth <int> min number of smoothing iterations, for bins with most data; MaxNSmooth <int> max number of smoothing iterations, for bins with least data; NAvEvtPerBin <int> minimum average number of events per PDF bin; TransformOutput <bool> transform (often strongly peaked) likelihood output through sigmoid inversion; fKDEtype <KernelType> type of the Kernel to use (1 is Gaussian); fKDEiter <KerneIter> number of iterations (1 --> ""static KDE"", 2 --> ""adaptive KDE""); fBorderMethod <KernelBorder> the method to take care about ""border"" effects (1=no treatment , 2=kernel renormalization, 3=sample mirroring). void ProcessOptions(). void AddXMLTo(void* parent); XML file writing. void ReadXML(void* pdfnode); XML file reading. TMVA::PDF* ThisPDF( void ); return global ""this"" pointer of PDF. TH1* GetPDFHist() const; histogram underlying the PDF. { return fPDFHist; }. TH1* GetOriginalHist() const; { return fHistOriginal; }. TH1* GetSmoothedHist() const; { return fHist; }. TH1* GetNSmoothHist() const; { return fNSmoothHist; }. TSpline* GetSpline() const; accessors. { return fSpline; }. Int_t GetNBins() const; { return fHist->GetNbinsX(); }. Double_t GetXmin() const; { return fHist->GetXaxis()->GetXmin(); }. Double_t GetXmax() const; { return fHist->GetXaxis()->GetXma",MatchSource.WIKI,root/html532/TMVA__PDF.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDF.html
https://root.cern/root/html532/TMVA__PDF.html:8493,Integrability,interface,interface,8493,"k; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. TStringfBorderMethodString; Bool_tfCheckHistcheck of source histogram; Float_tfFineFactorfine tuning factor for Adaptive KDE; TGraph*fGraph! needed to create PDF from histogram; TH1*fHistcopy of input histogram; Int_tfHistAvgEvtPerBinavg event per source hist bin; Int_tfHistDefinedNBinssource hist bin num set by user; TH1*fHistOriginalthe input histogram; TF1*fIGetValintegration interface; TMVA::PDF::EInterpolateMethodfInterpolMethodinterpolation method; TStringfInterpolateString; TMVA::KDEKernel::EKernelBorderfKDEborderThe method to take care about ""border"" effects (string); TMVA::KDEKernel::EKernelIterfKDEiterNumber of iterations (adaptive or not); TStringfKDEiterString; TMVA::KDEKernel::EKernelTypefKDEtypeKernel type to use for KDE; TStringfKDEtypeStringstrings used to read definitions; TMVA::MsgLogger*fLogger! message logger; Int_tfMaxNsmoothMax number of smoothing iterations; Int_tfMinNsmoothMin number of smoothing iterations; TH1*fNSmoothHistnumber of smooth for each bin; Bool_tfNormalizenormalize histogram (false for cumulative distribution used in GaussTranform); Int_tfNsmoothMin number of smoothing iterations; TH1*fPDFHistthe high-binned histogram corresponding to the PDF; TStringfPDFNamefor output; UInt_tfReadingVersionthe TMVA version of the weight file; TSpline*fSpline! the used spline type; TStringfSuffix! the suffix for options; Bool_tfUseHistogramspline0 uses histogram as reference; static const Double_tfgEpsilonminimum PDF return; static const Bool_tfgManualIntegrationmanual integration (sum over bins) or DGAUSS; static const Int_tfgNbin_PdfHistnumber of bins in high-binned reference histogram; static TMVA::PDF*fgThisPDFthis PDF pointer . Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDF(const TString& name, Bool_t norm = kTRUE); default constructor ",MatchSource.WIKI,root/html532/TMVA__PDF.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDF.html
https://root.cern/root/html532/TMVA__PDF.html:8937,Integrability,message,message,8937,"k; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. TStringfBorderMethodString; Bool_tfCheckHistcheck of source histogram; Float_tfFineFactorfine tuning factor for Adaptive KDE; TGraph*fGraph! needed to create PDF from histogram; TH1*fHistcopy of input histogram; Int_tfHistAvgEvtPerBinavg event per source hist bin; Int_tfHistDefinedNBinssource hist bin num set by user; TH1*fHistOriginalthe input histogram; TF1*fIGetValintegration interface; TMVA::PDF::EInterpolateMethodfInterpolMethodinterpolation method; TStringfInterpolateString; TMVA::KDEKernel::EKernelBorderfKDEborderThe method to take care about ""border"" effects (string); TMVA::KDEKernel::EKernelIterfKDEiterNumber of iterations (adaptive or not); TStringfKDEiterString; TMVA::KDEKernel::EKernelTypefKDEtypeKernel type to use for KDE; TStringfKDEtypeStringstrings used to read definitions; TMVA::MsgLogger*fLogger! message logger; Int_tfMaxNsmoothMax number of smoothing iterations; Int_tfMinNsmoothMin number of smoothing iterations; TH1*fNSmoothHistnumber of smooth for each bin; Bool_tfNormalizenormalize histogram (false for cumulative distribution used in GaussTranform); Int_tfNsmoothMin number of smoothing iterations; TH1*fPDFHistthe high-binned histogram corresponding to the PDF; TStringfPDFNamefor output; UInt_tfReadingVersionthe TMVA version of the weight file; TSpline*fSpline! the used spline type; TStringfSuffix! the suffix for options; Bool_tfUseHistogramspline0 uses histogram as reference; static const Double_tfgEpsilonminimum PDF return; static const Bool_tfgManualIntegrationmanual integration (sum over bins) or DGAUSS; static const Int_tfgNbin_PdfHistnumber of bins in high-binned reference histogram; static TMVA::PDF*fgThisPDFthis PDF pointer . Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDF(const TString& name, Bool_t norm = kTRUE); default constructor ",MatchSource.WIKI,root/html532/TMVA__PDF.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDF.html
https://root.cern/root/html532/TMVA__PDF.html:9627,Integrability,integrat,integration,9627,"k; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. TStringfBorderMethodString; Bool_tfCheckHistcheck of source histogram; Float_tfFineFactorfine tuning factor for Adaptive KDE; TGraph*fGraph! needed to create PDF from histogram; TH1*fHistcopy of input histogram; Int_tfHistAvgEvtPerBinavg event per source hist bin; Int_tfHistDefinedNBinssource hist bin num set by user; TH1*fHistOriginalthe input histogram; TF1*fIGetValintegration interface; TMVA::PDF::EInterpolateMethodfInterpolMethodinterpolation method; TStringfInterpolateString; TMVA::KDEKernel::EKernelBorderfKDEborderThe method to take care about ""border"" effects (string); TMVA::KDEKernel::EKernelIterfKDEiterNumber of iterations (adaptive or not); TStringfKDEiterString; TMVA::KDEKernel::EKernelTypefKDEtypeKernel type to use for KDE; TStringfKDEtypeStringstrings used to read definitions; TMVA::MsgLogger*fLogger! message logger; Int_tfMaxNsmoothMax number of smoothing iterations; Int_tfMinNsmoothMin number of smoothing iterations; TH1*fNSmoothHistnumber of smooth for each bin; Bool_tfNormalizenormalize histogram (false for cumulative distribution used in GaussTranform); Int_tfNsmoothMin number of smoothing iterations; TH1*fPDFHistthe high-binned histogram corresponding to the PDF; TStringfPDFNamefor output; UInt_tfReadingVersionthe TMVA version of the weight file; TSpline*fSpline! the used spline type; TStringfSuffix! the suffix for options; Bool_tfUseHistogramspline0 uses histogram as reference; static const Double_tfgEpsilonminimum PDF return; static const Bool_tfgManualIntegrationmanual integration (sum over bins) or DGAUSS; static const Int_tfgNbin_PdfHistnumber of bins in high-binned reference histogram; static TMVA::PDF*fgThisPDFthis PDF pointer . Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDF(const TString& name, Bool_t norm = kTRUE); default constructor ",MatchSource.WIKI,root/html532/TMVA__PDF.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDF.html
https://root.cern/root/html532/TMVA__PDF.html:8752,Modifiability,adapt,adaptive,8752,"k; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. TStringfBorderMethodString; Bool_tfCheckHistcheck of source histogram; Float_tfFineFactorfine tuning factor for Adaptive KDE; TGraph*fGraph! needed to create PDF from histogram; TH1*fHistcopy of input histogram; Int_tfHistAvgEvtPerBinavg event per source hist bin; Int_tfHistDefinedNBinssource hist bin num set by user; TH1*fHistOriginalthe input histogram; TF1*fIGetValintegration interface; TMVA::PDF::EInterpolateMethodfInterpolMethodinterpolation method; TStringfInterpolateString; TMVA::KDEKernel::EKernelBorderfKDEborderThe method to take care about ""border"" effects (string); TMVA::KDEKernel::EKernelIterfKDEiterNumber of iterations (adaptive or not); TStringfKDEiterString; TMVA::KDEKernel::EKernelTypefKDEtypeKernel type to use for KDE; TStringfKDEtypeStringstrings used to read definitions; TMVA::MsgLogger*fLogger! message logger; Int_tfMaxNsmoothMax number of smoothing iterations; Int_tfMinNsmoothMin number of smoothing iterations; TH1*fNSmoothHistnumber of smooth for each bin; Bool_tfNormalizenormalize histogram (false for cumulative distribution used in GaussTranform); Int_tfNsmoothMin number of smoothing iterations; TH1*fPDFHistthe high-binned histogram corresponding to the PDF; TStringfPDFNamefor output; UInt_tfReadingVersionthe TMVA version of the weight file; TSpline*fSpline! the used spline type; TStringfSuffix! the suffix for options; Bool_tfUseHistogramspline0 uses histogram as reference; static const Double_tfgEpsilonminimum PDF return; static const Bool_tfgManualIntegrationmanual integration (sum over bins) or DGAUSS; static const Int_tfgNbin_PdfHistnumber of bins in high-binned reference histogram; static TMVA::PDF*fgThisPDFthis PDF pointer . Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDF(const TString& name, Bool_t norm = kTRUE); default constructor ",MatchSource.WIKI,root/html532/TMVA__PDF.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDF.html
https://root.cern/root/html532/TMVA__PDF.html:12068,Modifiability,variab,variable,12068," of the; PDF for speed reasons. void CheckHist() const; sanity check: compare PDF with original histogram. void ValidatePDF(TH1* original = 0) const; comparison of original histogram with reference PDF. Double_t GetIntegral() const; computes normalisation. Double_t IGetVal(Double_t* , Double_t* ); static external auxiliary function (integrand). Double_t GetIntegral(Double_t xmin, Double_t xmax); computes PDF integral within given ranges. Double_t GetVal(Double_t x) const; returns value PDF(x). Double_t GetValInverse(Double_t y, Bool_t isMonotonouslyIncreasingFunction = kFALSE) const; returns value PDF^{-1}(y). void FindBinInverse(const TH1* histogram, Int_t& lowerBin, Int_t& higherBin, Double_t& lowerBinValue, Double_t& higherBinValue, Double_t y, Bool_t isMonotonouslyIncreasingFunction = kFALSE) const; find bin from value on ordinate. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options:; PDFInterpol[ivar] <string> Spline0, Spline1, Spline2 <default>, Spline3, Spline5, KDE used to interpolate reference histograms; if no variable index is given, it is valid for ALL the variables. NSmooth <int> how often the input histos are smoothed; MinNSmooth <int> min number of smoothing iterations, for bins with most data; MaxNSmooth <int> max number of smoothing iterations, for bins with least data; NAvEvtPerBin <int> minimum average number of events per PDF bin; TransformOutput <bool> transform (often strongly peaked) likelihood output through sigmoid inversion; fKDEtype <KernelType> type of the Kernel to use (1 is Gaussian); fKDEiter <KerneIter> number of iterations (1 --> ""static KDE"", 2 --> ""adaptive KDE""); fBorderMethod <KernelBorder> the method to take care about ""border"" effects (1=no treatment , 2=kernel renormalization, 3=sample mirroring). void ProcessOptions(). void AddXMLTo(void* parent); XML file writing. void ReadXML(void* pdfnode); XML file reading. TMVA::PDF* ThisPDF( void ); return global ""this"" pointer o",MatchSource.WIKI,root/html532/TMVA__PDF.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDF.html
https://root.cern/root/html532/TMVA__PDF.html:12117,Modifiability,variab,variables,12117," of the; PDF for speed reasons. void CheckHist() const; sanity check: compare PDF with original histogram. void ValidatePDF(TH1* original = 0) const; comparison of original histogram with reference PDF. Double_t GetIntegral() const; computes normalisation. Double_t IGetVal(Double_t* , Double_t* ); static external auxiliary function (integrand). Double_t GetIntegral(Double_t xmin, Double_t xmax); computes PDF integral within given ranges. Double_t GetVal(Double_t x) const; returns value PDF(x). Double_t GetValInverse(Double_t y, Bool_t isMonotonouslyIncreasingFunction = kFALSE) const; returns value PDF^{-1}(y). void FindBinInverse(const TH1* histogram, Int_t& lowerBin, Int_t& higherBin, Double_t& lowerBinValue, Double_t& higherBinValue, Double_t y, Bool_t isMonotonouslyIncreasingFunction = kFALSE) const; find bin from value on ordinate. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options:; PDFInterpol[ivar] <string> Spline0, Spline1, Spline2 <default>, Spline3, Spline5, KDE used to interpolate reference histograms; if no variable index is given, it is valid for ALL the variables. NSmooth <int> how often the input histos are smoothed; MinNSmooth <int> min number of smoothing iterations, for bins with most data; MaxNSmooth <int> max number of smoothing iterations, for bins with least data; NAvEvtPerBin <int> minimum average number of events per PDF bin; TransformOutput <bool> transform (often strongly peaked) likelihood output through sigmoid inversion; fKDEtype <KernelType> type of the Kernel to use (1 is Gaussian); fKDEiter <KerneIter> number of iterations (1 --> ""static KDE"", 2 --> ""adaptive KDE""); fBorderMethod <KernelBorder> the method to take care about ""border"" effects (1=no treatment , 2=kernel renormalization, 3=sample mirroring). void ProcessOptions(). void AddXMLTo(void* parent); XML file writing. void ReadXML(void* pdfnode); XML file reading. TMVA::PDF* ThisPDF( void ); return global ""this"" pointer o",MatchSource.WIKI,root/html532/TMVA__PDF.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDF.html
https://root.cern/root/html532/TMVA__PDF.html:12642,Modifiability,adapt,adaptive,12642,"e PDF(x). Double_t GetValInverse(Double_t y, Bool_t isMonotonouslyIncreasingFunction = kFALSE) const; returns value PDF^{-1}(y). void FindBinInverse(const TH1* histogram, Int_t& lowerBin, Int_t& higherBin, Double_t& lowerBinValue, Double_t& higherBinValue, Double_t y, Bool_t isMonotonouslyIncreasingFunction = kFALSE) const; find bin from value on ordinate. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options:; PDFInterpol[ivar] <string> Spline0, Spline1, Spline2 <default>, Spline3, Spline5, KDE used to interpolate reference histograms; if no variable index is given, it is valid for ALL the variables. NSmooth <int> how often the input histos are smoothed; MinNSmooth <int> min number of smoothing iterations, for bins with most data; MaxNSmooth <int> max number of smoothing iterations, for bins with least data; NAvEvtPerBin <int> minimum average number of events per PDF bin; TransformOutput <bool> transform (often strongly peaked) likelihood output through sigmoid inversion; fKDEtype <KernelType> type of the Kernel to use (1 is Gaussian); fKDEiter <KerneIter> number of iterations (1 --> ""static KDE"", 2 --> ""adaptive KDE""); fBorderMethod <KernelBorder> the method to take care about ""border"" effects (1=no treatment , 2=kernel renormalization, 3=sample mirroring). void ProcessOptions(). void AddXMLTo(void* parent); XML file writing. void ReadXML(void* pdfnode); XML file reading. TMVA::PDF* ThisPDF( void ); return global ""this"" pointer of PDF. TH1* GetPDFHist() const; histogram underlying the PDF. { return fPDFHist; }. TH1* GetOriginalHist() const; { return fHistOriginal; }. TH1* GetSmoothedHist() const; { return fHist; }. TH1* GetNSmoothHist() const; { return fNSmoothHist; }. TSpline* GetSpline() const; accessors. { return fSpline; }. Int_t GetNBins() const; { return fHist->GetNbinsX(); }. Double_t GetXmin() const; { return fHist->GetXaxis()->GetXmin(); }. Double_t GetXmax() const; { return fHist->GetXaxis()->GetXma",MatchSource.WIKI,root/html532/TMVA__PDF.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDF.html
https://root.cern/root/html532/TMVA__PDF.html:11029,Safety,sanity check,sanity check,11029,"Method method = kSpline2, Int_t minnsmooth = 0, Int_t maxnsmooth = 0, Bool_t checkHist = kFALSE, Bool_t norm = kTRUE); constructor of spline based PDF:. PDF(const TString& name, const TH1* theHist, TMVA::KDEKernel::EKernelType ktype, TMVA::KDEKernel::EKernelIter kiter, TMVA::KDEKernel::EKernelBorder kborder, Float_t FineFactor, Bool_t norm = kTRUE); constructor of kernel based PDF:. PDF(const TString& name, const TString& options, const TString& suffix = """", TMVA::PDF* defaultPDF = 0, Bool_t norm = kTRUE). ~PDF(); destructor. void BuildPDF(const TH1* theHist). Int_t GetHistNBins(Int_t evtNum = 0). void BuildSplinePDF(); build the PDF from the original histograms. void BuildKDEPDF(); creates high-binned reference histogram to be used instead of the; PDF for speed reasons. void SmoothHistogram(). void FillHistToGraph(); Simple conversion. void FillSplineToHist(); creates high-binned reference histogram to be used instead of the; PDF for speed reasons. void CheckHist() const; sanity check: compare PDF with original histogram. void ValidatePDF(TH1* original = 0) const; comparison of original histogram with reference PDF. Double_t GetIntegral() const; computes normalisation. Double_t IGetVal(Double_t* , Double_t* ); static external auxiliary function (integrand). Double_t GetIntegral(Double_t xmin, Double_t xmax); computes PDF integral within given ranges. Double_t GetVal(Double_t x) const; returns value PDF(x). Double_t GetValInverse(Double_t y, Bool_t isMonotonouslyIncreasingFunction = kFALSE) const; returns value PDF^{-1}(y). void FindBinInverse(const TH1* histogram, Int_t& lowerBin, Int_t& higherBin, Double_t& lowerBinValue, Double_t& higherBinValue, Double_t y, Bool_t isMonotonouslyIncreasingFunction = kFALSE) const; find bin from value on ordinate. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options:; PDFInterpol[ivar] <string> Spline0, Spline1, Spline2 <default>, Spline3, Spline5, KDE used to interpolate re",MatchSource.WIKI,root/html532/TMVA__PDF.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDF.html
https://root.cern/root/html532/TMVA__PDF.html:13247,Security,access,accessors,13247,"or bins with most data; MaxNSmooth <int> max number of smoothing iterations, for bins with least data; NAvEvtPerBin <int> minimum average number of events per PDF bin; TransformOutput <bool> transform (often strongly peaked) likelihood output through sigmoid inversion; fKDEtype <KernelType> type of the Kernel to use (1 is Gaussian); fKDEiter <KerneIter> number of iterations (1 --> ""static KDE"", 2 --> ""adaptive KDE""); fBorderMethod <KernelBorder> the method to take care about ""border"" effects (1=no treatment , 2=kernel renormalization, 3=sample mirroring). void ProcessOptions(). void AddXMLTo(void* parent); XML file writing. void ReadXML(void* pdfnode); XML file reading. TMVA::PDF* ThisPDF( void ); return global ""this"" pointer of PDF. TH1* GetPDFHist() const; histogram underlying the PDF. { return fPDFHist; }. TH1* GetOriginalHist() const; { return fHistOriginal; }. TH1* GetSmoothedHist() const; { return fHist; }. TH1* GetNSmoothHist() const; { return fNSmoothHist; }. TSpline* GetSpline() const; accessors. { return fSpline; }. Int_t GetNBins() const; { return fHist->GetNbinsX(); }. Double_t GetXmin() const; { return fHist->GetXaxis()->GetXmin(); }. Double_t GetXmax() const; { return fHist->GetXaxis()->GetXmax(); }. TMVA::PDF::EInterpolateMethod GetInterpolMethod(); { return fInterpolMethod;}. const char* GetName() const; modified name (remove TMVA::). { return fPDFName; }. void SetReadingVersion(UInt_t rv); TMVA version control (for weight files). { fReadingVersion = rv; }. UInt_t GetReadingVersion() const; { return fReadingVersion; }. Double_t GetPdfHistBinWidth() const. Bool_t UseHistogram() const; do we use the original histogram as reference ?. { return fUseHistogram; }. » Author: Asen Christov, Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss , Jan Therhaag » Copyright (c) 2005-2011: *; » Last changed: root/tmva $Id: PDF.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or sugge",MatchSource.WIKI,root/html532/TMVA__PDF.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDF.html
https://root.cern/root/html532/TMVA__PDF.html:8945,Testability,log,logger,8945,"k; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. TStringfBorderMethodString; Bool_tfCheckHistcheck of source histogram; Float_tfFineFactorfine tuning factor for Adaptive KDE; TGraph*fGraph! needed to create PDF from histogram; TH1*fHistcopy of input histogram; Int_tfHistAvgEvtPerBinavg event per source hist bin; Int_tfHistDefinedNBinssource hist bin num set by user; TH1*fHistOriginalthe input histogram; TF1*fIGetValintegration interface; TMVA::PDF::EInterpolateMethodfInterpolMethodinterpolation method; TStringfInterpolateString; TMVA::KDEKernel::EKernelBorderfKDEborderThe method to take care about ""border"" effects (string); TMVA::KDEKernel::EKernelIterfKDEiterNumber of iterations (adaptive or not); TStringfKDEiterString; TMVA::KDEKernel::EKernelTypefKDEtypeKernel type to use for KDE; TStringfKDEtypeStringstrings used to read definitions; TMVA::MsgLogger*fLogger! message logger; Int_tfMaxNsmoothMax number of smoothing iterations; Int_tfMinNsmoothMin number of smoothing iterations; TH1*fNSmoothHistnumber of smooth for each bin; Bool_tfNormalizenormalize histogram (false for cumulative distribution used in GaussTranform); Int_tfNsmoothMin number of smoothing iterations; TH1*fPDFHistthe high-binned histogram corresponding to the PDF; TStringfPDFNamefor output; UInt_tfReadingVersionthe TMVA version of the weight file; TSpline*fSpline! the used spline type; TStringfSuffix! the suffix for options; Bool_tfUseHistogramspline0 uses histogram as reference; static const Double_tfgEpsilonminimum PDF return; static const Bool_tfgManualIntegrationmanual integration (sum over bins) or DGAUSS; static const Int_tfgNbin_PdfHistnumber of bins in high-binned reference histogram; static TMVA::PDF*fgThisPDFthis PDF pointer . Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; PDF(const TString& name, Bool_t norm = kTRUE); default constructor ",MatchSource.WIKI,root/html532/TMVA__PDF.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__PDF.html
https://root.cern/root/html532/TMVA__Ranking.html:1032,Integrability,message,message,1032,":; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Ranking. class TMVA::Ranking. Ranking for variables in method (implementation). Function Members (Methods); public:. virtual~Ranking(); virtual voidAddRank(const TMVA::Rank& rank); static TClass*Class(); virtual TClass*IsA() const; TMVA::Ranking&operator=(const TMVA::Ranking&); virtual voidPrint() const; TMVA::RankingRanking(); TMVA::RankingRanking(const TMVA::Ranking&); TMVA::RankingRanking(const TString& context, const TString& rankingDiscriminatorName); voidSetContext(const TString& context); voidSetDiscrName(const TString& discrName); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). private:. TMVA::MsgLogger&Log() const. Data Members; private:. TStringfContextthe ranking context; TMVA::MsgLogger*fLogger! message logger; vector<TMVA::Rank>fRankingvector of ranks; TStringfRankingDiscriminatorNamethe name of the ranking discriminator. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Ranking(); default constructor. Ranking(const TString& context, const TString& rankingDiscriminatorName); constructor. ~Ranking(); destructor. void SetContext(const TString& context). void AddRank(const TMVA::Rank& rank); Add a new rank; take ownership of it. void Print() const; get maximum length of variable names. Ranking(). void SetDiscrName(const TString& discrName); { fRankingDiscriminatorName = discrName; }. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: Ranking.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Ranking.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Ranking.html
https://root.cern/root/html532/TMVA__Ranking.html:288,Modifiability,variab,variables,288,". TMVA::Ranking. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Ranking. class TMVA::Ranking. Ranking for variables in method (implementation). Function Members (Methods); public:. virtual~Ranking(); virtual voidAddRank(const TMVA::Rank& rank); static TClass*Class(); virtual TClass*IsA() const; TMVA::Ranking&operator=(const TMVA::Ranking&); virtual voidPrint() const; TMVA::RankingRanking(); TMVA::RankingRanking(const TMVA::Ranking&); TMVA::RankingRanking(const TString& context, const TString& rankingDiscriminatorName); voidSetContext(const TString& context); voidSetDiscrName(const TString& discrName); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). private:. TMVA::MsgLogger&Log() const. Data Members; private:. TStringfContextthe ranking context; TMVA::MsgLogger*fLogger! message logger; vector<TMVA::Rank>fRankingvector of ranks; TStringfRankingDiscriminatorNamethe name of the ranking discriminator. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Ranking(); default constructor. Ranking(const TString& context, const TString& rankingDiscriminatorName); constructor. ~Ranking(); destructor. void SetContext(const TString& context). void AddRank(const TMVA::Rank& rank); Add a new rank; take ownership of it. void Print() const; get maximum length of variable names. Ranking(). void SetDiscrName(const TString& discrName); { fRankingDiscriminatorName = discrName; }. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: Ranking.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please se",MatchSource.WIKI,root/html532/TMVA__Ranking.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Ranking.html
https://root.cern/root/html532/TMVA__Ranking.html:1555,Modifiability,variab,variable,1555,":; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Ranking. class TMVA::Ranking. Ranking for variables in method (implementation). Function Members (Methods); public:. virtual~Ranking(); virtual voidAddRank(const TMVA::Rank& rank); static TClass*Class(); virtual TClass*IsA() const; TMVA::Ranking&operator=(const TMVA::Ranking&); virtual voidPrint() const; TMVA::RankingRanking(); TMVA::RankingRanking(const TMVA::Ranking&); TMVA::RankingRanking(const TString& context, const TString& rankingDiscriminatorName); voidSetContext(const TString& context); voidSetDiscrName(const TString& discrName); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). private:. TMVA::MsgLogger&Log() const. Data Members; private:. TStringfContextthe ranking context; TMVA::MsgLogger*fLogger! message logger; vector<TMVA::Rank>fRankingvector of ranks; TStringfRankingDiscriminatorNamethe name of the ranking discriminator. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Ranking(); default constructor. Ranking(const TString& context, const TString& rankingDiscriminatorName); constructor. ~Ranking(); destructor. void SetContext(const TString& context). void AddRank(const TMVA::Rank& rank); Add a new rank; take ownership of it. void Print() const; get maximum length of variable names. Ranking(). void SetDiscrName(const TString& discrName); { fRankingDiscriminatorName = discrName; }. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: Ranking.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Ranking.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Ranking.html
https://root.cern/root/html532/TMVA__Ranking.html:1040,Testability,log,logger,1040,":; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Ranking. class TMVA::Ranking. Ranking for variables in method (implementation). Function Members (Methods); public:. virtual~Ranking(); virtual voidAddRank(const TMVA::Rank& rank); static TClass*Class(); virtual TClass*IsA() const; TMVA::Ranking&operator=(const TMVA::Ranking&); virtual voidPrint() const; TMVA::RankingRanking(); TMVA::RankingRanking(const TMVA::Ranking&); TMVA::RankingRanking(const TString& context, const TString& rankingDiscriminatorName); voidSetContext(const TString& context); voidSetDiscrName(const TString& discrName); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). private:. TMVA::MsgLogger&Log() const. Data Members; private:. TStringfContextthe ranking context; TMVA::MsgLogger*fLogger! message logger; vector<TMVA::Rank>fRankingvector of ranks; TStringfRankingDiscriminatorNamethe name of the ranking discriminator. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Ranking(); default constructor. Ranking(const TString& context, const TString& rankingDiscriminatorName); constructor. ~Ranking(); destructor. void SetContext(const TString& context). void AddRank(const TMVA::Rank& rank); Add a new rank; take ownership of it. void Print() const; get maximum length of variable names. Ranking(). void SetDiscrName(const TString& discrName); { fRankingDiscriminatorName = discrName; }. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: Ranking.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Ranking.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Ranking.html
https://root.cern/root/html532/TMVA__Reader.html:4489,Availability,error,error,4489,"p() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; const vector<Float_t>&EvaluateMulticlass(const TString& methodTag, Double_t aux = 0); const vector<Float_t>&EvaluateMulticlass(TMVA::MethodBase* method, Double_t aux = 0); Float_tEvaluateMulticlass(UInt_t clsNumber, const TString& methodTag, Double_t aux = 0); Double_tEvaluateMVA(TMVA::MethodBase* method, Double_t aux = 0); Double_tEvaluateMVA(const TString& methodTag, Double_t aux = 0); Double_tEvaluateMVA(const vector<Float_t>&, const TString& methodTag, Double_t aux = 0); Double_tEvaluateMVA(const vector<Double_t>&, const TString& methodTag, Double_t aux = 0); const vector<Float_t>&EvaluateRegression(const TString& methodTag, Double_t aux = 0); const vector<Float_t>&EvaluateRegression(TMVA::MethodBase* method, Double_t aux = 0); Float_tEvaluateRegression(UInt_t tgtNumber, const TString& methodTag, Double_t aux = 0); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; TMVA::MethodCuts*FindCutsMVA(const TString& methodTag); TMVA::IMethod*FindMVA(const TString& methodTag); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; Double_tGetMVAError() const; Double_tGetMVAErrorLower() const; Double_tGetMVAErrorUpper() const; virtual const char*GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const ",MatchSource.WIKI,root/html532/TMVA__Reader.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Reader.html
https://root.cern/root/html532/TMVA__Reader.html:4573,Availability,error,error,4573,"onst; const vector<Float_t>&EvaluateMulticlass(const TString& methodTag, Double_t aux = 0); const vector<Float_t>&EvaluateMulticlass(TMVA::MethodBase* method, Double_t aux = 0); Float_tEvaluateMulticlass(UInt_t clsNumber, const TString& methodTag, Double_t aux = 0); Double_tEvaluateMVA(TMVA::MethodBase* method, Double_t aux = 0); Double_tEvaluateMVA(const TString& methodTag, Double_t aux = 0); Double_tEvaluateMVA(const vector<Float_t>&, const TString& methodTag, Double_t aux = 0); Double_tEvaluateMVA(const vector<Double_t>&, const TString& methodTag, Double_t aux = 0); const vector<Float_t>&EvaluateRegression(const TString& methodTag, Double_t aux = 0); const vector<Float_t>&EvaluateRegression(TMVA::MethodBase* method, Double_t aux = 0); Float_tEvaluateRegression(UInt_t tgtNumber, const TString& methodTag, Double_t aux = 0); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; TMVA::MethodCuts*FindCutsMVA(const TString& methodTag); TMVA::IMethod*FindMVA(const TString& methodTag); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; Double_tGetMVAError() const; Double_tGetMVAErrorLower() const; Double_tGetMVAErrorUpper() const; virtual const char*GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&TMVA::Configurable::GetOptions() const; Double_tGetProba(const TString& meth",MatchSource.WIKI,root/html532/TMVA__Reader.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Reader.html
https://root.cern/root/html532/TMVA__Reader.html:10693,Availability,error,error,10693,"seOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. TMVA::IMethod*BookMVA(TMVA::Types::EMVA method, const TString& weightfile); voidDeclareOptions(); voidDecodeVarNames(const string& varNames); voidDecodeVarNames(const TString& varNames); TStringGetMethodTypeFromFile(const TString& filename); voidInit(); TMVA::MsgLogger&Log() const. Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. Bool_tfCalculateErrorerror calculation mode; Bool_tfColorcolor mode; TMVA::DataInputHandlerfDataInputHandler; TMVA::DataSetInfofDataSetInfothe data set; TMVA::DataSetManager*fDataSetManagerDSMTEST; TMVA::MsgLogger*fLoggermessage logger; map<TString,IMethod*>fMethodMapmap of methods; Double_tfMvaEventErrorper-event error returned by MVA; Double_tfMvaEventErrorUpperper-event error returned by MVA; Bool_tfSilentsilent mode; vector<Float_t>fTmpEvalVectemporary evaluation vector (if user input is v<double>); Bool_tfVerboseverbosity. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Reader(const TString& theOption = """", Bool_t verbose = 0); constructor. Reader(vector<TString>& varNames, const TString& theOption = """", Bool_t verbose = 0); constructor. Reader(vector<std::string>& varNames, const TString& theOption = """", Bool_t verbose = 0); constructor. Reader( const std::string& varNames, const TString& theOption, Bool_t verbose ); constructor. Reader(const TString& varNames, const TString& theOption, Bool_t verbose = 0); constructor. void DeclareOptions(); declaration of configuration options. ~Reader( void ); destructor. void Init( void ); default initialisation (no member variables); default initialisation (no",MatchSource.WIKI,root/html532/TMVA__Reader.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Reader.html
https://root.cern/root/html532/TMVA__Reader.html:10753,Availability,error,error,10753,"seOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. TMVA::IMethod*BookMVA(TMVA::Types::EMVA method, const TString& weightfile); voidDeclareOptions(); voidDecodeVarNames(const string& varNames); voidDecodeVarNames(const TString& varNames); TStringGetMethodTypeFromFile(const TString& filename); voidInit(); TMVA::MsgLogger&Log() const. Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. Bool_tfCalculateErrorerror calculation mode; Bool_tfColorcolor mode; TMVA::DataInputHandlerfDataInputHandler; TMVA::DataSetInfofDataSetInfothe data set; TMVA::DataSetManager*fDataSetManagerDSMTEST; TMVA::MsgLogger*fLoggermessage logger; map<TString,IMethod*>fMethodMapmap of methods; Double_tfMvaEventErrorper-event error returned by MVA; Double_tfMvaEventErrorUpperper-event error returned by MVA; Bool_tfSilentsilent mode; vector<Float_t>fTmpEvalVectemporary evaluation vector (if user input is v<double>); Bool_tfVerboseverbosity. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Reader(const TString& theOption = """", Bool_t verbose = 0); constructor. Reader(vector<TString>& varNames, const TString& theOption = """", Bool_t verbose = 0); constructor. Reader(vector<std::string>& varNames, const TString& theOption = """", Bool_t verbose = 0); constructor. Reader( const std::string& varNames, const TString& theOption, Bool_t verbose ); constructor. Reader(const TString& varNames, const TString& theOption, Bool_t verbose = 0); constructor. void DeclareOptions(); declaration of configuration options. ~Reader( void ); destructor. void Init( void ); default initialisation (no member variables); default initialisation (no",MatchSource.WIKI,root/html532/TMVA__Reader.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Reader.html
https://root.cern/root/html532/TMVA__Reader.html:14635,Availability,error,error,14635,"lticlass(const TString& methodTag, Double_t aux = 0); evaluates MVA for given set of input variables. const std::vector< Float_t >& EvaluateMulticlass(TMVA::MethodBase* method, Double_t aux = 0); evaluates the multiclass MVA. Float_t EvaluateMulticlass(UInt_t clsNumber, const TString& methodTag, Double_t aux = 0); evaluates the multiclass MVA. TMVA::IMethod* FindMVA(const TString& methodTag); return pointer to method with tag ""methodTag"". TMVA::MethodCuts* FindCutsMVA(const TString& methodTag); special function for Cuts to avoid dynamic_casts in ROOT macros,; which are not properly handled by CINT. Double_t GetProba(const TString& methodTag, Double_t ap_sig = 0.5, Double_t mvaVal = -9999999); evaluates probability of MVA for given set of input variables. Double_t GetRarity(const TString& methodTag, Double_t mvaVal = -9999999); evaluates the MVA's rarity. void DecodeVarNames( const std::string& varNames ); decodes ""name1:name2:..."" form. void DecodeVarNames(const TString& varNames); decodes ""name1:name2:..."" form. Double_t GetMVAError() const; returns error on MVA response for given event; NOTE: must be called AFTER ""EvaluateMVA(...)"" call !. { return fMvaEventError; }. Double_t GetMVAErrorLower() const; { return fMvaEventError; }. Double_t GetMVAErrorUpper() const; { return fMvaEventErrorUpper; }. const char* GetName() const; accessors. { return ""Reader""; }. Bool_t Verbose( void ); { return fVerbose; }. void SetVerbose(Bool_t v); { fVerbose = v; }. const DataSetInfo& DataInfo() const; { return fDataSetInfo; }. DataSetInfo& DataInfo(); { return fDataSetInfo; }. » Author: Andreas Hoecker, Peter Speckmayer, Joerg Stelzer, Helge Voss, Kai Voss, Eckhard von Toerne, Jan Therhaag » Copyright (c) 2005-2011: *; » Last changed: root/tmva $Id: Reader.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Reader.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Reader.html
https://root.cern/root/html532/TMVA__Reader.html:11500,Deployability,configurat,configuration,11500,"::DataSetInfofDataSetInfothe data set; TMVA::DataSetManager*fDataSetManagerDSMTEST; TMVA::MsgLogger*fLoggermessage logger; map<TString,IMethod*>fMethodMapmap of methods; Double_tfMvaEventErrorper-event error returned by MVA; Double_tfMvaEventErrorUpperper-event error returned by MVA; Bool_tfSilentsilent mode; vector<Float_t>fTmpEvalVectemporary evaluation vector (if user input is v<double>); Bool_tfVerboseverbosity. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Reader(const TString& theOption = """", Bool_t verbose = 0); constructor. Reader(vector<TString>& varNames, const TString& theOption = """", Bool_t verbose = 0); constructor. Reader(vector<std::string>& varNames, const TString& theOption = """", Bool_t verbose = 0); constructor. Reader( const std::string& varNames, const TString& theOption, Bool_t verbose ); constructor. Reader(const TString& varNames, const TString& theOption, Bool_t verbose = 0); constructor. void DeclareOptions(); declaration of configuration options. ~Reader( void ); destructor. void Init( void ); default initialisation (no member variables); default initialisation (no member variables). void AddVariable(const TString& expression, Float_t* ); Add a float variable or expression to the reader. void AddVariable(const TString& expression, Int_t* ). void AddSpectator(const TString& expression, Float_t* ); Add a float spectator or expression to the reader. void AddSpectator(const TString& expression, Int_t* ); Add an integer spectator or expression to the reader. TString GetMethodTypeFromFile(const TString& filename); read the method type from the file. TMVA::IMethod* BookMVA(const TString& methodTag, const TString& weightfile); read method name from weight file. TMVA::IMethod* BookMVA(TMVA::Types::EMVA method, const TString& weightfile); books MVA method from weightfile. TMVA::IMethod* BookMVA(TMVA::Types::EMVA methodType, const char* xmlstr). Double_t EvaluateMVA( const std::vector<Float_t>& inputVec, con",MatchSource.WIKI,root/html532/TMVA__Reader.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Reader.html
https://root.cern/root/html532/TMVA__Reader.html:438,Modifiability,variab,variables,438,". TMVA::Reader. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Reader. class TMVA::Reader: public TMVA::Configurable. The Reader class serves to use the MVAs in a specific analysis context.; Within an event loop, a vector is filled that corresponds to the variables; that were used to train the MVA(s) during the training stage. This vector; is transfered to the Reader, who takes care of interpreting the weight; file of the MVA of choice, and to return the MVA's output. This is then; used by the user for further analysis. Usage:. // ------ before starting the event loop (eg, in the initialisation step). // create TMVA::Reader object. TMVA::Reader *reader = new TMVA::Reader();. // create a set of variables and declare them to the reader; // - the variable names must corresponds in name and type to; // those given in the weight file(s) that you use; Float_t var1, var2, var3, var4;; reader->AddVariable( ""var1"", &var1 );; reader->AddVariable( ""var2"", &var2 );; reader->AddVariable( ""var3"", &var3 );; reader->AddVariable( ""var4"", &var4 );. // book the MVA of your choice (prior training of these methods, ie,; // existence of the weight files is required); reader->BookMVA( ""Fisher method"", ""weights/Fisher.weights.txt"" );; reader->BookMVA( ""MLP method"", ""weights/MLP.weights.txt"" );; // ... etc. // ------- start your event loop. for (Long64_t ievt=0; ievt<myTree->GetEntries();ievt++) {. // fill vector with values of variables computed from those in the tree; var1 = myvar1;; var2 = myvar2;; var3 = myvar3;; var4 = myvar4;. // retrieve the corresponding MVA output; double mvaFi = reader->EvaluateMVA( ""Fisher method"" );; double mvaNN = reader->EvaluateMVA( ""MLP method"" );. // do something with these ...., e.g., fill them into your ntuple. } // end of event loop. delete reader;. An example application of t",MatchSource.WIKI,root/html532/TMVA__Reader.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Reader.html
https://root.cern/root/html532/TMVA__Reader.html:885,Modifiability,variab,variables,885,"lass Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Reader. class TMVA::Reader: public TMVA::Configurable. The Reader class serves to use the MVAs in a specific analysis context.; Within an event loop, a vector is filled that corresponds to the variables; that were used to train the MVA(s) during the training stage. This vector; is transfered to the Reader, who takes care of interpreting the weight; file of the MVA of choice, and to return the MVA's output. This is then; used by the user for further analysis. Usage:. // ------ before starting the event loop (eg, in the initialisation step). // create TMVA::Reader object. TMVA::Reader *reader = new TMVA::Reader();. // create a set of variables and declare them to the reader; // - the variable names must corresponds in name and type to; // those given in the weight file(s) that you use; Float_t var1, var2, var3, var4;; reader->AddVariable( ""var1"", &var1 );; reader->AddVariable( ""var2"", &var2 );; reader->AddVariable( ""var3"", &var3 );; reader->AddVariable( ""var4"", &var4 );. // book the MVA of your choice (prior training of these methods, ie,; // existence of the weight files is required); reader->BookMVA( ""Fisher method"", ""weights/Fisher.weights.txt"" );; reader->BookMVA( ""MLP method"", ""weights/MLP.weights.txt"" );; // ... etc. // ------- start your event loop. for (Long64_t ievt=0; ievt<myTree->GetEntries();ievt++) {. // fill vector with values of variables computed from those in the tree; var1 = myvar1;; var2 = myvar2;; var3 = myvar3;; var4 = myvar4;. // retrieve the corresponding MVA output; double mvaFi = reader->EvaluateMVA( ""Fisher method"" );; double mvaNN = reader->EvaluateMVA( ""MLP method"" );. // do something with these ...., e.g., fill them into your ntuple. } // end of event loop. delete reader;. An example application of the Reader can be found in TMVA/macros/TMVAppli",MatchSource.WIKI,root/html532/TMVA__Reader.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Reader.html
https://root.cern/root/html532/TMVA__Reader.html:936,Modifiability,variab,variable,936,"lass Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Reader. class TMVA::Reader: public TMVA::Configurable. The Reader class serves to use the MVAs in a specific analysis context.; Within an event loop, a vector is filled that corresponds to the variables; that were used to train the MVA(s) during the training stage. This vector; is transfered to the Reader, who takes care of interpreting the weight; file of the MVA of choice, and to return the MVA's output. This is then; used by the user for further analysis. Usage:. // ------ before starting the event loop (eg, in the initialisation step). // create TMVA::Reader object. TMVA::Reader *reader = new TMVA::Reader();. // create a set of variables and declare them to the reader; // - the variable names must corresponds in name and type to; // those given in the weight file(s) that you use; Float_t var1, var2, var3, var4;; reader->AddVariable( ""var1"", &var1 );; reader->AddVariable( ""var2"", &var2 );; reader->AddVariable( ""var3"", &var3 );; reader->AddVariable( ""var4"", &var4 );. // book the MVA of your choice (prior training of these methods, ie,; // existence of the weight files is required); reader->BookMVA( ""Fisher method"", ""weights/Fisher.weights.txt"" );; reader->BookMVA( ""MLP method"", ""weights/MLP.weights.txt"" );; // ... etc. // ------- start your event loop. for (Long64_t ievt=0; ievt<myTree->GetEntries();ievt++) {. // fill vector with values of variables computed from those in the tree; var1 = myvar1;; var2 = myvar2;; var3 = myvar3;; var4 = myvar4;. // retrieve the corresponding MVA output; double mvaFi = reader->EvaluateMVA( ""Fisher method"" );; double mvaNN = reader->EvaluateMVA( ""MLP method"" );. // do something with these ...., e.g., fill them into your ntuple. } // end of event loop. delete reader;. An example application of the Reader can be found in TMVA/macros/TMVAppli",MatchSource.WIKI,root/html532/TMVA__Reader.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Reader.html
https://root.cern/root/html532/TMVA__Reader.html:1609,Modifiability,variab,variables,1609," output. This is then; used by the user for further analysis. Usage:. // ------ before starting the event loop (eg, in the initialisation step). // create TMVA::Reader object. TMVA::Reader *reader = new TMVA::Reader();. // create a set of variables and declare them to the reader; // - the variable names must corresponds in name and type to; // those given in the weight file(s) that you use; Float_t var1, var2, var3, var4;; reader->AddVariable( ""var1"", &var1 );; reader->AddVariable( ""var2"", &var2 );; reader->AddVariable( ""var3"", &var3 );; reader->AddVariable( ""var4"", &var4 );. // book the MVA of your choice (prior training of these methods, ie,; // existence of the weight files is required); reader->BookMVA( ""Fisher method"", ""weights/Fisher.weights.txt"" );; reader->BookMVA( ""MLP method"", ""weights/MLP.weights.txt"" );; // ... etc. // ------- start your event loop. for (Long64_t ievt=0; ievt<myTree->GetEntries();ievt++) {. // fill vector with values of variables computed from those in the tree; var1 = myvar1;; var2 = myvar2;; var3 = myvar3;; var4 = myvar4;. // retrieve the corresponding MVA output; double mvaFi = reader->EvaluateMVA( ""Fisher method"" );; double mvaNN = reader->EvaluateMVA( ""MLP method"" );. // do something with these ...., e.g., fill them into your ntuple. } // end of event loop. delete reader;. An example application of the Reader can be found in TMVA/macros/TMVApplication.C. Function Members (Methods); public:. virtual~Reader(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidAddSpectator(const TString& expression, Float_t*); voidAddSpectator(const TString& expression, Int_t*); voidAddVariable(const TString& expression, Float_t*); voidAddVariable(const TString& expression, Int_t*); virtual voidTObject::AppendPad(Option_t* option = """"); TMVA::IMethod*BookMVA(const TString& methodTag, const TString& weightfile); TMVA::IMethod*BookMVA(TMVA::Types::EMVA methodType, const char* xmlstr); v",MatchSource.WIKI,root/html532/TMVA__Reader.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Reader.html
https://root.cern/root/html532/TMVA__Reader.html:11500,Modifiability,config,configuration,11500,"::DataSetInfofDataSetInfothe data set; TMVA::DataSetManager*fDataSetManagerDSMTEST; TMVA::MsgLogger*fLoggermessage logger; map<TString,IMethod*>fMethodMapmap of methods; Double_tfMvaEventErrorper-event error returned by MVA; Double_tfMvaEventErrorUpperper-event error returned by MVA; Bool_tfSilentsilent mode; vector<Float_t>fTmpEvalVectemporary evaluation vector (if user input is v<double>); Bool_tfVerboseverbosity. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Reader(const TString& theOption = """", Bool_t verbose = 0); constructor. Reader(vector<TString>& varNames, const TString& theOption = """", Bool_t verbose = 0); constructor. Reader(vector<std::string>& varNames, const TString& theOption = """", Bool_t verbose = 0); constructor. Reader( const std::string& varNames, const TString& theOption, Bool_t verbose ); constructor. Reader(const TString& varNames, const TString& theOption, Bool_t verbose = 0); constructor. void DeclareOptions(); declaration of configuration options. ~Reader( void ); destructor. void Init( void ); default initialisation (no member variables); default initialisation (no member variables). void AddVariable(const TString& expression, Float_t* ); Add a float variable or expression to the reader. void AddVariable(const TString& expression, Int_t* ). void AddSpectator(const TString& expression, Float_t* ); Add a float spectator or expression to the reader. void AddSpectator(const TString& expression, Int_t* ); Add an integer spectator or expression to the reader. TString GetMethodTypeFromFile(const TString& filename); read the method type from the file. TMVA::IMethod* BookMVA(const TString& methodTag, const TString& weightfile); read method name from weight file. TMVA::IMethod* BookMVA(TMVA::Types::EMVA method, const TString& weightfile); books MVA method from weightfile. TMVA::IMethod* BookMVA(TMVA::Types::EMVA methodType, const char* xmlstr). Double_t EvaluateMVA( const std::vector<Float_t>& inputVec, con",MatchSource.WIKI,root/html532/TMVA__Reader.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Reader.html
https://root.cern/root/html532/TMVA__Reader.html:11605,Modifiability,variab,variables,11605,"logger; map<TString,IMethod*>fMethodMapmap of methods; Double_tfMvaEventErrorper-event error returned by MVA; Double_tfMvaEventErrorUpperper-event error returned by MVA; Bool_tfSilentsilent mode; vector<Float_t>fTmpEvalVectemporary evaluation vector (if user input is v<double>); Bool_tfVerboseverbosity. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Reader(const TString& theOption = """", Bool_t verbose = 0); constructor. Reader(vector<TString>& varNames, const TString& theOption = """", Bool_t verbose = 0); constructor. Reader(vector<std::string>& varNames, const TString& theOption = """", Bool_t verbose = 0); constructor. Reader( const std::string& varNames, const TString& theOption, Bool_t verbose ); constructor. Reader(const TString& varNames, const TString& theOption, Bool_t verbose = 0); constructor. void DeclareOptions(); declaration of configuration options. ~Reader( void ); destructor. void Init( void ); default initialisation (no member variables); default initialisation (no member variables). void AddVariable(const TString& expression, Float_t* ); Add a float variable or expression to the reader. void AddVariable(const TString& expression, Int_t* ). void AddSpectator(const TString& expression, Float_t* ); Add a float spectator or expression to the reader. void AddSpectator(const TString& expression, Int_t* ); Add an integer spectator or expression to the reader. TString GetMethodTypeFromFile(const TString& filename); read the method type from the file. TMVA::IMethod* BookMVA(const TString& methodTag, const TString& weightfile); read method name from weight file. TMVA::IMethod* BookMVA(TMVA::Types::EMVA method, const TString& weightfile); books MVA method from weightfile. TMVA::IMethod* BookMVA(TMVA::Types::EMVA methodType, const char* xmlstr). Double_t EvaluateMVA( const std::vector<Float_t>& inputVec, const TString& methodTag, Double_t aux ); Evaluate a vector<float> of input data for a given method; The parameter aux",MatchSource.WIKI,root/html532/TMVA__Reader.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Reader.html
https://root.cern/root/html532/TMVA__Reader.html:11651,Modifiability,variab,variables,11651,"logger; map<TString,IMethod*>fMethodMapmap of methods; Double_tfMvaEventErrorper-event error returned by MVA; Double_tfMvaEventErrorUpperper-event error returned by MVA; Bool_tfSilentsilent mode; vector<Float_t>fTmpEvalVectemporary evaluation vector (if user input is v<double>); Bool_tfVerboseverbosity. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Reader(const TString& theOption = """", Bool_t verbose = 0); constructor. Reader(vector<TString>& varNames, const TString& theOption = """", Bool_t verbose = 0); constructor. Reader(vector<std::string>& varNames, const TString& theOption = """", Bool_t verbose = 0); constructor. Reader( const std::string& varNames, const TString& theOption, Bool_t verbose ); constructor. Reader(const TString& varNames, const TString& theOption, Bool_t verbose = 0); constructor. void DeclareOptions(); declaration of configuration options. ~Reader( void ); destructor. void Init( void ); default initialisation (no member variables); default initialisation (no member variables). void AddVariable(const TString& expression, Float_t* ); Add a float variable or expression to the reader. void AddVariable(const TString& expression, Int_t* ). void AddSpectator(const TString& expression, Float_t* ); Add a float spectator or expression to the reader. void AddSpectator(const TString& expression, Int_t* ); Add an integer spectator or expression to the reader. TString GetMethodTypeFromFile(const TString& filename); read the method type from the file. TMVA::IMethod* BookMVA(const TString& methodTag, const TString& weightfile); read method name from weight file. TMVA::IMethod* BookMVA(TMVA::Types::EMVA method, const TString& weightfile); books MVA method from weightfile. TMVA::IMethod* BookMVA(TMVA::Types::EMVA methodType, const char* xmlstr). Double_t EvaluateMVA( const std::vector<Float_t>& inputVec, const TString& methodTag, Double_t aux ); Evaluate a vector<float> of input data for a given method; The parameter aux",MatchSource.WIKI,root/html532/TMVA__Reader.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Reader.html
https://root.cern/root/html532/TMVA__Reader.html:11731,Modifiability,variab,variable,11731," Double_tfMvaEventErrorUpperper-event error returned by MVA; Bool_tfSilentsilent mode; vector<Float_t>fTmpEvalVectemporary evaluation vector (if user input is v<double>); Bool_tfVerboseverbosity. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Reader(const TString& theOption = """", Bool_t verbose = 0); constructor. Reader(vector<TString>& varNames, const TString& theOption = """", Bool_t verbose = 0); constructor. Reader(vector<std::string>& varNames, const TString& theOption = """", Bool_t verbose = 0); constructor. Reader( const std::string& varNames, const TString& theOption, Bool_t verbose ); constructor. Reader(const TString& varNames, const TString& theOption, Bool_t verbose = 0); constructor. void DeclareOptions(); declaration of configuration options. ~Reader( void ); destructor. void Init( void ); default initialisation (no member variables); default initialisation (no member variables). void AddVariable(const TString& expression, Float_t* ); Add a float variable or expression to the reader. void AddVariable(const TString& expression, Int_t* ). void AddSpectator(const TString& expression, Float_t* ); Add a float spectator or expression to the reader. void AddSpectator(const TString& expression, Int_t* ); Add an integer spectator or expression to the reader. TString GetMethodTypeFromFile(const TString& filename); read the method type from the file. TMVA::IMethod* BookMVA(const TString& methodTag, const TString& weightfile); read method name from weight file. TMVA::IMethod* BookMVA(TMVA::Types::EMVA method, const TString& weightfile); books MVA method from weightfile. TMVA::IMethod* BookMVA(TMVA::Types::EMVA methodType, const char* xmlstr). Double_t EvaluateMVA( const std::vector<Float_t>& inputVec, const TString& methodTag, Double_t aux ); Evaluate a vector<float> of input data for a given method; The parameter aux is obligatory for the cuts method where it represents the efficiency cutoff. Double_t EvaluateMVA( const st",MatchSource.WIKI,root/html532/TMVA__Reader.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Reader.html
https://root.cern/root/html532/TMVA__Reader.html:13046,Modifiability,variab,variables,13046,"r spectator or expression to the reader. TString GetMethodTypeFromFile(const TString& filename); read the method type from the file. TMVA::IMethod* BookMVA(const TString& methodTag, const TString& weightfile); read method name from weight file. TMVA::IMethod* BookMVA(TMVA::Types::EMVA method, const TString& weightfile); books MVA method from weightfile. TMVA::IMethod* BookMVA(TMVA::Types::EMVA methodType, const char* xmlstr). Double_t EvaluateMVA( const std::vector<Float_t>& inputVec, const TString& methodTag, Double_t aux ); Evaluate a vector<float> of input data for a given method; The parameter aux is obligatory for the cuts method where it represents the efficiency cutoff. Double_t EvaluateMVA( const std::vector<Double_t>& inputVec, const TString& methodTag, Double_t aux ); Evaluate a vector<double> of input data for a given method; The parameter aux is obligatory for the cuts method where it represents the efficiency cutoff. Double_t EvaluateMVA(const TString& methodTag, Double_t aux = 0); evaluates MVA for given set of input variables. Double_t EvaluateMVA(TMVA::MethodBase* method, Double_t aux = 0); evaluates the MVA. const std::vector< Float_t >& EvaluateRegression(const TString& methodTag, Double_t aux = 0); evaluates MVA for given set of input variables. const std::vector< Float_t >& EvaluateRegression(TMVA::MethodBase* method, Double_t aux = 0); evaluates the regression MVA. Float_t EvaluateRegression(UInt_t tgtNumber, const TString& methodTag, Double_t aux = 0); evaluates the regression MVA. const std::vector< Float_t >& EvaluateMulticlass(const TString& methodTag, Double_t aux = 0); evaluates MVA for given set of input variables. const std::vector< Float_t >& EvaluateMulticlass(TMVA::MethodBase* method, Double_t aux = 0); evaluates the multiclass MVA. Float_t EvaluateMulticlass(UInt_t clsNumber, const TString& methodTag, Double_t aux = 0); evaluates the multiclass MVA. TMVA::IMethod* FindMVA(const TString& methodTag); return pointer to method with tag """,MatchSource.WIKI,root/html532/TMVA__Reader.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Reader.html
https://root.cern/root/html532/TMVA__Reader.html:13273,Modifiability,variab,variables,13273,"d method name from weight file. TMVA::IMethod* BookMVA(TMVA::Types::EMVA method, const TString& weightfile); books MVA method from weightfile. TMVA::IMethod* BookMVA(TMVA::Types::EMVA methodType, const char* xmlstr). Double_t EvaluateMVA( const std::vector<Float_t>& inputVec, const TString& methodTag, Double_t aux ); Evaluate a vector<float> of input data for a given method; The parameter aux is obligatory for the cuts method where it represents the efficiency cutoff. Double_t EvaluateMVA( const std::vector<Double_t>& inputVec, const TString& methodTag, Double_t aux ); Evaluate a vector<double> of input data for a given method; The parameter aux is obligatory for the cuts method where it represents the efficiency cutoff. Double_t EvaluateMVA(const TString& methodTag, Double_t aux = 0); evaluates MVA for given set of input variables. Double_t EvaluateMVA(TMVA::MethodBase* method, Double_t aux = 0); evaluates the MVA. const std::vector< Float_t >& EvaluateRegression(const TString& methodTag, Double_t aux = 0); evaluates MVA for given set of input variables. const std::vector< Float_t >& EvaluateRegression(TMVA::MethodBase* method, Double_t aux = 0); evaluates the regression MVA. Float_t EvaluateRegression(UInt_t tgtNumber, const TString& methodTag, Double_t aux = 0); evaluates the regression MVA. const std::vector< Float_t >& EvaluateMulticlass(const TString& methodTag, Double_t aux = 0); evaluates MVA for given set of input variables. const std::vector< Float_t >& EvaluateMulticlass(TMVA::MethodBase* method, Double_t aux = 0); evaluates the multiclass MVA. Float_t EvaluateMulticlass(UInt_t clsNumber, const TString& methodTag, Double_t aux = 0); evaluates the multiclass MVA. TMVA::IMethod* FindMVA(const TString& methodTag); return pointer to method with tag ""methodTag"". TMVA::MethodCuts* FindCutsMVA(const TString& methodTag); special function for Cuts to avoid dynamic_casts in ROOT macros,; which are not properly handled by CINT. Double_t GetProba(const TString& metho",MatchSource.WIKI,root/html532/TMVA__Reader.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Reader.html
https://root.cern/root/html532/TMVA__Reader.html:13659,Modifiability,variab,variables,13659,"meter aux is obligatory for the cuts method where it represents the efficiency cutoff. Double_t EvaluateMVA( const std::vector<Double_t>& inputVec, const TString& methodTag, Double_t aux ); Evaluate a vector<double> of input data for a given method; The parameter aux is obligatory for the cuts method where it represents the efficiency cutoff. Double_t EvaluateMVA(const TString& methodTag, Double_t aux = 0); evaluates MVA for given set of input variables. Double_t EvaluateMVA(TMVA::MethodBase* method, Double_t aux = 0); evaluates the MVA. const std::vector< Float_t >& EvaluateRegression(const TString& methodTag, Double_t aux = 0); evaluates MVA for given set of input variables. const std::vector< Float_t >& EvaluateRegression(TMVA::MethodBase* method, Double_t aux = 0); evaluates the regression MVA. Float_t EvaluateRegression(UInt_t tgtNumber, const TString& methodTag, Double_t aux = 0); evaluates the regression MVA. const std::vector< Float_t >& EvaluateMulticlass(const TString& methodTag, Double_t aux = 0); evaluates MVA for given set of input variables. const std::vector< Float_t >& EvaluateMulticlass(TMVA::MethodBase* method, Double_t aux = 0); evaluates the multiclass MVA. Float_t EvaluateMulticlass(UInt_t clsNumber, const TString& methodTag, Double_t aux = 0); evaluates the multiclass MVA. TMVA::IMethod* FindMVA(const TString& methodTag); return pointer to method with tag ""methodTag"". TMVA::MethodCuts* FindCutsMVA(const TString& methodTag); special function for Cuts to avoid dynamic_casts in ROOT macros,; which are not properly handled by CINT. Double_t GetProba(const TString& methodTag, Double_t ap_sig = 0.5, Double_t mvaVal = -9999999); evaluates probability of MVA for given set of input variables. Double_t GetRarity(const TString& methodTag, Double_t mvaVal = -9999999); evaluates the MVA's rarity. void DecodeVarNames( const std::string& varNames ); decodes ""name1:name2:..."" form. void DecodeVarNames(const TString& varNames); decodes ""name1:name2:..."" form. D",MatchSource.WIKI,root/html532/TMVA__Reader.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Reader.html
https://root.cern/root/html532/TMVA__Reader.html:14322,Modifiability,variab,variables,14322,"onst std::vector< Float_t >& EvaluateRegression(TMVA::MethodBase* method, Double_t aux = 0); evaluates the regression MVA. Float_t EvaluateRegression(UInt_t tgtNumber, const TString& methodTag, Double_t aux = 0); evaluates the regression MVA. const std::vector< Float_t >& EvaluateMulticlass(const TString& methodTag, Double_t aux = 0); evaluates MVA for given set of input variables. const std::vector< Float_t >& EvaluateMulticlass(TMVA::MethodBase* method, Double_t aux = 0); evaluates the multiclass MVA. Float_t EvaluateMulticlass(UInt_t clsNumber, const TString& methodTag, Double_t aux = 0); evaluates the multiclass MVA. TMVA::IMethod* FindMVA(const TString& methodTag); return pointer to method with tag ""methodTag"". TMVA::MethodCuts* FindCutsMVA(const TString& methodTag); special function for Cuts to avoid dynamic_casts in ROOT macros,; which are not properly handled by CINT. Double_t GetProba(const TString& methodTag, Double_t ap_sig = 0.5, Double_t mvaVal = -9999999); evaluates probability of MVA for given set of input variables. Double_t GetRarity(const TString& methodTag, Double_t mvaVal = -9999999); evaluates the MVA's rarity. void DecodeVarNames( const std::string& varNames ); decodes ""name1:name2:..."" form. void DecodeVarNames(const TString& varNames); decodes ""name1:name2:..."" form. Double_t GetMVAError() const; returns error on MVA response for given event; NOTE: must be called AFTER ""EvaluateMVA(...)"" call !. { return fMvaEventError; }. Double_t GetMVAErrorLower() const; { return fMvaEventError; }. Double_t GetMVAErrorUpper() const; { return fMvaEventErrorUpper; }. const char* GetName() const; accessors. { return ""Reader""; }. Bool_t Verbose( void ); { return fVerbose; }. void SetVerbose(Bool_t v); { fVerbose = v; }. const DataSetInfo& DataInfo() const; { return fDataSetInfo; }. DataSetInfo& DataInfo(); { return fDataSetInfo; }. » Author: Andreas Hoecker, Peter Speckmayer, Joerg Stelzer, Helge Voss, Kai Voss, Eckhard von Toerne, Jan Therhaag » Copyright (c)",MatchSource.WIKI,root/html532/TMVA__Reader.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Reader.html
https://root.cern/root/html532/TMVA__Reader.html:14097,Safety,avoid,avoid,14097,"ase* method, Double_t aux = 0); evaluates the MVA. const std::vector< Float_t >& EvaluateRegression(const TString& methodTag, Double_t aux = 0); evaluates MVA for given set of input variables. const std::vector< Float_t >& EvaluateRegression(TMVA::MethodBase* method, Double_t aux = 0); evaluates the regression MVA. Float_t EvaluateRegression(UInt_t tgtNumber, const TString& methodTag, Double_t aux = 0); evaluates the regression MVA. const std::vector< Float_t >& EvaluateMulticlass(const TString& methodTag, Double_t aux = 0); evaluates MVA for given set of input variables. const std::vector< Float_t >& EvaluateMulticlass(TMVA::MethodBase* method, Double_t aux = 0); evaluates the multiclass MVA. Float_t EvaluateMulticlass(UInt_t clsNumber, const TString& methodTag, Double_t aux = 0); evaluates the multiclass MVA. TMVA::IMethod* FindMVA(const TString& methodTag); return pointer to method with tag ""methodTag"". TMVA::MethodCuts* FindCutsMVA(const TString& methodTag); special function for Cuts to avoid dynamic_casts in ROOT macros,; which are not properly handled by CINT. Double_t GetProba(const TString& methodTag, Double_t ap_sig = 0.5, Double_t mvaVal = -9999999); evaluates probability of MVA for given set of input variables. Double_t GetRarity(const TString& methodTag, Double_t mvaVal = -9999999); evaluates the MVA's rarity. void DecodeVarNames( const std::string& varNames ); decodes ""name1:name2:..."" form. void DecodeVarNames(const TString& varNames); decodes ""name1:name2:..."" form. Double_t GetMVAError() const; returns error on MVA response for given event; NOTE: must be called AFTER ""EvaluateMVA(...)"" call !. { return fMvaEventError; }. Double_t GetMVAErrorLower() const; { return fMvaEventError; }. Double_t GetMVAErrorUpper() const; { return fMvaEventErrorUpper; }. const char* GetName() const; accessors. { return ""Reader""; }. Bool_t Verbose( void ); { return fVerbose; }. void SetVerbose(Bool_t v); { fVerbose = v; }. const DataSetInfo& DataInfo() const; { return fData",MatchSource.WIKI,root/html532/TMVA__Reader.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Reader.html
https://root.cern/root/html532/TMVA__Reader.html:14916,Security,access,accessors,14916,"lticlass(const TString& methodTag, Double_t aux = 0); evaluates MVA for given set of input variables. const std::vector< Float_t >& EvaluateMulticlass(TMVA::MethodBase* method, Double_t aux = 0); evaluates the multiclass MVA. Float_t EvaluateMulticlass(UInt_t clsNumber, const TString& methodTag, Double_t aux = 0); evaluates the multiclass MVA. TMVA::IMethod* FindMVA(const TString& methodTag); return pointer to method with tag ""methodTag"". TMVA::MethodCuts* FindCutsMVA(const TString& methodTag); special function for Cuts to avoid dynamic_casts in ROOT macros,; which are not properly handled by CINT. Double_t GetProba(const TString& methodTag, Double_t ap_sig = 0.5, Double_t mvaVal = -9999999); evaluates probability of MVA for given set of input variables. Double_t GetRarity(const TString& methodTag, Double_t mvaVal = -9999999); evaluates the MVA's rarity. void DecodeVarNames( const std::string& varNames ); decodes ""name1:name2:..."" form. void DecodeVarNames(const TString& varNames); decodes ""name1:name2:..."" form. Double_t GetMVAError() const; returns error on MVA response for given event; NOTE: must be called AFTER ""EvaluateMVA(...)"" call !. { return fMvaEventError; }. Double_t GetMVAErrorLower() const; { return fMvaEventError; }. Double_t GetMVAErrorUpper() const; { return fMvaEventErrorUpper; }. const char* GetName() const; accessors. { return ""Reader""; }. Bool_t Verbose( void ); { return fVerbose; }. void SetVerbose(Bool_t v); { fVerbose = v; }. const DataSetInfo& DataInfo() const; { return fDataSetInfo; }. DataSetInfo& DataInfo(); { return fDataSetInfo; }. » Author: Andreas Hoecker, Peter Speckmayer, Joerg Stelzer, Helge Voss, Kai Voss, Eckhard von Toerne, Jan Therhaag » Copyright (c) 2005-2011: *; » Last changed: root/tmva $Id: Reader.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Reader.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Reader.html
https://root.cern/root/html532/TMVA__Reader.html:10606,Testability,log,logger,10606,"seOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. TMVA::IMethod*BookMVA(TMVA::Types::EMVA method, const TString& weightfile); voidDeclareOptions(); voidDecodeVarNames(const string& varNames); voidDecodeVarNames(const TString& varNames); TStringGetMethodTypeFromFile(const TString& filename); voidInit(); TMVA::MsgLogger&Log() const. Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. Bool_tfCalculateErrorerror calculation mode; Bool_tfColorcolor mode; TMVA::DataInputHandlerfDataInputHandler; TMVA::DataSetInfofDataSetInfothe data set; TMVA::DataSetManager*fDataSetManagerDSMTEST; TMVA::MsgLogger*fLoggermessage logger; map<TString,IMethod*>fMethodMapmap of methods; Double_tfMvaEventErrorper-event error returned by MVA; Double_tfMvaEventErrorUpperper-event error returned by MVA; Bool_tfSilentsilent mode; vector<Float_t>fTmpEvalVectemporary evaluation vector (if user input is v<double>); Bool_tfVerboseverbosity. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Reader(const TString& theOption = """", Bool_t verbose = 0); constructor. Reader(vector<TString>& varNames, const TString& theOption = """", Bool_t verbose = 0); constructor. Reader(vector<std::string>& varNames, const TString& theOption = """", Bool_t verbose = 0); constructor. Reader( const std::string& varNames, const TString& theOption, Bool_t verbose ); constructor. Reader(const TString& varNames, const TString& theOption, Bool_t verbose = 0); constructor. void DeclareOptions(); declaration of configuration options. ~Reader( void ); destructor. void Init( void ); default initialisation (no member variables); default initialisation (no",MatchSource.WIKI,root/html532/TMVA__Reader.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Reader.html
https://root.cern/root/html532/TMVA__RegressionVariance.html:1679,Performance,optimiz,optimized,1679,"ual TClass*IsA() const; TMVA::RegressionVariance&operator=(const TMVA::RegressionVariance&); TMVA::RegressionVarianceRegressionVariance(); TMVA::RegressionVarianceRegressionVariance(const TMVA::RegressionVariance& s); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). Data Members; protected:. TStringfNamename of the concrete Separation Index impementation. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Double_t GetSeparationGain(const Double_t& nLeft, const Double_t& targetLeft, const Double_t& target2Left, const Double_t& nTot, const Double_t& targetTot, const Double_t& target2Tot); Separation Gain:; the measure of how the quality of separation of the sample increases; by splitting the sample e.g. into a ""left-node"" and a ""right-node""; (N * Index_parent) - (N_left * Index_left) - (N_right * Index_right); this is then the quality crition which is optimized for when trying; to increase the information in the system; for the Regression: as the ""Gain is maximised"", the RMS (sqrt(variance)); which is used as a ""separation"" index should be as small as possible.; the ""figure of merit"" here has to be -(rms left+rms-right) or 1/rms... Double_t GetSeparationIndex(const Double_t& n, const Double_t& target, const Double_t& target2); Separation Index: a simple Variance. RegressionVariance(); default constructor. {fName = ""Variance for Regression"";}. RegressionVariance(const TMVA::RegressionVariance& s); copy constructor. {}. virtual ~RegressionVariance(); destructor. {}. TString GetName(); Return the name of the concrete Index implementation. { return fName; }. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: RegressionVariance.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:20; This page has been automatically generated. For comments or suggestions regarding the documentation o",MatchSource.WIKI,root/html532/TMVA__RegressionVariance.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__RegressionVariance.html
https://root.cern/root/html532/TMVA__RegressionVariance.html:2082,Usability,simpl,simple,2082,"or=(const TMVA::RegressionVariance&); TMVA::RegressionVarianceRegressionVariance(); TMVA::RegressionVarianceRegressionVariance(const TMVA::RegressionVariance& s); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). Data Members; protected:. TStringfNamename of the concrete Separation Index impementation. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Double_t GetSeparationGain(const Double_t& nLeft, const Double_t& targetLeft, const Double_t& target2Left, const Double_t& nTot, const Double_t& targetTot, const Double_t& target2Tot); Separation Gain:; the measure of how the quality of separation of the sample increases; by splitting the sample e.g. into a ""left-node"" and a ""right-node""; (N * Index_parent) - (N_left * Index_left) - (N_right * Index_right); this is then the quality crition which is optimized for when trying; to increase the information in the system; for the Regression: as the ""Gain is maximised"", the RMS (sqrt(variance)); which is used as a ""separation"" index should be as small as possible.; the ""figure of merit"" here has to be -(rms left+rms-right) or 1/rms... Double_t GetSeparationIndex(const Double_t& n, const Double_t& target, const Double_t& target2); Separation Index: a simple Variance. RegressionVariance(); default constructor. {fName = ""Variance for Regression"";}. RegressionVariance(const TMVA::RegressionVariance& s); copy constructor. {}. virtual ~RegressionVariance(); destructor. {}. TString GetName(); Return the name of the concrete Index implementation. { return fName; }. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: RegressionVariance.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:20; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__RegressionVariance.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__RegressionVariance.html
https://root.cern/root/html532/TMVA__RootFinder.html:1272,Availability,error,error,1272," virtual~RootFinder(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TObject::GetTitle() c",MatchSource.WIKI,root/html532/TMVA__RootFinder.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__RootFinder.html
https://root.cern/root/html532/TMVA__RootFinder.html:1356,Availability,error,error,1356," voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTObject",MatchSource.WIKI,root/html532/TMVA__RootFinder.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__RootFinder.html
https://root.cern/root/html532/TMVA__RootFinder.html:5341,Availability,toler,tolerance,5341,"r(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTObject::MakeZombie(). private:. TMVA::MsgLogger&Log() const. Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. Double_tfAbsTolabsolute tolerance deviation; Double_t (*)(Double_t)fGetRootVal; TMVA::MsgLogger*fLogger! message logger; Int_tfMaxItermaximum number of iterations; Double_tfRootMaxmaximum root value; Double_tfRootMinminimum root value. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; RootFinder(Double_t (*)(Double_t) rootVal, Double_t rootMin, Double_t rootMax, Int_t maxIterations = 100, Double_t absTolerance = 0.0); constructor. ~RootFinder( void ); destructor. Double_t Root(Double_t refValue); Root finding using Brents algorithm; taken from CERNLIB function RZERO. RootFinder(Double_t (*)(Double_t) rootVal, Double_t rootMin, Double_t rootMax, Int_t maxIterations = 100, Double_t absTolerance = 0.0). » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: RootFinder.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:20; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__RootFinder.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__RootFinder.html
https://root.cern/root/html532/TMVA__RootFinder.html:5422,Integrability,message,message,5422,"r(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTObject::MakeZombie(). private:. TMVA::MsgLogger&Log() const. Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. Double_tfAbsTolabsolute tolerance deviation; Double_t (*)(Double_t)fGetRootVal; TMVA::MsgLogger*fLogger! message logger; Int_tfMaxItermaximum number of iterations; Double_tfRootMaxmaximum root value; Double_tfRootMinminimum root value. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; RootFinder(Double_t (*)(Double_t) rootVal, Double_t rootMin, Double_t rootMax, Int_t maxIterations = 100, Double_t absTolerance = 0.0); constructor. ~RootFinder( void ); destructor. Double_t Root(Double_t refValue); Root finding using Brents algorithm; taken from CERNLIB function RZERO. RootFinder(Double_t (*)(Double_t) rootVal, Double_t rootMin, Double_t rootMax, Int_t maxIterations = 100, Double_t absTolerance = 0.0). » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: RootFinder.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:20; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__RootFinder.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__RootFinder.html
https://root.cern/root/html532/TMVA__RootFinder.html:5430,Testability,log,logger,5430,"r(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTObject::MakeZombie(). private:. TMVA::MsgLogger&Log() const. Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. Double_tfAbsTolabsolute tolerance deviation; Double_t (*)(Double_t)fGetRootVal; TMVA::MsgLogger*fLogger! message logger; Int_tfMaxItermaximum number of iterations; Double_tfRootMaxmaximum root value; Double_tfRootMinminimum root value. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; RootFinder(Double_t (*)(Double_t) rootVal, Double_t rootMin, Double_t rootMax, Int_t maxIterations = 100, Double_t absTolerance = 0.0); constructor. ~RootFinder( void ); destructor. Double_t Root(Double_t refValue); Root finding using Brents algorithm; taken from CERNLIB function RZERO. RootFinder(Double_t (*)(Double_t) rootVal, Double_t rootMin, Double_t rootMax, Int_t maxIterations = 100, Double_t absTolerance = 0.0). » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: RootFinder.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:20; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__RootFinder.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__RootFinder.html
https://root.cern/root/html532/TMVA__RuleFit.html:4398,Integrability,message,message,4398,"Eventsall training events; vector<TMVA::Event*>fTrainingEventsRndmidem, but randomly shuffled; Bool_tfVisHistsUseImpif true, use importance as weight; else coef in vis hists; static const Int_trandSEEDset to 1 for debugging purposes or to zero for random seeds. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; RuleFit( const MethodBase *rfbase ); constructor. RuleFit(); default constructor. ~RuleFit(); destructor. void InitNEveEff(); init effective number of events (using event weights). void InitPtrs(const TMVA::MethodBase* rfbase); initialize pointers. void Initialize(const TMVA::MethodBase* rfbase); initialize the parameters of the RuleFit method and make rules. void SetMethodBase(const TMVA::MethodBase* rfbase); set MethodBase. void Copy(const TMVA::RuleFit& other); copy method. Double_t CalcWeightSum(const vector<TMVA::Event*>* events, UInt_t neve = 0); calculate the sum of weights. void SetMsgType(TMVA::EMsgType t); set the current message type to that of mlog for this class and all other subtools. void BuildTree(TMVA::DecisionTree* dt); build the decision tree using fNTreeSample events from fTrainingEventsRndm. void MakeForest(); make a forest of decisiontrees. void SaveEventWeights(); save event weights - must be done before making the forest. void RestoreEventWeights(); save event weights - must be done before making the forest. void Boost(TMVA::DecisionTree* dt); Boost the events. The algorithm below is the called AdaBoost.; See MethodBDT for details.; Actually, this is a more or less copy of MethodBDT::AdaBoost(). void ForestStatistics(); summary of statistics of all trees; * end-nodes: average and spread. void FitCoefficients(). Fit the coefficients for the rule ensemble. void CalcImportance(); calculates the importance of each rule. Double_t EvalEvent(const TMVA::Event& e); evaluate single event. void SetTrainingEvents(const vector<TMVA::Event*>& el); set the training events randomly. void GetRndmSampleEvents(vect",MatchSource.WIKI,root/html532/TMVA__RuleFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__RuleFit.html
https://root.cern/root/html532/TMVA__RuleFit.html:6090,Integrability,rout,routine,6090,"and spread. void FitCoefficients(). Fit the coefficients for the rule ensemble. void CalcImportance(); calculates the importance of each rule. Double_t EvalEvent(const TMVA::Event& e); evaluate single event. void SetTrainingEvents(const vector<TMVA::Event*>& el); set the training events randomly. void GetRndmSampleEvents(vector<const TMVA::Event*>& evevec, UInt_t nevents); draw a random subsample of the training events without replacement. void NormVisHists(vector<TH2F*>& hlist); normalize rule importance hists. if all weights are positive, the scale will be 1/maxweight; if minimum weight < 0, then the scale will be 1/max(maxweight,abs(minweight)). void FillCut(TH2F* h2, const TMVA::Rule* rule, Int_t vind); Fill cut. void FillLin(TH2F* h2, Int_t vind); fill lin. void FillCorr(TH2F* h2, const TMVA::Rule* rule, Int_t v1, Int_t v2); fill rule correlation between vx and vy, weighted with either the importance or the coefficient. void FillVisHistCut(const TMVA::Rule* rule, vector<TH2F*>& hlist); help routine to MakeVisHists() - fills for all variables. void FillVisHistCorr(const TMVA::Rule* rule, vector<TH2F*>& hlist); help routine to MakeVisHists() - fills for all correlation plots. Bool_t GetCorrVars(TString& title, TString& var1, TString& var2); get first and second variables from title. void MakeVisHists(); this will create histograms visualizing the rule ensemble. void MakeDebugHists(); this will create a histograms intended rather for debugging or for the curious user. RuleFit(const TMVA::MethodBase* rfbase); main constructor. void ReshuffleEvents(); { std::random_shuffle(fTrainingEventsRndm.begin(),fTrainingEventsRndm.end()); }. void SetModelLinear(); set usage of linear term. { fRuleEnsemble.SetModelLinear(); }. void SetModelRules(); set usage of rules. { fRuleEnsemble.SetModelRules(); }. void SetModelFull(); set usage of linear term. { fRuleEnsemble.SetModelFull(); }. void SetImportanceCut(Double_t minimp = 0); set minimum importance allowed. { fRuleEnsemble.SetI",MatchSource.WIKI,root/html532/TMVA__RuleFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__RuleFit.html
https://root.cern/root/html532/TMVA__RuleFit.html:6216,Integrability,rout,routine,6216,"f each rule. Double_t EvalEvent(const TMVA::Event& e); evaluate single event. void SetTrainingEvents(const vector<TMVA::Event*>& el); set the training events randomly. void GetRndmSampleEvents(vector<const TMVA::Event*>& evevec, UInt_t nevents); draw a random subsample of the training events without replacement. void NormVisHists(vector<TH2F*>& hlist); normalize rule importance hists. if all weights are positive, the scale will be 1/maxweight; if minimum weight < 0, then the scale will be 1/max(maxweight,abs(minweight)). void FillCut(TH2F* h2, const TMVA::Rule* rule, Int_t vind); Fill cut. void FillLin(TH2F* h2, Int_t vind); fill lin. void FillCorr(TH2F* h2, const TMVA::Rule* rule, Int_t v1, Int_t v2); fill rule correlation between vx and vy, weighted with either the importance or the coefficient. void FillVisHistCut(const TMVA::Rule* rule, vector<TH2F*>& hlist); help routine to MakeVisHists() - fills for all variables. void FillVisHistCorr(const TMVA::Rule* rule, vector<TH2F*>& hlist); help routine to MakeVisHists() - fills for all correlation plots. Bool_t GetCorrVars(TString& title, TString& var1, TString& var2); get first and second variables from title. void MakeVisHists(); this will create histograms visualizing the rule ensemble. void MakeDebugHists(); this will create a histograms intended rather for debugging or for the curious user. RuleFit(const TMVA::MethodBase* rfbase); main constructor. void ReshuffleEvents(); { std::random_shuffle(fTrainingEventsRndm.begin(),fTrainingEventsRndm.end()); }. void SetModelLinear(); set usage of linear term. { fRuleEnsemble.SetModelLinear(); }. void SetModelRules(); set usage of rules. { fRuleEnsemble.SetModelRules(); }. void SetModelFull(); set usage of linear term. { fRuleEnsemble.SetModelFull(); }. void SetImportanceCut(Double_t minimp = 0); set minimum importance allowed. { fRuleEnsemble.SetImportanceCut(minimp); }. void SetRuleMinDist(Double_t d); set minimum rule distance - see RuleEnsemble. { fRuleEnsemble.SetRuleMi",MatchSource.WIKI,root/html532/TMVA__RuleFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__RuleFit.html
https://root.cern/root/html532/TMVA__RuleFit.html:6132,Modifiability,variab,variables,6132,"and spread. void FitCoefficients(). Fit the coefficients for the rule ensemble. void CalcImportance(); calculates the importance of each rule. Double_t EvalEvent(const TMVA::Event& e); evaluate single event. void SetTrainingEvents(const vector<TMVA::Event*>& el); set the training events randomly. void GetRndmSampleEvents(vector<const TMVA::Event*>& evevec, UInt_t nevents); draw a random subsample of the training events without replacement. void NormVisHists(vector<TH2F*>& hlist); normalize rule importance hists. if all weights are positive, the scale will be 1/maxweight; if minimum weight < 0, then the scale will be 1/max(maxweight,abs(minweight)). void FillCut(TH2F* h2, const TMVA::Rule* rule, Int_t vind); Fill cut. void FillLin(TH2F* h2, Int_t vind); fill lin. void FillCorr(TH2F* h2, const TMVA::Rule* rule, Int_t v1, Int_t v2); fill rule correlation between vx and vy, weighted with either the importance or the coefficient. void FillVisHistCut(const TMVA::Rule* rule, vector<TH2F*>& hlist); help routine to MakeVisHists() - fills for all variables. void FillVisHistCorr(const TMVA::Rule* rule, vector<TH2F*>& hlist); help routine to MakeVisHists() - fills for all correlation plots. Bool_t GetCorrVars(TString& title, TString& var1, TString& var2); get first and second variables from title. void MakeVisHists(); this will create histograms visualizing the rule ensemble. void MakeDebugHists(); this will create a histograms intended rather for debugging or for the curious user. RuleFit(const TMVA::MethodBase* rfbase); main constructor. void ReshuffleEvents(); { std::random_shuffle(fTrainingEventsRndm.begin(),fTrainingEventsRndm.end()); }. void SetModelLinear(); set usage of linear term. { fRuleEnsemble.SetModelLinear(); }. void SetModelRules(); set usage of rules. { fRuleEnsemble.SetModelRules(); }. void SetModelFull(); set usage of linear term. { fRuleEnsemble.SetModelFull(); }. void SetImportanceCut(Double_t minimp = 0); set minimum importance allowed. { fRuleEnsemble.SetI",MatchSource.WIKI,root/html532/TMVA__RuleFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__RuleFit.html
https://root.cern/root/html532/TMVA__RuleFit.html:6364,Modifiability,variab,variables,6364,"vent*>& el); set the training events randomly. void GetRndmSampleEvents(vector<const TMVA::Event*>& evevec, UInt_t nevents); draw a random subsample of the training events without replacement. void NormVisHists(vector<TH2F*>& hlist); normalize rule importance hists. if all weights are positive, the scale will be 1/maxweight; if minimum weight < 0, then the scale will be 1/max(maxweight,abs(minweight)). void FillCut(TH2F* h2, const TMVA::Rule* rule, Int_t vind); Fill cut. void FillLin(TH2F* h2, Int_t vind); fill lin. void FillCorr(TH2F* h2, const TMVA::Rule* rule, Int_t v1, Int_t v2); fill rule correlation between vx and vy, weighted with either the importance or the coefficient. void FillVisHistCut(const TMVA::Rule* rule, vector<TH2F*>& hlist); help routine to MakeVisHists() - fills for all variables. void FillVisHistCorr(const TMVA::Rule* rule, vector<TH2F*>& hlist); help routine to MakeVisHists() - fills for all correlation plots. Bool_t GetCorrVars(TString& title, TString& var1, TString& var2); get first and second variables from title. void MakeVisHists(); this will create histograms visualizing the rule ensemble. void MakeDebugHists(); this will create a histograms intended rather for debugging or for the curious user. RuleFit(const TMVA::MethodBase* rfbase); main constructor. void ReshuffleEvents(); { std::random_shuffle(fTrainingEventsRndm.begin(),fTrainingEventsRndm.end()); }. void SetModelLinear(); set usage of linear term. { fRuleEnsemble.SetModelLinear(); }. void SetModelRules(); set usage of rules. { fRuleEnsemble.SetModelRules(); }. void SetModelFull(); set usage of linear term. { fRuleEnsemble.SetModelFull(); }. void SetImportanceCut(Double_t minimp = 0); set minimum importance allowed. { fRuleEnsemble.SetImportanceCut(minimp); }. void SetRuleMinDist(Double_t d); set minimum rule distance - see RuleEnsemble. { fRuleEnsemble.SetRuleMinDist(d); }. void SetGDTau(Double_t t = 0.0); set path related parameters. { fRuleFitParams.SetGDTau(t); }. void SetGDPath",MatchSource.WIKI,root/html532/TMVA__RuleFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__RuleFit.html
https://root.cern/root/html532/TMVA__RuleFit.html:7716,Security,access,accessors,7716,"),fTrainingEventsRndm.end()); }. void SetModelLinear(); set usage of linear term. { fRuleEnsemble.SetModelLinear(); }. void SetModelRules(); set usage of rules. { fRuleEnsemble.SetModelRules(); }. void SetModelFull(); set usage of linear term. { fRuleEnsemble.SetModelFull(); }. void SetImportanceCut(Double_t minimp = 0); set minimum importance allowed. { fRuleEnsemble.SetImportanceCut(minimp); }. void SetRuleMinDist(Double_t d); set minimum rule distance - see RuleEnsemble. { fRuleEnsemble.SetRuleMinDist(d); }. void SetGDTau(Double_t t = 0.0); set path related parameters. { fRuleFitParams.SetGDTau(t); }. void SetGDPathStep(Double_t s = 0.01); { fRuleFitParams.SetGDPathStep(s); }. void SetGDNPathSteps(Int_t n = 100); make visualization histograms. { fRuleFitParams.SetGDNPathSteps(n); }. void SetVisHistsUseImp(Bool_t f); { fVisHistsUseImp = f; }. void UseImportanceVisHists(); { fVisHistsUseImp = kTRUE; }. void UseCoefficientsVisHists(); { fVisHistsUseImp = kFALSE; }. UInt_t GetNTreeSample() const; accessors. { return fNTreeSample; }. Double_t GetNEveEff() const; { return fNEveEffTrain; }. const Event* GetTrainingEvent(UInt_t i) const; { return static_cast< const Event *>(fTrainingEvents[i]); }. Double_t GetTrainingEventWeight(UInt_t i) const; { return fTrainingEvents[i]->GetWeight(); }. const std::vector< TMVA::Event * > & GetTrainingEvents() const; const Event* GetTrainingEvent(UInt_t i, UInt_t isub) const { return &(fTrainingEvents[fSubsampleEvents[isub]])[i]; }. { return fTrainingEvents; }. const std::vector< const TMVA::DecisionTree *> & GetForest() const. { return fForest; }. const RuleEnsemble & GetRuleEnsemble() const; { return fRuleEnsemble; }. RuleEnsemble * GetRuleEnsemblePtr(); { return &fRuleEnsemble; }. const RuleFitParams & GetRuleFitParams() const; { return fRuleFitParams; }. RuleFitParams * GetRuleFitParamsPtr(); { return &fRuleFitParams; }. const MethodRuleFit * GetMethodRuleFit() const; { return fMethodRuleFit; }. const MethodBase * GetMethodBase() c",MatchSource.WIKI,root/html532/TMVA__RuleFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__RuleFit.html
https://root.cern/root/html532/TMVA__RuleFit.html:2939,Testability,log,logger,2939,"etModelFull(); voidSetModelLinear(); voidSetModelRules(); voidSetMsgType(TMVA::EMsgType t); voidSetRuleMinDist(Double_t d); voidSetTrainingEvents(const vector<TMVA::Event*>& el); voidSetVisHistsUseImp(Bool_t f); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); voidUseCoefficientsVisHists(); voidUseImportanceVisHists(). private:. voidCopy(const TMVA::RuleFit& other); TMVA::MsgLogger&Log() const; TMVA::RuleFitRuleFit(const TMVA::RuleFit& other). Data Members; private:. vector<Double_t>fEventWeightsoriginal weights of the events - follows fTrainingEvents; vector<const TMVA::DecisionTree*>fForestthe input forest of decision trees; TMVA::MsgLogger*fLoggermessage logger; const TMVA::MethodBase*fMethodBasepointer the method base which initialized this RuleFit instance; const TMVA::MethodRuleFit*fMethodRuleFitpointer the method which initialized this RuleFit instance; Double_tfNEveEffTrainreweighted number of events = sum(wi); UInt_tfNTreeSamplenumber of events in sub sample = frac*neve; TMVA::RuleEnsemblefRuleEnsemblethe ensemble of rules; TMVA::RuleFitParamsfRuleFitParamsfit rule parameters; vector<TMVA::Event*>fTrainingEventsall training events; vector<TMVA::Event*>fTrainingEventsRndmidem, but randomly shuffled; Bool_tfVisHistsUseImpif true, use importance as weight; else coef in vis hists; static const Int_trandSEEDset to 1 for debugging purposes or to zero for random seeds. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; RuleFit( const MethodBase *rfbase ); constructor. RuleFit(); default constructor. ~RuleFit(); destructor. void InitNEveEff(); init effective number of events (using event weights). void InitPtrs(const TMVA::MethodBase* rfbase); initialize pointers. void Initialize(const TMVA::MethodBase* rfbase); initialize the parameters of the RuleFit method and make rules. void SetMethodBase(const TMVA::MethodBase* rfbase); set MethodBase. void Copy(const T",MatchSource.WIKI,root/html532/TMVA__RuleFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__RuleFit.html
https://root.cern/root/html532/TMVA__RuleFitAPI.html:3906,Availability,mask,mask,3906,"s Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; RuleFitAPI(const TMVA::MethodRuleFit* rfbase, TMVA::RuleFit* rulefit, TMVA::EMsgType minType); standard constructor. ~RuleFitAPI(); destructor. void WelcomeMessage(); welcome message. void HowtoSetupRF(); howto message. void InitRuleFit(); default initialisation; SetRFWorkDir(""./rulefit"");. void ImportSetup(); import setup from MethodRuleFit. void SetRFWorkDir(const char* wdir); set the directory containing rf_go.exe. void CheckRFWorkDir(); check if the rulefit work dir is properly setup.; it aborts (kFATAL) if not. Check existance of directory. void SetTrainParms(); set the training parameters. void SetTestParms(); set the test params. void FillRealParmsDef(); set default real params. void FillIntParmsDef(); set default int params. Bool_t WriteAll(); write all files read by rf_go.exe. Bool_t WriteIntParms(); write int params file. Bool_t WriteRealParms(); write int params file. Bool_t WriteLx(); Save input variable mask. If the lx vector size is not the same as inputVars,; resize it and fill it with 1; NOTE: Always set all to 1; if (fRFLx.size() != m_inputVars->size()) {. Bool_t WriteProgram(); write command to rf_go.exe. Bool_t WriteRealVarImp(); write the minimum importance to be considered. Bool_t WriteRfOut(); written by rf_go.exe; write rulefit output (rfout). Bool_t WriteRfStatus(); written by rf_go.exe; write rulefit status. Bool_t WriteRuleFitMod(); written by rf_go.exe (NOTE:Format unknown!). Bool_t WriteRuleFitSum(); written by rf_go.exe (NOTE: format unknown!). Bool_t WriteTrain(); write training data, columnwise. Bool_t WriteTest(); Write test data. Bool_t WriteVarNames(); write variable names, ascii. Bool_t WriteVarImp(); written by rf_go.exe. Bool_t WriteYhat(); written by rf_go.exe. Bool_t ReadYhat(); read the score. Bool_t ReadVarImp(); read variable importance. Bool_t ReadModelSum(); read model from rulefit.sum. Int_t RunRuleFit(); execute rf_go.exe. void TrainRu",MatchSource.WIKI,root/html532/TMVA__RuleFitAPI.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__RuleFitAPI.html
https://root.cern/root/html532/TMVA__RuleFitAPI.html:3151,Integrability,message,message,3151,"ERFMode { kRfRegress; kRfClass; };; enum EModel { kRfLinear; kRfRules; kRfBoth; };; enum ERFProgram { kRfTrain; kRfPredict; kRfVarimp; };. private:. TMVA::MsgLoggerfLoggermessage logger; const TMVA::MethodRuleFit*fMethodRuleFitparent method - set in constructor; TStringfModelTypemodel type string; TMVA::RuleFitAPI::IntParmsfRFIntParmsinteger parameters; vector<int>fRFLxvariable selector; TMVA::RuleFitAPI::ERFProgramfRFProgramwhat to run; TMVA::RuleFitAPI::RealParmsfRFRealParmsreal parameters; vector<Float_t>fRFVarImpvariable importances; vector<Int_t>fRFVarImpIndvariable index; TStringfRFWorkDirworking directory; vector<Float_t>fRFYhatscore results from test sample; TMVA::RuleFit*fRuleFitnon const ptr to RuleFit class in MethodRuleFit. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; RuleFitAPI(const TMVA::MethodRuleFit* rfbase, TMVA::RuleFit* rulefit, TMVA::EMsgType minType); standard constructor. ~RuleFitAPI(); destructor. void WelcomeMessage(); welcome message. void HowtoSetupRF(); howto message. void InitRuleFit(); default initialisation; SetRFWorkDir(""./rulefit"");. void ImportSetup(); import setup from MethodRuleFit. void SetRFWorkDir(const char* wdir); set the directory containing rf_go.exe. void CheckRFWorkDir(); check if the rulefit work dir is properly setup.; it aborts (kFATAL) if not. Check existance of directory. void SetTrainParms(); set the training parameters. void SetTestParms(); set the test params. void FillRealParmsDef(); set default real params. void FillIntParmsDef(); set default int params. Bool_t WriteAll(); write all files read by rf_go.exe. Bool_t WriteIntParms(); write int params file. Bool_t WriteRealParms(); write int params file. Bool_t WriteLx(); Save input variable mask. If the lx vector size is not the same as inputVars,; resize it and fill it with 1; NOTE: Always set all to 1; if (fRFLx.size() != m_inputVars->size()) {. Bool_t WriteProgram(); write command to rf_go.exe. Bool_t WriteRealVarImp",MatchSource.WIKI,root/html532/TMVA__RuleFitAPI.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__RuleFitAPI.html
https://root.cern/root/html532/TMVA__RuleFitAPI.html:3187,Integrability,message,message,3187,"um EModel { kRfLinear; kRfRules; kRfBoth; };; enum ERFProgram { kRfTrain; kRfPredict; kRfVarimp; };. private:. TMVA::MsgLoggerfLoggermessage logger; const TMVA::MethodRuleFit*fMethodRuleFitparent method - set in constructor; TStringfModelTypemodel type string; TMVA::RuleFitAPI::IntParmsfRFIntParmsinteger parameters; vector<int>fRFLxvariable selector; TMVA::RuleFitAPI::ERFProgramfRFProgramwhat to run; TMVA::RuleFitAPI::RealParmsfRFRealParmsreal parameters; vector<Float_t>fRFVarImpvariable importances; vector<Int_t>fRFVarImpIndvariable index; TStringfRFWorkDirworking directory; vector<Float_t>fRFYhatscore results from test sample; TMVA::RuleFit*fRuleFitnon const ptr to RuleFit class in MethodRuleFit. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; RuleFitAPI(const TMVA::MethodRuleFit* rfbase, TMVA::RuleFit* rulefit, TMVA::EMsgType minType); standard constructor. ~RuleFitAPI(); destructor. void WelcomeMessage(); welcome message. void HowtoSetupRF(); howto message. void InitRuleFit(); default initialisation; SetRFWorkDir(""./rulefit"");. void ImportSetup(); import setup from MethodRuleFit. void SetRFWorkDir(const char* wdir); set the directory containing rf_go.exe. void CheckRFWorkDir(); check if the rulefit work dir is properly setup.; it aborts (kFATAL) if not. Check existance of directory. void SetTrainParms(); set the training parameters. void SetTestParms(); set the test params. void FillRealParmsDef(); set default real params. void FillIntParmsDef(); set default int params. Bool_t WriteAll(); write all files read by rf_go.exe. Bool_t WriteIntParms(); write int params file. Bool_t WriteRealParms(); write int params file. Bool_t WriteLx(); Save input variable mask. If the lx vector size is not the same as inputVars,; resize it and fill it with 1; NOTE: Always set all to 1; if (fRFLx.size() != m_inputVars->size()) {. Bool_t WriteProgram(); write command to rf_go.exe. Bool_t WriteRealVarImp(); write the minimum importance to be",MatchSource.WIKI,root/html532/TMVA__RuleFitAPI.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__RuleFitAPI.html
https://root.cern/root/html532/TMVA__RuleFitAPI.html:3897,Modifiability,variab,variable,3897,"s Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; RuleFitAPI(const TMVA::MethodRuleFit* rfbase, TMVA::RuleFit* rulefit, TMVA::EMsgType minType); standard constructor. ~RuleFitAPI(); destructor. void WelcomeMessage(); welcome message. void HowtoSetupRF(); howto message. void InitRuleFit(); default initialisation; SetRFWorkDir(""./rulefit"");. void ImportSetup(); import setup from MethodRuleFit. void SetRFWorkDir(const char* wdir); set the directory containing rf_go.exe. void CheckRFWorkDir(); check if the rulefit work dir is properly setup.; it aborts (kFATAL) if not. Check existance of directory. void SetTrainParms(); set the training parameters. void SetTestParms(); set the test params. void FillRealParmsDef(); set default real params. void FillIntParmsDef(); set default int params. Bool_t WriteAll(); write all files read by rf_go.exe. Bool_t WriteIntParms(); write int params file. Bool_t WriteRealParms(); write int params file. Bool_t WriteLx(); Save input variable mask. If the lx vector size is not the same as inputVars,; resize it and fill it with 1; NOTE: Always set all to 1; if (fRFLx.size() != m_inputVars->size()) {. Bool_t WriteProgram(); write command to rf_go.exe. Bool_t WriteRealVarImp(); write the minimum importance to be considered. Bool_t WriteRfOut(); written by rf_go.exe; write rulefit output (rfout). Bool_t WriteRfStatus(); written by rf_go.exe; write rulefit status. Bool_t WriteRuleFitMod(); written by rf_go.exe (NOTE:Format unknown!). Bool_t WriteRuleFitSum(); written by rf_go.exe (NOTE: format unknown!). Bool_t WriteTrain(); write training data, columnwise. Bool_t WriteTest(); Write test data. Bool_t WriteVarNames(); write variable names, ascii. Bool_t WriteVarImp(); written by rf_go.exe. Bool_t WriteYhat(); written by rf_go.exe. Bool_t ReadYhat(); read the score. Bool_t ReadVarImp(); read variable importance. Bool_t ReadModelSum(); read model from rulefit.sum. Int_t RunRuleFit(); execute rf_go.exe. void TrainRu",MatchSource.WIKI,root/html532/TMVA__RuleFitAPI.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__RuleFitAPI.html
https://root.cern/root/html532/TMVA__RuleFitAPI.html:4595,Modifiability,variab,variable,4595,"tParms(); set the test params. void FillRealParmsDef(); set default real params. void FillIntParmsDef(); set default int params. Bool_t WriteAll(); write all files read by rf_go.exe. Bool_t WriteIntParms(); write int params file. Bool_t WriteRealParms(); write int params file. Bool_t WriteLx(); Save input variable mask. If the lx vector size is not the same as inputVars,; resize it and fill it with 1; NOTE: Always set all to 1; if (fRFLx.size() != m_inputVars->size()) {. Bool_t WriteProgram(); write command to rf_go.exe. Bool_t WriteRealVarImp(); write the minimum importance to be considered. Bool_t WriteRfOut(); written by rf_go.exe; write rulefit output (rfout). Bool_t WriteRfStatus(); written by rf_go.exe; write rulefit status. Bool_t WriteRuleFitMod(); written by rf_go.exe (NOTE:Format unknown!). Bool_t WriteRuleFitSum(); written by rf_go.exe (NOTE: format unknown!). Bool_t WriteTrain(); write training data, columnwise. Bool_t WriteTest(); Write test data. Bool_t WriteVarNames(); write variable names, ascii. Bool_t WriteVarImp(); written by rf_go.exe. Bool_t WriteYhat(); written by rf_go.exe. Bool_t ReadYhat(); read the score. Bool_t ReadVarImp(); read variable importance. Bool_t ReadModelSum(); read model from rulefit.sum. Int_t RunRuleFit(); execute rf_go.exe. void TrainRuleFit(). void TestRuleFit(). void VarImp(). TString GetRFName(TString name). Bool_t OpenRFile(TString name, ofstream& f). Bool_t OpenRFile(TString name, ifstream& f). Bool_t WriteInt(ofstream& f, const Int_t* v, Int_t n = 1). Bool_t WriteFloat(ofstream& f, const Float_t* v, Int_t n = 1). Int_t ReadInt(ifstream& f, Int_t* v, Int_t n = 1) const. Int_t ReadFloat(ifstream& f, Float_t* v, Int_t n = 1) const. RuleFitAPI(const TMVA::MethodRuleFit* rfbase, TMVA::RuleFit* rulefit, TMVA::EMsgType minType). const TString GetRFWorkDir() const; Get working directory. { return fRFWorkDir; }. void SetRFTrain(); set rf_go.exe running mode. { fRFProgram = kRfTrain; }. void SetRFPredict(); { fRFProgram = kRfPre",MatchSource.WIKI,root/html532/TMVA__RuleFitAPI.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__RuleFitAPI.html
https://root.cern/root/html532/TMVA__RuleFitAPI.html:4765,Modifiability,variab,variable,4765," rf_go.exe. Bool_t WriteIntParms(); write int params file. Bool_t WriteRealParms(); write int params file. Bool_t WriteLx(); Save input variable mask. If the lx vector size is not the same as inputVars,; resize it and fill it with 1; NOTE: Always set all to 1; if (fRFLx.size() != m_inputVars->size()) {. Bool_t WriteProgram(); write command to rf_go.exe. Bool_t WriteRealVarImp(); write the minimum importance to be considered. Bool_t WriteRfOut(); written by rf_go.exe; write rulefit output (rfout). Bool_t WriteRfStatus(); written by rf_go.exe; write rulefit status. Bool_t WriteRuleFitMod(); written by rf_go.exe (NOTE:Format unknown!). Bool_t WriteRuleFitSum(); written by rf_go.exe (NOTE: format unknown!). Bool_t WriteTrain(); write training data, columnwise. Bool_t WriteTest(); Write test data. Bool_t WriteVarNames(); write variable names, ascii. Bool_t WriteVarImp(); written by rf_go.exe. Bool_t WriteYhat(); written by rf_go.exe. Bool_t ReadYhat(); read the score. Bool_t ReadVarImp(); read variable importance. Bool_t ReadModelSum(); read model from rulefit.sum. Int_t RunRuleFit(); execute rf_go.exe. void TrainRuleFit(). void TestRuleFit(). void VarImp(). TString GetRFName(TString name). Bool_t OpenRFile(TString name, ofstream& f). Bool_t OpenRFile(TString name, ifstream& f). Bool_t WriteInt(ofstream& f, const Int_t* v, Int_t n = 1). Bool_t WriteFloat(ofstream& f, const Float_t* v, Int_t n = 1). Int_t ReadInt(ifstream& f, Int_t* v, Int_t n = 1) const. Int_t ReadFloat(ifstream& f, Float_t* v, Int_t n = 1) const. RuleFitAPI(const TMVA::MethodRuleFit* rfbase, TMVA::RuleFit* rulefit, TMVA::EMsgType minType). const TString GetRFWorkDir() const; Get working directory. { return fRFWorkDir; }. void SetRFTrain(); set rf_go.exe running mode. { fRFProgram = kRfTrain; }. void SetRFPredict(); { fRFProgram = kRfPredict; }. void SetRFVarimp(); { fRFProgram = kRfVarimp; }. Bool_t ReadIntParms(). Bool_t ReadRealParms(). Bool_t ReadLx(). Bool_t ReadProgram(). Bool_t ReadRealVarImp(). Bo",MatchSource.WIKI,root/html532/TMVA__RuleFitAPI.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__RuleFitAPI.html
https://root.cern/root/html532/TMVA__RuleFitAPI.html:3474,Safety,abort,aborts,3474,"parameters; vector<int>fRFLxvariable selector; TMVA::RuleFitAPI::ERFProgramfRFProgramwhat to run; TMVA::RuleFitAPI::RealParmsfRFRealParmsreal parameters; vector<Float_t>fRFVarImpvariable importances; vector<Int_t>fRFVarImpIndvariable index; TStringfRFWorkDirworking directory; vector<Float_t>fRFYhatscore results from test sample; TMVA::RuleFit*fRuleFitnon const ptr to RuleFit class in MethodRuleFit. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; RuleFitAPI(const TMVA::MethodRuleFit* rfbase, TMVA::RuleFit* rulefit, TMVA::EMsgType minType); standard constructor. ~RuleFitAPI(); destructor. void WelcomeMessage(); welcome message. void HowtoSetupRF(); howto message. void InitRuleFit(); default initialisation; SetRFWorkDir(""./rulefit"");. void ImportSetup(); import setup from MethodRuleFit. void SetRFWorkDir(const char* wdir); set the directory containing rf_go.exe. void CheckRFWorkDir(); check if the rulefit work dir is properly setup.; it aborts (kFATAL) if not. Check existance of directory. void SetTrainParms(); set the training parameters. void SetTestParms(); set the test params. void FillRealParmsDef(); set default real params. void FillIntParmsDef(); set default int params. Bool_t WriteAll(); write all files read by rf_go.exe. Bool_t WriteIntParms(); write int params file. Bool_t WriteRealParms(); write int params file. Bool_t WriteLx(); Save input variable mask. If the lx vector size is not the same as inputVars,; resize it and fill it with 1; NOTE: Always set all to 1; if (fRFLx.size() != m_inputVars->size()) {. Bool_t WriteProgram(); write command to rf_go.exe. Bool_t WriteRealVarImp(); write the minimum importance to be considered. Bool_t WriteRfOut(); written by rf_go.exe; write rulefit output (rfout). Bool_t WriteRfStatus(); written by rf_go.exe; write rulefit status. Bool_t WriteRuleFitMod(); written by rf_go.exe (NOTE:Format unknown!). Bool_t WriteRuleFitSum(); written by rf_go.exe (NOTE: format unknown!). Bool_t Wr",MatchSource.WIKI,root/html532/TMVA__RuleFitAPI.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__RuleFitAPI.html
https://root.cern/root/html532/TMVA__RuleFitAPI.html:2318,Testability,log,logger,2318," voidSetTestParms(); voidSetTrainParms(); Bool_tWriteAll(); Bool_tWriteFloat(ofstream& f, const Float_t* v, Int_t n = 1); Bool_tWriteInt(ofstream& f, const Int_t* v, Int_t n = 1); Bool_tWriteIntParms(); Bool_tWriteLx(); Bool_tWriteProgram(); Bool_tWriteRealParms(); Bool_tWriteRealVarImp(); Bool_tWriteRfOut(); Bool_tWriteRfStatus(); Bool_tWriteRuleFitMod(); Bool_tWriteRuleFitSum(); Bool_tWriteTest(); Bool_tWriteTrain(); Bool_tWriteVarImp(); Bool_tWriteVarNames(); Bool_tWriteYhat(). private:. TMVA::RuleFitAPIRuleFitAPI(). Data Members; public:. enum ERFMode { kRfRegress; kRfClass; };; enum EModel { kRfLinear; kRfRules; kRfBoth; };; enum ERFProgram { kRfTrain; kRfPredict; kRfVarimp; };. private:. TMVA::MsgLoggerfLoggermessage logger; const TMVA::MethodRuleFit*fMethodRuleFitparent method - set in constructor; TStringfModelTypemodel type string; TMVA::RuleFitAPI::IntParmsfRFIntParmsinteger parameters; vector<int>fRFLxvariable selector; TMVA::RuleFitAPI::ERFProgramfRFProgramwhat to run; TMVA::RuleFitAPI::RealParmsfRFRealParmsreal parameters; vector<Float_t>fRFVarImpvariable importances; vector<Int_t>fRFVarImpIndvariable index; TStringfRFWorkDirworking directory; vector<Float_t>fRFYhatscore results from test sample; TMVA::RuleFit*fRuleFitnon const ptr to RuleFit class in MethodRuleFit. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; RuleFitAPI(const TMVA::MethodRuleFit* rfbase, TMVA::RuleFit* rulefit, TMVA::EMsgType minType); standard constructor. ~RuleFitAPI(); destructor. void WelcomeMessage(); welcome message. void HowtoSetupRF(); howto message. void InitRuleFit(); default initialisation; SetRFWorkDir(""./rulefit"");. void ImportSetup(); import setup from MethodRuleFit. void SetRFWorkDir(const char* wdir); set the directory containing rf_go.exe. void CheckRFWorkDir(); check if the rulefit work dir is properly setup.; it aborts (kFATAL) if not. Check existance of directory. void SetTrainParms(); set the training parameters. void Se",MatchSource.WIKI,root/html532/TMVA__RuleFitAPI.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__RuleFitAPI.html
https://root.cern/root/html532/TMVA__RuleFitAPI.html:2801,Testability,test,test,2801," voidSetTestParms(); voidSetTrainParms(); Bool_tWriteAll(); Bool_tWriteFloat(ofstream& f, const Float_t* v, Int_t n = 1); Bool_tWriteInt(ofstream& f, const Int_t* v, Int_t n = 1); Bool_tWriteIntParms(); Bool_tWriteLx(); Bool_tWriteProgram(); Bool_tWriteRealParms(); Bool_tWriteRealVarImp(); Bool_tWriteRfOut(); Bool_tWriteRfStatus(); Bool_tWriteRuleFitMod(); Bool_tWriteRuleFitSum(); Bool_tWriteTest(); Bool_tWriteTrain(); Bool_tWriteVarImp(); Bool_tWriteVarNames(); Bool_tWriteYhat(). private:. TMVA::RuleFitAPIRuleFitAPI(). Data Members; public:. enum ERFMode { kRfRegress; kRfClass; };; enum EModel { kRfLinear; kRfRules; kRfBoth; };; enum ERFProgram { kRfTrain; kRfPredict; kRfVarimp; };. private:. TMVA::MsgLoggerfLoggermessage logger; const TMVA::MethodRuleFit*fMethodRuleFitparent method - set in constructor; TStringfModelTypemodel type string; TMVA::RuleFitAPI::IntParmsfRFIntParmsinteger parameters; vector<int>fRFLxvariable selector; TMVA::RuleFitAPI::ERFProgramfRFProgramwhat to run; TMVA::RuleFitAPI::RealParmsfRFRealParmsreal parameters; vector<Float_t>fRFVarImpvariable importances; vector<Int_t>fRFVarImpIndvariable index; TStringfRFWorkDirworking directory; vector<Float_t>fRFYhatscore results from test sample; TMVA::RuleFit*fRuleFitnon const ptr to RuleFit class in MethodRuleFit. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; RuleFitAPI(const TMVA::MethodRuleFit* rfbase, TMVA::RuleFit* rulefit, TMVA::EMsgType minType); standard constructor. ~RuleFitAPI(); destructor. void WelcomeMessage(); welcome message. void HowtoSetupRF(); howto message. void InitRuleFit(); default initialisation; SetRFWorkDir(""./rulefit"");. void ImportSetup(); import setup from MethodRuleFit. void SetRFWorkDir(const char* wdir); set the directory containing rf_go.exe. void CheckRFWorkDir(); check if the rulefit work dir is properly setup.; it aborts (kFATAL) if not. Check existance of directory. void SetTrainParms(); set the training parameters. void Se",MatchSource.WIKI,root/html532/TMVA__RuleFitAPI.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__RuleFitAPI.html
https://root.cern/root/html532/TMVA__RuleFitAPI.html:3608,Testability,test,test,3608,"RealParmsfRFRealParmsreal parameters; vector<Float_t>fRFVarImpvariable importances; vector<Int_t>fRFVarImpIndvariable index; TStringfRFWorkDirworking directory; vector<Float_t>fRFYhatscore results from test sample; TMVA::RuleFit*fRuleFitnon const ptr to RuleFit class in MethodRuleFit. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; RuleFitAPI(const TMVA::MethodRuleFit* rfbase, TMVA::RuleFit* rulefit, TMVA::EMsgType minType); standard constructor. ~RuleFitAPI(); destructor. void WelcomeMessage(); welcome message. void HowtoSetupRF(); howto message. void InitRuleFit(); default initialisation; SetRFWorkDir(""./rulefit"");. void ImportSetup(); import setup from MethodRuleFit. void SetRFWorkDir(const char* wdir); set the directory containing rf_go.exe. void CheckRFWorkDir(); check if the rulefit work dir is properly setup.; it aborts (kFATAL) if not. Check existance of directory. void SetTrainParms(); set the training parameters. void SetTestParms(); set the test params. void FillRealParmsDef(); set default real params. void FillIntParmsDef(); set default int params. Bool_t WriteAll(); write all files read by rf_go.exe. Bool_t WriteIntParms(); write int params file. Bool_t WriteRealParms(); write int params file. Bool_t WriteLx(); Save input variable mask. If the lx vector size is not the same as inputVars,; resize it and fill it with 1; NOTE: Always set all to 1; if (fRFLx.size() != m_inputVars->size()) {. Bool_t WriteProgram(); write command to rf_go.exe. Bool_t WriteRealVarImp(); write the minimum importance to be considered. Bool_t WriteRfOut(); written by rf_go.exe; write rulefit output (rfout). Bool_t WriteRfStatus(); written by rf_go.exe; write rulefit status. Bool_t WriteRuleFitMod(); written by rf_go.exe (NOTE:Format unknown!). Bool_t WriteRuleFitSum(); written by rf_go.exe (NOTE: format unknown!). Bool_t WriteTrain(); write training data, columnwise. Bool_t WriteTest(); Write test data. Bool_t WriteVarNames(); write vari",MatchSource.WIKI,root/html532/TMVA__RuleFitAPI.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__RuleFitAPI.html
https://root.cern/root/html532/TMVA__RuleFitAPI.html:4554,Testability,test,test,4554,"s(); set the training parameters. void SetTestParms(); set the test params. void FillRealParmsDef(); set default real params. void FillIntParmsDef(); set default int params. Bool_t WriteAll(); write all files read by rf_go.exe. Bool_t WriteIntParms(); write int params file. Bool_t WriteRealParms(); write int params file. Bool_t WriteLx(); Save input variable mask. If the lx vector size is not the same as inputVars,; resize it and fill it with 1; NOTE: Always set all to 1; if (fRFLx.size() != m_inputVars->size()) {. Bool_t WriteProgram(); write command to rf_go.exe. Bool_t WriteRealVarImp(); write the minimum importance to be considered. Bool_t WriteRfOut(); written by rf_go.exe; write rulefit output (rfout). Bool_t WriteRfStatus(); written by rf_go.exe; write rulefit status. Bool_t WriteRuleFitMod(); written by rf_go.exe (NOTE:Format unknown!). Bool_t WriteRuleFitSum(); written by rf_go.exe (NOTE: format unknown!). Bool_t WriteTrain(); write training data, columnwise. Bool_t WriteTest(); Write test data. Bool_t WriteVarNames(); write variable names, ascii. Bool_t WriteVarImp(); written by rf_go.exe. Bool_t WriteYhat(); written by rf_go.exe. Bool_t ReadYhat(); read the score. Bool_t ReadVarImp(); read variable importance. Bool_t ReadModelSum(); read model from rulefit.sum. Int_t RunRuleFit(); execute rf_go.exe. void TrainRuleFit(). void TestRuleFit(). void VarImp(). TString GetRFName(TString name). Bool_t OpenRFile(TString name, ofstream& f). Bool_t OpenRFile(TString name, ifstream& f). Bool_t WriteInt(ofstream& f, const Int_t* v, Int_t n = 1). Bool_t WriteFloat(ofstream& f, const Float_t* v, Int_t n = 1). Int_t ReadInt(ifstream& f, Int_t* v, Int_t n = 1) const. Int_t ReadFloat(ifstream& f, Float_t* v, Int_t n = 1) const. RuleFitAPI(const TMVA::MethodRuleFit* rfbase, TMVA::RuleFit* rulefit, TMVA::EMsgType minType). const TString GetRFWorkDir() const; Get working directory. { return fRFWorkDir; }. void SetRFTrain(); set rf_go.exe running mode. { fRFProgram = kRfTrain; ",MatchSource.WIKI,root/html532/TMVA__RuleFitAPI.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__RuleFitAPI.html
https://root.cern/root/html532/TMVA__SeparationBase.html:431,Availability,avail,available,431,". TMVA::SeparationBase. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::SeparationBase. class TMVA::SeparationBase. Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~SeparationBase(); static TClass*Class(); const TString&GetName(); Double_tGetSeparationGain(const Double_t& nSelS, const Double_t& nSelB, const Double_t& nTotS, const Double_t& nTotB); virtual Double_tGetSeparationIndex(const Double_t& s, const Double_t& b); virtual TClass*IsA() const; TMVA::SeparationBase&operator=(const TMVA::SeparationBase&); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). Data Members; protected:. TStringfNamename of the concrete Separation Index impementation; Double_tfPrecisionCut. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Double_t GetSeparationGain(const Double_t& nSelS, const Double_t& nSelB, const Double_t& nTotS, const Double_t& nTotB); Separation Gain:; the measure of how the quality of separation of the sample increases; by splitting the sample e.g. into a ""left-node"" and a ""right-node""; (N * Index_parent) - (N_left * Index_left) - (N_right * Index_right); this is then the quality crition which is optimized for when trying; to increase the information in the system (making the best selection. virtual ~SeparationBase(); destructor. {}. Double_t GetSeparationIndex(const Double_t& s, const Double_t& b); Return the separation index (a measure for ""purity"" of the sample""). const TString& GetName(); Return the name of the concrete Index implementation. { return fName; }. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last ",MatchSource.WIKI,root/html532/TMVA__SeparationBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__SeparationBase.html
https://root.cern/root/html532/TMVA__SeparationBase.html:1531,Performance,optimiz,optimized,1531,"lass TMVA::SeparationBase. Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~SeparationBase(); static TClass*Class(); const TString&GetName(); Double_tGetSeparationGain(const Double_t& nSelS, const Double_t& nSelB, const Double_t& nTotS, const Double_t& nTotB); virtual Double_tGetSeparationIndex(const Double_t& s, const Double_t& b); virtual TClass*IsA() const; TMVA::SeparationBase&operator=(const TMVA::SeparationBase&); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). Data Members; protected:. TStringfNamename of the concrete Separation Index impementation; Double_tfPrecisionCut. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Double_t GetSeparationGain(const Double_t& nSelS, const Double_t& nSelB, const Double_t& nTotS, const Double_t& nTotB); Separation Gain:; the measure of how the quality of separation of the sample increases; by splitting the sample e.g. into a ""left-node"" and a ""right-node""; (N * Index_parent) - (N_left * Index_left) - (N_right * Index_right); this is then the quality crition which is optimized for when trying; to increase the information in the system (making the best selection. virtual ~SeparationBase(); destructor. {}. Double_t GetSeparationIndex(const Double_t& s, const Double_t& b); Return the separation index (a measure for ""purity"" of the sample""). const TString& GetName(); Return the name of the concrete Index implementation. { return fName; }. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: SeparationBase.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:20; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__SeparationBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__SeparationBase.html
https://root.cern/root/html532/TMVA__SimulatedAnnealing.html:840,Energy Efficiency,adapt,adaptiveSpeed,840,". TMVA::SimulatedAnnealing. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::SimulatedAnnealing. class TMVA::SimulatedAnnealing. Implementation of Simulated Annealing fitter. Function Members (Methods); public:. virtual~SimulatedAnnealing(); static TClass*Class(); virtual TClass*IsA() const; Double_tMinimize(vector<Double_t>& parameters); voidSetAccuracy(Double_t eps); voidSetAdaptiveSpeed(Double_t speed); voidSetInitTemp(Double_t it); voidSetMaxCalls(Int_t mc); voidSetMinTemp(Double_t min); voidSetOptions(Int_t maxCalls, Double_t initialTemperature, Double_t minTemperature, Double_t eps, TString kernelTemperatureS, Double_t temperatureScale, Double_t adaptiveSpeed, Double_t temperatureAdaptiveStep, Bool_t useDefaultScale, Bool_t useDefaultTemperature); voidSetTemperatureScale(Double_t scale); virtual voidShowMembers(TMemberInspector& insp); TMVA::SimulatedAnnealingSimulatedAnnealing(const TMVA::SimulatedAnnealing&); TMVA::SimulatedAnnealingSimulatedAnnealing(TMVA::IFitterTarget& target, const vector<TMVA::Interval*>& ranges); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). private:. voidFillWithRandomValues(vector<Double_t>& parameters); Double_tGenerateMaxTemperature(vector<Double_t>& parameters); vector<Double_t>GenerateNeighbour(vector<Double_t>& parameters, Double_t currentTemperature); voidGenerateNeighbour(vector<Double_t>& parameters, vector<Double_t>& oldParameters, Double_t currentTemperature); voidGenerateNewTemperature(Double_t& currentTemperature, Int_t Iter); TMVA::MsgLogger&Log() const; voidReWriteParameters(vector<Double_t>& from, vector<Double_t>& to); voidSetDefaultScale(); Bool_tShouldGoIn(Double_t currentFit, Double_t localFit, Double_t currentTemperature). Data Members; public:. enum EKernelTemperature { kSqrt; kIncreasingAdaptive; kDecreasingAdaptiv",MatchSource.WIKI,root/html532/TMVA__SimulatedAnnealing.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__SimulatedAnnealing.html
https://root.cern/root/html532/TMVA__SimulatedAnnealing.html:2096,Energy Efficiency,adapt,adaptive,2096,"ble_t>& parameters, Double_t currentTemperature); voidGenerateNeighbour(vector<Double_t>& parameters, vector<Double_t>& oldParameters, Double_t currentTemperature); voidGenerateNewTemperature(Double_t& currentTemperature, Int_t Iter); TMVA::MsgLogger&Log() const; voidReWriteParameters(vector<Double_t>& from, vector<Double_t>& to); voidSetDefaultScale(); Bool_tShouldGoIn(Double_t currentFit, Double_t localFit, Double_t currentTemperature). Data Members; public:. enum EKernelTemperature { kSqrt; kIncreasingAdaptive; kDecreasingAdaptive; kLog; kHomo; kSin; kGeo; };. private:. Double_tfAdaptiveSpeedhow fast temperature change in adaptive (in adaptive two variables describe; Double_tfEpsepsilon; TMVA::IFitterTarget&fFitterTargetthe fitter target; Double_tfInitialTemperatureinitial temperature; TMVA::SimulatedAnnealing::EKernelTemperaturefKernelTemperature; TMVA::MsgLogger*fLoggermessage logger; Int_tfMaxCallsmaximum number of minimisation calls; Double_tfMinTemperaturemimimum temperature; Double_tfProgress; TRandom*fRandomrandom generator; const vector<TMVA::Interval*>&fRangesparameter ranges; Double_tfTemperatureAdaptiveStepused to calculate InitialTemperature if fUseDefaultTemperature; Double_tfTemperatureScalehow fast temperature change; Bool_tfUseDefaultScaleif TRUE, SA calculates its own TemperatureScale; Bool_tfUseDefaultTemperatureif TRUE, SA calculates its own InitialTemperature (MinTemperautre). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; SimulatedAnnealing(TMVA::IFitterTarget& target, const vector<TMVA::Interval*>& ranges); constructor. void SetOptions(Int_t maxCalls, Double_t initialTemperature, Double_t minTemperature, Double_t eps, TString kernelTemperatureS, Double_t temperatureScale, Double_t adaptiveSpeed, Double_t temperatureAdaptiveStep, Bool_t useDefaultScale, Bool_t useDefaultTemperature); option setter. ~SimulatedAnnealing(); destructor. void FillWithRandomValues(vector<Double_t>& parameters); random star",MatchSource.WIKI,root/html532/TMVA__SimulatedAnnealing.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__SimulatedAnnealing.html
https://root.cern/root/html532/TMVA__SimulatedAnnealing.html:2109,Energy Efficiency,adapt,adaptive,2109,"ble_t>& parameters, Double_t currentTemperature); voidGenerateNeighbour(vector<Double_t>& parameters, vector<Double_t>& oldParameters, Double_t currentTemperature); voidGenerateNewTemperature(Double_t& currentTemperature, Int_t Iter); TMVA::MsgLogger&Log() const; voidReWriteParameters(vector<Double_t>& from, vector<Double_t>& to); voidSetDefaultScale(); Bool_tShouldGoIn(Double_t currentFit, Double_t localFit, Double_t currentTemperature). Data Members; public:. enum EKernelTemperature { kSqrt; kIncreasingAdaptive; kDecreasingAdaptive; kLog; kHomo; kSin; kGeo; };. private:. Double_tfAdaptiveSpeedhow fast temperature change in adaptive (in adaptive two variables describe; Double_tfEpsepsilon; TMVA::IFitterTarget&fFitterTargetthe fitter target; Double_tfInitialTemperatureinitial temperature; TMVA::SimulatedAnnealing::EKernelTemperaturefKernelTemperature; TMVA::MsgLogger*fLoggermessage logger; Int_tfMaxCallsmaximum number of minimisation calls; Double_tfMinTemperaturemimimum temperature; Double_tfProgress; TRandom*fRandomrandom generator; const vector<TMVA::Interval*>&fRangesparameter ranges; Double_tfTemperatureAdaptiveStepused to calculate InitialTemperature if fUseDefaultTemperature; Double_tfTemperatureScalehow fast temperature change; Bool_tfUseDefaultScaleif TRUE, SA calculates its own TemperatureScale; Bool_tfUseDefaultTemperatureif TRUE, SA calculates its own InitialTemperature (MinTemperautre). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; SimulatedAnnealing(TMVA::IFitterTarget& target, const vector<TMVA::Interval*>& ranges); constructor. void SetOptions(Int_t maxCalls, Double_t initialTemperature, Double_t minTemperature, Double_t eps, TString kernelTemperatureS, Double_t temperatureScale, Double_t adaptiveSpeed, Double_t temperatureAdaptiveStep, Bool_t useDefaultScale, Bool_t useDefaultTemperature); option setter. ~SimulatedAnnealing(); destructor. void FillWithRandomValues(vector<Double_t>& parameters); random star",MatchSource.WIKI,root/html532/TMVA__SimulatedAnnealing.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__SimulatedAnnealing.html
https://root.cern/root/html532/TMVA__SimulatedAnnealing.html:3242,Energy Efficiency,adapt,adaptiveSpeed,3242,"ble_tfInitialTemperatureinitial temperature; TMVA::SimulatedAnnealing::EKernelTemperaturefKernelTemperature; TMVA::MsgLogger*fLoggermessage logger; Int_tfMaxCallsmaximum number of minimisation calls; Double_tfMinTemperaturemimimum temperature; Double_tfProgress; TRandom*fRandomrandom generator; const vector<TMVA::Interval*>&fRangesparameter ranges; Double_tfTemperatureAdaptiveStepused to calculate InitialTemperature if fUseDefaultTemperature; Double_tfTemperatureScalehow fast temperature change; Bool_tfUseDefaultScaleif TRUE, SA calculates its own TemperatureScale; Bool_tfUseDefaultTemperatureif TRUE, SA calculates its own InitialTemperature (MinTemperautre). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; SimulatedAnnealing(TMVA::IFitterTarget& target, const vector<TMVA::Interval*>& ranges); constructor. void SetOptions(Int_t maxCalls, Double_t initialTemperature, Double_t minTemperature, Double_t eps, TString kernelTemperatureS, Double_t temperatureScale, Double_t adaptiveSpeed, Double_t temperatureAdaptiveStep, Bool_t useDefaultScale, Bool_t useDefaultTemperature); option setter. ~SimulatedAnnealing(); destructor. void FillWithRandomValues(vector<Double_t>& parameters); random starting parameters. void ReWriteParameters(vector<Double_t>& from, vector<Double_t>& to); copy parameters. void GenerateNeighbour(vector<Double_t>& parameters, vector<Double_t>& oldParameters, Double_t currentTemperature); generate adjacent parameters. std::vector<Double_t> GenerateNeighbour(vector<Double_t>& parameters, Double_t currentTemperature); generate adjacent parameters. void GenerateNewTemperature(Double_t& currentTemperature, Int_t Iter); generate new temperature. Bool_t ShouldGoIn(Double_t currentFit, Double_t localFit, Double_t currentTemperature); result checker. void SetDefaultScale(); setting of default scale. Double_t GenerateMaxTemperature(vector<Double_t>& parameters); maximum temperature. Double_t Minimize(vector<Double_t>& para",MatchSource.WIKI,root/html532/TMVA__SimulatedAnnealing.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__SimulatedAnnealing.html
https://root.cern/root/html532/TMVA__SimulatedAnnealing.html:840,Modifiability,adapt,adaptiveSpeed,840,". TMVA::SimulatedAnnealing. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::SimulatedAnnealing. class TMVA::SimulatedAnnealing. Implementation of Simulated Annealing fitter. Function Members (Methods); public:. virtual~SimulatedAnnealing(); static TClass*Class(); virtual TClass*IsA() const; Double_tMinimize(vector<Double_t>& parameters); voidSetAccuracy(Double_t eps); voidSetAdaptiveSpeed(Double_t speed); voidSetInitTemp(Double_t it); voidSetMaxCalls(Int_t mc); voidSetMinTemp(Double_t min); voidSetOptions(Int_t maxCalls, Double_t initialTemperature, Double_t minTemperature, Double_t eps, TString kernelTemperatureS, Double_t temperatureScale, Double_t adaptiveSpeed, Double_t temperatureAdaptiveStep, Bool_t useDefaultScale, Bool_t useDefaultTemperature); voidSetTemperatureScale(Double_t scale); virtual voidShowMembers(TMemberInspector& insp); TMVA::SimulatedAnnealingSimulatedAnnealing(const TMVA::SimulatedAnnealing&); TMVA::SimulatedAnnealingSimulatedAnnealing(TMVA::IFitterTarget& target, const vector<TMVA::Interval*>& ranges); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). private:. voidFillWithRandomValues(vector<Double_t>& parameters); Double_tGenerateMaxTemperature(vector<Double_t>& parameters); vector<Double_t>GenerateNeighbour(vector<Double_t>& parameters, Double_t currentTemperature); voidGenerateNeighbour(vector<Double_t>& parameters, vector<Double_t>& oldParameters, Double_t currentTemperature); voidGenerateNewTemperature(Double_t& currentTemperature, Int_t Iter); TMVA::MsgLogger&Log() const; voidReWriteParameters(vector<Double_t>& from, vector<Double_t>& to); voidSetDefaultScale(); Bool_tShouldGoIn(Double_t currentFit, Double_t localFit, Double_t currentTemperature). Data Members; public:. enum EKernelTemperature { kSqrt; kIncreasingAdaptive; kDecreasingAdaptiv",MatchSource.WIKI,root/html532/TMVA__SimulatedAnnealing.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__SimulatedAnnealing.html
https://root.cern/root/html532/TMVA__SimulatedAnnealing.html:2096,Modifiability,adapt,adaptive,2096,"ble_t>& parameters, Double_t currentTemperature); voidGenerateNeighbour(vector<Double_t>& parameters, vector<Double_t>& oldParameters, Double_t currentTemperature); voidGenerateNewTemperature(Double_t& currentTemperature, Int_t Iter); TMVA::MsgLogger&Log() const; voidReWriteParameters(vector<Double_t>& from, vector<Double_t>& to); voidSetDefaultScale(); Bool_tShouldGoIn(Double_t currentFit, Double_t localFit, Double_t currentTemperature). Data Members; public:. enum EKernelTemperature { kSqrt; kIncreasingAdaptive; kDecreasingAdaptive; kLog; kHomo; kSin; kGeo; };. private:. Double_tfAdaptiveSpeedhow fast temperature change in adaptive (in adaptive two variables describe; Double_tfEpsepsilon; TMVA::IFitterTarget&fFitterTargetthe fitter target; Double_tfInitialTemperatureinitial temperature; TMVA::SimulatedAnnealing::EKernelTemperaturefKernelTemperature; TMVA::MsgLogger*fLoggermessage logger; Int_tfMaxCallsmaximum number of minimisation calls; Double_tfMinTemperaturemimimum temperature; Double_tfProgress; TRandom*fRandomrandom generator; const vector<TMVA::Interval*>&fRangesparameter ranges; Double_tfTemperatureAdaptiveStepused to calculate InitialTemperature if fUseDefaultTemperature; Double_tfTemperatureScalehow fast temperature change; Bool_tfUseDefaultScaleif TRUE, SA calculates its own TemperatureScale; Bool_tfUseDefaultTemperatureif TRUE, SA calculates its own InitialTemperature (MinTemperautre). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; SimulatedAnnealing(TMVA::IFitterTarget& target, const vector<TMVA::Interval*>& ranges); constructor. void SetOptions(Int_t maxCalls, Double_t initialTemperature, Double_t minTemperature, Double_t eps, TString kernelTemperatureS, Double_t temperatureScale, Double_t adaptiveSpeed, Double_t temperatureAdaptiveStep, Bool_t useDefaultScale, Bool_t useDefaultTemperature); option setter. ~SimulatedAnnealing(); destructor. void FillWithRandomValues(vector<Double_t>& parameters); random star",MatchSource.WIKI,root/html532/TMVA__SimulatedAnnealing.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__SimulatedAnnealing.html
https://root.cern/root/html532/TMVA__SimulatedAnnealing.html:2109,Modifiability,adapt,adaptive,2109,"ble_t>& parameters, Double_t currentTemperature); voidGenerateNeighbour(vector<Double_t>& parameters, vector<Double_t>& oldParameters, Double_t currentTemperature); voidGenerateNewTemperature(Double_t& currentTemperature, Int_t Iter); TMVA::MsgLogger&Log() const; voidReWriteParameters(vector<Double_t>& from, vector<Double_t>& to); voidSetDefaultScale(); Bool_tShouldGoIn(Double_t currentFit, Double_t localFit, Double_t currentTemperature). Data Members; public:. enum EKernelTemperature { kSqrt; kIncreasingAdaptive; kDecreasingAdaptive; kLog; kHomo; kSin; kGeo; };. private:. Double_tfAdaptiveSpeedhow fast temperature change in adaptive (in adaptive two variables describe; Double_tfEpsepsilon; TMVA::IFitterTarget&fFitterTargetthe fitter target; Double_tfInitialTemperatureinitial temperature; TMVA::SimulatedAnnealing::EKernelTemperaturefKernelTemperature; TMVA::MsgLogger*fLoggermessage logger; Int_tfMaxCallsmaximum number of minimisation calls; Double_tfMinTemperaturemimimum temperature; Double_tfProgress; TRandom*fRandomrandom generator; const vector<TMVA::Interval*>&fRangesparameter ranges; Double_tfTemperatureAdaptiveStepused to calculate InitialTemperature if fUseDefaultTemperature; Double_tfTemperatureScalehow fast temperature change; Bool_tfUseDefaultScaleif TRUE, SA calculates its own TemperatureScale; Bool_tfUseDefaultTemperatureif TRUE, SA calculates its own InitialTemperature (MinTemperautre). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; SimulatedAnnealing(TMVA::IFitterTarget& target, const vector<TMVA::Interval*>& ranges); constructor. void SetOptions(Int_t maxCalls, Double_t initialTemperature, Double_t minTemperature, Double_t eps, TString kernelTemperatureS, Double_t temperatureScale, Double_t adaptiveSpeed, Double_t temperatureAdaptiveStep, Bool_t useDefaultScale, Bool_t useDefaultTemperature); option setter. ~SimulatedAnnealing(); destructor. void FillWithRandomValues(vector<Double_t>& parameters); random star",MatchSource.WIKI,root/html532/TMVA__SimulatedAnnealing.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__SimulatedAnnealing.html
https://root.cern/root/html532/TMVA__SimulatedAnnealing.html:2122,Modifiability,variab,variables,2122,"ble_t>& parameters, Double_t currentTemperature); voidGenerateNeighbour(vector<Double_t>& parameters, vector<Double_t>& oldParameters, Double_t currentTemperature); voidGenerateNewTemperature(Double_t& currentTemperature, Int_t Iter); TMVA::MsgLogger&Log() const; voidReWriteParameters(vector<Double_t>& from, vector<Double_t>& to); voidSetDefaultScale(); Bool_tShouldGoIn(Double_t currentFit, Double_t localFit, Double_t currentTemperature). Data Members; public:. enum EKernelTemperature { kSqrt; kIncreasingAdaptive; kDecreasingAdaptive; kLog; kHomo; kSin; kGeo; };. private:. Double_tfAdaptiveSpeedhow fast temperature change in adaptive (in adaptive two variables describe; Double_tfEpsepsilon; TMVA::IFitterTarget&fFitterTargetthe fitter target; Double_tfInitialTemperatureinitial temperature; TMVA::SimulatedAnnealing::EKernelTemperaturefKernelTemperature; TMVA::MsgLogger*fLoggermessage logger; Int_tfMaxCallsmaximum number of minimisation calls; Double_tfMinTemperaturemimimum temperature; Double_tfProgress; TRandom*fRandomrandom generator; const vector<TMVA::Interval*>&fRangesparameter ranges; Double_tfTemperatureAdaptiveStepused to calculate InitialTemperature if fUseDefaultTemperature; Double_tfTemperatureScalehow fast temperature change; Bool_tfUseDefaultScaleif TRUE, SA calculates its own TemperatureScale; Bool_tfUseDefaultTemperatureif TRUE, SA calculates its own InitialTemperature (MinTemperautre). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; SimulatedAnnealing(TMVA::IFitterTarget& target, const vector<TMVA::Interval*>& ranges); constructor. void SetOptions(Int_t maxCalls, Double_t initialTemperature, Double_t minTemperature, Double_t eps, TString kernelTemperatureS, Double_t temperatureScale, Double_t adaptiveSpeed, Double_t temperatureAdaptiveStep, Bool_t useDefaultScale, Bool_t useDefaultTemperature); option setter. ~SimulatedAnnealing(); destructor. void FillWithRandomValues(vector<Double_t>& parameters); random star",MatchSource.WIKI,root/html532/TMVA__SimulatedAnnealing.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__SimulatedAnnealing.html
https://root.cern/root/html532/TMVA__SimulatedAnnealing.html:3242,Modifiability,adapt,adaptiveSpeed,3242,"ble_tfInitialTemperatureinitial temperature; TMVA::SimulatedAnnealing::EKernelTemperaturefKernelTemperature; TMVA::MsgLogger*fLoggermessage logger; Int_tfMaxCallsmaximum number of minimisation calls; Double_tfMinTemperaturemimimum temperature; Double_tfProgress; TRandom*fRandomrandom generator; const vector<TMVA::Interval*>&fRangesparameter ranges; Double_tfTemperatureAdaptiveStepused to calculate InitialTemperature if fUseDefaultTemperature; Double_tfTemperatureScalehow fast temperature change; Bool_tfUseDefaultScaleif TRUE, SA calculates its own TemperatureScale; Bool_tfUseDefaultTemperatureif TRUE, SA calculates its own InitialTemperature (MinTemperautre). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; SimulatedAnnealing(TMVA::IFitterTarget& target, const vector<TMVA::Interval*>& ranges); constructor. void SetOptions(Int_t maxCalls, Double_t initialTemperature, Double_t minTemperature, Double_t eps, TString kernelTemperatureS, Double_t temperatureScale, Double_t adaptiveSpeed, Double_t temperatureAdaptiveStep, Bool_t useDefaultScale, Bool_t useDefaultTemperature); option setter. ~SimulatedAnnealing(); destructor. void FillWithRandomValues(vector<Double_t>& parameters); random starting parameters. void ReWriteParameters(vector<Double_t>& from, vector<Double_t>& to); copy parameters. void GenerateNeighbour(vector<Double_t>& parameters, vector<Double_t>& oldParameters, Double_t currentTemperature); generate adjacent parameters. std::vector<Double_t> GenerateNeighbour(vector<Double_t>& parameters, Double_t currentTemperature); generate adjacent parameters. void GenerateNewTemperature(Double_t& currentTemperature, Int_t Iter); generate new temperature. Bool_t ShouldGoIn(Double_t currentFit, Double_t localFit, Double_t currentTemperature); result checker. void SetDefaultScale(); setting of default scale. Double_t GenerateMaxTemperature(vector<Double_t>& parameters); maximum temperature. Double_t Minimize(vector<Double_t>& para",MatchSource.WIKI,root/html532/TMVA__SimulatedAnnealing.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__SimulatedAnnealing.html
https://root.cern/root/html532/TMVA__SimulatedAnnealing.html:4368,Security,access,accessors,4368,"alTemperature, Double_t minTemperature, Double_t eps, TString kernelTemperatureS, Double_t temperatureScale, Double_t adaptiveSpeed, Double_t temperatureAdaptiveStep, Bool_t useDefaultScale, Bool_t useDefaultTemperature); option setter. ~SimulatedAnnealing(); destructor. void FillWithRandomValues(vector<Double_t>& parameters); random starting parameters. void ReWriteParameters(vector<Double_t>& from, vector<Double_t>& to); copy parameters. void GenerateNeighbour(vector<Double_t>& parameters, vector<Double_t>& oldParameters, Double_t currentTemperature); generate adjacent parameters. std::vector<Double_t> GenerateNeighbour(vector<Double_t>& parameters, Double_t currentTemperature); generate adjacent parameters. void GenerateNewTemperature(Double_t& currentTemperature, Int_t Iter); generate new temperature. Bool_t ShouldGoIn(Double_t currentFit, Double_t localFit, Double_t currentTemperature); result checker. void SetDefaultScale(); setting of default scale. Double_t GenerateMaxTemperature(vector<Double_t>& parameters); maximum temperature. Double_t Minimize(vector<Double_t>& parameters); minimisation algorithm. SimulatedAnnealing(TMVA::IFitterTarget& target, const vector<TMVA::Interval*>& ranges). void SetMaxCalls(Int_t mc); accessors. { fMaxCalls = mc; }. void SetInitTemp(Double_t it); { fInitialTemperature = it; }. void SetMinTemp(Double_t min); { fMinTemperature = min; }. void SetAccuracy(Double_t eps); { fEps = eps; }. void SetTemperatureScale(Double_t scale); { fTemperatureScale = scale; }. void SetAdaptiveSpeed(Double_t speed); { fAdaptiveSpeed = speed; }. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Krzysztof Danielowski, Kamil Kraszewski, Maciej Kruk » Copyright (c) 2008: *; » Last changed: root/tmva $Id: SimulatedAnnealing.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:20; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__SimulatedAnnealing.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__SimulatedAnnealing.html
https://root.cern/root/html532/TMVA__SimulatedAnnealing.html:2358,Testability,log,logger,2358,"ble_t>& parameters, Double_t currentTemperature); voidGenerateNeighbour(vector<Double_t>& parameters, vector<Double_t>& oldParameters, Double_t currentTemperature); voidGenerateNewTemperature(Double_t& currentTemperature, Int_t Iter); TMVA::MsgLogger&Log() const; voidReWriteParameters(vector<Double_t>& from, vector<Double_t>& to); voidSetDefaultScale(); Bool_tShouldGoIn(Double_t currentFit, Double_t localFit, Double_t currentTemperature). Data Members; public:. enum EKernelTemperature { kSqrt; kIncreasingAdaptive; kDecreasingAdaptive; kLog; kHomo; kSin; kGeo; };. private:. Double_tfAdaptiveSpeedhow fast temperature change in adaptive (in adaptive two variables describe; Double_tfEpsepsilon; TMVA::IFitterTarget&fFitterTargetthe fitter target; Double_tfInitialTemperatureinitial temperature; TMVA::SimulatedAnnealing::EKernelTemperaturefKernelTemperature; TMVA::MsgLogger*fLoggermessage logger; Int_tfMaxCallsmaximum number of minimisation calls; Double_tfMinTemperaturemimimum temperature; Double_tfProgress; TRandom*fRandomrandom generator; const vector<TMVA::Interval*>&fRangesparameter ranges; Double_tfTemperatureAdaptiveStepused to calculate InitialTemperature if fUseDefaultTemperature; Double_tfTemperatureScalehow fast temperature change; Bool_tfUseDefaultScaleif TRUE, SA calculates its own TemperatureScale; Bool_tfUseDefaultTemperatureif TRUE, SA calculates its own InitialTemperature (MinTemperautre). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; SimulatedAnnealing(TMVA::IFitterTarget& target, const vector<TMVA::Interval*>& ranges); constructor. void SetOptions(Int_t maxCalls, Double_t initialTemperature, Double_t minTemperature, Double_t eps, TString kernelTemperatureS, Double_t temperatureScale, Double_t adaptiveSpeed, Double_t temperatureAdaptiveStep, Bool_t useDefaultScale, Bool_t useDefaultTemperature); option setter. ~SimulatedAnnealing(); destructor. void FillWithRandomValues(vector<Double_t>& parameters); random star",MatchSource.WIKI,root/html532/TMVA__SimulatedAnnealing.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__SimulatedAnnealing.html
https://root.cern/root/html532/TMVA__SimulatedAnnealingFitter.html:1657,Availability,error,error,1657,"t::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tTMVA::FitterBase::EstimatorFunction(vector<Double_t>& parameters); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TMVA::IFitterTarget&TMVA::FitterBase::GetFitterTarget() const; virtual const char*TObject::GetIconName() const; virtual const char*TMVA::FitterBase::GetName() const; Int_tTMVA::FitterBase::GetNpars() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&TMVA::Configurable::GetOptions() const; virtual const char*TObject::GetT",MatchSource.WIKI,root/html532/TMVA__SimulatedAnnealingFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__SimulatedAnnealingFitter.html
https://root.cern/root/html532/TMVA__SimulatedAnnealingFitter.html:1741,Availability,error,error,1741,"c TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tTMVA::FitterBase::EstimatorFunction(vector<Double_t>& parameters); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TMVA::IFitterTarget&TMVA::FitterBase::GetFitterTarget() const; virtual const char*TObject::GetIconName() const; virtual const char*TMVA::FitterBase::GetName() const; Int_tTMVA::FitterBase::GetNpars() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&TMVA::Configurable::GetOptions() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::Han",MatchSource.WIKI,root/html532/TMVA__SimulatedAnnealingFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__SimulatedAnnealingFitter.html
https://root.cern/root/html532/TMVA__SimulatedAnnealingFitter.html:8663,Deployability,configurat,configuration,8663,"Targetpointer to target of fitting procedure; TMVA::MsgLogger*TMVA::FitterBase::fLoggermessage logger; Int_tTMVA::FitterBase::fNparsnumber of parameters; const vector<TMVA::Interval*>TMVA::FitterBase::fRangesallowed intervals. private:. Double_tfAdaptiveSpeedhow fast temperature change in adaptive (in adaptive two variables describe; Double_tfEpsrelative required FCN accuracy at minimum; Double_tfInitialTemperatureinitial temperature (depends on FCN); TStringfKernelTemperatureSstring just to set fKernelTemperature; Int_tfMaxCallsmax number of FCN calls; Double_tfMinTemperatureminimum temperature before SA quit; Double_tfTemperatureAdaptiveStepused to calculate InitialTemperature if fUseDefaultTemperature; Double_tfTemperatureScalehow fast temperature change; Bool_tfUseDefaultScaleif TRUE, SA calculates its own TemperatureScale; Bool_tfUseDefaultTemperatureif TRUE, SA calculates its own InitialTemperature (MinTemperautre). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; SimulatedAnnealingFitter(TMVA::IFitterTarget& target, const TString& name, const vector<TMVA::Interval*>& ranges, const TString& theOption); constructor. void DeclareOptions(); declare SA options. void SetParameters(Int_t fMaxCalls, Double_t fInitialTemperature, Double_t fMinTemperature, Double_t fEps, TString fKernelTemperatureS, Double_t fTemperatureScale, Double_t fTemperatureAdaptiveStep, Bool_t fUseDefaultScale, Bool_t fUseDefaultTemperature); set SA configuration parameters. Double_t Run(vector<Double_t>& pars); Execute fitting. virtual ~SimulatedAnnealingFitter(); {}. » Author: Andreas Hoecker, Krzysztof Danielowski, Kamil Kraszewski, Maciej Kruk » Copyright (c) 2008: *; » Last changed: root/tmva $Id: SimulatedAnnealingFitter.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:20; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__SimulatedAnnealingFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__SimulatedAnnealingFitter.html
https://root.cern/root/html532/TMVA__SimulatedAnnealingFitter.html:7466,Energy Efficiency,adapt,adaptive,7466,"areOptions(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringTMVA::FitterBase::fClassNameremove TMVA:: from TObject name; TMVA::IFitterTarget&TMVA::FitterBase::fFitterTargetpointer to target of fitting procedure; TMVA::MsgLogger*TMVA::FitterBase::fLoggermessage logger; Int_tTMVA::FitterBase::fNparsnumber of parameters; const vector<TMVA::Interval*>TMVA::FitterBase::fRangesallowed intervals. private:. Double_tfAdaptiveSpeedhow fast temperature change in adaptive (in adaptive two variables describe; Double_tfEpsrelative required FCN accuracy at minimum; Double_tfInitialTemperatureinitial temperature (depends on FCN); TStringfKernelTemperatureSstring just to set fKernelTemperature; Int_tfMaxCallsmax number of FCN calls; Double_tfMinTemperatureminimum temperature before SA quit; Double_tfTemperatureAdaptiveStepused to calculate InitialTemperature if fUseDefaultTemperature; Double_tfTemperatureScalehow fast temperature change; Bool_tfUseDefaultScaleif TRUE, SA calculates its own TemperatureScale; Bool_tfUseDefaultTemperatureif TRUE, SA calculates its own InitialTemperature (MinTemperautre). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; SimulatedAnnealingFitter(TMVA::IFitterTarget& target, const TString& name, const vector<TMVA::Interval*>& ranges, const TString& theOption); constructor. void DeclareOptions(); declare SA options. void SetParameters(Int_t fMaxCalls, Double_t fInitialTemperature, Double_t fMinTemperature, Double_t fEps, TString fKernelTemperatureS, Double_t fTemperatureScale, Double_t fTemperatureAdaptiveStep, Bool_t fUseDefaultScale, Bool_t fUseDefaultTemperature); set SA configuration parameters. Double_t Run(vector<Double_t>& pars); Execute fitting. virtual ~Simulated",MatchSource.WIKI,root/html532/TMVA__SimulatedAnnealingFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__SimulatedAnnealingFitter.html
https://root.cern/root/html532/TMVA__SimulatedAnnealingFitter.html:7479,Energy Efficiency,adapt,adaptive,7479,"areOptions(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringTMVA::FitterBase::fClassNameremove TMVA:: from TObject name; TMVA::IFitterTarget&TMVA::FitterBase::fFitterTargetpointer to target of fitting procedure; TMVA::MsgLogger*TMVA::FitterBase::fLoggermessage logger; Int_tTMVA::FitterBase::fNparsnumber of parameters; const vector<TMVA::Interval*>TMVA::FitterBase::fRangesallowed intervals. private:. Double_tfAdaptiveSpeedhow fast temperature change in adaptive (in adaptive two variables describe; Double_tfEpsrelative required FCN accuracy at minimum; Double_tfInitialTemperatureinitial temperature (depends on FCN); TStringfKernelTemperatureSstring just to set fKernelTemperature; Int_tfMaxCallsmax number of FCN calls; Double_tfMinTemperatureminimum temperature before SA quit; Double_tfTemperatureAdaptiveStepused to calculate InitialTemperature if fUseDefaultTemperature; Double_tfTemperatureScalehow fast temperature change; Bool_tfUseDefaultScaleif TRUE, SA calculates its own TemperatureScale; Bool_tfUseDefaultTemperatureif TRUE, SA calculates its own InitialTemperature (MinTemperautre). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; SimulatedAnnealingFitter(TMVA::IFitterTarget& target, const TString& name, const vector<TMVA::Interval*>& ranges, const TString& theOption); constructor. void DeclareOptions(); declare SA options. void SetParameters(Int_t fMaxCalls, Double_t fInitialTemperature, Double_t fMinTemperature, Double_t fEps, TString fKernelTemperatureS, Double_t fTemperatureScale, Double_t fTemperatureAdaptiveStep, Bool_t fUseDefaultScale, Bool_t fUseDefaultTemperature); set SA configuration parameters. Double_t Run(vector<Double_t>& pars); Execute fitting. virtual ~Simulated",MatchSource.WIKI,root/html532/TMVA__SimulatedAnnealingFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__SimulatedAnnealingFitter.html
https://root.cern/root/html532/TMVA__SimulatedAnnealingFitter.html:7615,Integrability,depend,depends,7615,"areOptions(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringTMVA::FitterBase::fClassNameremove TMVA:: from TObject name; TMVA::IFitterTarget&TMVA::FitterBase::fFitterTargetpointer to target of fitting procedure; TMVA::MsgLogger*TMVA::FitterBase::fLoggermessage logger; Int_tTMVA::FitterBase::fNparsnumber of parameters; const vector<TMVA::Interval*>TMVA::FitterBase::fRangesallowed intervals. private:. Double_tfAdaptiveSpeedhow fast temperature change in adaptive (in adaptive two variables describe; Double_tfEpsrelative required FCN accuracy at minimum; Double_tfInitialTemperatureinitial temperature (depends on FCN); TStringfKernelTemperatureSstring just to set fKernelTemperature; Int_tfMaxCallsmax number of FCN calls; Double_tfMinTemperatureminimum temperature before SA quit; Double_tfTemperatureAdaptiveStepused to calculate InitialTemperature if fUseDefaultTemperature; Double_tfTemperatureScalehow fast temperature change; Bool_tfUseDefaultScaleif TRUE, SA calculates its own TemperatureScale; Bool_tfUseDefaultTemperatureif TRUE, SA calculates its own InitialTemperature (MinTemperautre). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; SimulatedAnnealingFitter(TMVA::IFitterTarget& target, const TString& name, const vector<TMVA::Interval*>& ranges, const TString& theOption); constructor. void DeclareOptions(); declare SA options. void SetParameters(Int_t fMaxCalls, Double_t fInitialTemperature, Double_t fMinTemperature, Double_t fEps, TString fKernelTemperatureS, Double_t fTemperatureScale, Double_t fTemperatureAdaptiveStep, Bool_t fUseDefaultScale, Bool_t fUseDefaultTemperature); set SA configuration parameters. Double_t Run(vector<Double_t>& pars); Execute fitting. virtual ~Simulated",MatchSource.WIKI,root/html532/TMVA__SimulatedAnnealingFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__SimulatedAnnealingFitter.html
https://root.cern/root/html532/TMVA__SimulatedAnnealingFitter.html:7466,Modifiability,adapt,adaptive,7466,"areOptions(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringTMVA::FitterBase::fClassNameremove TMVA:: from TObject name; TMVA::IFitterTarget&TMVA::FitterBase::fFitterTargetpointer to target of fitting procedure; TMVA::MsgLogger*TMVA::FitterBase::fLoggermessage logger; Int_tTMVA::FitterBase::fNparsnumber of parameters; const vector<TMVA::Interval*>TMVA::FitterBase::fRangesallowed intervals. private:. Double_tfAdaptiveSpeedhow fast temperature change in adaptive (in adaptive two variables describe; Double_tfEpsrelative required FCN accuracy at minimum; Double_tfInitialTemperatureinitial temperature (depends on FCN); TStringfKernelTemperatureSstring just to set fKernelTemperature; Int_tfMaxCallsmax number of FCN calls; Double_tfMinTemperatureminimum temperature before SA quit; Double_tfTemperatureAdaptiveStepused to calculate InitialTemperature if fUseDefaultTemperature; Double_tfTemperatureScalehow fast temperature change; Bool_tfUseDefaultScaleif TRUE, SA calculates its own TemperatureScale; Bool_tfUseDefaultTemperatureif TRUE, SA calculates its own InitialTemperature (MinTemperautre). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; SimulatedAnnealingFitter(TMVA::IFitterTarget& target, const TString& name, const vector<TMVA::Interval*>& ranges, const TString& theOption); constructor. void DeclareOptions(); declare SA options. void SetParameters(Int_t fMaxCalls, Double_t fInitialTemperature, Double_t fMinTemperature, Double_t fEps, TString fKernelTemperatureS, Double_t fTemperatureScale, Double_t fTemperatureAdaptiveStep, Bool_t fUseDefaultScale, Bool_t fUseDefaultTemperature); set SA configuration parameters. Double_t Run(vector<Double_t>& pars); Execute fitting. virtual ~Simulated",MatchSource.WIKI,root/html532/TMVA__SimulatedAnnealingFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__SimulatedAnnealingFitter.html
https://root.cern/root/html532/TMVA__SimulatedAnnealingFitter.html:7479,Modifiability,adapt,adaptive,7479,"areOptions(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringTMVA::FitterBase::fClassNameremove TMVA:: from TObject name; TMVA::IFitterTarget&TMVA::FitterBase::fFitterTargetpointer to target of fitting procedure; TMVA::MsgLogger*TMVA::FitterBase::fLoggermessage logger; Int_tTMVA::FitterBase::fNparsnumber of parameters; const vector<TMVA::Interval*>TMVA::FitterBase::fRangesallowed intervals. private:. Double_tfAdaptiveSpeedhow fast temperature change in adaptive (in adaptive two variables describe; Double_tfEpsrelative required FCN accuracy at minimum; Double_tfInitialTemperatureinitial temperature (depends on FCN); TStringfKernelTemperatureSstring just to set fKernelTemperature; Int_tfMaxCallsmax number of FCN calls; Double_tfMinTemperatureminimum temperature before SA quit; Double_tfTemperatureAdaptiveStepused to calculate InitialTemperature if fUseDefaultTemperature; Double_tfTemperatureScalehow fast temperature change; Bool_tfUseDefaultScaleif TRUE, SA calculates its own TemperatureScale; Bool_tfUseDefaultTemperatureif TRUE, SA calculates its own InitialTemperature (MinTemperautre). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; SimulatedAnnealingFitter(TMVA::IFitterTarget& target, const TString& name, const vector<TMVA::Interval*>& ranges, const TString& theOption); constructor. void DeclareOptions(); declare SA options. void SetParameters(Int_t fMaxCalls, Double_t fInitialTemperature, Double_t fMinTemperature, Double_t fEps, TString fKernelTemperatureS, Double_t fTemperatureScale, Double_t fTemperatureAdaptiveStep, Bool_t fUseDefaultScale, Bool_t fUseDefaultTemperature); set SA configuration parameters. Double_t Run(vector<Double_t>& pars); Execute fitting. virtual ~Simulated",MatchSource.WIKI,root/html532/TMVA__SimulatedAnnealingFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__SimulatedAnnealingFitter.html
https://root.cern/root/html532/TMVA__SimulatedAnnealingFitter.html:7492,Modifiability,variab,variables,7492,"areOptions(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringTMVA::FitterBase::fClassNameremove TMVA:: from TObject name; TMVA::IFitterTarget&TMVA::FitterBase::fFitterTargetpointer to target of fitting procedure; TMVA::MsgLogger*TMVA::FitterBase::fLoggermessage logger; Int_tTMVA::FitterBase::fNparsnumber of parameters; const vector<TMVA::Interval*>TMVA::FitterBase::fRangesallowed intervals. private:. Double_tfAdaptiveSpeedhow fast temperature change in adaptive (in adaptive two variables describe; Double_tfEpsrelative required FCN accuracy at minimum; Double_tfInitialTemperatureinitial temperature (depends on FCN); TStringfKernelTemperatureSstring just to set fKernelTemperature; Int_tfMaxCallsmax number of FCN calls; Double_tfMinTemperatureminimum temperature before SA quit; Double_tfTemperatureAdaptiveStepused to calculate InitialTemperature if fUseDefaultTemperature; Double_tfTemperatureScalehow fast temperature change; Bool_tfUseDefaultScaleif TRUE, SA calculates its own TemperatureScale; Bool_tfUseDefaultTemperatureif TRUE, SA calculates its own InitialTemperature (MinTemperautre). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; SimulatedAnnealingFitter(TMVA::IFitterTarget& target, const TString& name, const vector<TMVA::Interval*>& ranges, const TString& theOption); constructor. void DeclareOptions(); declare SA options. void SetParameters(Int_t fMaxCalls, Double_t fInitialTemperature, Double_t fMinTemperature, Double_t fEps, TString fKernelTemperatureS, Double_t fTemperatureScale, Double_t fTemperatureAdaptiveStep, Bool_t fUseDefaultScale, Bool_t fUseDefaultTemperature); set SA configuration parameters. Double_t Run(vector<Double_t>& pars); Execute fitting. virtual ~Simulated",MatchSource.WIKI,root/html532/TMVA__SimulatedAnnealingFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__SimulatedAnnealingFitter.html
https://root.cern/root/html532/TMVA__SimulatedAnnealingFitter.html:8663,Modifiability,config,configuration,8663,"Targetpointer to target of fitting procedure; TMVA::MsgLogger*TMVA::FitterBase::fLoggermessage logger; Int_tTMVA::FitterBase::fNparsnumber of parameters; const vector<TMVA::Interval*>TMVA::FitterBase::fRangesallowed intervals. private:. Double_tfAdaptiveSpeedhow fast temperature change in adaptive (in adaptive two variables describe; Double_tfEpsrelative required FCN accuracy at minimum; Double_tfInitialTemperatureinitial temperature (depends on FCN); TStringfKernelTemperatureSstring just to set fKernelTemperature; Int_tfMaxCallsmax number of FCN calls; Double_tfMinTemperatureminimum temperature before SA quit; Double_tfTemperatureAdaptiveStepused to calculate InitialTemperature if fUseDefaultTemperature; Double_tfTemperatureScalehow fast temperature change; Bool_tfUseDefaultScaleif TRUE, SA calculates its own TemperatureScale; Bool_tfUseDefaultTemperatureif TRUE, SA calculates its own InitialTemperature (MinTemperautre). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; SimulatedAnnealingFitter(TMVA::IFitterTarget& target, const TString& name, const vector<TMVA::Interval*>& ranges, const TString& theOption); constructor. void DeclareOptions(); declare SA options. void SetParameters(Int_t fMaxCalls, Double_t fInitialTemperature, Double_t fMinTemperature, Double_t fEps, TString fKernelTemperatureS, Double_t fTemperatureScale, Double_t fTemperatureAdaptiveStep, Bool_t fUseDefaultScale, Bool_t fUseDefaultTemperature); set SA configuration parameters. Double_t Run(vector<Double_t>& pars); Execute fitting. virtual ~SimulatedAnnealingFitter(); {}. » Author: Andreas Hoecker, Krzysztof Danielowski, Kamil Kraszewski, Maciej Kruk » Copyright (c) 2008: *; » Last changed: root/tmva $Id: SimulatedAnnealingFitter.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:20; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__SimulatedAnnealingFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__SimulatedAnnealingFitter.html
https://root.cern/root/html532/TMVA__SimulatedAnnealingFitter.html:7271,Testability,log,logger,7271,"tream& o, const TString& prefix) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&TMVA::FitterBase::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. virtual voidDeclareOptions(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringTMVA::FitterBase::fClassNameremove TMVA:: from TObject name; TMVA::IFitterTarget&TMVA::FitterBase::fFitterTargetpointer to target of fitting procedure; TMVA::MsgLogger*TMVA::FitterBase::fLoggermessage logger; Int_tTMVA::FitterBase::fNparsnumber of parameters; const vector<TMVA::Interval*>TMVA::FitterBase::fRangesallowed intervals. private:. Double_tfAdaptiveSpeedhow fast temperature change in adaptive (in adaptive two variables describe; Double_tfEpsrelative required FCN accuracy at minimum; Double_tfInitialTemperatureinitial temperature (depends on FCN); TStringfKernelTemperatureSstring just to set fKernelTemperature; Int_tfMaxCallsmax number of FCN calls; Double_tfMinTemperatureminimum temperature before SA quit; Double_tfTemperatureAdaptiveStepused to calculate InitialTemperature if fUseDefaultTemperature; Double_tfTemperatureScalehow fast temperature change; Bool_tfUseDefaultScaleif TRUE, SA calculates its own TemperatureScale; Bool_tfUseDefaultTemperatureif TRUE, SA calculates its own InitialTemperature (MinTemperautre). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; SimulatedAnnealingFitter(TMVA",MatchSource.WIKI,root/html532/TMVA__SimulatedAnnealingFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__SimulatedAnnealingFitter.html
https://root.cern/root/html532/TMVA__SVEvent.html:1923,Modifiability,variab,variables,1923,"int(ostream& os) const; voidPrintData(); voidSetAlpha(Float_t alpha); voidSetAlpha_p(Float_t alpha); voidSetErrorCache(Float_t err_cache); voidSetIdx(Int_t idx); voidSetIsShrinked(Int_t isshrinked); voidSetLine(Float_t* line); voidSetNs(UInt_t ns); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); TMVA::SVEventSVEvent(); TMVA::SVEventSVEvent(const TMVA::SVEvent&); TMVA::SVEventSVEvent(const TMVA::Event*, Float_t, Bool_t isSignal = kFALSE); TMVA::SVEventSVEvent(const vector<Float_t>*, Float_t alpha, Int_t typeFlag, UInt_t ns); TMVA::SVEventSVEvent(const vector<Float_t>* svector, Float_t alpha, Float_t alpha_p, Int_t typeFlag); voidUpdateErrorCache(Float_t upercache). Data Members; private:. Float_tfAlphalagrange multiplier; Float_tfAlpha_plagrange multiplier; const Float_tfCweightsvm cost weight; vector<Float_t>fDataVector; Float_tfErrorCacheoptimization parameter; Int_tfIdxindex flag; Int_tfIsShrinkedshrinking flag, see documentation; Float_t*fLinepointer to column of kerenl matrix ; UInt_tfNVarnumber of variables; UInt_tfNsdocumentation; const Float_tfTargetregression target; const Int_tfTypeFlagis sig or bkg - svm requieres 1 for sig and -1 for bkg. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; SVEvent(). SVEvent(const TMVA::Event* , Float_t , Bool_t isSignal = kFALSE); constructor. SVEvent(const vector<Float_t>* , Float_t alpha, Int_t typeFlag, UInt_t ns); constructor. SVEvent(const vector<Float_t>* svector, Float_t alpha, Float_t alpha_p, Int_t typeFlag); constructor. ~SVEvent(); destructor. void Print(ostream& os) const; printout. void PrintData(); printout. SVEvent(). void SetAlpha(Float_t alpha); { fAlpha = alpha; }. void SetAlpha_p(Float_t alpha); { fAlpha_p = alpha; }. void SetErrorCache(Float_t err_cache); { fErrorCache = err_cache; }. void SetIsShrinked(Int_t isshrinked); { fIsShrinked = isshrinked; }. void SetLine(Float_t* line); { fLine = line;",MatchSource.WIKI,root/html532/TMVA__SVEvent.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__SVEvent.html
https://root.cern/root/html532/TMVA__TActivation.html:422,Availability,avail,available,422,". TMVA::TActivation. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::TActivation. class TMVA::TActivation. Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~TActivation(); static TClass*Class(); virtual Double_tEval(Double_t arg); virtual Double_tEvalDerivative(Double_t arg); virtual TStringGetExpression(); virtual Double_tGetMax(); virtual Double_tGetMin(); virtual TClass*IsA() const; virtual voidMakeFunction(ostream& fout, const TString& fncName); TMVA::TActivation&operator=(const TMVA::TActivation&); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; virtual ~TActivation(); {}. Double_t Eval(Double_t arg); evaluate the activation function. Double_t EvalDerivative(Double_t arg); evaulate the derivative of the activation function. Double_t GetMin(); minimum of the range of activation function. Double_t GetMax(); maximum of the range of the activation function. TString GetExpression(); expression for activation function. void MakeFunction(ostream& fout, const TString& fncName); writer of function code. » Author: Matt Jachowski » Copyright (c) 2005: *; » Last changed: root/tmva $Id: TActivation.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:20; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__TActivation.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__TActivation.html
https://root.cern/root/html532/TMVA__TActivationChooser.html:1203,Integrability,message,message,1203, charts. ROOT; » TMVA; » TMVA::TActivationChooser. class TMVA::TActivationChooser. TActivationChooser. Class for easily choosing activation functions. Function Members (Methods); public:. virtual~TActivationChooser(); static TClass*Class(); TMVA::TActivation*CreateActivation(TMVA::TActivationChooser::EActivationType type) const; TMVA::TActivation*CreateActivation(const TString& type) const; vector<TString>*GetAllActivationNames() const; virtual TClass*IsA() const; TMVA::TActivationChooser&operator=(const TMVA::TActivationChooser&); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); TMVA::TActivationChooserTActivationChooser(); TMVA::TActivationChooserTActivationChooser(const TMVA::TActivationChooser&). private:. TMVA::MsgLogger&Log() const. Data Members; public:. enum EActivationType { kLinear; kSigmoid; kTanh; kRadial; };. private:. TStringfLINEARactivation function name; TMVA::MsgLogger*fLogger! message logger; TStringfRADIALactivation function name; TStringfSIGMOIDactivation function name; TStringfTANHactivation function name. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TActivationChooser(); defaut constructor. ~TActivationChooser(); destructor. CreateActivation(EActivationType type); instantiate the correct activation object according to the; type choosen (given as the enumeration type). CreateActivation(const TString& type) const; instantiate the correct activation object according to the; type choosen (given by a TString). GetAllActivationNames() const; retuns the names of all know activation functions. TActivationChooser(). » Author: Matt Jachowski » Copyright (c) 2005: *; » Last changed: root/tmva $Id: TActivationChooser.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:20; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ,MatchSource.WIKI,root/html532/TMVA__TActivationChooser.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__TActivationChooser.html
https://root.cern/root/html532/TMVA__TActivationChooser.html:1211,Testability,log,logger,1211, charts. ROOT; » TMVA; » TMVA::TActivationChooser. class TMVA::TActivationChooser. TActivationChooser. Class for easily choosing activation functions. Function Members (Methods); public:. virtual~TActivationChooser(); static TClass*Class(); TMVA::TActivation*CreateActivation(TMVA::TActivationChooser::EActivationType type) const; TMVA::TActivation*CreateActivation(const TString& type) const; vector<TString>*GetAllActivationNames() const; virtual TClass*IsA() const; TMVA::TActivationChooser&operator=(const TMVA::TActivationChooser&); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); TMVA::TActivationChooserTActivationChooser(); TMVA::TActivationChooserTActivationChooser(const TMVA::TActivationChooser&). private:. TMVA::MsgLogger&Log() const. Data Members; public:. enum EActivationType { kLinear; kSigmoid; kTanh; kRadial; };. private:. TStringfLINEARactivation function name; TMVA::MsgLogger*fLogger! message logger; TStringfRADIALactivation function name; TStringfSIGMOIDactivation function name; TStringfTANHactivation function name. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TActivationChooser(); defaut constructor. ~TActivationChooser(); destructor. CreateActivation(EActivationType type); instantiate the correct activation object according to the; type choosen (given as the enumeration type). CreateActivation(const TString& type) const; instantiate the correct activation object according to the; type choosen (given by a TString). GetAllActivationNames() const; retuns the names of all know activation functions. TActivationChooser(). » Author: Matt Jachowski » Copyright (c) 2005: *; » Last changed: root/tmva $Id: TActivationChooser.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:20; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ,MatchSource.WIKI,root/html532/TMVA__TActivationChooser.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__TActivationChooser.html
